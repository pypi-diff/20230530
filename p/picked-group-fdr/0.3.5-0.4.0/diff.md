# Comparing `tmp/picked_group_fdr-0.3.5-py3-none-any.whl.zip` & `tmp/picked_group_fdr-0.4.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,22 +1,23 @@
-Zip file size: 185450 bytes, number of entries: 73
+Zip file size: 186572 bytes, number of entries: 73
 -rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 LICENSE
--rw-r--r--  2.0 unx      889 b- defN 80-Jan-01 00:00 picked_group_fdr/__init__.py
+-rw-r--r--  2.0 unx     1528 b- defN 80-Jan-01 00:00 picked_group_fdr/__init__.py
 -rw-r--r--  2.0 unx      180 b- defN 80-Jan-01 00:00 picked_group_fdr/__main__.py
 -rw-r--r--  2.0 unx     6244 b- defN 80-Jan-01 00:00 picked_group_fdr/competition.py
--rwxr-xr-x  2.0 unx    22658 b- defN 80-Jan-01 00:00 picked_group_fdr/digest.py
+-rwxr-xr-x  2.0 unx    22945 b- defN 80-Jan-01 00:00 picked_group_fdr/digest.py
 -rw-r--r--  2.0 unx   432703 b- defN 80-Jan-01 00:00 picked_group_fdr/digestfast.cpp
 -rw-r--r--  2.0 unx   220141 b- defN 80-Jan-01 00:00 picked_group_fdr/digestfast.html
 -rw-r--r--  2.0 unx     3923 b- defN 80-Jan-01 00:00 picked_group_fdr/digestfast.pyx
 -rw-r--r--  2.0 unx     1725 b- defN 80-Jan-01 00:00 picked_group_fdr/entrapment.py
--rw-r--r--  2.0 unx     3255 b- defN 80-Jan-01 00:00 picked_group_fdr/fdr.py
+-rw-r--r--  2.0 unx     3120 b- defN 80-Jan-01 00:00 picked_group_fdr/fdr.py
 -rw-r--r--  2.0 unx     5782 b- defN 80-Jan-01 00:00 picked_group_fdr/graphs.py
--rw-r--r--  2.0 unx    10312 b- defN 80-Jan-01 00:00 picked_group_fdr/grouping.py
+-rw-r--r--  2.0 unx    10453 b- defN 80-Jan-01 00:00 picked_group_fdr/grouping.py
 -rw-r--r--  2.0 unx     2006 b- defN 80-Jan-01 00:00 picked_group_fdr/helpers.py
 -rw-r--r--  2.0 unx      134 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/classic_no_grouping.toml
+-rw-r--r--  2.0 unx      128 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/classic_no_grouping_no_remap.toml
 -rw-r--r--  2.0 unx      152 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/classic_protein_group.toml
 -rw-r--r--  2.0 unx      158 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/classic_rescued_subset_grouping.toml
 -rw-r--r--  2.0 unx      142 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/classic_subset_grouping.toml
 -rw-r--r--  2.0 unx      142 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/discard_picked.toml
 -rw-r--r--  2.0 unx      131 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/discard_picked_mq_input.toml
 -rw-r--r--  2.0 unx      114 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/maxquant.toml
 -rw-r--r--  2.0 unx      128 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/maxquant_mq_best.toml
@@ -30,46 +31,45 @@
 -rw-r--r--  2.0 unx      138 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/razor_picked.toml
 -rw-r--r--  2.0 unx      127 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/razor_picked_mq_input.toml
 -rw-r--r--  2.0 unx      122 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/savitski.toml
 -rw-r--r--  2.0 unx      123 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/savitski_classic.toml
 -rw-r--r--  2.0 unx      125 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/savitski_mq_best.toml
 -rw-r--r--  2.0 unx      125 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/savitski_mq_mult.toml
 -rw-r--r--  2.0 unx      116 b- defN 80-Jan-01 00:00 picked_group_fdr/methods/savitski_no_remap.toml
--rw-r--r--  2.0 unx     9633 b- defN 80-Jan-01 00:00 picked_group_fdr/methods.py
+-rw-r--r--  2.0 unx     9984 b- defN 80-Jan-01 00:00 picked_group_fdr/methods.py
 -rw-r--r--  2.0 unx     7163 b- defN 80-Jan-01 00:00 picked_group_fdr/observed_peptides.py
--rw-r--r--  2.0 unx    12947 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers.py
+-rw-r--r--  2.0 unx    13694 b- defN 80-Jan-01 00:00 picked_group_fdr/parsers.py
 -rw-r--r--  2.0 unx      295 b- defN 80-Jan-01 00:00 picked_group_fdr/peptide_info.py
--rw-r--r--  2.0 unx    13421 b- defN 80-Jan-01 00:00 picked_group_fdr/picked_group_fdr.py
+-rw-r--r--  2.0 unx    14009 b- defN 80-Jan-01 00:00 picked_group_fdr/picked_group_fdr.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/__init__.py
--rw-r--r--  2.0 unx    10619 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/andromeda2pin.py
--rw-r--r--  2.0 unx    14132 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/filter_fdr_maxquant.py
--rw-r--r--  2.0 unx     6126 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/merge_pout.py
+-rw-r--r--  2.0 unx    11039 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/andromeda2pin.py
+-rw-r--r--  2.0 unx    14156 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/filter_fdr_maxquant.py
+-rw-r--r--  2.0 unx     6140 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/merge_pout.py
 -rw-r--r--  2.0 unx     2018 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/run_mokapot.py
--rw-r--r--  2.0 unx    13618 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/update_evidence_from_pout.py
+-rw-r--r--  2.0 unx    13632 b- defN 80-Jan-01 00:00 picked_group_fdr/pipeline/update_evidence_from_pout.py
 -rw-r--r--  2.0 unx     7002 b- defN 80-Jan-01 00:00 picked_group_fdr/plotter.py
 -rw-r--r--  2.0 unx     5873 b- defN 80-Jan-01 00:00 picked_group_fdr/protein_groups.py
 -rw-r--r--  2.0 unx     4523 b- defN 80-Jan-01 00:00 picked_group_fdr/proteotypicity.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/__init__.py
 -rw-r--r--  2.0 unx      296 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/base.py
 -rw-r--r--  2.0 unx     1028 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/evidence_ids.py
 -rw-r--r--  2.0 unx     1263 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/id_type.py
 -rw-r--r--  2.0 unx    13389 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/lfq.py
 -rw-r--r--  2.0 unx     1229 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/peptide_count.py
 -rw-r--r--  2.0 unx      315 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/precursor_quant.py
 -rw-r--r--  2.0 unx     3593 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/sequence_coverage.py
 -rw-r--r--  2.0 unx     3909 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/sum_and_ibaq.py
 -rw-r--r--  2.0 unx     1769 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/tmt.py
 -rw-r--r--  2.0 unx     7312 b- defN 80-Jan-01 00:00 picked_group_fdr/quant/triqler.py
--rw-r--r--  2.0 unx    17843 b- defN 80-Jan-01 00:00 picked_group_fdr/quantification.py
--rw-r--r--  2.0 unx     7957 b- defN 80-Jan-01 00:00 picked_group_fdr/results.py
--rw-r--r--  2.0 unx    15090 b- defN 80-Jan-01 00:00 picked_group_fdr/scoring.py
+-rw-r--r--  2.0 unx    18041 b- defN 80-Jan-01 00:00 picked_group_fdr/quantification.py
+-rw-r--r--  2.0 unx     8506 b- defN 80-Jan-01 00:00 picked_group_fdr/results.py
+-rw-r--r--  2.0 unx    15088 b- defN 80-Jan-01 00:00 picked_group_fdr/scoring.py
 -rw-r--r--  2.0 unx      154 b- defN 80-Jan-01 00:00 picked_group_fdr/setup.py
 -rw-r--r--  2.0 unx    17000 b- defN 80-Jan-01 00:00 picked_group_fdr/simulation/simulate.py
 -rw-r--r--  2.0 unx     1539 b- defN 80-Jan-01 00:00 picked_group_fdr/utils/compare_results.py
 -rw-r--r--  2.0 unx     3412 b- defN 80-Jan-01 00:00 picked_group_fdr/utils/get_genes_with_multiple_isoforms.py
 -rw-r--r--  2.0 unx     4116 b- defN 80-Jan-01 00:00 picked_group_fdr/utils/multiprocessing_pool.py
--rw-r--r--  2.0 unx     1018 b- defN 80-Jan-01 00:00 picked_group_fdr/version.py
--rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 picked_group_fdr-0.3.5.dist-info/LICENSE
-?rw-r--r--  2.0 unx       83 b- defN 16-Jan-01 00:00 picked_group_fdr-0.3.5.dist-info/WHEEL
-?rw-r--r--  2.0 unx     3996 b- defN 16-Jan-01 00:00 picked_group_fdr-0.3.5.dist-info/METADATA
-?rw-r--r--  2.0 unx     6899 b- defN 16-Jan-01 00:00 picked_group_fdr-0.3.5.dist-info/RECORD
-73 files, 956110 bytes uncompressed, 174258 bytes compressed:  81.8%
+-rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 picked_group_fdr-0.4.0.dist-info/LICENSE
+?rw-r--r--  2.0 unx       83 b- defN 16-Jan-01 00:00 picked_group_fdr-0.4.0.dist-info/WHEEL
+?rw-r--r--  2.0 unx     4493 b- defN 16-Jan-01 00:00 picked_group_fdr-0.4.0.dist-info/METADATA
+?rw-r--r--  2.0 unx     6930 b- defN 16-Jan-01 00:00 picked_group_fdr-0.4.0.dist-info/RECORD
+73 files, 959583 bytes uncompressed, 175318 bytes compressed:  81.7%
```

## zipnote {}

```diff
@@ -36,14 +36,17 @@
 
 Filename: picked_group_fdr/helpers.py
 Comment: 
 
 Filename: picked_group_fdr/methods/classic_no_grouping.toml
 Comment: 
 
+Filename: picked_group_fdr/methods/classic_no_grouping_no_remap.toml
+Comment: 
+
 Filename: picked_group_fdr/methods/classic_protein_group.toml
 Comment: 
 
 Filename: picked_group_fdr/methods/classic_rescued_subset_grouping.toml
 Comment: 
 
 Filename: picked_group_fdr/methods/classic_subset_grouping.toml
@@ -198,23 +201,20 @@
 
 Filename: picked_group_fdr/utils/get_genes_with_multiple_isoforms.py
 Comment: 
 
 Filename: picked_group_fdr/utils/multiprocessing_pool.py
 Comment: 
 
-Filename: picked_group_fdr/version.py
-Comment: 
-
-Filename: picked_group_fdr-0.3.5.dist-info/LICENSE
+Filename: picked_group_fdr-0.4.0.dist-info/LICENSE
 Comment: 
 
-Filename: picked_group_fdr-0.3.5.dist-info/WHEEL
+Filename: picked_group_fdr-0.4.0.dist-info/WHEEL
 Comment: 
 
-Filename: picked_group_fdr-0.3.5.dist-info/METADATA
+Filename: picked_group_fdr-0.4.0.dist-info/METADATA
 Comment: 
 
-Filename: picked_group_fdr-0.3.5.dist-info/RECORD
+Filename: picked_group_fdr-0.4.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## picked_group_fdr/__init__.py

```diff
@@ -1,11 +1,31 @@
 import sys
 import logging.handlers
 import time
 
+# get version number of Picked Group FDR
+__version__ = "0.0.0"
+try:
+    from importlib.metadata import version, PackageNotFoundError
+
+    try:
+        __version__ = version(__name__)
+    except PackageNotFoundError:
+        pass
+except ImportError:
+    from pkg_resources import get_distribution, DistributionNotFound
+
+    try:
+        __version__ = get_distribution(__name__).version
+    except DistributionNotFound:
+        pass
+
+__copyright__ = '''Copyright (c) 2020-2022 Matthew The. All rights reserved.
+Written by Matthew The (matthew.the@tum.de) at the
+Chair of Proteomics and Bioanalytics at the Technical University of Munich.'''
 
 CONSOLE_LOG_LEVEL = logging.INFO
 logger = logging.getLogger(__name__)
 logger.setLevel(logging.DEBUG)
 if len(logger.handlers) == 0:
     #formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(name)s::%(funcName)s %(message)s")
     formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
```

## picked_group_fdr/digest.py

```diff
@@ -144,14 +144,18 @@
                                          help='''Special AAs that MaxQuant uses for decoy generation.
                                                     ''')
     
     apars.add_argument('--digestion', default = DIGESTION_DEFAULT, metavar='D', 
                                          help='''Digestion mode ('full', 'semi' or 'none').
                                                     ''')
 
+    apars.add_argument('--fasta_contains_decoys',
+                         help='Set this flag if your fasta file already contains decoy protein sequences.',
+                         action='store_true')
+
 
 def writeProteinToGeneMap(fastaFile, outputFile):
     writer = csv.writer(open(outputFile, 'w'), delimiter = '\t')
     for proteinName, _ in readFastaTide(fastaFile, db = "target"):
         proteinId = proteinName.split("|")[1]
         geneId = proteinName.split("|")[2].split(" ")[0]
         writer.writerow([proteinId, geneId])
@@ -352,16 +356,20 @@
 def get_peptide_to_protein_map(args, parseId):
     if args.fasta:
         logger.info("In silico protein digest for peptide-protein mapping")
         pre, not_post = getCleavageSites(args.enzyme)
         if args.enzyme == "no_enzyme":
             args.digestion = "none"
         
+        db = 'concat'
+        if args.fasta_contains_decoys:
+            db = 'target'
+
         peptideToProteinMap = getPeptideToProteinMap(
-                args.fasta, db = 'concat', digestion = args.digestion, 
+                args.fasta, db = db, digestion = args.digestion, 
                 min_len = args.min_length, max_len = args.max_length, 
                 pre = pre, not_post = not_post, 
                 miscleavages = args.cleavages, methionineCleavage = True, 
                 specialAAs = list(args.special_aas), useHashKey = (args.digestion == "none"), parseId = parseId)
     elif args.peptide_protein_map:
         logger.info("Loading peptide to protein map")
         peptideToProteinMap = getPeptideToProteinMapFromFile(args.peptide_protein_map, useHashKey = False)
```

## picked_group_fdr/fdr.py

```diff
@@ -52,24 +52,19 @@
 def printReportedAndEntrapmentFDRs(reportedQvals, observedQvals):
     import csv
     writer = csv.writer(open(f'protein_fdr_calibration_{datetime.now().strftime("%d%m%Y_%H%M%S")}.txt', 'w'), delimiter = '\t')
     for reportedQval, observedQval in zip(reportedQvals, observedQvals):
         writer.writerow([reportedQval, observedQval])
 
 
-def fdrsToQvals(fdrs: List[float]):
+def fdrsToQvals(fdrs: List[float]) -> np.array:
     """
     Makes a list of FDRs monotonically increasing (sometimes referred to as q-values after monotonization)
     """
-    qvals = [0] * len(fdrs)
-    if len(fdrs) > 0:
-        qvals[len(fdrs)-1] = fdrs[-1]
-        for i in range(len(fdrs)-2, -1, -1):
-            qvals[i] = min(qvals[i+1], fdrs[i])
-    return qvals
+    return np.minimum.accumulate(fdrs[::-1])[::-1]
 
 
 def countBelowThreshold(qvals: List[float], qvalThreshold: float, skipForCounting: Optional[List[bool]] = None):
     """
     Counts number of q-values below a threshold, if skipForCounting are provided, only the targets are counted
     """
     if skipForCounting is None:
```

## picked_group_fdr/grouping.py

```diff
@@ -198,15 +198,16 @@
     
     def _calculate_rescue_score_cutoff(self, proteinGroupResults: ProteinGroupResults):
         """Calculate PEP corresponding to 1% protein-level FDR. 
         N.B. this only works if the protein score is bestPEP!"""
         identifiedProteinScores = [pfr.score for pfr in proteinGroupResults if pfr.qValue < 0.01]
         
         if len(identifiedProteinScores) == 0:
-            raise ValueError("Could not calculate rescuing threshold as no proteins were found below 1% FDR")
+            logger.warning("Could not calculate rescuing threshold as no proteins were found below 1% FDR. Setting rescuing threshold to worst scoring protein's score.")
+            identifiedProteinScores = [pfr.score for pfr in proteinGroupResults]
 
         self.score_cutoff = np.power(10, min(identifiedProteinScores)*-1)
         logger.info(f"Rescuing threshold: protein score = {'{0:.3g}'.format(min(identifiedProteinScores))}, peptide PEP = {'{0:.3g}'.format(self.score_cutoff)}")
 
 
 class RescuedSubsetGrouping(RescuedGrouping, SubsetGrouping):
     def long_description(self, rescue_step):
```

## picked_group_fdr/methods.py

```diff
@@ -77,14 +77,20 @@
 
     return configs
 
 
 def parse_method_toml(method: str):
     dir_path = os.path.dirname(os.path.realpath(__file__))
     method_toml_file = os.path.join(dir_path, 'methods', f'{method}.toml')
+    if not os.path.isfile(method_toml_file):
+        if method.endswith(".toml") and os.path.isfile(method):
+            method_toml_file = method
+        else:
+            raise FileNotFoundError(f"Could not find method {method}. Please ensure that it is one of the builtin methods or that it is a path to a TOML file with a .toml file extension.")
+
     method = toml.load(method_toml_file)
     
     picked_strategy = ProteinCompetitionStrategyFactory(method['pickedStrategy'])
     score_type = method['scoreType']
     if method['sharedPeptides'] == "razor":
         score_type += " razor"
     scoring_strategy = ProteinScoringStrategy(score_type)
```

## picked_group_fdr/parsers.py

```diff
@@ -78,15 +78,37 @@
     for row in reader:
         if len(row[scoreCol]) == 0:
             yield row[proteinCol].split(";"), -100.0
         else:
             yield row[proteinCol].split(";"), float(row[scoreCol])
 
 
-def parseMqEvidenceFile(mqEvidenceFile, scoreType, forQuantification = False):
+def parseEvidenceFiles(evidenceFiles, scoreType, forQuantification=False):
+    for evidenceFile in evidenceFiles:
+        yield from parseEvidenceFile(evidenceFile, scoreType, forQuantification)
+
+
+def parseEvidenceFile(evidenceFile, scoreType, forQuantification=False):
+    if evidenceFile.endswith('.csv'):
+        delimiter = ','
+    else:
+        delimiter = '\t'
+    reader = getTsvReader(evidenceFile, delimiter)
+    headers = next(reader) # save the header
+    
+    if isPercolatorFile(headers):
+        yield from parsePercolatorOutFile(reader, headers, scoreType)
+    else:
+        headers = list(map(str.lower, headers)) # convert headers to lowercase since MQ changes the capitalization frequently
+        if evidenceFile.endswith('.csv'):
+            headers = [x.replace(".", " ") for x in headers]
+        yield from parseMqEvidenceFile(reader, headers, scoreType, forQuantification)
+
+
+def parseMqEvidenceFile(reader, headers, scoreType, forQuantification=False):
     """
     Reads in approximately 100,000 lines per second with forQuantification=False 
     and 50,000 lines per second with forQuantification=True
     
     Columns needed for identification:
     - Modified sequence
     - Leading proteins (not used for all methods, but should still be in the input file)
@@ -95,147 +117,153 @@
     
     Extra columns needed for quantification:
     - Charge
     - Intensity
     - Raw file
     - Fraction (optional)
     - Id
+    - Reporter intensity corrected (for TMT)
+    - Reporter intensity (for TMT)
+    - Reporter intensity count (for TMT)
+    - Intensity L (for SILAC)
+    - Intensity H (for SILAC)
+    - Intensity M (optional, for SILAC)
     """
-    if mqEvidenceFile.endswith('.csv'):
-        delimiter = ','
-    else:
-        delimiter = '\t'
-    reader = getTsvReader(mqEvidenceFile, delimiter)
-    headers = list(map(lambda x : x.lower(), next(reader))) # save the header
+    getHeaderCol = getHeaderColFunc(headers)
+    getHeaderColsStartingWith = getHeaderColsStartingWithFunc(headers)
     
-    if "psmid" in headers:
-        yield from parsePercolatorOutFile(mqEvidenceFile, scoreType)
-    else:
-        if mqEvidenceFile.endswith('.csv'):
-            headers = [x.replace(".", " ") for x in headers]
-        getHeaderCol = getHeaderColFunc(headers)
-        getHeaderColsStartingWith = getHeaderColsStartingWithFunc(headers)
+    peptCol = getHeaderCol('modified sequence', required = True)
+    
+    proteinCol = getHeaderCol('leading proteins', required = True) # all protein groups, each represented by the first protein in the group
+    if scoreType.use_razor:
+        proteinCol = getHeaderCol('leading razor protein', required = True) # best scoring protein group, represented by the first protein in the group            
+    
+    scoreCol = getHeaderCol(scoreType.get_score_column(), required = True)
+            
+    experimentCol = getHeaderCol('experiment')
+    chargeCol = getHeaderCol('charge', required = forQuantification)
+    
+    intensityCol = getHeaderCol('intensity', required = forQuantification)
+    tmtCols = getHeaderColsStartingWith('reporter intensity ')
+    silacCols = list()
+    if 'intensity l' in headers: # SILAC
+        silacCols.append(getHeaderCol('intensity l', required = forQuantification))
+        if 'intensity m' in headers:
+            silacCols.append(getHeaderCol('intensity m', required = forQuantification))
+        if 'intensity h' in headers:
+            silacCols.append(getHeaderCol('intensity h', required = forQuantification))
+    
+    rawFileCol = getHeaderCol('raw file', required = forQuantification)
+    fractionCol = getHeaderCol('fraction')
+    evidenceIdCol = getHeaderCol('id', required = forQuantification)
+    
+    logger.info("Parsing MaxQuant evidence.txt file")
+    for lineIdx, row in enumerate(reader):
+        if lineIdx % 500000 == 0:
+            logger.info(f"    Reading line {lineIdx}")
         
-        peptCol = getHeaderCol('modified sequence', required = True)
+        peptide = row[peptCol]
+        proteins = row[proteinCol]
+        if experimentCol >= 0:
+            experiment = row[experimentCol]
+        else:
+            experiment = "Experiment1"
         
-        proteinCol = getHeaderCol('leading proteins', required = True) # all protein groups, each represented by the first protein in the group
-        if scoreType.use_razor:
-            proteinCol = getHeaderCol('leading razor protein', required = True) # best scoring protein group, represented by the first protein in the group            
-        
-        scoreCol = getHeaderCol(scoreType.get_score_column(), required = True)
-                
-        experimentCol = getHeaderCol('experiment')
-        chargeCol = getHeaderCol('charge', required = forQuantification)
-        
-        intensityCol = getHeaderCol('intensity', required = forQuantification)
-        tmtCols = getHeaderColsStartingWith('reporter intensity ')
-        silacCols = list()
-        if 'intensity l' in headers: # SILAC
-            silacCols.append(getHeaderCol('intensity l', required = forQuantification))
-            if 'intensity m' in headers:
-                silacCols.append(getHeaderCol('intensity m', required = forQuantification))
-            if 'intensity h' in headers:
-                silacCols.append(getHeaderCol('intensity h', required = forQuantification))
-        
-        rawFileCol = getHeaderCol('raw file', required = forQuantification)
-        fractionCol = getHeaderCol('fraction')
-        evidenceIdCol = getHeaderCol('id', required = forQuantification)
-        
-        logger.info("Parsing MaxQuant evidence.txt file")
-        for lineIdx, row in enumerate(reader):
-            if lineIdx % 500000 == 0:
-                logger.info(f"    Reading line {lineIdx}")
-            
-            peptide = row[peptCol]
-            proteins = row[proteinCol]
-            if experimentCol >= 0:
-                experiment = row[experimentCol]
-            else:
-                experiment = "Experiment1"
-            
-            score = float(row[scoreCol])
-            
-            if forQuantification:
-                charge = int(row[chargeCol])
-                intensity = float(row[intensityCol]) if len(row[intensityCol]) > 0 else 0.0
-                if fractionCol >= 0:
-                    fraction = row[fractionCol]
-                else:
-                    fraction = -1
-                rawFile = row[rawFileCol]
-                tmtIntensities = [row[tmtCol] for tmtCol in tmtCols]
-                silacIntensities = [row[silacCol] if len(row[silacCol]) > 0 else 0 for silacCol in silacCols]
-                evidenceId = int(row[evidenceIdCol])
-                yield peptide, proteins.split(";"), charge, rawFile, experiment, fraction, intensity, score, tmtIntensities, silacIntensities, evidenceId
+        score = float(row[scoreCol])
+        
+        if forQuantification:
+            charge = int(row[chargeCol])
+            intensity = float(row[intensityCol]) if len(row[intensityCol]) > 0 else 0.0
+            if fractionCol >= 0:
+                fraction = row[fractionCol]
             else:
-                yield peptide, proteins.split(";"), experiment, score
+                fraction = -1
+            rawFile = row[rawFileCol]
+            tmtIntensities = [row[tmtCol] for tmtCol in tmtCols]
+            silacIntensities = [row[silacCol] if len(row[silacCol]) > 0 else 0 for silacCol in silacCols]
+            evidenceId = int(row[evidenceIdCol])
+            yield peptide, proteins.split(";"), charge, rawFile, experiment, fraction, intensity, score, tmtIntensities, silacIntensities, evidenceId
+        else:
+            yield peptide, proteins.split(";"), experiment, score
 
 
 def getHeaderColFunc(headers):
     def getHeaderCol(name, required = False):
         if required:
             return headers.index(name)
         else:
             if name in headers:
                 return headers.index(name)
             return -1
     return getHeaderCol
 
+
 def getHeaderColsStartingWithFunc(headers):
     def getHeaderColsStartingWith(name):
         cols = [idx for idx, h in enumerate(headers) if h.startswith(name)]
         return cols
     return getHeaderColsStartingWith
 
 
-def parsePercolatorOutFile(percOutFile, scoreType = "PEP", razor = False):
-    if percOutFile.endswith('.csv'):
-        delimiter = ','
-    else:
-        delimiter = '\t'
-    reader = getTsvReader(percOutFile, delimiter)
-    headers = next(reader) # save the header
+def parsePercolatorOutFile(reader, headers, scoreType = "PEP", razor = False):    
+    _, peptCol, scoreCol, _, postErrProbCol, proteinCol = getPercolatorColumnIdxs(headers)
     
-    peptCol = headers.index('peptide')
-    proteinCol = headers.index('proteinIds')
-    scoreCol = headers.index(scoreType.get_score_column())
+    if scoreType.get_score_column() == 'posterior_error_prob':
+        scoreCol = postErrProbCol
     
     logger.info("Parsing Percolator output file")
     for lineIdx, row in enumerate(reader):
         if lineIdx % 500000 == 0:
             logger.info(f"    Reading line {lineIdx}")
         
         peptide = row[peptCol][1:-1]
-        proteins = row[proteinCol:]
-        #proteins = list(map(lambda x : "REV__" + x.split("|")[1] if x.startswith("REV__") else x.split("|")[1], proteins)) # for mouse proteome
         experiment = 1
         score = float(row[scoreCol])
         
+        if isNativePercolatorFile(headers):
+            proteins = row[proteinCol:]
+        elif isMokapotFile(headers):
+            proteins = row[proteinCol].split('\t')
+        
         yield peptide, proteins, experiment, score
 
 
 def getPercolatorNativeHeaders():
     return ['PSMId', 'score', 'q-value', 'posterior_error_prob', 'peptide', 'proteinIds']
 
 
+def isPercolatorFile(headers):
+    return isNativePercolatorFile(headers) or isMokapotFile(headers)
+
+
+def isNativePercolatorFile(headers):
+    return 'psmid' in map(str.lower, headers)
+
+
+def isMokapotFile(headers):
+    return 'specid' in map(str.lower, headers)
+
+
 def getPercolatorColumnIdxs(headers):
-    if 'PSMId' in headers: # native percolator results
+    if isNativePercolatorFile(headers):
         idCol = headers.index('PSMId')
         peptCol = headers.index('peptide')
         scoreCol = headers.index('score')
         qvalCol = headers.index('q-value')
         postErrProbCol = headers.index('posterior_error_prob')
         proteinCol = headers.index('proteinIds')
-    else: # mokapot results
+    elif isMokapotFile(headers):
         idCol = headers.index('SpecId')
         peptCol = headers.index('Peptide')
         scoreCol = headers.index('mokapot score')
         qvalCol = headers.index('mokapot q-value')
         postErrProbCol = headers.index('mokapot PEP')
         proteinCol = headers.index('Proteins')
+    else:
+        raise ValueError("Could not determine percolator input file format. The file should either contain a column named PSMId (native percolator) or SpecId (mokapot).")
     return idCol, peptCol, scoreCol, qvalCol, postErrProbCol, proteinCol
 
 
 def parsePercolatorOutFileToDict(percOutFile, resultsDict, inputType = ""):
     if percOutFile.endswith('.csv'):
         delimiter = ','
     else:
```

## picked_group_fdr/picked_group_fdr.py

```diff
@@ -4,15 +4,15 @@
 import logging
 import argparse
 from timeit import default_timer as timer
 from typing import List, Dict, Tuple, Union
 
 import numpy as np
 
-from . import version
+from . import __version__, __copyright__
 from . import digest
 from . import helpers
 from . import parsers
 from . import results
 from . import proteotypicity
 from . import quantification
 from . import entrapment
@@ -28,60 +28,62 @@
 from .scoring import ProteinScoringStrategy
 from .grouping import ProteinGroupingStrategy
 from .competition import ProteinCompetitionStrategy
 from .plotter import Plotter, NoPlotter
 
 logger = logging.getLogger(__name__)
 
-__version__ = version.get_version_from_pyproject()
-__copyright__ = '''Copyright (c) 2020-2022 Matthew The. All rights reserved.
-Written by Matthew The (matthew.the@tum.de) at the
-Chair of Proteomics and Bioanalytics at the Technical University of Munich.'''
+GREETER = f'PickedGroupFDR version {__version__}\n{__copyright__}' 
 
 
 class ArgumentParserWithLogger(argparse.ArgumentParser):
     def error(self, message):
         logger.error(f"Error parsing input arguments: {message}")
         super().error(message)
 
 
 def parseArgs(argv):
     apars = ArgumentParserWithLogger(
+            description=GREETER,
             formatter_class=argparse.ArgumentDefaultsHelpFormatter)
 
-    apars.add_argument('--mq_evidence', default=None, metavar = "EV",
-                         help='''MaxQuant evidence file.''')
+    apars.add_argument('--mq_evidence', default=None, metavar = "EV", nargs="+",
+                         help='''MaxQuant evidence file(s).''')
 
     apars.add_argument('--protein_groups_out', default=None, metavar = "PG",
                          help='''Protein groups output file, mimicks a subset of the MQ protein groups columns.
                                 ''')
 
     apars.add_argument('--fasta', default=None, metavar = "F",
-                         help='''Fasta file to create mapping from peptides to proteins.
-                                                    ''')
-
+                         help='''Fasta file to create mapping from peptides to proteins. This should not contain the decoy sequences, unless you set the --fasta_contains_decoys flag.
+                                 ''')
+                         
     apars.add_argument('--mq_protein_groups', default=None, metavar = "PG",
                          help='''MaxQuant protein groups file; only specify if we want to keep MaxQuant's original grouping instead of Picked Grouping
                                 ''')
 
-    apars.add_argument('--perc_evidence', default=None, metavar = "POUT",
-                         help='''Percolator output file with PSMs or peptides; alternative for --mq_evidence if we want to use Percolator PEPs instead of MaxQuant's PEPs
+    apars.add_argument('--perc_evidence', default=None, metavar = "POUT", nargs="+",
+                         help='''Percolator output file(s) with PSMs or peptides; alternative for --mq_evidence if we want to use Percolator PEPs instead of MaxQuant's PEPs
                                 ''')
 
-    apars.add_argument('--methods', default=None, metavar = "M1,M2",
-                         help='''Use one or more predefined protein group FDR estimation methods, separated by commas.''')
+    apars.add_argument('--methods', default='picked_protein_group', metavar = "M1,M2",
+                         help='''Use one or more protein group FDR estimation methods, separated by commas. Examples of builtin methods: picked_protein_group, picked_protein_group_mq_input, savitski, maxquant. Alternatively, specify one our more paths to toml files with a .toml extension following the same format as the builtin method toml files.''')
 
     apars.add_argument('--peptide_protein_map', default=None, metavar = "M",
                          help='''File with mapping from peptides to proteins; alternative for --fasta flag if digestion is time consuming.
                                 ''')
 
     apars.add_argument('--peptide_proteotypicity_map', default=None, metavar = "M",
                          help='''File with mapping from peptides to proteotypicity.
                                 ''')
 
+    apars.add_argument('--keep_all_proteins', default=None,
+                         help='''Keep proteins that do not have peptides below the PSM FDR filter.''',
+                         action='store_true')
+    
     apars.add_argument('--gene_level',
                          help='Report gene-level statistics instead of protein group-level. This requires the GN= field to be present in the fasta file.',
                          action='store_true')
 
     apars.add_argument('--do_quant',
                          help='Do protein quantification, will calculate summed intensity, iBAQ and LFQ intensities.',
                          action='store_true')
@@ -114,15 +116,15 @@
     # ------------------------------------------------
     args = apars.parse_args(argv)
 
     return args
 
 
 def main(argv):
-    logger.info(f'PickedGroupFDR version {__version__}\n{__copyright__}')
+    logger.info(GREETER)
     logger.info(f'Issued command: {os.path.basename(__file__)} {" ".join(map(str, argv))}')
     
     args = parseArgs(argv)
     
     np.random.seed(1) # set seed for random shuffling of protein groups, see competition.do_competition()
     
     configs = methods.get_methods(args)
@@ -146,37 +148,37 @@
     peptideToProteinMap = dict()
     peptideToProteotypicityMap = dict()
     for config in configs:
         methodDescriptionLong = methods.long_description(config['scoreType'], config['grouping'], config['pickedStrategy'], True)
         label = config.get('label', "")
         logger.info(f"Protein group level estimation method: {label} ({methodDescriptionLong})")
         
-        peptideFile = config['scoreType'].get_evidence_file(args)
-        if not peptideFile:
-            logger.warning("No evidence file provided, skipping...")
+        evidenceFiles = config['scoreType'].get_evidence_file(args)
+        if not evidenceFiles:
+            logger.warning(f"No evidence input file found, skipping method \"{label}\". Check if an appropriate method was specified by the --methods flag.")
             continue
         
         if len(peptideToProteinMap) == 0 and (config['grouping'].needs_peptide_to_protein_map() or config['scoreType'].remaps_peptides_to_proteins()):
             peptideToProteinMap = digest.get_peptide_to_protein_map(args, parseId)
             entrapment.markEntrapmentProteins(peptideToProteinMap, args.mq_protein_groups)
             
         if len(peptideToProteotypicityMap) == 0 and config['scoreType'].use_proteotypicity:
             peptideToProteotypicityMap = proteotypicity.getPeptideToProteotypicityFromFile(args.peptide_proteotypicity_map)
         
-        peptideInfoList = parseMqEvidenceFile(peptideFile, 
-                                              peptideToProteinMap, 
-                                              config['scoreType'], 
-                                              args.suppress_missing_peptide_warning)
+        peptideInfoList = parseEvidenceFiles(evidenceFiles, 
+                                             peptideToProteinMap, 
+                                             config['scoreType'], 
+                                             args.suppress_missing_peptide_warning)
         
         plotter.set_series_label_base(config.get('label', None))
         proteinGroupResults = getProteinGroupResults(
                 peptideInfoList, args.mq_protein_groups, 
                 proteinAnnotations, peptideToProteotypicityMap,
                 config['pickedStrategy'], config['scoreType'], config['grouping'], 
-                plotter)
+                plotter, args.keep_all_proteins)
         
         if args.do_quant:
             doQuantification(config, args, proteinGroupResults, parseId, peptideToProteinMap)
 
         if args.protein_groups_out:
             writeProteinGroups(proteinGroupResults, args.protein_groups_out, config, apply_suffix=len(configs) > 1)
     
@@ -192,15 +194,16 @@
         peptideInfoList: PeptideInfoList, 
         mqProteinGroupsFile: str, 
         proteinAnnotations, 
         peptideToProteotypicityMap, 
         pickedStrategy: ProteinCompetitionStrategy,
         scoreType: ProteinScoringStrategy,
         groupingStrategy: ProteinGroupingStrategy, 
-        plotter: Union[Plotter, NoPlotter]):
+        plotter: Union[Plotter, NoPlotter],
+        keep_all_proteins: bool):
     proteinGroups = groupingStrategy.group_proteins(peptideInfoList, mqProteinGroupsFile)
     
     # for razor peptide strategy
     scoreType.set_peptide_counts_per_protein(peptideInfoList)
     
     for rescue_step in groupingStrategy.get_rescue_steps():
         if rescue_step:
@@ -222,29 +225,30 @@
         reportedQvals, observedQvals = fdr.calculateProteinFDRs(
                 pickedProteinGroups, proteinScores)
         
         scoreCutoff = groupingStrategy.score_cutoff if rescue_step else float("inf")
         proteinGroupResults = ProteinGroupResults.from_protein_groups(
                 pickedProteinGroups, pickedProteinGroupPeptideInfos, 
                 proteinScores, reportedQvals, 
-                scoreCutoff, proteinAnnotations)
+                scoreCutoff, proteinAnnotations,
+                keep_all_proteins)
 
     if scoreType.use_proteotypicity:
         proteotypicity.calculateProteotypicityScores(pickedProteinGroups, pickedProteinGroupPeptideInfos, peptideToProteotypicityMap, scoreType, scoreCutoff)
     
     plotter.set_series_label(scoreType, groupingStrategy, pickedStrategy, rescue_step=rescue_step)
     plotter.plotQvalCalibrationAndPerformance(reportedQvals, observedQvals, absentRatio=1.0)
         
     return proteinGroupResults
 
 
-def parseMqEvidenceFile(mqEvidenceFile: str, peptideToProteinMap, scoreType, suppressMissingPeptideWarning: bool) -> PeptideInfoList:
+def parseEvidenceFiles(evidenceFiles: List[str], peptideToProteinMap, scoreType, suppressMissingPeptideWarning: bool) -> PeptideInfoList:
     """Returns best score per peptide"""
     peptideInfoList = dict()
-    for peptide, tmp_proteins, _, score in parsers.parseMqEvidenceFile(mqEvidenceFile, scoreType = scoreType):
+    for peptide, tmp_proteins, _, score in parsers.parseEvidenceFiles(evidenceFiles, scoreType = scoreType):
         peptide = helpers.cleanPeptide(peptide)
         if np.isnan(score) or score >= peptideInfoList.get(peptide, [np.inf])[0]:
             continue
         
         if scoreType.remaps_peptides_to_proteins():
             proteins = digest.getProteins(peptideToProteinMap, peptide)
             if len(proteins) == 0:
```

## picked_group_fdr/pipeline/andromeda2pin.py

```diff
@@ -8,18 +8,19 @@
 import os
 import csv
 import getopt
 import logging
 
 import numpy as np
 
+from .. import __version__, __copyright__
 from .. import digest
 from .. import parsers
 from .. import helpers
-from ..picked_group_fdr import ArgumentParserWithLogger, __version__, __copyright__
+from ..picked_group_fdr import ArgumentParserWithLogger
 
 
 # hacky way to get the package logger instead of just __main__ when running as python -m picked_group_fdr.pipeline.update_evidence_from_pout ...
 logger = logging.getLogger(__package__ + "." + __file__)
 
 
 # TODO allow mqpar.xml as input
@@ -110,14 +111,29 @@
 
 def writeHeaders(writer, charges):
     writer.writerow(["SpecId", "Label", "ScanNr", "ExpMass", "AndromedaScore", "DeltaScore", "PepLen"] + ["Charge" + str(i) for i in charges] + ["Mass", "enzN", "enzC", "enzInt", "numMods", "dM", "absdM", "Peptide", "Proteins"])
     #writer.writerow(["DefaultDirection", "-", "-", "-", 1, 0.5, 0] + [0 for i in charges] + [0, 0, 0, -1.5, -2, 0, -1])
 
 
 def parseMqEvidenceFile(mqEvidenceFile, razor = False):
+    """
+    Columns needed (all headers are converted to lower case for the comparison, so no need to fix that):
+    - Sequence (needed if not using a meta input file)
+    - Modified sequence
+    - MS/MS Scan number
+    - Raw file
+    - Charge
+    - Mass
+    - Mass error [ppm] (optional)
+    - One out of: Leading proteins / Proteins
+    - Score
+    - Delta score
+    - Experiment (optional)
+    """
+    
     if mqEvidenceFile.endswith('.csv'):
         delimiter = ','
     else:
         delimiter = '\t'
     reader = parsers.getTsvReader(mqEvidenceFile, delimiter)
     headers = next(reader) # save the header
     headers = list(map(lambda x : x.lower(), headers))
```

## picked_group_fdr/pipeline/filter_fdr_maxquant.py

```diff
@@ -1,18 +1,20 @@
 import sys
 import collections
 import re
 import logging
+import os
 
 import numpy as np
 
+from .. import __version__, __copyright__
 from .. import parsers
 from .. import helpers
 from .. import fdr
-from ..picked_group_fdr import ArgumentParserWithLogger, __version__, __copyright__
+from ..picked_group_fdr import ArgumentParserWithLogger
 
 # hacky way to get the package logger instead of just __main__ when running as python -m picked_group_fdr.pipeline.update_evidence_from_pout ...
 logger = logging.getLogger(__package__ + "." + __file__)
 
 Scan = collections.namedtuple('Scan', 'postErrorProb rawFile scanNr sequence precCharge isDecoy')
```

## picked_group_fdr/pipeline/merge_pout.py

```diff
@@ -3,18 +3,19 @@
 import csv
 import collections
 import logging
 
 import numpy as np
 import triqler.qvality as qvality
 
+from .. import __version__, __copyright__
 from .. import helpers
 from .. import digest
 from .. import parsers
-from ..picked_group_fdr import ArgumentParserWithLogger, __version__, __copyright__
+from ..picked_group_fdr import ArgumentParserWithLogger
 
 # hacky way to get the package logger instead of just __main__ when running as python -m picked_group_fdr.pipeline.update_evidence_from_pout ...
 logger = logging.getLogger(__package__ + "." + __file__)
 
 
 def parseArgs(argv):
     import argparse
```

## picked_group_fdr/pipeline/update_evidence_from_pout.py

```diff
@@ -1,16 +1,17 @@
 import sys
 import os
 import collections
 import logging
 from typing import List, Dict, Set
 
+from .. import __version__, __copyright__
 from .. import parsers
 from .. import helpers
-from ..picked_group_fdr import ArgumentParserWithLogger, __version__, __copyright__
+from ..picked_group_fdr import ArgumentParserWithLogger
 
 # hacky way to get the package logger instead of just __main__ when running as python -m picked_group_fdr.pipeline.update_evidence_from_pout ...
 logger = logging.getLogger(__package__ + "." + __file__)
 
 
 def parseArgs(argv):
     import argparse
```

## picked_group_fdr/quantification.py

```diff
@@ -29,29 +29,29 @@
 
 
 def parseArgs(argv):
     import argparse
     apars = argparse.ArgumentParser(
             formatter_class=argparse.ArgumentDefaultsHelpFormatter)
 
-    apars.add_argument('--mq_evidence', default=None, metavar = "EV", required = True,
+    apars.add_argument('--mq_evidence', default=None, metavar = "EV", required = True, nargs="+",
                          help='''MaxQuant evidence file.''')
     
     apars.add_argument('--mq_protein_groups', default=None, metavar = "PG", required = True,
                          help='''MaxQuant protein groups file.''')
     
     apars.add_argument('--protein_groups_out', default=None, metavar = "PG", required = True,
                          help='''Protein groups output file, mimicks a subset of the MQ protein groups columns.
                                 ''')
     
     apars.add_argument('--peptide_protein_map', default=None, metavar = "M",
                          help='''TSV file with mapping from peptides to proteins.''')
     
     apars.add_argument('--fasta', default=None, metavar = "F",
-                         help='''Fasta file to create mapping from peptides to proteins.''')
+                         help='''Fasta file to create mapping from peptides to proteins. This should not contain the decoy sequences, unless you set the --fasta_contains_decoys flag.''')
     
     apars.add_argument('--fasta_use_uniprot_id',
                          help='''Parse protein identifiers in the fasta file as UniProt IDs, 
                                  i.e. Q9UM47 for the protein identifier sp|Q9UM47|NOTC3_HUMAN''',
                          action='store_true')
 
     apars.add_argument('--gene_level',
@@ -118,23 +118,27 @@
     minLenIbaq = max([6, args.min_length])
     maxLenIbaq = min([30, args.max_length])
     
     logger.info("Loading peptide to protein map...")
     if args.fasta:
         pre, not_post = digest.getCleavageSites(args.enzyme)
         
+        db = 'concat'
+        if args.fasta_contains_decoys:
+            db = 'target'
+            
         peptideToProteinMap = digest.getPeptideToProteinMap(
-                args.fasta, db = 'concat', digestion = args.digestion, 
+                args.fasta, db = db, digestion = args.digestion, 
                 min_len = args.min_length, max_len = args.max_length, 
                 pre = pre, not_post = not_post, miscleavages = args.cleavages, 
                 methionineCleavage = True, specialAAs = list(args.special_aas),
                 parseId = parseId, useHashKey = (args.digestion == "none"))
         
         peptideToProteinMapIbaq = digest.getPeptideToProteinMap(
-                args.fasta, db = 'concat', digestion = args.digestion, 
+                args.fasta, db = db, digestion = args.digestion, 
                 min_len = minLenIbaq, max_len = maxLenIbaq, 
                 pre = pre, not_post = not_post, miscleavages = 0,
                 methionineCleavage = False, specialAAs = list(args.special_aas),
                 parseId = parseId, useHashKey = (args.digestion == "none"))
     elif args.peptide_protein_map:
         pre, not_post = digest.getCleavageSites(args.enzyme)
         
@@ -152,30 +156,30 @@
         sys.exit('No peptide to protein map found, use either the --fasta or the --peptide_protein_map arguments')
     
     numIbaqPeptidesPerProtein = digest.getNumPeptidesPerProtein(peptideToProteinMapIbaq)
     
     return peptideToProteinMap, numIbaqPeptidesPerProtein
 
 
-def doQuantification(mqEvidenceFile, proteinGroupResults, proteinSequences,
+def doQuantification(mqEvidenceFiles, proteinGroupResults, proteinSequences,
         peptideToProteinMap, numIbaqPeptidesPerProtein, fileListFile, 
         scoreType, psmQvalCutoff = 0.01, 
         discardSharedPeptides = True, 
         minPeptideRatiosLFQ = 2, 
         stabilizeLargeRatiosLFQ = True,
         numThreads = 1):
     params = initTriqlerParams()
     
     logger.info("Preparing for quantification")
     fileMapping = None
     if fileListFile:
         experiments, fileMapping, params = parseFileList(fileListFile, params) 
     
-    proteinGroupResults, postErrProbs, numTmtChannels, numSilacChannels, parsedExperiments = parseEvidenceFile(
-            proteinGroupResults, mqEvidenceFile, peptideToProteinMap, 
+    proteinGroupResults, postErrProbs, numTmtChannels, numSilacChannels, parsedExperiments = parseEvidenceFiles(
+            proteinGroupResults, mqEvidenceFiles, peptideToProteinMap, 
             fileMapping, scoreType, discardSharedPeptides)
     
     silacChannels = getSilacChannels(numSilacChannels)
     
     if len(parsedExperiments) > 0:
         experiments = sorted(list(parsedExperiments))
     experimentToIdxMap = dict([(v,k) for k, v in enumerate(experiments)])
@@ -210,26 +214,26 @@
             columns.append(TriqlerIntensityColumns(params))
     
     for c in columns:
         c.append_headers(proteinGroupResults, experiments)
         c.append_columns(proteinGroupResults, experimentToIdxMap, postErrProbCutoff)
 
 
-def parseEvidenceFile(proteinGroupResults, mqEvidenceFile, peptideToProteinMap, 
+def parseEvidenceFiles(proteinGroupResults, mqEvidenceFiles, peptideToProteinMap, 
                                             fileMapping, scoreType, discardSharedPeptides):    
     proteinGroups = ProteinGroups.from_protein_group_results(proteinGroupResults)
     proteinGroups.create_index()
     
     postErrProbs = list()
     sharedPeptidePrecursors, uniquePeptidePrecursors = 0, 0
     numTmtChannels, numSilacChannels = -1, -1
     parsedExperiments = set()
     missingPeptidesInFasta, missingPeptidesInProteinGroups = 0, 0
     
-    for peptide, tmp_proteins, charge, rawFile, experiment, fraction, intensity, postErrProb, tmtCols, silacCols, evidenceId in parsers.parseMqEvidenceFile(mqEvidenceFile, scoreType = ProteinScoringStrategy("bestPEP"), forQuantification = True):
+    for peptide, tmp_proteins, charge, rawFile, experiment, fraction, intensity, postErrProb, tmtCols, silacCols, evidenceId in parsers.parseEvidenceFiles(mqEvidenceFiles, scoreType = ProteinScoringStrategy("bestPEP"), forQuantification = True):
         if numTmtChannels == -1:
             # There are 3 columns per TMT channel: 
             #     Reporter intensity corrected, 
             #     Reporter intensity
             #     Reporter intensity count
             numTmtChannels = int(len(tmtCols) / 3) 
         if numSilacChannels == -1:
```

## picked_group_fdr/results.py

```diff
@@ -59,22 +59,29 @@
         reverse = _get_field('Reverse')
         potentialContaminant = _get_field('Potential contaminant')
         return cls(proteinIds, majorityProteinIds, peptideCountsUnique, 
                              proteinNames, geneNames, fastaHeaders, bestPeptide, 
                              numberOfProteins, qValue, score, reverse, potentialContaminant, [], [])
         
     @classmethod
-    def from_protein_group(cls, proteinGroup, peptideScores, reportedFdr, proteinScore, scoreCutoff, proteinAnnotations):
-        proteinIds = ";".join(proteinGroup)
-        bestPeptide = sorted([(p[0], p[1]) for p in peptideScores])[0][1]
+    def from_protein_group(cls, proteinGroup, peptideScores, reportedFdr, proteinScore, scoreCutoff, proteinAnnotations, keep_all_proteins):
         numUniquePeptidesPerProtein = cls._get_peptide_counts(peptideScores, scoreCutoff)
-        peptideCountsUnique = ";".join([str(numUniquePeptidesPerProtein[p]) for p in proteinGroup])
-        majorityProteinIds = ";".join([p for p in proteinGroup if numUniquePeptidesPerProtein[p] >= max(numUniquePeptidesPerProtein.values()) / 2])
-        numberOfProteins = len(proteinGroup)
+        peptideCountsUnique = [numUniquePeptidesPerProtein[p] for p in proteinGroup]
+        if sum(peptideCountsUnique) == 0 and not keep_all_proteins:
+            return None
+
+        proteinGroup, peptideCountsUnique = zip(*[(p, num_peptides) for p, num_peptides in zip(proteinGroup, peptideCountsUnique) if num_peptides > 0 or keep_all_proteins])
         
+        bestPeptide = sorted([(p[0], p[1]) for p in peptideScores])[0][1]
+        majorityProteinIds = ";".join([p for p, num_peptides in zip(proteinGroup, peptideCountsUnique) if num_peptides >= max(peptideCountsUnique) / 2])
+        numberOfProteins = len(proteinGroup)
+
+        peptideCountsUnique = ";".join(map(str, peptideCountsUnique))
+        proteinIds = ";".join(proteinGroup)
+                
         proteinNames, geneNames, fastaHeaders = list(), list(), list()
         for p in proteinGroup:
             if p in proteinAnnotations:
                 proteinName, geneName, fastaHeader = proteinAnnotations[p]
                 if proteinName not in proteinNames:
                     proteinNames.append(proteinName)
                 if geneName not in geneNames:
@@ -189,17 +196,19 @@
     @classmethod
     def from_protein_groups(cls, 
             proteinGroups: ProteinGroups, 
             proteinGroupPeptideInfos: ProteinGroupPeptideInfos, 
             proteinScores: List[float], 
             reportedQvals: List[float], 
             scoreCutoff: float, 
-            proteinAnnotations) -> ProteinGroupResults:
+            proteinAnnotations,
+            keep_all_proteins: bool) -> ProteinGroupResults:
         protein_group_results = list()
         for proteinGroup, peptideScores, proteinScore, reportedFdr in zip(proteinGroups, proteinGroupPeptideInfos, proteinScores, reportedQvals):
             if helpers.isObsolete(proteinGroup):
                 continue
-            pgr = ProteinGroupResult.from_protein_group(proteinGroup, peptideScores, reportedFdr, proteinScore, scoreCutoff, proteinAnnotations)
-            protein_group_results.append(pgr)
+            pgr = ProteinGroupResult.from_protein_group(proteinGroup, peptideScores, reportedFdr, proteinScore, scoreCutoff, proteinAnnotations, keep_all_proteins)
+            if pgr is not None: # protein groups can get filtered out when they do not have any PSMs below the PSM FDR cutoff
+                protein_group_results.append(pgr)
         
         return cls(protein_group_results)
```

## picked_group_fdr/scoring.py

```diff
@@ -374,15 +374,15 @@
         logger.info(f"Shared peptides: {sharedPeptides}; Unique peptides: {uniquePeptides}")
         return proteinGroupPeptideInfos
     
 
 def compareRazorPeptides(mqEvidenceFile, peptideToProteinMap, proteinGroups, scoreType):
     """Compares the chosen protein by MaxQuant according to the razor peptide rule with our implementation of the razor peptide rule"""
     scoreType = ProteinScoringStrategy("multPEP razor")
-    for peptideRow in parsers.parseMqEvidenceFile(mqEvidenceFile, scoreType = scoreType):
+    for peptideRow in parsers.parseEvidenceFile(mqEvidenceFile, scoreType = scoreType):
         peptide, tmp_proteins, _, _ = peptideRow
         
         proteins = digest.getProteins(peptideToProteinMap, helpers.cleanPeptide(peptide))
         
         leadingProteins = proteinGroups.get_leading_proteins(proteins)
         if len(leadingProteins) > 1:
             predictedRazor = scoreType.filter_proteins(proteins) # filtering for razor peptide approach
```

## Comparing `picked_group_fdr-0.3.5.dist-info/LICENSE` & `picked_group_fdr-0.4.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `picked_group_fdr-0.3.5.dist-info/METADATA` & `picked_group_fdr-0.4.0.dist-info/METADATA`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: picked-group-fdr
-Version: 0.3.5
+Version: 0.4.0
 Summary: Scalable, accurate and sensitive protein group FDRs for large-scale mass spectrometry experiments
 Home-page: https://github.com/kusterlab/picked_group_fdr
 License: Apache-2.0
 Keywords: mass spectrometry,protein inference,proteomics
 Author: Matthew The
 Author-email: matthew.the@tum.de
 Requires-Python: >=3.8,<3.12
@@ -12,33 +12,37 @@
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Provides-Extra: gui
 Requires-Dist: Bottleneck (>=1.3.5,<2.0.0)
 Requires-Dist: cython (>=0.29.21)
-Requires-Dist: llvmlite (>=0.30)
+Requires-Dist: llvmlite (>=0.39.1,<0.40.0)
 Requires-Dist: matplotlib (>=3.3.1,<4.0.0)
 Requires-Dist: mokapot (>=0.3)
 Requires-Dist: networkx (>=2.4,<3.0)
 Requires-Dist: numpy (>=1.18,<2.0)
 Requires-Dist: pyqt5 (>=5.15.7,<6.0.0); extra == "gui"
 Requires-Dist: scipy (>=1.9,<2.0)
 Requires-Dist: toml (>=0.10.2,<0.11.0)
 Requires-Dist: triqler (>=0.4.0)
 Project-URL: Repository, https://github.com/kusterlab/picked_group_fdr
 Description-Content-Type: text/markdown
 
 # Picked Protein Group FDR
 
+[![PyPI version](https://img.shields.io/pypi/v/picked_group_fdr.svg?logo=pypi&logoColor=FFE873)](https://pypi.org/project/picked_group_fdr/)
+[![Supported Python versions](https://img.shields.io/pypi/pyversions/picked_group_fdr.svg?logo=python&logoColor=FFE873)](https://pypi.org/project/picked_group_fdr/)
+[![PyPI downloads](https://img.shields.io/pypi/dm/picked_group_fdr.svg)](https://pypistats.org/packages/picked_group_fdr)
+
 Scalable, accurate and sensitive protein group FDRs for large-scale mass spectrometry experiments
 
 ## Running Picked Protein Group FDR using the GUI
 
-On Windows, you can download the `PickedGroupFDR_GUI_windows.zip` from the latest release, unzip it and open `PickedGroupFDR.exe` to start the GUI (no installation necessary).
+On Windows, you can download the `PickedGroupFDR_GUI_windows.zip` from the [latest release](https://github.com/kusterlab/picked_group_fdr/releases), unzip it and open `PickedGroupFDR.exe` to start the GUI (no installation necessary).
 
 Make sure that you have run the MaxQuant search with 100% protein-level FDR.
 
 Alternatively, on all platforms, first install Picked Protein Group FDR as explained below. Then install `PyQt5` (`pip install PyQt5`) and run:
 
 ```shell
 python gui.py
```

## Comparing `picked_group_fdr-0.3.5.dist-info/RECORD` & `picked_group_fdr-0.4.0.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,21 +1,22 @@
 LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-picked_group_fdr/__init__.py,sha256=vTnlAWichTyeE--3gBp5unBboo5ef0niiAxIRZVjwxc,889
+picked_group_fdr/__init__.py,sha256=Yf20D8yKfzgTZ41U3NUs2r_BaQI9FPNbUKYLFVO3P_M,1528
 picked_group_fdr/__main__.py,sha256=QNyYCG7bIs9oec0-jwSyT7ztKA4CBC0A9dISNAzrTXo,180
 picked_group_fdr/competition.py,sha256=00RGrbYrLJDGdrQnDFWsg0cCgJ0_-3uQxndqVq7xAJ4,6244
-picked_group_fdr/digest.py,sha256=G6Ebd51z5PZAIvCqR4YDFsK_Y0GN1GHy_8_SsnpKbZY,22658
+picked_group_fdr/digest.py,sha256=qhbvGpqnfNc2poLbGpbhGric67ZWKXk6qCPVxqiW3tg,22945
 picked_group_fdr/digestfast.cpp,sha256=9v4bAVrBbUIC2Kxs6AuKhVm0inyUEtKyiZ4MgFDTasI,432703
 picked_group_fdr/digestfast.html,sha256=arq6PjwdayY1Znx8UfZHpqQpkQYGfR9Pf0CzEIw5DPQ,220141
 picked_group_fdr/digestfast.pyx,sha256=oyKJnFAHQdXB0pT2Z20FVMTwSEMKDlGCz3IvaJnBiuk,3923
 picked_group_fdr/entrapment.py,sha256=uD9wKGJT6xG4qC8N_K4p3svhJSdKvYk-3ObYBhlJB3s,1725
-picked_group_fdr/fdr.py,sha256=f4UVITdJRXbSuouxelgzOvplQXF0SNTdwwPiMHkVtdI,3255
+picked_group_fdr/fdr.py,sha256=EoKJN-F92cJdMfQmXQrsaP38oKKYo1GC36WR0EzraFY,3120
 picked_group_fdr/graphs.py,sha256=NSoUr3d2Ah8nkmtTkbaOjaipJlf_t07bDGRoKsU2oXw,5782
-picked_group_fdr/grouping.py,sha256=YcKWMudZL6SICuyGWYX0nYqBFydm_hzOzziR0S39NAE,10312
+picked_group_fdr/grouping.py,sha256=Gd7LwqBgpF94j0WabNAtiI7O54AljzH9JzykFx3less,10453
 picked_group_fdr/helpers.py,sha256=_rx0zzQzLpEzgEPHyIRvfKNAy1p5zZ2p6i3G_N_EryM,2006
 picked_group_fdr/methods/classic_no_grouping.toml,sha256=ALOogabOiCT0rqTx3quf9m-LbT-Z1AYWkEWIpYUPUeY,134
+picked_group_fdr/methods/classic_no_grouping_no_remap.toml,sha256=YhIXLd9RdiqF5EiHhkNI4YF5KVyakyPzSsbNGIhK93c,128
 picked_group_fdr/methods/classic_protein_group.toml,sha256=LRsZDr7ARiHryHzPbYXpssW9y_y8L6Vm5S54UKYWBic,152
 picked_group_fdr/methods/classic_rescued_subset_grouping.toml,sha256=COrWDPdv_io2LQpCMSZ8I67yquEe9AWN9kgDyQkvvHE,158
 picked_group_fdr/methods/classic_subset_grouping.toml,sha256=DTGQN82ioaKAx4PZd8eO4njBbGhY6BBmvkarI4VcYvw,142
 picked_group_fdr/methods/discard_picked.toml,sha256=5BKD6xZHc-_mehX2FMP-c2djsNMFAEyQuxwMBkRaOf8,142
 picked_group_fdr/methods/discard_picked_mq_input.toml,sha256=YvM-zIiNXdL6X2sjxBznDTLCR4AEdt16f-4UGli5YYA,131
 picked_group_fdr/methods/maxquant.toml,sha256=2Jplpy8nXGZacZrD9TfR29TS4xJAvucjb1_sVbZXEtE,114
 picked_group_fdr/methods/maxquant_mq_best.toml,sha256=gbnQPr5fBq-7IkVRkeHxgpowsgUDzoJmM2JAh0tBziY,128
@@ -29,45 +30,44 @@
 picked_group_fdr/methods/razor_picked.toml,sha256=CLGk34tf-nCAfwWayDzYLB04fOP3N8vflWDvlPci-48,138
 picked_group_fdr/methods/razor_picked_mq_input.toml,sha256=aa3UugGRRtDr5mk7Wcc9ewoVQcb8g9Q6ArnwWrrlP-k,127
 picked_group_fdr/methods/savitski.toml,sha256=yAxpgHVLMMH1O6595tPAfha1_KfX-SydNKZRWsE_8K4,122
 picked_group_fdr/methods/savitski_classic.toml,sha256=sJytbWRGCnOBMrOQxaHOnrHOxAlk-BkZRcvbnaHO4dI,123
 picked_group_fdr/methods/savitski_mq_best.toml,sha256=07qBvp7ym3h_prrXz6bSOM0adeH4n5_COioTLgGs_KE,125
 picked_group_fdr/methods/savitski_mq_mult.toml,sha256=I_MfeYMMfAO0CwjXt8ksx7--pP4ZCy5f-Cs0THhtRPk,125
 picked_group_fdr/methods/savitski_no_remap.toml,sha256=xIfM2ap2M24bcOy-3-_8phe0Ub2KbJI-4HTiycmO_FI,116
-picked_group_fdr/methods.py,sha256=1kgKr3nYEr6Tow5L70A5X-WsaKhAVyjkK9LIbKelmVk,9633
+picked_group_fdr/methods.py,sha256=ZkB4RBFOhcKl2mu0ZPHrTO6ndNFIp_r1iTAEL-nsZN4,9984
 picked_group_fdr/observed_peptides.py,sha256=RCpEyqhaPrTk2iEO13oQO5hrv5BO8KzA_bVIV59E1oY,7163
-picked_group_fdr/parsers.py,sha256=Nvi94jCfr8JsK2gi1KpmOaLvmTC1OuuwvR8LeM6oXnQ,12947
+picked_group_fdr/parsers.py,sha256=NYEp1aOP4mogr3QZohl0rw1sbQBzjgiBo8lDa6UV1hw,13694
 picked_group_fdr/peptide_info.py,sha256=0XzJLTNoM4DOm6B77ZlhZ1W3MBcFpnCeExPk-ozSf3E,295
-picked_group_fdr/picked_group_fdr.py,sha256=c4ZLwhmY53tjweKer502J07JsrCTDQLvIBtoOB8efcc,13421
+picked_group_fdr/picked_group_fdr.py,sha256=DNcavgcsU9QoB5JZ1LtUdgiNRxZnZPq9Rr_cTNIhk8c,14009
 picked_group_fdr/pipeline/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-picked_group_fdr/pipeline/andromeda2pin.py,sha256=-dyT14gbRIRogFjtFBAqmKTjB_aINnGWbDRuUFC-Yp4,10619
-picked_group_fdr/pipeline/filter_fdr_maxquant.py,sha256=YxuLaFTPydlALQr54V_xf21B_YrJe8EEZQSoq7MRfHI,14132
-picked_group_fdr/pipeline/merge_pout.py,sha256=dWgHSAe6Dx1svVxQBQe1ptGlicvfloyX_9H-y67ijS8,6126
+picked_group_fdr/pipeline/andromeda2pin.py,sha256=lLLeiRM8z-DflTANolmGXF8ZlxMXrR54Zuemij1yYIs,11039
+picked_group_fdr/pipeline/filter_fdr_maxquant.py,sha256=6VNJ3_nrIxh7dPAnwAS6ZVSZxKvfLRrMCQcvqH1Ptv4,14156
+picked_group_fdr/pipeline/merge_pout.py,sha256=hwGU-HXNJ7_NbnLXM8DCew7Ht1p3dGv06pr5Zp27Fr4,6140
 picked_group_fdr/pipeline/run_mokapot.py,sha256=o43SKIzfP_rwKwMt1hOSNVRNEjPwHdzVaUip-RYpI7k,2018
-picked_group_fdr/pipeline/update_evidence_from_pout.py,sha256=zIjRXu_AAtsapchVi5GBhCZOGpvn-TtYX0W13bY9vPo,13618
+picked_group_fdr/pipeline/update_evidence_from_pout.py,sha256=XJZA104tcPxWCc3kk7LVmuTFliMuwc2eYsh_4EQZY_Q,13632
 picked_group_fdr/plotter.py,sha256=l9V4m4MP9dAN3piu4GeWOL7r1lXukY8VL0B1ZSaiJKE,7002
 picked_group_fdr/protein_groups.py,sha256=RJEHg0gcSyGjvdpThMlE44H758-xJyfotbHweJdhkIc,5873
 picked_group_fdr/proteotypicity.py,sha256=6BoTqNqcCbLTICO2dFb7tdsek699tP3JcmD2VYJPUZw,4523
 picked_group_fdr/quant/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 picked_group_fdr/quant/base.py,sha256=5qpBTd1vL-2iJUjHdsfZmCCHdUiyg6JAfGwMD_2ZWZM,296
 picked_group_fdr/quant/evidence_ids.py,sha256=geqOVH338Cn7XsnFzeAaNlnFlCn1WVYAtc5po6rRLD0,1028
 picked_group_fdr/quant/id_type.py,sha256=eYwweeQA3a1a3-SuwqdqR5Y0ETBv9wL2yFl3MAnC5VI,1263
 picked_group_fdr/quant/lfq.py,sha256=Dhsp61gSSRCdUlZC5T9vNKJ39LXL1dEppQRgOIShP0s,13389
 picked_group_fdr/quant/peptide_count.py,sha256=1sZdSt5ZZ7ct2wghP6Kn8pS4mdD7Tk-3bEVR6JMrQ8Y,1229
 picked_group_fdr/quant/precursor_quant.py,sha256=WusE_F0pYN4PdP5rfbpAE3MSfHqQW7Xvj_isVdJ7cr0,315
 picked_group_fdr/quant/sequence_coverage.py,sha256=hJj0oBN5p-OH_JjTE3gc_-uGeQ4YKIh-sKPqoLYIM70,3593
 picked_group_fdr/quant/sum_and_ibaq.py,sha256=e8swpveIr0DYqc937HlJSRtTpoAQOfOWrikRGlT8SSY,3909
 picked_group_fdr/quant/tmt.py,sha256=eLQXSEHVK9iFM-AImc6IiCpOTuSCZBSpko7KEsaQUe0,1769
 picked_group_fdr/quant/triqler.py,sha256=H64UWzQ38pkou4sSV1zFERkk1ixepuTLJ05pE7ejwpg,7312
-picked_group_fdr/quantification.py,sha256=7YIzTOvm84AJx0aU0lG1vcYB7RFHGrdujkV5XOx8Na4,17843
-picked_group_fdr/results.py,sha256=Go0D5C4wARopVVadl1dEDkqlAMW70b3k7UGYuNULcF4,7957
-picked_group_fdr/scoring.py,sha256=ohnsiQxbWUc5ZomeijeFog6U5P2pN5gMIuG-QjGUTNQ,15090
+picked_group_fdr/quantification.py,sha256=MCvc_LDERHpv0ePAXQYNSE6HB8iOFe4E2_DtFCsh6NU,18041
+picked_group_fdr/results.py,sha256=KFiNH-RzFlJ1Xji4v2avookMZ7Z99FOrP8nvzCu_Z5I,8506
+picked_group_fdr/scoring.py,sha256=ZDy_5M5ca5Nn6oykamw3KadU4x-Oi_WJKMuzgJEsy9c,15088
 picked_group_fdr/setup.py,sha256=1RjiJ6Kqsf9WY-k7wq9QlHwp7neDGHI99O_oQI11eOw,154
 picked_group_fdr/simulation/simulate.py,sha256=Iqoxgbc77qqdb-NHgBpuk35Fjk_PuZjSgIA-dGw7DkA,17000
 picked_group_fdr/utils/compare_results.py,sha256=XvEn1JrmpTOSEETHetJBZaPDo4RjEruVQjae8DeYm90,1539
 picked_group_fdr/utils/get_genes_with_multiple_isoforms.py,sha256=i1G8AMQdjHT8w-t7zrv8SWw_fEfIHORBkQrOrXpXjVc,3412
 picked_group_fdr/utils/multiprocessing_pool.py,sha256=1ACjOUSgpTCQKOilU5GOfPe4Cwm1VfNcNzjcz5VeoG8,4116
-picked_group_fdr/version.py,sha256=zzbjDF36eHFnDr1FmWabpC8EPDbZ16N5ExMFhM1smPQ,1018
-picked_group_fdr-0.3.5.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-picked_group_fdr-0.3.5.dist-info/WHEEL,sha256=DA86_h4QwwzGeRoz62o1svYt5kGEXpoUTuTtwzoTb30,83
-picked_group_fdr-0.3.5.dist-info/METADATA,sha256=RYT9SpMrFzQ_xDtswKQD6qhqpolWAOeHyyUYqUYoVCk,3996
-picked_group_fdr-0.3.5.dist-info/RECORD,,
+picked_group_fdr-0.4.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+picked_group_fdr-0.4.0.dist-info/WHEEL,sha256=DA86_h4QwwzGeRoz62o1svYt5kGEXpoUTuTtwzoTb30,83
+picked_group_fdr-0.4.0.dist-info/METADATA,sha256=vFFJ2YFmr0VQnD7RTqKHBt1tS_wfhpvShU6P6lbpYVc,4493
+picked_group_fdr-0.4.0.dist-info/RECORD,,
```

