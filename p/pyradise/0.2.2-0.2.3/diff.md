# Comparing `tmp/pyradise-0.2.2.tar.gz` & `tmp/pyradise-0.2.3.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "pyradise-0.2.2.tar", last modified: Wed Apr  5 16:50:06 2023, max compression
+gzip compressed data, was "pyradise-0.2.3.tar", last modified: Tue May 30 13:51:25 2023, max compression
```

## Comparing `pyradise-0.2.2.tar` & `pyradise-0.2.3.tar`

### file list

```diff
@@ -1,47 +1,47 @@
-drwxrwxrwx   0        0        0        0 2023-04-05 16:50:06.182569 pyradise-0.2.2/
--rw-rw-rw-   0        0        0    11558 2022-08-09 08:55:56.000000 pyradise-0.2.2/LICENSE
--rw-rw-rw-   0        0        0     7369 2023-04-05 16:50:06.182045 pyradise-0.2.2/PKG-INFO
--rw-rw-rw-   0        0        0     5839 2023-01-30 17:47:11.000000 pyradise-0.2.2/README.md
--rw-rw-rw-   0        0        0     1784 2023-04-05 14:41:13.000000 pyradise-0.2.2/pyproject.toml
-drwxrwxrwx   0        0        0        0 2023-04-05 16:50:06.145401 pyradise-0.2.2/pyradise/
--rw-rw-rw-   0        0        0        0 2022-08-09 08:55:56.000000 pyradise-0.2.2/pyradise/__init__.py
--rw-rw-rw-   0        0        0      483 2023-04-05 16:48:38.000000 pyradise-0.2.2/pyradise/__version__.py
-drwxrwxrwx   0        0        0        0 2023-04-05 16:50:06.165898 pyradise-0.2.2/pyradise/data/
--rw-rw-rw-   0        0        0      542 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/data/__init__.py
--rw-rw-rw-   0        0        0     2950 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/data/annotator.py
--rw-rw-rw-   0        0        0    28362 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/data/image.py
--rw-rw-rw-   0        0        0     1866 2023-04-05 16:48:38.000000 pyradise-0.2.2/pyradise/data/modality.py
--rw-rw-rw-   0        0        0     2656 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/data/organ.py
--rw-rw-rw-   0        0        0    27110 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/data/subject.py
--rw-rw-rw-   0        0        0    11783 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/data/taping.py
--rw-rw-rw-   0        0        0     5329 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/data/utils.py
-drwxrwxrwx   0        0        0        0 2023-04-05 16:50:06.172916 pyradise-0.2.2/pyradise/fileio/
--rw-rw-rw-   0        0        0     1889 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/fileio/__init__.py
--rw-rw-rw-   0        0        0    35568 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/fileio/crawling.py
--rw-rw-rw-   0        0        0   132050 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/fileio/dicom_conversion.py
--rw-rw-rw-   0        0        0    21966 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/fileio/extraction.py
--rw-rw-rw-   0        0        0    22741 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/fileio/loading.py
--rw-rw-rw-   0        0        0    15642 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/fileio/modality_config.py
--rw-rw-rw-   0        0        0    12920 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/fileio/selection.py
--rw-rw-rw-   0        0        0    33893 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/fileio/series_info.py
--rw-rw-rw-   0        0        0    24321 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/fileio/writing.py
-drwxrwxrwx   0        0        0        0 2023-04-05 16:50:06.180991 pyradise-0.2.2/pyradise/process/
--rw-rw-rw-   0        0        0     2309 2023-04-05 16:49:37.000000 pyradise-0.2.2/pyradise/process/__init__.py
--rw-rw-rw-   0        0        0    25707 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/process/base.py
--rw-rw-rw-   0        0        0    26136 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/process/inference.py
--rw-rw-rw-   0        0        0    60208 2023-04-05 16:49:37.000000 pyradise-0.2.2/pyradise/process/intensity.py
--rw-rw-rw-   0        0        0     6466 2023-04-05 16:49:37.000000 pyradise-0.2.2/pyradise/process/invertibility.py
--rw-rw-rw-   0        0        0    27876 2023-04-05 16:49:37.000000 pyradise-0.2.2/pyradise/process/modification.py
--rw-rw-rw-   0        0        0    20978 2023-04-05 16:49:37.000000 pyradise-0.2.2/pyradise/process/orientation.py
--rw-rw-rw-   0        0        0    11751 2023-04-05 16:49:37.000000 pyradise-0.2.2/pyradise/process/postprocess.py
--rw-rw-rw-   0        0        0    29214 2023-04-05 16:49:37.000000 pyradise-0.2.2/pyradise/process/registration.py
--rw-rw-rw-   0        0        0    22383 2023-04-05 16:49:37.000000 pyradise-0.2.2/pyradise/process/resampling.py
--rw-rw-rw-   0        0        0    10277 2023-04-05 16:49:36.000000 pyradise-0.2.2/pyradise/utils.py
-drwxrwxrwx   0        0        0        0 2023-04-05 16:50:06.158892 pyradise-0.2.2/pyradise.egg-info/
--rw-rw-rw-   0        0        0     7369 2023-04-05 16:50:06.000000 pyradise-0.2.2/pyradise.egg-info/PKG-INFO
--rw-rw-rw-   0        0        0     1040 2023-04-05 16:50:06.000000 pyradise-0.2.2/pyradise.egg-info/SOURCES.txt
--rw-rw-rw-   0        0        0        1 2023-04-05 16:50:06.000000 pyradise-0.2.2/pyradise.egg-info/dependency_links.txt
--rw-rw-rw-   0        0        0       57 2023-04-05 16:50:06.000000 pyradise-0.2.2/pyradise.egg-info/requires.txt
--rw-rw-rw-   0        0        0        9 2023-04-05 16:50:06.000000 pyradise-0.2.2/pyradise.egg-info/top_level.txt
--rw-rw-rw-   0        0        0       42 2023-04-05 16:50:06.182569 pyradise-0.2.2/setup.cfg
--rw-rw-rw-   0        0        0     2315 2023-04-05 16:49:36.000000 pyradise-0.2.2/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 13:51:25.013126 pyradise-0.2.3/
+-rw-r--r--   0 runner    (1001) docker     (123)    11357 2023-05-30 13:50:21.000000 pyradise-0.2.3/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (123)     7262 2023-05-30 13:51:25.013126 pyradise-0.2.3/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     5762 2023-05-30 13:50:21.000000 pyradise-0.2.3/README.md
+-rw-r--r--   0 runner    (1001) docker     (123)     1725 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyproject.toml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 13:51:25.005125 pyradise-0.2.3/pyradise/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      471 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/__version__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 13:51:25.005125 pyradise-0.2.3/pyradise/data/
+-rw-r--r--   0 runner    (1001) docker     (123)      532 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2863 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/data/annotator.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27566 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/data/image.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1802 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/data/modality.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2563 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/data/organ.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26434 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/data/subject.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11481 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/data/taping.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5186 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/data/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 13:51:25.009126 pyradise-0.2.3/pyradise/fileio/
+-rw-r--r--   0 runner    (1001) docker     (123)     1858 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/fileio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    34749 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/fileio/crawling.py
+-rw-r--r--   0 runner    (1001) docker     (123)   129094 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/fileio/dicom_conversion.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21468 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/fileio/extraction.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22246 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/fileio/loading.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15261 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/fileio/modality_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12619 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/fileio/selection.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32981 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/fileio/series_info.py
+-rw-r--r--   0 runner    (1001) docker     (123)    23732 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/fileio/writing.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 13:51:25.013126 pyradise-0.2.3/pyradise/process/
+-rw-r--r--   0 runner    (1001) docker     (123)     2272 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/process/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25129 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/process/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25541 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/process/inference.py
+-rw-r--r--   0 runner    (1001) docker     (123)    58811 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/process/intensity.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6326 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/process/invertibility.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27251 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/process/modification.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20465 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/process/orientation.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11458 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/process/postprocess.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29435 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/process/registration.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21893 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/process/resampling.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9970 2023-05-30 13:50:21.000000 pyradise-0.2.3/pyradise/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 13:51:25.005125 pyradise-0.2.3/pyradise.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)     7262 2023-05-30 13:51:24.000000 pyradise-0.2.3/pyradise.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     1040 2023-05-30 13:51:25.000000 pyradise-0.2.3/pyradise.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-05-30 13:51:24.000000 pyradise-0.2.3/pyradise.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       57 2023-05-30 13:51:24.000000 pyradise-0.2.3/pyradise.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        9 2023-05-30 13:51:24.000000 pyradise-0.2.3/pyradise.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       38 2023-05-30 13:51:25.013126 pyradise-0.2.3/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (123)     2240 2023-05-30 13:50:21.000000 pyradise-0.2.3/setup.py
```

### Comparing `pyradise-0.2.2/LICENSE` & `pyradise-0.2.3/LICENSE`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,201 +1,201 @@
-                                 Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
-
-   APPENDIX: How to apply the Apache License to your work.
-
-      To apply the Apache License to your work, attach the following
-      boilerplate notice, with the fields enclosed by brackets "[]"
-      replaced with your own identifying information. (Don't include
-      the brackets!)  The text should be enclosed in the appropriate
-      comment syntax for the file format. We also recommend that a
-      file or class name and description of purpose be included on the
-      same "printed page" as the copyright notice for easier
-      identification within third-party archives.
-
-   Copyright [yyyy] [name of copyright owner]
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
```

### Comparing `pyradise-0.2.2/PKG-INFO` & `pyradise-0.2.3/PKG-INFO`

 * *Files 9% similar despite different names*

```diff
@@ -1,107 +1,107 @@
-Metadata-Version: 2.1
-Name: pyradise
-Version: 0.2.2
-Summary: PyRaDiSe: A Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion
-Home-page: https://pyradise.readthedocs.io/
-Author: Elias Ruefenacht
-Author-email: Elias Ruefenacht <elias.ruefenacht@unibe.ch>
-License: Apache-2.0
-Project-URL: Homepage, https://pyradise.readthedocs.io/
-Project-URL: Bug Tracker, https://github.com/ubern-mia/pyradise/issues
-Project-URL: GitHub, https://github.com/ubern-mia/pyradise/
-Keywords: medical image analysis,deep learning,auto-segmentation,radiotherapy,DICOM conversion,DICOM data handling,DICOM-RT Structure Sets
-Classifier: Development Status :: 3 - Alpha
-Classifier: Intended Audience :: Developers
-Classifier: Intended Audience :: Science/Research
-Classifier: License :: OSI Approved :: Apache Software License
-Classifier: Natural Language :: English
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11
-Classifier: Topic :: Scientific/Engineering :: Image Recognition
-Classifier: Topic :: Scientific/Engineering :: Mathematics
-Classifier: Topic :: Scientific/Engineering :: Medical Science Apps.
-Classifier: Topic :: Software Development :: Libraries :: Python Modules
-Classifier: Topic :: Software Development :: Libraries
-Requires-Python: >=3.8
-Description-Content-Type: text/markdown
-License-File: LICENSE
-
-PyRaDiSe
-========
-
-[![Documentation Status](https://readthedocs.org/projects/pyradise/badge/?version=latest)](https://pyradise.readthedocs.io/en/latest/?badge=latest)
-
-PyRaDiSe is an open-source Python (Py) package for developing deployable, radiotherapy-oriented (Ra), DICOM-based (Di) 
-auto-segmentation (Se) solutions. PyRaDiSe is DL framework-independent but can easily integrate most DL frameworks, 
-such as PyTorch or TensorFlow. The package addresses the following challenges for building radiotherapy-oriented 
-auto-segmentation solutions: handling DICOM data, managing and converting DICOM-RTSS data (incl. a 2D-based and 
-a 3D-based conversion algorithm), invertible pre-processing, and post-processing. In addition to building 
-auto-segmentation solutions, PyRaDiSe allows for converting and curating DICOM image series and DICOM-RTSS data to 
-simplify segmentation training dataset construction. Therefore, PyRaDiSe is highly flexible, allows for fast 
-prototyping, and facilitates a fast transition of data science research results into clinical radiotherapy research.
-
-<img alt="PyRaDiSe_Meme" src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/meme.jpg" width="300">
-
-Main Features
--------------
-The main features of PyRaDiSe are data handling, conversion from and to DICOM-RTSS, and data processing, including deep 
-learning model inference. The intended use of PyRaDiSe in the radiotherapy environment is depicted below. The 
-DICOM and other discrete medical image file formats, such as NIfTI, are imported into the provided data model using 
-the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html). In contrast to the 
-standard way of loading DICOM data, this package provides comprehensive and flexible import routines that consider 
-data relation details and automate import steps, such as registering DICOM images if DICOM registration files are 
-available. However, in some cases, the DICOM standard does not provide sufficient information for automation, 
-requiring minimal human interaction for resolution. In addition, discrete medical images also suffer from the lack of 
-identification data needed for automation. However, the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) 
-package offers the necessary methods to address these issues with flexible approaches and prototypes. Furthermore, 
-the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) provides 
-routines to select specific entities from the available data before loading by generating filterable pre-loading 
-information (so-called [`SeriesInfo`](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.series_info.html#pyradise.fileio.series_info.SeriesInfo))
-so that the computation time and memory usage for loading is minimal. Finally, after the data is loaded, it is 
-represented using the data model implemented in the [`data` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.data.html). 
-All downstream tasks are performed using the simple and extensible radiotherapy-oriented data model from this step on.
-
-After loading, the data is either converted and written to a file or processed using routines from the 
-[`process` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.process.html). This package includes 
-functionality and prototypes for pre-processing, deep learning model inference, and post-processing with a similar mode 
-of operations as well-known medical image libraries, such as SimpleITK or ITK. However, in contrast to other libraries, 
-the process package offers a mechanism for guaranteeing reproducibility and limited invertibility.
-
-After processing or loading, the altered data can be written to disk using a versatile writer from the 
-[`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) to save the data as either 
-a discrete image file or as DICOM-RTSS. In addition, specific writers provide the additional functionality to copy 
-the input data from the source to the target directory. This feature is handy if the developed auto-segmentation 
-solution will be deployed to the clinical environment or the cloud, where the original input data should remain 
-unmodified.
-
-<img src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/architecture_overview_v2.png" alt="Schematic illustration of PyRaDiSe in the radiotherapy environment">
-
-
-Getting Started
----------------
-
-If you are new to PyRaDiSe, here are a few guides to get you up to speed right away:
-
- - [Installation](https://pyradise.readthedocs.io/en/latest/installation.html) for installation instructions - or simply run `pip install pyradise`
- - [Examples](https://pyradise.readthedocs.io/en/latest/examples.html) give you an overview of PyRaDiSe's intended use. Jupyter notebooks are available in the directory [./examples](https://github.com/ubern-mia/pyradise/tree/main/examples/).
- - [Change history](https://pyradise.readthedocs.io/en/latest/change_history.html)
- - [Acknowledgments](https://pyradise.readthedocs.io/en/latest/acknowledgment.html)
-
-
-Citation
---------
-
-If you use PyRaDiSe for your research, please acknowledge it accordingly by citing our paper:
-
-BibTeX entry:
-
-    @article{Ruefenacht2023,
-    author = {Rüfenacht, Elias and Kamath, Amith and Suter, Yannick and Poel, Robert and Ermis, Ekin and Scheib, Stefan and Reyes, Mauricio},
-    title = {{PyRaDiSe: A Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion}},
-    journal = {Computer Methods and Programs in Biomedicine},
-    doi = {10.1016/j.cmpb.2023.107374},
-    issn = {0169-2607},
-    year = {2023}
-    }
+Metadata-Version: 2.1
+Name: pyradise
+Version: 0.2.3
+Summary: PyRaDiSe: A Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion
+Home-page: https://pyradise.readthedocs.io/
+Author: Elias Ruefenacht
+Author-email: Elias Ruefenacht <elias.ruefenacht@unibe.ch>
+License: Apache-2.0
+Project-URL: Homepage, https://pyradise.readthedocs.io/
+Project-URL: Bug Tracker, https://github.com/ubern-mia/pyradise/issues
+Project-URL: GitHub, https://github.com/ubern-mia/pyradise/
+Keywords: medical image analysis,deep learning,auto-segmentation,radiotherapy,DICOM conversion,DICOM data handling,DICOM-RT Structure Sets
+Classifier: Development Status :: 3 - Alpha
+Classifier: Intended Audience :: Developers
+Classifier: Intended Audience :: Science/Research
+Classifier: License :: OSI Approved :: Apache Software License
+Classifier: Natural Language :: English
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Topic :: Scientific/Engineering :: Image Recognition
+Classifier: Topic :: Scientific/Engineering :: Mathematics
+Classifier: Topic :: Scientific/Engineering :: Medical Science Apps.
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Classifier: Topic :: Software Development :: Libraries
+Requires-Python: >=3.8
+Description-Content-Type: text/markdown
+License-File: LICENSE
+
+PyRaDiSe
+========
+
+[![Documentation Status](https://readthedocs.org/projects/pyradise/badge/?version=latest)](https://pyradise.readthedocs.io/en/latest/?badge=latest)
+
+PyRaDiSe is an open-source Python (Py) package for developing deployable, radiotherapy-oriented (Ra), DICOM-based (Di) 
+auto-segmentation (Se) solutions. PyRaDiSe is DL framework-independent but can easily integrate most DL frameworks, 
+such as PyTorch or TensorFlow. The package addresses the following challenges for building radiotherapy-oriented 
+auto-segmentation solutions: handling DICOM data, managing and converting DICOM-RTSS data (incl. a 2D-based and 
+a 3D-based conversion algorithm), invertible pre-processing, and post-processing. In addition to building 
+auto-segmentation solutions, PyRaDiSe allows for converting and curating DICOM image series and DICOM-RTSS data to 
+simplify segmentation training dataset construction. Therefore, PyRaDiSe is highly flexible, allows for fast 
+prototyping, and facilitates a fast transition of data science research results into clinical radiotherapy research.
+
+<img alt="PyRaDiSe_Meme" src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/meme.jpg" width="300">
+
+Main Features
+-------------
+The main features of PyRaDiSe are data handling, conversion from and to DICOM-RTSS, and data processing, including deep 
+learning model inference. The intended use of PyRaDiSe in the radiotherapy environment is depicted below. The 
+DICOM and other discrete medical image file formats, such as NIfTI, are imported into the provided data model using 
+the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html). In contrast to the 
+standard way of loading DICOM data, this package provides comprehensive and flexible import routines that consider 
+data relation details and automate import steps, such as registering DICOM images if DICOM registration files are 
+available. However, in some cases, the DICOM standard does not provide sufficient information for automation, 
+requiring minimal human interaction for resolution. In addition, discrete medical images also suffer from the lack of 
+identification data needed for automation. However, the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) 
+package offers the necessary methods to address these issues with flexible approaches and prototypes. Furthermore, 
+the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) provides 
+routines to select specific entities from the available data before loading by generating filterable pre-loading 
+information (so-called [`SeriesInfo`](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.series_info.html#pyradise.fileio.series_info.SeriesInfo))
+so that the computation time and memory usage for loading is minimal. Finally, after the data is loaded, it is 
+represented using the data model implemented in the [`data` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.data.html). 
+All downstream tasks are performed using the simple and extensible radiotherapy-oriented data model from this step on.
+
+After loading, the data is either converted and written to a file or processed using routines from the 
+[`process` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.process.html). This package includes 
+functionality and prototypes for pre-processing, deep learning model inference, and post-processing with a similar mode 
+of operations as well-known medical image libraries, such as SimpleITK or ITK. However, in contrast to other libraries, 
+the process package offers a mechanism for guaranteeing reproducibility and limited invertibility.
+
+After processing or loading, the altered data can be written to disk using a versatile writer from the 
+[`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) to save the data as either 
+a discrete image file or as DICOM-RTSS. In addition, specific writers provide the additional functionality to copy 
+the input data from the source to the target directory. This feature is handy if the developed auto-segmentation 
+solution will be deployed to the clinical environment or the cloud, where the original input data should remain 
+unmodified.
+
+<img src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/architecture_overview_v2.png" alt="Schematic illustration of PyRaDiSe in the radiotherapy environment">
+
+
+Getting Started
+---------------
+
+If you are new to PyRaDiSe, here are a few guides to get you up to speed right away:
+
+ - [Installation](https://pyradise.readthedocs.io/en/latest/installation.html) for installation instructions - or simply run `pip install pyradise`
+ - [Examples](https://pyradise.readthedocs.io/en/latest/examples.html) give you an overview of PyRaDiSe's intended use. Jupyter notebooks are available in the directory [./examples](https://github.com/ubern-mia/pyradise/tree/main/examples/).
+ - [Change history](https://pyradise.readthedocs.io/en/latest/change_history.html)
+ - [Acknowledgments](https://pyradise.readthedocs.io/en/latest/acknowledgment.html)
+
+
+Citation
+--------
+
+If you use PyRaDiSe for your research, please acknowledge it accordingly by citing our paper:
+
+BibTeX entry:
+
+    @article{Ruefenacht2023,
+    author = {Rüfenacht, Elias and Kamath, Amith and Suter, Yannick and Poel, Robert and Ermis, Ekin and Scheib, Stefan and Reyes, Mauricio},
+    title = {{PyRaDiSe: A Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion}},
+    journal = {Computer Methods and Programs in Biomedicine},
+    doi = {10.1016/j.cmpb.2023.107374},
+    issn = {0169-2607},
+    year = {2023}
+    }
```

### Comparing `pyradise-0.2.2/README.md` & `pyradise-0.2.3/README.md`

 * *Ordering differences only*

 * *Files 7% similar despite different names*

```diff
@@ -1,77 +1,77 @@
-PyRaDiSe
-========
-
-[![Documentation Status](https://readthedocs.org/projects/pyradise/badge/?version=latest)](https://pyradise.readthedocs.io/en/latest/?badge=latest)
-
-PyRaDiSe is an open-source Python (Py) package for developing deployable, radiotherapy-oriented (Ra), DICOM-based (Di) 
-auto-segmentation (Se) solutions. PyRaDiSe is DL framework-independent but can easily integrate most DL frameworks, 
-such as PyTorch or TensorFlow. The package addresses the following challenges for building radiotherapy-oriented 
-auto-segmentation solutions: handling DICOM data, managing and converting DICOM-RTSS data (incl. a 2D-based and 
-a 3D-based conversion algorithm), invertible pre-processing, and post-processing. In addition to building 
-auto-segmentation solutions, PyRaDiSe allows for converting and curating DICOM image series and DICOM-RTSS data to 
-simplify segmentation training dataset construction. Therefore, PyRaDiSe is highly flexible, allows for fast 
-prototyping, and facilitates a fast transition of data science research results into clinical radiotherapy research.
-
-<img alt="PyRaDiSe_Meme" src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/meme.jpg" width="300">
-
-Main Features
--------------
-The main features of PyRaDiSe are data handling, conversion from and to DICOM-RTSS, and data processing, including deep 
-learning model inference. The intended use of PyRaDiSe in the radiotherapy environment is depicted below. The 
-DICOM and other discrete medical image file formats, such as NIfTI, are imported into the provided data model using 
-the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html). In contrast to the 
-standard way of loading DICOM data, this package provides comprehensive and flexible import routines that consider 
-data relation details and automate import steps, such as registering DICOM images if DICOM registration files are 
-available. However, in some cases, the DICOM standard does not provide sufficient information for automation, 
-requiring minimal human interaction for resolution. In addition, discrete medical images also suffer from the lack of 
-identification data needed for automation. However, the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) 
-package offers the necessary methods to address these issues with flexible approaches and prototypes. Furthermore, 
-the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) provides 
-routines to select specific entities from the available data before loading by generating filterable pre-loading 
-information (so-called [`SeriesInfo`](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.series_info.html#pyradise.fileio.series_info.SeriesInfo))
-so that the computation time and memory usage for loading is minimal. Finally, after the data is loaded, it is 
-represented using the data model implemented in the [`data` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.data.html). 
-All downstream tasks are performed using the simple and extensible radiotherapy-oriented data model from this step on.
-
-After loading, the data is either converted and written to a file or processed using routines from the 
-[`process` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.process.html). This package includes 
-functionality and prototypes for pre-processing, deep learning model inference, and post-processing with a similar mode 
-of operations as well-known medical image libraries, such as SimpleITK or ITK. However, in contrast to other libraries, 
-the process package offers a mechanism for guaranteeing reproducibility and limited invertibility.
-
-After processing or loading, the altered data can be written to disk using a versatile writer from the 
-[`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) to save the data as either 
-a discrete image file or as DICOM-RTSS. In addition, specific writers provide the additional functionality to copy 
-the input data from the source to the target directory. This feature is handy if the developed auto-segmentation 
-solution will be deployed to the clinical environment or the cloud, where the original input data should remain 
-unmodified.
-
-<img src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/architecture_overview_v2.png" alt="Schematic illustration of PyRaDiSe in the radiotherapy environment">
-
-
-Getting Started
----------------
-
-If you are new to PyRaDiSe, here are a few guides to get you up to speed right away:
-
- - [Installation](https://pyradise.readthedocs.io/en/latest/installation.html) for installation instructions - or simply run `pip install pyradise`
- - [Examples](https://pyradise.readthedocs.io/en/latest/examples.html) give you an overview of PyRaDiSe's intended use. Jupyter notebooks are available in the directory [./examples](https://github.com/ubern-mia/pyradise/tree/main/examples/).
- - [Change history](https://pyradise.readthedocs.io/en/latest/change_history.html)
- - [Acknowledgments](https://pyradise.readthedocs.io/en/latest/acknowledgment.html)
-
-
-Citation
---------
-
-If you use PyRaDiSe for your research, please acknowledge it accordingly by citing our paper:
-
-BibTeX entry:
-
-    @article{Ruefenacht2023,
-    author = {Rüfenacht, Elias and Kamath, Amith and Suter, Yannick and Poel, Robert and Ermis, Ekin and Scheib, Stefan and Reyes, Mauricio},
-    title = {{PyRaDiSe: A Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion}},
-    journal = {Computer Methods and Programs in Biomedicine},
-    doi = {10.1016/j.cmpb.2023.107374},
-    issn = {0169-2607},
-    year = {2023}
-    }
+PyRaDiSe
+========
+
+[![Documentation Status](https://readthedocs.org/projects/pyradise/badge/?version=latest)](https://pyradise.readthedocs.io/en/latest/?badge=latest)
+
+PyRaDiSe is an open-source Python (Py) package for developing deployable, radiotherapy-oriented (Ra), DICOM-based (Di) 
+auto-segmentation (Se) solutions. PyRaDiSe is DL framework-independent but can easily integrate most DL frameworks, 
+such as PyTorch or TensorFlow. The package addresses the following challenges for building radiotherapy-oriented 
+auto-segmentation solutions: handling DICOM data, managing and converting DICOM-RTSS data (incl. a 2D-based and 
+a 3D-based conversion algorithm), invertible pre-processing, and post-processing. In addition to building 
+auto-segmentation solutions, PyRaDiSe allows for converting and curating DICOM image series and DICOM-RTSS data to 
+simplify segmentation training dataset construction. Therefore, PyRaDiSe is highly flexible, allows for fast 
+prototyping, and facilitates a fast transition of data science research results into clinical radiotherapy research.
+
+<img alt="PyRaDiSe_Meme" src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/meme.jpg" width="300">
+
+Main Features
+-------------
+The main features of PyRaDiSe are data handling, conversion from and to DICOM-RTSS, and data processing, including deep 
+learning model inference. The intended use of PyRaDiSe in the radiotherapy environment is depicted below. The 
+DICOM and other discrete medical image file formats, such as NIfTI, are imported into the provided data model using 
+the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html). In contrast to the 
+standard way of loading DICOM data, this package provides comprehensive and flexible import routines that consider 
+data relation details and automate import steps, such as registering DICOM images if DICOM registration files are 
+available. However, in some cases, the DICOM standard does not provide sufficient information for automation, 
+requiring minimal human interaction for resolution. In addition, discrete medical images also suffer from the lack of 
+identification data needed for automation. However, the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) 
+package offers the necessary methods to address these issues with flexible approaches and prototypes. Furthermore, 
+the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) provides 
+routines to select specific entities from the available data before loading by generating filterable pre-loading 
+information (so-called [`SeriesInfo`](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.series_info.html#pyradise.fileio.series_info.SeriesInfo))
+so that the computation time and memory usage for loading is minimal. Finally, after the data is loaded, it is 
+represented using the data model implemented in the [`data` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.data.html). 
+All downstream tasks are performed using the simple and extensible radiotherapy-oriented data model from this step on.
+
+After loading, the data is either converted and written to a file or processed using routines from the 
+[`process` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.process.html). This package includes 
+functionality and prototypes for pre-processing, deep learning model inference, and post-processing with a similar mode 
+of operations as well-known medical image libraries, such as SimpleITK or ITK. However, in contrast to other libraries, 
+the process package offers a mechanism for guaranteeing reproducibility and limited invertibility.
+
+After processing or loading, the altered data can be written to disk using a versatile writer from the 
+[`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) to save the data as either 
+a discrete image file or as DICOM-RTSS. In addition, specific writers provide the additional functionality to copy 
+the input data from the source to the target directory. This feature is handy if the developed auto-segmentation 
+solution will be deployed to the clinical environment or the cloud, where the original input data should remain 
+unmodified.
+
+<img src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/architecture_overview_v2.png" alt="Schematic illustration of PyRaDiSe in the radiotherapy environment">
+
+
+Getting Started
+---------------
+
+If you are new to PyRaDiSe, here are a few guides to get you up to speed right away:
+
+ - [Installation](https://pyradise.readthedocs.io/en/latest/installation.html) for installation instructions - or simply run `pip install pyradise`
+ - [Examples](https://pyradise.readthedocs.io/en/latest/examples.html) give you an overview of PyRaDiSe's intended use. Jupyter notebooks are available in the directory [./examples](https://github.com/ubern-mia/pyradise/tree/main/examples/).
+ - [Change history](https://pyradise.readthedocs.io/en/latest/change_history.html)
+ - [Acknowledgments](https://pyradise.readthedocs.io/en/latest/acknowledgment.html)
+
+
+Citation
+--------
+
+If you use PyRaDiSe for your research, please acknowledge it accordingly by citing our paper:
+
+BibTeX entry:
+
+    @article{Ruefenacht2023,
+    author = {Rüfenacht, Elias and Kamath, Amith and Suter, Yannick and Poel, Robert and Ermis, Ekin and Scheib, Stefan and Reyes, Mauricio},
+    title = {{PyRaDiSe: A Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion}},
+    journal = {Computer Methods and Programs in Biomedicine},
+    doi = {10.1016/j.cmpb.2023.107374},
+    issn = {0169-2607},
+    year = {2023}
+    }
```

### Comparing `pyradise-0.2.2/pyradise/data/__init__.py` & `pyradise-0.2.3/pyradise/data/__init__.py`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,10 +1,10 @@
-from .annotator import Annotator
-from .image import Image, ImageProperties, IntensityImage, SegmentationImage
-from .modality import Modality
-from .organ import Organ, OrganAnnotatorCombination
-from .subject import Subject
-from .taping import Tape, TransformInfo, TransformTape
-from .utils import (seq_to_annotators, seq_to_modalities,
-                    seq_to_organ_annotator_combinations, seq_to_organs,
-                    str_to_annotator, str_to_modality, str_to_organ,
-                    str_to_organ_annotator_combination)
+from .annotator import Annotator
+from .image import Image, ImageProperties, IntensityImage, SegmentationImage
+from .modality import Modality
+from .organ import Organ, OrganAnnotatorCombination
+from .subject import Subject
+from .taping import Tape, TransformInfo, TransformTape
+from .utils import (seq_to_annotators, seq_to_modalities,
+                    seq_to_organ_annotator_combinations, seq_to_organs,
+                    str_to_annotator, str_to_modality, str_to_organ,
+                    str_to_organ_annotator_combination)
```

### Comparing `pyradise-0.2.2/pyradise/data/annotator.py` & `pyradise-0.2.3/pyradise/data/annotator.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,87 +1,87 @@
-from re import sub
-from typing import Optional
-
-__all__ = ["Annotator"]
-
-
-class Annotator:
-    """A class for identifying the annotator who segmented a certain organ. Because the name of the annotator takes
-    every value, the annotator can either be a human expert or an auto-segmentation algorithm.
-
-    Args:
-        name (str): The name of the annotator.
-        abbreviation (Optional[str]): The abbreviation of the annotator (default: None).
-    """
-
-    default_annotator_name = "NA"
-    default_annotator_abbreviation = "NA"
-
-    def __init__(self, name: str, abbreviation: Optional[str] = None) -> None:
-        super().__init__()
-        name_ = self._remove_illegal_characters(name)
-
-        if not name_:
-            raise ValueError(f"The annotator's consists exclusively of illegal characters!")
-
-        self.name: str = name_
-        self.abbreviation: Optional[str] = abbreviation
-
-    def get_name(self) -> str:
-        """Get the name of the :class:`Annotator`.
-
-        Returns:
-            str: The name of the :class:`Annotator`.
-        """
-        return self.name
-
-    def get_abbreviation(self) -> Optional[str]:
-        """Get the abbreviation of the :class:`Annotator`.
-
-        Returns:
-            Optional[str]: The abbreviation of the :class:`Annotator` if contained, otherwise :data:`None`.
-        """
-        return self.abbreviation
-
-    @classmethod
-    def get_default(cls) -> "Annotator":
-        """Get the default :class:`Annotator`.
-
-        The default :class:`Annotator` name is 'NA' and its abbreviation is also 'NA'.
-
-        Returns:
-            Annotator: The default :class:`Annotator`.
-        """
-        return Annotator(Annotator.default_annotator_name, Annotator.default_annotator_abbreviation)
-
-    def is_default(self) -> bool:
-        """Check if the :class:`Annotator` is the default :class:`Annotator`.
-
-        Returns:
-            bool: True if the :class:`Annotator` is the default :class:`Annotator`, otherwise False.
-        """
-        return self.name == Annotator.default_annotator_name and self.abbreviation == Annotator.default_annotator_name
-
-    @staticmethod
-    def _remove_illegal_characters(text: str) -> str:
-        """Remove a set of illegal characters from a string.
-
-        Args:
-            text (str): The string to remove illegal characters from.
-
-        Returns:
-            str: The string without illegal characters.
-        """
-        illegal_characters = '[<>:/\\|?*"]|[\0-\31]'
-        return sub(illegal_characters, "", text)
-
-    def __str__(self) -> str:
-        if self.abbreviation:
-            return f"{self.name} ({self.abbreviation})"
-
-        return self.name
-
-    def __eq__(self, other: object) -> bool:
-        if not isinstance(other, Annotator):
-            return False
-
-        return self.name == other.name and self.abbreviation == other.abbreviation
+from re import sub
+from typing import Optional
+
+__all__ = ["Annotator"]
+
+
+class Annotator:
+    """A class for identifying the annotator who segmented a certain organ. Because the name of the annotator takes
+    every value, the annotator can either be a human expert or an auto-segmentation algorithm.
+
+    Args:
+        name (str): The name of the annotator.
+        abbreviation (Optional[str]): The abbreviation of the annotator (default: None).
+    """
+
+    default_annotator_name = "NA"
+    default_annotator_abbreviation = "NA"
+
+    def __init__(self, name: str, abbreviation: Optional[str] = None) -> None:
+        super().__init__()
+        name_ = self._remove_illegal_characters(name)
+
+        if not name_:
+            raise ValueError(f"The annotator's consists exclusively of illegal characters!")
+
+        self.name: str = name_
+        self.abbreviation: Optional[str] = abbreviation
+
+    def get_name(self) -> str:
+        """Get the name of the :class:`Annotator`.
+
+        Returns:
+            str: The name of the :class:`Annotator`.
+        """
+        return self.name
+
+    def get_abbreviation(self) -> Optional[str]:
+        """Get the abbreviation of the :class:`Annotator`.
+
+        Returns:
+            Optional[str]: The abbreviation of the :class:`Annotator` if contained, otherwise :data:`None`.
+        """
+        return self.abbreviation
+
+    @classmethod
+    def get_default(cls) -> "Annotator":
+        """Get the default :class:`Annotator`.
+
+        The default :class:`Annotator` name is 'NA' and its abbreviation is also 'NA'.
+
+        Returns:
+            Annotator: The default :class:`Annotator`.
+        """
+        return Annotator(Annotator.default_annotator_name, Annotator.default_annotator_abbreviation)
+
+    def is_default(self) -> bool:
+        """Check if the :class:`Annotator` is the default :class:`Annotator`.
+
+        Returns:
+            bool: True if the :class:`Annotator` is the default :class:`Annotator`, otherwise False.
+        """
+        return self.name == Annotator.default_annotator_name and self.abbreviation == Annotator.default_annotator_name
+
+    @staticmethod
+    def _remove_illegal_characters(text: str) -> str:
+        """Remove a set of illegal characters from a string.
+
+        Args:
+            text (str): The string to remove illegal characters from.
+
+        Returns:
+            str: The string without illegal characters.
+        """
+        illegal_characters = '[<>:/\\|?*"]|[\0-\31]'
+        return sub(illegal_characters, "", text)
+
+    def __str__(self) -> str:
+        if self.abbreviation:
+            return f"{self.name} ({self.abbreviation})"
+
+        return self.name
+
+    def __eq__(self, other: object) -> bool:
+        if not isinstance(other, Annotator):
+            return False
+
+        return self.name == other.name and self.abbreviation == other.abbreviation
```

### Comparing `pyradise-0.2.2/pyradise/data/image.py` & `pyradise-0.2.3/pyradise/data/image.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,807 +1,807 @@
-import warnings
-from abc import ABC, abstractmethod
-from copy import deepcopy
-from typing import Any, Dict, Optional, Tuple, TypeVar, Union
-
-import itk
-import numpy as np
-import SimpleITK as sitk
-
-from ..utils import convert_to_itk_image, convert_to_sitk_image
-from .annotator import Annotator
-from .modality import Modality
-from .organ import Organ, OrganAnnotatorCombination
-from .taping import TransformTape
-from .utils import str_to_annotator, str_to_modality, str_to_organ
-
-TransformInfo = TypeVar("TransformInfo")
-
-__all__ = ["Image", "IntensityImage", "SegmentationImage", "ImageProperties"]
-
-
-class ImageProperties:
-    """A class to store image properties. This class is predominantly used in combination with a
-    :class:`~pyradise.data.taping.TransformTapeV2` to keep track of the image properties before or after a
-    transformation has been applied.
-
-    Args:
-        image (Union[sitk.Image, itk.Image]): The image to extract the properties from.
-        **kwargs: Additional information.
-    """
-
-    def __init__(self, image: Union[sitk.Image], **kwargs):
-        if isinstance(image, sitk.Image):
-            image_ = image
-        elif isinstance(image, itk.Image):
-            image_ = convert_to_sitk_image(image)
-        else:
-            raise TypeError("Image must be of type SimpleITK.Image or itk.Image")
-
-        self._spacing = image_.GetSpacing()
-        self._origin = image_.GetOrigin()
-        self._direction = image_.GetDirection()
-        self._size = image_.GetSize()
-        self.kwargs = kwargs
-
-    def get_entry(self, key: str) -> Any:
-        """Get entry from additional information.
-
-        Args:
-            key (str): Key of the entry.
-
-        Returns:
-            Any: The value of the entry or ``None`` if the key is not existing.
-        """
-        return self.kwargs.get(key, None)
-
-    def set_entry(self, key: str, value: Any) -> None:
-        """Set an entry as additional information.
-
-        Args:
-            key (str): Key of the entry.
-            value (Any): Value of the entry.
-
-        Returns:
-            None
-        """
-        if key in self.kwargs.keys():
-            raise ValueError(f"Key {key} already exists.")
-
-        self.kwargs[key] = value
-
-    @property
-    def origin(self) -> Tuple[float, ...]:
-        """Get the origin of the image.
-
-        Returns:
-            Tuple[float, ...]: The origin of the image.
-        """
-        return self._origin
-
-    @property
-    def spacing(self) -> Tuple[float, ...]:
-        """Get the spacing of the image.
-
-        Returns:
-            Tuple[float, ...]: The spacing of the image.
-        """
-        return self._spacing
-
-    @property
-    def direction(self) -> Tuple[float, ...]:
-        """Get the direction of the image.
-
-        Returns:
-            Tuple[float, ...]: The direction of the image.
-        """
-        return self._direction
-
-    @property
-    def size(self) -> Tuple[int, ...]:
-        """Get the size of the image.
-
-        Returns:
-            Tuple[int, ...]: The size of the image.
-        """
-        return self._size
-
-    def has_equal_origin_direction(self, other: "ImageProperties") -> bool:
-        """Check if the origin and direction of another :class:`ImageProperties` instance is equal.
-
-        Args:
-            other (ImageProperties): The other image properties.
-
-        Returns:
-            bool: True if the origin and direction are equal, False otherwise.
-        """
-        return self._origin == other._origin and self._direction == other._direction
-
-    def __eq__(self, other: object) -> bool:
-        if not isinstance(other, ImageProperties):
-            return False
-        return (
-            self._origin == other._origin
-            and self._spacing == other._spacing
-            and self._direction == other._direction
-            and self._size == other._size
-        )
-
-
-class Image(ABC):
-    """An abstract class to store images with additional attributes compared to :class:`SimpleITK.Image` and
-    :class:`itk.Image`.
-
-    In addition to standard image types, the :class:`Image` contains a :class:`~pyradise.data.taping.TransformTape`
-    which is used to track and playback transformations applied to the image, such that the original physical
-    properties (i.e. origin, direction, spacing) of the image can be retrieved.
-
-    Args:
-        image (Union[sitk.Image, itk.Image]): The image data to be stored.
-    """
-
-    def __init__(self, image: Union[sitk.Image, itk.Image], data: Optional[Dict[str, Any]] = None) -> None:
-        super().__init__()
-
-        # set the image
-        if isinstance(image, sitk.Image):
-            self.image: sitk.Image = image
-        else:
-            self.image: sitk.Image = convert_to_sitk_image(image)
-
-        # initialize the transform tape
-        self.transform_tape = TransformTape()
-
-        # check validity of the additional data
-        if data is not None:
-            if not isinstance(data, dict):
-                raise TypeError(
-                    "Additional data must be of type dict with the key providing an identifier for " "data retrieval."
-                )
-            if not all(isinstance(key, str) for key in data.keys()):
-                raise TypeError(
-                    "Additional data keys must be of type str because they are used as an identifier for"
-                    "data retrieval!"
-                )
-        else:
-            data = {}
-
-        self.data: Dict[str, Any] = data
-
-    @staticmethod
-    def _return_image_as(image: Union[sitk.Image, itk.Image], as_sitk: bool) -> Union[sitk.Image, itk.Image]:
-        """Return the image as either a :class:`SimpleITK.Image` or :class:`itk.Image`.
-
-        Args:
-            image (Union[sitk.Image, itk.Image]): The image to be returned.
-            as_sitk (bool): If True, the image is returned as a :class:`SimpleITK.Image`, otherwise as a
-             :class:`itk.Image`.
-
-        Returns:
-            Union[sitk.Image, itk.Image]: The image as either a :class:`SimpleITK.Image` or :class:`itk.Image`.
-        """
-        if isinstance(image, sitk.Image) and as_sitk:
-            return image
-
-        if isinstance(image, sitk.Image) and not as_sitk:
-            return convert_to_itk_image(image)
-
-        if isinstance(image, itk.Image) and as_sitk:
-            return convert_to_sitk_image(image)
-
-        return image
-
-    def add_data(self, data: Dict[str, Any]) -> None:
-        """Add additional data to the image.
-
-        Args:
-            data (Dict[str, Any]): The additional data.
-
-        Returns:
-            None
-        """
-        self.data.update(data)
-
-    def add_data_by_key(self, key: str, data: Any) -> None:
-        """Add additional data by key to the image.
-
-        Args:
-            key (str): The key of the additional data.
-            data (Any): The additional data.
-
-        Returns:
-            None
-        """
-        self.data[key] = data
-
-    def get_data(self) -> Dict[str, Any]:
-        """Get the additional data associated with the image.
-
-        Returns:
-            Dict[str, Any]: The additional data associated with the subject.
-        """
-        return self.data
-
-    def get_data_by_key(self, key: str) -> Any:
-        """Get additional data by key or :data:`None` if the key is not existing.
-
-        Args:
-            key (str): The key of the specific additional data.
-
-        Returns:
-            Any: The data or :data:`None`.
-        """
-        return self.data.get(key, None)
-
-    def replace_data(self, key: str, new_data: Any, add_if_missing: bool = False) -> bool:
-        """Replace data by a new value.
-
-        Args:
-            key (str): The key of the additional data.
-            new_data (Any): The new additional data.
-            add_if_missing (bool): If True, the additional data will be added if the key is not existing
-             (default: False).
-
-        Returns:
-            bool: True if the additional data is replaced successfully, False otherwise.
-        """
-        if key not in self.data.keys() and not add_if_missing:
-            warnings.warn(f"The key {key} is not contained in the additional data. No replacement will be performed.")
-            return False
-
-        self.data[key] = new_data
-        return True
-
-    def remove_additional_data(self) -> None:
-        """Remove all additional data from the image.
-
-        Returns:
-            None
-        """
-        self.data.clear()
-
-    def remove_additional_data_by_key(self, key: str) -> bool:
-        """Remove additional data by a key from the image.
-
-        Args:
-            key (str): The key of the additional data.
-
-        Returns:
-            bool: True when the removal procedure was successful otherwise False.
-        """
-        return self.data.pop(key, None) is not None
-
-    @staticmethod
-    def cast(
-        image: Union[sitk.Image, itk.Image], pixel_type: Union[itk.support.types.itkCType, int], as_sitk: bool = True
-    ) -> Union[sitk.Image, itk.Image]:
-        """Cast an image to a certain pixel type and return it as either a :class:`itk.Image` or
-        :class:`SimpleITK.Image`.
-
-        Args:
-            image (Union[sitk.Image, itk.Image]): The image to be casted.
-            pixel_type (Union[itk.support.types.itkCType, int]): The output pixel type.
-            as_sitk (bool): If True the image gets returned as a SimpleITK image otherwise as an ITK image
-             (default: True).
-
-        Returns:
-            Union[sitk.Image, itk.Image]: The casted image as :class:`itk.Image` or :class:`SimpleITK.Image`.
-        """
-        if isinstance(image, sitk.Image):
-            img = sitk.Cast(image, pixel_type)
-
-        else:
-            dimensions = itk.template(image)[1][1]
-            input_image_type = itk.Image[itk.template(image)[1]]
-            output_image_type = itk.Image[pixel_type, dimensions]
-
-            caster = itk.CastImageFilter[input_image_type, output_image_type].New()
-            caster.SetInput(image)
-            caster.Update()
-            img = caster.GetOutput()
-
-        return Image._return_image_as(img, as_sitk)
-
-    def get_image_data(self, as_sitk: bool = True) -> Union[itk.Image, sitk.Image]:
-        """Get the image data as an :class:`itk.Image` (with ``as_sitk=False``) or :class:`SimpleITK.Image`
-        (with ``as_sitk=True``).
-
-        Args:
-            as_sitk (bool): If True returns the image as a SimpleITK image else as an ITK image (default: True).
-
-        Returns:
-            Union[itk.Image, sitk.Image]: The image as the either a :class:`itk.Image` or a :class:`SimpleITK.Image`.
-        """
-        if as_sitk:
-            return self.image
-
-        return convert_to_itk_image(self.image)
-
-    def set_image_data(self, image: Union[sitk.Image, itk.Image]) -> None:
-        """Set the image data.
-
-        Args:
-            image (Union[sitk.Image, itk.Image]): The image to be set.
-
-        Returns:
-            None
-        """
-        if isinstance(image, sitk.Image):
-            self.image: sitk.Image = image
-
-        else:
-            self.image: sitk.Image = convert_to_sitk_image(image)
-
-    def get_image_data_as_np(self, adjust_axes: bool = True) -> np.ndarray:
-        """Get the image data as a numpy array.
-
-        Args:
-            adjust_axes (bool): If True, the axes of the image are adjusted to the numpy convention (default: True).
-
-        Returns:
-            np.ndarray: The image data as a numpy array.
-        """
-        if adjust_axes:
-            image_np = sitk.GetArrayFromImage(self.image)
-            return image_np.reshape(image_np.shape[::-1])
-
-        return sitk.GetArrayFromImage(self.image)
-
-    def get_image_itk_type(self) -> itk.Image:
-        """Get the image type of this image.
-
-        Returns:
-            itk.Image: The image type of this image.
-        """
-        image = convert_to_itk_image(self.image)
-        return itk.Image[itk.template(image)[1]]
-
-    def get_origin(self) -> Tuple[float, ...]:
-        """Get the origin of the image.
-
-        Returns:
-            Tuple[float, ...]: The origin of the image.
-        """
-        return tuple(self.image.GetOrigin())
-
-    def get_direction(self) -> np.ndarray:
-        """Get the direction of the image.
-
-        Returns:
-            np.ndarray: The direction of the image.
-        """
-        dims = self.image.GetDimension()
-        return np.array(self.image.GetDirection()).reshape(dims, dims)
-
-    def get_spacing(self) -> Tuple[float, ...]:
-        """Get the spacing of the image.
-
-        Returns:
-            Tuple[float, ...]: The spacing of the image
-        """
-        return tuple(self.image.GetSpacing())
-
-    def get_size(self) -> Tuple[int, ...]:
-        """Get the size of the image.
-
-        Returns:
-            Tuple[int, ...]: The size of the image.
-        """
-        return tuple(self.image.GetSize())
-
-    def get_dimensions(self) -> int:
-        """Get the number of image dimensions.
-
-        Returns:
-            int: The number of image dimensions.
-        """
-        return self.image.GetDimension()
-
-    def get_orientation(self) -> str:
-        """Get the orientation of the image.
-
-        Returns:
-            str: The orientation of the image.
-        """
-        return sitk.DICOMOrientImageFilter_GetOrientationFromDirectionCosines(self.image.GetDirection())
-
-    def get_transform_tape(self) -> TransformTape:
-        """Get the :class:`~pyradise.data.taping.TransformTape`.
-
-        Returns:
-            TransformTape: The :class:`~pyradise.data.taping.TransformTape`.
-        """
-        return self.transform_tape
-
-    def set_transform_tape(self, tape: TransformTape) -> None:
-        """Set the :class:`~pyradise.data.taping.TransformTape`.
-
-        Args:
-            tape (TransformTape): The :class:`~pyradise.data.taping.TransformTape`.
-
-        Returns:
-            None
-        """
-        self.transform_tape = tape
-
-    def add_transform_info(self, info: TransformInfo) -> None:
-        """Add a :class:`~pyradise.data.taping.TransformInfo` instance to the
-        :class:`~pyradise.data.taping.TransformTape` instance of the image.
-
-        Args:
-            info (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance to be added.
-
-        Returns:
-            None
-        """
-        self.transform_tape.record(info)
-
-    @abstractmethod
-    def copy_info(self, source: "Image", include_transforms: bool = False) -> None:
-        """Copy the image information from another image.
-
-        Args:
-            source (Image): The image to copy the information from.
-            include_transforms (bool): If True the :class:`~pyradise.data.taping.TransformTape` is copied,
-             otherwise not.
-
-        Returns:
-            None
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def is_intensity_image(self) -> bool:
-        """Return True if the image is an intensity image otherwise False.
-
-        Returns:
-            bool: n/a
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def __eq__(self, other: object):
-        """Check if the provided instance is of the same type and if it has the same identification.
-
-        Args:
-            other (object): The object to be checked.
-
-        Returns:
-            bool: True if the object is an image and possess the same identification.
-        """
-        raise NotImplementedError()
-
-
-class IntensityImage(Image):
-    """An intensity image class including a :class:`~pyradise.data.taping.TransformTape` and
-    :class:`~pyradise.data.modality.Modality` to identify the imaging modality of the image.
-
-    Args:
-        image (Union[sitk.Image, itk.Image]): The image data as :class:`itk.Image` or :class:`SimpleITK.Image`.
-        modality (Union[Modality, str]): The image :class:`~pyradise.data.modality.Modality` or the modality's name.
-    """
-
-    def __init__(self, image: Union[sitk.Image, itk.Image], modality: Union[Modality, str]) -> None:
-        super().__init__(image)
-
-        self.modality: Modality = str_to_modality(modality)
-
-    def get_modality(self, as_str: bool = False) -> Union[Modality, str]:
-        """Get the :class:`~pyradise.data.modality.Modality`.
-
-        Args:
-            as_str (bool): If True returns the :class:`~pyradise.data.modality.Modality` as a string, otherwise as
-             type :class:`~pyradise.data.modality.Modality`.
-
-        Returns:
-            Union[Modality, str]: The :class:`~pyradise.data.modality.Modality`.
-        """
-        if as_str:
-            return self.modality.get_name()
-
-        return self.modality
-
-    def set_modality(self, modality: Modality) -> None:
-        """Set the :class:`~pyradise.data.modality.Modality`.
-
-        Args:
-            modality (Modality): The :class:`~pyradise.data.modality.Modality`.
-
-        Returns:
-            None
-        """
-        self.modality: Modality = modality
-
-    def copy_info(self, source: "IntensityImage", include_transforms: bool = False) -> None:
-        """Copy the image information from another :class:`IntensityImage`.
-
-        The copied information includes the following attributes:
-
-            - :class:`~pyradise.data.modality.Modality`
-            - :class:`~pyradise.data.taping.TransformTape` (optional)
-
-        Raises:
-            ValueError: If the source image is not an instance of :class:`IntensityImage`.
-
-        Args:
-            source (IntensityImage): The source image.
-            include_transforms (bool): If True the :class:`~pyradise.data.taping.TransformTape` is copied,
-             otherwise not.
-
-        Returns:
-            None
-        """
-        if not isinstance(source, IntensityImage):
-            raise TypeError("The source image must be an instance of IntensityImage.")
-
-        self.modality: Modality = deepcopy(source.get_modality())
-
-        if include_transforms:
-            self.transform_tape = deepcopy(source.get_transform_tape())
-
-    def is_intensity_image(self) -> bool:
-        """If the image is an instance of :class:`IntensityImage` this function returns True otherwise False.
-
-        Returns:
-            bool: True
-        """
-        return True
-
-    def __eq__(self, other: object) -> bool:
-        """Check if the provided instance is of the same type and if it has the same
-        :class:`~pyradise.data.modality.Modality`.
-
-        Args:
-            other (object): The object to be checked.
-
-        Returns:
-            bool: True if the object is an :class:`IntensityImage` and possess the same identification.
-
-        """
-        if not isinstance(other, IntensityImage):
-            return False
-
-        return self.modality == other.modality
-
-    def __str__(self) -> str:
-        return f"Intensity image: {self.modality.name}"
-
-
-class SegmentationImage(Image):
-    """A segmentation image class including a :class:`~pyradise.data.taping.TransformTape` and additional attributes
-    to identify the :class:`~pyradise.data.organ.Organ` segmented and the :class:`~pyradise.data.annotator.Annotator`
-    who created the segmentation.
-
-    The specification of :class:`~pyradise.data.annotator.Annotator` is optional and can be omitted if not explicitly
-    used.
-
-    Args:
-        image (Union[sitk.Image, itk.Image]): The segmentation image data.
-        organ (Union[Organ, str]): The :class:`~pyradise.data.organ.Organ` represented by the segmentation image or its
-         name.
-        annotator (Optional[Union[Annotator, str]]): The :class:`~pyradise.data.annotator.Annotator` of the segmentation
-         image or a string with the name of the annotator (default: Annotator.get_default()).
-    """
-
-    def __init__(
-        self,
-        image: Union[sitk.Image, itk.Image],
-        organ: Union[Organ, str],
-        annotator: Optional[Union[Annotator, str]] = Annotator.get_default(),
-    ) -> None:
-        super().__init__(image)
-        self.organ: Organ = str_to_organ(organ)
-        if annotator is not None:
-            self.annotator: Optional[Annotator] = str_to_annotator(annotator)
-        else:
-            self.annotator: Optional[Annotator] = None
-
-    def get_organ(self, as_str: bool = False) -> Union[Organ, str]:
-        """Get the :class:`~pyradise.data.organ.Organ`.
-
-        Args:
-            as_str (bool): It True the :class:`~pyradise.data.organ.Organ` gets returned as a :class:`str`,
-             otherwise as an :class:`~pyradise.data.organ.Organ`.
-
-        Returns:
-            Union[Organ, str]: The :class:`~pyradise.data.organ.Organ` or its name as a string.
-        """
-        if as_str:
-            return self.organ.get_name()
-
-        return self.organ
-
-    def set_organ(self, organ: Organ) -> None:
-        """Set the :class:`~pyradise.data.organ.Organ`.
-
-        Args:
-            organ (Organ): The :class:`~pyradise.data.organ.Organ`.
-
-        Returns:
-            None
-        """
-        self.organ: Organ = organ
-
-    def get_annotator(self, as_str: bool = False) -> Union[Annotator, str]:
-        """Get the :class:`~pyradise.data.annotator.Annotator`.
-
-        Args:
-            as_str (bool): If True the name of the :class:`~pyradise.data.annotator.Annotator` gets returned as a
-             :class:`str`, otherwise as an :class:`~pyradise.data.annotator.Annotator` (default: False).
-
-        Returns:
-            Union[Annotator, str]: The :class:`~pyradise.data.annotator.Annotator` or its name as string.
-        """
-        if as_str:
-            return self.annotator.get_name()
-
-        return self.annotator
-
-    def set_annotator(self, annotator: Annotator) -> None:
-        """Set the :class:`~pyradise.data.annotator.Annotator`.
-
-        Args:
-            annotator (Annotator): The :class:`~pyradise.data.annotator.Annotator`.
-
-        Returns:
-            None
-        """
-        self.annotator: Annotator = annotator
-
-    def get_organ_annotator_combination(self) -> OrganAnnotatorCombination:
-        """Get the :class:`~pyradise.data.organ.OrganAnnotatorCombination`.
-
-        Returns:
-            OrganAnnotatorCombination: The combination of the :class:`~pyradise.data.organ.Organ` and the
-            :class:`~pyradise.data.annotator.Annotator`.
-        """
-        return OrganAnnotatorCombination(self.organ, self.annotator)
-
-    def set_organ_annotator_combination(self, organ_annotator_combination: OrganAnnotatorCombination) -> None:
-        """Set the :class:`~pyradise.data.organ.OrganAnnotatorCombination`.
-
-        Args:
-            organ_annotator_combination (OrganAnnotatorCombination): The
-             :class:`~pyradise.data.organ.OrganAnnotatorCombination`.
-
-        Returns:
-            None
-        """
-        self.organ: Organ = organ_annotator_combination.organ
-        self.annotator: Annotator = organ_annotator_combination.annotator
-
-    def copy_info(self, source: "SegmentationImage", include_transforms: bool = False) -> None:
-        """Copy the image information from another :class:`SegmentationImage`.
-
-        The copied information includes the following attributes:
-
-            - :class:`~pyradise.data.organ.Organ`
-            - :class:`~pyradise.data.annotator.Annotator`
-            - :class:`~pyradise.data.taping.TransformTape` (optional)
-
-        Raises:
-            ValueError: If the source image is not an instance of :class:`SegmentationImage`.
-
-        Args:
-            source (IntensityImage): The source image.
-            include_transforms (bool): If True the :class:`~pyradise.data.taping.TransformTape` is copied, otherwise
-             not.
-
-        Returns:
-            None
-        """
-        if not isinstance(source, SegmentationImage):
-            raise TypeError("The source image must be an instance of SegmentationImage.")
-
-        self.organ: Organ = deepcopy(source.get_organ())
-        self.annotator: Annotator = deepcopy(source.get_annotator())
-
-        if include_transforms:
-            self.transform_tape = deepcopy(source.get_transform_tape())
-
-    def is_intensity_image(self) -> bool:
-        """If the image is an :class:`IntensityImage` this function returns True, otherwise False.
-
-        Returns:
-            bool: False
-        """
-        return False
-
-    def is_binary(self) -> bool:
-        """Check if the image is binary.
-
-        Returns:
-            bool: True if the image is binary, otherwise False.
-        """
-        image_np = sitk.GetArrayViewFromImage(self.image)
-        unique_pixel_vals = np.unique(image_np)
-
-        if unique_pixel_vals.shape[0] == 2 and unique_pixel_vals[0] == 0:
-            return True
-
-        return False
-
-    def __eq__(self, other) -> bool:
-        """Check if the provided instance is of the same type and if it has the same :class:`~pyradise.data.organ.Organ`
-         and :class:`~pyradise.annotator.Annotator`.
-
-        Args:
-            other (object): The object to be checked.
-
-        Returns:
-            bool: True if the object is an :class:`SegmentationImage` and possess the same identification.
-        """
-        if not isinstance(other, SegmentationImage):
-            return False
-
-        return all((self.organ == other.organ, self.annotator == other.annotator))
-
-    def __str__(self) -> str:
-        if not self.annotator:
-            return f"SegmentationImage: {self.organ.get_name()}"
-
-        return f"SegmentationImage: {self.organ.get_name()} / {self.annotator.get_name()}"
-
-
-# Preparation for next release
-# class DoseImage(Image):
-#     """A dose image class including a :class:`~pyradise.data.taping.TransformTape`.
-#
-#     Args:
-#         image (Union[sitk.Image, itk.Image]): The image data as :class:`itk.Image` or :class:`SimpleITK.Image`.
-#         data (Optional[Dict[str, Any]], optional): Additional data. Defaults to None.
-#     """
-#     def __init__(self,
-#                  image: Union[sitk.Image, itk.Image],
-#                  data: Optional[Dict[str, Any]] = None,
-#                  ) -> None:
-#         super().__init__(image, data)
-#
-#     def copy_info(self,
-#                   source: 'DoseImage',
-#                   include_transforms: bool = False
-#                   ) -> None:
-#         """Copy the image information from another :class:`DoseImage`.
-#
-#         The copied information includes the following attributes:
-#
-#             - :class:`~pyradise.data.taping.TransformTape` (optional)
-#
-#         Raises:
-#             ValueError: If the source image is not an instance of :class:`DoseImage`.
-#
-#         Args:
-#             source (DoseImage): The source image.
-#             include_transforms (bool): If True the :class:`~pyradise.data.taping.TransformTape` is copied,
-#              otherwise not.
-#
-#         Returns:
-#             None
-#         """
-#         if not isinstance(source, IntensityImage):
-#             raise TypeError('The source image must be an instance of DoseImage.')
-#
-#         if include_transforms:
-#             self.transform_tape = deepcopy(source.get_transform_tape())
-#
-#     def is_intensity_image(self) -> bool:
-#         """If the image is an instance of :class:`IntensityImage` this function returns True otherwise False.
-#
-#         Returns:
-#             bool: False
-#         """
-#         return False
-#
-#     def __eq__(self, other: object):
-#         """Check if the provided instance is of the same type and has the same image content.
-#
-#         Args:
-#             other (object): The object to be checked.
-#
-#         Returns:
-#             bool: True if the object is an :class:`DoseImage` and possess the same identification.
-#
-#         """
-#         if not isinstance(other, DoseImage):
-#             return False
-#
-#         return self.image == other.image
+import warnings
+from abc import ABC, abstractmethod
+from copy import deepcopy
+from typing import Any, Dict, Optional, Tuple, TypeVar, Union
+
+import itk
+import numpy as np
+import SimpleITK as sitk
+
+from ..utils import convert_to_itk_image, convert_to_sitk_image
+from .annotator import Annotator
+from .modality import Modality
+from .organ import Organ, OrganAnnotatorCombination
+from .taping import TransformTape
+from .utils import str_to_annotator, str_to_modality, str_to_organ
+
+TransformInfo = TypeVar("TransformInfo")
+
+__all__ = ["Image", "IntensityImage", "SegmentationImage", "ImageProperties"]
+
+
+class ImageProperties:
+    """A class to store image properties. This class is predominantly used in combination with a
+    :class:`~pyradise.data.taping.TransformTapeV2` to keep track of the image properties before or after a
+    transformation has been applied.
+
+    Args:
+        image (Union[sitk.Image, itk.Image]): The image to extract the properties from.
+        **kwargs: Additional information.
+    """
+
+    def __init__(self, image: Union[sitk.Image, itk.Image], **kwargs):
+        if isinstance(image, sitk.Image):
+            image_ = image
+        elif isinstance(image, itk.Image):
+            image_ = convert_to_sitk_image(image)
+        else:
+            raise TypeError("Image must be of type SimpleITK.Image or itk.Image")
+
+        self._spacing = image_.GetSpacing()
+        self._origin = image_.GetOrigin()
+        self._direction = image_.GetDirection()
+        self._size = image_.GetSize()
+        self.kwargs = kwargs
+
+    def get_entry(self, key: str) -> Any:
+        """Get entry from additional information.
+
+        Args:
+            key (str): Key of the entry.
+
+        Returns:
+            Any: The value of the entry or ``None`` if the key is not existing.
+        """
+        return self.kwargs.get(key, None)
+
+    def set_entry(self, key: str, value: Any) -> None:
+        """Set an entry as additional information.
+
+        Args:
+            key (str): Key of the entry.
+            value (Any): Value of the entry.
+
+        Returns:
+            None
+        """
+        if key in self.kwargs.keys():
+            raise ValueError(f"Key {key} already exists.")
+
+        self.kwargs[key] = value
+
+    @property
+    def origin(self) -> Tuple[float, ...]:
+        """Get the origin of the image.
+
+        Returns:
+            Tuple[float, ...]: The origin of the image.
+        """
+        return self._origin
+
+    @property
+    def spacing(self) -> Tuple[float, ...]:
+        """Get the spacing of the image.
+
+        Returns:
+            Tuple[float, ...]: The spacing of the image.
+        """
+        return self._spacing
+
+    @property
+    def direction(self) -> Tuple[float, ...]:
+        """Get the direction of the image.
+
+        Returns:
+            Tuple[float, ...]: The direction of the image.
+        """
+        return self._direction
+
+    @property
+    def size(self) -> Tuple[int, ...]:
+        """Get the size of the image.
+
+        Returns:
+            Tuple[int, ...]: The size of the image.
+        """
+        return self._size
+
+    def has_equal_origin_direction(self, other: "ImageProperties") -> bool:
+        """Check if the origin and direction of another :class:`ImageProperties` instance is equal.
+
+        Args:
+            other (ImageProperties): The other image properties.
+
+        Returns:
+            bool: True if the origin and direction are equal, False otherwise.
+        """
+        return self._origin == other._origin and self._direction == other._direction
+
+    def __eq__(self, other: object) -> bool:
+        if not isinstance(other, ImageProperties):
+            return False
+        return (
+            self._origin == other._origin
+            and self._spacing == other._spacing
+            and self._direction == other._direction
+            and self._size == other._size
+        )
+
+
+class Image(ABC):
+    """An abstract class to store images with additional attributes compared to :class:`SimpleITK.Image` and
+    :class:`itk.Image`.
+
+    In addition to standard image types, the :class:`Image` contains a :class:`~pyradise.data.taping.TransformTape`
+    which is used to track and playback transformations applied to the image, such that the original physical
+    properties (i.e. origin, direction, spacing) of the image can be retrieved.
+
+    Args:
+        image (Union[sitk.Image, itk.Image]): The image data to be stored.
+    """
+
+    def __init__(self, image: Union[sitk.Image, itk.Image], data: Optional[Dict[str, Any]] = None) -> None:
+        super().__init__()
+
+        # set the image
+        if isinstance(image, sitk.Image):
+            self.image: sitk.Image = image
+        else:
+            self.image: sitk.Image = convert_to_sitk_image(image)
+
+        # initialize the transform tape
+        self.transform_tape = TransformTape()
+
+        # check validity of the additional data
+        if data is not None:
+            if not isinstance(data, dict):
+                raise TypeError(
+                    "Additional data must be of type dict with the key providing an identifier for " "data retrieval."
+                )
+            if not all(isinstance(key, str) for key in data.keys()):
+                raise TypeError(
+                    "Additional data keys must be of type str because they are used as an identifier for"
+                    "data retrieval!"
+                )
+        else:
+            data = {}
+
+        self.data: Dict[str, Any] = data
+
+    @staticmethod
+    def _return_image_as(image: Union[sitk.Image, itk.Image], as_sitk: bool) -> Union[sitk.Image, itk.Image]:
+        """Return the image as either a :class:`SimpleITK.Image` or :class:`itk.Image`.
+
+        Args:
+            image (Union[sitk.Image, itk.Image]): The image to be returned.
+            as_sitk (bool): If True, the image is returned as a :class:`SimpleITK.Image`, otherwise as a
+             :class:`itk.Image`.
+
+        Returns:
+            Union[sitk.Image, itk.Image]: The image as either a :class:`SimpleITK.Image` or :class:`itk.Image`.
+        """
+        if isinstance(image, sitk.Image) and as_sitk:
+            return image
+
+        if isinstance(image, sitk.Image) and not as_sitk:
+            return convert_to_itk_image(image)
+
+        if isinstance(image, itk.Image) and as_sitk:
+            return convert_to_sitk_image(image)
+
+        return image
+
+    def add_data(self, data: Dict[str, Any]) -> None:
+        """Add additional data to the image.
+
+        Args:
+            data (Dict[str, Any]): The additional data.
+
+        Returns:
+            None
+        """
+        self.data.update(data)
+
+    def add_data_by_key(self, key: str, data: Any) -> None:
+        """Add additional data by key to the image.
+
+        Args:
+            key (str): The key of the additional data.
+            data (Any): The additional data.
+
+        Returns:
+            None
+        """
+        self.data[key] = data
+
+    def get_data(self) -> Dict[str, Any]:
+        """Get the additional data associated with the image.
+
+        Returns:
+            Dict[str, Any]: The additional data associated with the subject.
+        """
+        return self.data
+
+    def get_data_by_key(self, key: str) -> Any:
+        """Get additional data by key or :data:`None` if the key is not existing.
+
+        Args:
+            key (str): The key of the specific additional data.
+
+        Returns:
+            Any: The data or :data:`None`.
+        """
+        return self.data.get(key, None)
+
+    def replace_data(self, key: str, new_data: Any, add_if_missing: bool = False) -> bool:
+        """Replace data by a new value.
+
+        Args:
+            key (str): The key of the additional data.
+            new_data (Any): The new additional data.
+            add_if_missing (bool): If True, the additional data will be added if the key is not existing
+             (default: False).
+
+        Returns:
+            bool: True if the additional data is replaced successfully, False otherwise.
+        """
+        if key not in self.data.keys() and not add_if_missing:
+            warnings.warn(f"The key {key} is not contained in the additional data. No replacement will be performed.")
+            return False
+
+        self.data[key] = new_data
+        return True
+
+    def remove_additional_data(self) -> None:
+        """Remove all additional data from the image.
+
+        Returns:
+            None
+        """
+        self.data.clear()
+
+    def remove_additional_data_by_key(self, key: str) -> bool:
+        """Remove additional data by a key from the image.
+
+        Args:
+            key (str): The key of the additional data.
+
+        Returns:
+            bool: True when the removal procedure was successful otherwise False.
+        """
+        return self.data.pop(key, None) is not None
+
+    @staticmethod
+    def cast(
+        image: Union[sitk.Image, itk.Image], pixel_type: Union[itk.support.types.itkCType, int], as_sitk: bool = True
+    ) -> Union[sitk.Image, itk.Image]:
+        """Cast an image to a certain pixel type and return it as either a :class:`itk.Image` or
+        :class:`SimpleITK.Image`.
+
+        Args:
+            image (Union[sitk.Image, itk.Image]): The image to be casted.
+            pixel_type (Union[itk.support.types.itkCType, int]): The output pixel type.
+            as_sitk (bool): If True the image gets returned as a SimpleITK image otherwise as an ITK image
+             (default: True).
+
+        Returns:
+            Union[sitk.Image, itk.Image]: The casted image as :class:`itk.Image` or :class:`SimpleITK.Image`.
+        """
+        if isinstance(image, sitk.Image):
+            img = sitk.Cast(image, pixel_type)
+
+        else:
+            dimensions = itk.template(image)[1][1]
+            input_image_type = itk.Image[itk.template(image)[1]]
+            output_image_type = itk.Image[pixel_type, dimensions]
+
+            caster = itk.CastImageFilter[input_image_type, output_image_type].New()
+            caster.SetInput(image)
+            caster.Update()
+            img = caster.GetOutput()
+
+        return Image._return_image_as(img, as_sitk)
+
+    def get_image_data(self, as_sitk: bool = True) -> Union[itk.Image, sitk.Image]:
+        """Get the image data as an :class:`itk.Image` (with ``as_sitk=False``) or :class:`SimpleITK.Image`
+        (with ``as_sitk=True``).
+
+        Args:
+            as_sitk (bool): If True returns the image as a SimpleITK image else as an ITK image (default: True).
+
+        Returns:
+            Union[itk.Image, sitk.Image]: The image as the either a :class:`itk.Image` or a :class:`SimpleITK.Image`.
+        """
+        if as_sitk:
+            return self.image
+
+        return convert_to_itk_image(self.image)
+
+    def set_image_data(self, image: Union[sitk.Image, itk.Image]) -> None:
+        """Set the image data.
+
+        Args:
+            image (Union[sitk.Image, itk.Image]): The image to be set.
+
+        Returns:
+            None
+        """
+        if isinstance(image, sitk.Image):
+            self.image: sitk.Image = image
+
+        else:
+            self.image: sitk.Image = convert_to_sitk_image(image)
+
+    def get_image_data_as_np(self, adjust_axes: bool = True) -> np.ndarray:
+        """Get the image data as a numpy array.
+
+        Args:
+            adjust_axes (bool): If True, the axes of the image are adjusted to the numpy convention (default: True).
+
+        Returns:
+            np.ndarray: The image data as a numpy array.
+        """
+        if adjust_axes:
+            image_np = sitk.GetArrayFromImage(self.image)
+            return image_np.reshape(image_np.shape[::-1])
+
+        return sitk.GetArrayFromImage(self.image)
+
+    def get_image_itk_type(self) -> itk.Image:
+        """Get the image type of this image.
+
+        Returns:
+            itk.Image: The image type of this image.
+        """
+        image = convert_to_itk_image(self.image)
+        return itk.Image[itk.template(image)[1]]
+
+    def get_origin(self) -> Tuple[float, ...]:
+        """Get the origin of the image.
+
+        Returns:
+            Tuple[float, ...]: The origin of the image.
+        """
+        return tuple(self.image.GetOrigin())
+
+    def get_direction(self) -> np.ndarray:
+        """Get the direction of the image.
+
+        Returns:
+            np.ndarray: The direction of the image.
+        """
+        dims = self.image.GetDimension()
+        return np.array(self.image.GetDirection()).reshape(dims, dims)
+
+    def get_spacing(self) -> Tuple[float, ...]:
+        """Get the spacing of the image.
+
+        Returns:
+            Tuple[float, ...]: The spacing of the image
+        """
+        return tuple(self.image.GetSpacing())
+
+    def get_size(self) -> Tuple[int, ...]:
+        """Get the size of the image.
+
+        Returns:
+            Tuple[int, ...]: The size of the image.
+        """
+        return tuple(self.image.GetSize())
+
+    def get_dimensions(self) -> int:
+        """Get the number of image dimensions.
+
+        Returns:
+            int: The number of image dimensions.
+        """
+        return self.image.GetDimension()
+
+    def get_orientation(self) -> str:
+        """Get the orientation of the image.
+
+        Returns:
+            str: The orientation of the image.
+        """
+        return sitk.DICOMOrientImageFilter_GetOrientationFromDirectionCosines(self.image.GetDirection())
+
+    def get_transform_tape(self) -> TransformTape:
+        """Get the :class:`~pyradise.data.taping.TransformTape`.
+
+        Returns:
+            TransformTape: The :class:`~pyradise.data.taping.TransformTape`.
+        """
+        return self.transform_tape
+
+    def set_transform_tape(self, tape: TransformTape) -> None:
+        """Set the :class:`~pyradise.data.taping.TransformTape`.
+
+        Args:
+            tape (TransformTape): The :class:`~pyradise.data.taping.TransformTape`.
+
+        Returns:
+            None
+        """
+        self.transform_tape = tape
+
+    def add_transform_info(self, info: TransformInfo) -> None:
+        """Add a :class:`~pyradise.data.taping.TransformInfo` instance to the
+        :class:`~pyradise.data.taping.TransformTape` instance of the image.
+
+        Args:
+            info (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance to be added.
+
+        Returns:
+            None
+        """
+        self.transform_tape.record(info)
+
+    @abstractmethod
+    def copy_info(self, source: "Image", include_transforms: bool = False) -> None:
+        """Copy the image information from another image.
+
+        Args:
+            source (Image): The image to copy the information from.
+            include_transforms (bool): If True the :class:`~pyradise.data.taping.TransformTape` is copied,
+             otherwise not.
+
+        Returns:
+            None
+        """
+        raise NotImplementedError()
+
+    @abstractmethod
+    def is_intensity_image(self) -> bool:
+        """Return True if the image is an intensity image otherwise False.
+
+        Returns:
+            bool: n/a
+        """
+        raise NotImplementedError()
+
+    @abstractmethod
+    def __eq__(self, other: object):
+        """Check if the provided instance is of the same type and if it has the same identification.
+
+        Args:
+            other (object): The object to be checked.
+
+        Returns:
+            bool: True if the object is an image and possess the same identification.
+        """
+        raise NotImplementedError()
+
+
+class IntensityImage(Image):
+    """An intensity image class including a :class:`~pyradise.data.taping.TransformTape` and
+    :class:`~pyradise.data.modality.Modality` to identify the imaging modality of the image.
+
+    Args:
+        image (Union[sitk.Image, itk.Image]): The image data as :class:`itk.Image` or :class:`SimpleITK.Image`.
+        modality (Union[Modality, str]): The image :class:`~pyradise.data.modality.Modality` or the modality's name.
+    """
+
+    def __init__(self, image: Union[sitk.Image, itk.Image], modality: Union[Modality, str]) -> None:
+        super().__init__(image)
+
+        self.modality: Modality = str_to_modality(modality)
+
+    def get_modality(self, as_str: bool = False) -> Union[Modality, str]:
+        """Get the :class:`~pyradise.data.modality.Modality`.
+
+        Args:
+            as_str (bool): If True returns the :class:`~pyradise.data.modality.Modality` as a string, otherwise as
+             type :class:`~pyradise.data.modality.Modality`.
+
+        Returns:
+            Union[Modality, str]: The :class:`~pyradise.data.modality.Modality`.
+        """
+        if as_str:
+            return self.modality.get_name()
+
+        return self.modality
+
+    def set_modality(self, modality: Modality) -> None:
+        """Set the :class:`~pyradise.data.modality.Modality`.
+
+        Args:
+            modality (Modality): The :class:`~pyradise.data.modality.Modality`.
+
+        Returns:
+            None
+        """
+        self.modality: Modality = modality
+
+    def copy_info(self, source: "IntensityImage", include_transforms: bool = False) -> None:
+        """Copy the image information from another :class:`IntensityImage`.
+
+        The copied information includes the following attributes:
+
+            - :class:`~pyradise.data.modality.Modality`
+            - :class:`~pyradise.data.taping.TransformTape` (optional)
+
+        Raises:
+            ValueError: If the source image is not an instance of :class:`IntensityImage`.
+
+        Args:
+            source (IntensityImage): The source image.
+            include_transforms (bool): If True the :class:`~pyradise.data.taping.TransformTape` is copied,
+             otherwise not.
+
+        Returns:
+            None
+        """
+        if not isinstance(source, IntensityImage):
+            raise TypeError("The source image must be an instance of IntensityImage.")
+
+        self.modality: Modality = deepcopy(source.get_modality())
+
+        if include_transforms:
+            self.transform_tape = deepcopy(source.get_transform_tape())
+
+    def is_intensity_image(self) -> bool:
+        """If the image is an instance of :class:`IntensityImage` this function returns True otherwise False.
+
+        Returns:
+            bool: True
+        """
+        return True
+
+    def __eq__(self, other: object) -> bool:
+        """Check if the provided instance is of the same type and if it has the same
+        :class:`~pyradise.data.modality.Modality`.
+
+        Args:
+            other (object): The object to be checked.
+
+        Returns:
+            bool: True if the object is an :class:`IntensityImage` and possess the same identification.
+
+        """
+        if not isinstance(other, IntensityImage):
+            return False
+
+        return self.modality == other.modality
+
+    def __str__(self) -> str:
+        return f"Intensity image: {self.modality.name}"
+
+
+class SegmentationImage(Image):
+    """A segmentation image class including a :class:`~pyradise.data.taping.TransformTape` and additional attributes
+    to identify the :class:`~pyradise.data.organ.Organ` segmented and the :class:`~pyradise.data.annotator.Annotator`
+    who created the segmentation.
+
+    The specification of :class:`~pyradise.data.annotator.Annotator` is optional and can be omitted if not explicitly
+    used.
+
+    Args:
+        image (Union[sitk.Image, itk.Image]): The segmentation image data.
+        organ (Union[Organ, str]): The :class:`~pyradise.data.organ.Organ` represented by the segmentation image or its
+         name.
+        annotator (Optional[Union[Annotator, str]]): The :class:`~pyradise.data.annotator.Annotator` of the segmentation
+         image or a string with the name of the annotator (default: Annotator.get_default()).
+    """
+
+    def __init__(
+        self,
+        image: Union[sitk.Image, itk.Image],
+        organ: Union[Organ, str],
+        annotator: Optional[Union[Annotator, str]] = Annotator.get_default(),
+    ) -> None:
+        super().__init__(image)
+        self.organ: Organ = str_to_organ(organ)
+        if annotator is not None:
+            self.annotator: Optional[Annotator] = str_to_annotator(annotator)
+        else:
+            self.annotator: Optional[Annotator] = None
+
+    def get_organ(self, as_str: bool = False) -> Union[Organ, str]:
+        """Get the :class:`~pyradise.data.organ.Organ`.
+
+        Args:
+            as_str (bool): It True the :class:`~pyradise.data.organ.Organ` gets returned as a :class:`str`,
+             otherwise as an :class:`~pyradise.data.organ.Organ`.
+
+        Returns:
+            Union[Organ, str]: The :class:`~pyradise.data.organ.Organ` or its name as a string.
+        """
+        if as_str:
+            return self.organ.get_name()
+
+        return self.organ
+
+    def set_organ(self, organ: Organ) -> None:
+        """Set the :class:`~pyradise.data.organ.Organ`.
+
+        Args:
+            organ (Organ): The :class:`~pyradise.data.organ.Organ`.
+
+        Returns:
+            None
+        """
+        self.organ: Organ = organ
+
+    def get_annotator(self, as_str: bool = False) -> Union[Annotator, str]:
+        """Get the :class:`~pyradise.data.annotator.Annotator`.
+
+        Args:
+            as_str (bool): If True the name of the :class:`~pyradise.data.annotator.Annotator` gets returned as a
+             :class:`str`, otherwise as an :class:`~pyradise.data.annotator.Annotator` (default: False).
+
+        Returns:
+            Union[Annotator, str]: The :class:`~pyradise.data.annotator.Annotator` or its name as string.
+        """
+        if as_str:
+            return self.annotator.get_name()
+
+        return self.annotator
+
+    def set_annotator(self, annotator: Annotator) -> None:
+        """Set the :class:`~pyradise.data.annotator.Annotator`.
+
+        Args:
+            annotator (Annotator): The :class:`~pyradise.data.annotator.Annotator`.
+
+        Returns:
+            None
+        """
+        self.annotator: Annotator = annotator
+
+    def get_organ_annotator_combination(self) -> OrganAnnotatorCombination:
+        """Get the :class:`~pyradise.data.organ.OrganAnnotatorCombination`.
+
+        Returns:
+            OrganAnnotatorCombination: The combination of the :class:`~pyradise.data.organ.Organ` and the
+            :class:`~pyradise.data.annotator.Annotator`.
+        """
+        return OrganAnnotatorCombination(self.organ, self.annotator)
+
+    def set_organ_annotator_combination(self, organ_annotator_combination: OrganAnnotatorCombination) -> None:
+        """Set the :class:`~pyradise.data.organ.OrganAnnotatorCombination`.
+
+        Args:
+            organ_annotator_combination (OrganAnnotatorCombination): The
+             :class:`~pyradise.data.organ.OrganAnnotatorCombination`.
+
+        Returns:
+            None
+        """
+        self.organ: Organ = organ_annotator_combination.organ
+        self.annotator: Annotator = organ_annotator_combination.annotator
+
+    def copy_info(self, source: "SegmentationImage", include_transforms: bool = False) -> None:
+        """Copy the image information from another :class:`SegmentationImage`.
+
+        The copied information includes the following attributes:
+
+            - :class:`~pyradise.data.organ.Organ`
+            - :class:`~pyradise.data.annotator.Annotator`
+            - :class:`~pyradise.data.taping.TransformTape` (optional)
+
+        Raises:
+            ValueError: If the source image is not an instance of :class:`SegmentationImage`.
+
+        Args:
+            source (IntensityImage): The source image.
+            include_transforms (bool): If True the :class:`~pyradise.data.taping.TransformTape` is copied, otherwise
+             not.
+
+        Returns:
+            None
+        """
+        if not isinstance(source, SegmentationImage):
+            raise TypeError("The source image must be an instance of SegmentationImage.")
+
+        self.organ: Organ = deepcopy(source.get_organ())
+        self.annotator: Annotator = deepcopy(source.get_annotator())
+
+        if include_transforms:
+            self.transform_tape = deepcopy(source.get_transform_tape())
+
+    def is_intensity_image(self) -> bool:
+        """If the image is an :class:`IntensityImage` this function returns True, otherwise False.
+
+        Returns:
+            bool: False
+        """
+        return False
+
+    def is_binary(self) -> bool:
+        """Check if the image is binary.
+
+        Returns:
+            bool: True if the image is binary, otherwise False.
+        """
+        image_np = sitk.GetArrayViewFromImage(self.image)
+        unique_pixel_vals = np.unique(image_np)
+
+        if unique_pixel_vals.shape[0] == 2 and unique_pixel_vals[0] == 0:
+            return True
+
+        return False
+
+    def __eq__(self, other) -> bool:
+        """Check if the provided instance is of the same type and if it has the same :class:`~pyradise.data.organ.Organ`
+         and :class:`~pyradise.annotator.Annotator`.
+
+        Args:
+            other (object): The object to be checked.
+
+        Returns:
+            bool: True if the object is an :class:`SegmentationImage` and possess the same identification.
+        """
+        if not isinstance(other, SegmentationImage):
+            return False
+
+        return all((self.organ == other.organ, self.annotator == other.annotator))
+
+    def __str__(self) -> str:
+        if not self.annotator:
+            return f"SegmentationImage: {self.organ.get_name()}"
+
+        return f"SegmentationImage: {self.organ.get_name()} / {self.annotator.get_name()}"
+
+
+# Preparation for next release
+# class DoseImage(Image):
+#     """A dose image class including a :class:`~pyradise.data.taping.TransformTape`.
+#
+#     Args:
+#         image (Union[sitk.Image, itk.Image]): The image data as :class:`itk.Image` or :class:`SimpleITK.Image`.
+#         data (Optional[Dict[str, Any]], optional): Additional data. Defaults to None.
+#     """
+#     def __init__(self,
+#                  image: Union[sitk.Image, itk.Image],
+#                  data: Optional[Dict[str, Any]] = None,
+#                  ) -> None:
+#         super().__init__(image, data)
+#
+#     def copy_info(self,
+#                   source: 'DoseImage',
+#                   include_transforms: bool = False
+#                   ) -> None:
+#         """Copy the image information from another :class:`DoseImage`.
+#
+#         The copied information includes the following attributes:
+#
+#             - :class:`~pyradise.data.taping.TransformTape` (optional)
+#
+#         Raises:
+#             ValueError: If the source image is not an instance of :class:`DoseImage`.
+#
+#         Args:
+#             source (DoseImage): The source image.
+#             include_transforms (bool): If True the :class:`~pyradise.data.taping.TransformTape` is copied,
+#              otherwise not.
+#
+#         Returns:
+#             None
+#         """
+#         if not isinstance(source, IntensityImage):
+#             raise TypeError('The source image must be an instance of DoseImage.')
+#
+#         if include_transforms:
+#             self.transform_tape = deepcopy(source.get_transform_tape())
+#
+#     def is_intensity_image(self) -> bool:
+#         """If the image is an instance of :class:`IntensityImage` this function returns True otherwise False.
+#
+#         Returns:
+#             bool: False
+#         """
+#         return False
+#
+#     def __eq__(self, other: object):
+#         """Check if the provided instance is of the same type and has the same image content.
+#
+#         Args:
+#             other (object): The object to be checked.
+#
+#         Returns:
+#             bool: True if the object is an :class:`DoseImage` and possess the same identification.
+#
+#         """
+#         if not isinstance(other, DoseImage):
+#             return False
+#
+#         return self.image == other.image
```

### Comparing `pyradise-0.2.2/pyradise/data/modality.py` & `pyradise-0.2.3/pyradise/data/modality.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,64 +1,64 @@
-__all__ = ["Modality"]
-
-
-class Modality:
-    """A class for identifying the imaging modality and its details.
-
-    Notes:
-        The :class:`Modality` class is used to discriminate between different imaging modalities and its details
-        (e.g. the MR-sequence (T1c or T1w)). We are aware that the name modality may be misleading and does not follow
-        precisely the professional taxonomy of the community, but we decided to stick to it for the sake of clarity and
-        ease of use.
-
-    Args:
-        name (str): The name of the modality.
-
-    """
-
-    def __init__(self, name: str) -> None:
-        super().__init__()
-        self.name = name
-        self.default_name = "UNKNOWN"
-
-    @classmethod
-    def get_default(cls) -> "Modality":
-        """Get the default :class:`Modality`.
-
-        Notes:
-            The default :class:`Modality` is 'UNKNOWN'.
-
-        Returns:
-            Modality: The default :class:`Modality`.
-        """
-        return Modality("UNKNOWN")
-
-    def is_default(self) -> bool:
-        """Check if the :class:`Modality` is the default :class:`Modality`.
-
-        Notes:
-            The default :class:`Modality` is 'UNKNOWN'.
-
-        Returns:
-            bool: True if the :class:`Modality` is the default :class:`Modality`, otherwise False.
-        """
-        return self.name == self.default_name
-
-    def get_name(self) -> str:
-        """Get the name of the :class:`Modality`.
-
-        Returns:
-            str: The name of the :class:`Modality`.
-        """
-        return self.name
-
-    def __str__(self) -> str:
-        return self.name
-
-    def __eq__(self, other: object) -> bool:
-        if not isinstance(other, Modality):
-            raise False
-
-        return self.name == other.name
-
-    def __hash__(self):
-        return hash(self.name)
+__all__ = ["Modality"]
+
+
+class Modality:
+    """A class for identifying the imaging modality and its details.
+
+    Notes:
+        The :class:`Modality` class is used to discriminate between different imaging modalities and its details
+        (e.g. the MR-sequence (T1c or T1w)). We are aware that the name modality may be misleading and does not follow
+        precisely the professional taxonomy of the community, but we decided to stick to it for the sake of clarity and
+        ease of use.
+
+    Args:
+        name (str): The name of the modality.
+
+    """
+
+    def __init__(self, name: str) -> None:
+        super().__init__()
+        self.name = name
+        self.default_name = "UNKNOWN"
+
+    @classmethod
+    def get_default(cls) -> "Modality":
+        """Get the default :class:`Modality`.
+
+        Notes:
+            The default :class:`Modality` is 'UNKNOWN'.
+
+        Returns:
+            Modality: The default :class:`Modality`.
+        """
+        return Modality("UNKNOWN")
+
+    def is_default(self) -> bool:
+        """Check if the :class:`Modality` is the default :class:`Modality`.
+
+        Notes:
+            The default :class:`Modality` is 'UNKNOWN'.
+
+        Returns:
+            bool: True if the :class:`Modality` is the default :class:`Modality`, otherwise False.
+        """
+        return self.name == self.default_name
+
+    def get_name(self) -> str:
+        """Get the name of the :class:`Modality`.
+
+        Returns:
+            str: The name of the :class:`Modality`.
+        """
+        return self.name
+
+    def __str__(self) -> str:
+        return self.name
+
+    def __eq__(self, other: object) -> bool:
+        if not isinstance(other, Modality):
+            raise False
+
+        return self.name == other.name
+
+    def __hash__(self):
+        return hash(self.name)
```

### Comparing `pyradise-0.2.2/pyradise/data/organ.py` & `pyradise-0.2.3/pyradise/data/organ.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,93 +1,93 @@
-from typing import Optional, Union
-
-from .annotator import Annotator
-
-__all__ = ["Organ", "OrganAnnotatorCombination"]
-
-
-class Organ:
-    """A class for identifying an organ.
-
-    Notes:
-        The :class:`Organ` is used to identify the organ segmented on a :class:`~pyradise.data.image.SegmentationImage`.
-        If multiple organs are segmented on a single :class:`~pyradise.data.image.SegmentationImage`, the
-        :class:`Organ` may be assigned an artificial name describing the set of organs.
-
-
-    Args:
-        name (str): The name of the :class:`Organ`.
-        index (Optional[int]): The index of the :class:`Organ` (default: None).
-    """
-
-    def __init__(self, name: str, index: Optional[int] = None) -> None:
-        super().__init__()
-
-        self.name: str = name
-        self.index: Optional[int] = index
-
-    def get_name(self) -> str:
-        """Get the name of the :class:`Organ`.
-
-        Returns:
-            str: The name of the :class:`Organ`.
-        """
-        return self.name
-
-    def set_name(self, name: str) -> None:
-        """Set the name of the :class:`Organ`.
-
-        Args:
-            name (str): The name of the :class:`Organ`.
-        """
-        self.name = name
-
-    def __str__(self) -> str:
-        return self.name
-
-    def __eq__(self, other: object) -> bool:
-        if not isinstance(other, Organ):
-            return False
-
-        return self.name == other.name
-
-    def __hash__(self):
-        return hash(str(self))
-
-
-class OrganAnnotatorCombination:
-    """A class combining an :class:`Organ` with a :class:`~pyradise.data.annotator.Annotator`.
-
-    Args:
-        organ (Union[Organ, str]): The :class:`Organ` or its name.
-        annotator (Union[Annotator, str]): The :class:`~pyradise.data.annotator.Annotator` or its name.
-    """
-
-    def __init__(self, organ: Union[Organ, str], annotator: Union[Annotator, str]) -> None:
-        super().__init__()
-
-        if isinstance(organ, str):
-            organ = Organ(organ)
-
-        if isinstance(annotator, str):
-            annotator = Annotator(annotator)
-
-        self.organ: Organ = organ
-        self.annotator: Annotator = annotator
-
-    def __str__(self) -> str:
-        return self.name
-
-    def __eq__(self, other):
-        return self.name == other.name
-
-    def __hash__(self):
-        return hash(str(self))
-
-    @property
-    def name(self) -> str:
-        """Get the name of the :class:`OrganAnnotatorCombination`.
-
-        Returns:
-            str: The combined name.
-        """
-        return self.organ.name + "_" + self.annotator.name
+from typing import Optional, Union
+
+from .annotator import Annotator
+
+__all__ = ["Organ", "OrganAnnotatorCombination"]
+
+
+class Organ:
+    """A class for identifying an organ.
+
+    Notes:
+        The :class:`Organ` is used to identify the organ segmented on a :class:`~pyradise.data.image.SegmentationImage`.
+        If multiple organs are segmented on a single :class:`~pyradise.data.image.SegmentationImage`, the
+        :class:`Organ` may be assigned an artificial name describing the set of organs.
+
+
+    Args:
+        name (str): The name of the :class:`Organ`.
+        index (Optional[int]): The index of the :class:`Organ` (default: None).
+    """
+
+    def __init__(self, name: str, index: Optional[int] = None) -> None:
+        super().__init__()
+
+        self.name: str = name
+        self.index: Optional[int] = index
+
+    def get_name(self) -> str:
+        """Get the name of the :class:`Organ`.
+
+        Returns:
+            str: The name of the :class:`Organ`.
+        """
+        return self.name
+
+    def set_name(self, name: str) -> None:
+        """Set the name of the :class:`Organ`.
+
+        Args:
+            name (str): The name of the :class:`Organ`.
+        """
+        self.name = name
+
+    def __str__(self) -> str:
+        return self.name
+
+    def __eq__(self, other: object) -> bool:
+        if not isinstance(other, Organ):
+            return False
+
+        return self.name == other.name
+
+    def __hash__(self):
+        return hash(str(self))
+
+
+class OrganAnnotatorCombination:
+    """A class combining an :class:`Organ` with a :class:`~pyradise.data.annotator.Annotator`.
+
+    Args:
+        organ (Union[Organ, str]): The :class:`Organ` or its name.
+        annotator (Union[Annotator, str]): The :class:`~pyradise.data.annotator.Annotator` or its name.
+    """
+
+    def __init__(self, organ: Union[Organ, str], annotator: Union[Annotator, str]) -> None:
+        super().__init__()
+
+        if isinstance(organ, str):
+            organ = Organ(organ)
+
+        if isinstance(annotator, str):
+            annotator = Annotator(annotator)
+
+        self.organ: Organ = organ
+        self.annotator: Annotator = annotator
+
+    def __str__(self) -> str:
+        return self.name
+
+    def __eq__(self, other):
+        return self.name == other.name
+
+    def __hash__(self):
+        return hash(str(self))
+
+    @property
+    def name(self) -> str:
+        """Get the name of the :class:`OrganAnnotatorCombination`.
+
+        Returns:
+            str: The combined name.
+        """
+        return self.organ.name + "_" + self.annotator.name
```

### Comparing `pyradise-0.2.2/pyradise/data/subject.py` & `pyradise-0.2.3/pyradise/data/subject.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,676 +1,676 @@
-from collections import abc as col_abc
-from typing import Any, Dict, List, Optional, Sequence, Tuple, Union
-from warnings import warn
-
-from .annotator import Annotator
-from .image import Image, IntensityImage, SegmentationImage
-from .modality import Modality
-from .organ import Organ
-
-__all__ = ["Subject"]
-
-
-class Subject:
-    """The :class:`Subject` is the main data object which holds all :class:`~pyradise.data.image.IntensityImage` s and
-    :class:`~pyradise.data.image.SegmentationImage` s associated with the subject. Furthermore, it can hold any type
-    of additional data associated with the patient. Currently, the routines implemented in PyRaDiSe do not use this
-    mechanism so it can be used freely by the user.
-
-    Args:
-        name (str): The name of the subject.
-        images (Optional[Union[Image, Sequence[Image]]]): One or multiple images to add to the subject.
-        data (Optional[Dict[str, Any]]): Additional data which is associated with the subject.
-
-    Examples:
-        The following example demonstrates the manual construction of a :class:`Subject`:
-
-        >>> from argparse import ArgumentParser
-        >>> from typing import Tuple
-        >>> import os
-        >>>
-        >>> import SimpleITK as sitk
-        >>>
-        >>> from pyradise.data import (Subject, IntensityImage, SegmentationImage,
-        >>>                            Modality, Organ, Annotator)
-        >>> from pyradise.fileio import SubjectWriter, ImageFileFormat
-        >>>
-        >>>
-        >>> def get_segmentation_file_paths(path: str,
-        >>>                                 valid_organs: Tuple[Organ, ...]
-        >>>                                 ) -> Tuple[str]:
-        >>>     file_paths = []
-        >>>
-        >>>     for file in os.listdir(path):
-        >>>         if not file.endswith('.nii.gz'):
-        >>>             continue
-        >>>
-        >>>         if any(entry.name in file for entry in valid_organs):
-        >>>             file_paths.append(os.path.join(path, file))
-        >>>
-        >>>     return tuple(sorted(file_paths))
-        >>>
-        >>>
-        >>> def get_intensity_file_paths(path: str,
-        >>>                              valid_modalities: Tuple[Modality, ...]
-        >>>                              ) -> Tuple[str]:
-        >>>     file_paths = []
-        >>>
-        >>>     for file in os.listdir(path):
-        >>>         if not file.endswith('.nii.gz'):
-        >>>             continue
-        >>>
-        >>>         if any(entry.get_name() in file for entry in valid_modalities):
-        >>>             file_paths.append(os.path.join(path, file))
-        >>>
-        >>>     return tuple(sorted(file_paths))
-        >>>
-        >>>
-        >>> def main(input_dir: str,
-        >>>          output_dir: str
-        >>>          ) -> None:
-        >>>     # Retrieve image file paths
-        >>>     organs = (Organ('Brainstem'), Organ('Eyes'),
-        >>>               Organ('Hippocampi'), Organ('OpticNerves'))
-        >>>     modalities = (Modality('CT'), Modality('T1c'),
-        >>>                   Modality('T1w'), Modality('T2w'))
-        >>>
-        >>>     segmentation_file_paths = get_segmentation_file_paths(input_dir, organs)
-        >>>     intensity_file_paths = get_intensity_file_paths(input_dir, modalities)
-        >>>
-        >>>     # Load the segmentation image files
-        >>>     images = []
-        >>>     for path, organ in zip(segmentation_file_paths, organs):
-        >>>         image = SegmentationImage(sitk.ReadImage(path, sitk.sitkUInt8),
-        >>>                                   organ, Annotator.get_default())
-        >>>         images.append(image)
-        >>>
-        >>>     # Load the intensity image files
-        >>>     for path, modality in zip(intensity_file_paths, modalities):
-        >>>         image = IntensityImage(sitk.ReadImage(path, sitk.sitkFloat32),
-        >>>                                modality)
-        >>>         images.append(image)
-        >>>
-        >>>     # Construct the subject
-        >>>     subject = Subject(os.path.basename(input_dir), images)
-        >>>
-        >>>     # Display the subject name and properties of the intensity and
-        >>>     # segmentation images
-        >>>     print(f'Subject {subject.get_name()} contains the following images:')
-        >>>
-        >>>     for image in subject.intensity_images:
-        >>>         print(f'Intensity image of modality {image.get_modality(True)} '
-        >>>               f'with size: {image.get_size()}')
-        >>>
-        >>>     for image in subject.segmentation_images:
-        >>>         print(f'Segmentation image of {image.get_organ(True)} '
-        >>>               f'with size: {image.get_size()}')
-        >>>
-        >>>     # Write the subject to disk
-        >>>     SubjectWriter(ImageFileFormat.NRRD).write(output_dir, subject,
-        >>>                                               write_transforms=False)
-        >>>
-        >>>
-        >>> if __name__ == '__main__':
-        >>>     parser = ArgumentParser()
-        >>>     parser.add_argument('-input_dir', type=str)
-        >>>     parser.add_argument('-output_dir', type=str)
-        >>>     args = parser.parse_args()
-        >>>
-        >>>     main(args.input_dir, args.output_dir)
-        >>>
-        >>> # Output:
-        >>> # Subject subject_1 contains the following images:
-        >>> # Intensity image of modality CT with size: (256, 256, 256)
-        >>> # Intensity image of modality T1c with size: (256, 256, 256)
-        >>> # Intensity image of modality T1w with size: (256, 256, 256)
-        >>> # Intensity image of modality T2w with size: (256, 256, 256)
-        >>> # Segmentation image of Brainstem with size: (256, 256, 256)
-        >>> # Segmentation image of Eyes with size: (256, 256, 256)
-        >>> # Segmentation image of Hippocampi with size: (256, 256, 256)
-        >>> # Segmentation image of OpticNerves with size: (256, 256, 256)
-    """
-
-    def __init__(
-        self, name: str, images: Optional[Union[Image, Sequence[Image]]] = None, data: Optional[Dict[str, Any]] = None
-    ) -> None:
-        super().__init__()
-
-        self.name = name
-
-        self.intensity_images: List[IntensityImage] = []
-        self.segmentation_images: List[SegmentationImage] = []
-
-        if isinstance(images, IntensityImage):
-            self.intensity_images.append(images)
-
-        if isinstance(images, SegmentationImage):
-            self.segmentation_images.append(images)
-
-        if isinstance(images, col_abc.Sequence):
-            for image in images:
-                if isinstance(image, IntensityImage):
-                    self.intensity_images.append(image)
-                elif isinstance(image, SegmentationImage):
-                    self.segmentation_images.append(image)
-                else:
-                    raise ValueError(
-                        f"At least one image is not of type {IntensityImage.__class__.__name__} or"
-                        f"{SegmentationImage.__class__.__name__}!"
-                    )
-
-        # check validity of the additional data
-        if data is not None:
-            if not isinstance(data, dict):
-                raise TypeError(
-                    "Additional data must be of type dict with the key providing an identifier for " "data retrieval."
-                )
-            if not all(isinstance(key, str) for key in data.keys()):
-                raise TypeError(
-                    "Additional data keys must be of type str because they are used as an identifier for"
-                    "data retrieval.!"
-                )
-        else:
-            data = {}
-
-        self.data: Dict[str, Any] = data
-
-    @staticmethod
-    def _check_for_single_candidate(candidates: List[Any], entity_name: str, return_first_on_multiple: bool) -> Any:
-        if len(candidates) == 1:
-            return candidates[0]
-
-        if len(candidates) > 1:
-            if return_first_on_multiple:
-                warn(
-                    f"The search for {entity_name} is ambiguous because there are multiple ({len(candidates)}) "
-                    "candidates which are equal. The first found candidate will be returned."
-                )
-                return candidates[0]
-            else:
-                raise ValueError(f"There are multiple {entity_name} which fulfil the criterion ({len(candidates)})!")
-
-        return None
-
-    def get_name(self) -> str:
-        """Get the name of the subject.
-
-        Returns:
-            str: The name of the subject.
-        """
-        return self.name
-
-    def get_modalities(self) -> Tuple[Optional[Modality], ...]:
-        """Get the modalities of the subject-associated intensity images.
-
-        Returns:
-            Tuple[Optional[Modality], ...]: The modalities of the intensity images.
-        """
-        modalities = [img.get_modality() for img in self.intensity_images]
-        return tuple(modalities)
-
-    def get_organs(self) -> Tuple[Optional[Organ], ...]:
-        """Get the organs of the subject-associated segmentation images.
-
-        Returns:
-            Tuple[Optional[Organ], ...]: The organs of the segmentation images.
-        """
-        organs = [seg.get_organ() for seg in self.segmentation_images]
-        return tuple(organs)
-
-    def get_annotators(self) -> Tuple[Optional[Annotator], ...]:
-        """Get the annotators of the subject-associated segmentation images.
-
-        Returns:
-            Tuple[Optional[Rater], ...]: The annotators of the segmentation images.
-        """
-        raters = [seg.get_annotator() for seg in self.segmentation_images]
-        return tuple(raters)
-
-    def add_image(self, image: Union[IntensityImage, SegmentationImage], force: bool = False) -> None:
-        """Add an image to the subject.
-
-        Args:
-            image (Union[IntensityImage, SegmentationImage]): The image to add to the subject.
-            force (bool): Indicates if addition should be performed even if a similar (same modality for intensity
-             images or same organ for segmentation images) image is already contained (default: False).
-
-        Raises:
-            ValueError: If an intensity image with similar modality is already contained or a segmentation image with
-             similar organ is already contained and ``force`` if False.
-
-        Returns:
-            None
-        """
-        images = self.get_images_by_type(type(image))
-
-        for image_ in images:
-            if image_ == image:
-                if force:
-                    warn(
-                        f"An image of type {type(image).__name__} with the same properties is already contained in "
-                        f"the subject. The image will be added anyway due to force=True."
-                    )
-                else:
-                    raise ValueError(
-                        f"An image of type {type(image).__name__} with the same properties is already "
-                        "contained in the subject. No image will be added!"
-                    )
-
-        images.append(image)
-
-    def add_images(self, images: Sequence[Union[IntensityImage, SegmentationImage]], force: bool = False) -> None:
-        """Add multiple images to the subject.
-
-        Args:
-            images (Sequence[Union[IntensityImage, SegmentationImage]]): The images to add to the subject.
-            force (bool): Indicates if addition should be performed even if a similar (same modality for intensity
-             images or same organ for segmentation images) image is already contained (default: False).
-
-        Returns:
-            None
-        """
-        for image in images:
-            self.add_image(image, force)
-
-    def get_images(self) -> List[Union[IntensityImage, SegmentationImage]]:
-        """Get all images of the subject.
-
-        Returns:
-            List[Union[IntensityImage, SegmentationImage]]: All images of the subject.
-        """
-        return [*self.intensity_images, *self.segmentation_images]
-
-    def get_image_by_modality(
-        self, modality: Union[Modality, str], return_first_on_multiple: bool = False
-    ) -> Optional[IntensityImage]:
-        """Get one intensity image by its modality.
-
-        Args:
-            modality (Union[Modality, str]): The modality of the image to retrieve.
-            return_first_on_multiple (bool): Indicates if the first found image should be returned if there are
-             multiple candidates, otherwise an error is raised on multiple candidates (default: False).
-
-        Returns:
-            Optional[IntensityImage]: The intensity image or None if there are multiple candidates.
-        """
-        if isinstance(modality, str):
-            modality = Modality(modality)
-
-        candidates = [img for img in self.intensity_images if img.get_modality() == modality]
-
-        return self._check_for_single_candidate(candidates, "modalities", return_first_on_multiple)
-
-    def get_image_by_organ(
-        self, organ: Union[Organ, str], return_first_on_multiple: bool = False
-    ) -> Optional[SegmentationImage]:
-        """Get one segmentation image by its organ.
-
-        Args:
-            organ (Union[Organ, str]): The organ of the image to retrieve.
-            return_first_on_multiple (bool): Indicates if the first found image should be returned if there are
-             multiple candidates, otherwise an error is raised on multiple candidates (default: False).
-
-        Returns:
-            Optional[SegmentationImage]: The segmentation image or None if there are multiple candidates.
-        """
-        if isinstance(organ, str):
-            organ = Organ(organ, None)
-
-        candidates = [img for img in self.segmentation_images if img.get_organ() == organ]
-
-        return self._check_for_single_candidate(candidates, "organs", return_first_on_multiple)
-
-    def get_images_by_annotator(self, annotator: Union[Annotator, str]) -> Optional[Tuple[SegmentationImage]]:
-        """Get one or multiple segmentation images by their annotator.
-
-        Args:
-            annotator (Union[Annotator, str]): The annotator of the image to retrieve.
-
-        Returns:
-            Optional[Union[SegmentationImage, Tuple[SegmentationImage]]]: The segmentation images or None if there is
-            no image with this annotator.
-        """
-        if isinstance(annotator, str):
-            annotator = Annotator(annotator)
-
-        candidates: List[SegmentationImage] = [
-            img for img in self.segmentation_images if img.get_annotator() == annotator
-        ]
-
-        if not candidates:
-            return None
-
-        return tuple(candidates)
-
-    def get_image_by_organ_and_annotator(
-        self, organ: Union[Organ, str], annotator: Union[Annotator, str], return_first_on_multiple: bool = False
-    ) -> Optional[SegmentationImage]:
-        """Get one segmentation image by its organ and annotator.
-
-        Args:
-            organ (Union[Organ, str]): The organ of the image to retrieve.
-            annotator (Union[Annotator, str]): The annotator of the image to retrieve.
-            return_first_on_multiple (bool): Indicates if the first found image should be returned if there are
-             multiple candidates, otherwise an error is raised on multiple candidates (default: False).
-
-        Returns:
-            Optional[SegmentationImage]: The segmentation image or :data:`None` if there are multiple candidates.
-        """
-        if isinstance(organ, str):
-            organ = Organ(organ, None)
-        if isinstance(annotator, str):
-            annotator = Annotator(annotator)
-
-        candidates = [
-            img for img in self.segmentation_images if img.get_organ() == organ and img.get_annotator() == annotator
-        ]
-
-        return self._check_for_single_candidate(candidates, "organs and annotators", return_first_on_multiple)
-
-    def get_images_by_type(self, image_type: type) -> List[Image]:
-        """Get all images of a specific type.
-
-        Args:
-            image_type: The type of the images to retrieve.
-
-        Returns:
-            List[Image]: A list of all images of the specified type.
-        """
-        if image_type == IntensityImage:
-            return self.intensity_images
-        elif image_type == SegmentationImage:
-            return self.segmentation_images
-        else:
-            raise ValueError("The given data type is not supported or not contained in the subject!")
-
-    def replace_image(
-        self,
-        new_image: Union[IntensityImage, SegmentationImage],
-        old_image: Optional[Union[IntensityImage, SegmentationImage]] = None,
-    ) -> bool:
-        """Replace an image in the subject either specified by an old image or by the properties of the new image.
-
-        The following properties are used to identify the image to be replaced:
-
-        - :class:`~pyradise.data.image.IntensityImage`: The :class:`~pyradise.data.modality.Modality` of the image.
-        - :class:`~pyradise.data.image.SegmentationImage`: The :class:`~pyradise.data.organ.Organ` and the
-          :class:`~pyradise.data.annotator.Rater` of the image.
-
-        Args:
-            new_image (Union[IntensityImage, SegmentationImage]): The new image which will be inserted into the subject.
-            old_image (Optional[Union[IntensityImage, SegmentationImage]]): The old image which will be replaced by the
-             new image. If None, the new image properties are used to find an image to replace (default: None).
-
-        Returns:
-            bool: True if the image is replaced successfully, False otherwise.
-        """
-
-        def _get_equal_entities(reference: Any, candidates: Sequence[Any]) -> Tuple[Any]:
-            candidates_ = [candidate for candidate in candidates if isinstance(candidate, type(reference))]
-
-            if not candidates_:
-                return tuple()
-
-            return tuple(candidate for candidate in candidates_ if candidate == reference)
-
-        image_sequence = self.get_images_by_type(type(new_image))
-
-        if old_image is None:
-            equal_images = _get_equal_entities(new_image, image_sequence)
-
-            if not equal_images:
-                return False
-
-            if len(equal_images) > 1:
-                warn(
-                    f"More than one image of type {type(new_image).__name__} with the same properties is present "
-                    "in the subject. Exclusively the first image found will be replaced!"
-                )
-
-            old_image_idx = image_sequence.index(equal_images[0])
-            image_sequence[old_image_idx] = new_image
-            return True
-
-        else:
-            if not isinstance(old_image, type(new_image)):
-                raise TypeError(
-                    "The new and old image must be of the same type "
-                    f"(new image: {type(new_image).__name__}, old image: {type(old_image).__name__})!"
-                )
-
-            try:
-                old_image_idx = image_sequence.index(old_image)
-            except ValueError:
-                warn(f"The old image is not contained in the subject. No replacement will be performed.")
-                return False
-
-            image_sequence[old_image_idx] = new_image
-            return True
-
-    def remove_image_by_modality(self, modality: Union[Modality, str]) -> bool:
-        """Remove one or multiple images as specified by the modality.
-
-        Args:
-            modality (Union[Modality, str]): The modality of all images to remove.
-
-        Returns:
-            bool: True when the removal procedure was successful otherwise False.
-        """
-        if isinstance(modality, str):
-            modality = Modality(modality)
-
-        candidates = [img for img in self.intensity_images if img.get_modality() == modality]
-
-        if not candidates:
-            return False
-
-        success = True
-        for candidate in candidates:
-            try:
-                self.intensity_images.remove(candidate)
-            except ValueError:
-                success = False
-
-        return success
-
-    def remove_image_by_organ(self, organ: Union[Organ, str]) -> bool:
-        """Remove one or multiple images as specified by the organ.
-
-        Args:
-            organ (Union[Organ, str]): The organ of all images to remove.
-
-        Returns:
-            bool: True when the removal procedure was successful otherwise False.
-        """
-        if isinstance(organ, str):
-            organ = Organ(organ, None)
-
-        candidates = [img for img in self.segmentation_images if img.get_organ() == organ]
-
-        if not candidates:
-            return False
-
-        success = True
-        for candidate in candidates:
-            try:
-                self.segmentation_images.remove(candidate)
-            except ValueError:
-                success = False
-
-        return success
-
-    def remove_image_by_annotator(self, annotator: Union[Annotator, str]) -> bool:
-        """Remove one or multiple images as specified by the annotator.
-
-        Args:
-            annotator (Union[Annotator, str]): The annotator of all images to remove.
-
-        Returns:
-            bool: True when the removal procedure was successful, otherwise False.
-        """
-        if isinstance(annotator, str):
-            annotator = Annotator(annotator)
-
-        candidates = [img for img in self.segmentation_images if img.get_annotator() == annotator]
-
-        if not candidates:
-            return False
-
-        success = True
-        for candidate in candidates:
-            try:
-                self.segmentation_images.remove(candidate)
-            except ValueError:
-                success = False
-
-        return success
-
-    def remove_image_by_organ_and_annotator(self, organ: Union[Organ, str], annotator: Union[Annotator, str]) -> bool:
-        """Remove one or multiple images as specified by the organ and annotator.
-
-        Args:
-            organ (Union[Organ, str]): The organ of all images to remove.
-            annotator (Union[Annotator, str]): The annotator of all images to remove.
-
-        Returns:
-            bool: True when the removal procedure was successful, otherwise False.
-        """
-        if isinstance(organ, str):
-            organ = Organ(organ, None)
-        if isinstance(annotator, str):
-            annotator = Annotator(annotator)
-
-        candidates = [
-            img for img in self.segmentation_images if img.get_organ() == organ and img.get_annotator() == annotator
-        ]
-
-        if not candidates:
-            return False
-
-        success = True
-        for candidate in candidates:
-            try:
-                self.segmentation_images.remove(candidate)
-            except ValueError:
-                success = False
-
-        return success
-
-    def remove_image(self, image: Union[IntensityImage, SegmentationImage]) -> bool:
-        """Remove a given image from the subject.
-
-        Args:
-            image (Union[IntensityImage, SegmentationImage]): The image to remove from the subject.
-
-        Returns:
-            bool: True when the removal procedure was successful otherwise False.
-        """
-        images = self.get_images_by_type(type(image))
-        candidates = [img for img in images if img == image]
-
-        if len(candidates) > 1:
-            warn(
-                f"The removal of the image is ambiguous because there are multiple ({len(candidates)}) "
-                "images which are equal. Only the first found image will be removed"
-            )
-
-        if not candidates:
-            return False
-
-        images.remove(candidates[0])
-        return True
-
-    def add_data(self, data: Dict[str, Any]) -> None:
-        """Add additional data to the subject.
-
-        Args:
-            data (Dict[str, Any]): The additional datas.
-
-        Returns:
-            None
-        """
-        self.data.update(data)
-
-    def add_data_by_key(self, key: str, data: Any) -> None:
-        """Add additional data by key to the subject.
-
-        Args:
-            key (str): The key of the additional data.
-            data (Any): The additional data.
-
-        Returns:
-            None
-        """
-        self.data[key] = data
-
-    def get_data(self) -> Dict[str, Any]:
-        """Get the additional data associated with the subject.
-
-        Returns:
-            Dict[str, Any]: The additional data associated with the subject.
-        """
-        return self.data
-
-    def get_data_by_key(self, key: str) -> Any:
-        """Get additional data by key or :data:`None` if the key is not existing.
-
-        Args:
-            key (str): The key of the specific additional data.
-
-        Returns:
-            Any: The data or :data:`None`.
-        """
-        return self.data.get(key, None)
-
-    def replace_data(self, key: str, new_data: Any, add_if_missing: bool = False) -> bool:
-        """Replace data by a new value.
-
-        Args:
-            key (str): The key of the additional data.
-            new_data (Any): The new additional data.
-            add_if_missing (bool): If True, the additional data will be added if the key is not existing
-             (default: False).
-
-        Returns:
-            bool: True if the additional data is replaced successfully, False otherwise.
-        """
-        if key not in self.data.keys() and not add_if_missing:
-            warn(f"The key {key} is not contained in the additional data. No replacement will be performed.")
-            return False
-
-        self.data[key] = new_data
-        return True
-
-    def remove_additional_data(self) -> None:
-        """Remove all additional data from the subject.
-
-        Returns:
-            None
-        """
-        self.data.clear()
-
-    def remove_additional_data_by_key(self, key: str) -> bool:
-        """Remove additional data by a key from the subject.
-
-        Args:
-            key (str): The key of the additional data.
-
-        Returns:
-            bool: True when the removal procedure was successful otherwise False.
-        """
-        return self.data.pop(key, None) is not None
-
-    def playback_transform_tapes(self) -> None:
-        """Playback the transform tapes.
-
-        Returns:
-            None
-        """
-        for image in self.get_images():
-            image.get_transform_tape().playback(image, subject=self)
-
-    def __str__(self) -> str:
-        return (
-            f"{self.name} (Intensity Images: {len(self.intensity_images)} / "
-            f"Segmentation Images: {len(self.segmentation_images)})"
-        )
+from collections import abc as col_abc
+from typing import Any, Dict, List, Optional, Sequence, Tuple, Union
+from warnings import warn
+
+from .annotator import Annotator
+from .image import Image, IntensityImage, SegmentationImage
+from .modality import Modality
+from .organ import Organ
+
+__all__ = ["Subject"]
+
+
+class Subject:
+    """The :class:`Subject` is the main data object which holds all :class:`~pyradise.data.image.IntensityImage` s and
+    :class:`~pyradise.data.image.SegmentationImage` s associated with the subject. Furthermore, it can hold any type
+    of additional data associated with the patient. Currently, the routines implemented in PyRaDiSe do not use this
+    mechanism so it can be used freely by the user.
+
+    Args:
+        name (str): The name of the subject.
+        images (Optional[Union[Image, Sequence[Image]]]): One or multiple images to add to the subject.
+        data (Optional[Dict[str, Any]]): Additional data which is associated with the subject.
+
+    Examples:
+        The following example demonstrates the manual construction of a :class:`Subject`:
+
+        >>> from argparse import ArgumentParser
+        >>> from typing import Tuple
+        >>> import os
+        >>>
+        >>> import SimpleITK as sitk
+        >>>
+        >>> from pyradise.data import (Subject, IntensityImage, SegmentationImage,
+        >>>                            Modality, Organ, Annotator)
+        >>> from pyradise.fileio import SubjectWriter, ImageFileFormat
+        >>>
+        >>>
+        >>> def get_segmentation_file_paths(path: str,
+        >>>                                 valid_organs: Tuple[Organ, ...]
+        >>>                                 ) -> Tuple[str]:
+        >>>     file_paths = []
+        >>>
+        >>>     for file in os.listdir(path):
+        >>>         if not file.endswith('.nii.gz'):
+        >>>             continue
+        >>>
+        >>>         if any(entry.name in file for entry in valid_organs):
+        >>>             file_paths.append(os.path.join(path, file))
+        >>>
+        >>>     return tuple(sorted(file_paths))
+        >>>
+        >>>
+        >>> def get_intensity_file_paths(path: str,
+        >>>                              valid_modalities: Tuple[Modality, ...]
+        >>>                              ) -> Tuple[str]:
+        >>>     file_paths = []
+        >>>
+        >>>     for file in os.listdir(path):
+        >>>         if not file.endswith('.nii.gz'):
+        >>>             continue
+        >>>
+        >>>         if any(entry.get_name() in file for entry in valid_modalities):
+        >>>             file_paths.append(os.path.join(path, file))
+        >>>
+        >>>     return tuple(sorted(file_paths))
+        >>>
+        >>>
+        >>> def main(input_dir: str,
+        >>>          output_dir: str
+        >>>          ) -> None:
+        >>>     # Retrieve image file paths
+        >>>     organs = (Organ('Brainstem'), Organ('Eyes'),
+        >>>               Organ('Hippocampi'), Organ('OpticNerves'))
+        >>>     modalities = (Modality('CT'), Modality('T1c'),
+        >>>                   Modality('T1w'), Modality('T2w'))
+        >>>
+        >>>     segmentation_file_paths = get_segmentation_file_paths(input_dir, organs)
+        >>>     intensity_file_paths = get_intensity_file_paths(input_dir, modalities)
+        >>>
+        >>>     # Load the segmentation image files
+        >>>     images = []
+        >>>     for path, organ in zip(segmentation_file_paths, organs):
+        >>>         image = SegmentationImage(sitk.ReadImage(path, sitk.sitkUInt8),
+        >>>                                   organ, Annotator.get_default())
+        >>>         images.append(image)
+        >>>
+        >>>     # Load the intensity image files
+        >>>     for path, modality in zip(intensity_file_paths, modalities):
+        >>>         image = IntensityImage(sitk.ReadImage(path, sitk.sitkFloat32),
+        >>>                                modality)
+        >>>         images.append(image)
+        >>>
+        >>>     # Construct the subject
+        >>>     subject = Subject(os.path.basename(input_dir), images)
+        >>>
+        >>>     # Display the subject name and properties of the intensity and
+        >>>     # segmentation images
+        >>>     print(f'Subject {subject.get_name()} contains the following images:')
+        >>>
+        >>>     for image in subject.intensity_images:
+        >>>         print(f'Intensity image of modality {image.get_modality(True)} '
+        >>>               f'with size: {image.get_size()}')
+        >>>
+        >>>     for image in subject.segmentation_images:
+        >>>         print(f'Segmentation image of {image.get_organ(True)} '
+        >>>               f'with size: {image.get_size()}')
+        >>>
+        >>>     # Write the subject to disk
+        >>>     SubjectWriter(ImageFileFormat.NRRD).write(output_dir, subject,
+        >>>                                               write_transforms=False)
+        >>>
+        >>>
+        >>> if __name__ == '__main__':
+        >>>     parser = ArgumentParser()
+        >>>     parser.add_argument('-input_dir', type=str)
+        >>>     parser.add_argument('-output_dir', type=str)
+        >>>     args = parser.parse_args()
+        >>>
+        >>>     main(args.input_dir, args.output_dir)
+        >>>
+        >>> # Output:
+        >>> # Subject subject_1 contains the following images:
+        >>> # Intensity image of modality CT with size: (256, 256, 256)
+        >>> # Intensity image of modality T1c with size: (256, 256, 256)
+        >>> # Intensity image of modality T1w with size: (256, 256, 256)
+        >>> # Intensity image of modality T2w with size: (256, 256, 256)
+        >>> # Segmentation image of Brainstem with size: (256, 256, 256)
+        >>> # Segmentation image of Eyes with size: (256, 256, 256)
+        >>> # Segmentation image of Hippocampi with size: (256, 256, 256)
+        >>> # Segmentation image of OpticNerves with size: (256, 256, 256)
+    """
+
+    def __init__(
+        self, name: str, images: Optional[Union[Image, Sequence[Image]]] = None, data: Optional[Dict[str, Any]] = None
+    ) -> None:
+        super().__init__()
+
+        self.name = name
+
+        self.intensity_images: List[IntensityImage] = []
+        self.segmentation_images: List[SegmentationImage] = []
+
+        if isinstance(images, IntensityImage):
+            self.intensity_images.append(images)
+
+        if isinstance(images, SegmentationImage):
+            self.segmentation_images.append(images)
+
+        if isinstance(images, col_abc.Sequence):
+            for image in images:
+                if isinstance(image, IntensityImage):
+                    self.intensity_images.append(image)
+                elif isinstance(image, SegmentationImage):
+                    self.segmentation_images.append(image)
+                else:
+                    raise ValueError(
+                        f"At least one image is not of type {IntensityImage.__class__.__name__} or"
+                        f"{SegmentationImage.__class__.__name__}!"
+                    )
+
+        # check validity of the additional data
+        if data is not None:
+            if not isinstance(data, dict):
+                raise TypeError(
+                    "Additional data must be of type dict with the key providing an identifier for " "data retrieval."
+                )
+            if not all(isinstance(key, str) for key in data.keys()):
+                raise TypeError(
+                    "Additional data keys must be of type str because they are used as an identifier for"
+                    "data retrieval.!"
+                )
+        else:
+            data = {}
+
+        self.data: Dict[str, Any] = data
+
+    @staticmethod
+    def _check_for_single_candidate(candidates: List[Any], entity_name: str, return_first_on_multiple: bool) -> Any:
+        if len(candidates) == 1:
+            return candidates[0]
+
+        if len(candidates) > 1:
+            if return_first_on_multiple:
+                warn(
+                    f"The search for {entity_name} is ambiguous because there are multiple ({len(candidates)}) "
+                    "candidates which are equal. The first found candidate will be returned."
+                )
+                return candidates[0]
+            else:
+                raise ValueError(f"There are multiple {entity_name} which fulfil the criterion ({len(candidates)})!")
+
+        return None
+
+    def get_name(self) -> str:
+        """Get the name of the subject.
+
+        Returns:
+            str: The name of the subject.
+        """
+        return self.name
+
+    def get_modalities(self) -> Tuple[Optional[Modality], ...]:
+        """Get the modalities of the subject-associated intensity images.
+
+        Returns:
+            Tuple[Optional[Modality], ...]: The modalities of the intensity images.
+        """
+        modalities = [img.get_modality() for img in self.intensity_images]
+        return tuple(modalities)
+
+    def get_organs(self) -> Tuple[Optional[Organ], ...]:
+        """Get the organs of the subject-associated segmentation images.
+
+        Returns:
+            Tuple[Optional[Organ], ...]: The organs of the segmentation images.
+        """
+        organs = [seg.get_organ() for seg in self.segmentation_images]
+        return tuple(organs)
+
+    def get_annotators(self) -> Tuple[Optional[Annotator], ...]:
+        """Get the annotators of the subject-associated segmentation images.
+
+        Returns:
+            Tuple[Optional[Rater], ...]: The annotators of the segmentation images.
+        """
+        raters = [seg.get_annotator() for seg in self.segmentation_images]
+        return tuple(raters)
+
+    def add_image(self, image: Union[IntensityImage, SegmentationImage], force: bool = False) -> None:
+        """Add an image to the subject.
+
+        Args:
+            image (Union[IntensityImage, SegmentationImage]): The image to add to the subject.
+            force (bool): Indicates if addition should be performed even if a similar (same modality for intensity
+             images or same organ for segmentation images) image is already contained (default: False).
+
+        Raises:
+            ValueError: If an intensity image with similar modality is already contained or a segmentation image with
+             similar organ is already contained and ``force`` if False.
+
+        Returns:
+            None
+        """
+        images = self.get_images_by_type(type(image))
+
+        for image_ in images:
+            if image_ == image:
+                if force:
+                    warn(
+                        f"An image of type {type(image).__name__} with the same properties is already contained in "
+                        f"the subject. The image will be added anyway due to force=True."
+                    )
+                else:
+                    raise ValueError(
+                        f"An image of type {type(image).__name__} with the same properties is already "
+                        "contained in the subject. No image will be added!"
+                    )
+
+        images.append(image)
+
+    def add_images(self, images: Sequence[Union[IntensityImage, SegmentationImage]], force: bool = False) -> None:
+        """Add multiple images to the subject.
+
+        Args:
+            images (Sequence[Union[IntensityImage, SegmentationImage]]): The images to add to the subject.
+            force (bool): Indicates if addition should be performed even if a similar (same modality for intensity
+             images or same organ for segmentation images) image is already contained (default: False).
+
+        Returns:
+            None
+        """
+        for image in images:
+            self.add_image(image, force)
+
+    def get_images(self) -> List[Union[IntensityImage, SegmentationImage]]:
+        """Get all images of the subject.
+
+        Returns:
+            List[Union[IntensityImage, SegmentationImage]]: All images of the subject.
+        """
+        return [*self.intensity_images, *self.segmentation_images]
+
+    def get_image_by_modality(
+        self, modality: Union[Modality, str], return_first_on_multiple: bool = False
+    ) -> Optional[IntensityImage]:
+        """Get one intensity image by its modality.
+
+        Args:
+            modality (Union[Modality, str]): The modality of the image to retrieve.
+            return_first_on_multiple (bool): Indicates if the first found image should be returned if there are
+             multiple candidates, otherwise an error is raised on multiple candidates (default: False).
+
+        Returns:
+            Optional[IntensityImage]: The intensity image or None if there are multiple candidates.
+        """
+        if isinstance(modality, str):
+            modality = Modality(modality)
+
+        candidates = [img for img in self.intensity_images if img.get_modality() == modality]
+
+        return self._check_for_single_candidate(candidates, "modalities", return_first_on_multiple)
+
+    def get_image_by_organ(
+        self, organ: Union[Organ, str], return_first_on_multiple: bool = False
+    ) -> Optional[SegmentationImage]:
+        """Get one segmentation image by its organ.
+
+        Args:
+            organ (Union[Organ, str]): The organ of the image to retrieve.
+            return_first_on_multiple (bool): Indicates if the first found image should be returned if there are
+             multiple candidates, otherwise an error is raised on multiple candidates (default: False).
+
+        Returns:
+            Optional[SegmentationImage]: The segmentation image or None if there are multiple candidates.
+        """
+        if isinstance(organ, str):
+            organ = Organ(organ, None)
+
+        candidates = [img for img in self.segmentation_images if img.get_organ() == organ]
+
+        return self._check_for_single_candidate(candidates, "organs", return_first_on_multiple)
+
+    def get_images_by_annotator(self, annotator: Union[Annotator, str]) -> Optional[Tuple[SegmentationImage]]:
+        """Get one or multiple segmentation images by their annotator.
+
+        Args:
+            annotator (Union[Annotator, str]): The annotator of the image to retrieve.
+
+        Returns:
+            Optional[Union[SegmentationImage, Tuple[SegmentationImage]]]: The segmentation images or None if there is
+            no image with this annotator.
+        """
+        if isinstance(annotator, str):
+            annotator = Annotator(annotator)
+
+        candidates: List[SegmentationImage] = [
+            img for img in self.segmentation_images if img.get_annotator() == annotator
+        ]
+
+        if not candidates:
+            return None
+
+        return tuple(candidates)
+
+    def get_image_by_organ_and_annotator(
+        self, organ: Union[Organ, str], annotator: Union[Annotator, str], return_first_on_multiple: bool = False
+    ) -> Optional[SegmentationImage]:
+        """Get one segmentation image by its organ and annotator.
+
+        Args:
+            organ (Union[Organ, str]): The organ of the image to retrieve.
+            annotator (Union[Annotator, str]): The annotator of the image to retrieve.
+            return_first_on_multiple (bool): Indicates if the first found image should be returned if there are
+             multiple candidates, otherwise an error is raised on multiple candidates (default: False).
+
+        Returns:
+            Optional[SegmentationImage]: The segmentation image or :data:`None` if there are multiple candidates.
+        """
+        if isinstance(organ, str):
+            organ = Organ(organ, None)
+        if isinstance(annotator, str):
+            annotator = Annotator(annotator)
+
+        candidates = [
+            img for img in self.segmentation_images if img.get_organ() == organ and img.get_annotator() == annotator
+        ]
+
+        return self._check_for_single_candidate(candidates, "organs and annotators", return_first_on_multiple)
+
+    def get_images_by_type(self, image_type: type) -> List[Image]:
+        """Get all images of a specific type.
+
+        Args:
+            image_type: The type of the images to retrieve.
+
+        Returns:
+            List[Image]: A list of all images of the specified type.
+        """
+        if image_type == IntensityImage:
+            return self.intensity_images
+        elif image_type == SegmentationImage:
+            return self.segmentation_images
+        else:
+            raise ValueError("The given data type is not supported or not contained in the subject!")
+
+    def replace_image(
+        self,
+        new_image: Union[IntensityImage, SegmentationImage],
+        old_image: Optional[Union[IntensityImage, SegmentationImage]] = None,
+    ) -> bool:
+        """Replace an image in the subject either specified by an old image or by the properties of the new image.
+
+        The following properties are used to identify the image to be replaced:
+
+        - :class:`~pyradise.data.image.IntensityImage`: The :class:`~pyradise.data.modality.Modality` of the image.
+        - :class:`~pyradise.data.image.SegmentationImage`: The :class:`~pyradise.data.organ.Organ` and the
+          :class:`~pyradise.data.annotator.Rater` of the image.
+
+        Args:
+            new_image (Union[IntensityImage, SegmentationImage]): The new image which will be inserted into the subject.
+            old_image (Optional[Union[IntensityImage, SegmentationImage]]): The old image which will be replaced by the
+             new image. If None, the new image properties are used to find an image to replace (default: None).
+
+        Returns:
+            bool: True if the image is replaced successfully, False otherwise.
+        """
+
+        def _get_equal_entities(reference: Any, candidates: Sequence[Any]) -> Tuple[Any]:
+            candidates_ = [candidate for candidate in candidates if isinstance(candidate, type(reference))]
+
+            if not candidates_:
+                return tuple()
+
+            return tuple(candidate for candidate in candidates_ if candidate == reference)
+
+        image_sequence = self.get_images_by_type(type(new_image))
+
+        if old_image is None:
+            equal_images = _get_equal_entities(new_image, image_sequence)
+
+            if not equal_images:
+                return False
+
+            if len(equal_images) > 1:
+                warn(
+                    f"More than one image of type {type(new_image).__name__} with the same properties is present "
+                    "in the subject. Exclusively the first image found will be replaced!"
+                )
+
+            old_image_idx = image_sequence.index(equal_images[0])
+            image_sequence[old_image_idx] = new_image
+            return True
+
+        else:
+            if not isinstance(old_image, type(new_image)):
+                raise TypeError(
+                    "The new and old image must be of the same type "
+                    f"(new image: {type(new_image).__name__}, old image: {type(old_image).__name__})!"
+                )
+
+            try:
+                old_image_idx = image_sequence.index(old_image)
+            except ValueError:
+                warn(f"The old image is not contained in the subject. No replacement will be performed.")
+                return False
+
+            image_sequence[old_image_idx] = new_image
+            return True
+
+    def remove_image_by_modality(self, modality: Union[Modality, str]) -> bool:
+        """Remove one or multiple images as specified by the modality.
+
+        Args:
+            modality (Union[Modality, str]): The modality of all images to remove.
+
+        Returns:
+            bool: True when the removal procedure was successful otherwise False.
+        """
+        if isinstance(modality, str):
+            modality = Modality(modality)
+
+        candidates = [img for img in self.intensity_images if img.get_modality() == modality]
+
+        if not candidates:
+            return False
+
+        success = True
+        for candidate in candidates:
+            try:
+                self.intensity_images.remove(candidate)
+            except ValueError:
+                success = False
+
+        return success
+
+    def remove_image_by_organ(self, organ: Union[Organ, str]) -> bool:
+        """Remove one or multiple images as specified by the organ.
+
+        Args:
+            organ (Union[Organ, str]): The organ of all images to remove.
+
+        Returns:
+            bool: True when the removal procedure was successful otherwise False.
+        """
+        if isinstance(organ, str):
+            organ = Organ(organ, None)
+
+        candidates = [img for img in self.segmentation_images if img.get_organ() == organ]
+
+        if not candidates:
+            return False
+
+        success = True
+        for candidate in candidates:
+            try:
+                self.segmentation_images.remove(candidate)
+            except ValueError:
+                success = False
+
+        return success
+
+    def remove_image_by_annotator(self, annotator: Union[Annotator, str]) -> bool:
+        """Remove one or multiple images as specified by the annotator.
+
+        Args:
+            annotator (Union[Annotator, str]): The annotator of all images to remove.
+
+        Returns:
+            bool: True when the removal procedure was successful, otherwise False.
+        """
+        if isinstance(annotator, str):
+            annotator = Annotator(annotator)
+
+        candidates = [img for img in self.segmentation_images if img.get_annotator() == annotator]
+
+        if not candidates:
+            return False
+
+        success = True
+        for candidate in candidates:
+            try:
+                self.segmentation_images.remove(candidate)
+            except ValueError:
+                success = False
+
+        return success
+
+    def remove_image_by_organ_and_annotator(self, organ: Union[Organ, str], annotator: Union[Annotator, str]) -> bool:
+        """Remove one or multiple images as specified by the organ and annotator.
+
+        Args:
+            organ (Union[Organ, str]): The organ of all images to remove.
+            annotator (Union[Annotator, str]): The annotator of all images to remove.
+
+        Returns:
+            bool: True when the removal procedure was successful, otherwise False.
+        """
+        if isinstance(organ, str):
+            organ = Organ(organ, None)
+        if isinstance(annotator, str):
+            annotator = Annotator(annotator)
+
+        candidates = [
+            img for img in self.segmentation_images if img.get_organ() == organ and img.get_annotator() == annotator
+        ]
+
+        if not candidates:
+            return False
+
+        success = True
+        for candidate in candidates:
+            try:
+                self.segmentation_images.remove(candidate)
+            except ValueError:
+                success = False
+
+        return success
+
+    def remove_image(self, image: Union[IntensityImage, SegmentationImage]) -> bool:
+        """Remove a given image from the subject.
+
+        Args:
+            image (Union[IntensityImage, SegmentationImage]): The image to remove from the subject.
+
+        Returns:
+            bool: True when the removal procedure was successful otherwise False.
+        """
+        images = self.get_images_by_type(type(image))
+        candidates = [img for img in images if img == image]
+
+        if len(candidates) > 1:
+            warn(
+                f"The removal of the image is ambiguous because there are multiple ({len(candidates)}) "
+                "images which are equal. Only the first found image will be removed"
+            )
+
+        if not candidates:
+            return False
+
+        images.remove(candidates[0])
+        return True
+
+    def add_data(self, data: Dict[str, Any]) -> None:
+        """Add additional data to the subject.
+
+        Args:
+            data (Dict[str, Any]): The additional datas.
+
+        Returns:
+            None
+        """
+        self.data.update(data)
+
+    def add_data_by_key(self, key: str, data: Any) -> None:
+        """Add additional data by key to the subject.
+
+        Args:
+            key (str): The key of the additional data.
+            data (Any): The additional data.
+
+        Returns:
+            None
+        """
+        self.data[key] = data
+
+    def get_data(self) -> Dict[str, Any]:
+        """Get the additional data associated with the subject.
+
+        Returns:
+            Dict[str, Any]: The additional data associated with the subject.
+        """
+        return self.data
+
+    def get_data_by_key(self, key: str) -> Any:
+        """Get additional data by key or :data:`None` if the key is not existing.
+
+        Args:
+            key (str): The key of the specific additional data.
+
+        Returns:
+            Any: The data or :data:`None`.
+        """
+        return self.data.get(key, None)
+
+    def replace_data(self, key: str, new_data: Any, add_if_missing: bool = False) -> bool:
+        """Replace data by a new value.
+
+        Args:
+            key (str): The key of the additional data.
+            new_data (Any): The new additional data.
+            add_if_missing (bool): If True, the additional data will be added if the key is not existing
+             (default: False).
+
+        Returns:
+            bool: True if the additional data is replaced successfully, False otherwise.
+        """
+        if key not in self.data.keys() and not add_if_missing:
+            warn(f"The key {key} is not contained in the additional data. No replacement will be performed.")
+            return False
+
+        self.data[key] = new_data
+        return True
+
+    def remove_additional_data(self) -> None:
+        """Remove all additional data from the subject.
+
+        Returns:
+            None
+        """
+        self.data.clear()
+
+    def remove_additional_data_by_key(self, key: str) -> bool:
+        """Remove additional data by a key from the subject.
+
+        Args:
+            key (str): The key of the additional data.
+
+        Returns:
+            bool: True when the removal procedure was successful otherwise False.
+        """
+        return self.data.pop(key, None) is not None
+
+    def playback_transform_tapes(self) -> None:
+        """Playback the transform tapes.
+
+        Returns:
+            None
+        """
+        for image in self.get_images():
+            image.get_transform_tape().playback(image, subject=self)
+
+    def __str__(self) -> str:
+        return (
+            f"{self.name} (Intensity Images: {len(self.intensity_images)} / "
+            f"Segmentation Images: {len(self.segmentation_images)})"
+        )
```

### Comparing `pyradise-0.2.2/pyradise/data/taping.py` & `pyradise-0.2.3/pyradise/data/taping.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,302 +1,302 @@
-from abc import ABC, abstractmethod
-from typing import Any, Dict, Optional, Tuple, TypeVar
-
-import numpy as np
-import SimpleITK as sitk
-
-__all__ = ["Tape", "TransformTape", "TransformInfo"]
-
-# pylint: disable=no-member
-
-# Forward declaration of image types
-Image = TypeVar("Image")
-IntensityImage = TypeVar("IntensityImage")
-SegmentationImage = TypeVar("SegmentationImage")
-Filter = TypeVar("Filter")
-FilterParameters = TypeVar("FilterParameters")
-ImageProperties = TypeVar("ImageProperties")
-Subject = TypeVar("Subject")
-
-
-class Tape(ABC):
-    """An abstract class for a tape which records defined elements and can replay them upon request."""
-
-    def __init__(self) -> None:
-        super().__init__()
-        self.recordings = []
-
-    @abstractmethod
-    def record(self, value: Any) -> None:
-        """Record a value on the :class:`Tape`.
-
-        Args:
-            value (Any): The value to be recorded.
-
-        Returns:
-            None
-        """
-        raise NotImplementedError()
-
-    @staticmethod
-    @abstractmethod
-    def playback(data: Any, **kwargs) -> Any:
-        """Playback the recorded elements of the :class:`Tape` on the data object.
-
-        Args:
-            data (Any): The data on which the playback should take place. This object need to contain also the tape.
-            **kwargs: Additional keyword arguments.
-
-        Returns:
-            Any: The back played data.
-        """
-        raise NotImplementedError()
-
-    def get_recorded_elements(self, reverse: bool = False) -> Tuple[Any, ...]:
-        """Get the recorded elements on the :class:`Tape`.
-
-        Args:
-            reverse (bool): Indicates if the recordings should be returned in reverse order.
-
-        Returns:
-            Tuple[Any, ...]: The recorded elements of the :class:`Tape`.
-        """
-        if reverse:
-            return tuple(reversed(self.recordings))
-
-        return tuple(self.recordings)
-
-    def reset(self) -> None:
-        """Reset the :class:`Tape`.
-
-        Returns:
-            None
-        """
-        self.recordings = []
-
-
-class TransformInfo:
-    """A class to store information about a data transformation performed via a :class:`~pyradise.process.base.Filter`.
-    This class is used in combination with a :class:`~pyradise.data.taping.TransformTape` instance to keep track
-    of data transformations and to render invertibility feasible for invertible filters operations.
-
-    Args:
-        name (str): The name of the filter which performed the data transformation.
-        params (Optional[FilterParameters]): The filter parameters which parameterize the data transformation.
-        pre_transform_image_properties (ImageProperties): The image properties before the data transformation.
-        post_transform_image_properties (ImageProperties): The image properties after the data transformation.
-        filter_args (Optional[Dict[str, Any]]): The filter arguments passed via the constructor of the filter
-         (default: None).
-        additional_data (Optional[Dict[str, Any]]): Additional data which is required the data transformation or to
-         inverse it (default: None).
-        transform (Optional[sitk.Transform]): A SimpleITK transform which may be used for the data transformation
-         (default: None).
-    """
-
-    def __init__(
-        self,
-        name: str,
-        params: Optional[FilterParameters],
-        pre_transform_image_properties: ImageProperties,
-        post_transform_image_properties: ImageProperties,
-        filter_args: Optional[Dict[str, Any]] = None,
-        additional_data: Optional[Dict[str, Any]] = None,
-        transform: Optional[sitk.Transform] = None,
-    ) -> None:
-        super().__init__()
-
-        self.name = name
-        self.params = params
-        self.pre_transform_image_properties: ImageProperties = pre_transform_image_properties
-        self.post_transform_image_properties: ImageProperties = post_transform_image_properties
-        self.filter_args: Dict[str, Any] = filter_args if filter_args is not None else dict()
-        self.additional_data: Dict[str, Any] = additional_data if additional_data is not None else dict()
-        self.transform: Optional[sitk.Transform] = transform
-
-    def _get_subclasses(self, cls: type) -> Dict[str, type]:
-        """Get all subclasses of the provided class.
-
-        Args:
-            cls (type): The class to get the subclasses of.
-
-        Returns:
-            Dict[str, type]: A dictionary containing the subclasses of the provided class.
-        """
-        subclasses = {}
-        for subclass in cls.__subclasses__():
-            subclasses.update({subclass.__name__: subclass})
-            if subclass.__subclasses__():
-                subclasses.update(self._get_subclasses(subclass))
-        return subclasses
-
-    def get_filter(self) -> Filter:
-        """Get the :class:`~pyradise.process.base.Filter` instance which performed the data transformation.
-
-        Returns:
-            Filter: The filter used for the data transformation.
-        """
-        from pyradise.process import Filter
-
-        subclasses = self._get_subclasses(Filter)
-        return subclasses.get(self.name)(**self.filter_args)
-
-    def get_params(self) -> FilterParameters:
-        """Get the :class:`~pyradise.process.base.FilterParams` instance which was used to parameterize the
-        data transformation.
-
-        Returns:
-            FilterParameters: The filter parameters used for the data transformation.
-        """
-        return self.params
-
-    def get_image_properties(self, pre_transform: bool) -> ImageProperties:
-        """Get the pre-transform or post-transform :class:`~pyradise.data.image.ImageProperties` instance.
-
-        Args:
-            pre_transform (bool): If True returns the pre-transform image properties, otherwise the post-transform
-             image properties.
-
-        Returns:
-            ImageProperties: The pre-transform or post-transform image properties.
-        """
-        if pre_transform:
-            return self.pre_transform_image_properties
-        return self.post_transform_image_properties
-
-    def add_data(self, key: str, value: Any) -> None:
-        """Add additional data to the :class:`TransformInfo` instance.
-
-        Note:
-            If the provided key already exists, the value will be overwritten.
-
-        Args:
-            key (str): The key of the additional data.
-            value (Any): The value of the additional data.
-
-        Returns:
-            None
-        """
-        self.additional_data[key] = value
-
-    def get_data(self, key: str) -> Any:
-        """Get additional data from the :class:`TransformInfo` instance by key.
-
-        Args:
-            key (str): The key of the additional data entry to get.
-
-        Returns:
-            Any: The value of the additional data entry. If the key is not existing :data:`None` is returned.
-        """
-        return self.additional_data.get(key, None)
-
-    def get_transform(self, inverse: bool = False) -> sitk.Transform:
-        """Get the :class:`SimpleITK.Transform` instance which was used to perform the data transformation.
-
-        Args:
-            inverse (bool): Indicates if the inverse transform should be returned (default: False).
-
-        Returns:
-            sitk.Transform: The transform used for the data transformation or the identity transform if origin and
-            direction did not change during data transformation.
-        """
-        if self.transform is not None:
-            if inverse:
-                return self.transform.GetInverse()
-            return self.transform
-
-        # check if the image origin and direction have changed
-        num_dims = len(self.pre_transform_image_properties.size)
-        if self.pre_transform_image_properties.has_equal_origin_direction(self.post_transform_image_properties):
-            transform = sitk.AffineTransform(num_dims)
-            transform.SetIdentity()
-            return transform
-
-        else:
-            transform = sitk.AffineTransform(num_dims)
-            transform.SetIdentity()
-
-            # compute the translation
-            post_origin = self.post_transform_image_properties.origin
-            pre_origin = self.pre_transform_image_properties.origin
-            translation = list(np.array(post_origin) - np.array(pre_origin))
-
-            # compute the rotation
-            post_direction = np.array(self.post_transform_image_properties.direction).reshape(num_dims, num_dims)
-            pre_direction = np.array(self.pre_transform_image_properties.direction).reshape(num_dims, num_dims)
-            rotation = np.matmul(np.linalg.inv(pre_direction), post_direction)
-            rotation = list(rotation.reshape(-1))
-
-            # set the transform parameters
-            transform.SetParameters(rotation + translation)
-
-            # return the inverted or the original transform
-            if inverse:
-                transform = transform.GetInverse()
-            return transform
-
-
-class TransformTape(Tape):
-    """A class to keep track of the :class:`~pyradise.data.taping.TransformInfo` instances such that they can be
-    played back on appropriate data. This class provides the basic functionality to render invertibility and
-    reproducibility feasible.
-    """
-
-    def __init__(self):
-        super().__init__()
-
-    def record(self, value: TransformInfo) -> None:
-        """Record a :class:`~pyradise.data.taping.TransformInfo` instance on the tape.
-
-        Args:
-            value (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance to record.
-
-        Returns:
-            None
-        """
-        self.recordings.append(value)
-
-    def get_recorded_elements(self, reverse: bool = False) -> Tuple[TransformInfo, ...]:
-        """Get the recorded :class:`~pyradise.data.taping.TransformInfo` instances.
-
-        Args:
-            reverse (bool): Indicates if the recorded elements should be returned in reverse order (default: False).
-
-        Returns:
-            Tuple[TransformInfo, ...]: The recorded :class:`~pyradise.data.taping.TransformInfo` instances.
-        """
-        return super().get_recorded_elements(reverse)
-
-    @staticmethod
-    def playback(data: Image, **kwargs) -> Image:
-        """Play back the recorded :class:`~pyradise.data.taping.TransformInfo` instances on the provided data.
-
-        Args:
-            data (Image): The data to play back the recorded :class:`~pyradise.data.taping.TransformInfo` instances on.
-            **kwargs: Additional keyword arguments.
-
-        Returns:
-            Image: The :class:`~pyradise.data.image.Image` instance after the playback of the recorded
-            :class:`~pyradise.data.taping.TransformInfo` instances.
-
-        """
-        from pyradise.data import Subject
-
-        # create a temporary subject to store the image
-        subject = Subject("temporary_playback_subject", data)
-
-        # playback the transformations
-        for transform_info in data.get_transform_tape().get_recorded_elements(reverse=True):
-            filter_ = transform_info.get_filter()
-
-            if not filter_.is_invertible():
-                continue
-
-            subject = filter_.execute_inverse(subject, transform_info)
-
-        # set the new image data on the original image
-        image = subject.get_images_by_type(type(data))[0]
-        data.set_image_data(image.get_image_data())
-
-        # clear the recordings after playback
-        data.get_transform_tape().recordings.clear()
-
-        return data
+from abc import ABC, abstractmethod
+from typing import Any, Dict, Optional, Tuple, TypeVar
+
+import numpy as np
+import SimpleITK as sitk
+
+__all__ = ["Tape", "TransformTape", "TransformInfo"]
+
+# pylint: disable=no-member
+
+# Forward declaration of image types
+Image = TypeVar("Image")
+IntensityImage = TypeVar("IntensityImage")
+SegmentationImage = TypeVar("SegmentationImage")
+Filter = TypeVar("Filter")
+FilterParameters = TypeVar("FilterParameters")
+ImageProperties = TypeVar("ImageProperties")
+Subject = TypeVar("Subject")
+
+
+class Tape(ABC):
+    """An abstract class for a tape which records defined elements and can replay them upon request."""
+
+    def __init__(self) -> None:
+        super().__init__()
+        self.recordings = []
+
+    @abstractmethod
+    def record(self, value: Any) -> None:
+        """Record a value on the :class:`Tape`.
+
+        Args:
+            value (Any): The value to be recorded.
+
+        Returns:
+            None
+        """
+        raise NotImplementedError()
+
+    @staticmethod
+    @abstractmethod
+    def playback(data: Any, **kwargs) -> Any:
+        """Playback the recorded elements of the :class:`Tape` on the data object.
+
+        Args:
+            data (Any): The data on which the playback should take place. This object need to contain also the tape.
+            **kwargs: Additional keyword arguments.
+
+        Returns:
+            Any: The back played data.
+        """
+        raise NotImplementedError()
+
+    def get_recorded_elements(self, reverse: bool = False) -> Tuple[Any, ...]:
+        """Get the recorded elements on the :class:`Tape`.
+
+        Args:
+            reverse (bool): Indicates if the recordings should be returned in reverse order.
+
+        Returns:
+            Tuple[Any, ...]: The recorded elements of the :class:`Tape`.
+        """
+        if reverse:
+            return tuple(reversed(self.recordings))
+
+        return tuple(self.recordings)
+
+    def reset(self) -> None:
+        """Reset the :class:`Tape`.
+
+        Returns:
+            None
+        """
+        self.recordings = []
+
+
+class TransformInfo:
+    """A class to store information about a data transformation performed via a :class:`~pyradise.process.base.Filter`.
+    This class is used in combination with a :class:`~pyradise.data.taping.TransformTape` instance to keep track
+    of data transformations and to render invertibility feasible for invertible filters operations.
+
+    Args:
+        name (str): The name of the filter which performed the data transformation.
+        params (Optional[FilterParameters]): The filter parameters which parameterize the data transformation.
+        pre_transform_image_properties (ImageProperties): The image properties before the data transformation.
+        post_transform_image_properties (ImageProperties): The image properties after the data transformation.
+        filter_args (Optional[Dict[str, Any]]): The filter arguments passed via the constructor of the filter
+         (default: None).
+        additional_data (Optional[Dict[str, Any]]): Additional data which is required the data transformation or to
+         inverse it (default: None).
+        transform (Optional[sitk.Transform]): A SimpleITK transform which may be used for the data transformation
+         (default: None).
+    """
+
+    def __init__(
+        self,
+        name: str,
+        params: Optional[FilterParameters],
+        pre_transform_image_properties: ImageProperties,
+        post_transform_image_properties: ImageProperties,
+        filter_args: Optional[Dict[str, Any]] = None,
+        additional_data: Optional[Dict[str, Any]] = None,
+        transform: Optional[sitk.Transform] = None,
+    ) -> None:
+        super().__init__()
+
+        self.name = name
+        self.params = params
+        self.pre_transform_image_properties: ImageProperties = pre_transform_image_properties
+        self.post_transform_image_properties: ImageProperties = post_transform_image_properties
+        self.filter_args: Dict[str, Any] = filter_args if filter_args is not None else dict()
+        self.additional_data: Dict[str, Any] = additional_data if additional_data is not None else dict()
+        self.transform: Optional[sitk.Transform] = transform
+
+    def _get_subclasses(self, cls: type) -> Dict[str, type]:
+        """Get all subclasses of the provided class.
+
+        Args:
+            cls (type): The class to get the subclasses of.
+
+        Returns:
+            Dict[str, type]: A dictionary containing the subclasses of the provided class.
+        """
+        subclasses = {}
+        for subclass in cls.__subclasses__():
+            subclasses.update({subclass.__name__: subclass})
+            if subclass.__subclasses__():
+                subclasses.update(self._get_subclasses(subclass))
+        return subclasses
+
+    def get_filter(self) -> Filter:
+        """Get the :class:`~pyradise.process.base.Filter` instance which performed the data transformation.
+
+        Returns:
+            Filter: The filter used for the data transformation.
+        """
+        from pyradise.process import Filter
+
+        subclasses = self._get_subclasses(Filter)
+        return subclasses.get(self.name)(**self.filter_args)
+
+    def get_params(self) -> FilterParameters:
+        """Get the :class:`~pyradise.process.base.FilterParams` instance which was used to parameterize the
+        data transformation.
+
+        Returns:
+            FilterParameters: The filter parameters used for the data transformation.
+        """
+        return self.params
+
+    def get_image_properties(self, pre_transform: bool) -> ImageProperties:
+        """Get the pre-transform or post-transform :class:`~pyradise.data.image.ImageProperties` instance.
+
+        Args:
+            pre_transform (bool): If True returns the pre-transform image properties, otherwise the post-transform
+             image properties.
+
+        Returns:
+            ImageProperties: The pre-transform or post-transform image properties.
+        """
+        if pre_transform:
+            return self.pre_transform_image_properties
+        return self.post_transform_image_properties
+
+    def add_data(self, key: str, value: Any) -> None:
+        """Add additional data to the :class:`TransformInfo` instance.
+
+        Note:
+            If the provided key already exists, the value will be overwritten.
+
+        Args:
+            key (str): The key of the additional data.
+            value (Any): The value of the additional data.
+
+        Returns:
+            None
+        """
+        self.additional_data[key] = value
+
+    def get_data(self, key: str) -> Any:
+        """Get additional data from the :class:`TransformInfo` instance by key.
+
+        Args:
+            key (str): The key of the additional data entry to get.
+
+        Returns:
+            Any: The value of the additional data entry. If the key is not existing :data:`None` is returned.
+        """
+        return self.additional_data.get(key, None)
+
+    def get_transform(self, inverse: bool = False) -> sitk.Transform:
+        """Get the :class:`SimpleITK.Transform` instance which was used to perform the data transformation.
+
+        Args:
+            inverse (bool): Indicates if the inverse transform should be returned (default: False).
+
+        Returns:
+            sitk.Transform: The transform used for the data transformation or the identity transform if origin and
+            direction did not change during data transformation.
+        """
+        if self.transform is not None:
+            if inverse:
+                return self.transform.GetInverse()
+            return self.transform
+
+        # check if the image origin and direction have changed
+        num_dims = len(self.pre_transform_image_properties.size)
+        if self.pre_transform_image_properties.has_equal_origin_direction(self.post_transform_image_properties):
+            transform = sitk.AffineTransform(num_dims)
+            transform.SetIdentity()
+            return transform
+
+        else:
+            transform = sitk.AffineTransform(num_dims)
+            transform.SetIdentity()
+
+            # compute the translation
+            post_origin = self.post_transform_image_properties.origin
+            pre_origin = self.pre_transform_image_properties.origin
+            translation = list(np.array(post_origin) - np.array(pre_origin))
+
+            # compute the rotation
+            post_direction = np.array(self.post_transform_image_properties.direction).reshape(num_dims, num_dims)
+            pre_direction = np.array(self.pre_transform_image_properties.direction).reshape(num_dims, num_dims)
+            rotation = np.matmul(np.linalg.inv(pre_direction), post_direction)
+            rotation = list(rotation.reshape(-1))
+
+            # set the transform parameters
+            transform.SetParameters(rotation + translation)
+
+            # return the inverted or the original transform
+            if inverse:
+                transform = transform.GetInverse()
+            return transform
+
+
+class TransformTape(Tape):
+    """A class to keep track of the :class:`~pyradise.data.taping.TransformInfo` instances such that they can be
+    played back on appropriate data. This class provides the basic functionality to render invertibility and
+    reproducibility feasible.
+    """
+
+    def __init__(self):
+        super().__init__()
+
+    def record(self, value: TransformInfo) -> None:
+        """Record a :class:`~pyradise.data.taping.TransformInfo` instance on the tape.
+
+        Args:
+            value (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance to record.
+
+        Returns:
+            None
+        """
+        self.recordings.append(value)
+
+    def get_recorded_elements(self, reverse: bool = False) -> Tuple[TransformInfo, ...]:
+        """Get the recorded :class:`~pyradise.data.taping.TransformInfo` instances.
+
+        Args:
+            reverse (bool): Indicates if the recorded elements should be returned in reverse order (default: False).
+
+        Returns:
+            Tuple[TransformInfo, ...]: The recorded :class:`~pyradise.data.taping.TransformInfo` instances.
+        """
+        return super().get_recorded_elements(reverse)
+
+    @staticmethod
+    def playback(data: Image, **kwargs) -> Image:
+        """Play back the recorded :class:`~pyradise.data.taping.TransformInfo` instances on the provided data.
+
+        Args:
+            data (Image): The data to play back the recorded :class:`~pyradise.data.taping.TransformInfo` instances on.
+            **kwargs: Additional keyword arguments.
+
+        Returns:
+            Image: The :class:`~pyradise.data.image.Image` instance after the playback of the recorded
+            :class:`~pyradise.data.taping.TransformInfo` instances.
+
+        """
+        from pyradise.data import Subject
+
+        # create a temporary subject to store the image
+        subject = Subject("temporary_playback_subject", data)
+
+        # playback the transformations
+        for transform_info in data.get_transform_tape().get_recorded_elements(reverse=True):
+            filter_ = transform_info.get_filter()
+
+            if not filter_.is_invertible():
+                continue
+
+            subject = filter_.execute_inverse(subject, transform_info)
+
+        # set the new image data on the original image
+        image = subject.get_images_by_type(type(data))[0]
+        data.set_image_data(image.get_image_data())
+
+        # clear the recordings after playback
+        data.get_transform_tape().recordings.clear()
+
+        return data
```

### Comparing `pyradise-0.2.2/pyradise/data/utils.py` & `pyradise-0.2.3/pyradise/data/utils.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,143 +1,143 @@
-from typing import Optional, Sequence, Tuple, Union
-
-from .annotator import Annotator
-from .modality import Modality
-from .organ import Organ, OrganAnnotatorCombination
-
-__all__ = [
-    "str_to_modality",
-    "seq_to_modalities",
-    "str_to_organ",
-    "seq_to_organs",
-    "str_to_annotator",
-    "seq_to_annotators",
-    "str_to_organ_annotator_combination",
-    "seq_to_organ_annotator_combinations",
-]
-
-
-def str_to_modality(text: Union[str, Modality]) -> Modality:
-    """Converts a string to a :class:`~pyradise.data.modality.Modality` instance.
-
-    Args:
-        text (Union[str, Modality]): A string or a :class:`~pyradise.data.modality.Modality` instance.
-
-    Returns:
-        Modality: A :class:`~pyradise.data.modality.Modality` instance.
-    """
-    if isinstance(text, Modality):
-        return text
-
-    return Modality(text)
-
-
-def seq_to_modalities(seq: Sequence[Union[str, Modality]]) -> Tuple[Modality, ...]:
-    """Converts a sequence of strings to a tuple of :class:`~pyradise.data.modality.Modality` instances.
-
-    Args:
-        seq (Sequence[Union[str, Modality]]): A sequence of strings or :class:`~pyradise.data.modality.Modality`
-         instances.
-
-    Returns:
-        Tuple[Modality, ...]: A tuple of :class:`~pyradise.data.modality.Modality` instances.
-    """
-    return tuple(str_to_modality(text) for text in seq)
-
-
-def str_to_organ(name: Union[str, Organ]) -> Organ:
-    """Converts a string to a :class:`~pyradise.data.organ.Organ` instance.
-
-    Args:
-        name (Union[str, Organ]): A string or a :class:`~pyradise.data.organ.Organ` instance.
-
-    Returns:
-        Organ: A :class:`~pyradise.data.organ.Organ` instance.
-    """
-    if isinstance(name, Organ):
-        return name
-
-    return Organ(name)
-
-
-def seq_to_organs(seq: Sequence[Union[str, Organ]]) -> Tuple[Organ, ...]:
-    """Converts a sequence of strings to a tuple of :class:`~pyradise.data.organ.Organ` instances.
-
-    Args:
-        seq (Sequence[Union[str, Organ]]): A sequence of strings or :class:`~pyradise.data.organ.Organ` instances.
-
-    Returns:
-        Tuple[Organ, ...]: A tuple of :class:`~pyradise.data.organ.Organ` instances.
-    """
-    return tuple(str_to_organ(text) for text in seq)
-
-
-def str_to_annotator(name: Union[str, Annotator]) -> Annotator:
-    """Converts a string to a :class:`~pyradise.data.annotator.Annotator` instance.
-
-    Args:
-        name (Union[str, Annotator]): A string or a :class:`~pyradise.data.annotator.Annotator` instance.
-
-    Returns:
-        Annotator: A :class:`~pyradise.data.annotator.Annotator` instance.
-    """
-    if isinstance(name, Annotator):
-        return name
-
-    return Annotator(name)
-
-
-def seq_to_annotators(seq: Sequence[Union[str, Annotator]]) -> Tuple[Annotator, ...]:
-    """Converts a sequence of strings to a tuple of :class:`~pyradise.data.annotator.Annotator` instances.
-
-    Args:
-        seq (Sequence[Union[str, Annotator]]): A sequence of strings or :class:`~pyradise.data.annotator.Annotator`
-         instances.
-
-    Returns:
-        Tuple[Annotator, ...]: A tuple of :class:`~pyradise.data.annotator.Annotator` instances.
-    """
-    return tuple(str_to_annotator(text) for text in seq)
-
-
-def str_to_organ_annotator_combination(
-    data_or_organ_name: Union[str, Tuple[str, str], OrganAnnotatorCombination], annotator_name: Optional[str] = None
-) -> OrganAnnotatorCombination:
-    """Converts a string to a :class:`~pyradise.data.organ.OrganAnnotatorCombination` instance.
-
-    Args:
-        data_or_organ_name (Union[str, Tuple[str, str], OrganAnnotatorCombination]): A string for the organ name, a
-         tuple of two strings for the organ name and the annotator name, or a
-         :class:`~pyradise.data.organ.OrganAnnotatorCombination` instance.
-        annotator_name (Optional[str], optional): A string for the annotator's name (default: None).
-
-    Returns:
-        OrganAnnotatorCombination: A :class:`~pyradise.data.organ.OrganAnnotatorCombination` instance.
-    """
-    if isinstance(data_or_organ_name, OrganAnnotatorCombination):
-        return data_or_organ_name
-
-    elif isinstance(data_or_organ_name, tuple):
-        return OrganAnnotatorCombination(*data_or_organ_name)
-
-    else:
-        if annotator_name is None:
-            raise ValueError("`annotator_name` must be provided if `data_or_organ_name` is a string.")
-        return OrganAnnotatorCombination(data_or_organ_name, annotator_name)
-
-
-def seq_to_organ_annotator_combinations(
-    seq: Sequence[Union[Tuple[str, str], OrganAnnotatorCombination]],
-) -> Tuple[OrganAnnotatorCombination, ...]:
-    """Converts a sequence of string tuples to a tuple of :class:`~pyradise.data.organ.OrganAnnotatorCombination`
-    instances.
-
-    Args:
-        seq (Sequence[Union[Tuple[str, str], OrganAnnotatorCombination]]): A sequence of tuples of two strings for the
-         organ names and the annotator names or a sequence of :class:`~pyradise.data.organ.OrganAnnotatorCombination`
-         instances.
-
-    Returns:
-        Tuple[OrganAnnotatorCombination, ...]: A tuple of :class:`~pyradise.data.organ.OrganAnnotatorCombination`
-        instances.
-    """
-    return tuple(str_to_organ_annotator_combination(text) for text in seq)
+from typing import Optional, Sequence, Tuple, Union
+
+from .annotator import Annotator
+from .modality import Modality
+from .organ import Organ, OrganAnnotatorCombination
+
+__all__ = [
+    "str_to_modality",
+    "seq_to_modalities",
+    "str_to_organ",
+    "seq_to_organs",
+    "str_to_annotator",
+    "seq_to_annotators",
+    "str_to_organ_annotator_combination",
+    "seq_to_organ_annotator_combinations",
+]
+
+
+def str_to_modality(text: Union[str, Modality]) -> Modality:
+    """Converts a string to a :class:`~pyradise.data.modality.Modality` instance.
+
+    Args:
+        text (Union[str, Modality]): A string or a :class:`~pyradise.data.modality.Modality` instance.
+
+    Returns:
+        Modality: A :class:`~pyradise.data.modality.Modality` instance.
+    """
+    if isinstance(text, Modality):
+        return text
+
+    return Modality(text)
+
+
+def seq_to_modalities(seq: Sequence[Union[str, Modality]]) -> Tuple[Modality, ...]:
+    """Converts a sequence of strings to a tuple of :class:`~pyradise.data.modality.Modality` instances.
+
+    Args:
+        seq (Sequence[Union[str, Modality]]): A sequence of strings or :class:`~pyradise.data.modality.Modality`
+         instances.
+
+    Returns:
+        Tuple[Modality, ...]: A tuple of :class:`~pyradise.data.modality.Modality` instances.
+    """
+    return tuple(str_to_modality(text) for text in seq)
+
+
+def str_to_organ(name: Union[str, Organ]) -> Organ:
+    """Converts a string to a :class:`~pyradise.data.organ.Organ` instance.
+
+    Args:
+        name (Union[str, Organ]): A string or a :class:`~pyradise.data.organ.Organ` instance.
+
+    Returns:
+        Organ: A :class:`~pyradise.data.organ.Organ` instance.
+    """
+    if isinstance(name, Organ):
+        return name
+
+    return Organ(name)
+
+
+def seq_to_organs(seq: Sequence[Union[str, Organ]]) -> Tuple[Organ, ...]:
+    """Converts a sequence of strings to a tuple of :class:`~pyradise.data.organ.Organ` instances.
+
+    Args:
+        seq (Sequence[Union[str, Organ]]): A sequence of strings or :class:`~pyradise.data.organ.Organ` instances.
+
+    Returns:
+        Tuple[Organ, ...]: A tuple of :class:`~pyradise.data.organ.Organ` instances.
+    """
+    return tuple(str_to_organ(text) for text in seq)
+
+
+def str_to_annotator(name: Union[str, Annotator]) -> Annotator:
+    """Converts a string to a :class:`~pyradise.data.annotator.Annotator` instance.
+
+    Args:
+        name (Union[str, Annotator]): A string or a :class:`~pyradise.data.annotator.Annotator` instance.
+
+    Returns:
+        Annotator: A :class:`~pyradise.data.annotator.Annotator` instance.
+    """
+    if isinstance(name, Annotator):
+        return name
+
+    return Annotator(name)
+
+
+def seq_to_annotators(seq: Sequence[Union[str, Annotator]]) -> Tuple[Annotator, ...]:
+    """Converts a sequence of strings to a tuple of :class:`~pyradise.data.annotator.Annotator` instances.
+
+    Args:
+        seq (Sequence[Union[str, Annotator]]): A sequence of strings or :class:`~pyradise.data.annotator.Annotator`
+         instances.
+
+    Returns:
+        Tuple[Annotator, ...]: A tuple of :class:`~pyradise.data.annotator.Annotator` instances.
+    """
+    return tuple(str_to_annotator(text) for text in seq)
+
+
+def str_to_organ_annotator_combination(
+    data_or_organ_name: Union[str, Tuple[str, str], OrganAnnotatorCombination], annotator_name: Optional[str] = None
+) -> OrganAnnotatorCombination:
+    """Converts a string to a :class:`~pyradise.data.organ.OrganAnnotatorCombination` instance.
+
+    Args:
+        data_or_organ_name (Union[str, Tuple[str, str], OrganAnnotatorCombination]): A string for the organ name, a
+         tuple of two strings for the organ name and the annotator name, or a
+         :class:`~pyradise.data.organ.OrganAnnotatorCombination` instance.
+        annotator_name (Optional[str], optional): A string for the annotator's name (default: None).
+
+    Returns:
+        OrganAnnotatorCombination: A :class:`~pyradise.data.organ.OrganAnnotatorCombination` instance.
+    """
+    if isinstance(data_or_organ_name, OrganAnnotatorCombination):
+        return data_or_organ_name
+
+    elif isinstance(data_or_organ_name, tuple):
+        return OrganAnnotatorCombination(*data_or_organ_name)
+
+    else:
+        if annotator_name is None:
+            raise ValueError("`annotator_name` must be provided if `data_or_organ_name` is a string.")
+        return OrganAnnotatorCombination(data_or_organ_name, annotator_name)
+
+
+def seq_to_organ_annotator_combinations(
+    seq: Sequence[Union[Tuple[str, str], OrganAnnotatorCombination]],
+) -> Tuple[OrganAnnotatorCombination, ...]:
+    """Converts a sequence of string tuples to a tuple of :class:`~pyradise.data.organ.OrganAnnotatorCombination`
+    instances.
+
+    Args:
+        seq (Sequence[Union[Tuple[str, str], OrganAnnotatorCombination]]): A sequence of tuples of two strings for the
+         organ names and the annotator names or a sequence of :class:`~pyradise.data.organ.OrganAnnotatorCombination`
+         instances.
+
+    Returns:
+        Tuple[OrganAnnotatorCombination, ...]: A tuple of :class:`~pyradise.data.organ.OrganAnnotatorCombination`
+        instances.
+    """
+    return tuple(str_to_organ_annotator_combination(text) for text in seq)
```

### Comparing `pyradise-0.2.2/pyradise/fileio/__init__.py` & `pyradise-0.2.3/pyradise/fileio/__init__.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,31 +1,31 @@
-from pydicom.tag import Tag
-
-from .crawling import (Crawler, DatasetDicomCrawler, DatasetFileCrawler,
-                       SubjectDicomCrawler, SubjectFileCrawler)
-from .dicom_conversion import (Converter, DicomImageSeriesConverter,
-                               DicomRTSSSeriesConverter,
-                               RTSSConverter2DConfiguration,
-                               RTSSConverter3DConfiguration, RTSSMetaData,
-                               RTSSToSegmentConverter,
-                               SegmentToRTSSConverter2D,
-                               SegmentToRTSSConverter3D,
-                               SubjectToRTSSConverter)
-from .extraction import (AnnotatorExtractor, ModalityExtractor, OrganExtractor,
-                         SimpleAnnotatorExtractor, SimpleModalityExtractor,
-                         SimpleOrganExtractor)
-from .loading import ExplicitLoader, IterableSubjectLoader, SubjectLoader
-from .modality_config import ModalityConfiguration
-from .selection import (AnnotatorInfoSelector, ModalityInfoSelector,
-                        NoRegistrationInfoSelector, NoRTSSInfoSelector,
-                        OrganInfoSelector, SeriesInfoSelector,
-                        SeriesInfoSelectorPipeline)
-from .series_info import (DicomSeriesImageInfo, DicomSeriesInfo,
-                          DicomSeriesRegistrationInfo, DicomSeriesRTSSInfo,
-                          FileSeriesInfo, IntensityFileSeriesInfo,
-                          ReferenceInfo, RegistrationInfo,
-                          RegistrationSequenceInfo, SegmentationFileSeriesInfo,
-                          SeriesInfo)
-from .writing import (DicomSeriesSubjectWriter, DirectorySubjectWriter,
-                      ImageFileFormat, SubjectWriter,
-                      default_intensity_file_name_fn,
-                      default_segmentation_file_name_fn)
+from pydicom.tag import Tag
+
+from .crawling import (Crawler, DatasetDicomCrawler, DatasetFileCrawler,
+                       SubjectDicomCrawler, SubjectFileCrawler)
+from .dicom_conversion import (Converter, DicomImageSeriesConverter,
+                               DicomRTSSSeriesConverter,
+                               RTSSConverter2DConfiguration,
+                               RTSSConverter3DConfiguration, RTSSMetaData,
+                               RTSSToSegmentConverter,
+                               SegmentToRTSSConverter2D,
+                               SegmentToRTSSConverter3D,
+                               SubjectToRTSSConverter)
+from .extraction import (AnnotatorExtractor, ModalityExtractor, OrganExtractor,
+                         SimpleAnnotatorExtractor, SimpleModalityExtractor,
+                         SimpleOrganExtractor)
+from .loading import ExplicitLoader, IterableSubjectLoader, SubjectLoader
+from .modality_config import ModalityConfiguration
+from .selection import (AnnotatorInfoSelector, ModalityInfoSelector,
+                        NoRegistrationInfoSelector, NoRTSSInfoSelector,
+                        OrganInfoSelector, SeriesInfoSelector,
+                        SeriesInfoSelectorPipeline)
+from .series_info import (DicomSeriesImageInfo, DicomSeriesInfo,
+                          DicomSeriesRegistrationInfo, DicomSeriesRTSSInfo,
+                          FileSeriesInfo, IntensityFileSeriesInfo,
+                          ReferenceInfo, RegistrationInfo,
+                          RegistrationSequenceInfo, SegmentationFileSeriesInfo,
+                          SeriesInfo)
+from .writing import (DicomSeriesSubjectWriter, DirectorySubjectWriter,
+                      ImageFileFormat, SubjectWriter,
+                      default_intensity_file_name_fn,
+                      default_segmentation_file_name_fn)
```

### Comparing `pyradise-0.2.2/pyradise/fileio/crawling.py` & `pyradise-0.2.3/pyradise/fileio/crawling.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,819 +1,819 @@
-import os
-import warnings
-from abc import ABC, abstractmethod
-from typing import Any, Optional, Tuple
-
-import itk
-from pydicom.tag import Tag
-
-from pyradise.data import Modality
-from pyradise.utils import (assume_is_segmentation, is_dicom_file,
-                            is_dir_and_exists, load_dataset_tag)
-
-from .extraction import AnnotatorExtractor, ModalityExtractor, OrganExtractor
-from .modality_config import ModalityConfiguration
-from .series_info import (DicomSeriesImageInfo, DicomSeriesInfo,
-                          DicomSeriesRegistrationInfo, DicomSeriesRTSSInfo,
-                          FileSeriesInfo, IntensityFileSeriesInfo,
-                          SegmentationFileSeriesInfo)
-
-__all__ = ["Crawler", "SubjectFileCrawler", "DatasetFileCrawler", "SubjectDicomCrawler", "DatasetDicomCrawler"]
-
-
-class Crawler(ABC):
-    """An abstract crawler whose subtypes are intended to be used for searching files of a certain type in a specified
-    location or within a hierarchy of directories.
-
-    Args:
-        path (str): The directory path for which the crawling will be performed.
-    """
-
-    def __init__(self, path: str) -> None:
-        super().__init__()
-
-        self.path = is_dir_and_exists(os.path.normpath(path))
-
-    @abstractmethod
-    def execute(self) -> Any:
-        """Execute the crawling process.
-
-        Returns:
-            Any: The crawled data.
-        """
-        raise NotImplementedError()
-
-
-class SubjectFileCrawler(Crawler):
-    """A crawler for retrieving :class:`~pyradise.fileio.series_info.FileSeriesInfo` entries from a subject directory
-    containing discrete image files of a specified type (see ``extension`` parameter).
-
-    The :class:`SubjectFileCrawler` is used for searching appropriate files within a specific subject directory
-    containing all the subject's data. If there are multiple subjects in separate directories but within a
-    common top-level directory to be crawled we recommend using the :class:`DatasetFileCrawler`.
-
-    Important:
-        The DICOM format is not supported by this crawler. Use the appropriate crawler variant instead.
-
-    Raises:
-        ValueError: If the ``extension`` parameter specifies the DICOM file extension (i.e. ``.dcm``).
-
-    Args:
-        path (str): The directory path to crawl for files.
-        subject_name (str): The name of the subject.
-        extension (str): The file extension of the files to be searched.
-        modality_extractor (ModalityExtractor): The modality extractor.
-        organ_extractor (OrganExtractor): The organ extractor.
-        annotator_extractor (AnnotatorExtractor): The annotator extractor.
-
-    """
-
-    def __init__(
-        self,
-        path: str,
-        subject_name: str,
-        extension: str,
-        modality_extractor: ModalityExtractor,
-        organ_extractor: OrganExtractor,
-        annotator_extractor: AnnotatorExtractor,
-    ) -> None:
-        super().__init__(path)
-
-        if "dcm" in extension:
-            raise ValueError(
-                f"The DICOM format is not supported by {self.__class__.__name__}! "
-                "Use the appropriate DICOM variant instead."
-            )
-
-        self.extension = extension
-        self.subject_name = subject_name
-        self.modality_extractor = modality_extractor
-        self.organ_extractor = organ_extractor
-        self.annotator_extractor = annotator_extractor
-
-    def execute(self) -> Tuple[FileSeriesInfo, ...]:
-        """Execute the crawling process.
-
-        Returns:
-            Tuple[FileSeriesInfo, ...]: The crawled data.
-        """
-
-        series_infos = []
-        for root, _, files in os.walk(self.path):
-            for file in files:
-                if file.endswith(self.extension):
-                    file_path = os.path.join(root, file)
-                    modality = self.modality_extractor.extract(file_path)
-
-                    if self.modality_extractor.is_enumerated_default_modality(modality):
-                        is_segmentation = assume_is_segmentation(file_path)
-                    else:
-                        is_segmentation = True if modality is None else False
-
-                    if is_segmentation:
-                        organ = self.organ_extractor.extract(file_path)
-                        annotator = self.annotator_extractor.extract(file_path)
-
-                        series_info = SegmentationFileSeriesInfo(file_path, self.subject_name, organ, annotator)
-                    else:
-                        series_info = IntensityFileSeriesInfo(file_path, self.subject_name, modality)
-
-                    series_infos.append(series_info)
-
-        return tuple(series_infos)
-
-
-class DatasetFileCrawler(Crawler):
-    """An iterable crawler for retrieving :class:`~pyradise.fileio.series_info.FileSeriesInfo` entries from a dataset
-    directory containing at least one subject directory with image files of a specified type (see ``extension``
-    parameter).
-
-    If you want to load a large dataset with many subjects, we recommend using the iterative crawling approach instead
-    of crawling the data via :meth:`execute` to reduce memory consumption (see example below).
-
-    Important:
-        The DICOM format is not supported by this crawler. Use the appropriate crawler variant instead.
-
-    Example:
-
-        Demonstration of the iterative and the non-iterative loading approach:
-
-        >>> from pyradise.data import (Modality, Organ, Annotator)
-        >>> from pyradise.fileio import (DatasetFileCrawler, ModalityExtractor,
-        >>>                              OrganExtractor, AnnotatorExtractor, SubjectLoader)
-        >>>
-        >>>
-        >>> # An example modality extractor
-        >>> class MyModalityExtractor(ModalityExtractor):
-        >>>
-        >>>     def extract_from_dicom(self, path: str) -> Optional[Modality]:
-        >>>         return None
-        >>>
-        >>>     def extract_from_path(self, path: str) -> Optional[Modality]:
-        >>>         file_name = os.path.basename(path)
-        >>>         if 't1' in file_name:
-        >>>             return Modality('T1')
-        >>>         elif 't2' in file_name:
-        >>>             return Modality('T2')
-        >>>         else:
-        >>>             return None
-        >>>
-        >>>
-        >>> # An example organ extractor
-        >>> class MyOrganExtractor(OrganExtractor):
-        >>>
-        >>>     def extract(self, path: str) -> Optional[Organ]:
-        >>>         file_name = os.path.basename(path).lower()
-        >>>         if 'brainstem' in file_name:
-        >>>             return Organ('Brainstem')
-        >>>         elif 'tumor' in file_name:
-        >>>             return Organ('Tumor')
-        >>>         else:
-        >>>             return None
-        >>>
-        >>>
-        >>> # An example annotator extractor
-        >>> class MyAnnotatorExtractor(AnnotatorExtractor):
-        >>>
-        >>>     def extract(self, path: str) -> Optional[Annotator]:
-        >>>         file_name = os.path.basename(path).lower()
-        >>>         if 'example_expert' in file_name:
-        >>>             return Annotator('ExampleExpert')
-        >>>         return None
-        >>>
-        >>>
-        >>> def main_iterative_crawling(dataset_path: str) -> None:
-        >>>     extension = '.nii.gz'
-        >>>
-        >>>     # Create the crawler
-        >>>     crawler = DatasetFileCrawler(dataset_path, extension, MyModalityExtractor(),
-        >>>                                  MyOrganExtractor(), MyAnnotatorExtractor())
-        >>>
-        >>>     # Use the crawler iteratively (more memory efficient)
-        >>>     for series_info in crawler:
-        >>>         subject = SubjectLoader().load(series_info)
-        >>>         # Do something with the subject
-        >>>         print(subject.get_name())
-        >>>
-        >>>
-        >>> def main_crawling_using_execute_fn(dataset_path: str) -> None:
-        >>>     extension = '.nii.gz'
-        >>>
-        >>>     # Create the crawler
-        >>>     crawler = DatasetFileCrawler(dataset_path, extension, MyModalityExtractor(),
-        >>>                                  MyOrganExtractor(), MyAnnotatorExtractor())
-        >>>
-        >>>     # Use the crawler with the execute function
-        >>>     # (all series info entries are loaded in one step)
-        >>>     series_infos = crawler.execute()
-        >>>
-        >>>     # Iterate over the series infos
-        >>>     for series_info in series_infos:
-        >>>         subject = SubjectLoader().load(series_info)
-        >>>         # Do something with the subject
-        >>>         print(subject.get_name())
-
-    Raises:
-        ValueError: If the ``extension`` parameter specifies the DICOM file extension (i.e. ``.dcm``).
-
-    Args:
-        path (str): The dataset directory path to crawl for data.
-        extension (str): The file extension of the image files to be crawled.
-        modality_extractor (ModalityExtractor): The modality extractor.
-        organ_extractor (OrganExtractor): The organ extractor.
-        annotator_extractor (AnnotatorExtractor): The annotator extractor.
-    """
-
-    def __init__(
-        self,
-        path: str,
-        extension: str,
-        modality_extractor: ModalityExtractor,
-        organ_extractor: OrganExtractor,
-        annotator_extractor: AnnotatorExtractor,
-    ) -> None:
-        super().__init__(path)
-
-        if "dcm" in extension:
-            raise ValueError(
-                f"The DICOM format is not supported by {self.__class__.__name__}! "
-                "Use the appropriate DICOM variant instead."
-            )
-        self.extension = extension
-
-        self.modality_extractor = modality_extractor
-        self.organ_extractor = organ_extractor
-        self.annotator_extractor = annotator_extractor
-
-        subject_dir_paths = self._get_subject_dir_paths(self.path, self.extension)
-        self.subject_dir_path = tuple(sorted(subject_dir_paths))
-        self.subject_names = tuple(os.path.basename(path) for path in self.subject_dir_path)
-
-        self.current_idx = 0
-        self.num_subjects = len(self.subject_dir_path)
-
-    @staticmethod
-    def _get_subject_dir_paths(path: str, extension: str) -> Tuple[str, ...]:
-        """Get the paths of the subject directories containing valid files.
-
-        Args:
-            path (str): The directory path for which the crawling will be performed.
-            extension (str): The file extension of the files to be considered.
-
-        Returns:
-            Tuple[str, ...]: The subject directory paths containing valid files.
-        """
-        candidate_dir_paths = [entry.path for entry in os.scandir(path) if entry.is_dir()]
-
-        subject_dir_paths = []
-        for candidate_dir_path in candidate_dir_paths:
-            for root, _, files in os.walk(candidate_dir_path):
-                for file in files:
-                    if file.endswith(extension):
-                        subject_dir_paths.append(candidate_dir_path)
-                        break
-
-        return tuple(subject_dir_paths)
-
-    def execute(self) -> Tuple[Tuple[FileSeriesInfo, ...], ...]:
-        """Execute the crawling process.
-
-        Returns:
-            Tuple[Tuple[FileSeriesInfo, ...], ...]: The crawled data.
-        """
-        # Get subject files
-        subject_files = []
-        for subject_dir, subject_name in zip(self.subject_dir_path, self.subject_names):
-            subject_file_crawler = SubjectFileCrawler(
-                subject_dir,
-                subject_name,
-                self.extension,
-                self.modality_extractor,
-                self.organ_extractor,
-                self.annotator_extractor,
-            )
-            subject_files.append(subject_file_crawler.execute())
-
-        return tuple(subject_files)
-
-    def __iter__(self) -> "DatasetFileCrawler":
-        self.current_idx = 0
-        return self
-
-    def __next__(self) -> Tuple[FileSeriesInfo, ...]:
-        if self.current_idx < self.num_subjects:
-            subject_info = SubjectFileCrawler(
-                self.subject_dir_path[self.current_idx],
-                self.subject_names[self.current_idx],
-                self.extension,
-                self.modality_extractor,
-                self.organ_extractor,
-                self.annotator_extractor,
-            ).execute()
-            self.current_idx += 1
-            return subject_info
-        else:
-            raise StopIteration
-
-    def __len__(self) -> int:
-        return self.num_subjects
-
-
-class SubjectDicomCrawler(Crawler):
-    """A crawler for retrieving :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries from a subject directory
-    containing DICOM files (e.g. DICOM images, DICOM registrations, DICOM RTSS). Files of other formats then DICOM will
-    be ignored and can not be crawled with this type of crawler.
-
-    The :class:`SubjectDicomCrawler` is used for searching appropriate files within a specific subject directory
-    containing all the subject's data. If there are multiple subjects in separate directories but within a common
-    top-level directory to be crawled we recommend using the :class:`DatasetDicomCrawler`.
-
-    The prioritized method to extract the :class:`~pyradise.data.modality.Modality` for the retrieved images is the
-    usage of a modality configuration file. If no modality configuration file is available the
-    :class:`SubjectDicomCrawler` will try to extract the :class:`~pyradise.data.modality.Modality` from the retrieved
-    images using the class:`ModalityExtractor`. If no :class:`~pyradise.fileio.extraction.ModalityExtractor` is
-    provided an exception will be raised.
-
-    The :class:`SubjectDicomCrawler` can be used to generate the modality configuration file skeleton for a
-    specific subject. In this case set the ``generate_modality_config`` parameter to ``True`` and execute the
-    crawling process. The generated modality configuration file skeleton will be saved in the subject directory.
-
-    Important:
-        This crawler exclusively support the DICOM file format and does not support any other file format.
-
-    Args:
-        path (str): The subject directory path to crawl.
-        modality_extractor (Optional[ModalityExtractor]): The modality extractor (default: None).
-        modality_config_file_name (str): The file name for the modality configuration file within the subject
-         directory (default: modality_config.json).
-        write_modality_config (bool): If True writes the modality configuration retrieved to the subject directory
-         (default: False).
-    """
-
-    def __init__(
-        self,
-        path: str,
-        modality_extractor: Optional[ModalityExtractor] = None,
-        modality_config_file_name: str = "modality_config.json",
-        write_modality_config: bool = False,
-    ) -> None:
-        super().__init__(path)
-        self.modality_extractor: Optional[ModalityExtractor] = modality_extractor
-        self.config_file_name = modality_config_file_name
-        self.write_config = write_modality_config
-
-    def _get_dicom_files(self) -> Tuple[str, ...]:
-        """Get all DICOM files in the subject directory.
-
-        Returns:
-            Tuple[str, ...]: The DICOM file paths.
-        """
-        file_paths = []
-        for root, _, files in os.walk(self.path):
-            for file in files:
-                if file == "DICOMDIR":
-                    continue
-
-                file_path = os.path.join(root, file)
-                if is_dicom_file(file_path):
-                    file_paths.append(file_path)
-
-        return tuple(file_paths)
-
-    def _get_image_files(self) -> Tuple[Tuple[str, ...], ...]:
-        """Get all DICOM image files in the subject directory.
-
-        Notes:
-            The DICOM image files are grouped by their SeriesInstanceUID.
-
-        Returns:
-            Tuple[Tuple[str, ...], ...]: The DICOM image file paths separated by SeriesInstanceUID.
-        """
-        series_extractor = itk.GDCMSeriesFileNames.New()
-        series_extractor.SetRecursive(True)
-        series_extractor.SetDirectory(self.path)
-        series_extractor.Update()
-
-        image_series_paths = []
-        for series_uid in series_extractor.GetSeriesUIDs():
-            series_paths = [str(os.path.normpath(entry)) for entry in series_extractor.GetFileNames(series_uid)]
-
-            # check if the image belongs to the DICOM RT SOP Classes
-            dataset = load_dataset_tag(series_paths[0], (Tag(0x0008, 0x0016),))
-            if "481" in str(dataset.get("SOPClassUID", "")):
-                continue
-
-            image_series_paths.append(tuple(series_paths))
-
-        return tuple(image_series_paths)
-
-    @staticmethod
-    def _get_registration_files(paths: Tuple[str, ...]) -> Tuple[str, ...]:
-        """Get all DICOM registration files in the subject directory.
-
-        Args:
-            paths (Tuple[str, ...]): The DICOM file paths to check if they specify a DICOM registration file.
-
-        Returns:
-            Tuple[str, ...]: The DICOM registration file paths.
-        """
-        valid_sop_class_uids = (
-            "1.2.840.10008.5.1.4.1.1.66.1",  # Spatial Registration Storage
-            "1.2.840.10008.5.1.4.1.1.66.3",
-        )  # Deformable Spatial Registration Storage
-
-        registration_files = []
-        for path in paths:
-            dataset = load_dataset_tag(path, (Tag(0x0008, 0x0016),))
-
-            if dataset.get("SOPClassUID", None) in valid_sop_class_uids:
-                registration_files.append(path)
-
-        return tuple(registration_files)
-
-    @staticmethod
-    def _get_rtss_files(paths: Tuple[str, ...]) -> Tuple[str, ...]:
-        """Get all DICOM RTSS files in the subject directory.
-
-        Args:
-            paths (Tuple[str, ...]): The DICOM file paths to check if they specify a DICOM RTSS file.
-
-        Returns:
-            Tuple[str, ...]: The DICOM RTSS file paths.
-        """
-        valid_sop_class_uid = "1.2.840.10008.5.1.4.1.1.481.3"  # RT Structure Set Storage
-
-        rtss_files = []
-        for path in paths:
-            dataset = load_dataset_tag(path, (Tag(0x0008, 0x0016),))
-
-            if dataset.get("SOPClassUID", None) == valid_sop_class_uid:
-                rtss_files.append(path)
-
-        return tuple(rtss_files)
-
-    @staticmethod
-    def _generate_image_infos(image_paths: Tuple[Tuple[str, ...], ...]) -> Tuple[DicomSeriesImageInfo]:
-        """Generate the :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries for the DICOM file paths
-        specified.
-
-        Args:
-            image_paths (Tuple[Tuple[str, ...], ...]): The DICOM image file paths provided.
-
-        Returns:
-            Tuple[DicomSeriesImageInfo, ...]: The retrieved :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo`
-            entries.
-        """
-        infos = []
-
-        for paths in image_paths:
-            image_info = DicomSeriesImageInfo(paths)
-            infos.append(image_info)
-
-        return tuple(infos)
-
-    @staticmethod
-    def _generate_registration_infos(
-        registration_paths: Tuple[str, ...], image_infos: Tuple[DicomSeriesImageInfo, ...]
-    ) -> Tuple[DicomSeriesRegistrationInfo]:
-        """Generate the :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries for the DICOM file
-        paths specified.
-
-        Args:
-            registration_paths (Tuple[str, ...]): The DICOM registration file paths provided.
-            image_infos (Tuple[DicomSeriesImageInfo, ...]): The available
-             :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries.
-
-        Returns:
-            Tuple[DicomSeriesRegistrationInfo, ...]: The retrieved
-             :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries.
-        """
-        infos = []
-
-        for path in registration_paths:
-            registration_info = DicomSeriesRegistrationInfo(path, image_infos, persistent_image_infos=False)
-            infos.append(registration_info)
-
-        return tuple(infos)
-
-    @staticmethod
-    def _generate_rtss_info(rtss_paths: Tuple[str, ...]) -> Tuple[DicomSeriesRTSSInfo]:
-        """Generate the :class:`~pyradise.fileio.series_info.DicomSeriesRTStructureSetInfo` entries for the DICOM file
-        paths specified.
-
-        Args:
-            rtss_paths (Tuple[str, ...]): The DICOM RTSS file paths.
-
-        Returns:
-            Tuple[DicomSeriesRTStructureSetInfo, ...]: AThe retrieved
-             :class:`~pyradise.fileio.series_info.DicomSeriesRTStructureSetInfo` entries.
-        """
-        infos = []
-
-        for path in rtss_paths:
-            rtss_info = DicomSeriesRTSSInfo(path)
-            infos.append(rtss_info)
-
-        return tuple(infos)
-
-    def _export_modality_config(self, infos: Tuple[DicomSeriesInfo, ...]) -> None:
-        """Export the retrieved :class:`~pyradise.fileio.modality_config.ModalityConfiguration` to a file.
-
-        Args:
-            infos (Tuple[DicomSeriesInfo, ...]): The :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries
-             containing the information to export.
-
-        Returns:
-            None
-        """
-        config = ModalityConfiguration.from_dicom_series_info(infos)
-        config.to_file(os.path.join(self.path, self.config_file_name))
-
-    def _apply_modality_config(self, infos: Tuple[DicomSeriesImageInfo, ...]) -> None:
-        """Load the :class:`~pyradise.fileio.modality_config.ModalityConfiguration` from a file if available and apply
-        it to the specified :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries. If the
-        :class:`~pyradise.fileio.modality_config.ModalityConfiguration` file is not available and a
-        :class:`~pyradise.fileio.extraction.ModalityExtractor` is provided the extractor is used for modality
-        determination.
-
-        Args:
-            infos (Tuple[DicomSeriesImageInfo, ...]): The available
-             :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries to which the
-             loaded :class:`~pyradise.fileio.modality_config.ModalityConfiguration` can be applied.
-
-        Returns:
-            None
-        """
-        # try to apply the modality configuration if it exists
-        modality_file_path = ""
-        for root, _, files in os.walk(self.path):
-            for file in files:
-                if self.config_file_name in file:
-                    modality_file_path = os.path.join(root, file)
-                    break
-
-        # apply the modality configuration if it exists
-        if os.path.exists(modality_file_path):
-            config = ModalityConfiguration.from_file(modality_file_path)
-            config.add_modalities_to_info(infos)
-
-            if config.has_default_modalities():
-                warnings.warn("The modality configuration file contains at least one default modality.")
-
-            if config.has_duplicate_modalities():
-                raise ValueError(
-                    "The modalities from the modality configuration file contain at least one duplicate "
-                    "modality. This will cause ambiguity when loading the DICOM series."
-                )
-
-            if self.write_config:
-                warnings.warn("The modality configuration file already exists and will not be overwritten.")
-
-            return
-
-        # if no modality configuration file exists, try to apply the default configuration
-        else:
-            if self.modality_extractor is not None:
-                extraction_possible_for_all = True
-                for info in infos:
-                    modality = self.modality_extractor.extract(info.path[0])
-                    if modality is not None:
-                        info.set_modality(modality)
-                    else:
-                        info.set_modality(Modality.get_default())
-                        extraction_possible_for_all = False
-
-                config = ModalityConfiguration.from_dicom_series_info(infos)
-                if self.write_config:
-                    config.to_file(os.path.join(self.path, self.config_file_name))
-
-                if config.has_duplicate_modalities():
-                    raise ValueError(
-                        "The extracted modalities contain at least one duplicate modality. "
-                        "This will cause ambiguity when loading the DICOM series."
-                    )
-
-                if extraction_possible_for_all:
-                    return
-                else:
-                    warnings.warn(
-                        "Modality extraction failed for one DICOM series. The default modality will "
-                        "be used for the series which failed during modality extraction."
-                    )
-                    return
-
-            else:
-                config = ModalityConfiguration.from_dicom_series_info(infos)
-
-                if config.has_duplicate_modalities() and self.write_config is False:
-                    raise ValueError(
-                        "The extracted modalities contain at least one duplicate modality. "
-                        "This will cause ambiguity when loading the DICOM series. Use either a modality "
-                        "configuration file or a modality extractor to resolve this issue."
-                    )
-
-                if config.has_default_modalities() and self.write_config is False and len(config.configuration) > 1:
-                    raise ValueError(
-                        "The extracted modalities contain at least one default modality. "
-                        "This will cause ambiguity when loading the DICOM series. Use either a modality "
-                        "configuration file or a modality extractor to resolve this issue."
-                    )
-
-                if self.write_config:
-                    config.to_file(os.path.join(self.path, self.config_file_name))
-                    return
-
-                if not config.has_duplicate_modalities():
-                    return
-
-                raise ValueError(
-                    "The modality configuration file could not be found "
-                    f"in the specified path ({self.path}) and there is no modality extractor provided!"
-                )
-
-    def execute(self) -> Tuple[DicomSeriesInfo, ...]:
-        """Execute the crawling process to retrieve the :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries.
-
-        Returns:
-            Tuple[DicomSeriesInfo, ...]: The retrieved :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries.
-        """
-        # get the dicom file paths and sort them according to the file content
-        file_paths = self._get_dicom_files()
-        image_paths = self._get_image_files()
-
-        flat_image_paths = [path for paths in image_paths for path in paths]
-        remaining_paths = tuple(set(file_paths) - set(flat_image_paths))
-
-        registration_paths = self._get_registration_files(remaining_paths)
-        remaining_paths = tuple(set(remaining_paths) - set(registration_paths))
-
-        rtss_paths = self._get_rtss_files(remaining_paths)
-
-        # generate the series infos
-        image_infos = self._generate_image_infos(image_paths)
-        registration_infos = self._generate_registration_infos(registration_paths, image_infos)
-        rtss_infos = self._generate_rtss_info(rtss_paths)
-
-        # apply the modality config and write it to disk if requested
-        self._apply_modality_config(image_infos)
-
-        return image_infos + registration_infos + rtss_infos
-
-
-class DatasetDicomCrawler(Crawler):
-    """A crawler for retrieving :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries from a dataset directory
-    containing at least one subject directory with DICOM files (e.g. DICOM images, DICOM registrations, DICOM RTSS).
-    Files of other formats then DICOM will be ignored and can not be crawled with this type of crawler.
-
-    The :class:`DatasetDicomCrawler` is used for searching appropriate files within a specific dataset directory
-    containing at least one subject folder with DICOM files. If there is just one subject in a single directory to be
-    crawled we recommend using the :class:`SubjectDicomCrawler`. If you want to load a large dataset with many subjects,
-    we recommend using the iterative crawling approach instead of crawling the data via :meth:`execute` to reduce
-    memory consumption (see example below).
-
-    The prioritized method to extract the :class:`~pyradise.data.modality.Modality` for the retrieved images is the
-    usage of a modality configuration file. If no modality configuration file is available for a specific subject
-    directory the :class:`DatasetDicomCrawler` will try to extract the :class:`~pyradise.data.modality.Modality` from
-    the retrieved subject images using the :class:`~pyradise.fileio.extraction.ModalityExtractor`. If no
-    :class:`~pyradise.fileio.extraction.ModalityExtractor` is provided an exception will be raised.
-
-    The :class:`DatasetDicomCrawler` can be used to generate the modality configuration file skeletons for all
-    subjects in the dataset directory. In this case set the ``generate_modality_config`` parameter to ``True`` and
-    execute the crawling process. The generated modality configuration file skeletons will be saved in the appropriate
-    subject directories.
-
-    Important:
-        This crawler exclusively support the DICOM file format and does not support any other file format.
-
-    Example:
-
-        Demonstration of the iterative and the non-iterative loading approach:
-
-        >>> from pyradise.fileio import (DatasetDicomCrawler, SubjectLoader)
-        >>>
-        >>>
-        >>> def main_iterative_crawling(dataset_path: str) -> None:
-        >>>     # Create the crawler (using the modality configuration file)
-        >>>     crawler = DatasetDicomCrawler(dataset_path)
-        >>>
-        >>>     # Use the crawler iteratively (more memory efficient)
-        >>>     for series_info in crawler:
-        >>>         subject = SubjectLoader().load(series_info)
-        >>>         # Do something with the subject
-        >>>         print(subject.get_name())
-        >>>
-        >>>
-        >>> def main_crawling_using_execute_fn(dataset_path: str) -> None:
-        >>>     # Create the crawler (using the modality configuration file)
-        >>>     crawler = DatasetDicomCrawler(dataset_path)
-        >>>
-        >>>     # Use the crawler with the execute function
-        >>>     # (all series info entries are loaded in one step)
-        >>>     series_infos = crawler.execute()
-        >>>
-        >>>     # Iterate over the series infos
-        >>>     for series_info in series_infos:
-        >>>         subject = SubjectLoader().load(series_info)
-        >>>         # Do something with the subject
-        >>>         print(subject.get_name())
-
-    Args:
-        path (str): The dataset directory path to crawl.
-        modality_extractor (Optional[ModalityExtractor]): The modality extractor (default: None)
-        modality_config_file_name (str): The file name for the modality configuration file within the subject
-         directory (default: modality_config.json).
-        write_modality_config (bool): If True writes the modality configuration retrieved to the subject directory
-         (default: False).
-    """
-
-    def __init__(
-        self,
-        path: str,
-        modality_extractor: Optional[ModalityExtractor] = None,
-        modality_config_file_name: str = "modality_config.json",
-        write_modality_config: bool = False,
-    ) -> None:
-        super().__init__(path)
-        self.modality_extractor: Optional[ModalityExtractor] = modality_extractor
-        self.config_file_name = modality_config_file_name
-        self.write_config = write_modality_config
-
-        self.subject_dir_paths: Optional[str] = None
-
-        self.current_idx = 0
-        self.num_subjects = 0
-
-    @staticmethod
-    def _get_subject_dir_paths(path: str) -> Tuple[str, ...]:
-        """Get the paths of the subject directories containing DICOM files.
-
-        Args:
-            path (str): The base directory path which contain the subject directories.
-
-        Returns:
-            Tuple[str, ...]: Paths to all subject directories containing DICOM files.
-        """
-        # Search for all dicom files and sort them according to their patient id
-        subjects = {}
-        patient_id_tag = Tag(0x0010, 0x0020)  # Patient ID
-
-        for root, _, files in os.walk(path):
-            for file in files:
-                if file == "DICOMDIR":
-                    continue
-
-                file_path = os.path.join(root, file)
-
-                # check if file is a dicom file
-                if is_dicom_file(file_path):
-                    # get the patient id
-                    patient_id = str(load_dataset_tag(file_path, (patient_id_tag,)).get(patient_id_tag).value)
-
-                    # collect the file paths per patient id
-                    if patient_id not in subjects:
-                        subjects[patient_id] = file_path
-                    else:
-                        common_path = os.path.commonpath([subjects.get(patient_id), file_path])
-                        subjects[patient_id] = common_path
-
-        return tuple(sorted(subjects.values()))
-
-    def execute(self) -> Tuple[Tuple[DicomSeriesInfo, ...], ...]:
-        """Execute the crawling process to retrieve the :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries.
-
-        Returns:
-            Tuple[Tuple[DicomSeriesInfo, ...], ...]: The retrieved :class:`~pyradise.fileio.series_info.DicomSeriesInfo`
-             entries.
-        """
-        self.subject_dir_paths = self._get_subject_dir_paths(self.path)
-
-        subject_infos = []
-        for subject_dir_path in self.subject_dir_paths:
-            subject_info = SubjectDicomCrawler(
-                subject_dir_path, self.modality_extractor, self.config_file_name, self.write_config
-            ).execute()
-
-            subject_infos.append(subject_info) if subject_info else None
-
-        return tuple(subject_infos)
-
-    def __iter__(self) -> "DatasetDicomCrawler":
-        self.subject_dir_paths = self._get_subject_dir_paths(self.path)
-        self.num_subjects = len(self.subject_dir_paths)
-        self.current_idx = 0
-        return self
-
-    def __next__(self) -> Tuple[DicomSeriesInfo, ...]:
-        if self.current_idx < self.num_subjects:
-            subject_info = SubjectDicomCrawler(
-                self.subject_dir_paths[self.current_idx],
-                self.modality_extractor,
-                self.config_file_name,
-                self.write_config,
-            ).execute()
-            self.current_idx += 1
-            return subject_info
-
-        raise StopIteration
-
-    def __len__(self) -> int:
-        return self.num_subjects
+import os
+import warnings
+from abc import ABC, abstractmethod
+from typing import Any, Optional, Tuple
+
+import itk
+from pydicom.tag import Tag
+
+from pyradise.data import Modality
+from pyradise.utils import (assume_is_segmentation, is_dicom_file,
+                            is_dir_and_exists, load_dataset_tag)
+
+from .extraction import AnnotatorExtractor, ModalityExtractor, OrganExtractor
+from .modality_config import ModalityConfiguration
+from .series_info import (DicomSeriesImageInfo, DicomSeriesInfo,
+                          DicomSeriesRegistrationInfo, DicomSeriesRTSSInfo,
+                          FileSeriesInfo, IntensityFileSeriesInfo,
+                          SegmentationFileSeriesInfo)
+
+__all__ = ["Crawler", "SubjectFileCrawler", "DatasetFileCrawler", "SubjectDicomCrawler", "DatasetDicomCrawler"]
+
+
+class Crawler(ABC):
+    """An abstract crawler whose subtypes are intended to be used for searching files of a certain type in a specified
+    location or within a hierarchy of directories.
+
+    Args:
+        path (str): The directory path for which the crawling will be performed.
+    """
+
+    def __init__(self, path: str) -> None:
+        super().__init__()
+
+        self.path = is_dir_and_exists(os.path.normpath(path))
+
+    @abstractmethod
+    def execute(self) -> Any:
+        """Execute the crawling process.
+
+        Returns:
+            Any: The crawled data.
+        """
+        raise NotImplementedError()
+
+
+class SubjectFileCrawler(Crawler):
+    """A crawler for retrieving :class:`~pyradise.fileio.series_info.FileSeriesInfo` entries from a subject directory
+    containing discrete image files of a specified type (see ``extension`` parameter).
+
+    The :class:`SubjectFileCrawler` is used for searching appropriate files within a specific subject directory
+    containing all the subject's data. If there are multiple subjects in separate directories but within a
+    common top-level directory to be crawled we recommend using the :class:`DatasetFileCrawler`.
+
+    Important:
+        The DICOM format is not supported by this crawler. Use the appropriate crawler variant instead.
+
+    Raises:
+        ValueError: If the ``extension`` parameter specifies the DICOM file extension (i.e. ``.dcm``).
+
+    Args:
+        path (str): The directory path to crawl for files.
+        subject_name (str): The name of the subject.
+        extension (str): The file extension of the files to be searched.
+        modality_extractor (ModalityExtractor): The modality extractor.
+        organ_extractor (OrganExtractor): The organ extractor.
+        annotator_extractor (AnnotatorExtractor): The annotator extractor.
+
+    """
+
+    def __init__(
+        self,
+        path: str,
+        subject_name: str,
+        extension: str,
+        modality_extractor: ModalityExtractor,
+        organ_extractor: OrganExtractor,
+        annotator_extractor: AnnotatorExtractor,
+    ) -> None:
+        super().__init__(path)
+
+        if "dcm" in extension:
+            raise ValueError(
+                f"The DICOM format is not supported by {self.__class__.__name__}! "
+                "Use the appropriate DICOM variant instead."
+            )
+
+        self.extension = extension
+        self.subject_name = subject_name
+        self.modality_extractor = modality_extractor
+        self.organ_extractor = organ_extractor
+        self.annotator_extractor = annotator_extractor
+
+    def execute(self) -> Tuple[FileSeriesInfo, ...]:
+        """Execute the crawling process.
+
+        Returns:
+            Tuple[FileSeriesInfo, ...]: The crawled data.
+        """
+
+        series_infos = []
+        for root, _, files in os.walk(self.path):
+            for file in files:
+                if file.endswith(self.extension):
+                    file_path = os.path.join(root, file)
+                    modality = self.modality_extractor.extract(file_path)
+
+                    if self.modality_extractor.is_enumerated_default_modality(modality):
+                        is_segmentation = assume_is_segmentation(file_path)
+                    else:
+                        is_segmentation = True if modality is None else False
+
+                    if is_segmentation:
+                        organ = self.organ_extractor.extract(file_path)
+                        annotator = self.annotator_extractor.extract(file_path)
+
+                        series_info = SegmentationFileSeriesInfo(file_path, self.subject_name, organ, annotator)
+                    else:
+                        series_info = IntensityFileSeriesInfo(file_path, self.subject_name, modality)
+
+                    series_infos.append(series_info)
+
+        return tuple(series_infos)
+
+
+class DatasetFileCrawler(Crawler):
+    """An iterable crawler for retrieving :class:`~pyradise.fileio.series_info.FileSeriesInfo` entries from a dataset
+    directory containing at least one subject directory with image files of a specified type (see ``extension``
+    parameter).
+
+    If you want to load a large dataset with many subjects, we recommend using the iterative crawling approach instead
+    of crawling the data via :meth:`execute` to reduce memory consumption (see example below).
+
+    Important:
+        The DICOM format is not supported by this crawler. Use the appropriate crawler variant instead.
+
+    Example:
+
+        Demonstration of the iterative and the non-iterative loading approach:
+
+        >>> from pyradise.data import (Modality, Organ, Annotator)
+        >>> from pyradise.fileio import (DatasetFileCrawler, ModalityExtractor,
+        >>>                              OrganExtractor, AnnotatorExtractor, SubjectLoader)
+        >>>
+        >>>
+        >>> # An example modality extractor
+        >>> class MyModalityExtractor(ModalityExtractor):
+        >>>
+        >>>     def extract_from_dicom(self, path: str) -> Optional[Modality]:
+        >>>         return None
+        >>>
+        >>>     def extract_from_path(self, path: str) -> Optional[Modality]:
+        >>>         file_name = os.path.basename(path)
+        >>>         if 't1' in file_name:
+        >>>             return Modality('T1')
+        >>>         elif 't2' in file_name:
+        >>>             return Modality('T2')
+        >>>         else:
+        >>>             return None
+        >>>
+        >>>
+        >>> # An example organ extractor
+        >>> class MyOrganExtractor(OrganExtractor):
+        >>>
+        >>>     def extract(self, path: str) -> Optional[Organ]:
+        >>>         file_name = os.path.basename(path).lower()
+        >>>         if 'brainstem' in file_name:
+        >>>             return Organ('Brainstem')
+        >>>         elif 'tumor' in file_name:
+        >>>             return Organ('Tumor')
+        >>>         else:
+        >>>             return None
+        >>>
+        >>>
+        >>> # An example annotator extractor
+        >>> class MyAnnotatorExtractor(AnnotatorExtractor):
+        >>>
+        >>>     def extract(self, path: str) -> Optional[Annotator]:
+        >>>         file_name = os.path.basename(path).lower()
+        >>>         if 'example_expert' in file_name:
+        >>>             return Annotator('ExampleExpert')
+        >>>         return None
+        >>>
+        >>>
+        >>> def main_iterative_crawling(dataset_path: str) -> None:
+        >>>     extension = '.nii.gz'
+        >>>
+        >>>     # Create the crawler
+        >>>     crawler = DatasetFileCrawler(dataset_path, extension, MyModalityExtractor(),
+        >>>                                  MyOrganExtractor(), MyAnnotatorExtractor())
+        >>>
+        >>>     # Use the crawler iteratively (more memory efficient)
+        >>>     for series_info in crawler:
+        >>>         subject = SubjectLoader().load(series_info)
+        >>>         # Do something with the subject
+        >>>         print(subject.get_name())
+        >>>
+        >>>
+        >>> def main_crawling_using_execute_fn(dataset_path: str) -> None:
+        >>>     extension = '.nii.gz'
+        >>>
+        >>>     # Create the crawler
+        >>>     crawler = DatasetFileCrawler(dataset_path, extension, MyModalityExtractor(),
+        >>>                                  MyOrganExtractor(), MyAnnotatorExtractor())
+        >>>
+        >>>     # Use the crawler with the execute function
+        >>>     # (all series info entries are loaded in one step)
+        >>>     series_infos = crawler.execute()
+        >>>
+        >>>     # Iterate over the series infos
+        >>>     for series_info in series_infos:
+        >>>         subject = SubjectLoader().load(series_info)
+        >>>         # Do something with the subject
+        >>>         print(subject.get_name())
+
+    Raises:
+        ValueError: If the ``extension`` parameter specifies the DICOM file extension (i.e. ``.dcm``).
+
+    Args:
+        path (str): The dataset directory path to crawl for data.
+        extension (str): The file extension of the image files to be crawled.
+        modality_extractor (ModalityExtractor): The modality extractor.
+        organ_extractor (OrganExtractor): The organ extractor.
+        annotator_extractor (AnnotatorExtractor): The annotator extractor.
+    """
+
+    def __init__(
+        self,
+        path: str,
+        extension: str,
+        modality_extractor: ModalityExtractor,
+        organ_extractor: OrganExtractor,
+        annotator_extractor: AnnotatorExtractor,
+    ) -> None:
+        super().__init__(path)
+
+        if "dcm" in extension:
+            raise ValueError(
+                f"The DICOM format is not supported by {self.__class__.__name__}! "
+                "Use the appropriate DICOM variant instead."
+            )
+        self.extension = extension
+
+        self.modality_extractor = modality_extractor
+        self.organ_extractor = organ_extractor
+        self.annotator_extractor = annotator_extractor
+
+        subject_dir_paths = self._get_subject_dir_paths(self.path, self.extension)
+        self.subject_dir_path = tuple(sorted(subject_dir_paths))
+        self.subject_names = tuple(os.path.basename(path) for path in self.subject_dir_path)
+
+        self.current_idx = 0
+        self.num_subjects = len(self.subject_dir_path)
+
+    @staticmethod
+    def _get_subject_dir_paths(path: str, extension: str) -> Tuple[str, ...]:
+        """Get the paths of the subject directories containing valid files.
+
+        Args:
+            path (str): The directory path for which the crawling will be performed.
+            extension (str): The file extension of the files to be considered.
+
+        Returns:
+            Tuple[str, ...]: The subject directory paths containing valid files.
+        """
+        candidate_dir_paths = [entry.path for entry in os.scandir(path) if entry.is_dir()]
+
+        subject_dir_paths = []
+        for candidate_dir_path in candidate_dir_paths:
+            for root, _, files in os.walk(candidate_dir_path):
+                for file in files:
+                    if file.endswith(extension):
+                        subject_dir_paths.append(candidate_dir_path)
+                        break
+
+        return tuple(subject_dir_paths)
+
+    def execute(self) -> Tuple[Tuple[FileSeriesInfo, ...], ...]:
+        """Execute the crawling process.
+
+        Returns:
+            Tuple[Tuple[FileSeriesInfo, ...], ...]: The crawled data.
+        """
+        # Get subject files
+        subject_files = []
+        for subject_dir, subject_name in zip(self.subject_dir_path, self.subject_names):
+            subject_file_crawler = SubjectFileCrawler(
+                subject_dir,
+                subject_name,
+                self.extension,
+                self.modality_extractor,
+                self.organ_extractor,
+                self.annotator_extractor,
+            )
+            subject_files.append(subject_file_crawler.execute())
+
+        return tuple(subject_files)
+
+    def __iter__(self) -> "DatasetFileCrawler":
+        self.current_idx = 0
+        return self
+
+    def __next__(self) -> Tuple[FileSeriesInfo, ...]:
+        if self.current_idx < self.num_subjects:
+            subject_info = SubjectFileCrawler(
+                self.subject_dir_path[self.current_idx],
+                self.subject_names[self.current_idx],
+                self.extension,
+                self.modality_extractor,
+                self.organ_extractor,
+                self.annotator_extractor,
+            ).execute()
+            self.current_idx += 1
+            return subject_info
+        else:
+            raise StopIteration
+
+    def __len__(self) -> int:
+        return self.num_subjects
+
+
+class SubjectDicomCrawler(Crawler):
+    """A crawler for retrieving :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries from a subject directory
+    containing DICOM files (e.g. DICOM images, DICOM registrations, DICOM RTSS). Files of other formats then DICOM will
+    be ignored and can not be crawled with this type of crawler.
+
+    The :class:`SubjectDicomCrawler` is used for searching appropriate files within a specific subject directory
+    containing all the subject's data. If there are multiple subjects in separate directories but within a common
+    top-level directory to be crawled we recommend using the :class:`DatasetDicomCrawler`.
+
+    The prioritized method to extract the :class:`~pyradise.data.modality.Modality` for the retrieved images is the
+    usage of a modality configuration file. If no modality configuration file is available the
+    :class:`SubjectDicomCrawler` will try to extract the :class:`~pyradise.data.modality.Modality` from the retrieved
+    images using the class:`ModalityExtractor`. If no :class:`~pyradise.fileio.extraction.ModalityExtractor` is
+    provided an exception will be raised.
+
+    The :class:`SubjectDicomCrawler` can be used to generate the modality configuration file skeleton for a
+    specific subject. In this case set the ``generate_modality_config`` parameter to ``True`` and execute the
+    crawling process. The generated modality configuration file skeleton will be saved in the subject directory.
+
+    Important:
+        This crawler exclusively support the DICOM file format and does not support any other file format.
+
+    Args:
+        path (str): The subject directory path to crawl.
+        modality_extractor (Optional[ModalityExtractor]): The modality extractor (default: None).
+        modality_config_file_name (str): The file name for the modality configuration file within the subject
+         directory (default: modality_config.json).
+        write_modality_config (bool): If True writes the modality configuration retrieved to the subject directory
+         (default: False).
+    """
+
+    def __init__(
+        self,
+        path: str,
+        modality_extractor: Optional[ModalityExtractor] = None,
+        modality_config_file_name: str = "modality_config.json",
+        write_modality_config: bool = False,
+    ) -> None:
+        super().__init__(path)
+        self.modality_extractor: Optional[ModalityExtractor] = modality_extractor
+        self.config_file_name = modality_config_file_name
+        self.write_config = write_modality_config
+
+    def _get_dicom_files(self) -> Tuple[str, ...]:
+        """Get all DICOM files in the subject directory.
+
+        Returns:
+            Tuple[str, ...]: The DICOM file paths.
+        """
+        file_paths = []
+        for root, _, files in os.walk(self.path):
+            for file in files:
+                if file == "DICOMDIR":
+                    continue
+
+                file_path = os.path.join(root, file)
+                if is_dicom_file(file_path):
+                    file_paths.append(file_path)
+
+        return tuple(file_paths)
+
+    def _get_image_files(self) -> Tuple[Tuple[str, ...], ...]:
+        """Get all DICOM image files in the subject directory.
+
+        Notes:
+            The DICOM image files are grouped by their SeriesInstanceUID.
+
+        Returns:
+            Tuple[Tuple[str, ...], ...]: The DICOM image file paths separated by SeriesInstanceUID.
+        """
+        series_extractor = itk.GDCMSeriesFileNames.New()
+        series_extractor.SetRecursive(True)
+        series_extractor.SetDirectory(self.path)
+        series_extractor.Update()
+
+        image_series_paths = []
+        for series_uid in series_extractor.GetSeriesUIDs():
+            series_paths = [str(os.path.normpath(entry)) for entry in series_extractor.GetFileNames(series_uid)]
+
+            # check if the image belongs to the DICOM RT SOP Classes
+            dataset = load_dataset_tag(series_paths[0], (Tag(0x0008, 0x0016),))
+            if "481" in str(dataset.get("SOPClassUID", "")):
+                continue
+
+            image_series_paths.append(tuple(series_paths))
+
+        return tuple(image_series_paths)
+
+    @staticmethod
+    def _get_registration_files(paths: Tuple[str, ...]) -> Tuple[str, ...]:
+        """Get all DICOM registration files in the subject directory.
+
+        Args:
+            paths (Tuple[str, ...]): The DICOM file paths to check if they specify a DICOM registration file.
+
+        Returns:
+            Tuple[str, ...]: The DICOM registration file paths.
+        """
+        valid_sop_class_uids = (
+            "1.2.840.10008.5.1.4.1.1.66.1",  # Spatial Registration Storage
+            "1.2.840.10008.5.1.4.1.1.66.3",
+        )  # Deformable Spatial Registration Storage
+
+        registration_files = []
+        for path in paths:
+            dataset = load_dataset_tag(path, (Tag(0x0008, 0x0016),))
+
+            if dataset.get("SOPClassUID", None) in valid_sop_class_uids:
+                registration_files.append(path)
+
+        return tuple(registration_files)
+
+    @staticmethod
+    def _get_rtss_files(paths: Tuple[str, ...]) -> Tuple[str, ...]:
+        """Get all DICOM RTSS files in the subject directory.
+
+        Args:
+            paths (Tuple[str, ...]): The DICOM file paths to check if they specify a DICOM RTSS file.
+
+        Returns:
+            Tuple[str, ...]: The DICOM RTSS file paths.
+        """
+        valid_sop_class_uid = "1.2.840.10008.5.1.4.1.1.481.3"  # RT Structure Set Storage
+
+        rtss_files = []
+        for path in paths:
+            dataset = load_dataset_tag(path, (Tag(0x0008, 0x0016),))
+
+            if dataset.get("SOPClassUID", None) == valid_sop_class_uid:
+                rtss_files.append(path)
+
+        return tuple(rtss_files)
+
+    @staticmethod
+    def _generate_image_infos(image_paths: Tuple[Tuple[str, ...], ...]) -> Tuple[DicomSeriesImageInfo]:
+        """Generate the :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries for the DICOM file paths
+        specified.
+
+        Args:
+            image_paths (Tuple[Tuple[str, ...], ...]): The DICOM image file paths provided.
+
+        Returns:
+            Tuple[DicomSeriesImageInfo, ...]: The retrieved :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo`
+            entries.
+        """
+        infos = []
+
+        for paths in image_paths:
+            image_info = DicomSeriesImageInfo(paths)
+            infos.append(image_info)
+
+        return tuple(infos)
+
+    @staticmethod
+    def _generate_registration_infos(
+        registration_paths: Tuple[str, ...], image_infos: Tuple[DicomSeriesImageInfo, ...]
+    ) -> Tuple[DicomSeriesRegistrationInfo]:
+        """Generate the :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries for the DICOM file
+        paths specified.
+
+        Args:
+            registration_paths (Tuple[str, ...]): The DICOM registration file paths provided.
+            image_infos (Tuple[DicomSeriesImageInfo, ...]): The available
+             :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries.
+
+        Returns:
+            Tuple[DicomSeriesRegistrationInfo, ...]: The retrieved
+             :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries.
+        """
+        infos = []
+
+        for path in registration_paths:
+            registration_info = DicomSeriesRegistrationInfo(path, image_infos, persistent_image_infos=False)
+            infos.append(registration_info)
+
+        return tuple(infos)
+
+    @staticmethod
+    def _generate_rtss_info(rtss_paths: Tuple[str, ...]) -> Tuple[DicomSeriesRTSSInfo]:
+        """Generate the :class:`~pyradise.fileio.series_info.DicomSeriesRTStructureSetInfo` entries for the DICOM file
+        paths specified.
+
+        Args:
+            rtss_paths (Tuple[str, ...]): The DICOM RTSS file paths.
+
+        Returns:
+            Tuple[DicomSeriesRTStructureSetInfo, ...]: AThe retrieved
+             :class:`~pyradise.fileio.series_info.DicomSeriesRTStructureSetInfo` entries.
+        """
+        infos = []
+
+        for path in rtss_paths:
+            rtss_info = DicomSeriesRTSSInfo(path)
+            infos.append(rtss_info)
+
+        return tuple(infos)
+
+    def _export_modality_config(self, infos: Tuple[DicomSeriesInfo, ...]) -> None:
+        """Export the retrieved :class:`~pyradise.fileio.modality_config.ModalityConfiguration` to a file.
+
+        Args:
+            infos (Tuple[DicomSeriesInfo, ...]): The :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries
+             containing the information to export.
+
+        Returns:
+            None
+        """
+        config = ModalityConfiguration.from_dicom_series_info(infos)
+        config.to_file(os.path.join(self.path, self.config_file_name))
+
+    def _apply_modality_config(self, infos: Tuple[DicomSeriesImageInfo, ...]) -> None:
+        """Load the :class:`~pyradise.fileio.modality_config.ModalityConfiguration` from a file if available and apply
+        it to the specified :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries. If the
+        :class:`~pyradise.fileio.modality_config.ModalityConfiguration` file is not available and a
+        :class:`~pyradise.fileio.extraction.ModalityExtractor` is provided the extractor is used for modality
+        determination.
+
+        Args:
+            infos (Tuple[DicomSeriesImageInfo, ...]): The available
+             :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries to which the
+             loaded :class:`~pyradise.fileio.modality_config.ModalityConfiguration` can be applied.
+
+        Returns:
+            None
+        """
+        # try to apply the modality configuration if it exists
+        modality_file_path = ""
+        for root, _, files in os.walk(self.path):
+            for file in files:
+                if self.config_file_name in file:
+                    modality_file_path = os.path.join(root, file)
+                    break
+
+        # apply the modality configuration if it exists
+        if os.path.exists(modality_file_path):
+            config = ModalityConfiguration.from_file(modality_file_path)
+            config.add_modalities_to_info(infos)
+
+            if config.has_default_modalities():
+                warnings.warn("The modality configuration file contains at least one default modality.")
+
+            if config.has_duplicate_modalities():
+                raise ValueError(
+                    "The modalities from the modality configuration file contain at least one duplicate "
+                    "modality. This will cause ambiguity when loading the DICOM series."
+                )
+
+            if self.write_config:
+                warnings.warn("The modality configuration file already exists and will not be overwritten.")
+
+            return
+
+        # if no modality configuration file exists, try to apply the default configuration
+        else:
+            if self.modality_extractor is not None:
+                extraction_possible_for_all = True
+                for info in infos:
+                    modality = self.modality_extractor.extract(info.path[0])
+                    if modality is not None:
+                        info.set_modality(modality)
+                    else:
+                        info.set_modality(Modality.get_default())
+                        extraction_possible_for_all = False
+
+                config = ModalityConfiguration.from_dicom_series_info(infos)
+                if self.write_config:
+                    config.to_file(os.path.join(self.path, self.config_file_name))
+
+                if config.has_duplicate_modalities():
+                    raise ValueError(
+                        "The extracted modalities contain at least one duplicate modality. "
+                        "This will cause ambiguity when loading the DICOM series."
+                    )
+
+                if extraction_possible_for_all:
+                    return
+                else:
+                    warnings.warn(
+                        "Modality extraction failed for one DICOM series. The default modality will "
+                        "be used for the series which failed during modality extraction."
+                    )
+                    return
+
+            else:
+                config = ModalityConfiguration.from_dicom_series_info(infos)
+
+                if config.has_duplicate_modalities() and self.write_config is False:
+                    raise ValueError(
+                        "The extracted modalities contain at least one duplicate modality. "
+                        "This will cause ambiguity when loading the DICOM series. Use either a modality "
+                        "configuration file or a modality extractor to resolve this issue."
+                    )
+
+                if config.has_default_modalities() and self.write_config is False and len(config.configuration) > 1:
+                    raise ValueError(
+                        "The extracted modalities contain at least one default modality. "
+                        "This will cause ambiguity when loading the DICOM series. Use either a modality "
+                        "configuration file or a modality extractor to resolve this issue."
+                    )
+
+                if self.write_config:
+                    config.to_file(os.path.join(self.path, self.config_file_name))
+                    return
+
+                if not config.has_duplicate_modalities():
+                    return
+
+                raise ValueError(
+                    "The modality configuration file could not be found "
+                    f"in the specified path ({self.path}) and there is no modality extractor provided!"
+                )
+
+    def execute(self) -> Tuple[DicomSeriesInfo, ...]:
+        """Execute the crawling process to retrieve the :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries.
+
+        Returns:
+            Tuple[DicomSeriesInfo, ...]: The retrieved :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries.
+        """
+        # get the dicom file paths and sort them according to the file content
+        file_paths = self._get_dicom_files()
+        image_paths = self._get_image_files()
+
+        flat_image_paths = [path for paths in image_paths for path in paths]
+        remaining_paths = tuple(set(file_paths) - set(flat_image_paths))
+
+        registration_paths = self._get_registration_files(remaining_paths)
+        remaining_paths = tuple(set(remaining_paths) - set(registration_paths))
+
+        rtss_paths = self._get_rtss_files(remaining_paths)
+
+        # generate the series infos
+        image_infos = self._generate_image_infos(image_paths)
+        registration_infos = self._generate_registration_infos(registration_paths, image_infos)
+        rtss_infos = self._generate_rtss_info(rtss_paths)
+
+        # apply the modality config and write it to disk if requested
+        self._apply_modality_config(image_infos)
+
+        return image_infos + registration_infos + rtss_infos
+
+
+class DatasetDicomCrawler(Crawler):
+    """A crawler for retrieving :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries from a dataset directory
+    containing at least one subject directory with DICOM files (e.g. DICOM images, DICOM registrations, DICOM RTSS).
+    Files of other formats then DICOM will be ignored and can not be crawled with this type of crawler.
+
+    The :class:`DatasetDicomCrawler` is used for searching appropriate files within a specific dataset directory
+    containing at least one subject folder with DICOM files. If there is just one subject in a single directory to be
+    crawled we recommend using the :class:`SubjectDicomCrawler`. If you want to load a large dataset with many subjects,
+    we recommend using the iterative crawling approach instead of crawling the data via :meth:`execute` to reduce
+    memory consumption (see example below).
+
+    The prioritized method to extract the :class:`~pyradise.data.modality.Modality` for the retrieved images is the
+    usage of a modality configuration file. If no modality configuration file is available for a specific subject
+    directory the :class:`DatasetDicomCrawler` will try to extract the :class:`~pyradise.data.modality.Modality` from
+    the retrieved subject images using the :class:`~pyradise.fileio.extraction.ModalityExtractor`. If no
+    :class:`~pyradise.fileio.extraction.ModalityExtractor` is provided an exception will be raised.
+
+    The :class:`DatasetDicomCrawler` can be used to generate the modality configuration file skeletons for all
+    subjects in the dataset directory. In this case set the ``generate_modality_config`` parameter to ``True`` and
+    execute the crawling process. The generated modality configuration file skeletons will be saved in the appropriate
+    subject directories.
+
+    Important:
+        This crawler exclusively support the DICOM file format and does not support any other file format.
+
+    Example:
+
+        Demonstration of the iterative and the non-iterative loading approach:
+
+        >>> from pyradise.fileio import (DatasetDicomCrawler, SubjectLoader)
+        >>>
+        >>>
+        >>> def main_iterative_crawling(dataset_path: str) -> None:
+        >>>     # Create the crawler (using the modality configuration file)
+        >>>     crawler = DatasetDicomCrawler(dataset_path)
+        >>>
+        >>>     # Use the crawler iteratively (more memory efficient)
+        >>>     for series_info in crawler:
+        >>>         subject = SubjectLoader().load(series_info)
+        >>>         # Do something with the subject
+        >>>         print(subject.get_name())
+        >>>
+        >>>
+        >>> def main_crawling_using_execute_fn(dataset_path: str) -> None:
+        >>>     # Create the crawler (using the modality configuration file)
+        >>>     crawler = DatasetDicomCrawler(dataset_path)
+        >>>
+        >>>     # Use the crawler with the execute function
+        >>>     # (all series info entries are loaded in one step)
+        >>>     series_infos = crawler.execute()
+        >>>
+        >>>     # Iterate over the series infos
+        >>>     for series_info in series_infos:
+        >>>         subject = SubjectLoader().load(series_info)
+        >>>         # Do something with the subject
+        >>>         print(subject.get_name())
+
+    Args:
+        path (str): The dataset directory path to crawl.
+        modality_extractor (Optional[ModalityExtractor]): The modality extractor (default: None)
+        modality_config_file_name (str): The file name for the modality configuration file within the subject
+         directory (default: modality_config.json).
+        write_modality_config (bool): If True writes the modality configuration retrieved to the subject directory
+         (default: False).
+    """
+
+    def __init__(
+        self,
+        path: str,
+        modality_extractor: Optional[ModalityExtractor] = None,
+        modality_config_file_name: str = "modality_config.json",
+        write_modality_config: bool = False,
+    ) -> None:
+        super().__init__(path)
+        self.modality_extractor: Optional[ModalityExtractor] = modality_extractor
+        self.config_file_name = modality_config_file_name
+        self.write_config = write_modality_config
+
+        self.subject_dir_paths: Optional[str] = None
+
+        self.current_idx = 0
+        self.num_subjects = 0
+
+    @staticmethod
+    def _get_subject_dir_paths(path: str) -> Tuple[str, ...]:
+        """Get the paths of the subject directories containing DICOM files.
+
+        Args:
+            path (str): The base directory path which contain the subject directories.
+
+        Returns:
+            Tuple[str, ...]: Paths to all subject directories containing DICOM files.
+        """
+        # Search for all dicom files and sort them according to their patient id
+        subjects = {}
+        patient_id_tag = Tag(0x0010, 0x0020)  # Patient ID
+
+        for root, _, files in os.walk(path):
+            for file in files:
+                if file == "DICOMDIR":
+                    continue
+
+                file_path = os.path.join(root, file)
+
+                # check if file is a dicom file
+                if is_dicom_file(file_path):
+                    # get the patient id
+                    patient_id = str(load_dataset_tag(file_path, (patient_id_tag,)).get(patient_id_tag).value)
+
+                    # collect the file paths per patient id
+                    if patient_id not in subjects:
+                        subjects[patient_id] = file_path
+                    else:
+                        common_path = os.path.commonpath([subjects.get(patient_id), file_path])
+                        subjects[patient_id] = common_path
+
+        return tuple(sorted(subjects.values()))
+
+    def execute(self) -> Tuple[Tuple[DicomSeriesInfo, ...], ...]:
+        """Execute the crawling process to retrieve the :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries.
+
+        Returns:
+            Tuple[Tuple[DicomSeriesInfo, ...], ...]: The retrieved :class:`~pyradise.fileio.series_info.DicomSeriesInfo`
+             entries.
+        """
+        self.subject_dir_paths = self._get_subject_dir_paths(self.path)
+
+        subject_infos = []
+        for subject_dir_path in self.subject_dir_paths:
+            subject_info = SubjectDicomCrawler(
+                subject_dir_path, self.modality_extractor, self.config_file_name, self.write_config
+            ).execute()
+
+            subject_infos.append(subject_info) if subject_info else None
+
+        return tuple(subject_infos)
+
+    def __iter__(self) -> "DatasetDicomCrawler":
+        self.subject_dir_paths = self._get_subject_dir_paths(self.path)
+        self.num_subjects = len(self.subject_dir_paths)
+        self.current_idx = 0
+        return self
+
+    def __next__(self) -> Tuple[DicomSeriesInfo, ...]:
+        if self.current_idx < self.num_subjects:
+            subject_info = SubjectDicomCrawler(
+                self.subject_dir_paths[self.current_idx],
+                self.modality_extractor,
+                self.config_file_name,
+                self.write_config,
+            ).execute()
+            self.current_idx += 1
+            return subject_info
+
+        raise StopIteration
+
+    def __len__(self) -> int:
+        return self.num_subjects
```

### Comparing `pyradise-0.2.2/pyradise/fileio/dicom_conversion.py` & `pyradise-0.2.3/pyradise/fileio/dicom_conversion.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,2956 +1,2956 @@
-import itertools
-import warnings
-from abc import ABC, abstractmethod
-from copy import deepcopy
-from dataclasses import dataclass
-from datetime import datetime
-from typing import Any, Dict, List, Optional, Tuple, Union
-
-import cv2 as cv
-import itk
-import numpy as np
-import scipy
-import SimpleITK as sitk
-import vtkmodules.vtkCommonCore as vtk_ccore
-import vtkmodules.vtkCommonDataModel as vtk_dm
-import vtkmodules.vtkFiltersCore as vtk_fcore
-import vtkmodules.vtkFiltersHybrid as vtk_fhybrid
-import vtkmodules.vtkFiltersModeling as vtk_fmodel
-import vtkmodules.vtkImagingCore as vtk_icore
-import vtkmodules.vtkImagingGeneral as vtk_igen
-from pydicom import Dataset, FileDataset, Sequence
-from pydicom.dataset import FileMetaDataset
-from pydicom.tag import Tag
-from pydicom.uid import (PYDICOM_IMPLEMENTATION_UID, ImplicitVRLittleEndian,
-                         generate_uid)
-
-from pyradise.data import (IntensityImage, Modality, Organ, SegmentationImage,
-                           Subject, str_to_modality)
-from pyradise.utils import (chunkify, convert_to_itk_image,
-                            get_slice_direction, get_slice_position,
-                            get_spacing_between_slices, load_dataset,
-                            load_dataset_tag, load_datasets)
-
-from .series_info import (DicomSeriesImageInfo, DicomSeriesRegistrationInfo,
-                          DicomSeriesRTSSInfo, RegistrationInfo, SeriesInfo)
-
-__all__ = [
-    "Converter",
-    "DicomImageSeriesConverter",
-    "DicomRTSSSeriesConverter",
-    "SubjectToRTSSConverter",
-    "RTSSToSegmentConverter",
-    "SegmentToRTSSConverter2D",
-    "SegmentToRTSSConverter3D",
-    "RTSSMetaData",
-    "RTSSConverter2DConfiguration",
-    "RTSSConverter3DConfiguration",
-]
-
-ROI_GENERATION_ALGORITHMS = ["AUTOMATIC", "SEMIAUTOMATIC", "MANUAL"]
-
-COLOR_PALETTE = [
-    [255, 0, 255],
-    [0, 235, 235],
-    [255, 255, 0],
-    [255, 0, 0],
-    [0, 132, 255],
-    [0, 240, 0],
-    [255, 175, 0],
-    [0, 208, 255],
-    [180, 255, 105],
-    [255, 20, 147],
-    [160, 32, 240],
-    [0, 255, 127],
-    [255, 114, 0],
-    [64, 224, 208],
-    [0, 178, 47],
-    [220, 20, 60],
-    [238, 130, 238],
-    [218, 165, 32],
-    [255, 140, 190],
-    [0, 0, 255],
-    [255, 225, 0],
-]
-
-
-class Converter(ABC):
-    """An abstract base class for all :class:`Converter` classes. Typically, the :class:`Converter` classes are used to
-    convert DICOM data from and to other representations. For example, the :class:`DicomImageSeriesConverter` converts
-    DICOM image series to :class:`~pyradise.data.image.IntensityImage` instances and applies the associated DICOM
-    registration if provided.
-    """
-
-    @abstractmethod
-    def convert(self) -> Any:
-        """Convert the provided :class:`~pyradise.fileio.series_info.DicomSeriesInfo`.
-
-        Returns:
-            Any: The converted data.
-        """
-        raise NotImplementedError()
-
-
-class RTSSToSegmentConverter(Converter):
-    """A low-level DICOM-RTSS to SimpleITK image :class:`Converter` class converting the content of the DICOM-RTSS to
-    one or multiple SimpleITK images. In contrast to the :class:`DicomRTSSSeriesConverter` this class generates a dict
-    of binary :class:`SimpleITK.Image` instances and organ names instead of a tuple of
-    :class:`~pyradise.data.image.SegmentationImage` s.
-
-    Notes:
-        Typically, this class is not used directly by the user but via the :class:`DicomRTSSSeriesConverter` which
-        processes :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries directly.
-
-        This class can be used with a DICOM registration which will be applied to the reference image and the structure
-        set. However, the registration must reference the corresponding DICOM image, otherwise the registration will not
-        be applied.
-
-    Args:
-        rtss_dataset (Union[str, Dataset]): The path to the DICOM-RTSS file or DICOM-RTSS
-         :class:`~pydicom.dataset.Dataset`.
-        image_datasets (Union[Tuple[str], Tuple[Dataset]]): The path to the DICOM image files or the DICOM image
-         :class:`~pydicom.dataset.Dataset` entries which are referenced in the ``rtss_dataset``.
-        registration_dataset (Union[str, Dataset, None]): The path to a DICOM registration file or a DICOM
-         registration :class:`~pydicom.dataset.Dataset` entry which contains a reference to the DICOM image
-         (default: None).
-        fill_hole_search_distance (int): The search distance for the hole filling algorithm. If the search distance is
-         set to zero the hole filling algorithm is omitted. The search distance must be an odd number larger than 1
-         (default: 0).
-    """
-
-    def __init__(
-        self,
-        rtss_dataset: Union[str, Dataset],
-        image_datasets: Union[Tuple[str], Tuple[Dataset]],
-        registration_dataset: Union[str, Dataset, None] = None,
-        fill_hole_search_distance: int = 0,
-    ) -> None:
-        super().__init__()
-
-        # get the RTSS dataset and the referenced SeriesInstanceUID
-        if isinstance(rtss_dataset, str):
-            self.rtss_dataset: Dataset = load_dataset(rtss_dataset)
-        else:
-            self.rtss_dataset: Dataset = rtss_dataset
-        ref_series_uid = self._get_ref_series_instance(self.rtss_dataset)
-
-        # get the appropriate image datasets according to the RTSS
-        if isinstance(image_datasets[0], str):
-            self.rtss_image_datasets = self._load_ref_image_datasets(image_datasets, ref_series_uid)
-        else:
-            self.rtss_image_datasets = self._clean_image_datasets_for_rtss(image_datasets, ref_series_uid)
-
-        # get the registration dataset and the appropriate images
-        if not registration_dataset:
-            self.reg_dataset: Optional[Dataset] = None
-        elif isinstance(registration_dataset, str):
-            self.reg_dataset: Optional[Dataset] = load_dataset(registration_dataset)
-        elif isinstance(registration_dataset, Dataset):
-            self.reg_dataset: Optional[Dataset] = registration_dataset
-        self.reg_image_datasets = self._get_image_datasets_for_reg(image_datasets, self.reg_dataset)
-
-        # store the fill hole search distance
-        if fill_hole_search_distance == 0:
-            self.fill_hole_distance = 0
-        elif fill_hole_search_distance % 2 == 0:
-            raise ValueError("The fill hole search distance must be an odd number.")
-        elif fill_hole_search_distance == 1:
-            raise ValueError("The fill hole search distance must be larger than 1.")
-        else:
-            self.fill_hole_distance = fill_hole_search_distance
-
-        # validate the loaded data
-        self._validate_rtss_dataset(self.rtss_dataset)
-        self._validate_rtss_image_references(self.rtss_dataset, self.rtss_image_datasets)
-        self.reg_dataset: Optional[Dataset] = self._validate_registration_dataset(self.reg_dataset, self.rtss_dataset)
-
-    @staticmethod
-    def _get_ref_series_instance(rtss_dataset: Dataset) -> str:
-        """Get the referenced SeriesInstanceUID of the image series in the RTSS dataset.
-
-        Args:
-            rtss_dataset (Dataset): The RTSS dataset.
-
-        Returns:
-            str: The referenced SeriesInstanceUID of the image series.
-        """
-        ref_series_instance_uids = []
-        for ref_frame_of_ref in rtss_dataset.get("ReferencedFrameOfReferenceSequence", []):
-            for rt_ref_study in ref_frame_of_ref.get("RTReferencedStudySequence", []):
-                for rt_ref_series in rt_ref_study.get("RTReferencedSeriesSequence", []):
-                    si_uid = rt_ref_series.get("SeriesInstanceUID", None)
-                    if si_uid is not None:
-                        ref_series_instance_uids.append(str(si_uid))
-
-        if len(ref_series_instance_uids) > 1:
-            raise Exception(
-                f"Multiple ({len(ref_series_instance_uids)}) referenced SeriesInstanceUIDs "
-                "have been retrieved from the RTSS but only one is allowed!"
-            )
-
-        if not ref_series_instance_uids:
-            raise Exception("No referenced SeriesInstanceUID could be retrieved!")
-
-        return ref_series_instance_uids[0]
-
-    @staticmethod
-    def _load_ref_image_datasets(image_paths: Tuple[str], referenced_series_uid: str) -> Tuple[Dataset]:
-        """Load the appropriate image datasets which are referenced in the RTSS dataset.
-
-        Args:
-            image_paths (Tuple[str]): The paths to the image datasets.
-            referenced_series_uid (str): The referenced SeriesInstanceUID.
-
-        Returns:
-            Tuple[Dataset]: The referenced image datasets.
-        """
-        # check all image file paths for the referenced SeriesInstanceUID
-        ref_image_files = []
-        for image_path in image_paths:
-            image_dataset = load_dataset_tag(image_path, (Tag(0x0020, 0x000E),))
-            if image_dataset.get("SeriesInstanceUID", "") == referenced_series_uid:
-                ref_image_files.append(image_path)
-
-        # load the appropriate image datasets
-        ref_image_datasets = []
-        for ref_image_file in ref_image_files:
-            ref_image_datasets.append(load_dataset(ref_image_file))
-
-        ref_image_datasets.sort(key=get_slice_position, reverse=False)
-
-        return tuple(ref_image_datasets)
-
-    @staticmethod
-    def _clean_image_datasets_for_rtss(image_datasets: Tuple[Dataset], referenced_series_uid: str) -> Tuple[Dataset]:
-        """Clean the image datasets based on the referenced SeriesInstanceUID.
-
-        Args:
-            image_datasets (Tuple[Dataset]): The image Datasets which should be analyzed.
-            referenced_series_uid (str): The referenced SeriesInstanceUID to identify the appropriate images.
-
-        Returns:
-            Tuple[Dataset]: The image datasets which are referenced by the RTSS Dataset.
-        """
-        selected = [
-            image_dataset
-            for image_dataset in image_datasets
-            if image_dataset.get("SeriesInstanceUID", None) == referenced_series_uid
-        ]
-
-        selected.sort(key=get_slice_position, reverse=False)
-
-        return tuple(selected)
-
-    @staticmethod
-    def _get_image_datasets_for_reg(
-        image_datasets: Union[Tuple[Dataset, ...], Tuple[str, ...]], registration_dataset: Optional[Dataset]
-    ) -> Optional[Tuple[Dataset, ...]]:
-        """Get the image datasets for registration. This function outputs the datasets which are referenced within
-         the registration dataset.
-
-        Args:
-            image_datasets (Union[Tuple[Dataset, ...], Tuple[str, ...]]): The image datasets to analyze.
-            registration_dataset (Optional[Dataset]): The registration dataset containing the references.
-
-        Returns:
-            Optional[Tuple[Dataset, ...]]: The datasets being referenced within the registration.
-        """
-        if not registration_dataset:
-            return None
-
-        selected = []
-
-        ref_image_series = DicomSeriesRegistrationInfo.get_referenced_series_info(registration_dataset)
-        ref_series_uids = [ref_info.series_instance_uid for ref_info in ref_image_series]
-        ref_study_uids = [ref_info.study_instance_uid for ref_info in ref_image_series]
-
-        if isinstance(image_datasets[0], str):
-            for path in image_datasets:
-                dataset = load_dataset_tag(path, (Tag(0x0020, 0x000E), Tag(0x0020, 0x000D)))
-                criteria = (
-                    str(dataset.get("SeriesInstanceUID", "")) in ref_series_uids,
-                    str(dataset.get("StudyInstanceUID", "")) in ref_study_uids,
-                )
-                if all(criteria):
-                    selected.append(load_dataset(path))
-
-        else:
-            for image_dataset in image_datasets:
-                criteria = (
-                    str(image_dataset.get("SeriesInstanceUID", "")) in ref_series_uids,
-                    str(image_dataset.get("StudyInstanceUID", "")) in ref_study_uids,
-                )
-                if all(criteria):
-                    selected.append(image_dataset)
-
-        return tuple(selected)
-
-    @staticmethod
-    def _validate_rtss_dataset(rtss_dataset: Dataset) -> None:
-        """Validate if the RTSS dataset is containing the minimal data for conversion.
-
-        Args:
-            rtss_dataset (Dataset): The RTSS dataset to validate.
-
-        Returns:
-            None
-        """
-        criteria = (
-            rtss_dataset.get("SOPClassUID", "") == "1.2.840.10008.5.1.4.1.1.481.3",
-            hasattr(rtss_dataset, "ROIContourSequence"),
-            hasattr(rtss_dataset, "StructureSetROISequence"),
-            hasattr(rtss_dataset, "RTROIObservationsSequence"),
-        )
-
-        if not all(criteria):
-            raise Exception(f'The checked RTSS from subject {rtss_dataset.get("PatientID")} is invalid!')
-
-    # pylint: disable=use-a-generator
-    @staticmethod
-    def _validate_registration_dataset(reg_dataset: Optional[Dataset], rtss_dataset: Dataset) -> Optional[Dataset]:
-        """Validate the registration dataset if it contains the minimally required data for conversion. If the provided
-        information is insufficient this function will return None.
-
-        Args:
-            reg_dataset (Optional[Dataset]): The registration dataset to validate.
-            rtss_dataset (Dataset): The RTSS dataset containing the references.
-
-        Returns:
-            Optional[Dataset]: The valid registration dataset or None.
-        """
-
-        if not reg_dataset:
-            return None
-
-        # search for references in the registration dataset
-        reg_ref_instance_uids = []
-        for ref_study_item in reg_dataset.get("StudiesContainingOtherReferencedInstancesSequence", []):
-            for ref_series_item in ref_study_item.get("ReferencedSeriesSequence", []):
-                ref_series_instance_uid = ref_series_item.get("SeriesInstanceUID", None)
-                if ref_series_instance_uid:
-                    reg_ref_instance_uids.append(ref_series_instance_uid)
-
-        for ref_series_item in reg_dataset.get("ReferencedSeriesSequence", []):
-            ref_series_uid = ref_series_item.get("SeriesInstanceUID", None)
-            if ref_series_uid:
-                reg_ref_instance_uids.append(ref_series_uid)
-
-        # search for references in the rtss dataset
-        rtss_ref_instance_uids = []
-        for ref_frame_of_ref in rtss_dataset.get("ReferencedFrameOfReferenceSequence", []):
-            for rt_ref_study in ref_frame_of_ref.get("RTReferencedStudySequence", []):
-                for rt_ref_series in rt_ref_study.get("RTReferencedSeriesSequence", []):
-                    ref_series_uid = rt_ref_series.get("SeriesInstanceUID", None)
-                    if ref_series_uid:
-                        rtss_ref_instance_uids.append(ref_series_uid)
-
-        # check the criteria
-        criteria = (
-            reg_dataset.get("SOPClassUID", "") == "1.2.840.10008.5.1.4.1.1.66.1",
-            hasattr(reg_dataset, "RegistrationSequence"),
-            hasattr(reg_dataset, "ReferencedSeriesSequence"),
-            all([rt_reference in reg_ref_instance_uids for rt_reference in rtss_ref_instance_uids]),
-            len(reg_ref_instance_uids) != 0,
-        )
-
-        if not all(criteria):
-            print(f'The checked registration from subject {rtss_dataset.get("PatientID", "n/a")} is invalid!')
-            return None
-
-        return reg_dataset
-
-    @staticmethod
-    def _validate_rtss_image_references(rtss_dataset: Dataset, image_datasets: Tuple[Dataset]) -> None:
-        """Validate if the ReferencedSOPInstanceUIDs of the RTSS dataset are contained in the image datasets.
-
-        Args:
-            rtss_dataset (Dataset): The RTSS dataset to validate.
-            image_datasets (Tuple[Dataset]): The image datasets to be used for comparison.
-
-        Returns:
-            None
-        """
-        # get the ReferencedSOPInstanceUIDs from the RTSS dataset
-        ref_sop_instance_uids = []
-        for ref_frame_of_ref in rtss_dataset.get("ReferencedFrameOfReferenceSequence", []):
-            for rt_ref_study in ref_frame_of_ref.get("RTReferencedStudySequence", []):
-                for rt_ref_series in rt_ref_study.get("RTReferencedSeriesSequence", []):
-                    for contour_image_entry in rt_ref_series.get("ContourImageSequence", []):
-                        ref_sop_instance_uids.append(contour_image_entry.get("ReferencedSOPInstanceUID", ""))
-
-        # get MediaStorageSOPInstanceUIDs from the image datasets
-        image_sop_instance_uids = [entry.file_meta.get("MediaStorageSOPInstanceUID") for entry in image_datasets]
-
-        # check if all ReferencedSOPInstanceUIDs are contained in the image datasets
-        missing_sop_instance_uids = tuple(set(ref_sop_instance_uids) - set(image_sop_instance_uids))
-        if missing_sop_instance_uids:
-            raise ValueError(
-                "The following ReferencedSOPInstanceUIDs are missing in the image datasets: "
-                f"{missing_sop_instance_uids}"
-            )
-
-    @staticmethod
-    def _get_contour_sequence_by_roi_number(rtss_dataset: Dataset, roi_number: int) -> Optional[Sequence]:
-        """Get the ContourSequence by the ROINumber.
-
-        Args:
-            rtss_dataset (Dataset): The RT Structure Set dataset to retrieve the ContourSequence from.
-            roi_number (int): The ROINumber for which the ContourSequence should be returned.
-
-        Returns:
-            Optional[Sequence]: The ContourSequence with the corresponding ROINumber if available, otherwise
-             :class:`None`.
-        """
-        if rtss_dataset.get("ROIContourSequence", None) is None:
-            return None
-
-        for roi_contour_entry in rtss_dataset.get("ROIContourSequence", []):
-            if str(roi_contour_entry.get("ReferencedROINumber", None)) == str(roi_number):
-                if roi_contour_entry.get("ContourSequence", None) is None:
-                    return None
-                return roi_contour_entry.get("ContourSequence")
-
-        raise Exception(f"Referenced ROI number '{roi_number}' not found")
-
-    @staticmethod
-    def _create_empty_series_mask(image_datasets: Tuple[Dataset, ...]) -> np.ndarray:
-        """Create an empty numpy array with the shape according to the reference image.
-
-        Returns:
-            np.ndarray: The empty numpy array with appropriate shape.
-        """
-        rows = int(image_datasets[0].get("Rows"))
-        columns = int(image_datasets[0].get("Columns"))
-        num_slices = len(image_datasets)
-
-        return np.zeros((columns, rows, num_slices)).astype(bool)
-
-    @staticmethod
-    def _create_empty_slice_mask(image_dataset: Dataset) -> np.ndarray:
-        """Create an empty numpy array representing one slice of the output mask.
-
-        Args:
-            image_dataset (Dataset): The dataset providing the spatial information for the empty mask.
-
-        Returns:
-            np.ndarray: The empty slice numpy array.
-        """
-        columns = int(image_dataset.get("Columns"))
-        rows = int(image_dataset.get("Rows"))
-        return np.zeros((columns, rows)).astype(np.uint8)
-
-    @staticmethod
-    def _apply_transformation_to_3d_points(points: np.ndarray, transformation_matrix: np.ndarray) -> np.ndarray:
-        """Apply the provided transformation to multiple points in the 3D-space.
-
-        Args:
-            points (np.ndarray): The points to transform.
-            transformation_matrix (np.ndarray): The transformation matrix.
-
-        Notes:
-            1. Augment each point with a '1' as the fourth coordinate for homogeneous coordinates.
-            2. Multiply by a 4x4 transformation matrix
-            3. Throw away the adaptation for homogeneous coordinates
-
-        Returns:
-            np.ndarray: The transformed points.
-        """
-        vec = np.concatenate((points, np.ones((points.shape[0], 1))), axis=1)
-        return vec.dot(transformation_matrix.T)[:, :3]
-
-    @staticmethod
-    def _get_patient_to_pixel_transformation_matrix(image_datasets: Tuple[Dataset, ...]) -> np.ndarray:
-        """Get the patient to pixel transformation matrix from the first image dataset.
-
-        Args:
-            image_datasets (Tuple[Dataset, ...]): The datasets to retrieve the transformation matrix.
-
-        Returns:
-            np.ndarray: The transformation matrix.
-        """
-        offset = np.array(image_datasets[0].get("ImagePositionPatient"))
-        row_spacing, column_spacing = image_datasets[0].get("PixelSpacing")
-        slice_spacing = get_spacing_between_slices(image_datasets)
-        row_direction, column_direction, slice_direction = get_slice_direction(image_datasets[0])
-
-        linear = np.identity(3, dtype=float)
-        linear[0, :3] = row_direction / row_spacing
-        linear[1, :3] = column_direction / column_spacing
-        linear[2, :3] = slice_direction / slice_spacing
-
-        mat = np.identity(4, dtype=float)
-        mat[:3, :3] = linear
-        mat[:3, 3] = offset.dot(-linear.T)
-
-        return mat
-
-    @staticmethod
-    def _get_slice_contour_data(image_dataset: Dataset, contour_sequence: Sequence) -> Tuple[Any, ...]:
-        """Get the contour data from the corresponding ContourSequence.
-
-        Args:
-            image_dataset (Dataset): The referenced image dataset.
-            contour_sequence (Sequence): The ContourSequence.
-
-        Returns:
-            Tuple[Any, ...]: The retrieved ContourData.
-        """
-        slice_contour_data = []
-
-        for contour in contour_sequence:
-            for contour_image in contour.get("ContourImageSequence", []):
-                if contour_image.get("ReferencedSOPInstanceUID", None) == image_dataset.get("SOPInstanceUID", "1"):
-                    slice_contour_data.append(contour.get("ContourData", []))
-
-        return tuple(slice_contour_data)
-
-    @staticmethod
-    def _get_slice_mask_from_slice_contour_data(
-        image_dataset: Dataset, contour_data: Tuple[Any, ...], transformation_matrix: np.ndarray
-    ) -> np.ndarray:
-        """Get the slice mask from the ContourData.
-
-        Args:
-            image_dataset (Dataset): The referenced image dataset.
-            contour_data (Tuple[Any, ...]): The contour data.
-            transformation_matrix (np.ndarray): The transformation matrix.
-
-        Returns:
-            np.ndarray: The discrete slice mask.
-        """
-        raw_polygons = []
-        for contour_coords in contour_data:
-            reshaped_contour_data = np.reshape(contour_coords, [len(contour_coords) // 3, 3])
-            translated_contour_data = RTSSToSegmentConverter._apply_transformation_to_3d_points(
-                reshaped_contour_data, transformation_matrix
-            )
-            polygon = [np.around([translated_contour_data[:, :2]]).astype(int)]
-            polygon = np.array(polygon).squeeze()
-            if polygon.shape[0] > 2:
-                raw_polygons.append(polygon.astype(int))
-
-        slice_mask = RTSSToSegmentConverter._create_empty_slice_mask(image_dataset)
-        cv.fillPoly(img=slice_mask, pts=raw_polygons, color=1)
-        return slice_mask
-
-    @staticmethod
-    def _create_mask_from_contour_sequence(
-        image_datasets: Tuple[Dataset, ...], contour_sequence: Sequence
-    ) -> np.ndarray:
-        """Create the whole 3D mask from the ContourSequence.
-
-        Args:
-            image_datasets (Tuple[Dataset, ...]): The image datasets to be used for mask creation.
-            contour_sequence (Sequence): The ContourSequence to be discretized.
-
-        Returns:
-            np.ndarray: The discrete segmentation mask.
-        """
-        mask = RTSSToSegmentConverter._create_empty_series_mask(image_datasets)
-        transformation_matrix = RTSSToSegmentConverter._get_patient_to_pixel_transformation_matrix(image_datasets)
-
-        for i, image_dataset in enumerate(image_datasets):
-            slice_contour_data = RTSSToSegmentConverter._get_slice_contour_data(image_dataset, contour_sequence)
-            if slice_contour_data:
-                mask[:, :, i] = RTSSToSegmentConverter._get_slice_mask_from_slice_contour_data(
-                    image_dataset, slice_contour_data, transformation_matrix
-                )
-
-        return mask
-
-    @staticmethod
-    def _create_image_from_mask(image_datasets: Tuple[Dataset, ...], mask: np.ndarray) -> sitk.Image:
-        """Create an image from the numpy segmentation mask with appropriate orientation.
-
-        Args:
-            image_datasets (Tuple[Dataset, ...]): The image datasets used to create the image.
-            mask (np.ndarray): The mask to be converted into a sitk.Image.
-
-        Returns:
-            sitk.Image: The image generated.
-        """
-        mask = np.swapaxes(mask, 0, 2)
-        mask = np.swapaxes(mask, 1, 2)
-
-        image = sitk.GetImageFromArray(mask.astype(np.uint8))
-        image = sitk.Cast(image, sitk.sitkUInt8)
-
-        image.SetOrigin(image_datasets[0].get("ImagePositionPatient"))
-
-        row_spacing, column_spacing = image_datasets[0].get("PixelSpacing")
-        slice_spacing = get_spacing_between_slices(image_datasets)
-        image.SetSpacing((float(row_spacing), float(column_spacing), float(slice_spacing)))
-
-        slice_direction = np.stack(get_slice_direction(image_datasets[0]), axis=0).astype(float).T.flatten()
-        slice_direction = slice_direction.tolist()
-        image.SetDirection(slice_direction)
-
-        return image
-
-    @staticmethod
-    def _get_transform_from_registration_info(registration_infos: Tuple[RegistrationInfo, ...]) -> sitk.Transform:
-        """Get the transformation from the registration infos.
-
-        Args:
-            registration_infos (Tuple[RegistrationInfo]): Registration info entries which hold transformations and
-             references.
-
-        Returns:
-            sitk.Transform: The transformation which is not an identity transformation.
-        """
-        assert len(registration_infos) <= 2, (
-            "The number of registration infos must be at max two but is " f"{len(registration_infos)}!"
-        )
-
-        transforms = []
-        for registration_info in registration_infos:
-            if not registration_info.is_reference_image:
-                transforms = registration_info.registration_info.transforms
-
-        if len(transforms) != 1:
-            raise NotImplementedError("The use of multiple sequential transformations is currently not supported!")
-
-        return transforms[0]
-
-    @staticmethod
-    def _transform_image_datasets(
-        image_datasets: Tuple[Dataset, ...], transform: sitk.Transform
-    ) -> Tuple[Dataset, ...]:
-        """Apply the transformation to multiple image datasets.
-
-        Args:
-            image_datasets (Tuple[Dataset, ...]): The image datasets to be transformed.
-            transform (sitk.Transform): The transformation to be applied.
-
-        Returns:
-            Tuple[Dataset, ...]: The transformed image datasets.
-        """
-
-        transformed_image_datasets = []
-
-        for image_dataset in image_datasets:
-            # transform the patient position
-            image_position_patient = image_dataset.get("ImagePositionPatient")
-            position_transformed = list(transform.GetInverse().TransformPoint(image_position_patient))
-            image_dataset["ImagePositionPatient"].value = position_transformed
-
-            # transform the image orientation
-            image_orientation_patient = image_dataset.get("ImageOrientationPatient")
-            vector_0 = np.array(image_orientation_patient[:3])
-            vector_1 = np.array(image_orientation_patient[3:6])
-
-            vector_0_transformed = transform.GetInverse().TransformVector(vector_0, (0, 0, 0))
-            vector_1_transformed = transform.GetInverse().TransformVector(vector_1, (0, 0, 0))
-
-            new_direction = list(vector_0_transformed + vector_1_transformed)
-            image_dataset["ImageOrientationPatient"].value = new_direction
-
-            transformed_image_datasets.append(image_dataset)
-
-        return image_datasets
-
-    @staticmethod
-    def _transform_rtss_dataset(rtss_dataset: Dataset, transform: sitk.Transform) -> Dataset:
-        """Apply the transformation to the RTSS.
-
-        Args:
-            rtss_dataset (Dataset): The dataset to be transformed.
-            transform (sitk.Transform): The transformation to apply.
-
-        Returns:
-            Dataset: The transformed dataset.
-        """
-        dataset = deepcopy(rtss_dataset)
-
-        for roi_contour in dataset.get("ROIContourSequence", []):
-            for contour_sequence_item in roi_contour.get("ContourSequence", []):
-                contour_data = contour_sequence_item.get("ContourData")
-
-                if len(contour_data) % 3 != 0:
-                    raise ValueError("The number of contour points must be a multiple of three!")
-
-                transformed_points = []
-
-                for chunk in chunkify(contour_data, 3):
-                    transformed_point = list(transform.GetInverse().TransformPoint(np.array(chunk)))
-                    transformed_points.extend(transformed_point)
-
-                contour_sequence_item["ContourData"].value = transformed_points
-
-        return dataset
-
-    @staticmethod
-    def _fill_holes_in_mask(
-        mask: np.ndarray,
-        search_radius: int = 5,
-    ) -> np.ndarray:
-        """Fill holes in a binary mask using morphological closing.
-
-        Args:
-            mask (np.ndarray): The mask to fill holes in.
-            search_radius (int): The radius to search for holes.
-
-        Returns:
-            np.ndarray: The mask with filled holes.
-        """
-
-        # get the bounding box of the mask
-        bb = []
-        for ax in itertools.combinations(reversed(range(mask.ndim)), mask.ndim - 1):
-            nonzero = np.any(mask, axis=ax)
-            bb.extend(np.where(nonzero)[0][[0, -1]])
-
-        # extend the bounding box by the search radius
-        bb = np.array(bb)
-        bb[::2] = np.maximum(bb[::2] - search_radius, 0)
-        bb[1::2] = np.minimum(bb[1::2] + search_radius, mask.shape)
-
-        if mask.ndim == 3:
-            inner_mask = mask[bb[0] : bb[1], bb[2] : bb[3], bb[4] : bb[5]]
-        else:
-            inner_mask = mask[bb[0] : bb[1], bb[2] : bb[3]]
-
-        # fill the holes in the inner mask
-        structure = np.ones(tuple([search_radius for _ in range(mask.ndim)]), dtype=int)
-        inner_mask = scipy.ndimage.binary_fill_holes(inner_mask, structure).astype(np.bool)
-
-        # remove additional unconnected single voxel segmentations
-        inner_mask2 = np.copy(inner_mask).astype(np.uint8)
-        id_regions, num_ids = scipy.ndimage.label(inner_mask, structure=np.ones(tuple([3 for _ in range(mask.ndim)])))
-        id_sizes = np.array(scipy.ndimage.sum(inner_mask, id_regions, range(num_ids + 1)))
-        area_mask = id_sizes == 1
-        inner_mask2[area_mask[id_regions]] = 0
-        inner_mask = inner_mask2.astype(np.bool)
-
-        # insert the inner mask into the original mask
-        new_mask = np.zeros_like(mask, dtype=np.uint8)
-        if mask.ndim == 3:
-            new_mask[bb[0] : bb[1], bb[2] : bb[3], bb[4] : bb[5]] = inner_mask
-        else:
-            new_mask[bb[0] : bb[1], bb[2] : bb[3]] = inner_mask
-
-        return new_mask
-
-    def convert(self) -> Dict[str, sitk.Image]:
-        """Convert a DICOM-RTSS :class:`~pydicom.dataset.Dataset` instance into a dict of binary
-        :class:`SimpleITK.Image` instances including their associated ROINames as a key in the dict.
-
-        Returns:
-            Dict[str, sitk.Image]: The ROINames and the corresponding binary segmented :class:`SimpleITK.Image`
-            instances.
-        """
-        converted_images = {}
-
-        # apply the registration if available
-        if self.reg_dataset:
-            reg_infos = DicomSeriesRegistrationInfo.get_registration_infos(self.reg_dataset, self.reg_image_datasets)
-            transform = self._get_transform_from_registration_info(reg_infos)
-            image_datasets = self._transform_image_datasets(self.rtss_image_datasets, transform)
-            rtss_dataset = self._transform_rtss_dataset(self.rtss_dataset, transform)
-
-        else:
-            image_datasets = self.rtss_image_datasets
-            rtss_dataset = self.rtss_dataset
-
-        # convert the contours to images
-        for ss_roi in rtss_dataset.get("StructureSetROISequence", []):
-            roi_number = int(ss_roi.get("ROINumber"))
-            roi_name = str(ss_roi.get("ROIName", ""))
-
-            contour_sequence = self._get_contour_sequence_by_roi_number(rtss_dataset, roi_number)
-
-            if contour_sequence is None:
-                continue
-
-            # create the mask from the contours
-            mask = self._create_mask_from_contour_sequence(image_datasets, contour_sequence)
-
-            # fill holes in the mask
-            if self.fill_hole_distance > 0:
-                mask = self._fill_holes_in_mask(mask, search_radius=5)
-
-            # create the image from the mask
-            image = self._create_image_from_mask(image_datasets, mask)
-            converted_images.update({roi_name: image})
-
-        return converted_images
-
-
-@dataclass
-class RTSSMetaData:
-    """A class to define metadata of a new DICOM-RTSS dataset.
-
-    Note:
-        Some attributes can take ``None`` as a value. This means that the attribute will be copied from the reference
-        DICOM image dataset.
-
-    Note:
-        For some attributes, the value must follow the value representation of the DICOM standard. For example, the
-        ``PatientSex`` attribute must be either ``'M'``, ``'F'``, or ``'O'``. For more information, we refer to the
-        `DICOM standard part 5 chapter 6.2 <https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html>`_.
-
-    Args:
-        patient_name (Optional[str]): The patient name.
-        patient_id (Optional[str]): The patient ID.
-        patient_birth_date (Optional[str]): The patient birth date (format: YYYYMMDD).
-        patient_sex (Optional[str]): The patient sex (valid values: 'F' (female), 'M' (male), 'O' (other)).
-        patient_weight (Optional[str]): The patient weight (unit: kilograms with decimals).
-        patient_size (Optional[str]): The patient size (unit: meters with decimals).
-        study_description (Optional[str]): The study description.
-        series_description (Optional[str]): The series description.
-        series_number (Optional[str]): The series number (default: '99').
-        structure_set_label (str): The structure set label (default: 'Autogenerated').
-        operators_name (str): The operator's name (default: 'NA').
-        manufacturer (str): The manufacturer (default: 'University of Bern, Switzerland').
-        manufacturer_model_name (str): The manufacturer model name (default: 'PyRaDiSe Package').
-        institution_name (str): The institution name (default: 'Unknown Institution').
-        referring_physician_name (str): The referring physician name (default: 'NA').
-        approval_status (str): The approval status (valid values: 'APPROVED', 'UNAPPROVED', 'REJECTED',
-         default: 'UNAPPROVED').
-        roi_gen_algorithm (str): The ROI generation algorithm (valid values: 'AUTOMATIC', 'SEMIAUTOMATIC', 'MANUAL',
-         default: 'AUTOMATIC').
-
-    """
-
-    patient_name: Optional[str] = None
-    patient_id: Optional[str] = None
-    patient_birth_date: Optional[str] = None
-    patient_sex: Optional[str] = None
-    patient_age: Optional[str] = None
-    patient_weight: Optional[str] = None
-    patient_size: Optional[str] = None
-    study_description: Optional[str] = None
-    series_description: Optional[str] = None
-    series_number: str = "99"
-    structure_set_label: str = "Autogenerated"
-    operators_name: str = "NA"
-    manufacturer: str = "University of Bern, Switzerland"
-    manufacturer_model_name: str = "PyRaDiSe Package"
-    institution_name: str = "Unknown Institution"
-    referring_physician_name: str = "NA"
-    approval_status: str = "UNAPPROVED"
-    roi_gen_algorithm: str = "AUTOMATIC"
-
-    def __post_init__(self) -> None:
-        # validate entries
-        criteria = (
-            isinstance(self.patient_name, str) or self.patient_name is None,
-            isinstance(self.patient_id, str) or self.patient_id is None,
-            isinstance(self.patient_birth_date, str) or self.patient_birth_date is None,
-            isinstance(self.patient_sex, str) or self.patient_sex is None,
-            isinstance(self.patient_age, str) or self.patient_age is None,
-            isinstance(self.patient_weight, str) or self.patient_weight is None,
-            isinstance(self.patient_size, str) or self.patient_size is None,
-            isinstance(self.study_description, str) or self.study_description is None,
-            isinstance(self.series_description, str) or self.series_description is None,
-            isinstance(self.series_number, str),
-            isinstance(self.structure_set_label, str),
-            isinstance(self.operators_name, str),
-            isinstance(self.manufacturer, str),
-            isinstance(self.manufacturer_model_name, str),
-            isinstance(self.institution_name, str),
-            isinstance(self.referring_physician_name, str),
-            isinstance(self.approval_status, str) and self.approval_status in ("APPROVED", "UNAPPROVED", "REJECTED"),
-            isinstance(self.roi_gen_algorithm, str)
-            and self.roi_gen_algorithm
-            in (
-                "AUTOMATIC",
-                "SEMIAUTOMATIC",
-                "MANUAL",
-            ),
-        )
-
-        if not all(criteria):
-            raise ValueError("The RTSS meta data is not valid! Please check the input values.")
-
-
-class RTSSConverterConfiguration(ABC):
-    """An abstract base class to parameterize a segment to DICOM-RTSS converter."""
-
-    def __init__(self) -> None:
-        super().__init__()
-        self.general_params: Dict[str, Any] = {}
-        self.image_specific_params: Dict[str, Dict[str, Any]] = {}
-
-    @abstractmethod
-    def set_general_params(self, **kwargs: Any) -> None:
-        """Set the general parameters of the converter.
-
-        Args:
-            **kwargs: The parameters of the converter.
-
-        Returns:
-            None
-        """
-        raise NotImplementedError()
-
-    def get_general_params(self, name: Optional[str] = None) -> Optional[Union[Dict[str, Any], Any]]:
-        """Get all or a specific general parameter for the converter.
-
-        Args:
-            name (Optional[str]): The name of the parameter to get. If ``None``, all parameters are returned
-             (default: None).
-
-        Returns:
-            Optional[Union[Dict[str, Any], Any]]: All or the selected parameter.
-        """
-        if name is None:
-            if self.general_params:
-                return self.general_params
-            return None
-
-        return self.general_params.get(name, None)
-
-    @abstractmethod
-    def set_image_params(self, **kwargs: Any) -> None:
-        """Set the parameters of the converter for a specific image using an identifier.
-        instance.
-
-        Args:
-            **kwargs: The parameters of the converter.
-
-        Returns:
-            None
-        """
-        raise NotImplementedError()
-
-    def get_image_params(
-        self, image_identifier: str, name: Optional[str] = None
-    ) -> Optional[Union[Dict[str, Any], Any]]:
-        """Get all parameters for a specific image using its identifier.
-
-        Args:
-            image_identifier (str): The identifier of the image
-            name (Optional[str]): The name of the parameter to get. If ``None``, all parameters are returned (default:
-             None).
-
-        Returns:
-            Optional[Union[Dict[str, Any], Any]]: All or the selected parameter belonging to the specific image
-
-        """
-        if image_identifier not in self.image_specific_params:
-            return None
-
-        specific = self.image_specific_params[image_identifier]
-        if name is None:
-            if specific:
-                return specific
-            return None
-        return specific.get(name, None)
-
-
-class RTSSConverter2DConfiguration(RTSSConverterConfiguration):
-    """A configuration class to parameterize a :class:`SegmentToRTSSConverter2D` instance.
-
-    The configuration can be used to set the general and image specific conversion parameters of the converter.
-    The general parameters are applied to all images except if image specific parameters are provided.
-    used for the image.
-
-    The parameters define the following:
-
-    * ``smoothing``: Indicates if Gaussian smoothing is applied.
-
-    * ``smoothing_sigma``: The variance of the discrete Gaussian smoothing kernel.
-
-    * ``smoothing_kernel_size``: The size of the discrete Gaussian smoothing kernel.
-
-    Args:
-        smoothing (bool): Whether to smooth the contours or not (default: True).
-        smoothing_sigma (float): The variance of the Gaussian smoothing (default: 1.0).
-        smoothing_kernel_size (int): The size of the Gaussian smoothing kernel (default: 8).
-    """
-
-    def __init__(
-        self,
-        smoothing: bool = True,
-        smoothing_sigma: float = 1.0,
-        smoothing_kernel_size: int = 8,
-    ) -> None:
-        super().__init__()
-
-        self._validate_entries(smoothing, smoothing_sigma, smoothing_kernel_size)
-
-        self.set_general_params(smoothing, smoothing_sigma, smoothing_kernel_size)
-
-    @staticmethod
-    def _validate_entries(
-        smoothing: bool,
-        smoothing_sigma: float,
-        smoothing_kernel_size: int,
-    ) -> None:
-        """Validate the entries of the configuration.
-
-        Args:
-            smoothing (bool): Whether to smooth the contours or not.
-            smoothing_sigma (float): The variance of the Gaussian smoothing.
-            smoothing_kernel_size (int): The size of the Gaussian smoothing kernel.
-
-        Raises:
-            ValueError: If the entries are not valid.
-
-        Returns:
-            None
-        """
-        criteria = (
-            isinstance(smoothing, bool),
-            isinstance(smoothing_sigma, float) and smoothing_sigma > 0,
-            isinstance(smoothing_kernel_size, int) and smoothing_kernel_size > 0,
-        )
-
-        if not all(criteria):
-            raise ValueError("The RTSS converter configuration is not valid! Please check the input values.")
-
-    def set_general_params(
-        self,
-        smoothing: bool,
-        smoothing_sigma: float,
-        smoothing_kernel_size: int,
-    ) -> None:
-        """Set the general parameters for all images except those that have specific parameters.
-
-        Args:
-            smoothing (bool): Whether to apply Gaussian smoothing.
-            smoothing_sigma (float): The sigma of the Gaussian filter.
-            smoothing_kernel_size (int): The kernel size of the Gaussian filter.
-
-        Returns:
-            None
-        """
-        self._validate_entries(smoothing, smoothing_sigma, smoothing_kernel_size)
-
-        self.general_params["smoothing"] = smoothing
-        self.general_params["smoothing_sigma"] = smoothing_sigma
-        self.general_params["smoothing_kernel_size"] = smoothing_kernel_size
-
-    def set_image_params(
-        self, image_identifier: str, smoothing: bool, smoothing_sigma: float, smoothing_kernel_size: int
-    ) -> None:
-        """Set the parameters of the converter for a specific image using the :class:`~pyradise.data.organ.Organ`
-        instance.
-
-        Args:
-            image_identifier (str): The image to set the parameter(s) for.
-            smoothing (bool): Whether to apply Gaussian smoothing to the image.
-            smoothing_sigma (float): The sigma value for the Gaussian smoothing kernel.
-            smoothing_kernel_size (int): The kernel size for the Gaussian smoothing kernel.
-
-        Returns:
-            None
-        """
-        self._validate_entries(smoothing, smoothing_sigma, smoothing_kernel_size)
-
-        self.image_specific_params[image_identifier] = {
-            "smoothing": smoothing,
-            "smoothing_sigma": smoothing_sigma,
-            "smoothing_kernel_size": smoothing_kernel_size,
-        }
-
-
-class RTSSConverter3DConfiguration(RTSSConverterConfiguration):
-    """A configuration class to parameterize a :class:`SegmentToRTSSConverter3D` instance.
-
-    The configuration can be used to set the general and image specific conversion parameters of the converter.
-    The general parameters are applied to all images except if image specific parameters are provided.
-    used for the image.
-
-    The parameters define the following:
-
-    * ``image_smoothing``: Whether to apply Gaussian smoothing to the image before 3D model construction.
-
-    * ``image_smoothing_sigma``: The standard deviation value for the Gaussian smoothing kernel.
-
-    * ``image_smoothing_radius``: The radius of the Gaussian smoothing kernel.
-
-    * ``image_smoothing_threshold``: The threshold value for the Gaussian smoothing. All segmentation masks that
-      have less foreground voxels than this threshold are not smoothed to avoid deletion.
-
-    * ``decimate_reduction``: The reduction factor for the decimation of the 3D model. This factor defines how much
-      vertices are removed from the model during the decimation process (0 = none, 1: all).
-
-    * ``decimate_threshold``: The threshold value for the decimation of the 3D model. All models that arise from a
-      segmentation mask with less than the threshold number of foreground voxels are not decimated to avoid
-      deletion.
-
-    * ``model_smoothing_iterations``: The number of iterations for the smoothing of the 3D model (Sinc-Filter).
-      Typically, 10 to 20 iterations are sufficient for smoothing.
-
-    * ``model_smoothing_pass_band``: The pass band for the smoothing of the 3D model (Sinc-Filter). The closer this
-      value is to zero (e.g., 0.001) the stronger the smoothing is. The higher the value (e.g., 0.4) the less the
-      smoothing is.
-
-    * ``min_segment_lines``: The minimum number of lines that a segment must have to be considered for the RTSS. All
-      segments smaller than this value are discarded.
-
-
-    Args:
-        image_smoothing (bool): Whether to smooth the image before 3D model construction or not (default: False).
-        image_smoothing_sigma (float): The standard deviation of the Gaussian smoothing before 3D model construction
-         (default: 2.).
-        image_smoothing_radius (float): The radius of the Gaussian smoothing before 3D model construction (default: 1.).
-        image_smoothing_threshold (float): The minimum number of foreground voxels that must be contained in the
-         segmentation mask to trigger Gaussian smoothing (default: 0).
-        decimate_reduction (float): The reduction factor for the 3D decimation. The decimation factor is valid
-         between 0 and 1 and the lower it is the more smoothing is applied (default: 0.5).
-        decimate_threshold (float): The minimum number of foreground voxels that must be contained in the
-         segmentation mask to trigger 3D decimation (default: 0).
-        model_smoothing_iterations (int): The number of 3D smoothing steps (typically 10 - 20 steps) (default: 10).
-        model_smoothing_pass_band (bool): The strength of the 3D smoothing (0.001 - 0.1 = strong smoothing,
-         0.1 - 0.5 = intermediate smoothing, 0.5 - 1 = almost no smoothing) (default: 0.25).
-        min_segment_lines (int): The minimum number of lines that a segment must have to be considered for the RTSS
-         (default: 0).
-    """
-
-    def __init__(
-        self,
-        image_smoothing: bool = False,
-        image_smoothing_sigma: float = 2.0,
-        image_smoothing_radius: float = 1.0,
-        image_smoothing_threshold: float = 0.0,
-        decimate_reduction: float = 0.5,
-        decimate_threshold: float = 0.0,
-        model_smoothing_iterations: int = 10,
-        model_smoothing_pass_band: float = 0.25,
-        min_segment_lines: int = 0,
-    ) -> None:
-        super().__init__()
-
-        self.set_general_params(
-            image_smoothing,
-            image_smoothing_sigma,
-            image_smoothing_radius,
-            image_smoothing_threshold,
-            decimate_reduction,
-            decimate_threshold,
-            model_smoothing_iterations,
-            model_smoothing_pass_band,
-            min_segment_lines,
-        )
-
-    @staticmethod
-    def _validate_entries(
-        image_smoothing: bool,
-        image_smoothing_sigma: float,
-        image_smoothing_radius: float,
-        image_smoothing_threshold: float,
-        decimate_reduction: float,
-        decimate_threshold: float,
-        model_smoothing_iterations: int,
-        model_smoothing_pass_band: float,
-        min_segment_lines: int,
-    ) -> None:
-        """Validate the entries of the configuration.
-
-        Args:
-            image_smoothing (bool): Whether to smooth the image before 3D model construction or not.
-            image_smoothing_sigma (float): The standard deviation of the Gaussian smoothing before 3D model
-             construction.
-            image_smoothing_radius (float): The radius of the Gaussian smoothing before 3D model construction.
-            image_smoothing_threshold (float): The minimum number of foreground voxels that must be contained in the
-             segmentation mask to trigger Gaussian smoothing.
-            decimate_reduction (float): The reduction factor for the 3D decimation. The decimation factor is valid
-             between 0 and 1 and the lower it is the more smoothing is applied.
-            decimate_threshold (float): The minimum number of foreground voxels that must be contained in the
-             segmentation mask to trigger 3D decimation.
-            model_smoothing_iterations (int): The number of 3D smoothing steps (typically 15 - 20 steps).
-            model_smoothing_pass_band (float): The strength of the 3D smoothing (0.001 - 0.1 = strong smoothing,
-             0.5 - 1 = almost no smoothing).
-            min_segment_lines (int): The minimum number of lines that a segment must have to be considered for the RTSS.
-
-        Raises:
-            ValueError: If the entries are not valid.
-
-        Returns:
-            None
-        """
-        criteria = (
-            isinstance(image_smoothing, bool),
-            isinstance(image_smoothing_sigma, float) and image_smoothing_sigma > 0,
-            isinstance(image_smoothing_radius, float) and image_smoothing_radius > 0,
-            isinstance(image_smoothing_threshold, (float, int)) and image_smoothing_threshold >= 0,
-            isinstance(decimate_reduction, float) and 0 < decimate_reduction < 0.99,
-            isinstance(decimate_threshold, (float, int)) and decimate_threshold >= 0,
-            isinstance(model_smoothing_iterations, int) and model_smoothing_iterations >= 0,
-            isinstance(model_smoothing_pass_band, float),
-            isinstance(min_segment_lines, int),
-        )
-
-        if not all(criteria):
-            raise ValueError("The RTSS converter configuration is not valid! Please check the input values.")
-
-    def set_general_params(
-        self,
-        image_smoothing: bool,
-        image_smoothing_sigma: float,
-        image_smoothing_radius: float,
-        image_smoothing_threshold: float,
-        decimate_reduction: float,
-        decimate_threshold: float,
-        model_smoothing_iterations: int,
-        model_smoothing_pass_band: float,
-        min_segment_lines: int,
-    ) -> None:
-        """Set the general parameters for all images except those that have specific parameters.
-
-        Args:
-            image_smoothing (bool): Whether to smooth the image before 3D model construction or not.
-            image_smoothing_sigma (float): The standard deviation of the Gaussian smoothing before 3D model
-             construction.
-            image_smoothing_radius (float): The radius of the Gaussian smoothing before 3D model construction.
-            image_smoothing_threshold (float): The minimum number of foreground voxels that must be contained in the
-             segmentation mask to trigger Gaussian smoothing.
-            decimate_reduction (float): The reduction factor for the 3D decimation. The decimation factor is valid
-             between 0 and 1 and the lower it is the more smoothing is applied.
-            decimate_threshold (float): The minimum number of foreground voxels that must be contained in the
-             segmentation mask to trigger 3D decimation.
-            model_smoothing_iterations (int): The number of 3D smoothing steps (typically 15 - 20 steps).
-            model_smoothing_pass_band (bool): The strength of the 3D smoothing (0.001 - 0.1 = strong smoothing,
-             0.5 - 1 = almost no smoothing).
-            min_segment_lines (int): The minimum number of lines that a segment must have to be considered for the RTSS.
-
-        Returns:
-            None
-        """
-        self._validate_entries(
-            image_smoothing,
-            image_smoothing_sigma,
-            image_smoothing_radius,
-            image_smoothing_threshold,
-            decimate_reduction,
-            decimate_threshold,
-            model_smoothing_iterations,
-            model_smoothing_pass_band,
-            min_segment_lines,
-        )
-
-        self.general_params["image_smoothing"] = image_smoothing
-        self.general_params["image_smoothing_sigma"] = image_smoothing_sigma
-        self.general_params["image_smoothing_radius"] = image_smoothing_radius
-        self.general_params["image_smoothing_threshold"] = image_smoothing_threshold
-        self.general_params["decimate_reduction"] = decimate_reduction
-        self.general_params["decimate_threshold"] = decimate_threshold
-        self.general_params["model_smoothing_iterations"] = model_smoothing_iterations
-        self.general_params["model_smoothing_pass_band"] = model_smoothing_pass_band
-        self.general_params["min_segment_lines"] = min_segment_lines
-
-    def set_image_params(
-        self,
-        image_identifier: str,
-        image_smoothing: bool,
-        image_smoothing_sigma: float,
-        image_smoothing_radius: float,
-        image_smoothing_threshold: float,
-        decimate_reduction: float,
-        decimate_threshold: float,
-        model_smoothing_iterations: int,
-        model_smoothing_pass_band: float,
-        min_segment_lines: int,
-    ) -> None:
-        """Set the parameters of the converter for a specific image using an identifier.
-
-        Args:
-            image_identifier (str): The identifier that identifies the segmentation mask for which the parameters are
-             set.
-            image_smoothing (bool): Whether to smooth the image before 3D model construction or not.
-            image_smoothing_sigma (float): The variance of the Gaussian smoothing before 3D model construction.
-            image_smoothing_radius (float): The radius of the Gaussian smoothing before 3D model construction.
-            image_smoothing_threshold (float): The minimum number of foreground voxels that must be contained in the
-             segmentation mask to trigger Gaussian smoothing.
-            decimate_reduction (float): The reduction factor for the 3D decimation. The decimation factor is valid
-             between 0 and 1 and the lower it is the more smoothing is applied.
-            decimate_threshold (float): The minimum number of foreground voxels that must be contained in the
-             segmentation mask to trigger 3D decimation.
-            model_smoothing_iterations (int): The number of 3D smoothing steps (typically 15 - 20 steps).
-            model_smoothing_pass_band (bool): The strength of the 3D smoothing (0.001 - 0.1 = strong smoothing,
-             0.5 - 1 = almost no smoothing).
-            min_segment_lines (int): The minimum number of lines that a segment must have to be considered for the RTSS.
-
-        Returns:
-            None
-        """
-
-        self._validate_entries(
-            image_smoothing,
-            image_smoothing_sigma,
-            image_smoothing_radius,
-            image_smoothing_threshold,
-            decimate_reduction,
-            decimate_threshold,
-            model_smoothing_iterations,
-            model_smoothing_pass_band,
-            min_segment_lines,
-        )
-
-        self.image_specific_params[image_identifier] = {
-            "image_smoothing": image_smoothing,
-            "image_smoothing_sigma": image_smoothing_sigma,
-            "image_smoothing_radius": image_smoothing_radius,
-            "image_smoothing_threshold": image_smoothing_threshold,
-            "decimate_reduction": decimate_reduction,
-            "decimate_threshold": decimate_threshold,
-            "model_smoothing_iterations": model_smoothing_iterations,
-            "model_smoothing_pass_band": model_smoothing_pass_band,
-            "min_segment_lines": min_segment_lines,
-        }
-
-
-class SegmentToRTSSConverterBase(Converter):
-    """A base class for low-level segmentation mask to DICOM-RTSS converters. This class is not intended to be used
-    directly but rather as a base class for more specific conversion algorithm implementations.
-
-    Args:
-        label_images (Union[Tuple[str, ...], Tuple[sitk.Image, ...]]): The path to the images or a sequence of
-         :class:`SimpleITK.Image` instances.
-        ref_image_datasets (Union[Tuple[str, ...], Tuple[Dataset, ...]]): The referenced DICOM image
-         :class:`~pydicom.dataset.Dataset` instances.
-        roi_names (Union[Tuple[str, ...], Dict[int, str], None]): The label names which will be assigned to the ROIs.
-        colors (Optional[Tuple[Tuple[int, int, int], ...]]): The colors which will be assigned to the ROIs.
-        meta_data (RTSSMetaData): The configuration to specify certain DICOM attributes (default: RTSSMetaData()).
-    """
-
-    def __init__(
-        self,
-        label_images: Union[Tuple[str, ...], Tuple[sitk.Image, ...]],
-        ref_image_datasets: Union[Tuple[str, ...], Tuple[Dataset, ...]],
-        roi_names: Union[Tuple[str, ...], Dict[int, str], None],
-        colors: Optional[Tuple[Tuple[int, int, int], ...]],
-        config: RTSSConverterConfiguration,
-        meta_data: RTSSMetaData = RTSSMetaData(),
-    ) -> None:
-        super().__init__()
-
-        # get or load the label images
-        self.label_images: Tuple[sitk.Image, ...] = (
-            label_images
-            if isinstance(label_images[0], sitk.Image)
-            else tuple([sitk.ReadImage(path, sitk.sitkUInt8) for path in label_images])
-        )
-
-        # get or load the reference image datasets
-        self.image_datasets: Tuple[Dataset, ...] = (
-            ref_image_datasets if isinstance(ref_image_datasets[0], Dataset) else load_datasets(ref_image_datasets)
-        )
-        self.image_datasets = self._sort_datasets(self.image_datasets)
-
-        # get the ROI names
-        if isinstance(roi_names, dict):
-            sorted_keys = sorted(roi_names.keys())
-            self.roi_names = tuple([str(roi_names.get(key)) for key in sorted_keys])
-        elif not roi_names:
-            self.roi_names = tuple([f"Structure_{i}" for i in range(len(self.label_images))])
-        else:
-            self.roi_names = roi_names
-
-        # get the colors
-        if not colors:
-            self.colors = COLOR_PALETTE
-        else:
-            self.colors = colors
-
-        # check if the correct number of ROI names and colors are provided
-        if len(self.roi_names) < len(self.label_images):
-            raise ValueError("The number of ROI names must be equal or larger than the number of label images!")
-
-        if len(self.colors) < len(self.label_images):
-            raise ValueError("The number of colors must be equal or larger than the number of label images!")
-
-        # get the meta data
-        self.meta_data = meta_data
-
-        # get the configuration
-        self.config = config
-
-    @staticmethod
-    def _sort_datasets(datasets: Tuple[Dataset, ...]) -> Tuple[Dataset, ...]:
-        """Sort the datasets by their patient image position.
-
-        Args:
-            datasets (Tuple[Dataset, ...]): The datasets to sort.
-
-        Returns:
-            Tuple[Dataset, ...]: The sorted datasets.
-        """
-        # get the principal axes of the image orientation
-        direction = np.array(get_slice_direction(datasets[0]))[2]
-
-        principal_component = np.argmax(np.abs(direction))
-        principal_direction = np.sign(direction[principal_component])
-
-        datasets_ = tuple(
-            sorted(
-                datasets,
-                key=lambda dataset: float(datasets[0].ImagePositionPatient[principal_component]),
-                reverse=principal_direction < 0,
-            )
-        )
-        return datasets_
-
-    def _validate_label_images(self) -> None:
-        """Validate the label images.
-
-        Raises:
-            ValueError: If the label images are not binary or the pixel type is not an integer.
-        """
-        # check if the label images are binary and that they have an integer pixel type
-        for image in self.label_images:
-            if np.unique(sitk.GetArrayFromImage(image)).size > 2:
-                raise ValueError("The label images must be binary!")
-
-            if "float" in image.GetPixelIDTypeAsString():
-                raise ValueError("The label images must have an integer pixel type!")
-
-    def _generate_basic_rtss(self) -> FileDataset:
-        """Generate the basic RTSS skeleton.
-
-        Returns:
-            FileDataset: The basic RT Structure Set.
-        """
-        # create the file meta for the dataset
-        file_meta = FileMetaDataset()
-        file_meta.FileMetaInformationGroupLength = 202
-        file_meta.FileMetaInformationVersion = b"\x00\x01"
-        file_meta.TransferSyntaxUID = ImplicitVRLittleEndian
-        file_meta.MediaStorageSOPClassUID = "1.2.840.10008.5.1.4.1.1.481.3"
-        file_meta.MediaStorageSOPInstanceUID = generate_uid()
-        file_meta.ImplementationClassUID = PYDICOM_IMPLEMENTATION_UID
-
-        # create the dataset
-        rtss = FileDataset("rt_struct", {}, file_meta=file_meta, preamble=b"\0" * 128)
-
-        # add the basic information
-        now = datetime.now()
-        rtss.SpecificCharacterSet = "ISO_IR 100"
-        rtss.InstanceCreationDate = now.strftime("%Y%m%d")
-        rtss.InstanceCreationTime = now.strftime("%H%M%S.%f")
-        rtss.StructureSetLabel = self.meta_data.structure_set_label
-        rtss.StructureSetDate = now.strftime("%Y%m%d")
-        rtss.StructureSetTime = now.strftime("%H%M%S.%f")
-        rtss.Modality = "RTSTRUCT"
-        rtss.Manufacturer = self.meta_data.manufacturer
-        rtss.ManufacturerModelName = self.meta_data.manufacturer_model_name
-        rtss.InstitutionName = self.meta_data.institution_name
-        rtss.OperatorsName = self.meta_data.operators_name
-        rtss.ApprovalStatus = self.meta_data.approval_status
-
-        rtss.is_little_endian = True
-        rtss.is_implicit_VR = True
-
-        # set values already defined in the file meta
-        rtss.SOPClassUID = rtss.file_meta.MediaStorageSOPClassUID
-        rtss.SOPInstanceUID = rtss.file_meta.MediaStorageSOPInstanceUID
-
-        # add study and series information
-        reference_dataset = self.image_datasets[0]
-        rtss.StudyDate = reference_dataset.StudyDate
-        rtss.SeriesDate = getattr(reference_dataset, "SeriesDate", "")
-        rtss.StudyTime = reference_dataset.StudyTime
-        rtss.SeriesTime = getattr(reference_dataset, "SeriesTime", "")
-
-        if self.meta_data.study_description is None:
-            rtss.StudyDescription = getattr(reference_dataset, "StudyDescription", "")
-        else:
-            rtss.StudyDescription = self.meta_data.study_description
-
-        if self.meta_data.series_description is None:
-            rtss.SeriesDescription = getattr(reference_dataset, "SeriesDescription", "")
-        else:
-            rtss.SeriesDescription = self.meta_data.series_description
-
-        rtss.StudyInstanceUID = reference_dataset.StudyInstanceUID
-        rtss.SeriesInstanceUID = generate_uid()
-        rtss.StudyID = reference_dataset.StudyID
-        rtss.SeriesNumber = self.meta_data.series_number
-        rtss.ReferringPhysicianName = self.meta_data.referring_physician_name
-        rtss.AccessionNumber = "0"
-
-        # add the patient information
-        if self.meta_data.patient_name is None:
-            rtss.PatientName = getattr(reference_dataset, "PatientName", "")
-        else:
-            rtss.PatientName = self.meta_data.patient_name
-
-        if self.meta_data.patient_id is None:
-            rtss.PatientID = getattr(reference_dataset, "PatientID", "")
-        else:
-            rtss.PatientID = self.meta_data.patient_id
-
-        if self.meta_data.patient_birth_date is None:
-            rtss.PatientBirthDate = getattr(reference_dataset, "PatientBirthDate", "")
-        else:
-            rtss.PatientBirthDate = self.meta_data.patient_birth_date
-
-        if self.meta_data.patient_sex is None:
-            rtss.PatientSex = getattr(reference_dataset, "PatientSex", "")
-        else:
-            rtss.PatientSex = self.meta_data.patient_sex
-
-        if self.meta_data.patient_age is None:
-            rtss.PatientAge = getattr(reference_dataset, "PatientAge", "")
-        else:
-            rtss.PatientAge = self.meta_data.patient_age
-
-        if self.meta_data.patient_weight is None:
-            rtss.PatientWeight = getattr(reference_dataset, "PatientWeight", "")
-        else:
-            rtss.PatientWeight = self.meta_data.patient_weight
-
-        if self.meta_data.patient_size is None:
-            rtss.PatientSize = getattr(reference_dataset, "PatientSize", "")
-        else:
-            rtss.PatientSize = self.meta_data.patient_size
-
-        # construct the ContourImageSequence
-        contour_image_sequence = Sequence()
-        for image_dataset in self.image_datasets:
-            contour_image_entry = Dataset()
-            contour_image_entry.ReferencedSOPClassUID = image_dataset.file_meta.MediaStorageSOPClassUID
-            contour_image_entry.ReferencedSOPInstanceUID = image_dataset.file_meta.MediaStorageSOPInstanceUID
-            contour_image_sequence.append(contour_image_entry)
-
-        # construct the RTReferencedSeriesSequence
-        rt_referenced_series_sequence = Sequence()
-        rt_referenced_series_entry = Dataset()
-        rt_referenced_series_entry.SeriesInstanceUID = reference_dataset.SeriesInstanceUID
-        rt_referenced_series_entry.ContourImageSequence = contour_image_sequence
-        rt_referenced_series_sequence.append(rt_referenced_series_entry)
-
-        # construct the RTReferencedStudySequence
-        rt_referenced_study_sequence = Sequence()
-        rt_referenced_study_entry = Dataset()
-        rt_referenced_study_entry.ReferencedSOPClassUID = "1.2.840.10008.3.1.2.3.1"  # RT Structure Set Storage
-        rt_referenced_study_entry.ReferencedSOPInstanceUID = reference_dataset.StudyInstanceUID
-        rt_referenced_study_entry.RTReferencedSeriesSequence = rt_referenced_series_sequence
-        rt_referenced_study_sequence.append(rt_referenced_study_entry)
-
-        # construct the ReferencedFrameOfReferenceSequence
-        rtss.ReferencedFrameOfReferenceSequence = Sequence()
-        referenced_frame_of_ref_entry = Dataset()
-        referenced_frame_of_ref_entry.FrameOfReferenceUID = reference_dataset.FrameOfReferenceUID
-        referenced_frame_of_ref_entry.RTReferencedStudySequence = rt_referenced_study_sequence
-        rtss.ReferencedFrameOfReferenceSequence.append(referenced_frame_of_ref_entry)
-
-        # construct the ROIContourSequence, StructureSetROISequence and RTROIObservationsSequence
-        rtss.ROIContourSequence = Sequence()
-        rtss.StructureSetROISequence = Sequence()
-        rtss.RTROIObservationsSequence = Sequence()
-
-        return rtss
-
-    @staticmethod
-    def _append_rt_roi_observation(roi_number: int, rtss: Dataset) -> None:
-        """Create a RTROIObservationsSequence entry for the given ROI data.
-
-        Args:
-            roi_number (int): The ROI data to be used for creating the RTROIObservationsSequence entry.
-            rtss (Dataset): The RTSS to be used for creating the RTROIObservationsSequence entry.
-
-        Returns:
-            None
-        """
-        # generate the RTROIObservationsSequence entry
-        rt_roi_observation = Dataset()
-        rt_roi_observation.ObservationNumber = roi_number
-        rt_roi_observation.ReferencedROINumber = roi_number
-        rt_roi_observation.ROIObservationDescription = (
-            "Type:Soft,Range:*/*,Fill:0,Opacity:0.0,Thickness:1," "LineThickness:2,read-only:false"
-        )
-        rt_roi_observation.private_creators = "University of Bern, Switzerland"
-        rt_roi_observation.RTROIInterpretedType = ""
-        rt_roi_observation.ROIInterpreter = ""
-
-        # add the RTROIObservationsSequence entry to the RTSS
-        rtss.RTROIObservationsSequence.append(rt_roi_observation)
-
-    def _append_structure_set_roi_sequence_entry(self, roi_name: str, roi_number: int, rtss: Dataset) -> None:
-        """Append a StructureSetROISequence entry to the given RTSS.
-
-        Args:
-            roi_name (str): The name of the ROI.
-            roi_number (int): The number of the ROI.
-            rtss (Dataset): The RTSS to be used for creating the StructureSetROISequence entry.
-
-        Returns:
-            None
-        """
-        # generate the StructureSetROISequence entry
-        structure_set_roi = Dataset()
-        structure_set_roi.ROINumber = roi_number
-        structure_set_roi.ReferencedFrameOfReferenceUID = self.image_datasets[0].get("FrameOfReferenceUID")
-        structure_set_roi.ROIName = roi_name
-        structure_set_roi.ROIDescription = ""
-        structure_set_roi.ROIGenerationAlgorithm = self.meta_data.roi_gen_algorithm
-
-        # add the StructureSetROISequence entry to the RTSS
-        rtss.StructureSetROISequence.append(structure_set_roi)
-
-    @abstractmethod
-    def convert(self) -> Any:
-        """Abstract method for starting the conversion procedure.
-
-        Returns:
-            Any: The converted data.
-        """
-        raise NotImplementedError()
-
-
-class SegmentToRTSSConverter2D(SegmentToRTSSConverterBase):
-    """A low-level 2D-based :class:`Converter` class for converting one or multiple
-    :class:`~pyradise.data.image.SegmentationImage` instances to a DICOM-RTSS :class:`~pydicom.dataset.Dataset`.
-    In contrast to the :class:`SegmentToRTSSConverter3D` class, this class generates the DICOM-RTSS contours using a
-    two-dimensional approach. This reduces the computation time and leads to a more robust conversion procedure.
-    However, this class has limitations such as the inability to smooth contours in all three dimensions. Furthermore,
-    the resulting contours may appear to be artificially generated and not as smooth as the ones generated by the
-    :class:`SegmentToRTSSConverter3D` class.
-
-    Warning:
-        The provided ``label_images`` must be binary, otherwise the conversion will fail.
-
-    Note:
-        Typically, this class is not used directly by the used but via the :class:`SubjectToRTSSConverter` which
-        processes :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries and thus provides a more suitable
-        interface.
-
-    Note:
-        This class can take a :class:`RTSSMetaData` instance as input to specify certain DICOM attributes of the
-        output DICOM-RTSS. If no instance is provided, the default values will be used.
-
-    Args:
-        label_images (Union[Tuple[str, ...], Tuple[sitk.Image, ...]]): The path to the images or a sequence of
-         :class:`SimpleITK.Image` instances.
-        ref_image_datasets (Union[Tuple[str, ...], Tuple[Dataset, ...]]): The referenced DICOM image
-         :class:`~pydicom.dataset.Dataset` instances.
-        roi_names (Union[Tuple[str, ...], Dict[int, str], None]): The label names which will be assigned to the ROIs.
-        colors (Optional[Tuple[Tuple[int, int, int], ...]]): The colors which will be assigned to the ROIs.
-        meta_data (RTSSMetaData): The configuration to specify certain DICOM attributes (default: RTSSMetaData()).
-        config (RTSSConverter2DConfiguration): The configuration to specify certain conversion parameters (default:
-         RTSSConverter2DConfiguration()).
-    """
-
-    def __init__(
-        self,
-        label_images: Union[Tuple[str, ...], Tuple[sitk.Image, ...]],
-        ref_image_datasets: Union[Tuple[str, ...], Tuple[Dataset, ...]],
-        roi_names: Union[Tuple[str, ...], Dict[int, str], None],
-        colors: Optional[Tuple[Tuple[int, int, int], ...]],
-        meta_data: RTSSMetaData = RTSSMetaData(),
-        config: RTSSConverter2DConfiguration = RTSSConverter2DConfiguration(),
-    ) -> None:
-        super().__init__(label_images, ref_image_datasets, roi_names, colors, config, meta_data)
-
-        self.config = config
-
-    @staticmethod
-    def _append_roi_contour(
-        mask: np.ndarray,
-        image_datasets: Tuple[Dataset, ...],
-        rtss: Dataset,
-        roi_color: Tuple[int, int, int],
-        roi_number: int,
-    ) -> None:
-        """Create a ROIContourSequence entry for the given ROI data.
-
-        Args:
-            mask (np.ndarray): The ROI mask to generate the contours from.
-            image_datasets (Tuple[Dataset, ...]): The referenced image datasets.
-            rtss (Dataset): The RTSS dataset.
-
-        Returns:
-            None
-        """
-        roi_contour = Dataset()
-        roi_contour.ROIDisplayColor = [str(color) for color in roi_color]
-        roi_contour.ContourSequence = SegmentToRTSSConverter2D._create_contour_sequence(mask, image_datasets)
-        roi_contour.ReferencedROINumber = str(roi_number)
-
-        # add the ROIContourSequence entry to the RTSS
-        rtss.ROIContourSequence.append(roi_contour)
-
-    @staticmethod
-    def _create_contour_sequence(mask: np.ndarray, image_datasets: Tuple[Dataset, ...]) -> Sequence:
-        """Create a ContourSequence for the given ROI data by iterating through each slice of the mask.
-        For each connected segment within a slice, a ContourSequence entry is created.
-
-        Args:
-            mask (np.ndarray): The ROI mask for generating the contours.
-            image_datasets (Tuple[Dataset, ...]): The referenced image datasets.
-
-        Returns:
-            Sequence: The created ContourSequence.
-        """
-        contour_sequence = Sequence()
-
-        contours_coordinates = SegmentToRTSSConverter2D._get_contours_coordinates(mask, image_datasets)
-
-        for series_slice, slice_contours in zip(image_datasets, contours_coordinates):
-            for contour_data in slice_contours:
-                if len(contour_data) <= 3:
-                    continue
-                contour_seq_entry = SegmentToRTSSConverter2D._create_contour_sequence_entry(series_slice, contour_data)
-                contour_sequence.append(contour_seq_entry)
-
-        return contour_sequence
-
-    @staticmethod
-    def _get_contours_coordinates(mask: np.ndarray, image_datasets: Tuple[Dataset, ...]) -> List[List[List[float]]]:
-        """Get the contour coordinates for each slice of the mask.
-
-        Args:
-            mask (np.ndarray): The ROI mask for generating the contours.
-            image_datasets (Tuple[Dataset, ...]): The referenced image datasets.
-
-        Returns:
-            List[List[List[float]]]: The contour coordinates for each slice of the mask.
-        """
-        transform_matrix = SegmentToRTSSConverter2D._get_pixel_to_patient_transformation_matrix(image_datasets)
-
-        series_contours = []
-        for i in range(len(image_datasets)):
-            mask_slice = mask[i, :, :]
-
-            # Do not add ROI's for blank slices
-            if np.sum(mask_slice) == 0:
-                series_contours.append([])
-                continue
-
-            # Get contours from mask
-            contours, _ = SegmentToRTSSConverter2D._find_mask_contours(mask_slice)
-
-            if not contours:
-                raise Exception("Unable to find contour in non empty mask, please check your mask formatting!")
-
-            # Format for DICOM
-            formatted_contours = []
-            for contour in contours:
-                # Add z index
-                contour = np.concatenate((np.array(contour), np.full((len(contour), 1), i)), axis=1)
-
-                transformed_contour = SegmentToRTSSConverter2D._apply_transformation_to_3d_points(
-                    contour, transform_matrix
-                )
-                dicom_formatted_contour = np.ravel(transformed_contour).tolist()
-                formatted_contours.append(dicom_formatted_contour)
-
-            series_contours.append(formatted_contours)
-
-        return series_contours
-
-    @staticmethod
-    def _get_pixel_to_patient_transformation_matrix(image_datasets: Tuple[Dataset]) -> np.ndarray:
-        """Get the pixel to patient transformation matrix according to the referenced image datasets.
-
-        Notes:
-            Description see: https://nipy.org/nibabel/dicom/dicom_orientation.html
-
-        Args:
-            image_datasets (Tuple[Dataset]): The image datasets with the necessary information to retrieve the pixel
-             to patient transformation matrix.
-
-        Returns:
-            np.ndarray: The pixel to patient transformation matrix.
-        """
-
-        first_slice = image_datasets[0]
-
-        offset = np.array(first_slice.ImagePositionPatient)
-        row_spacing, column_spacing = first_slice.PixelSpacing
-        slice_spacing = get_spacing_between_slices(image_datasets)
-        row_direction, column_direction, slice_direction = get_slice_direction(first_slice)
-
-        mat = np.identity(4, dtype=float)
-        mat[:3, 0] = row_direction * row_spacing
-        mat[:3, 1] = column_direction * column_spacing
-        mat[:3, 2] = slice_direction * slice_spacing
-        mat[:3, 3] = offset
-
-        return mat
-
-    @staticmethod
-    def _find_mask_contours(mask: np.ndarray, approximate_contours: bool = True) -> Tuple[List[np.ndarray], List]:
-        """Find the contours in the provided mask.
-
-        Args:
-            mask (np.ndarray): The mask to be used for finding the contours.
-            approximate_contours (bool): Whether to approximate the contours (default: True).
-
-        Returns:
-            Tuple[List[np.ndarray], List]: The contours and the hierarchy.
-        """
-        method = cv.CHAIN_APPROX_SIMPLE if approximate_contours else cv.CHAIN_APPROX_NONE
-        contours, hierarchy = cv.findContours(mask.astype(np.uint8), cv.RETR_TREE, method)
-        contours = list(contours)
-
-        for i, contour in enumerate(contours):
-            contours[i] = [[pos[0][0], pos[0][1]] for pos in contour]
-        hierarchy = hierarchy[0]
-
-        return contours, hierarchy
-
-    @staticmethod
-    def _apply_transformation_to_3d_points(points: np.ndarray, transformation_matrix: np.ndarray) -> np.ndarray:
-        """Apply the given transformation matrix to the given 3D points.
-
-        Notes:
-            The transformation matrix is expected to be a 4x4 matrix (homogeneous coordinate transform).
-
-
-        Args:
-            points (np.ndarray): The points to be transformed.
-            transformation_matrix (np.ndarray): The transformation matrix.
-
-        Returns:
-            np.ndarray: The transformed points.
-        """
-        vec = np.concatenate((points, np.ones((points.shape[0], 1))), axis=1)
-        return vec.dot(transformation_matrix.T)[:, :3]
-
-    @staticmethod
-    def _create_contour_sequence_entry(series_slice: Dataset, contour_data: List[float]) -> Dataset:
-        """Create a contour sequence entry for the given slice.
-
-        Args:
-            series_slice (Dataset): The slice to be used for creating the contour sequence entry.
-            contour_data (List[float]): The contour data to be used for creating the contour sequence entry.
-
-        Returns:
-            Dataset: The contour sequence entry.
-        """
-        # create the ContourImageSequence entry
-        contour_image = Dataset()
-        contour_image.ReferencedSOPClassUID = series_slice.file_meta.MediaStorageSOPClassUID
-        contour_image.ReferencedSOPInstanceUID = series_slice.file_meta.MediaStorageSOPInstanceUID
-
-        # construct the ContourImageSequence
-        contour_image_sequence = Sequence()
-        contour_image_sequence.append(contour_image)
-
-        # construct the ContourSequence entry
-        contour = Dataset()
-        contour.ContourImageSequence = contour_image_sequence
-        contour.ContourGeometricType = "CLOSED_PLANAR"
-        contour.NumberOfContourPoints = len(contour_data) // 3  # each contour point consists of an x, y, and z value
-        contour.ContourData = contour_data
-
-        return contour
-
-    @staticmethod
-    def _adjust_label_image_to_dicom(label_image: sitk.Image, image_datasets: Tuple[Dataset, ...]) -> sitk.Image:
-        """Adjust the given label image to the DICOM image.
-
-        Args:
-            label_image (sitk.Image): The label image to be adjusted.
-            image_datasets (Tuple[Dataset, ...]): The DICOM image datasets.
-
-        Returns:
-            sitk.Image: The adjusted label image.
-        """
-        # construct a reference image from the DICOM datasets
-
-        # compute the direction from the DICOM datasets
-        vec_0 = image_datasets[0].ImageOrientationPatient[:3]
-        vec_1 = image_datasets[0].ImageOrientationPatient[3:]
-        vec_2 = np.cross(np.array(vec_0, dtype=float), np.array(vec_1, dtype=float))
-        dicom_direction = np.stack((vec_0, vec_1, vec_2)).astype(float).T.reshape(-1).tolist()
-
-        # compute the origin from the DICOM datasets
-        dicom_origin = image_datasets[0].ImagePositionPatient
-
-        # compute the spacing from the DICOM datasets
-        dicom_spacing = [
-            float(image_datasets[0].PixelSpacing[0]),
-            float(image_datasets[0].PixelSpacing[1]),
-            get_spacing_between_slices(image_datasets),
-        ]
-
-        # compute the size from the DICOM datasets
-        # note: sizes must be in z, x, y order because numpy reverses axes
-        dicom_size = (len(image_datasets), image_datasets[0].Rows, image_datasets[0].Columns)
-
-        # construct the reference image via numpy
-        reference_image_np = np.zeros(dicom_size)
-        reference_image_sitk = sitk.GetImageFromArray(reference_image_np)
-        reference_image_sitk.SetDirection(dicom_direction)
-        reference_image_sitk.SetOrigin(dicom_origin)
-        reference_image_sitk.SetSpacing(dicom_spacing)
-
-        # orient the label image according to the reference image
-        reference_orientation = sitk.DICOMOrientImageFilter_GetOrientationFromDirectionCosines(
-            reference_image_sitk.GetDirection()
-        )
-        label_image_0 = sitk.DICOMOrient(label_image, reference_orientation)
-
-        criteria = []
-        criteria.extend(
-            [
-                reference_image_sitk.GetSpacing()[i] == label_image_0.GetSpacing()[i]
-                for i in range(label_image.GetDimension())
-            ]
-        )
-        criteria.extend(
-            [
-                reference_image_sitk.GetOrigin()[i] == label_image_0.GetOrigin()[i]
-                for i in range(label_image.GetDimension())
-            ]
-        )
-        criteria.extend(
-            [
-                reference_image_sitk.GetDirection()[i] == label_image_0.GetDirection()[i]
-                for i in range(label_image.GetDimension())
-            ]
-        )
-        criteria.extend(
-            [reference_image_sitk.GetSize()[i] == label_image_0.GetSize()[i] for i in range(label_image.GetDimension())]
-        )
-
-        if all(criteria):
-            return label_image_0
-
-        # resample the oriented label image to the reference image
-        label_image_1 = sitk.Resample(
-            label_image_0, reference_image_sitk, sitk.Transform(), sitk.sitkNearestNeighbor, 0.0, sitk.sitkUInt8
-        )
-        return label_image_1
-
-    @staticmethod
-    def _smooth_label_image(label_image: sitk.Image, kernel_size: int, sigma: float) -> sitk.Image:
-        """Apply Gaussian smoothing to a label image.
-
-        Args:
-            label_image (sitk.Image): The image to be smoothened.
-            kernel_size (int): The maximum kernel size for the Gaussian kernel.
-            sigma (float): The sigma for the Gaussian Kernel.
-
-        Returns:
-             sitk.Image: The smoothened image.
-        """
-        label_image_0 = sitk.Cast(label_image, sitk.sitkFloat32)
-
-        num_dims = label_image.GetDimension()
-        label_image_1 = sitk.DiscreteGaussian(
-            label_image_0, variance=[sigma] * num_dims, maximumKernelWidth=kernel_size
-        )
-        label_image_2 = sitk.BinaryThreshold(label_image_1, 0.5, 1.0, 1, 0)
-
-        return label_image_2
-
-    def convert(self) -> Dataset:
-        """Convert the provided :class:`SimpleITK.Image` instances to a DICOM-RTSS :class:`~pydicom.dataset.Dataset`
-        instance using a two-dimensional reconstruction algorithm.
-
-        Returns:
-            Dataset: The generated DICOM-RTSS :class:`~pydicom.dataset.Dataset`.
-        """
-        # generate the basic RTSS dataset
-        rtss = self._generate_basic_rtss()
-
-        # convert and add the ROIs to the RTSS
-        for idx, (label, name, color) in enumerate(zip(self.label_images, self.roi_names, self.colors)):
-            # check if a specific parameterization must be used for this image
-            if self.config.get_image_params(name) is not None:
-                smooth = self.config.get_image_params(name, "smoothing")
-                kernel = self.config.get_image_params(name, "smoothing_kernel_size")
-                sigma = self.config.get_image_params(name, "smoothing_sigma")
-            else:
-                config = self.config.get_general_params()
-                smooth = config.get("smoothing")
-                kernel = config.get("smoothing_kernel_size")
-                sigma = config.get("smoothing_sigma")
-
-            # adjust the label image to have the same properties as the DICOM datasets
-            label_processed = self._adjust_label_image_to_dicom(label, self.image_datasets)
-
-            # smooth the label image
-            if smooth:
-                label_processed = self._smooth_label_image(label_processed, kernel, sigma)
-
-            # get the binary image data from the label image
-            mask = sitk.GetArrayFromImage(label_processed)
-
-            self._append_roi_contour(mask, self.image_datasets, rtss, color, idx + 1)
-            self._append_structure_set_roi_sequence_entry(name, idx + 1, rtss)
-            self._append_rt_roi_observation(idx + 1, rtss)
-
-        return rtss
-
-
-class SegmentToRTSSConverter3D(SegmentToRTSSConverterBase):
-    """A low-level 3D-based :class:`Converter` class for converting one or multiple
-    :class:`~pyradise.data.image.SegmentationImage` instances to a DICOM-RTSS :class:`~pydicom.dataset.Dataset`.
-    In contrast to the :class:`SegmentToRTSSConverter2D` class, this class generates the DICOM-RTSS contours using a
-    three-dimensional approach. This reduces spatial inconsistencies but comes at the cost of a longer computation time
-    and higher memory consumption. Furthermore, this converter is less robust than its two-dimensional counterpart.
-    However, the resulting contours are more accurate and appear more natural it the converter is applied with
-    appropriate parameterization.
-
-    Warning:
-        The provided ``label_images`` must be binary, otherwise the conversion will fail.
-
-    Note:
-        Typically, this class is not used directly by the used but via the :class:`SubjectToRTSSConverter` which
-        processes :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries and thus provides a more suitable
-        interface.
-
-    Note:
-        This class can take a :class:`RTSSMetaData` instance as input to specify certain DICOM attributes of the
-        output DICOM-RTSS. If no instance is provided, the default values will be used.
-
-    Args:
-        label_images (Union[Tuple[str, ...], Tuple[sitk.Image, ...]]): The path to the images or a sequence of
-         :class:`SimpleITK.Image` instances.
-        ref_image_datasets (Union[Tuple[str, ...], Tuple[Dataset, ...]]): The referenced DICOM image
-         :class:`~pydicom.dataset.Dataset` instances.
-        roi_names (Union[Tuple[str, ...], Dict[int, str], None]): The label names which will be assigned to the ROIs.
-        colors (Optional[Tuple[Tuple[int, int, int], ...]]): The colors which will be assigned to the ROIs.
-        meta_data (RTSSMetaData): The configuration to specify certain DICOM attributes (default: RTSSMetaData()).
-        config (RTSSConverter3DConfiguration): The configuration to specify certain conversion parameters (default:
-         RTSSConverter3DConfiguration()).
-    """
-
-    def __init__(
-        self,
-        label_images: Union[Tuple[str, ...], Tuple[sitk.Image, ...]],
-        ref_image_datasets: Union[Tuple[str, ...], Tuple[Dataset, ...]],
-        roi_names: Union[Tuple[str, ...], Dict[int, str], None],
-        colors: Optional[Tuple[Tuple[int, int, int], ...]],
-        meta_data: RTSSMetaData = RTSSMetaData(),
-        config: RTSSConverter3DConfiguration = RTSSConverter3DConfiguration(),
-    ):
-        super().__init__(label_images, ref_image_datasets, roi_names, colors, config, meta_data)
-
-        self.config = config
-
-    @staticmethod
-    def _has_foreground_on_borders(image: sitk.Image):
-        """Check if the provided image has foreground pixels on the borders.
-
-        Args:
-            image (sitk.Image): The image to check.
-
-        Returns:
-            bool: True if the image has foreground pixels on the borders, False otherwise.
-        """
-        image_array = sitk.GetArrayFromImage(image)
-
-        return any(
-            (
-                np.any(image_array[0, :, :]),
-                np.any(image_array[-1, :, :]),
-                np.any(image_array[:, 0, :]),
-                np.any(image_array[:, -1, :]),
-                np.any(image_array[:, :, 0]),
-                np.any(image_array[:, :, -1]),
-            )
-        )
-
-    def preprocess_image(self, image_sitk: sitk.Image) -> sitk.Image:
-        """Preprocess the provided :class:`SimpleITK.Image` instance such that the image has the same properties as
-        the referenced DICOM image series.
-
-        Args:
-            image_sitk (sitk.Image): The :class:`SimpleITK.Image` instance to preprocess.
-
-        Returns:
-            sitk.Image: The preprocessed :class:`SimpleITK.Image` instance.
-        """
-        # orient the image to the LPS coordinate system (-> DICOM standard)
-        image_sitk = sitk.DICOMOrient(image_sitk, "LPS")
-
-        # resample to match the DICOM image
-        origin = self.image_datasets[0].ImagePositionPatient
-        slice_spacing = get_spacing_between_slices(self.image_datasets)
-        spacing = (
-            float(self.image_datasets[0].PixelSpacing[0]),
-            float(self.image_datasets[0].PixelSpacing[1]),
-            slice_spacing,
-        )
-        direction = np.array(get_slice_direction(self.image_datasets[0])).T.flatten()
-        size = (self.image_datasets[0].Rows, self.image_datasets[0].Columns, len(self.image_datasets))
-
-        resampler = sitk.ResampleImageFilter()
-        resampler.SetOutputOrigin(origin)
-        resampler.SetOutputSpacing(spacing)
-        resampler.SetOutputDirection(direction)
-        resampler.SetSize(size)
-        resampler.SetTransform(sitk.Transform())
-        resampler.SetOutputPixelType(sitk.sitkUInt8)
-        resampler.SetInterpolator(sitk.sitkNearestNeighbor)
-        resampler.SetDefaultPixelValue(0)
-        image_sitk = resampler.Execute(image_sitk)
-
-        # convert to binary
-        image_sitk = sitk.BinaryThreshold(image_sitk, 1, 255, 255, 0)
-
-        return image_sitk
-
-    def _get_3d_model(
-        self,
-        sitk_image: sitk.Image,
-        image_smoothing: bool,
-        smooth_sigma: float,
-        smooth_radius: float,
-        smooth_threshold: float,
-        decimate_reduction: float,
-        decimate_threshold: float,
-        model_smooth_iter: int,
-        model_smooth_pass_band: float,
-    ) -> vtk_dm.vtkPolyData:
-        """Generate a 3D model of the provided :class:`SimpleITK.Image` instance.
-
-        Args:
-            sitk_image (sitk.Image): The :class:`SimpleITK.Image` instance to generate the 3D model for.
-            image_smoothing (bool): Whether to smooth the image before generating the 3D model.
-            smooth_sigma (float): The sigma value for the Gaussian smoothing.
-            smooth_radius (float): The radius value for the Gaussian smoothing.
-            smooth_threshold (float): The threshold value for the Gaussian smoothing.
-            decimate_reduction (float): The reduction value for the decimation.
-            decimate_threshold (float): The threshold value for the decimation.
-            model_smooth_iter (int): The number of iterations for the model smoothing.
-            model_smooth_pass_band (float): The pass band value for the model smoothing.
-
-        Returns:
-            vtk_dm.vtkPolyData: The 3D model of the provided :class:`SimpleITK.Image` instance.
-        """
-        # cast the image to vtkImageData
-        itk_image = convert_to_itk_image(sitk_image)
-        vtk_image = itk.vtk_image_from_image(itk_image)
-
-        # set the direction matrix
-        vtk_image.SetDirectionMatrix(sitk_image.GetDirection())
-
-        # pad the image to avoid boundary effects if necessary
-        if self._has_foreground_on_borders(sitk_image):
-            margin = 10
-            extent = vtk_image.GetExtent()
-            new_extent = (
-                extent[0] - margin,
-                extent[1] + margin,
-                extent[2] - margin,
-                extent[3] + margin,
-                extent[4] - margin,
-                extent[5] + margin,
-            )
-            padder = vtk_icore.vtkImageConstantPad()
-            padder.SetConstant(0)
-            padder.SetInputDataObject(0, vtk_image)
-            padder.SetOutputWholeExtent(new_extent)
-            padder.Update(0)
-            vtk_image = padder.GetOutput()
-
-            # update the image properties
-            vtk_image.SetDirectionMatrix(sitk_image.GetDirection())
-            vtk_image.SetOrigin(sitk_image.GetOrigin())
-            vtk_image.SetSpacing(sitk_image.GetSpacing())
-
-        # apply gaussian smoothing
-        foreground_amount = sitk.GetArrayFromImage(sitk_image).sum() / 255
-        if foreground_amount > smooth_threshold and image_smoothing:
-            gaussian = vtk_igen.vtkImageGaussianSmooth()
-            gaussian.SetInputDataObject(0, vtk_image)
-            gaussian.SetStandardDeviation(smooth_sigma)
-            gaussian.SetRadiusFactor(smooth_radius)
-            gaussian.Update(0)
-            vtk_image = gaussian.GetOutputDataObject(0)
-
-            # apply the thresholding
-            image_threshold = vtk_icore.vtkImageThreshold()
-            image_threshold.ThresholdByUpper(127.5)
-            image_threshold.SetInValue(255)
-            image_threshold.SetOutValue(0)
-            image_threshold.SetInputDataObject(0, vtk_image)
-            image_threshold.Update(0)
-            vtk_image = image_threshold.GetOutputDataObject(0)
-
-            # update the image properties
-            vtk_image.SetDirectionMatrix(sitk_image.GetDirection())
-            vtk_image.SetOrigin(sitk_image.GetOrigin())
-            vtk_image.SetSpacing(sitk_image.GetSpacing())
-
-        # apply flying edges
-        flying_edges = vtk_fcore.vtkFlyingEdges3D()
-        flying_edges.SetInputDataObject(0, vtk_image)
-        flying_edges.SetValue(0, 255)
-        flying_edges.ComputeGradientsOff()
-        flying_edges.ComputeNormalsOff()
-        flying_edges.Update(0)
-        model = flying_edges.GetOutputDataObject(0)
-
-        # apply decimation
-        if foreground_amount > decimate_threshold:
-            decimate = vtk_fcore.vtkDecimatePro()
-            decimate.SetInputConnection(0, flying_edges.GetOutputPort(0))
-            decimate.SetTargetReduction(decimate_reduction)
-            decimate.PreserveTopologyOn()
-            decimate.SetMaximumError(1)
-            decimate.SplittingOff()
-            decimate.SetFeatureAngle(60.0)
-            decimate.Update(0)
-            model = decimate.GetOutputDataObject(0)
-
-        # smooth via the sinc filter
-        if model_smooth_iter > 0:
-            smoother = vtk_fcore.vtkWindowedSincPolyDataFilter()
-            smoother.SetInputDataObject(0, model)
-            smoother.SetNumberOfIterations(model_smooth_iter)
-            smoother.BoundarySmoothingOff()
-            smoother.FeatureEdgeSmoothingOff()
-            smoother.SetFeatureAngle(60.0)
-            smoother.SetPassBand(model_smooth_pass_band)
-            smoother.NonManifoldSmoothingOn()
-            smoother.NormalizeCoordinatesOn()
-            smoother.Update(0)
-            model = smoother.GetOutputDataObject(0)
-
-        # get normals
-        normals = vtk_fcore.vtkPolyDataNormals()
-        normals.SetInputDataObject(0, model)
-        normals.SetFeatureAngle(60.0)
-
-        # strip the polydata
-        stripper = vtk_fcore.vtkStripper()
-        stripper.SetInputConnection(0, normals.GetOutputPort(0))
-        stripper.JoinContiguousSegmentsOn()
-        stripper.Update(0)
-        stripped = stripper.GetOutput()
-
-        return stripped
-
-    def _get_2d_contours(
-        self, polydata: vtk_dm.vtkPolyData, min_segment_lines: int = 0
-    ) -> List[Optional[List[List[List[float]]]]]:
-        """Get the 2D contours of the provided :class:`vtk.vtkPolyData` instance that correspond with the referenced
-        DICOM image series.
-
-        Args:
-            polydata (vtk.vtkPolyData): The :class:`vtk.vtkPolyData` instance to get the 2D contours for.
-            min_segment_lines (int): The minimum number of lines that a contour segment must have to be considered
-             (default: 0).
-
-        Returns:
-            List[Optional[List[List[List[float]]]]]: The 2D contours of the provided :class:`vtk.vtkPolyData` instance
-            that correspond with the referenced DICOM image series.
-        """
-        origin = self.image_datasets[0].ImagePositionPatient
-        origin = [float(val) for val in origin]
-        first_pos = self.image_datasets[0].ImagePositionPatient
-        last_pos = self.image_datasets[-1].ImagePositionPatient
-        length = np.abs(np.linalg.norm(np.array(last_pos) - np.array(first_pos)))
-        slice_spacing = length / (len(self.image_datasets) - 1)
-        normal = tuple(
-            np.cross(
-                np.array(self.image_datasets[0].get("ImageOrientationPatient")[0:3]),
-                np.array(self.image_datasets[0].get("ImageOrientationPatient")[3:6]),
-            )
-        )
-
-        # create the initial cutting plane
-        plane = vtk_dm.vtkPlane()
-        plane.SetOrigin(*origin)
-        plane.SetNormal(*normal)
-
-        # create the cutter
-        cutter = vtk_fcore.vtkCutter()
-        cutter.SetInputDataObject(0, polydata)
-        cutter.SetCutFunction(plane)
-        cutter.GenerateTrianglesOn()
-        cutter.GenerateValues(len(self.image_datasets), 0, length)
-
-        # create the cleaner
-        cleaner = vtk_fcore.vtkCleanPolyData()
-        cleaner.SetInputConnection(0, cutter.GetOutputPort(0))
-        cleaner.SetAbsoluteTolerance(0.01)
-        cleaner.PointMergingOn()
-        cleaner.Update(0)
-
-        # get the polylines
-        loop = vtk_fmodel.vtkContourLoopExtraction()
-        loop.SetInputConnection(0, cleaner.GetOutputPort(0))
-        loop.SetOutputModeToPolylines()
-        loop.SetNormal(*normal)
-        loop.Update(0)
-        looped = loop.GetOutput()
-
-        # sort the polydata
-        sorter = vtk_fhybrid.vtkDepthSortPolyData()
-        sorter.SetInputDataObject(0, looped)
-        sorter.SetVector(*tuple(np.array(normal) * -1))
-        sorter.SetOrigin(*origin)
-        sorter.SetSortScalars(True)
-        sorter.SetDirectionToSpecifiedVector()
-        sorter.Update(0)
-        looped = sorter.GetOutput()
-
-        # get the polylines for each slice if there are any
-        cells = looped.GetLines()
-        points = looped.GetPoints()
-
-        indices = vtk_ccore.vtkIdList()
-        cell_indicator = cells.GetNextCell(indices)
-
-        # if there are no cells return an empty list
-        if cell_indicator == 0:
-            return [None for _ in range(len(self.image_datasets))]
-
-        # get the slice planes
-        slice_planes = {}
-        for slice_idx, dataset in enumerate(self.image_datasets):
-            slice_plane = vtk_dm.vtkPlane()
-            slice_plane.SetOrigin(*dataset.ImagePositionPatient)
-            slice_plane.SetNormal(*normal)
-
-            slice_planes.update({slice_idx: slice_plane})
-
-        # get the contours for the appropriate slices
-        contours_points: List[Optional[List[List[float]]]] = [None for _ in range(len(self.image_datasets))]
-        while cell_indicator == 1:
-            if indices.GetNumberOfIds() <= min_segment_lines:
-                cell_indicator = cells.GetNextCell(indices)
-                continue
-
-            reference_point = points.GetPoint(indices.GetId(0))
-
-            for slice_idx, slice_plane in slice_planes.items():
-                distance = slice_plane.DistanceToPlane(reference_point)
-
-                if distance <= slice_spacing * 0.5:
-                    contour_points = []
-
-                    for idx in range(indices.GetNumberOfIds()):
-                        contour_points.append(points.GetPoint(indices.GetId(idx)))
-
-                    if isinstance(contours_points[slice_idx], list):
-                        contours_points[slice_idx].append(contour_points)
-                    else:
-                        contours_points[slice_idx] = [contour_points]
-
-                    cell_indicator = cells.GetNextCell(indices)
-                    break
-
-        return contours_points
-
-    def _append_roi_contour_sequence_entry(
-        self, contours: List[List[List[List[float]]]], color: Tuple[int, int, int], roi_number: int, rtss: Dataset
-    ) -> None:
-        """Append a ROIContourSequence entry to the given DICOM-RTSS.
-
-        Args:
-            contours (List[List[List[List[float]]]]): The 2D contours of the ROI.
-            color (Tuple[int, int, int]): The color of the ROI.
-            roi_number (int): The ROI number.
-            rtss (Dataset): The DICOM-RTSS to append the ROIContourSequence entry to.
-
-        Returns:
-            None
-        """
-        roi_contour = Dataset()
-        roi_contour.ROIDisplayColor = [str(color_) for color_ in color]
-        roi_contour.ReferencedROINumber = str(roi_number)
-
-        # create the contour sequence
-        contour_sequence = Sequence()
-        for slice_dataset, slice_coords in zip(self.image_datasets, contours):
-            if slice_coords is None:
-                continue
-
-            for slice_coord_set in slice_coords:
-                # create the contour image sequence
-                contour_image = Dataset()
-                contour_image.ReferencedSOPClassUID = str(slice_dataset.file_meta.MediaStorageSOPClassUID)
-                contour_image.ReferencedSOPInstanceUID = str(slice_dataset.SOPInstanceUID)
-
-                contour_image_sequence = Sequence()
-                contour_image_sequence.append(contour_image)
-
-                # append to the contour sequence
-                contour = Dataset()
-                contour.ContourImageSequence = contour_image_sequence
-                contour.ContourGeometricType = "CLOSED_PLANAR"
-                contour.NumberOfContourPoints = len(slice_coord_set)
-                contour.ContourData = [coord for point in slice_coord_set for coord in point]
-                contour_sequence.append(contour)
-
-        roi_contour.ContourSequence = contour_sequence
-
-        # append to the ROIContourSequence to the RTSS
-        rtss.ROIContourSequence.append(roi_contour)
-
-    def convert(self) -> Dataset:
-        """Convert the provided :class:`SimpleITK.Image` instances to a DICOM-RTSS :class:`~pydicom.dataset.Dataset`
-        instance using a three-dimensional reconstruction algorithm.
-
-        Returns:
-            Dataset: The generated DICOM-RTSS :class:`~pydicom.dataset.Dataset`.
-        """
-        rtss = self._generate_basic_rtss()
-
-        for idx, (label, name, color) in enumerate(zip(self.label_images, self.roi_names, self.colors)):
-            # check if the image is empty
-            label_image_np = sitk.GetArrayFromImage(label)
-            if np.sum(label_image_np) == 0:
-                contours = [None for _ in range(len(self.image_datasets))]
-
-            else:
-                # check if specific parameters are given for this ROI
-                if self.config.get_image_params(name) is not None:
-                    image_params = self.config.get_image_params(name)
-                    image_smooth = image_params.get("image_smoothing")
-                    image_smooth_sigma = image_params.get("image_smoothing_sigma")
-                    image_smooth_radius = image_params.get("image_smoothing_radius")
-                    image_threshold = image_params.get("image_smoothing_threshold")
-                    decimate_reduction = image_params.get("decimate_reduction")
-                    decimate_threshold = image_params.get("decimate_threshold")
-                    model_smoothing_iter = image_params.get("model_smoothing_iterations")
-                    model_smoothing_pass_band = image_params.get("model_smoothing_pass_band")
-                    min_segment_lines = image_params.get("min_segment_lines")
-                else:
-                    image_params = self.config.get_general_params()
-                    image_smooth = image_params.get("image_smoothing")
-                    image_smooth_sigma = image_params.get("image_smoothing_sigma")
-                    image_smooth_radius = image_params.get("image_smoothing_radius")
-                    image_threshold = image_params.get("image_smoothing_threshold")
-                    decimate_reduction = image_params.get("decimate_reduction")
-                    decimate_threshold = image_params.get("decimate_threshold")
-                    model_smoothing_iter = image_params.get("model_smoothing_iterations")
-                    model_smoothing_pass_band = image_params.get("model_smoothing_pass_band")
-                    min_segment_lines = image_params.get("min_segment_lines")
-
-                # preprocess the image
-                label = self.preprocess_image(label)
-
-                # Get polydata
-                polydata = self._get_3d_model(
-                    label,
-                    image_smooth,
-                    image_smooth_sigma,
-                    image_smooth_radius,
-                    image_threshold,
-                    decimate_reduction,
-                    decimate_threshold,
-                    model_smoothing_iter,
-                    model_smoothing_pass_band,
-                )
-
-                # Get the contour data
-                contours = self._get_2d_contours(polydata, min_segment_lines)
-
-            # enhance the rtss with the data
-            self._append_structure_set_roi_sequence_entry(name, idx + 1, rtss)
-            self._append_roi_contour_sequence_entry(contours, color, idx + 1, rtss)
-            self._append_rt_roi_observation(idx + 1, rtss)
-
-        return rtss
-
-
-class DicomImageSeriesConverter(Converter):
-    """A :class:`Converter` class for converting DICOM image series to one or multiple
-    :class:`~pyradise.data.image.IntensityImage` instances.
-
-    Args:
-        image_info (Tuple[DicomSeriesImageInfo, ...]): The :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo`
-         entries of the images to convert.
-        registration_info (Tuple[DicomSeriesRegistrationInfo, ...]): The
-         :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries (default: tuple()).
-    """
-
-    def __init__(
-        self,
-        image_info: Tuple[DicomSeriesImageInfo, ...],
-        registration_info: Tuple[DicomSeriesRegistrationInfo, ...] = tuple(),
-    ) -> None:
-        super().__init__()
-        self.image_info = image_info
-        self.reg_info = registration_info
-
-    def _get_image_info_by_series_instance_uid(self, series_instance_uid: str) -> Optional[DicomSeriesImageInfo]:
-        """Get the :class:`DicomSeriesImageInfo` entries which match with the specified SeriesInstanceUID.
-
-        Args:
-            series_instance_uid (str): The SeriesInstanceUID which must be contained in the returned
-             :class:`DicomSeriesImageInfo` entries.
-
-        Returns:
-            Optional[DicomSeriesImageInfo]: The :class:`DicomSeriesImageInfo` entries which contains the specified
-             SeriesInstanceUID or None
-        """
-        if not self.image_info:
-            return None
-
-        selected = [info for info in self.image_info if info.series_instance_uid == series_instance_uid]
-
-        if len(selected) > 1:
-            raise ValueError(f"Multiple image infos detected with the same SeriesInstanceUID ({series_instance_uid})!")
-
-        if not selected:
-            return None
-
-        return selected[0]
-
-    def _get_registration_info(
-        self,
-        image_info: DicomSeriesImageInfo,
-    ) -> Optional[DicomSeriesRegistrationInfo]:
-        """Get the :class:`DicomSeriesRegistrationInfo` instance which belongs to the specified
-        :class:`DicomSeriesImageInfo`, if available. If no :class:`DicomSeriesRegistrationInfo` is available
-        :class:`None` is returned.
-
-        Args:
-            image_info (DicomSeriesImageInfo): The :class:`DicomSeriesImageInfo` for which the
-             :class:`DicomSeriesRegistrationInfo` is requested.
-
-        Returns:
-            Optional[DicomSeriesRegistrationInfo]: The :class:`DicomSeriesRegistrationInfo` which belongs to the
-             specified :class:`DicomSeriesImageInfo` or :class:`None`.
-        """
-        if not self.reg_info:
-            return None
-
-        selected = []
-        for reg_info in self.reg_info:
-            reg_info.update() if not reg_info.is_updated() else None
-
-            if reg_info.referenced_series_instance_uid_transform == image_info.series_instance_uid:
-                selected.append(reg_info)
-
-        if len(selected) > 1:
-            raise ValueError(
-                f"Multiple registration infos detected with the same referenced "
-                f"SeriesInstanceUID ({image_info.series_instance_uid})!"
-            )
-
-        if not selected:
-            return None
-
-        return selected[0]
-
-    @staticmethod
-    def _transform_image(image: sitk.Image, transform: sitk.Transform, is_intensity: bool) -> sitk.Image:
-        """Transform an :class:`sitk.Image` according to the provided :class:`sitk.Transform`.
-
-        Args:
-            image (sitk.Image): The image to transform.
-            transform (sitk.Transform): The transform to be applied to the image.
-            is_intensity (bool): If True the image will be resampled using a B-Spline interpolation function,
-             otherwise a nearest neighbour interpolation function will be used.
-
-        Returns:
-            sitk.Image: The transformed image.
-        """
-        # select the appropriate interpolation function
-        if is_intensity:
-            interpolator = sitk.sitkBSpline
-        else:
-            interpolator = sitk.sitkNearestNeighbor
-
-        image_np = sitk.GetArrayFromImage(image)
-        default_pixel_value = np.min(image_np).astype(float)
-
-        # compute the new origin
-        new_origin = transform.GetInverse().TransformPoint(image.GetOrigin())
-
-        # compute the new direction
-        new_direction_0 = transform.TransformVector(image.GetDirection()[:3], image.GetOrigin())
-        new_direction_1 = transform.TransformVector(image.GetDirection()[3:6], image.GetOrigin())
-        new_direction_2 = transform.TransformVector(image.GetDirection()[6:], image.GetOrigin())
-        new_direction = new_direction_0 + new_direction_1 + new_direction_2
-
-        new_direction_matrix = np.array(new_direction).reshape(3, 3)
-        original_direction_matrix = np.array(image.GetDirection()).reshape(3, 3)
-        new_direction_corr = np.dot(
-            np.dot(new_direction_matrix, original_direction_matrix).transpose(), original_direction_matrix
-        ).transpose()
-
-        # resample the image
-        resampled_image = sitk.Resample(
-            image,
-            image.GetSize(),
-            transform=transform,
-            interpolator=interpolator,
-            outputOrigin=new_origin,
-            outputSpacing=image.GetSpacing(),
-            outputDirection=tuple(new_direction_corr.flatten()),
-            defaultPixelValue=default_pixel_value,
-            outputPixelType=image.GetPixelIDValue(),
-        )
-
-        return resampled_image
-
-    def convert(self) -> Tuple[IntensityImage, ...]:
-        """Convert the provided :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries to one or multiple
-        :class:`~pyradise.data.image.IntensityImage` instances.
-
-        Returns:
-            Tuple[IntensityImage, ...]: The converted :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        images = []
-
-        for info in self.image_info:
-            # read the image
-            reader = sitk.ImageSeriesReader()
-            reader.SetFileNames(info.path)
-            image = reader.Execute()
-
-            # get the registration info if available
-            reg_info = self._get_registration_info(info)
-
-            if not info.is_updated():
-                info.update()
-
-            # if no registration info is available, the image is added as is
-            if reg_info is None:
-                image_ = IntensityImage(image, info.modality)
-                image_.add_data({"SeriesInstanceUID": info.series_instance_uid})
-                images.append(image_)
-
-            # else the image is transformed
-            else:
-                ref_series_instance_uid = reg_info.referenced_series_instance_uid_identity
-                ref_image_info = self._get_image_info_by_series_instance_uid(ref_series_instance_uid)
-
-                if ref_image_info is None:
-                    raise ValueError(
-                        f"The reference image with SeriesInstanceUID {ref_series_instance_uid} "
-                        f"is missing for the registration!"
-                    )
-
-                image = self._transform_image(image, reg_info.transform, is_intensity=True)
-                image_ = IntensityImage(image, info.modality)
-                image_.add_data({"SeriesInstanceUID": info.series_instance_uid})
-                images.append(image_)
-
-        return tuple(images)
-
-
-class DicomRTSSSeriesConverter(Converter):
-    """A :class:`Converter` class for converting a DICOM-RTSS (i.e.
-    :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo`) to one or multiple
-    :class:`~pyradise.data.image.SegmentationImage` instances.
-
-    Notes:
-        The user may provide all available :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` and
-        :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries to the corresponding ``image_infos``
-        and ``registration_infos``, respectively. In this case the :class:`DicomRTSSSeriesConverter` will sort out
-        unused entries.
-
-    Args:
-        rtss_infos (Union[DicomSeriesRTSSInfo, Tuple[DicomSeriesRTSSInfo, ...]]): The
-         :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` instance holding the information to be converted.
-        image_infos (Tuple[DicomSeriesImageInfo, ...]): The :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo`
-         entries which are referenced in the :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` instance.
-        registration_infos (Optional[Tuple[DicomSeriesRegistrationInfo, ...]]): The
-         :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries referencing the DICOM image or
-         DICOM-RTSS.
-        fill_hole_search_distance (int): The search distance for the hole filling algorithm. If the search distance is
-         set to zero the hole filling algorithm is omitted. The search distance must be an odd number larger than 1
-         (default: 0).
-    """
-
-    def __init__(
-        self,
-        rtss_infos: Union[DicomSeriesRTSSInfo, Tuple[DicomSeriesRTSSInfo, ...]],
-        image_infos: Tuple[DicomSeriesImageInfo, ...],
-        registration_infos: Optional[Tuple[DicomSeriesRegistrationInfo, ...]],
-        fill_hole_search_distance: int = 0,
-    ) -> None:
-        super().__init__()
-
-        if isinstance(rtss_infos, DicomSeriesRTSSInfo):
-            self.rtss_infos = (rtss_infos,)
-        else:
-            self.rtss_infos = rtss_infos
-
-        self.image_infos = image_infos
-        self.reg_infos = registration_infos
-
-        # store the fill hole search distance
-        if fill_hole_search_distance == 0:
-            self.fill_hole_distance = 0
-        elif fill_hole_search_distance % 2 == 0:
-            raise ValueError("The fill hole search distance must be an odd number.")
-        elif fill_hole_search_distance == 1:
-            raise ValueError("The fill hole search distance must be larger than 1.")
-        else:
-            self.fill_hole_distance = fill_hole_search_distance
-
-    def _get_referenced_image_info(self, rtss_info: DicomSeriesRTSSInfo) -> Optional[DicomSeriesImageInfo]:
-        """Get the :class:`DicomSeriesImageInfo` which is referenced by the provided :class:`DicomSeriesRTSSInfo`.
-
-        Args:
-            rtss_info (DicomSeriesRTSSInfo): The :class:`DicomSeriesRTSSInfo` containing the reference.
-
-        Returns:
-            Optional[DicomSeriesImageInfo]: The referenced :class:`DicomSeriesImageInfo` or :class:`None` if no
-             reference is available.
-
-        """
-        if not self.image_infos:
-            return None
-
-        selected = [info for info in self.image_infos if info.series_instance_uid == rtss_info.referenced_instance_uid]
-
-        if len(selected) > 1:
-            raise ValueError(
-                f"Multiple image infos detected with the same referenced "
-                f"SeriesInstanceUID ({rtss_info.referenced_instance_uid})!"
-            )
-
-        if not selected:
-            raise ValueError(
-                f"The reference image with the SeriesInstanceUID "
-                f"{rtss_info.referenced_instance_uid} for the RTSS conversion is missing!"
-            )
-
-        return selected[0]
-
-    def _get_referenced_registration_info(
-        self,
-        rtss_info: DicomSeriesRTSSInfo,
-    ) -> Optional[DicomSeriesRegistrationInfo]:
-        """Get the :class:`DicomSeriesRegistrationInfo` which is referenced in the :class:`DicomSeriesRTSSInfo`.
-
-        Args:
-            rtss_info (DicomSeriesRTSSInfo): The :class:`DicomSeriesRTSSInfo` for which the referenced
-             :class:`DicomSeriesRegistrationInfo` should be retrieved.
-
-        Returns:
-            Optional[DicomSeriesRegistrationInfo]: The :class:`DicomSeriesRegistrationInfo` instance referenced in the
-             RTSS or None.
-        """
-
-        if not self.reg_infos:
-            return None
-
-        selected = []
-
-        for registration_info in self.reg_infos:
-            if registration_info.referenced_series_instance_uid_transform == rtss_info.referenced_instance_uid:
-                selected.append(registration_info)
-
-        if not selected:
-            return None
-
-        if len(selected) > 1:
-            raise NotImplementedError(
-                "The number of referenced registrations is larger than one! "
-                "The sequential application of registrations is not supported yet!"
-            )
-
-        return selected[0]
-
-    def convert(self) -> Tuple[SegmentationImage, ...]:
-        """Convert the :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` instances into one or multiple
-        :class:`~pyradise.data.image.SegmentationImage` instances.
-
-        Returns:
-            Tuple[SegmentationImage, ...]: The converted :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-        images = []
-
-        for rtss_info in self.rtss_infos:
-            ref_image_info = self._get_referenced_image_info(rtss_info)
-            ref_reg_info = self._get_referenced_registration_info(rtss_info)
-
-            if ref_reg_info:
-                ref_reg_info.update() if not ref_reg_info.is_updated() else None
-                reg_dataset = ref_reg_info.dataset
-            else:
-                reg_dataset = None
-
-            dataset = load_dataset(rtss_info.get_path()[0])
-            structures = RTSSToSegmentConverter(
-                dataset, ref_image_info.path, reg_dataset, self.fill_hole_distance
-            ).convert()
-
-            for roi_name, segmentation_image in structures.items():
-                segmentation = SegmentationImage(segmentation_image, Organ(roi_name), rtss_info.get_annotator())
-                segmentation.add_data(
-                    {"SeriesInstanceUID": rtss_info.referenced_instance_uid, "ROINames": rtss_info.roi_names}
-                )
-                images.append(segmentation)
-
-        return tuple(images)
-
-
-class SubjectToRTSSConverter(Converter):
-    """A :class:`Converter` class for converting the :class:`~pyradise.data.image.SegmentationImage` instances of a
-    :class:`~pyradise.data.subject.Subject` instance to a :class:`~pydicom.dataset.Dataset` instance.
-
-    Note:
-        This class is typically used at the end of a processing pipeline to output a DICOM-RTSS file containing the
-        segmentation results of the pipeline.
-
-    Note:
-        This class can take a :class:`RTSSMetaData` instance as input to specify certain DICOM attributes of the
-        output DICOM-RTSS. If no instance is provided, the default values will be used.
-
-    Important:
-        The ``config`` parameter defines the type of conversion algorithm. If specific conversion parameters are
-        required for a certain :class:`~pyradise.data.image.SegmentationImage` instance, they must be provided in the
-        appropriate :class:`RTSSConverterConfiguration` (i.e., :class:`RTSSConverter2DConfiguration` or
-        :class:`RTSSConverter3DConfiguration`). Furthermore, the ``image_identifier`` parameter must be set to the
-        organ name of the :class:`~pyradise.data.image.SegmentationImage` instance. Otherwise, segmentation masks with
-        specific parameters can not be identified.
-
-    Args:
-        subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be converted to a DICOM-RTSS
-         :class:`~pydicom.dataset.Dataset` instance.
-        infos (Tuple[SeriesInfo, ...]): The :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries provided for
-         the conversion (only :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` will be considered).
-        reference_modality (Union[Modality, str]): The reference :class:`~pyradise.data.modality.Modality` of the
-         images to be used for the conversion to DICOM-RTSS.
-        config (Union[RTSSConverter2DConfiguration, RTSSConverter3DConfiguration]): The configuration for the conversion
-         procedure. The type of conversion configuration determines also the conversion algorithm (2D or 3D) that is
-         used.
-        meta_data (RTSSMetaData): The configuration to specify certain DICOM attributes (default: RTSSMetaData()).
-        colors (Optional[Tuple[Tuple[int, int, int], ...]]): The colors to be used for the segmentation masks. If None,
-         the default colors will be used (default: None).
-    """
-
-    def __init__(
-        self,
-        subject: Subject,
-        infos: Tuple[SeriesInfo, ...],
-        reference_modality: Union[Modality, str],
-        config: Union[RTSSConverter2DConfiguration, RTSSConverter3DConfiguration],
-        meta_data: RTSSMetaData = RTSSMetaData(),
-        colors: Optional[Tuple[Tuple[int, int, int], ...]] = None,
-    ) -> None:
-        super().__init__()
-
-        assert subject.segmentation_images, "The subject must contain segmentation images!"
-        self.subject = subject
-
-        assert infos, "There must be infos provided for the conversion!"
-
-        reference_modality_: Modality = str_to_modality(reference_modality)
-        image_infos = [
-            entry
-            for entry in infos
-            if isinstance(entry, DicomSeriesImageInfo) and entry.modality == reference_modality_
-        ]
-
-        assert image_infos, "There must be image infos in the provided infos!"
-
-        assert len(image_infos) == 1, "There are multiple image infos fitting the reference modality!"
-        self.image_info = image_infos[0]
-        self.ref_modality = reference_modality_
-
-        if not isinstance(config, (RTSSConverter2DConfiguration, RTSSConverter3DConfiguration)):
-            raise ValueError(f"The config type {type(config)} is not supported!")
-
-        self.config: Union[RTSSConverter2DConfiguration, RTSSConverter3DConfiguration] = config
-        self.meta_data = meta_data
-
-        self._validate_colors(colors)
-        self.colors = colors
-
-    @staticmethod
-    def _validate_colors(colors: Optional[Tuple[Tuple[int, int, int], ...]]) -> None:
-        """Validate the provided colors.
-
-        Args:
-            colors (Optional[Tuple[Tuple[int, int, int], ...]]): The colors to be validated.
-
-        Raises:
-            ValueError: If the provided colors are not valid.
-
-        Returns:
-            None: If the provided colors are valid.
-        """
-        if not colors:
-            return
-
-        for color in colors:
-            if len(color) != 3:
-                raise ValueError(f"The color {color} is not valid!")
-
-            for value in color:
-                if not isinstance(value, int) or value < 0 or value > 255:
-                    raise ValueError(f"The color {color} is not valid!")
-
-    def convert(self) -> Dataset:
-        """Convert a :class:`~pyradise.data.subject.Subject` instance to a DICOM-RTSS :class:`~pydicom.dataset.Dataset`
-        instance.
-
-        Returns:
-            Dataset: The DICOM-RTSS :class:`~pydicom.dataset.Dataset` instance generated from the provided
-            :class:`~pyradise.data.subject.Subject` instance.
-        """
-        # get the image data and the label names
-        sitk_images = []
-        label_names = []
-        for image in self.subject.segmentation_images:
-            sitk_image = image.get_image_data()
-            if "int" not in sitk_image.GetPixelIDTypeAsString():
-                try:
-                    sitk_image = sitk.Cast(sitk_image, sitk.sitkUInt8)
-                except Exception:  # noqa
-                    warnings.warn(
-                        f"Could not cast SegmentationImage for organ {image.get_organ(True)} to an integer "
-                        "type. The SegmentationImage will be skipped!"
-                    )
-                    continue
-
-            sitk_images.append(sitk_image)
-            label_names.append(image.get_organ(as_str=True))
-
-        # load the image datasets
-        image_datasets = load_datasets(self.image_info.path)
-
-        # convert the images to a rtss
-        if isinstance(self.config, RTSSConverter2DConfiguration):
-            rtss = SegmentToRTSSConverter2D(
-                label_images=tuple(sitk_images),
-                ref_image_datasets=image_datasets,
-                roi_names=tuple(label_names),
-                colors=self.colors,
-                meta_data=self.meta_data,
-                config=self.config,
-            ).convert()
-
-        elif isinstance(self.config, RTSSConverter3DConfiguration):
-            rtss = SegmentToRTSSConverter3D(
-                label_images=tuple(sitk_images),
-                ref_image_datasets=image_datasets,
-                roi_names=tuple(label_names),
-                colors=self.colors,
-                meta_data=self.meta_data,
-                config=self.config,
-            ).convert()
-
-        else:
-            raise ValueError(f"Invalid configuration type: {type(self.config)}!")
-
-        return rtss
-
-
-# def show_polydata(polydata: vtk_dm.vtkPolyData) -> None:
-#     import vtkmodules.vtkInteractionStyle
-#     import vtkmodules.vtkRenderingOpenGL2
-#     from vtkmodules.vtkCommonColor import vtkNamedColors
-#     from vtkmodules.vtkRenderingCore import (
-#         vtkActor,
-#         vtkPolyDataMapper,
-#         vtkRenderWindow,
-#         vtkRenderWindowInteractor,
-#         vtkRenderer
-#     )
-#
-#     # Visualize
-#     colors = vtkNamedColors()
-#
-#     mapper = vtkPolyDataMapper()
-#     mapper.SetInputData(polydata)
-#     actor = vtkActor()
-#     actor.SetMapper(mapper)
-#     actor.GetProperty().SetLineWidth(4)
-#     actor.GetProperty().SetColor(colors.GetColor3d("Peacock"))
-#
-#     renderer = vtkRenderer()
-#     renderWindow = vtkRenderWindow()
-#     renderWindow.SetWindowName("Line")
-#     renderWindow.AddRenderer(renderer)
-#     renderWindowInteractor = vtkRenderWindowInteractor()
-#     renderWindowInteractor.SetRenderWindow(renderWindow)
-#
-#     renderer.SetBackground(*colors.GetColor3d("Silver"))
-#     renderer.AddActor(actor)
-#
-#     renderWindow.Render()
-#     renderWindowInteractor.Start()
+import itertools
+import warnings
+from abc import ABC, abstractmethod
+from copy import deepcopy
+from dataclasses import dataclass
+from datetime import datetime
+from typing import Any, Dict, List, Optional, Tuple, Union
+
+import cv2 as cv
+import itk
+import numpy as np
+import scipy
+import SimpleITK as sitk
+import vtkmodules.vtkCommonCore as vtk_ccore
+import vtkmodules.vtkCommonDataModel as vtk_dm
+import vtkmodules.vtkFiltersCore as vtk_fcore
+import vtkmodules.vtkFiltersHybrid as vtk_fhybrid
+import vtkmodules.vtkFiltersModeling as vtk_fmodel
+import vtkmodules.vtkImagingCore as vtk_icore
+import vtkmodules.vtkImagingGeneral as vtk_igen
+from pydicom import Dataset, FileDataset, Sequence
+from pydicom.dataset import FileMetaDataset
+from pydicom.tag import Tag
+from pydicom.uid import (PYDICOM_IMPLEMENTATION_UID, ImplicitVRLittleEndian,
+                         generate_uid)
+
+from pyradise.data import (IntensityImage, Modality, Organ, SegmentationImage,
+                           Subject, str_to_modality)
+from pyradise.utils import (chunkify, convert_to_itk_image,
+                            get_slice_direction, get_slice_position,
+                            get_spacing_between_slices, load_dataset,
+                            load_dataset_tag, load_datasets)
+
+from .series_info import (DicomSeriesImageInfo, DicomSeriesRegistrationInfo,
+                          DicomSeriesRTSSInfo, RegistrationInfo, SeriesInfo)
+
+__all__ = [
+    "Converter",
+    "DicomImageSeriesConverter",
+    "DicomRTSSSeriesConverter",
+    "SubjectToRTSSConverter",
+    "RTSSToSegmentConverter",
+    "SegmentToRTSSConverter2D",
+    "SegmentToRTSSConverter3D",
+    "RTSSMetaData",
+    "RTSSConverter2DConfiguration",
+    "RTSSConverter3DConfiguration",
+]
+
+ROI_GENERATION_ALGORITHMS = ["AUTOMATIC", "SEMIAUTOMATIC", "MANUAL"]
+
+COLOR_PALETTE = [
+    [255, 0, 255],
+    [0, 235, 235],
+    [255, 255, 0],
+    [255, 0, 0],
+    [0, 132, 255],
+    [0, 240, 0],
+    [255, 175, 0],
+    [0, 208, 255],
+    [180, 255, 105],
+    [255, 20, 147],
+    [160, 32, 240],
+    [0, 255, 127],
+    [255, 114, 0],
+    [64, 224, 208],
+    [0, 178, 47],
+    [220, 20, 60],
+    [238, 130, 238],
+    [218, 165, 32],
+    [255, 140, 190],
+    [0, 0, 255],
+    [255, 225, 0],
+]
+
+
+class Converter(ABC):
+    """An abstract base class for all :class:`Converter` classes. Typically, the :class:`Converter` classes are used to
+    convert DICOM data from and to other representations. For example, the :class:`DicomImageSeriesConverter` converts
+    DICOM image series to :class:`~pyradise.data.image.IntensityImage` instances and applies the associated DICOM
+    registration if provided.
+    """
+
+    @abstractmethod
+    def convert(self) -> Any:
+        """Convert the provided :class:`~pyradise.fileio.series_info.DicomSeriesInfo`.
+
+        Returns:
+            Any: The converted data.
+        """
+        raise NotImplementedError()
+
+
+class RTSSToSegmentConverter(Converter):
+    """A low-level DICOM-RTSS to SimpleITK image :class:`Converter` class converting the content of the DICOM-RTSS to
+    one or multiple SimpleITK images. In contrast to the :class:`DicomRTSSSeriesConverter` this class generates a dict
+    of binary :class:`SimpleITK.Image` instances and organ names instead of a tuple of
+    :class:`~pyradise.data.image.SegmentationImage` s.
+
+    Notes:
+        Typically, this class is not used directly by the user but via the :class:`DicomRTSSSeriesConverter` which
+        processes :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries directly.
+
+        This class can be used with a DICOM registration which will be applied to the reference image and the structure
+        set. However, the registration must reference the corresponding DICOM image, otherwise the registration will not
+        be applied.
+
+    Args:
+        rtss_dataset (Union[str, Dataset]): The path to the DICOM-RTSS file or DICOM-RTSS
+         :class:`~pydicom.dataset.Dataset`.
+        image_datasets (Union[Tuple[str], Tuple[Dataset]]): The path to the DICOM image files or the DICOM image
+         :class:`~pydicom.dataset.Dataset` entries which are referenced in the ``rtss_dataset``.
+        registration_dataset (Union[str, Dataset, None]): The path to a DICOM registration file or a DICOM
+         registration :class:`~pydicom.dataset.Dataset` entry which contains a reference to the DICOM image
+         (default: None).
+        fill_hole_search_distance (int): The search distance for the hole filling algorithm. If the search distance is
+         set to zero the hole filling algorithm is omitted. The search distance must be an odd number larger than 1
+         (default: 0).
+    """
+
+    def __init__(
+        self,
+        rtss_dataset: Union[str, Dataset],
+        image_datasets: Union[Tuple[str], Tuple[Dataset]],
+        registration_dataset: Union[str, Dataset, None] = None,
+        fill_hole_search_distance: int = 0,
+    ) -> None:
+        super().__init__()
+
+        # get the RTSS dataset and the referenced SeriesInstanceUID
+        if isinstance(rtss_dataset, str):
+            self.rtss_dataset: Dataset = load_dataset(rtss_dataset)
+        else:
+            self.rtss_dataset: Dataset = rtss_dataset
+        ref_series_uid = self._get_ref_series_instance(self.rtss_dataset)
+
+        # get the appropriate image datasets according to the RTSS
+        if isinstance(image_datasets[0], str):
+            self.rtss_image_datasets = self._load_ref_image_datasets(image_datasets, ref_series_uid)
+        else:
+            self.rtss_image_datasets = self._clean_image_datasets_for_rtss(image_datasets, ref_series_uid)
+
+        # get the registration dataset and the appropriate images
+        if not registration_dataset:
+            self.reg_dataset: Optional[Dataset] = None
+        elif isinstance(registration_dataset, str):
+            self.reg_dataset: Optional[Dataset] = load_dataset(registration_dataset)
+        elif isinstance(registration_dataset, Dataset):
+            self.reg_dataset: Optional[Dataset] = registration_dataset
+        self.reg_image_datasets = self._get_image_datasets_for_reg(image_datasets, self.reg_dataset)
+
+        # store the fill hole search distance
+        if fill_hole_search_distance == 0:
+            self.fill_hole_distance = 0
+        elif fill_hole_search_distance % 2 == 0:
+            raise ValueError("The fill hole search distance must be an odd number.")
+        elif fill_hole_search_distance == 1:
+            raise ValueError("The fill hole search distance must be larger than 1.")
+        else:
+            self.fill_hole_distance = fill_hole_search_distance
+
+        # validate the loaded data
+        self._validate_rtss_dataset(self.rtss_dataset)
+        self._validate_rtss_image_references(self.rtss_dataset, self.rtss_image_datasets)
+        self.reg_dataset: Optional[Dataset] = self._validate_registration_dataset(self.reg_dataset, self.rtss_dataset)
+
+    @staticmethod
+    def _get_ref_series_instance(rtss_dataset: Dataset) -> str:
+        """Get the referenced SeriesInstanceUID of the image series in the RTSS dataset.
+
+        Args:
+            rtss_dataset (Dataset): The RTSS dataset.
+
+        Returns:
+            str: The referenced SeriesInstanceUID of the image series.
+        """
+        ref_series_instance_uids = []
+        for ref_frame_of_ref in rtss_dataset.get("ReferencedFrameOfReferenceSequence", []):
+            for rt_ref_study in ref_frame_of_ref.get("RTReferencedStudySequence", []):
+                for rt_ref_series in rt_ref_study.get("RTReferencedSeriesSequence", []):
+                    si_uid = rt_ref_series.get("SeriesInstanceUID", None)
+                    if si_uid is not None:
+                        ref_series_instance_uids.append(str(si_uid))
+
+        if len(ref_series_instance_uids) > 1:
+            raise Exception(
+                f"Multiple ({len(ref_series_instance_uids)}) referenced SeriesInstanceUIDs "
+                "have been retrieved from the RTSS but only one is allowed!"
+            )
+
+        if not ref_series_instance_uids:
+            raise Exception("No referenced SeriesInstanceUID could be retrieved!")
+
+        return ref_series_instance_uids[0]
+
+    @staticmethod
+    def _load_ref_image_datasets(image_paths: Tuple[str], referenced_series_uid: str) -> Tuple[Dataset]:
+        """Load the appropriate image datasets which are referenced in the RTSS dataset.
+
+        Args:
+            image_paths (Tuple[str]): The paths to the image datasets.
+            referenced_series_uid (str): The referenced SeriesInstanceUID.
+
+        Returns:
+            Tuple[Dataset]: The referenced image datasets.
+        """
+        # check all image file paths for the referenced SeriesInstanceUID
+        ref_image_files = []
+        for image_path in image_paths:
+            image_dataset = load_dataset_tag(image_path, (Tag(0x0020, 0x000E),))
+            if image_dataset.get("SeriesInstanceUID", "") == referenced_series_uid:
+                ref_image_files.append(image_path)
+
+        # load the appropriate image datasets
+        ref_image_datasets = []
+        for ref_image_file in ref_image_files:
+            ref_image_datasets.append(load_dataset(ref_image_file))
+
+        ref_image_datasets.sort(key=get_slice_position, reverse=False)
+
+        return tuple(ref_image_datasets)
+
+    @staticmethod
+    def _clean_image_datasets_for_rtss(image_datasets: Tuple[Dataset], referenced_series_uid: str) -> Tuple[Dataset]:
+        """Clean the image datasets based on the referenced SeriesInstanceUID.
+
+        Args:
+            image_datasets (Tuple[Dataset]): The image Datasets which should be analyzed.
+            referenced_series_uid (str): The referenced SeriesInstanceUID to identify the appropriate images.
+
+        Returns:
+            Tuple[Dataset]: The image datasets which are referenced by the RTSS Dataset.
+        """
+        selected = [
+            image_dataset
+            for image_dataset in image_datasets
+            if image_dataset.get("SeriesInstanceUID", None) == referenced_series_uid
+        ]
+
+        selected.sort(key=get_slice_position, reverse=False)
+
+        return tuple(selected)
+
+    @staticmethod
+    def _get_image_datasets_for_reg(
+        image_datasets: Union[Tuple[Dataset, ...], Tuple[str, ...]], registration_dataset: Optional[Dataset]
+    ) -> Optional[Tuple[Dataset, ...]]:
+        """Get the image datasets for registration. This function outputs the datasets which are referenced within
+         the registration dataset.
+
+        Args:
+            image_datasets (Union[Tuple[Dataset, ...], Tuple[str, ...]]): The image datasets to analyze.
+            registration_dataset (Optional[Dataset]): The registration dataset containing the references.
+
+        Returns:
+            Optional[Tuple[Dataset, ...]]: The datasets being referenced within the registration.
+        """
+        if not registration_dataset:
+            return None
+
+        selected = []
+
+        ref_image_series = DicomSeriesRegistrationInfo.get_referenced_series_info(registration_dataset)
+        ref_series_uids = [ref_info.series_instance_uid for ref_info in ref_image_series]
+        ref_study_uids = [ref_info.study_instance_uid for ref_info in ref_image_series]
+
+        if isinstance(image_datasets[0], str):
+            for path in image_datasets:
+                dataset = load_dataset_tag(path, (Tag(0x0020, 0x000E), Tag(0x0020, 0x000D)))
+                criteria = (
+                    str(dataset.get("SeriesInstanceUID", "")) in ref_series_uids,
+                    str(dataset.get("StudyInstanceUID", "")) in ref_study_uids,
+                )
+                if all(criteria):
+                    selected.append(load_dataset(path))
+
+        else:
+            for image_dataset in image_datasets:
+                criteria = (
+                    str(image_dataset.get("SeriesInstanceUID", "")) in ref_series_uids,
+                    str(image_dataset.get("StudyInstanceUID", "")) in ref_study_uids,
+                )
+                if all(criteria):
+                    selected.append(image_dataset)
+
+        return tuple(selected)
+
+    @staticmethod
+    def _validate_rtss_dataset(rtss_dataset: Dataset) -> None:
+        """Validate if the RTSS dataset is containing the minimal data for conversion.
+
+        Args:
+            rtss_dataset (Dataset): The RTSS dataset to validate.
+
+        Returns:
+            None
+        """
+        criteria = (
+            rtss_dataset.get("SOPClassUID", "") == "1.2.840.10008.5.1.4.1.1.481.3",
+            hasattr(rtss_dataset, "ROIContourSequence"),
+            hasattr(rtss_dataset, "StructureSetROISequence"),
+            hasattr(rtss_dataset, "RTROIObservationsSequence"),
+        )
+
+        if not all(criteria):
+            raise Exception(f'The checked RTSS from subject {rtss_dataset.get("PatientID")} is invalid!')
+
+    # pylint: disable=use-a-generator
+    @staticmethod
+    def _validate_registration_dataset(reg_dataset: Optional[Dataset], rtss_dataset: Dataset) -> Optional[Dataset]:
+        """Validate the registration dataset if it contains the minimally required data for conversion. If the provided
+        information is insufficient this function will return None.
+
+        Args:
+            reg_dataset (Optional[Dataset]): The registration dataset to validate.
+            rtss_dataset (Dataset): The RTSS dataset containing the references.
+
+        Returns:
+            Optional[Dataset]: The valid registration dataset or None.
+        """
+
+        if not reg_dataset:
+            return None
+
+        # search for references in the registration dataset
+        reg_ref_instance_uids = []
+        for ref_study_item in reg_dataset.get("StudiesContainingOtherReferencedInstancesSequence", []):
+            for ref_series_item in ref_study_item.get("ReferencedSeriesSequence", []):
+                ref_series_instance_uid = ref_series_item.get("SeriesInstanceUID", None)
+                if ref_series_instance_uid:
+                    reg_ref_instance_uids.append(ref_series_instance_uid)
+
+        for ref_series_item in reg_dataset.get("ReferencedSeriesSequence", []):
+            ref_series_uid = ref_series_item.get("SeriesInstanceUID", None)
+            if ref_series_uid:
+                reg_ref_instance_uids.append(ref_series_uid)
+
+        # search for references in the rtss dataset
+        rtss_ref_instance_uids = []
+        for ref_frame_of_ref in rtss_dataset.get("ReferencedFrameOfReferenceSequence", []):
+            for rt_ref_study in ref_frame_of_ref.get("RTReferencedStudySequence", []):
+                for rt_ref_series in rt_ref_study.get("RTReferencedSeriesSequence", []):
+                    ref_series_uid = rt_ref_series.get("SeriesInstanceUID", None)
+                    if ref_series_uid:
+                        rtss_ref_instance_uids.append(ref_series_uid)
+
+        # check the criteria
+        criteria = (
+            reg_dataset.get("SOPClassUID", "") == "1.2.840.10008.5.1.4.1.1.66.1",
+            hasattr(reg_dataset, "RegistrationSequence"),
+            hasattr(reg_dataset, "ReferencedSeriesSequence"),
+            all([rt_reference in reg_ref_instance_uids for rt_reference in rtss_ref_instance_uids]),
+            len(reg_ref_instance_uids) != 0,
+        )
+
+        if not all(criteria):
+            print(f'The checked registration from subject {rtss_dataset.get("PatientID", "n/a")} is invalid!')
+            return None
+
+        return reg_dataset
+
+    @staticmethod
+    def _validate_rtss_image_references(rtss_dataset: Dataset, image_datasets: Tuple[Dataset]) -> None:
+        """Validate if the ReferencedSOPInstanceUIDs of the RTSS dataset are contained in the image datasets.
+
+        Args:
+            rtss_dataset (Dataset): The RTSS dataset to validate.
+            image_datasets (Tuple[Dataset]): The image datasets to be used for comparison.
+
+        Returns:
+            None
+        """
+        # get the ReferencedSOPInstanceUIDs from the RTSS dataset
+        ref_sop_instance_uids = []
+        for ref_frame_of_ref in rtss_dataset.get("ReferencedFrameOfReferenceSequence", []):
+            for rt_ref_study in ref_frame_of_ref.get("RTReferencedStudySequence", []):
+                for rt_ref_series in rt_ref_study.get("RTReferencedSeriesSequence", []):
+                    for contour_image_entry in rt_ref_series.get("ContourImageSequence", []):
+                        ref_sop_instance_uids.append(contour_image_entry.get("ReferencedSOPInstanceUID", ""))
+
+        # get MediaStorageSOPInstanceUIDs from the image datasets
+        image_sop_instance_uids = [entry.file_meta.get("MediaStorageSOPInstanceUID") for entry in image_datasets]
+
+        # check if all ReferencedSOPInstanceUIDs are contained in the image datasets
+        missing_sop_instance_uids = tuple(set(ref_sop_instance_uids) - set(image_sop_instance_uids))
+        if missing_sop_instance_uids:
+            raise ValueError(
+                "The following ReferencedSOPInstanceUIDs are missing in the image datasets: "
+                f"{missing_sop_instance_uids}"
+            )
+
+    @staticmethod
+    def _get_contour_sequence_by_roi_number(rtss_dataset: Dataset, roi_number: int) -> Optional[Sequence]:
+        """Get the ContourSequence by the ROINumber.
+
+        Args:
+            rtss_dataset (Dataset): The RT Structure Set dataset to retrieve the ContourSequence from.
+            roi_number (int): The ROINumber for which the ContourSequence should be returned.
+
+        Returns:
+            Optional[Sequence]: The ContourSequence with the corresponding ROINumber if available, otherwise
+             :class:`None`.
+        """
+        if rtss_dataset.get("ROIContourSequence", None) is None:
+            return None
+
+        for roi_contour_entry in rtss_dataset.get("ROIContourSequence", []):
+            if str(roi_contour_entry.get("ReferencedROINumber", None)) == str(roi_number):
+                if roi_contour_entry.get("ContourSequence", None) is None:
+                    return None
+                return roi_contour_entry.get("ContourSequence")
+
+        raise Exception(f"Referenced ROI number '{roi_number}' not found")
+
+    @staticmethod
+    def _create_empty_series_mask(image_datasets: Tuple[Dataset, ...]) -> np.ndarray:
+        """Create an empty numpy array with the shape according to the reference image.
+
+        Returns:
+            np.ndarray: The empty numpy array with appropriate shape.
+        """
+        rows = int(image_datasets[0].get("Rows"))
+        columns = int(image_datasets[0].get("Columns"))
+        num_slices = len(image_datasets)
+
+        return np.zeros((columns, rows, num_slices)).astype(bool)
+
+    @staticmethod
+    def _create_empty_slice_mask(image_dataset: Dataset) -> np.ndarray:
+        """Create an empty numpy array representing one slice of the output mask.
+
+        Args:
+            image_dataset (Dataset): The dataset providing the spatial information for the empty mask.
+
+        Returns:
+            np.ndarray: The empty slice numpy array.
+        """
+        columns = int(image_dataset.get("Columns"))
+        rows = int(image_dataset.get("Rows"))
+        return np.zeros((columns, rows)).astype(np.uint8)
+
+    @staticmethod
+    def _apply_transformation_to_3d_points(points: np.ndarray, transformation_matrix: np.ndarray) -> np.ndarray:
+        """Apply the provided transformation to multiple points in the 3D-space.
+
+        Args:
+            points (np.ndarray): The points to transform.
+            transformation_matrix (np.ndarray): The transformation matrix.
+
+        Notes:
+            1. Augment each point with a '1' as the fourth coordinate for homogeneous coordinates.
+            2. Multiply by a 4x4 transformation matrix
+            3. Throw away the adaptation for homogeneous coordinates
+
+        Returns:
+            np.ndarray: The transformed points.
+        """
+        vec = np.concatenate((points, np.ones((points.shape[0], 1))), axis=1)
+        return vec.dot(transformation_matrix.T)[:, :3]
+
+    @staticmethod
+    def _get_patient_to_pixel_transformation_matrix(image_datasets: Tuple[Dataset, ...]) -> np.ndarray:
+        """Get the patient to pixel transformation matrix from the first image dataset.
+
+        Args:
+            image_datasets (Tuple[Dataset, ...]): The datasets to retrieve the transformation matrix.
+
+        Returns:
+            np.ndarray: The transformation matrix.
+        """
+        offset = np.array(image_datasets[0].get("ImagePositionPatient"))
+        row_spacing, column_spacing = image_datasets[0].get("PixelSpacing")
+        slice_spacing = get_spacing_between_slices(image_datasets)
+        row_direction, column_direction, slice_direction = get_slice_direction(image_datasets[0])
+
+        linear = np.identity(3, dtype=float)
+        linear[0, :3] = row_direction / row_spacing
+        linear[1, :3] = column_direction / column_spacing
+        linear[2, :3] = slice_direction / slice_spacing
+
+        mat = np.identity(4, dtype=float)
+        mat[:3, :3] = linear
+        mat[:3, 3] = offset.dot(-linear.T)
+
+        return mat
+
+    @staticmethod
+    def _get_slice_contour_data(image_dataset: Dataset, contour_sequence: Sequence) -> Tuple[Any, ...]:
+        """Get the contour data from the corresponding ContourSequence.
+
+        Args:
+            image_dataset (Dataset): The referenced image dataset.
+            contour_sequence (Sequence): The ContourSequence.
+
+        Returns:
+            Tuple[Any, ...]: The retrieved ContourData.
+        """
+        slice_contour_data = []
+
+        for contour in contour_sequence:
+            for contour_image in contour.get("ContourImageSequence", []):
+                if contour_image.get("ReferencedSOPInstanceUID", None) == image_dataset.get("SOPInstanceUID", "1"):
+                    slice_contour_data.append(contour.get("ContourData", []))
+
+        return tuple(slice_contour_data)
+
+    @staticmethod
+    def _get_slice_mask_from_slice_contour_data(
+        image_dataset: Dataset, contour_data: Tuple[Any, ...], transformation_matrix: np.ndarray
+    ) -> np.ndarray:
+        """Get the slice mask from the ContourData.
+
+        Args:
+            image_dataset (Dataset): The referenced image dataset.
+            contour_data (Tuple[Any, ...]): The contour data.
+            transformation_matrix (np.ndarray): The transformation matrix.
+
+        Returns:
+            np.ndarray: The discrete slice mask.
+        """
+        raw_polygons = []
+        for contour_coords in contour_data:
+            reshaped_contour_data = np.reshape(contour_coords, [len(contour_coords) // 3, 3])
+            translated_contour_data = RTSSToSegmentConverter._apply_transformation_to_3d_points(
+                reshaped_contour_data, transformation_matrix
+            )
+            polygon = [np.around([translated_contour_data[:, :2]]).astype(int)]
+            polygon = np.array(polygon).squeeze()
+            if polygon.shape[0] > 2:
+                raw_polygons.append(polygon.astype(int))
+
+        slice_mask = RTSSToSegmentConverter._create_empty_slice_mask(image_dataset)
+        cv.fillPoly(img=slice_mask, pts=raw_polygons, color=1)
+        return slice_mask
+
+    @staticmethod
+    def _create_mask_from_contour_sequence(
+        image_datasets: Tuple[Dataset, ...], contour_sequence: Sequence
+    ) -> np.ndarray:
+        """Create the whole 3D mask from the ContourSequence.
+
+        Args:
+            image_datasets (Tuple[Dataset, ...]): The image datasets to be used for mask creation.
+            contour_sequence (Sequence): The ContourSequence to be discretized.
+
+        Returns:
+            np.ndarray: The discrete segmentation mask.
+        """
+        mask = RTSSToSegmentConverter._create_empty_series_mask(image_datasets)
+        transformation_matrix = RTSSToSegmentConverter._get_patient_to_pixel_transformation_matrix(image_datasets)
+
+        for i, image_dataset in enumerate(image_datasets):
+            slice_contour_data = RTSSToSegmentConverter._get_slice_contour_data(image_dataset, contour_sequence)
+            if slice_contour_data:
+                mask[:, :, i] = RTSSToSegmentConverter._get_slice_mask_from_slice_contour_data(
+                    image_dataset, slice_contour_data, transformation_matrix
+                )
+
+        return mask
+
+    @staticmethod
+    def _create_image_from_mask(image_datasets: Tuple[Dataset, ...], mask: np.ndarray) -> sitk.Image:
+        """Create an image from the numpy segmentation mask with appropriate orientation.
+
+        Args:
+            image_datasets (Tuple[Dataset, ...]): The image datasets used to create the image.
+            mask (np.ndarray): The mask to be converted into a sitk.Image.
+
+        Returns:
+            sitk.Image: The image generated.
+        """
+        mask = np.swapaxes(mask, 0, 2)
+        mask = np.swapaxes(mask, 1, 2)
+
+        image = sitk.GetImageFromArray(mask.astype(np.uint8))
+        image = sitk.Cast(image, sitk.sitkUInt8)
+
+        image.SetOrigin(image_datasets[0].get("ImagePositionPatient"))
+
+        row_spacing, column_spacing = image_datasets[0].get("PixelSpacing")
+        slice_spacing = get_spacing_between_slices(image_datasets)
+        image.SetSpacing((float(row_spacing), float(column_spacing), float(slice_spacing)))
+
+        slice_direction = np.stack(get_slice_direction(image_datasets[0]), axis=0).astype(float).T.flatten()
+        slice_direction = slice_direction.tolist()
+        image.SetDirection(slice_direction)
+
+        return image
+
+    @staticmethod
+    def _get_transform_from_registration_info(registration_infos: Tuple[RegistrationInfo, ...]) -> sitk.Transform:
+        """Get the transformation from the registration infos.
+
+        Args:
+            registration_infos (Tuple[RegistrationInfo]): Registration info entries which hold transformations and
+             references.
+
+        Returns:
+            sitk.Transform: The transformation which is not an identity transformation.
+        """
+        assert len(registration_infos) <= 2, (
+            "The number of registration infos must be at max two but is " f"{len(registration_infos)}!"
+        )
+
+        transforms = []
+        for registration_info in registration_infos:
+            if not registration_info.is_reference_image:
+                transforms = registration_info.registration_info.transforms
+
+        if len(transforms) != 1:
+            raise NotImplementedError("The use of multiple sequential transformations is currently not supported!")
+
+        return transforms[0]
+
+    @staticmethod
+    def _transform_image_datasets(
+        image_datasets: Tuple[Dataset, ...], transform: sitk.Transform
+    ) -> Tuple[Dataset, ...]:
+        """Apply the transformation to multiple image datasets.
+
+        Args:
+            image_datasets (Tuple[Dataset, ...]): The image datasets to be transformed.
+            transform (sitk.Transform): The transformation to be applied.
+
+        Returns:
+            Tuple[Dataset, ...]: The transformed image datasets.
+        """
+
+        transformed_image_datasets = []
+
+        for image_dataset in image_datasets:
+            # transform the patient position
+            image_position_patient = image_dataset.get("ImagePositionPatient")
+            position_transformed = list(transform.GetInverse().TransformPoint(image_position_patient))
+            image_dataset["ImagePositionPatient"].value = position_transformed
+
+            # transform the image orientation
+            image_orientation_patient = image_dataset.get("ImageOrientationPatient")
+            vector_0 = np.array(image_orientation_patient[:3])
+            vector_1 = np.array(image_orientation_patient[3:6])
+
+            vector_0_transformed = transform.GetInverse().TransformVector(vector_0, (0, 0, 0))
+            vector_1_transformed = transform.GetInverse().TransformVector(vector_1, (0, 0, 0))
+
+            new_direction = list(vector_0_transformed + vector_1_transformed)
+            image_dataset["ImageOrientationPatient"].value = new_direction
+
+            transformed_image_datasets.append(image_dataset)
+
+        return image_datasets
+
+    @staticmethod
+    def _transform_rtss_dataset(rtss_dataset: Dataset, transform: sitk.Transform) -> Dataset:
+        """Apply the transformation to the RTSS.
+
+        Args:
+            rtss_dataset (Dataset): The dataset to be transformed.
+            transform (sitk.Transform): The transformation to apply.
+
+        Returns:
+            Dataset: The transformed dataset.
+        """
+        dataset = deepcopy(rtss_dataset)
+
+        for roi_contour in dataset.get("ROIContourSequence", []):
+            for contour_sequence_item in roi_contour.get("ContourSequence", []):
+                contour_data = contour_sequence_item.get("ContourData")
+
+                if len(contour_data) % 3 != 0:
+                    raise ValueError("The number of contour points must be a multiple of three!")
+
+                transformed_points = []
+
+                for chunk in chunkify(contour_data, 3):
+                    transformed_point = list(transform.GetInverse().TransformPoint(np.array(chunk)))
+                    transformed_points.extend(transformed_point)
+
+                contour_sequence_item["ContourData"].value = transformed_points
+
+        return dataset
+
+    @staticmethod
+    def _fill_holes_in_mask(
+        mask: np.ndarray,
+        search_radius: int = 5,
+    ) -> np.ndarray:
+        """Fill holes in a binary mask using morphological closing.
+
+        Args:
+            mask (np.ndarray): The mask to fill holes in.
+            search_radius (int): The radius to search for holes.
+
+        Returns:
+            np.ndarray: The mask with filled holes.
+        """
+
+        # get the bounding box of the mask
+        bb = []
+        for ax in itertools.combinations(reversed(range(mask.ndim)), mask.ndim - 1):
+            nonzero = np.any(mask, axis=ax)
+            bb.extend(np.where(nonzero)[0][[0, -1]])
+
+        # extend the bounding box by the search radius
+        bb = np.array(bb)
+        bb[::2] = np.maximum(bb[::2] - search_radius, 0)
+        bb[1::2] = np.minimum(bb[1::2] + search_radius, mask.shape)
+
+        if mask.ndim == 3:
+            inner_mask = mask[bb[0] : bb[1], bb[2] : bb[3], bb[4] : bb[5]]
+        else:
+            inner_mask = mask[bb[0] : bb[1], bb[2] : bb[3]]
+
+        # fill the holes in the inner mask
+        structure = np.ones(tuple([search_radius for _ in range(mask.ndim)]), dtype=int)
+        inner_mask = scipy.ndimage.binary_fill_holes(inner_mask, structure).astype(np.bool)
+
+        # remove additional unconnected single voxel segmentations
+        inner_mask2 = np.copy(inner_mask).astype(np.uint8)
+        id_regions, num_ids = scipy.ndimage.label(inner_mask, structure=np.ones(tuple([3 for _ in range(mask.ndim)])))
+        id_sizes = np.array(scipy.ndimage.sum(inner_mask, id_regions, range(num_ids + 1)))
+        area_mask = id_sizes == 1
+        inner_mask2[area_mask[id_regions]] = 0
+        inner_mask = inner_mask2.astype(np.bool)
+
+        # insert the inner mask into the original mask
+        new_mask = np.zeros_like(mask, dtype=np.uint8)
+        if mask.ndim == 3:
+            new_mask[bb[0] : bb[1], bb[2] : bb[3], bb[4] : bb[5]] = inner_mask
+        else:
+            new_mask[bb[0] : bb[1], bb[2] : bb[3]] = inner_mask
+
+        return new_mask
+
+    def convert(self) -> Dict[str, sitk.Image]:
+        """Convert a DICOM-RTSS :class:`~pydicom.dataset.Dataset` instance into a dict of binary
+        :class:`SimpleITK.Image` instances including their associated ROINames as a key in the dict.
+
+        Returns:
+            Dict[str, sitk.Image]: The ROINames and the corresponding binary segmented :class:`SimpleITK.Image`
+            instances.
+        """
+        converted_images = {}
+
+        # apply the registration if available
+        if self.reg_dataset:
+            reg_infos = DicomSeriesRegistrationInfo.get_registration_infos(self.reg_dataset, self.reg_image_datasets)
+            transform = self._get_transform_from_registration_info(reg_infos)
+            image_datasets = self._transform_image_datasets(self.rtss_image_datasets, transform)
+            rtss_dataset = self._transform_rtss_dataset(self.rtss_dataset, transform)
+
+        else:
+            image_datasets = self.rtss_image_datasets
+            rtss_dataset = self.rtss_dataset
+
+        # convert the contours to images
+        for ss_roi in rtss_dataset.get("StructureSetROISequence", []):
+            roi_number = int(ss_roi.get("ROINumber"))
+            roi_name = str(ss_roi.get("ROIName", ""))
+
+            contour_sequence = self._get_contour_sequence_by_roi_number(rtss_dataset, roi_number)
+
+            if contour_sequence is None:
+                continue
+
+            # create the mask from the contours
+            mask = self._create_mask_from_contour_sequence(image_datasets, contour_sequence)
+
+            # fill holes in the mask
+            if self.fill_hole_distance > 0:
+                mask = self._fill_holes_in_mask(mask, search_radius=5)
+
+            # create the image from the mask
+            image = self._create_image_from_mask(image_datasets, mask)
+            converted_images.update({roi_name: image})
+
+        return converted_images
+
+
+@dataclass
+class RTSSMetaData:
+    """A class to define metadata of a new DICOM-RTSS dataset.
+
+    Note:
+        Some attributes can take ``None`` as a value. This means that the attribute will be copied from the reference
+        DICOM image dataset.
+
+    Note:
+        For some attributes, the value must follow the value representation of the DICOM standard. For example, the
+        ``PatientSex`` attribute must be either ``'M'``, ``'F'``, or ``'O'``. For more information, we refer to the
+        `DICOM standard part 5 chapter 6.2 <https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html>`_.
+
+    Args:
+        patient_name (Optional[str]): The patient name.
+        patient_id (Optional[str]): The patient ID.
+        patient_birth_date (Optional[str]): The patient birth date (format: YYYYMMDD).
+        patient_sex (Optional[str]): The patient sex (valid values: 'F' (female), 'M' (male), 'O' (other)).
+        patient_weight (Optional[str]): The patient weight (unit: kilograms with decimals).
+        patient_size (Optional[str]): The patient size (unit: meters with decimals).
+        study_description (Optional[str]): The study description.
+        series_description (Optional[str]): The series description.
+        series_number (Optional[str]): The series number (default: '99').
+        structure_set_label (str): The structure set label (default: 'Autogenerated').
+        operators_name (str): The operator's name (default: 'NA').
+        manufacturer (str): The manufacturer (default: 'University of Bern, Switzerland').
+        manufacturer_model_name (str): The manufacturer model name (default: 'PyRaDiSe Package').
+        institution_name (str): The institution name (default: 'Unknown Institution').
+        referring_physician_name (str): The referring physician name (default: 'NA').
+        approval_status (str): The approval status (valid values: 'APPROVED', 'UNAPPROVED', 'REJECTED',
+         default: 'UNAPPROVED').
+        roi_gen_algorithm (str): The ROI generation algorithm (valid values: 'AUTOMATIC', 'SEMIAUTOMATIC', 'MANUAL',
+         default: 'AUTOMATIC').
+
+    """
+
+    patient_name: Optional[str] = None
+    patient_id: Optional[str] = None
+    patient_birth_date: Optional[str] = None
+    patient_sex: Optional[str] = None
+    patient_age: Optional[str] = None
+    patient_weight: Optional[str] = None
+    patient_size: Optional[str] = None
+    study_description: Optional[str] = None
+    series_description: Optional[str] = None
+    series_number: str = "99"
+    structure_set_label: str = "Autogenerated"
+    operators_name: str = "NA"
+    manufacturer: str = "University of Bern, Switzerland"
+    manufacturer_model_name: str = "PyRaDiSe Package"
+    institution_name: str = "Unknown Institution"
+    referring_physician_name: str = "NA"
+    approval_status: str = "UNAPPROVED"
+    roi_gen_algorithm: str = "AUTOMATIC"
+
+    def __post_init__(self) -> None:
+        # validate entries
+        criteria = (
+            isinstance(self.patient_name, str) or self.patient_name is None,
+            isinstance(self.patient_id, str) or self.patient_id is None,
+            isinstance(self.patient_birth_date, str) or self.patient_birth_date is None,
+            isinstance(self.patient_sex, str) or self.patient_sex is None,
+            isinstance(self.patient_age, str) or self.patient_age is None,
+            isinstance(self.patient_weight, str) or self.patient_weight is None,
+            isinstance(self.patient_size, str) or self.patient_size is None,
+            isinstance(self.study_description, str) or self.study_description is None,
+            isinstance(self.series_description, str) or self.series_description is None,
+            isinstance(self.series_number, str),
+            isinstance(self.structure_set_label, str),
+            isinstance(self.operators_name, str),
+            isinstance(self.manufacturer, str),
+            isinstance(self.manufacturer_model_name, str),
+            isinstance(self.institution_name, str),
+            isinstance(self.referring_physician_name, str),
+            isinstance(self.approval_status, str) and self.approval_status in ("APPROVED", "UNAPPROVED", "REJECTED"),
+            isinstance(self.roi_gen_algorithm, str)
+            and self.roi_gen_algorithm
+            in (
+                "AUTOMATIC",
+                "SEMIAUTOMATIC",
+                "MANUAL",
+            ),
+        )
+
+        if not all(criteria):
+            raise ValueError("The RTSS meta data is not valid! Please check the input values.")
+
+
+class RTSSConverterConfiguration(ABC):
+    """An abstract base class to parameterize a segment to DICOM-RTSS converter."""
+
+    def __init__(self) -> None:
+        super().__init__()
+        self.general_params: Dict[str, Any] = {}
+        self.image_specific_params: Dict[str, Dict[str, Any]] = {}
+
+    @abstractmethod
+    def set_general_params(self, **kwargs: Any) -> None:
+        """Set the general parameters of the converter.
+
+        Args:
+            **kwargs: The parameters of the converter.
+
+        Returns:
+            None
+        """
+        raise NotImplementedError()
+
+    def get_general_params(self, name: Optional[str] = None) -> Optional[Union[Dict[str, Any], Any]]:
+        """Get all or a specific general parameter for the converter.
+
+        Args:
+            name (Optional[str]): The name of the parameter to get. If ``None``, all parameters are returned
+             (default: None).
+
+        Returns:
+            Optional[Union[Dict[str, Any], Any]]: All or the selected parameter.
+        """
+        if name is None:
+            if self.general_params:
+                return self.general_params
+            return None
+
+        return self.general_params.get(name, None)
+
+    @abstractmethod
+    def set_image_params(self, **kwargs: Any) -> None:
+        """Set the parameters of the converter for a specific image using an identifier.
+        instance.
+
+        Args:
+            **kwargs: The parameters of the converter.
+
+        Returns:
+            None
+        """
+        raise NotImplementedError()
+
+    def get_image_params(
+        self, image_identifier: str, name: Optional[str] = None
+    ) -> Optional[Union[Dict[str, Any], Any]]:
+        """Get all parameters for a specific image using its identifier.
+
+        Args:
+            image_identifier (str): The identifier of the image
+            name (Optional[str]): The name of the parameter to get. If ``None``, all parameters are returned (default:
+             None).
+
+        Returns:
+            Optional[Union[Dict[str, Any], Any]]: All or the selected parameter belonging to the specific image
+
+        """
+        if image_identifier not in self.image_specific_params:
+            return None
+
+        specific = self.image_specific_params[image_identifier]
+        if name is None:
+            if specific:
+                return specific
+            return None
+        return specific.get(name, None)
+
+
+class RTSSConverter2DConfiguration(RTSSConverterConfiguration):
+    """A configuration class to parameterize a :class:`SegmentToRTSSConverter2D` instance.
+
+    The configuration can be used to set the general and image specific conversion parameters of the converter.
+    The general parameters are applied to all images except if image specific parameters are provided.
+    used for the image.
+
+    The parameters define the following:
+
+    * ``smoothing``: Indicates if Gaussian smoothing is applied.
+
+    * ``smoothing_sigma``: The variance of the discrete Gaussian smoothing kernel.
+
+    * ``smoothing_kernel_size``: The size of the discrete Gaussian smoothing kernel.
+
+    Args:
+        smoothing (bool): Whether to smooth the contours or not (default: True).
+        smoothing_sigma (float): The variance of the Gaussian smoothing (default: 1.0).
+        smoothing_kernel_size (int): The size of the Gaussian smoothing kernel (default: 8).
+    """
+
+    def __init__(
+        self,
+        smoothing: bool = True,
+        smoothing_sigma: float = 1.0,
+        smoothing_kernel_size: int = 8,
+    ) -> None:
+        super().__init__()
+
+        self._validate_entries(smoothing, smoothing_sigma, smoothing_kernel_size)
+
+        self.set_general_params(smoothing, smoothing_sigma, smoothing_kernel_size)
+
+    @staticmethod
+    def _validate_entries(
+        smoothing: bool,
+        smoothing_sigma: float,
+        smoothing_kernel_size: int,
+    ) -> None:
+        """Validate the entries of the configuration.
+
+        Args:
+            smoothing (bool): Whether to smooth the contours or not.
+            smoothing_sigma (float): The variance of the Gaussian smoothing.
+            smoothing_kernel_size (int): The size of the Gaussian smoothing kernel.
+
+        Raises:
+            ValueError: If the entries are not valid.
+
+        Returns:
+            None
+        """
+        criteria = (
+            isinstance(smoothing, bool),
+            isinstance(smoothing_sigma, float) and smoothing_sigma > 0,
+            isinstance(smoothing_kernel_size, int) and smoothing_kernel_size > 0,
+        )
+
+        if not all(criteria):
+            raise ValueError("The RTSS converter configuration is not valid! Please check the input values.")
+
+    def set_general_params(
+        self,
+        smoothing: bool,
+        smoothing_sigma: float,
+        smoothing_kernel_size: int,
+    ) -> None:
+        """Set the general parameters for all images except those that have specific parameters.
+
+        Args:
+            smoothing (bool): Whether to apply Gaussian smoothing.
+            smoothing_sigma (float): The sigma of the Gaussian filter.
+            smoothing_kernel_size (int): The kernel size of the Gaussian filter.
+
+        Returns:
+            None
+        """
+        self._validate_entries(smoothing, smoothing_sigma, smoothing_kernel_size)
+
+        self.general_params["smoothing"] = smoothing
+        self.general_params["smoothing_sigma"] = smoothing_sigma
+        self.general_params["smoothing_kernel_size"] = smoothing_kernel_size
+
+    def set_image_params(
+        self, image_identifier: str, smoothing: bool, smoothing_sigma: float, smoothing_kernel_size: int
+    ) -> None:
+        """Set the parameters of the converter for a specific image using the :class:`~pyradise.data.organ.Organ`
+        instance.
+
+        Args:
+            image_identifier (str): The image to set the parameter(s) for.
+            smoothing (bool): Whether to apply Gaussian smoothing to the image.
+            smoothing_sigma (float): The sigma value for the Gaussian smoothing kernel.
+            smoothing_kernel_size (int): The kernel size for the Gaussian smoothing kernel.
+
+        Returns:
+            None
+        """
+        self._validate_entries(smoothing, smoothing_sigma, smoothing_kernel_size)
+
+        self.image_specific_params[image_identifier] = {
+            "smoothing": smoothing,
+            "smoothing_sigma": smoothing_sigma,
+            "smoothing_kernel_size": smoothing_kernel_size,
+        }
+
+
+class RTSSConverter3DConfiguration(RTSSConverterConfiguration):
+    """A configuration class to parameterize a :class:`SegmentToRTSSConverter3D` instance.
+
+    The configuration can be used to set the general and image specific conversion parameters of the converter.
+    The general parameters are applied to all images except if image specific parameters are provided.
+    used for the image.
+
+    The parameters define the following:
+
+    * ``image_smoothing``: Whether to apply Gaussian smoothing to the image before 3D model construction.
+
+    * ``image_smoothing_sigma``: The standard deviation value for the Gaussian smoothing kernel.
+
+    * ``image_smoothing_radius``: The radius of the Gaussian smoothing kernel.
+
+    * ``image_smoothing_threshold``: The threshold value for the Gaussian smoothing. All segmentation masks that
+      have less foreground voxels than this threshold are not smoothed to avoid deletion.
+
+    * ``decimate_reduction``: The reduction factor for the decimation of the 3D model. This factor defines how much
+      vertices are removed from the model during the decimation process (0 = none, 1: all).
+
+    * ``decimate_threshold``: The threshold value for the decimation of the 3D model. All models that arise from a
+      segmentation mask with less than the threshold number of foreground voxels are not decimated to avoid
+      deletion.
+
+    * ``model_smoothing_iterations``: The number of iterations for the smoothing of the 3D model (Sinc-Filter).
+      Typically, 10 to 20 iterations are sufficient for smoothing.
+
+    * ``model_smoothing_pass_band``: The pass band for the smoothing of the 3D model (Sinc-Filter). The closer this
+      value is to zero (e.g., 0.001) the stronger the smoothing is. The higher the value (e.g., 0.4) the less the
+      smoothing is.
+
+    * ``min_segment_lines``: The minimum number of lines that a segment must have to be considered for the RTSS. All
+      segments smaller than this value are discarded.
+
+
+    Args:
+        image_smoothing (bool): Whether to smooth the image before 3D model construction or not (default: False).
+        image_smoothing_sigma (float): The standard deviation of the Gaussian smoothing before 3D model construction
+         (default: 2.).
+        image_smoothing_radius (float): The radius of the Gaussian smoothing before 3D model construction (default: 1.).
+        image_smoothing_threshold (float): The minimum number of foreground voxels that must be contained in the
+         segmentation mask to trigger Gaussian smoothing (default: 0).
+        decimate_reduction (float): The reduction factor for the 3D decimation. The decimation factor is valid
+         between 0 and 1 and the lower it is the more smoothing is applied (default: 0.5).
+        decimate_threshold (float): The minimum number of foreground voxels that must be contained in the
+         segmentation mask to trigger 3D decimation (default: 0).
+        model_smoothing_iterations (int): The number of 3D smoothing steps (typically 10 - 20 steps) (default: 10).
+        model_smoothing_pass_band (bool): The strength of the 3D smoothing (0.001 - 0.1 = strong smoothing,
+         0.1 - 0.5 = intermediate smoothing, 0.5 - 1 = almost no smoothing) (default: 0.25).
+        min_segment_lines (int): The minimum number of lines that a segment must have to be considered for the RTSS
+         (default: 0).
+    """
+
+    def __init__(
+        self,
+        image_smoothing: bool = False,
+        image_smoothing_sigma: float = 2.0,
+        image_smoothing_radius: float = 1.0,
+        image_smoothing_threshold: float = 0.0,
+        decimate_reduction: float = 0.5,
+        decimate_threshold: float = 0.0,
+        model_smoothing_iterations: int = 10,
+        model_smoothing_pass_band: float = 0.25,
+        min_segment_lines: int = 0,
+    ) -> None:
+        super().__init__()
+
+        self.set_general_params(
+            image_smoothing,
+            image_smoothing_sigma,
+            image_smoothing_radius,
+            image_smoothing_threshold,
+            decimate_reduction,
+            decimate_threshold,
+            model_smoothing_iterations,
+            model_smoothing_pass_band,
+            min_segment_lines,
+        )
+
+    @staticmethod
+    def _validate_entries(
+        image_smoothing: bool,
+        image_smoothing_sigma: float,
+        image_smoothing_radius: float,
+        image_smoothing_threshold: float,
+        decimate_reduction: float,
+        decimate_threshold: float,
+        model_smoothing_iterations: int,
+        model_smoothing_pass_band: float,
+        min_segment_lines: int,
+    ) -> None:
+        """Validate the entries of the configuration.
+
+        Args:
+            image_smoothing (bool): Whether to smooth the image before 3D model construction or not.
+            image_smoothing_sigma (float): The standard deviation of the Gaussian smoothing before 3D model
+             construction.
+            image_smoothing_radius (float): The radius of the Gaussian smoothing before 3D model construction.
+            image_smoothing_threshold (float): The minimum number of foreground voxels that must be contained in the
+             segmentation mask to trigger Gaussian smoothing.
+            decimate_reduction (float): The reduction factor for the 3D decimation. The decimation factor is valid
+             between 0 and 1 and the lower it is the more smoothing is applied.
+            decimate_threshold (float): The minimum number of foreground voxels that must be contained in the
+             segmentation mask to trigger 3D decimation.
+            model_smoothing_iterations (int): The number of 3D smoothing steps (typically 15 - 20 steps).
+            model_smoothing_pass_band (float): The strength of the 3D smoothing (0.001 - 0.1 = strong smoothing,
+             0.5 - 1 = almost no smoothing).
+            min_segment_lines (int): The minimum number of lines that a segment must have to be considered for the RTSS.
+
+        Raises:
+            ValueError: If the entries are not valid.
+
+        Returns:
+            None
+        """
+        criteria = (
+            isinstance(image_smoothing, bool),
+            isinstance(image_smoothing_sigma, float) and image_smoothing_sigma > 0,
+            isinstance(image_smoothing_radius, float) and image_smoothing_radius > 0,
+            isinstance(image_smoothing_threshold, (float, int)) and image_smoothing_threshold >= 0,
+            isinstance(decimate_reduction, float) and 0 < decimate_reduction < 0.99,
+            isinstance(decimate_threshold, (float, int)) and decimate_threshold >= 0,
+            isinstance(model_smoothing_iterations, int) and model_smoothing_iterations >= 0,
+            isinstance(model_smoothing_pass_band, float),
+            isinstance(min_segment_lines, int),
+        )
+
+        if not all(criteria):
+            raise ValueError("The RTSS converter configuration is not valid! Please check the input values.")
+
+    def set_general_params(
+        self,
+        image_smoothing: bool,
+        image_smoothing_sigma: float,
+        image_smoothing_radius: float,
+        image_smoothing_threshold: float,
+        decimate_reduction: float,
+        decimate_threshold: float,
+        model_smoothing_iterations: int,
+        model_smoothing_pass_band: float,
+        min_segment_lines: int,
+    ) -> None:
+        """Set the general parameters for all images except those that have specific parameters.
+
+        Args:
+            image_smoothing (bool): Whether to smooth the image before 3D model construction or not.
+            image_smoothing_sigma (float): The standard deviation of the Gaussian smoothing before 3D model
+             construction.
+            image_smoothing_radius (float): The radius of the Gaussian smoothing before 3D model construction.
+            image_smoothing_threshold (float): The minimum number of foreground voxels that must be contained in the
+             segmentation mask to trigger Gaussian smoothing.
+            decimate_reduction (float): The reduction factor for the 3D decimation. The decimation factor is valid
+             between 0 and 1 and the lower it is the more smoothing is applied.
+            decimate_threshold (float): The minimum number of foreground voxels that must be contained in the
+             segmentation mask to trigger 3D decimation.
+            model_smoothing_iterations (int): The number of 3D smoothing steps (typically 15 - 20 steps).
+            model_smoothing_pass_band (bool): The strength of the 3D smoothing (0.001 - 0.1 = strong smoothing,
+             0.5 - 1 = almost no smoothing).
+            min_segment_lines (int): The minimum number of lines that a segment must have to be considered for the RTSS.
+
+        Returns:
+            None
+        """
+        self._validate_entries(
+            image_smoothing,
+            image_smoothing_sigma,
+            image_smoothing_radius,
+            image_smoothing_threshold,
+            decimate_reduction,
+            decimate_threshold,
+            model_smoothing_iterations,
+            model_smoothing_pass_band,
+            min_segment_lines,
+        )
+
+        self.general_params["image_smoothing"] = image_smoothing
+        self.general_params["image_smoothing_sigma"] = image_smoothing_sigma
+        self.general_params["image_smoothing_radius"] = image_smoothing_radius
+        self.general_params["image_smoothing_threshold"] = image_smoothing_threshold
+        self.general_params["decimate_reduction"] = decimate_reduction
+        self.general_params["decimate_threshold"] = decimate_threshold
+        self.general_params["model_smoothing_iterations"] = model_smoothing_iterations
+        self.general_params["model_smoothing_pass_band"] = model_smoothing_pass_band
+        self.general_params["min_segment_lines"] = min_segment_lines
+
+    def set_image_params(
+        self,
+        image_identifier: str,
+        image_smoothing: bool,
+        image_smoothing_sigma: float,
+        image_smoothing_radius: float,
+        image_smoothing_threshold: float,
+        decimate_reduction: float,
+        decimate_threshold: float,
+        model_smoothing_iterations: int,
+        model_smoothing_pass_band: float,
+        min_segment_lines: int,
+    ) -> None:
+        """Set the parameters of the converter for a specific image using an identifier.
+
+        Args:
+            image_identifier (str): The identifier that identifies the segmentation mask for which the parameters are
+             set.
+            image_smoothing (bool): Whether to smooth the image before 3D model construction or not.
+            image_smoothing_sigma (float): The variance of the Gaussian smoothing before 3D model construction.
+            image_smoothing_radius (float): The radius of the Gaussian smoothing before 3D model construction.
+            image_smoothing_threshold (float): The minimum number of foreground voxels that must be contained in the
+             segmentation mask to trigger Gaussian smoothing.
+            decimate_reduction (float): The reduction factor for the 3D decimation. The decimation factor is valid
+             between 0 and 1 and the lower it is the more smoothing is applied.
+            decimate_threshold (float): The minimum number of foreground voxels that must be contained in the
+             segmentation mask to trigger 3D decimation.
+            model_smoothing_iterations (int): The number of 3D smoothing steps (typically 15 - 20 steps).
+            model_smoothing_pass_band (bool): The strength of the 3D smoothing (0.001 - 0.1 = strong smoothing,
+             0.5 - 1 = almost no smoothing).
+            min_segment_lines (int): The minimum number of lines that a segment must have to be considered for the RTSS.
+
+        Returns:
+            None
+        """
+
+        self._validate_entries(
+            image_smoothing,
+            image_smoothing_sigma,
+            image_smoothing_radius,
+            image_smoothing_threshold,
+            decimate_reduction,
+            decimate_threshold,
+            model_smoothing_iterations,
+            model_smoothing_pass_band,
+            min_segment_lines,
+        )
+
+        self.image_specific_params[image_identifier] = {
+            "image_smoothing": image_smoothing,
+            "image_smoothing_sigma": image_smoothing_sigma,
+            "image_smoothing_radius": image_smoothing_radius,
+            "image_smoothing_threshold": image_smoothing_threshold,
+            "decimate_reduction": decimate_reduction,
+            "decimate_threshold": decimate_threshold,
+            "model_smoothing_iterations": model_smoothing_iterations,
+            "model_smoothing_pass_band": model_smoothing_pass_band,
+            "min_segment_lines": min_segment_lines,
+        }
+
+
+class SegmentToRTSSConverterBase(Converter):
+    """A base class for low-level segmentation mask to DICOM-RTSS converters. This class is not intended to be used
+    directly but rather as a base class for more specific conversion algorithm implementations.
+
+    Args:
+        label_images (Union[Tuple[str, ...], Tuple[sitk.Image, ...]]): The path to the images or a sequence of
+         :class:`SimpleITK.Image` instances.
+        ref_image_datasets (Union[Tuple[str, ...], Tuple[Dataset, ...]]): The referenced DICOM image
+         :class:`~pydicom.dataset.Dataset` instances.
+        roi_names (Union[Tuple[str, ...], Dict[int, str], None]): The label names which will be assigned to the ROIs.
+        colors (Optional[Tuple[Tuple[int, int, int], ...]]): The colors which will be assigned to the ROIs.
+        meta_data (RTSSMetaData): The configuration to specify certain DICOM attributes (default: RTSSMetaData()).
+    """
+
+    def __init__(
+        self,
+        label_images: Union[Tuple[str, ...], Tuple[sitk.Image, ...]],
+        ref_image_datasets: Union[Tuple[str, ...], Tuple[Dataset, ...]],
+        roi_names: Union[Tuple[str, ...], Dict[int, str], None],
+        colors: Optional[Tuple[Tuple[int, int, int], ...]],
+        config: RTSSConverterConfiguration,
+        meta_data: RTSSMetaData = RTSSMetaData(),
+    ) -> None:
+        super().__init__()
+
+        # get or load the label images
+        self.label_images: Tuple[sitk.Image, ...] = (
+            label_images
+            if isinstance(label_images[0], sitk.Image)
+            else tuple([sitk.ReadImage(path, sitk.sitkUInt8) for path in label_images])
+        )
+
+        # get or load the reference image datasets
+        self.image_datasets: Tuple[Dataset, ...] = (
+            ref_image_datasets if isinstance(ref_image_datasets[0], Dataset) else load_datasets(ref_image_datasets)
+        )
+        self.image_datasets = self._sort_datasets(self.image_datasets)
+
+        # get the ROI names
+        if isinstance(roi_names, dict):
+            sorted_keys = sorted(roi_names.keys())
+            self.roi_names = tuple([str(roi_names.get(key)) for key in sorted_keys])
+        elif not roi_names:
+            self.roi_names = tuple([f"Structure_{i}" for i in range(len(self.label_images))])
+        else:
+            self.roi_names = roi_names
+
+        # get the colors
+        if not colors:
+            self.colors = COLOR_PALETTE
+        else:
+            self.colors = colors
+
+        # check if the correct number of ROI names and colors are provided
+        if len(self.roi_names) < len(self.label_images):
+            raise ValueError("The number of ROI names must be equal or larger than the number of label images!")
+
+        if len(self.colors) < len(self.label_images):
+            raise ValueError("The number of colors must be equal or larger than the number of label images!")
+
+        # get the meta data
+        self.meta_data = meta_data
+
+        # get the configuration
+        self.config = config
+
+    @staticmethod
+    def _sort_datasets(datasets: Tuple[Dataset, ...]) -> Tuple[Dataset, ...]:
+        """Sort the datasets by their patient image position.
+
+        Args:
+            datasets (Tuple[Dataset, ...]): The datasets to sort.
+
+        Returns:
+            Tuple[Dataset, ...]: The sorted datasets.
+        """
+        # get the principal axes of the image orientation
+        direction = np.array(get_slice_direction(datasets[0]))[2]
+
+        principal_component = np.argmax(np.abs(direction))
+        principal_direction = np.sign(direction[principal_component])
+
+        datasets_ = tuple(
+            sorted(
+                datasets,
+                key=lambda dataset: float(datasets[0].ImagePositionPatient[principal_component]),
+                reverse=principal_direction < 0,
+            )
+        )
+        return datasets_
+
+    def _validate_label_images(self) -> None:
+        """Validate the label images.
+
+        Raises:
+            ValueError: If the label images are not binary or the pixel type is not an integer.
+        """
+        # check if the label images are binary and that they have an integer pixel type
+        for image in self.label_images:
+            if np.unique(sitk.GetArrayFromImage(image)).size > 2:
+                raise ValueError("The label images must be binary!")
+
+            if "float" in image.GetPixelIDTypeAsString():
+                raise ValueError("The label images must have an integer pixel type!")
+
+    def _generate_basic_rtss(self) -> FileDataset:
+        """Generate the basic RTSS skeleton.
+
+        Returns:
+            FileDataset: The basic RT Structure Set.
+        """
+        # create the file meta for the dataset
+        file_meta = FileMetaDataset()
+        file_meta.FileMetaInformationGroupLength = 202
+        file_meta.FileMetaInformationVersion = b"\x00\x01"
+        file_meta.TransferSyntaxUID = ImplicitVRLittleEndian
+        file_meta.MediaStorageSOPClassUID = "1.2.840.10008.5.1.4.1.1.481.3"
+        file_meta.MediaStorageSOPInstanceUID = generate_uid()
+        file_meta.ImplementationClassUID = PYDICOM_IMPLEMENTATION_UID
+
+        # create the dataset
+        rtss = FileDataset("rt_struct", {}, file_meta=file_meta, preamble=b"\0" * 128)
+
+        # add the basic information
+        now = datetime.now()
+        rtss.SpecificCharacterSet = "ISO_IR 100"
+        rtss.InstanceCreationDate = now.strftime("%Y%m%d")
+        rtss.InstanceCreationTime = now.strftime("%H%M%S.%f")
+        rtss.StructureSetLabel = self.meta_data.structure_set_label
+        rtss.StructureSetDate = now.strftime("%Y%m%d")
+        rtss.StructureSetTime = now.strftime("%H%M%S.%f")
+        rtss.Modality = "RTSTRUCT"
+        rtss.Manufacturer = self.meta_data.manufacturer
+        rtss.ManufacturerModelName = self.meta_data.manufacturer_model_name
+        rtss.InstitutionName = self.meta_data.institution_name
+        rtss.OperatorsName = self.meta_data.operators_name
+        rtss.ApprovalStatus = self.meta_data.approval_status
+
+        rtss.is_little_endian = True
+        rtss.is_implicit_VR = True
+
+        # set values already defined in the file meta
+        rtss.SOPClassUID = rtss.file_meta.MediaStorageSOPClassUID
+        rtss.SOPInstanceUID = rtss.file_meta.MediaStorageSOPInstanceUID
+
+        # add study and series information
+        reference_dataset = self.image_datasets[0]
+        rtss.StudyDate = reference_dataset.StudyDate
+        rtss.SeriesDate = getattr(reference_dataset, "SeriesDate", "")
+        rtss.StudyTime = reference_dataset.StudyTime
+        rtss.SeriesTime = getattr(reference_dataset, "SeriesTime", "")
+
+        if self.meta_data.study_description is None:
+            rtss.StudyDescription = getattr(reference_dataset, "StudyDescription", "")
+        else:
+            rtss.StudyDescription = self.meta_data.study_description
+
+        if self.meta_data.series_description is None:
+            rtss.SeriesDescription = getattr(reference_dataset, "SeriesDescription", "")
+        else:
+            rtss.SeriesDescription = self.meta_data.series_description
+
+        rtss.StudyInstanceUID = reference_dataset.StudyInstanceUID
+        rtss.SeriesInstanceUID = generate_uid()
+        rtss.StudyID = reference_dataset.StudyID
+        rtss.SeriesNumber = self.meta_data.series_number
+        rtss.ReferringPhysicianName = self.meta_data.referring_physician_name
+        rtss.AccessionNumber = "0"
+
+        # add the patient information
+        if self.meta_data.patient_name is None:
+            rtss.PatientName = getattr(reference_dataset, "PatientName", "")
+        else:
+            rtss.PatientName = self.meta_data.patient_name
+
+        if self.meta_data.patient_id is None:
+            rtss.PatientID = getattr(reference_dataset, "PatientID", "")
+        else:
+            rtss.PatientID = self.meta_data.patient_id
+
+        if self.meta_data.patient_birth_date is None:
+            rtss.PatientBirthDate = getattr(reference_dataset, "PatientBirthDate", "")
+        else:
+            rtss.PatientBirthDate = self.meta_data.patient_birth_date
+
+        if self.meta_data.patient_sex is None:
+            rtss.PatientSex = getattr(reference_dataset, "PatientSex", "")
+        else:
+            rtss.PatientSex = self.meta_data.patient_sex
+
+        if self.meta_data.patient_age is None:
+            rtss.PatientAge = getattr(reference_dataset, "PatientAge", "")
+        else:
+            rtss.PatientAge = self.meta_data.patient_age
+
+        if self.meta_data.patient_weight is None:
+            rtss.PatientWeight = getattr(reference_dataset, "PatientWeight", "")
+        else:
+            rtss.PatientWeight = self.meta_data.patient_weight
+
+        if self.meta_data.patient_size is None:
+            rtss.PatientSize = getattr(reference_dataset, "PatientSize", "")
+        else:
+            rtss.PatientSize = self.meta_data.patient_size
+
+        # construct the ContourImageSequence
+        contour_image_sequence = Sequence()
+        for image_dataset in self.image_datasets:
+            contour_image_entry = Dataset()
+            contour_image_entry.ReferencedSOPClassUID = image_dataset.file_meta.MediaStorageSOPClassUID
+            contour_image_entry.ReferencedSOPInstanceUID = image_dataset.file_meta.MediaStorageSOPInstanceUID
+            contour_image_sequence.append(contour_image_entry)
+
+        # construct the RTReferencedSeriesSequence
+        rt_referenced_series_sequence = Sequence()
+        rt_referenced_series_entry = Dataset()
+        rt_referenced_series_entry.SeriesInstanceUID = reference_dataset.SeriesInstanceUID
+        rt_referenced_series_entry.ContourImageSequence = contour_image_sequence
+        rt_referenced_series_sequence.append(rt_referenced_series_entry)
+
+        # construct the RTReferencedStudySequence
+        rt_referenced_study_sequence = Sequence()
+        rt_referenced_study_entry = Dataset()
+        rt_referenced_study_entry.ReferencedSOPClassUID = "1.2.840.10008.3.1.2.3.1"  # RT Structure Set Storage
+        rt_referenced_study_entry.ReferencedSOPInstanceUID = reference_dataset.StudyInstanceUID
+        rt_referenced_study_entry.RTReferencedSeriesSequence = rt_referenced_series_sequence
+        rt_referenced_study_sequence.append(rt_referenced_study_entry)
+
+        # construct the ReferencedFrameOfReferenceSequence
+        rtss.ReferencedFrameOfReferenceSequence = Sequence()
+        referenced_frame_of_ref_entry = Dataset()
+        referenced_frame_of_ref_entry.FrameOfReferenceUID = reference_dataset.FrameOfReferenceUID
+        referenced_frame_of_ref_entry.RTReferencedStudySequence = rt_referenced_study_sequence
+        rtss.ReferencedFrameOfReferenceSequence.append(referenced_frame_of_ref_entry)
+
+        # construct the ROIContourSequence, StructureSetROISequence and RTROIObservationsSequence
+        rtss.ROIContourSequence = Sequence()
+        rtss.StructureSetROISequence = Sequence()
+        rtss.RTROIObservationsSequence = Sequence()
+
+        return rtss
+
+    @staticmethod
+    def _append_rt_roi_observation(roi_number: int, rtss: Dataset) -> None:
+        """Create a RTROIObservationsSequence entry for the given ROI data.
+
+        Args:
+            roi_number (int): The ROI data to be used for creating the RTROIObservationsSequence entry.
+            rtss (Dataset): The RTSS to be used for creating the RTROIObservationsSequence entry.
+
+        Returns:
+            None
+        """
+        # generate the RTROIObservationsSequence entry
+        rt_roi_observation = Dataset()
+        rt_roi_observation.ObservationNumber = roi_number
+        rt_roi_observation.ReferencedROINumber = roi_number
+        rt_roi_observation.ROIObservationDescription = (
+            "Type:Soft,Range:*/*,Fill:0,Opacity:0.0,Thickness:1," "LineThickness:2,read-only:false"
+        )
+        rt_roi_observation.private_creators = "University of Bern, Switzerland"
+        rt_roi_observation.RTROIInterpretedType = ""
+        rt_roi_observation.ROIInterpreter = ""
+
+        # add the RTROIObservationsSequence entry to the RTSS
+        rtss.RTROIObservationsSequence.append(rt_roi_observation)
+
+    def _append_structure_set_roi_sequence_entry(self, roi_name: str, roi_number: int, rtss: Dataset) -> None:
+        """Append a StructureSetROISequence entry to the given RTSS.
+
+        Args:
+            roi_name (str): The name of the ROI.
+            roi_number (int): The number of the ROI.
+            rtss (Dataset): The RTSS to be used for creating the StructureSetROISequence entry.
+
+        Returns:
+            None
+        """
+        # generate the StructureSetROISequence entry
+        structure_set_roi = Dataset()
+        structure_set_roi.ROINumber = roi_number
+        structure_set_roi.ReferencedFrameOfReferenceUID = self.image_datasets[0].get("FrameOfReferenceUID")
+        structure_set_roi.ROIName = roi_name
+        structure_set_roi.ROIDescription = ""
+        structure_set_roi.ROIGenerationAlgorithm = self.meta_data.roi_gen_algorithm
+
+        # add the StructureSetROISequence entry to the RTSS
+        rtss.StructureSetROISequence.append(structure_set_roi)
+
+    @abstractmethod
+    def convert(self) -> Any:
+        """Abstract method for starting the conversion procedure.
+
+        Returns:
+            Any: The converted data.
+        """
+        raise NotImplementedError()
+
+
+class SegmentToRTSSConverter2D(SegmentToRTSSConverterBase):
+    """A low-level 2D-based :class:`Converter` class for converting one or multiple
+    :class:`~pyradise.data.image.SegmentationImage` instances to a DICOM-RTSS :class:`~pydicom.dataset.Dataset`.
+    In contrast to the :class:`SegmentToRTSSConverter3D` class, this class generates the DICOM-RTSS contours using a
+    two-dimensional approach. This reduces the computation time and leads to a more robust conversion procedure.
+    However, this class has limitations such as the inability to smooth contours in all three dimensions. Furthermore,
+    the resulting contours may appear to be artificially generated and not as smooth as the ones generated by the
+    :class:`SegmentToRTSSConverter3D` class.
+
+    Warning:
+        The provided ``label_images`` must be binary, otherwise the conversion will fail.
+
+    Note:
+        Typically, this class is not used directly by the used but via the :class:`SubjectToRTSSConverter` which
+        processes :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries and thus provides a more suitable
+        interface.
+
+    Note:
+        This class can take a :class:`RTSSMetaData` instance as input to specify certain DICOM attributes of the
+        output DICOM-RTSS. If no instance is provided, the default values will be used.
+
+    Args:
+        label_images (Union[Tuple[str, ...], Tuple[sitk.Image, ...]]): The path to the images or a sequence of
+         :class:`SimpleITK.Image` instances.
+        ref_image_datasets (Union[Tuple[str, ...], Tuple[Dataset, ...]]): The referenced DICOM image
+         :class:`~pydicom.dataset.Dataset` instances.
+        roi_names (Union[Tuple[str, ...], Dict[int, str], None]): The label names which will be assigned to the ROIs.
+        colors (Optional[Tuple[Tuple[int, int, int], ...]]): The colors which will be assigned to the ROIs.
+        meta_data (RTSSMetaData): The configuration to specify certain DICOM attributes (default: RTSSMetaData()).
+        config (RTSSConverter2DConfiguration): The configuration to specify certain conversion parameters (default:
+         RTSSConverter2DConfiguration()).
+    """
+
+    def __init__(
+        self,
+        label_images: Union[Tuple[str, ...], Tuple[sitk.Image, ...]],
+        ref_image_datasets: Union[Tuple[str, ...], Tuple[Dataset, ...]],
+        roi_names: Union[Tuple[str, ...], Dict[int, str], None],
+        colors: Optional[Tuple[Tuple[int, int, int], ...]],
+        meta_data: RTSSMetaData = RTSSMetaData(),
+        config: RTSSConverter2DConfiguration = RTSSConverter2DConfiguration(),
+    ) -> None:
+        super().__init__(label_images, ref_image_datasets, roi_names, colors, config, meta_data)
+
+        self.config = config
+
+    @staticmethod
+    def _append_roi_contour(
+        mask: np.ndarray,
+        image_datasets: Tuple[Dataset, ...],
+        rtss: Dataset,
+        roi_color: Tuple[int, int, int],
+        roi_number: int,
+    ) -> None:
+        """Create a ROIContourSequence entry for the given ROI data.
+
+        Args:
+            mask (np.ndarray): The ROI mask to generate the contours from.
+            image_datasets (Tuple[Dataset, ...]): The referenced image datasets.
+            rtss (Dataset): The RTSS dataset.
+
+        Returns:
+            None
+        """
+        roi_contour = Dataset()
+        roi_contour.ROIDisplayColor = [str(color) for color in roi_color]
+        roi_contour.ContourSequence = SegmentToRTSSConverter2D._create_contour_sequence(mask, image_datasets)
+        roi_contour.ReferencedROINumber = str(roi_number)
+
+        # add the ROIContourSequence entry to the RTSS
+        rtss.ROIContourSequence.append(roi_contour)
+
+    @staticmethod
+    def _create_contour_sequence(mask: np.ndarray, image_datasets: Tuple[Dataset, ...]) -> Sequence:
+        """Create a ContourSequence for the given ROI data by iterating through each slice of the mask.
+        For each connected segment within a slice, a ContourSequence entry is created.
+
+        Args:
+            mask (np.ndarray): The ROI mask for generating the contours.
+            image_datasets (Tuple[Dataset, ...]): The referenced image datasets.
+
+        Returns:
+            Sequence: The created ContourSequence.
+        """
+        contour_sequence = Sequence()
+
+        contours_coordinates = SegmentToRTSSConverter2D._get_contours_coordinates(mask, image_datasets)
+
+        for series_slice, slice_contours in zip(image_datasets, contours_coordinates):
+            for contour_data in slice_contours:
+                if len(contour_data) <= 3:
+                    continue
+                contour_seq_entry = SegmentToRTSSConverter2D._create_contour_sequence_entry(series_slice, contour_data)
+                contour_sequence.append(contour_seq_entry)
+
+        return contour_sequence
+
+    @staticmethod
+    def _get_contours_coordinates(mask: np.ndarray, image_datasets: Tuple[Dataset, ...]) -> List[List[List[float]]]:
+        """Get the contour coordinates for each slice of the mask.
+
+        Args:
+            mask (np.ndarray): The ROI mask for generating the contours.
+            image_datasets (Tuple[Dataset, ...]): The referenced image datasets.
+
+        Returns:
+            List[List[List[float]]]: The contour coordinates for each slice of the mask.
+        """
+        transform_matrix = SegmentToRTSSConverter2D._get_pixel_to_patient_transformation_matrix(image_datasets)
+
+        series_contours = []
+        for i in range(len(image_datasets)):
+            mask_slice = mask[i, :, :]
+
+            # Do not add ROI's for blank slices
+            if np.sum(mask_slice) == 0:
+                series_contours.append([])
+                continue
+
+            # Get contours from mask
+            contours, _ = SegmentToRTSSConverter2D._find_mask_contours(mask_slice)
+
+            if not contours:
+                raise Exception("Unable to find contour in non empty mask, please check your mask formatting!")
+
+            # Format for DICOM
+            formatted_contours = []
+            for contour in contours:
+                # Add z index
+                contour = np.concatenate((np.array(contour), np.full((len(contour), 1), i)), axis=1)
+
+                transformed_contour = SegmentToRTSSConverter2D._apply_transformation_to_3d_points(
+                    contour, transform_matrix
+                )
+                dicom_formatted_contour = np.ravel(transformed_contour).tolist()
+                formatted_contours.append(dicom_formatted_contour)
+
+            series_contours.append(formatted_contours)
+
+        return series_contours
+
+    @staticmethod
+    def _get_pixel_to_patient_transformation_matrix(image_datasets: Tuple[Dataset]) -> np.ndarray:
+        """Get the pixel to patient transformation matrix according to the referenced image datasets.
+
+        Notes:
+            Description see: https://nipy.org/nibabel/dicom/dicom_orientation.html
+
+        Args:
+            image_datasets (Tuple[Dataset]): The image datasets with the necessary information to retrieve the pixel
+             to patient transformation matrix.
+
+        Returns:
+            np.ndarray: The pixel to patient transformation matrix.
+        """
+
+        first_slice = image_datasets[0]
+
+        offset = np.array(first_slice.ImagePositionPatient)
+        row_spacing, column_spacing = first_slice.PixelSpacing
+        slice_spacing = get_spacing_between_slices(image_datasets)
+        row_direction, column_direction, slice_direction = get_slice_direction(first_slice)
+
+        mat = np.identity(4, dtype=float)
+        mat[:3, 0] = row_direction * row_spacing
+        mat[:3, 1] = column_direction * column_spacing
+        mat[:3, 2] = slice_direction * slice_spacing
+        mat[:3, 3] = offset
+
+        return mat
+
+    @staticmethod
+    def _find_mask_contours(mask: np.ndarray, approximate_contours: bool = True) -> Tuple[List[np.ndarray], List]:
+        """Find the contours in the provided mask.
+
+        Args:
+            mask (np.ndarray): The mask to be used for finding the contours.
+            approximate_contours (bool): Whether to approximate the contours (default: True).
+
+        Returns:
+            Tuple[List[np.ndarray], List]: The contours and the hierarchy.
+        """
+        method = cv.CHAIN_APPROX_SIMPLE if approximate_contours else cv.CHAIN_APPROX_NONE
+        contours, hierarchy = cv.findContours(mask.astype(np.uint8), cv.RETR_TREE, method)
+        contours = list(contours)
+
+        for i, contour in enumerate(contours):
+            contours[i] = [[pos[0][0], pos[0][1]] for pos in contour]
+        hierarchy = hierarchy[0]
+
+        return contours, hierarchy
+
+    @staticmethod
+    def _apply_transformation_to_3d_points(points: np.ndarray, transformation_matrix: np.ndarray) -> np.ndarray:
+        """Apply the given transformation matrix to the given 3D points.
+
+        Notes:
+            The transformation matrix is expected to be a 4x4 matrix (homogeneous coordinate transform).
+
+
+        Args:
+            points (np.ndarray): The points to be transformed.
+            transformation_matrix (np.ndarray): The transformation matrix.
+
+        Returns:
+            np.ndarray: The transformed points.
+        """
+        vec = np.concatenate((points, np.ones((points.shape[0], 1))), axis=1)
+        return vec.dot(transformation_matrix.T)[:, :3]
+
+    @staticmethod
+    def _create_contour_sequence_entry(series_slice: Dataset, contour_data: List[float]) -> Dataset:
+        """Create a contour sequence entry for the given slice.
+
+        Args:
+            series_slice (Dataset): The slice to be used for creating the contour sequence entry.
+            contour_data (List[float]): The contour data to be used for creating the contour sequence entry.
+
+        Returns:
+            Dataset: The contour sequence entry.
+        """
+        # create the ContourImageSequence entry
+        contour_image = Dataset()
+        contour_image.ReferencedSOPClassUID = series_slice.file_meta.MediaStorageSOPClassUID
+        contour_image.ReferencedSOPInstanceUID = series_slice.file_meta.MediaStorageSOPInstanceUID
+
+        # construct the ContourImageSequence
+        contour_image_sequence = Sequence()
+        contour_image_sequence.append(contour_image)
+
+        # construct the ContourSequence entry
+        contour = Dataset()
+        contour.ContourImageSequence = contour_image_sequence
+        contour.ContourGeometricType = "CLOSED_PLANAR"
+        contour.NumberOfContourPoints = len(contour_data) // 3  # each contour point consists of an x, y, and z value
+        contour.ContourData = contour_data
+
+        return contour
+
+    @staticmethod
+    def _adjust_label_image_to_dicom(label_image: sitk.Image, image_datasets: Tuple[Dataset, ...]) -> sitk.Image:
+        """Adjust the given label image to the DICOM image.
+
+        Args:
+            label_image (sitk.Image): The label image to be adjusted.
+            image_datasets (Tuple[Dataset, ...]): The DICOM image datasets.
+
+        Returns:
+            sitk.Image: The adjusted label image.
+        """
+        # construct a reference image from the DICOM datasets
+
+        # compute the direction from the DICOM datasets
+        vec_0 = image_datasets[0].ImageOrientationPatient[:3]
+        vec_1 = image_datasets[0].ImageOrientationPatient[3:]
+        vec_2 = np.cross(np.array(vec_0, dtype=float), np.array(vec_1, dtype=float))
+        dicom_direction = np.stack((vec_0, vec_1, vec_2)).astype(float).T.reshape(-1).tolist()
+
+        # compute the origin from the DICOM datasets
+        dicom_origin = image_datasets[0].ImagePositionPatient
+
+        # compute the spacing from the DICOM datasets
+        dicom_spacing = [
+            float(image_datasets[0].PixelSpacing[0]),
+            float(image_datasets[0].PixelSpacing[1]),
+            get_spacing_between_slices(image_datasets),
+        ]
+
+        # compute the size from the DICOM datasets
+        # note: sizes must be in z, x, y order because numpy reverses axes
+        dicom_size = (len(image_datasets), image_datasets[0].Rows, image_datasets[0].Columns)
+
+        # construct the reference image via numpy
+        reference_image_np = np.zeros(dicom_size)
+        reference_image_sitk = sitk.GetImageFromArray(reference_image_np)
+        reference_image_sitk.SetDirection(dicom_direction)
+        reference_image_sitk.SetOrigin(dicom_origin)
+        reference_image_sitk.SetSpacing(dicom_spacing)
+
+        # orient the label image according to the reference image
+        reference_orientation = sitk.DICOMOrientImageFilter_GetOrientationFromDirectionCosines(
+            reference_image_sitk.GetDirection()
+        )
+        label_image_0 = sitk.DICOMOrient(label_image, reference_orientation)
+
+        criteria = []
+        criteria.extend(
+            [
+                reference_image_sitk.GetSpacing()[i] == label_image_0.GetSpacing()[i]
+                for i in range(label_image.GetDimension())
+            ]
+        )
+        criteria.extend(
+            [
+                reference_image_sitk.GetOrigin()[i] == label_image_0.GetOrigin()[i]
+                for i in range(label_image.GetDimension())
+            ]
+        )
+        criteria.extend(
+            [
+                reference_image_sitk.GetDirection()[i] == label_image_0.GetDirection()[i]
+                for i in range(label_image.GetDimension())
+            ]
+        )
+        criteria.extend(
+            [reference_image_sitk.GetSize()[i] == label_image_0.GetSize()[i] for i in range(label_image.GetDimension())]
+        )
+
+        if all(criteria):
+            return label_image_0
+
+        # resample the oriented label image to the reference image
+        label_image_1 = sitk.Resample(
+            label_image_0, reference_image_sitk, sitk.Transform(), sitk.sitkNearestNeighbor, 0.0, sitk.sitkUInt8
+        )
+        return label_image_1
+
+    @staticmethod
+    def _smooth_label_image(label_image: sitk.Image, kernel_size: int, sigma: float) -> sitk.Image:
+        """Apply Gaussian smoothing to a label image.
+
+        Args:
+            label_image (sitk.Image): The image to be smoothened.
+            kernel_size (int): The maximum kernel size for the Gaussian kernel.
+            sigma (float): The sigma for the Gaussian Kernel.
+
+        Returns:
+             sitk.Image: The smoothened image.
+        """
+        label_image_0 = sitk.Cast(label_image, sitk.sitkFloat32)
+
+        num_dims = label_image.GetDimension()
+        label_image_1 = sitk.DiscreteGaussian(
+            label_image_0, variance=[sigma] * num_dims, maximumKernelWidth=kernel_size
+        )
+        label_image_2 = sitk.BinaryThreshold(label_image_1, 0.5, 1.0, 1, 0)
+
+        return label_image_2
+
+    def convert(self) -> Dataset:
+        """Convert the provided :class:`SimpleITK.Image` instances to a DICOM-RTSS :class:`~pydicom.dataset.Dataset`
+        instance using a two-dimensional reconstruction algorithm.
+
+        Returns:
+            Dataset: The generated DICOM-RTSS :class:`~pydicom.dataset.Dataset`.
+        """
+        # generate the basic RTSS dataset
+        rtss = self._generate_basic_rtss()
+
+        # convert and add the ROIs to the RTSS
+        for idx, (label, name, color) in enumerate(zip(self.label_images, self.roi_names, self.colors)):
+            # check if a specific parameterization must be used for this image
+            if self.config.get_image_params(name) is not None:
+                smooth = self.config.get_image_params(name, "smoothing")
+                kernel = self.config.get_image_params(name, "smoothing_kernel_size")
+                sigma = self.config.get_image_params(name, "smoothing_sigma")
+            else:
+                config = self.config.get_general_params()
+                smooth = config.get("smoothing")
+                kernel = config.get("smoothing_kernel_size")
+                sigma = config.get("smoothing_sigma")
+
+            # adjust the label image to have the same properties as the DICOM datasets
+            label_processed = self._adjust_label_image_to_dicom(label, self.image_datasets)
+
+            # smooth the label image
+            if smooth:
+                label_processed = self._smooth_label_image(label_processed, kernel, sigma)
+
+            # get the binary image data from the label image
+            mask = sitk.GetArrayFromImage(label_processed)
+
+            self._append_roi_contour(mask, self.image_datasets, rtss, color, idx + 1)
+            self._append_structure_set_roi_sequence_entry(name, idx + 1, rtss)
+            self._append_rt_roi_observation(idx + 1, rtss)
+
+        return rtss
+
+
+class SegmentToRTSSConverter3D(SegmentToRTSSConverterBase):
+    """A low-level 3D-based :class:`Converter` class for converting one or multiple
+    :class:`~pyradise.data.image.SegmentationImage` instances to a DICOM-RTSS :class:`~pydicom.dataset.Dataset`.
+    In contrast to the :class:`SegmentToRTSSConverter2D` class, this class generates the DICOM-RTSS contours using a
+    three-dimensional approach. This reduces spatial inconsistencies but comes at the cost of a longer computation time
+    and higher memory consumption. Furthermore, this converter is less robust than its two-dimensional counterpart.
+    However, the resulting contours are more accurate and appear more natural it the converter is applied with
+    appropriate parameterization.
+
+    Warning:
+        The provided ``label_images`` must be binary, otherwise the conversion will fail.
+
+    Note:
+        Typically, this class is not used directly by the used but via the :class:`SubjectToRTSSConverter` which
+        processes :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries and thus provides a more suitable
+        interface.
+
+    Note:
+        This class can take a :class:`RTSSMetaData` instance as input to specify certain DICOM attributes of the
+        output DICOM-RTSS. If no instance is provided, the default values will be used.
+
+    Args:
+        label_images (Union[Tuple[str, ...], Tuple[sitk.Image, ...]]): The path to the images or a sequence of
+         :class:`SimpleITK.Image` instances.
+        ref_image_datasets (Union[Tuple[str, ...], Tuple[Dataset, ...]]): The referenced DICOM image
+         :class:`~pydicom.dataset.Dataset` instances.
+        roi_names (Union[Tuple[str, ...], Dict[int, str], None]): The label names which will be assigned to the ROIs.
+        colors (Optional[Tuple[Tuple[int, int, int], ...]]): The colors which will be assigned to the ROIs.
+        meta_data (RTSSMetaData): The configuration to specify certain DICOM attributes (default: RTSSMetaData()).
+        config (RTSSConverter3DConfiguration): The configuration to specify certain conversion parameters (default:
+         RTSSConverter3DConfiguration()).
+    """
+
+    def __init__(
+        self,
+        label_images: Union[Tuple[str, ...], Tuple[sitk.Image, ...]],
+        ref_image_datasets: Union[Tuple[str, ...], Tuple[Dataset, ...]],
+        roi_names: Union[Tuple[str, ...], Dict[int, str], None],
+        colors: Optional[Tuple[Tuple[int, int, int], ...]],
+        meta_data: RTSSMetaData = RTSSMetaData(),
+        config: RTSSConverter3DConfiguration = RTSSConverter3DConfiguration(),
+    ):
+        super().__init__(label_images, ref_image_datasets, roi_names, colors, config, meta_data)
+
+        self.config = config
+
+    @staticmethod
+    def _has_foreground_on_borders(image: sitk.Image):
+        """Check if the provided image has foreground pixels on the borders.
+
+        Args:
+            image (sitk.Image): The image to check.
+
+        Returns:
+            bool: True if the image has foreground pixels on the borders, False otherwise.
+        """
+        image_array = sitk.GetArrayFromImage(image)
+
+        return any(
+            (
+                np.any(image_array[0, :, :]),
+                np.any(image_array[-1, :, :]),
+                np.any(image_array[:, 0, :]),
+                np.any(image_array[:, -1, :]),
+                np.any(image_array[:, :, 0]),
+                np.any(image_array[:, :, -1]),
+            )
+        )
+
+    def preprocess_image(self, image_sitk: sitk.Image) -> sitk.Image:
+        """Preprocess the provided :class:`SimpleITK.Image` instance such that the image has the same properties as
+        the referenced DICOM image series.
+
+        Args:
+            image_sitk (sitk.Image): The :class:`SimpleITK.Image` instance to preprocess.
+
+        Returns:
+            sitk.Image: The preprocessed :class:`SimpleITK.Image` instance.
+        """
+        # orient the image to the LPS coordinate system (-> DICOM standard)
+        image_sitk = sitk.DICOMOrient(image_sitk, "LPS")
+
+        # resample to match the DICOM image
+        origin = self.image_datasets[0].ImagePositionPatient
+        slice_spacing = get_spacing_between_slices(self.image_datasets)
+        spacing = (
+            float(self.image_datasets[0].PixelSpacing[0]),
+            float(self.image_datasets[0].PixelSpacing[1]),
+            slice_spacing,
+        )
+        direction = np.array(get_slice_direction(self.image_datasets[0])).T.flatten()
+        size = (self.image_datasets[0].Rows, self.image_datasets[0].Columns, len(self.image_datasets))
+
+        resampler = sitk.ResampleImageFilter()
+        resampler.SetOutputOrigin(origin)
+        resampler.SetOutputSpacing(spacing)
+        resampler.SetOutputDirection(direction)
+        resampler.SetSize(size)
+        resampler.SetTransform(sitk.Transform())
+        resampler.SetOutputPixelType(sitk.sitkUInt8)
+        resampler.SetInterpolator(sitk.sitkNearestNeighbor)
+        resampler.SetDefaultPixelValue(0)
+        image_sitk = resampler.Execute(image_sitk)
+
+        # convert to binary
+        image_sitk = sitk.BinaryThreshold(image_sitk, 1, 255, 255, 0)
+
+        return image_sitk
+
+    def _get_3d_model(
+        self,
+        sitk_image: sitk.Image,
+        image_smoothing: bool,
+        smooth_sigma: float,
+        smooth_radius: float,
+        smooth_threshold: float,
+        decimate_reduction: float,
+        decimate_threshold: float,
+        model_smooth_iter: int,
+        model_smooth_pass_band: float,
+    ) -> vtk_dm.vtkPolyData:
+        """Generate a 3D model of the provided :class:`SimpleITK.Image` instance.
+
+        Args:
+            sitk_image (sitk.Image): The :class:`SimpleITK.Image` instance to generate the 3D model for.
+            image_smoothing (bool): Whether to smooth the image before generating the 3D model.
+            smooth_sigma (float): The sigma value for the Gaussian smoothing.
+            smooth_radius (float): The radius value for the Gaussian smoothing.
+            smooth_threshold (float): The threshold value for the Gaussian smoothing.
+            decimate_reduction (float): The reduction value for the decimation.
+            decimate_threshold (float): The threshold value for the decimation.
+            model_smooth_iter (int): The number of iterations for the model smoothing.
+            model_smooth_pass_band (float): The pass band value for the model smoothing.
+
+        Returns:
+            vtk_dm.vtkPolyData: The 3D model of the provided :class:`SimpleITK.Image` instance.
+        """
+        # cast the image to vtkImageData
+        itk_image = convert_to_itk_image(sitk_image)
+        vtk_image = itk.vtk_image_from_image(itk_image)
+
+        # set the direction matrix
+        vtk_image.SetDirectionMatrix(sitk_image.GetDirection())
+
+        # pad the image to avoid boundary effects if necessary
+        if self._has_foreground_on_borders(sitk_image):
+            margin = 10
+            extent = vtk_image.GetExtent()
+            new_extent = (
+                extent[0] - margin,
+                extent[1] + margin,
+                extent[2] - margin,
+                extent[3] + margin,
+                extent[4] - margin,
+                extent[5] + margin,
+            )
+            padder = vtk_icore.vtkImageConstantPad()
+            padder.SetConstant(0)
+            padder.SetInputDataObject(0, vtk_image)
+            padder.SetOutputWholeExtent(new_extent)
+            padder.Update(0)
+            vtk_image = padder.GetOutput()
+
+            # update the image properties
+            vtk_image.SetDirectionMatrix(sitk_image.GetDirection())
+            vtk_image.SetOrigin(sitk_image.GetOrigin())
+            vtk_image.SetSpacing(sitk_image.GetSpacing())
+
+        # apply gaussian smoothing
+        foreground_amount = sitk.GetArrayFromImage(sitk_image).sum() / 255
+        if foreground_amount > smooth_threshold and image_smoothing:
+            gaussian = vtk_igen.vtkImageGaussianSmooth()
+            gaussian.SetInputDataObject(0, vtk_image)
+            gaussian.SetStandardDeviation(smooth_sigma)
+            gaussian.SetRadiusFactor(smooth_radius)
+            gaussian.Update(0)
+            vtk_image = gaussian.GetOutputDataObject(0)
+
+            # apply the thresholding
+            image_threshold = vtk_icore.vtkImageThreshold()
+            image_threshold.ThresholdByUpper(127.5)
+            image_threshold.SetInValue(255)
+            image_threshold.SetOutValue(0)
+            image_threshold.SetInputDataObject(0, vtk_image)
+            image_threshold.Update(0)
+            vtk_image = image_threshold.GetOutputDataObject(0)
+
+            # update the image properties
+            vtk_image.SetDirectionMatrix(sitk_image.GetDirection())
+            vtk_image.SetOrigin(sitk_image.GetOrigin())
+            vtk_image.SetSpacing(sitk_image.GetSpacing())
+
+        # apply flying edges
+        flying_edges = vtk_fcore.vtkFlyingEdges3D()
+        flying_edges.SetInputDataObject(0, vtk_image)
+        flying_edges.SetValue(0, 255)
+        flying_edges.ComputeGradientsOff()
+        flying_edges.ComputeNormalsOff()
+        flying_edges.Update(0)
+        model = flying_edges.GetOutputDataObject(0)
+
+        # apply decimation
+        if foreground_amount > decimate_threshold:
+            decimate = vtk_fcore.vtkDecimatePro()
+            decimate.SetInputConnection(0, flying_edges.GetOutputPort(0))
+            decimate.SetTargetReduction(decimate_reduction)
+            decimate.PreserveTopologyOn()
+            decimate.SetMaximumError(1)
+            decimate.SplittingOff()
+            decimate.SetFeatureAngle(60.0)
+            decimate.Update(0)
+            model = decimate.GetOutputDataObject(0)
+
+        # smooth via the sinc filter
+        if model_smooth_iter > 0:
+            smoother = vtk_fcore.vtkWindowedSincPolyDataFilter()
+            smoother.SetInputDataObject(0, model)
+            smoother.SetNumberOfIterations(model_smooth_iter)
+            smoother.BoundarySmoothingOff()
+            smoother.FeatureEdgeSmoothingOff()
+            smoother.SetFeatureAngle(60.0)
+            smoother.SetPassBand(model_smooth_pass_band)
+            smoother.NonManifoldSmoothingOn()
+            smoother.NormalizeCoordinatesOn()
+            smoother.Update(0)
+            model = smoother.GetOutputDataObject(0)
+
+        # get normals
+        normals = vtk_fcore.vtkPolyDataNormals()
+        normals.SetInputDataObject(0, model)
+        normals.SetFeatureAngle(60.0)
+
+        # strip the polydata
+        stripper = vtk_fcore.vtkStripper()
+        stripper.SetInputConnection(0, normals.GetOutputPort(0))
+        stripper.JoinContiguousSegmentsOn()
+        stripper.Update(0)
+        stripped = stripper.GetOutput()
+
+        return stripped
+
+    def _get_2d_contours(
+        self, polydata: vtk_dm.vtkPolyData, min_segment_lines: int = 0
+    ) -> List[Optional[List[List[List[float]]]]]:
+        """Get the 2D contours of the provided :class:`vtk.vtkPolyData` instance that correspond with the referenced
+        DICOM image series.
+
+        Args:
+            polydata (vtk.vtkPolyData): The :class:`vtk.vtkPolyData` instance to get the 2D contours for.
+            min_segment_lines (int): The minimum number of lines that a contour segment must have to be considered
+             (default: 0).
+
+        Returns:
+            List[Optional[List[List[List[float]]]]]: The 2D contours of the provided :class:`vtk.vtkPolyData` instance
+            that correspond with the referenced DICOM image series.
+        """
+        origin = self.image_datasets[0].ImagePositionPatient
+        origin = [float(val) for val in origin]
+        first_pos = self.image_datasets[0].ImagePositionPatient
+        last_pos = self.image_datasets[-1].ImagePositionPatient
+        length = np.abs(np.linalg.norm(np.array(last_pos) - np.array(first_pos)))
+        slice_spacing = length / (len(self.image_datasets) - 1)
+        normal = tuple(
+            np.cross(
+                np.array(self.image_datasets[0].get("ImageOrientationPatient")[0:3]),
+                np.array(self.image_datasets[0].get("ImageOrientationPatient")[3:6]),
+            )
+        )
+
+        # create the initial cutting plane
+        plane = vtk_dm.vtkPlane()
+        plane.SetOrigin(*origin)
+        plane.SetNormal(*normal)
+
+        # create the cutter
+        cutter = vtk_fcore.vtkCutter()
+        cutter.SetInputDataObject(0, polydata)
+        cutter.SetCutFunction(plane)
+        cutter.GenerateTrianglesOn()
+        cutter.GenerateValues(len(self.image_datasets), 0, length)
+
+        # create the cleaner
+        cleaner = vtk_fcore.vtkCleanPolyData()
+        cleaner.SetInputConnection(0, cutter.GetOutputPort(0))
+        cleaner.SetAbsoluteTolerance(0.01)
+        cleaner.PointMergingOn()
+        cleaner.Update(0)
+
+        # get the polylines
+        loop = vtk_fmodel.vtkContourLoopExtraction()
+        loop.SetInputConnection(0, cleaner.GetOutputPort(0))
+        loop.SetOutputModeToPolylines()
+        loop.SetNormal(*normal)
+        loop.Update(0)
+        looped = loop.GetOutput()
+
+        # sort the polydata
+        sorter = vtk_fhybrid.vtkDepthSortPolyData()
+        sorter.SetInputDataObject(0, looped)
+        sorter.SetVector(*tuple(np.array(normal) * -1))
+        sorter.SetOrigin(*origin)
+        sorter.SetSortScalars(True)
+        sorter.SetDirectionToSpecifiedVector()
+        sorter.Update(0)
+        looped = sorter.GetOutput()
+
+        # get the polylines for each slice if there are any
+        cells = looped.GetLines()
+        points = looped.GetPoints()
+
+        indices = vtk_ccore.vtkIdList()
+        cell_indicator = cells.GetNextCell(indices)
+
+        # if there are no cells return an empty list
+        if cell_indicator == 0:
+            return [None for _ in range(len(self.image_datasets))]
+
+        # get the slice planes
+        slice_planes = {}
+        for slice_idx, dataset in enumerate(self.image_datasets):
+            slice_plane = vtk_dm.vtkPlane()
+            slice_plane.SetOrigin(*dataset.ImagePositionPatient)
+            slice_plane.SetNormal(*normal)
+
+            slice_planes.update({slice_idx: slice_plane})
+
+        # get the contours for the appropriate slices
+        contours_points: List[Optional[List[List[float]]]] = [None for _ in range(len(self.image_datasets))]
+        while cell_indicator == 1:
+            if indices.GetNumberOfIds() <= min_segment_lines:
+                cell_indicator = cells.GetNextCell(indices)
+                continue
+
+            reference_point = points.GetPoint(indices.GetId(0))
+
+            for slice_idx, slice_plane in slice_planes.items():
+                distance = slice_plane.DistanceToPlane(reference_point)
+
+                if distance <= slice_spacing * 0.5:
+                    contour_points = []
+
+                    for idx in range(indices.GetNumberOfIds()):
+                        contour_points.append(points.GetPoint(indices.GetId(idx)))
+
+                    if isinstance(contours_points[slice_idx], list):
+                        contours_points[slice_idx].append(contour_points)
+                    else:
+                        contours_points[slice_idx] = [contour_points]
+
+                    cell_indicator = cells.GetNextCell(indices)
+                    break
+
+        return contours_points
+
+    def _append_roi_contour_sequence_entry(
+        self, contours: List[List[List[List[float]]]], color: Tuple[int, int, int], roi_number: int, rtss: Dataset
+    ) -> None:
+        """Append a ROIContourSequence entry to the given DICOM-RTSS.
+
+        Args:
+            contours (List[List[List[List[float]]]]): The 2D contours of the ROI.
+            color (Tuple[int, int, int]): The color of the ROI.
+            roi_number (int): The ROI number.
+            rtss (Dataset): The DICOM-RTSS to append the ROIContourSequence entry to.
+
+        Returns:
+            None
+        """
+        roi_contour = Dataset()
+        roi_contour.ROIDisplayColor = [str(color_) for color_ in color]
+        roi_contour.ReferencedROINumber = str(roi_number)
+
+        # create the contour sequence
+        contour_sequence = Sequence()
+        for slice_dataset, slice_coords in zip(self.image_datasets, contours):
+            if slice_coords is None:
+                continue
+
+            for slice_coord_set in slice_coords:
+                # create the contour image sequence
+                contour_image = Dataset()
+                contour_image.ReferencedSOPClassUID = str(slice_dataset.file_meta.MediaStorageSOPClassUID)
+                contour_image.ReferencedSOPInstanceUID = str(slice_dataset.SOPInstanceUID)
+
+                contour_image_sequence = Sequence()
+                contour_image_sequence.append(contour_image)
+
+                # append to the contour sequence
+                contour = Dataset()
+                contour.ContourImageSequence = contour_image_sequence
+                contour.ContourGeometricType = "CLOSED_PLANAR"
+                contour.NumberOfContourPoints = len(slice_coord_set)
+                contour.ContourData = [coord for point in slice_coord_set for coord in point]
+                contour_sequence.append(contour)
+
+        roi_contour.ContourSequence = contour_sequence
+
+        # append to the ROIContourSequence to the RTSS
+        rtss.ROIContourSequence.append(roi_contour)
+
+    def convert(self) -> Dataset:
+        """Convert the provided :class:`SimpleITK.Image` instances to a DICOM-RTSS :class:`~pydicom.dataset.Dataset`
+        instance using a three-dimensional reconstruction algorithm.
+
+        Returns:
+            Dataset: The generated DICOM-RTSS :class:`~pydicom.dataset.Dataset`.
+        """
+        rtss = self._generate_basic_rtss()
+
+        for idx, (label, name, color) in enumerate(zip(self.label_images, self.roi_names, self.colors)):
+            # check if the image is empty
+            label_image_np = sitk.GetArrayFromImage(label)
+            if np.sum(label_image_np) == 0:
+                contours = [None for _ in range(len(self.image_datasets))]
+
+            else:
+                # check if specific parameters are given for this ROI
+                if self.config.get_image_params(name) is not None:
+                    image_params = self.config.get_image_params(name)
+                    image_smooth = image_params.get("image_smoothing")
+                    image_smooth_sigma = image_params.get("image_smoothing_sigma")
+                    image_smooth_radius = image_params.get("image_smoothing_radius")
+                    image_threshold = image_params.get("image_smoothing_threshold")
+                    decimate_reduction = image_params.get("decimate_reduction")
+                    decimate_threshold = image_params.get("decimate_threshold")
+                    model_smoothing_iter = image_params.get("model_smoothing_iterations")
+                    model_smoothing_pass_band = image_params.get("model_smoothing_pass_band")
+                    min_segment_lines = image_params.get("min_segment_lines")
+                else:
+                    image_params = self.config.get_general_params()
+                    image_smooth = image_params.get("image_smoothing")
+                    image_smooth_sigma = image_params.get("image_smoothing_sigma")
+                    image_smooth_radius = image_params.get("image_smoothing_radius")
+                    image_threshold = image_params.get("image_smoothing_threshold")
+                    decimate_reduction = image_params.get("decimate_reduction")
+                    decimate_threshold = image_params.get("decimate_threshold")
+                    model_smoothing_iter = image_params.get("model_smoothing_iterations")
+                    model_smoothing_pass_band = image_params.get("model_smoothing_pass_band")
+                    min_segment_lines = image_params.get("min_segment_lines")
+
+                # preprocess the image
+                label = self.preprocess_image(label)
+
+                # Get polydata
+                polydata = self._get_3d_model(
+                    label,
+                    image_smooth,
+                    image_smooth_sigma,
+                    image_smooth_radius,
+                    image_threshold,
+                    decimate_reduction,
+                    decimate_threshold,
+                    model_smoothing_iter,
+                    model_smoothing_pass_band,
+                )
+
+                # Get the contour data
+                contours = self._get_2d_contours(polydata, min_segment_lines)
+
+            # enhance the rtss with the data
+            self._append_structure_set_roi_sequence_entry(name, idx + 1, rtss)
+            self._append_roi_contour_sequence_entry(contours, color, idx + 1, rtss)
+            self._append_rt_roi_observation(idx + 1, rtss)
+
+        return rtss
+
+
+class DicomImageSeriesConverter(Converter):
+    """A :class:`Converter` class for converting DICOM image series to one or multiple
+    :class:`~pyradise.data.image.IntensityImage` instances.
+
+    Args:
+        image_info (Tuple[DicomSeriesImageInfo, ...]): The :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo`
+         entries of the images to convert.
+        registration_info (Tuple[DicomSeriesRegistrationInfo, ...]): The
+         :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries (default: tuple()).
+    """
+
+    def __init__(
+        self,
+        image_info: Tuple[DicomSeriesImageInfo, ...],
+        registration_info: Tuple[DicomSeriesRegistrationInfo, ...] = tuple(),
+    ) -> None:
+        super().__init__()
+        self.image_info = image_info
+        self.reg_info = registration_info
+
+    def _get_image_info_by_series_instance_uid(self, series_instance_uid: str) -> Optional[DicomSeriesImageInfo]:
+        """Get the :class:`DicomSeriesImageInfo` entries which match with the specified SeriesInstanceUID.
+
+        Args:
+            series_instance_uid (str): The SeriesInstanceUID which must be contained in the returned
+             :class:`DicomSeriesImageInfo` entries.
+
+        Returns:
+            Optional[DicomSeriesImageInfo]: The :class:`DicomSeriesImageInfo` entries which contains the specified
+             SeriesInstanceUID or None
+        """
+        if not self.image_info:
+            return None
+
+        selected = [info for info in self.image_info if info.series_instance_uid == series_instance_uid]
+
+        if len(selected) > 1:
+            raise ValueError(f"Multiple image infos detected with the same SeriesInstanceUID ({series_instance_uid})!")
+
+        if not selected:
+            return None
+
+        return selected[0]
+
+    def _get_registration_info(
+        self,
+        image_info: DicomSeriesImageInfo,
+    ) -> Optional[DicomSeriesRegistrationInfo]:
+        """Get the :class:`DicomSeriesRegistrationInfo` instance which belongs to the specified
+        :class:`DicomSeriesImageInfo`, if available. If no :class:`DicomSeriesRegistrationInfo` is available
+        :class:`None` is returned.
+
+        Args:
+            image_info (DicomSeriesImageInfo): The :class:`DicomSeriesImageInfo` for which the
+             :class:`DicomSeriesRegistrationInfo` is requested.
+
+        Returns:
+            Optional[DicomSeriesRegistrationInfo]: The :class:`DicomSeriesRegistrationInfo` which belongs to the
+             specified :class:`DicomSeriesImageInfo` or :class:`None`.
+        """
+        if not self.reg_info:
+            return None
+
+        selected = []
+        for reg_info in self.reg_info:
+            reg_info.update() if not reg_info.is_updated() else None
+
+            if reg_info.referenced_series_instance_uid_transform == image_info.series_instance_uid:
+                selected.append(reg_info)
+
+        if len(selected) > 1:
+            raise ValueError(
+                f"Multiple registration infos detected with the same referenced "
+                f"SeriesInstanceUID ({image_info.series_instance_uid})!"
+            )
+
+        if not selected:
+            return None
+
+        return selected[0]
+
+    @staticmethod
+    def _transform_image(image: sitk.Image, transform: sitk.Transform, is_intensity: bool) -> sitk.Image:
+        """Transform an :class:`sitk.Image` according to the provided :class:`sitk.Transform`.
+
+        Args:
+            image (sitk.Image): The image to transform.
+            transform (sitk.Transform): The transform to be applied to the image.
+            is_intensity (bool): If True the image will be resampled using a B-Spline interpolation function,
+             otherwise a nearest neighbour interpolation function will be used.
+
+        Returns:
+            sitk.Image: The transformed image.
+        """
+        # select the appropriate interpolation function
+        if is_intensity:
+            interpolator = sitk.sitkBSpline
+        else:
+            interpolator = sitk.sitkNearestNeighbor
+
+        image_np = sitk.GetArrayFromImage(image)
+        default_pixel_value = np.min(image_np).astype(float)
+
+        # compute the new origin
+        new_origin = transform.GetInverse().TransformPoint(image.GetOrigin())
+
+        # compute the new direction
+        new_direction_0 = transform.TransformVector(image.GetDirection()[:3], image.GetOrigin())
+        new_direction_1 = transform.TransformVector(image.GetDirection()[3:6], image.GetOrigin())
+        new_direction_2 = transform.TransformVector(image.GetDirection()[6:], image.GetOrigin())
+        new_direction = new_direction_0 + new_direction_1 + new_direction_2
+
+        new_direction_matrix = np.array(new_direction).reshape(3, 3)
+        original_direction_matrix = np.array(image.GetDirection()).reshape(3, 3)
+        new_direction_corr = np.dot(
+            np.dot(new_direction_matrix, original_direction_matrix).transpose(), original_direction_matrix
+        ).transpose()
+
+        # resample the image
+        resampled_image = sitk.Resample(
+            image,
+            image.GetSize(),
+            transform=transform,
+            interpolator=interpolator,
+            outputOrigin=new_origin,
+            outputSpacing=image.GetSpacing(),
+            outputDirection=tuple(new_direction_corr.flatten()),
+            defaultPixelValue=default_pixel_value,
+            outputPixelType=image.GetPixelIDValue(),
+        )
+
+        return resampled_image
+
+    def convert(self) -> Tuple[IntensityImage, ...]:
+        """Convert the provided :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries to one or multiple
+        :class:`~pyradise.data.image.IntensityImage` instances.
+
+        Returns:
+            Tuple[IntensityImage, ...]: The converted :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        images = []
+
+        for info in self.image_info:
+            # read the image
+            reader = sitk.ImageSeriesReader()
+            reader.SetFileNames(info.path)
+            image = reader.Execute()
+
+            # get the registration info if available
+            reg_info = self._get_registration_info(info)
+
+            if not info.is_updated():
+                info.update()
+
+            # if no registration info is available, the image is added as is
+            if reg_info is None:
+                image_ = IntensityImage(image, info.modality)
+                image_.add_data({"SeriesInstanceUID": info.series_instance_uid})
+                images.append(image_)
+
+            # else the image is transformed
+            else:
+                ref_series_instance_uid = reg_info.referenced_series_instance_uid_identity
+                ref_image_info = self._get_image_info_by_series_instance_uid(ref_series_instance_uid)
+
+                if ref_image_info is None:
+                    raise ValueError(
+                        f"The reference image with SeriesInstanceUID {ref_series_instance_uid} "
+                        f"is missing for the registration!"
+                    )
+
+                image = self._transform_image(image, reg_info.transform, is_intensity=True)
+                image_ = IntensityImage(image, info.modality)
+                image_.add_data({"SeriesInstanceUID": info.series_instance_uid})
+                images.append(image_)
+
+        return tuple(images)
+
+
+class DicomRTSSSeriesConverter(Converter):
+    """A :class:`Converter` class for converting a DICOM-RTSS (i.e.
+    :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo`) to one or multiple
+    :class:`~pyradise.data.image.SegmentationImage` instances.
+
+    Notes:
+        The user may provide all available :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` and
+        :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries to the corresponding ``image_infos``
+        and ``registration_infos``, respectively. In this case the :class:`DicomRTSSSeriesConverter` will sort out
+        unused entries.
+
+    Args:
+        rtss_infos (Union[DicomSeriesRTSSInfo, Tuple[DicomSeriesRTSSInfo, ...]]): The
+         :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` instance holding the information to be converted.
+        image_infos (Tuple[DicomSeriesImageInfo, ...]): The :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo`
+         entries which are referenced in the :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` instance.
+        registration_infos (Optional[Tuple[DicomSeriesRegistrationInfo, ...]]): The
+         :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries referencing the DICOM image or
+         DICOM-RTSS.
+        fill_hole_search_distance (int): The search distance for the hole filling algorithm. If the search distance is
+         set to zero the hole filling algorithm is omitted. The search distance must be an odd number larger than 1
+         (default: 0).
+    """
+
+    def __init__(
+        self,
+        rtss_infos: Union[DicomSeriesRTSSInfo, Tuple[DicomSeriesRTSSInfo, ...]],
+        image_infos: Tuple[DicomSeriesImageInfo, ...],
+        registration_infos: Optional[Tuple[DicomSeriesRegistrationInfo, ...]],
+        fill_hole_search_distance: int = 0,
+    ) -> None:
+        super().__init__()
+
+        if isinstance(rtss_infos, DicomSeriesRTSSInfo):
+            self.rtss_infos = (rtss_infos,)
+        else:
+            self.rtss_infos = rtss_infos
+
+        self.image_infos = image_infos
+        self.reg_infos = registration_infos
+
+        # store the fill hole search distance
+        if fill_hole_search_distance == 0:
+            self.fill_hole_distance = 0
+        elif fill_hole_search_distance % 2 == 0:
+            raise ValueError("The fill hole search distance must be an odd number.")
+        elif fill_hole_search_distance == 1:
+            raise ValueError("The fill hole search distance must be larger than 1.")
+        else:
+            self.fill_hole_distance = fill_hole_search_distance
+
+    def _get_referenced_image_info(self, rtss_info: DicomSeriesRTSSInfo) -> Optional[DicomSeriesImageInfo]:
+        """Get the :class:`DicomSeriesImageInfo` which is referenced by the provided :class:`DicomSeriesRTSSInfo`.
+
+        Args:
+            rtss_info (DicomSeriesRTSSInfo): The :class:`DicomSeriesRTSSInfo` containing the reference.
+
+        Returns:
+            Optional[DicomSeriesImageInfo]: The referenced :class:`DicomSeriesImageInfo` or :class:`None` if no
+             reference is available.
+
+        """
+        if not self.image_infos:
+            return None
+
+        selected = [info for info in self.image_infos if info.series_instance_uid == rtss_info.referenced_instance_uid]
+
+        if len(selected) > 1:
+            raise ValueError(
+                f"Multiple image infos detected with the same referenced "
+                f"SeriesInstanceUID ({rtss_info.referenced_instance_uid})!"
+            )
+
+        if not selected:
+            raise ValueError(
+                f"The reference image with the SeriesInstanceUID "
+                f"{rtss_info.referenced_instance_uid} for the RTSS conversion is missing!"
+            )
+
+        return selected[0]
+
+    def _get_referenced_registration_info(
+        self,
+        rtss_info: DicomSeriesRTSSInfo,
+    ) -> Optional[DicomSeriesRegistrationInfo]:
+        """Get the :class:`DicomSeriesRegistrationInfo` which is referenced in the :class:`DicomSeriesRTSSInfo`.
+
+        Args:
+            rtss_info (DicomSeriesRTSSInfo): The :class:`DicomSeriesRTSSInfo` for which the referenced
+             :class:`DicomSeriesRegistrationInfo` should be retrieved.
+
+        Returns:
+            Optional[DicomSeriesRegistrationInfo]: The :class:`DicomSeriesRegistrationInfo` instance referenced in the
+             RTSS or None.
+        """
+
+        if not self.reg_infos:
+            return None
+
+        selected = []
+
+        for registration_info in self.reg_infos:
+            if registration_info.referenced_series_instance_uid_transform == rtss_info.referenced_instance_uid:
+                selected.append(registration_info)
+
+        if not selected:
+            return None
+
+        if len(selected) > 1:
+            raise NotImplementedError(
+                "The number of referenced registrations is larger than one! "
+                "The sequential application of registrations is not supported yet!"
+            )
+
+        return selected[0]
+
+    def convert(self) -> Tuple[SegmentationImage, ...]:
+        """Convert the :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` instances into one or multiple
+        :class:`~pyradise.data.image.SegmentationImage` instances.
+
+        Returns:
+            Tuple[SegmentationImage, ...]: The converted :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+        images = []
+
+        for rtss_info in self.rtss_infos:
+            ref_image_info = self._get_referenced_image_info(rtss_info)
+            ref_reg_info = self._get_referenced_registration_info(rtss_info)
+
+            if ref_reg_info:
+                ref_reg_info.update() if not ref_reg_info.is_updated() else None
+                reg_dataset = ref_reg_info.dataset
+            else:
+                reg_dataset = None
+
+            dataset = load_dataset(rtss_info.get_path()[0])
+            structures = RTSSToSegmentConverter(
+                dataset, ref_image_info.path, reg_dataset, self.fill_hole_distance
+            ).convert()
+
+            for roi_name, segmentation_image in structures.items():
+                segmentation = SegmentationImage(segmentation_image, Organ(roi_name), rtss_info.get_annotator())
+                segmentation.add_data(
+                    {"SeriesInstanceUID": rtss_info.referenced_instance_uid, "ROINames": rtss_info.roi_names}
+                )
+                images.append(segmentation)
+
+        return tuple(images)
+
+
+class SubjectToRTSSConverter(Converter):
+    """A :class:`Converter` class for converting the :class:`~pyradise.data.image.SegmentationImage` instances of a
+    :class:`~pyradise.data.subject.Subject` instance to a :class:`~pydicom.dataset.Dataset` instance.
+
+    Note:
+        This class is typically used at the end of a processing pipeline to output a DICOM-RTSS file containing the
+        segmentation results of the pipeline.
+
+    Note:
+        This class can take a :class:`RTSSMetaData` instance as input to specify certain DICOM attributes of the
+        output DICOM-RTSS. If no instance is provided, the default values will be used.
+
+    Important:
+        The ``config`` parameter defines the type of conversion algorithm. If specific conversion parameters are
+        required for a certain :class:`~pyradise.data.image.SegmentationImage` instance, they must be provided in the
+        appropriate :class:`RTSSConverterConfiguration` (i.e., :class:`RTSSConverter2DConfiguration` or
+        :class:`RTSSConverter3DConfiguration`). Furthermore, the ``image_identifier`` parameter must be set to the
+        organ name of the :class:`~pyradise.data.image.SegmentationImage` instance. Otherwise, segmentation masks with
+        specific parameters can not be identified.
+
+    Args:
+        subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be converted to a DICOM-RTSS
+         :class:`~pydicom.dataset.Dataset` instance.
+        infos (Tuple[SeriesInfo, ...]): The :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries provided for
+         the conversion (only :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` will be considered).
+        reference_modality (Union[Modality, str]): The reference :class:`~pyradise.data.modality.Modality` of the
+         images to be used for the conversion to DICOM-RTSS.
+        config (Union[RTSSConverter2DConfiguration, RTSSConverter3DConfiguration]): The configuration for the conversion
+         procedure. The type of conversion configuration determines also the conversion algorithm (2D or 3D) that is
+         used.
+        meta_data (RTSSMetaData): The configuration to specify certain DICOM attributes (default: RTSSMetaData()).
+        colors (Optional[Tuple[Tuple[int, int, int], ...]]): The colors to be used for the segmentation masks. If None,
+         the default colors will be used (default: None).
+    """
+
+    def __init__(
+        self,
+        subject: Subject,
+        infos: Tuple[SeriesInfo, ...],
+        reference_modality: Union[Modality, str],
+        config: Union[RTSSConverter2DConfiguration, RTSSConverter3DConfiguration],
+        meta_data: RTSSMetaData = RTSSMetaData(),
+        colors: Optional[Tuple[Tuple[int, int, int], ...]] = None,
+    ) -> None:
+        super().__init__()
+
+        assert subject.segmentation_images, "The subject must contain segmentation images!"
+        self.subject = subject
+
+        assert infos, "There must be infos provided for the conversion!"
+
+        reference_modality_: Modality = str_to_modality(reference_modality)
+        image_infos = [
+            entry
+            for entry in infos
+            if isinstance(entry, DicomSeriesImageInfo) and entry.modality == reference_modality_
+        ]
+
+        assert image_infos, "There must be image infos in the provided infos!"
+
+        assert len(image_infos) == 1, "There are multiple image infos fitting the reference modality!"
+        self.image_info = image_infos[0]
+        self.ref_modality = reference_modality_
+
+        if not isinstance(config, (RTSSConverter2DConfiguration, RTSSConverter3DConfiguration)):
+            raise ValueError(f"The config type {type(config)} is not supported!")
+
+        self.config: Union[RTSSConverter2DConfiguration, RTSSConverter3DConfiguration] = config
+        self.meta_data = meta_data
+
+        self._validate_colors(colors)
+        self.colors = colors
+
+    @staticmethod
+    def _validate_colors(colors: Optional[Tuple[Tuple[int, int, int], ...]]) -> None:
+        """Validate the provided colors.
+
+        Args:
+            colors (Optional[Tuple[Tuple[int, int, int], ...]]): The colors to be validated.
+
+        Raises:
+            ValueError: If the provided colors are not valid.
+
+        Returns:
+            None: If the provided colors are valid.
+        """
+        if not colors:
+            return
+
+        for color in colors:
+            if len(color) != 3:
+                raise ValueError(f"The color {color} is not valid!")
+
+            for value in color:
+                if not isinstance(value, int) or value < 0 or value > 255:
+                    raise ValueError(f"The color {color} is not valid!")
+
+    def convert(self) -> Dataset:
+        """Convert a :class:`~pyradise.data.subject.Subject` instance to a DICOM-RTSS :class:`~pydicom.dataset.Dataset`
+        instance.
+
+        Returns:
+            Dataset: The DICOM-RTSS :class:`~pydicom.dataset.Dataset` instance generated from the provided
+            :class:`~pyradise.data.subject.Subject` instance.
+        """
+        # get the image data and the label names
+        sitk_images = []
+        label_names = []
+        for image in self.subject.segmentation_images:
+            sitk_image = image.get_image_data()
+            if "int" not in sitk_image.GetPixelIDTypeAsString():
+                try:
+                    sitk_image = sitk.Cast(sitk_image, sitk.sitkUInt8)
+                except Exception:  # noqa
+                    warnings.warn(
+                        f"Could not cast SegmentationImage for organ {image.get_organ(True)} to an integer "
+                        "type. The SegmentationImage will be skipped!"
+                    )
+                    continue
+
+            sitk_images.append(sitk_image)
+            label_names.append(image.get_organ(as_str=True))
+
+        # load the image datasets
+        image_datasets = load_datasets(self.image_info.path)
+
+        # convert the images to a rtss
+        if isinstance(self.config, RTSSConverter2DConfiguration):
+            rtss = SegmentToRTSSConverter2D(
+                label_images=tuple(sitk_images),
+                ref_image_datasets=image_datasets,
+                roi_names=tuple(label_names),
+                colors=self.colors,
+                meta_data=self.meta_data,
+                config=self.config,
+            ).convert()
+
+        elif isinstance(self.config, RTSSConverter3DConfiguration):
+            rtss = SegmentToRTSSConverter3D(
+                label_images=tuple(sitk_images),
+                ref_image_datasets=image_datasets,
+                roi_names=tuple(label_names),
+                colors=self.colors,
+                meta_data=self.meta_data,
+                config=self.config,
+            ).convert()
+
+        else:
+            raise ValueError(f"Invalid configuration type: {type(self.config)}!")
+
+        return rtss
+
+
+# def show_polydata(polydata: vtk_dm.vtkPolyData) -> None:
+#     import vtkmodules.vtkInteractionStyle
+#     import vtkmodules.vtkRenderingOpenGL2
+#     from vtkmodules.vtkCommonColor import vtkNamedColors
+#     from vtkmodules.vtkRenderingCore import (
+#         vtkActor,
+#         vtkPolyDataMapper,
+#         vtkRenderWindow,
+#         vtkRenderWindowInteractor,
+#         vtkRenderer
+#     )
+#
+#     # Visualize
+#     colors = vtkNamedColors()
+#
+#     mapper = vtkPolyDataMapper()
+#     mapper.SetInputData(polydata)
+#     actor = vtkActor()
+#     actor.SetMapper(mapper)
+#     actor.GetProperty().SetLineWidth(4)
+#     actor.GetProperty().SetColor(colors.GetColor3d("Peacock"))
+#
+#     renderer = vtkRenderer()
+#     renderWindow = vtkRenderWindow()
+#     renderWindow.SetWindowName("Line")
+#     renderWindow.AddRenderer(renderer)
+#     renderWindowInteractor = vtkRenderWindowInteractor()
+#     renderWindowInteractor.SetRenderWindow(renderWindow)
+#
+#     renderer.SetBackground(*colors.GetColor3d("Silver"))
+#     renderer.AddActor(actor)
+#
+#     renderWindow.Render()
+#     renderWindowInteractor.Start()
```

### Comparing `pyradise-0.2.2/pyradise/fileio/extraction.py` & `pyradise-0.2.3/pyradise/fileio/extraction.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,498 +1,498 @@
-import os
-from abc import ABC, abstractmethod
-from typing import Any, Dict, Optional, Tuple, Union
-
-from pydicom.tag import Tag
-
-from pyradise.data import Annotator, Modality, Organ
-from pyradise.utils import is_dicom_file, load_dataset_tag
-
-__all__ = [
-    "Extractor",
-    "ModalityExtractor",
-    "SimpleModalityExtractor",
-    "OrganExtractor",
-    "SimpleOrganExtractor",
-    "AnnotatorExtractor",
-    "SimpleAnnotatorExtractor",
-]
-
-
-class Extractor(ABC):
-    """An abstract base class for all extractors. An extractor extracts information about a file from its file path,
-    the files content or from any other source of data in order to provide identification information
-    (e.g. the imaging modality of a certain NIFTI file). Extractors can be used in combination with a
-    :class:`~pyradise.fileio.crawling.Crawler` to extract the :class:`~pyradise.data.modality.Modality`,
-    :class:`~pyradise.data.organ.Organ` or :class:`~pyradise.data.annotator.Annotator` instances for
-    :class:`~pyradise.data.subject.Subject` construction.
-
-    Typically, the user needs to implement the concrete extractor classes specific for the current task. This renders
-    flexibility and allows for a wide range of use cases. However, the user can also use the provided implementations
-    and examples to get started quickly.
-
-    """
-
-    @abstractmethod
-    def extract(self, path: str) -> Any:
-        """Extract information about the file at the specified path.
-
-        Args:
-            path (str): The path to the file for which information needs to be extracted.
-
-        Returns:
-            Any: The extracted information.
-        """
-        pass
-
-
-class ModalityExtractor(Extractor):
-    """A prototype class to extract the :class:`~pyradise.data.modality.Modality` from DICOM files and discrete image
-    file paths. It must be implemented by the user and is intended to be used with the
-    :class:`~pyradise.fileio.crawling.Crawler` types for DICOM and discrete image files. Thus, both abstract methods
-    (i.e. :meth:`extract_from_dicom` and :meth:`extract_from_path`) need to be implemented. In case of working
-    exclusively on DICOM or discrete image files, one extraction method may contain just a ``return None``.
-
-    Important:
-        If the file path does not specify an intensity image the extractor must return :data:`None`.
-
-    Warnings:
-        If :data:`return_default` is set to :data:`True` the :class:`ModalityExtractor` will return an enumerated
-        default :class:`~pyradise.data.modality.Modality` for each file for which no modality could be extracted.
-        This will have the effect that no error will be raised during loading. However, this functionality is intended
-        to be used exlusively for experimenting and debugging purposes such that the user can load data without
-        implementing a complete extractor. It's not recommended to use this feature for production purposes.
-        Subsequent errors may arise.
-
-    Notes:
-        If using the :class:`ModalityExtractor` in combination with a :class:`~pyradise.fileio.crawling.Crawler` all
-        paths to the discrete image files are provided sequentially to extract the
-        :class:`~pyradise.data.modality.Modality`. In case of working with DICOM data the
-        :class:`~pyradise.fileio.crawling.Crawler` will provide just one arbitrary file path to the
-        :class:`ModalityExtractor`.
-
-    Example:
-
-        Example of a :class:`ModalityExtractor` implementation to identify detailed modalities:
-
-        >>> from typing import (Any, Dict, Optional)
-        >>>
-        >>> from pyradise.fileio import (ModalityExtractor, Tag)
-        >>> from pyradise.data import Modality
-        >>>
-        >>>
-        >>> class ExampleModalityExtractor(ModalityExtractor):
-        >>>
-        >>>     @staticmethod
-        >>>     def _get_mr_modality(ds_dict: Dict[str, Any]) -> Optional[Modality]:
-        >>>         # check for different variants of attributes to get the sequence
-        >>>         # identification
-        >>>         scanning_sq = ds_dict.get('Scanning Sequence', {}).get('value', [])
-        >>>         scanning_sq = [scanning_sq] if isinstance(scanning_sq, str) else scanning_sq
-        >>>         contrast = ds_dict.get('Contrast/Bolus Agent', {}).get('value', '')
-        >>>
-        >>>         if all(val in scanning_sq for val in ('SE', 'IR')):
-        >>>             return Modality('FLAIR')
-        >>>         elif all(val in scanning_sq for val in ('GR', 'IR')) and len(contrast) > 0:
-        >>>             return Modality('T1c')
-        >>>         elif all(val in scanning_sq for val in ('GR', 'IR')) and len(contrast) == 0:
-        >>>             return Modality('T1w')
-        >>>         elif all(val == 'SE' for val in scanning_sq):
-        >>>             return Modality('T2w')
-        >>>         else:
-        >>>             return None
-        >>>
-        >>>     def extract_from_dicom(self, path: str) -> Optional[Modality]:
-        >>>         # extract the necessary attributes from the file
-        >>>         tags = (Tag(0x0008, 0x0060),  # Modality
-        >>>                 Tag(0x0018, 0x0010),  # ContrastBolusAgent
-        >>>                 Tag(0x0018, 0x0020))  # ScanningSequence
-        >>>         dataset_dict = self._load_dicom_attributes(tags, path)
-        >>>
-        >>>         # identify the modality
-        >>>         extracted_modality = dataset_dict.get('Modality', {}).get('value', None)
-        >>>         if extracted_modality == 'CT':
-        >>>             return Modality('CT')
-        >>>         elif extracted_modality == 'MR':
-        >>>             return self._get_mr_modality(dataset_dict)
-        >>>         else:
-        >>>             return None
-        >>>
-        >>>     def extract_from_path(self, path: str) -> Optional[Modality]:
-        >>>         # extract the necessary attributes from the file name
-        >>>         file_name = os.path.basename(path)
-        >>>         if 'T1c' in file_name:
-        >>>             return Modality('T1c')
-        >>>         elif 'T1w' in file_name:
-        >>>             return Modality('T1w')
-        >>>         elif 'T2w' in file_name:
-        >>>             return Modality('T2w')
-        >>>         elif 'FLAIR' in file_name:
-        >>>             return Modality('FLAIR')
-        >>>         elif 'CT' in file_name:
-        >>>             return Modality('CT')
-        >>>         else:
-        >>>             return None
-
-    Args:
-        return_default (bool): Indicates if an enumerated default :class:`~pyradise.data.modality.Modality` should be
-         returned if the extraction was not successful. Use this option exclusively for experimentation and debugging
-         because it can cause severe damage (default: False).
-    """
-
-    modality_default_idx = 0
-    default_modality_name = "UnknownModality"
-
-    def __init__(self, return_default: bool = False) -> None:
-        super().__init__()
-
-        self.return_default = return_default
-
-    @staticmethod
-    def _load_dicom_attributes(tags: Union[Tuple[Tuple[int, int], ...], Tuple[Tag, ...]], path: str) -> Dict[str, Any]:
-        """Load the DICOM attributes for the specified tags.
-
-        Args:
-            tags (Union[Tuple[Tuple[int, int], ...], Tuple[Tag, ...]]): The DICOM tags to extract the attributes for.
-            path (str): The path to the DICOM file to extract the attributes from.
-
-        Returns:
-            Dict[str, Any]: The loaded DICOM attributes.
-        """
-        tags_ = [Tag(tag) for tag in tags]
-        dataset = load_dataset_tag(path, tags_)
-
-        data = {}
-        for tag in tags_:
-            item = dataset.get(tag, None)
-            if item is not None:
-                data[item.name] = {"name": item.name, "value": item.value, "vr": item.VR}
-
-        return data
-
-    def _get_next_default_modality_name(self) -> str:
-        """Get the next enumerated modality name for unrecognized modalities.
-
-        Returns:
-            str: The next enumerated modality name.
-        """
-        name = self.default_modality_name + str(self.modality_default_idx)
-        self.modality_default_idx += 1
-        return name
-
-    def is_enumerated_default_modality(self, modality: Optional[Union[Modality, str]]) -> bool:
-        """Check if the specified modality is an enumerated default modality.
-
-        Args:
-            modality (Optional[Union[Modality, str]]): The modality to check.
-
-        Returns:
-            bool: True if the modality is an enumerated default modality, False otherwise.
-        """
-        if modality is None:
-            return False
-
-        if isinstance(modality, Modality):
-            modality = modality.name
-        return self.default_modality_name in modality
-
-    @abstractmethod
-    def extract_from_dicom(self, path: str) -> Optional[Modality]:
-        """Extract the :class:`~pyradise.data.modality.Modality` from the DICOM file at the specified path.
-        If the modality can not be detected :data:`None` must be returned.
-
-        Notes:
-            For your implementation you can load the DICOM file or specific DICOM attributes using the
-            :meth:`load_dataset` or :meth:`load_dataset_tag` functions from the :mod:`pyradise.utils` module.
-            For a detailed description of the DICOM attributes we refer to the `DICOM Standard
-            <https://www.dicomstandard.org/>`_ and the `DICOM Standard Browser <https://dicom.innolitics.com/>`_.
-
-        Args:
-            path (str): The path to the DICOM file to extract the :class:`~pyradise.data.modality.Modality` from.
-
-        Returns:
-            Optional[Modality]: The extracted :class:`~pyradise.data.modality.Modality` or :data:`None`.
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def extract_from_path(self, path: str) -> Optional[Modality]:
-        """Extract the :class:`~pyradise.data.modality.Modality` from the file path to a discrete image file or
-        from another other data source. If the modality can not be detected :data:`None` must be returned.
-
-        Args:
-            path (str): The path to the file to extract the :class:`~pyradise.data.modality.Modality` for.
-
-        Returns:
-            Optional[Modality]: The extracted :class:`~pyradise.data.modality.Modality` or :data:`None`.
-        """
-        raise NotImplementedError()
-
-    def extract(self, path: str) -> Optional[Modality]:
-        """Extract the :class:`~pyradise.data.modality.Modality` for either a DICOM or a discrete medical image file.
-
-        Args:
-            path (str): The path to the file to extract the :class:`~pyradise.data.modality.Modality` for.
-
-        Returns:
-            Optional[Modality]: The extracted :class:`~pyradise.data.modality.Modality` or :data:`None`.
-        """
-        if is_dicom_file(path):
-            modality = self.extract_from_dicom(path)
-        else:
-            modality = self.extract_from_path(path)
-
-        if self.return_default and modality is None:
-            return Modality(self._get_next_default_modality_name())
-
-        return modality
-
-
-class SimpleModalityExtractor(ModalityExtractor):
-    """A simple :class:`ModalityExtractor` implementation that uses the 'Modality' attribute in the provided DICOM
-    image or searches for a provided set of modality names (``modalities``) in the file name in case of a
-    discrete image file to generate a :class:`~pyradise.data.modality.Modality` with the same name. If no match is
-    found :data:`None` is returned.
-
-    Args:
-        modalities (Tuple[str, ...]): The possible modality names for the intensity files which will also
-         be used to name the :class:`~pyradise.data.modality.Modality`.
-        return_default (bool): Indicates if an enumerated default :class:`~pyradise.data.modality.Modality` should be
-         returned if the extraction was not successfully. Use this option exclusively for experimentation and debugging
-         because it can cause severe damage (default: False).
-
-    """
-
-    def __init__(
-        self,
-        modalities: Tuple[str, ...],
-        return_default: bool = False,
-    ) -> None:
-        super().__init__(return_default)
-
-        self.modalities = modalities
-
-    def extract_from_path(self, path: str) -> Optional[Modality]:
-        """Extract the :class:`~pyradise.data.modality.Modality` from the file name using the provided
-        ``modalities``. If there is no match :data:`None` is returned.
-
-        Args:
-            path (str): The path to the file to extract the :class:`~pyradise.data.modality.Modality` for.
-
-        Returns:
-            Optional[Modality]: The extracted :class:`~pyradise.data.modality.Modality` or :data:`None`.
-        """
-        file_name = os.path.basename(path)
-
-        for modality in self.modalities:
-            if modality in file_name:
-                return Modality(modality)
-
-        return None
-
-    def extract_from_dicom(self, path: str) -> Optional[Modality]:
-        """Extract the DICOM attribute 'Modality' from the provided DICOM file. If no or an invalid 'Modality'
-        attribute is found, :data:`None` is returned.
-
-        Notes:
-            This method exclusively extracts the following top-level modalities: CT, MR, PT, and US.
-            For all other values of the DICOM 'Modality' attribute :data:`None` is returned.
-
-        Args:
-            path (str): The path to the DICOM file to extract the :class:`~pyradise.data.modality.Modality` from.
-
-        Returns:
-            Optional[Modality]: The extracted :class:`~pyradise.data.modality.Modality` or :data:`None`.
-        """
-        # extract the Modality attribute
-        tags = (Tag(0x0008, 0x0060),)  # Modality
-        dataset_dict = self._load_dicom_attributes(tags, path)
-
-        # get the general modality
-        extracted_modality = dataset_dict.get("Modality", {}).get("value", None)
-        if extracted_modality in ("CT", "MR", "PT", "US"):
-            return Modality(extracted_modality)
-        else:
-            return None
-
-
-class OrganExtractor(Extractor):
-    """A prototype class to extract an :class:`~pyradise.data.organ.Organ` from a discrete image file path. This class
-    must be implemented by the user and is intended to be used with a :class:`~pyradise.fileio.crawling.Crawler` for
-    discrete image formats.
-
-    Important:
-        If the file path does not specify a segmentation image the extractor must return :data:`None`.
-
-    Example:
-
-        Example of an :class:`OrganExtractor` implementation which takes search strings and associated organ names to
-        extract an :class:`Organ` from a file path:
-
-        >>> from typing import (Any, Dict, Optional)
-        >>>
-        >>> from pyradise.fileio import OrganExtractor
-        >>> from pyradise.data import Organ
-        >>>
-        >>>
-        >>> class ExampleOrganExtractor(OrganExtractor):
-        >>>
-        >>>     def __init__(self,
-        >>>                  search_strings: Dict[str, str],
-        >>>                  names: Tuple[str, ...]
-        >>>                  ) -> None:
-        >>>         super().__init__()
-        >>>
-        >>>         assert len(search_strings) == len(names), /
-        >>>         f'Number of search strings ({len(search_strings)}) must match the ' \
-        >>>         f'number of organ names ({len(names)})!'
-        >>>
-        >>>         self.search_strings = search_strings
-        >>>         self.names = names
-        >>>
-        >>>     def extract(self, path: str) -> Optional[Organ]:
-        >>>         file_name = os.path.basename(path)
-        >>>
-        >>>         for search_string, name in zip(self.search_strings, self.names):
-        >>>             if search_string in file_name:
-        >>>                 return Organ(name)
-        >>>
-        >>>         return None
-    """
-
-    def extract(self, path: str) -> Optional[Organ]:
-        """Extract the :class:`~pyradise.data.organ.Organ` from the file path.
-
-        Args:
-            path (str): The path to the file to extract the :class:`~pyradise.data.organ.Organ` for.
-
-        Returns:
-            Optional[Organ]: The extracted :class:`~pyradise.data.organ.Organ` or :data:`None`.
-        """
-        raise NotImplementedError("The extract method needs to be adopted for the intended use case!")
-
-
-class SimpleOrganExtractor(OrganExtractor):
-    """A simple :class:`OrganExtractor` implementation that searches for a provided set of organ names
-    (``organs``) in the file name and generates an :class:`~pyradise.data.organ.Organ` with the same name. If no
-    match is found :data:`None` is returned.
-
-    Args:
-        organs (Tuple[str, ...]): The possible organ names which will also be used to name the output
-         :class:`~pyradise.data.organ.Organ`.
-
-    """
-
-    def __init__(self, organs: Tuple[str, ...]) -> None:
-        super().__init__()
-        self.organs = organs
-
-    def extract(self, path: str) -> Optional[Organ]:
-        """Extract the :class:`~pyradise.data.organ.Organ` from the file name using the provided ``organs``. If
-        no :class:`~pyradise.data.organ.Organ` can be extracted or the file does not contain a segmentation image
-        :data:`None` is returned.
-
-        Args:
-            path (str): The path to the file to extract the :class:`~pyradise.data.organ.Organ` for.
-
-        Returns:
-            Optional[Organ]: The extracted :class:`~pyradise.data.organ.Organ` or :data:`None`.
-        """
-        file_name = os.path.basename(path)
-
-        for organ in reversed(self.organs):
-            if organ in file_name:
-                return Organ(organ)
-
-        return None
-
-
-class AnnotatorExtractor(Extractor):
-    """A prototype class to extract an :class:`~pyradise.data.annotator.Annotator` from a discrete image file path.
-    This class must be implemented by the user and is intended to be used with a
-    :class:`~pyradise.fileio.crawling.Crawler` for discrete image formats.
-
-    Important:
-        If the file path does not specify a segmentation image the extractor must return :data:`None`.
-
-    Example:
-
-        Example of an :class:`AnnotatorExtractor` implementation which takes search strings and associated annotator
-        names to extract a :class:`~pyradise.data.annotator.Annotator` from a file path:
-
-        >>> from typing import (Any, Dict, Optional)
-        >>>
-        >>> from pyradise.fileio import AnnotatorExtractor
-        >>> from pyradise.data import Annotator
-        >>>
-        >>>
-        >>> class ExampleAnnotatorExtractor(AnnotatorExtractor):
-        >>>
-        >>>     def __init__(self,
-        >>>                  search_strings: Dict[str, str],
-        >>>                  names: Tuple[str, ...]
-        >>>                  ) -> None:
-        >>>         super().__init__()
-        >>>
-        >>>         assert len(search_strings) == len(names), /
-        >>>         f'Number of search strings ({len(search_strings)}) must match the' \
-        >>>         f'number of annotator names ({len(names)})!'
-        >>>
-        >>>         self.search_strings = search_strings
-        >>>         self.names = names
-        >>>
-        >>>     def extract(self, path: str) -> Optional[Annotator]:
-        >>>         file_name = os.path.basename(path)
-        >>>
-        >>>         for search_string, name in zip(self.search_strings, self.names):
-        >>>             if search_string in file_name:
-        >>>                 return Annotator(name)
-        >>>
-        >>>         return None
-    """
-
-    def extract(self, path: str) -> Optional[Annotator]:
-        """Extract the :class:`~pyradise.data.annotator.Annotator` from the file path.
-
-        Args:
-            path (str): The path to the file to extract the :class:`~pyradise.data.annotator.Annotator` for.
-
-        Returns:
-            Optional[Annotator]: The extracted :class:`~pyradise.data.annotator.Annotator` or :data:`None`.
-        """
-        raise NotImplementedError("The extract method needs to be adopted for the intended use case!")
-
-
-class SimpleAnnotatorExtractor(AnnotatorExtractor):
-    """A simple :class:`AnnotatorExtractor` implementation that searches for a provided set of annotator names
-    (``annotators``) in the file name and generates a :class:`~pyradise.data.annotator.Annotator` with the same name.
-    If no match is found :data:`None` is returned.
-
-    Args:
-        annotators (Tuple[str, ...]): The possible annotator names which will also be used to name the output
-         :class:`Annotator`.
-
-    """
-
-    def __init__(self, annotators: Tuple[str, ...]) -> None:
-        super().__init__()
-
-        self.annotators = annotators
-
-    def extract(self, path: str) -> Optional[Annotator]:
-        """Extract the :class:`~pyradise.data.annotator.Annotator` from the file name using the provided ``annotators``.
-        If no :class:`~pyradise.data.annotator.Annotator` can be extracted or the file does not contain a segmentation
-        image :data:`None` is returned.
-
-        Args:
-            path (str): The path to the file to extract the :class:`~pyradise.data.annotator.Annotator` for.
-
-        Returns:
-            Optional[Annotator]: The extracted :class:`~pyradise.data.annotator.Annotator` or :data:`None`.
-        """
-        file_name = os.path.basename(path)
-
-        for annotator in self.annotators:
-            if annotator in file_name:
-                return Annotator(annotator)
-
-        return None
+import os
+from abc import ABC, abstractmethod
+from typing import Any, Dict, Optional, Tuple, Union
+
+from pydicom.tag import Tag
+
+from pyradise.data import Annotator, Modality, Organ
+from pyradise.utils import is_dicom_file, load_dataset_tag
+
+__all__ = [
+    "Extractor",
+    "ModalityExtractor",
+    "SimpleModalityExtractor",
+    "OrganExtractor",
+    "SimpleOrganExtractor",
+    "AnnotatorExtractor",
+    "SimpleAnnotatorExtractor",
+]
+
+
+class Extractor(ABC):
+    """An abstract base class for all extractors. An extractor extracts information about a file from its file path,
+    the files content or from any other source of data in order to provide identification information
+    (e.g. the imaging modality of a certain NIFTI file). Extractors can be used in combination with a
+    :class:`~pyradise.fileio.crawling.Crawler` to extract the :class:`~pyradise.data.modality.Modality`,
+    :class:`~pyradise.data.organ.Organ` or :class:`~pyradise.data.annotator.Annotator` instances for
+    :class:`~pyradise.data.subject.Subject` construction.
+
+    Typically, the user needs to implement the concrete extractor classes specific for the current task. This renders
+    flexibility and allows for a wide range of use cases. However, the user can also use the provided implementations
+    and examples to get started quickly.
+
+    """
+
+    @abstractmethod
+    def extract(self, path: str) -> Any:
+        """Extract information about the file at the specified path.
+
+        Args:
+            path (str): The path to the file for which information needs to be extracted.
+
+        Returns:
+            Any: The extracted information.
+        """
+        pass
+
+
+class ModalityExtractor(Extractor):
+    """A prototype class to extract the :class:`~pyradise.data.modality.Modality` from DICOM files and discrete image
+    file paths. It must be implemented by the user and is intended to be used with the
+    :class:`~pyradise.fileio.crawling.Crawler` types for DICOM and discrete image files. Thus, both abstract methods
+    (i.e. :meth:`extract_from_dicom` and :meth:`extract_from_path`) need to be implemented. In case of working
+    exclusively on DICOM or discrete image files, one extraction method may contain just a ``return None``.
+
+    Important:
+        If the file path does not specify an intensity image the extractor must return :data:`None`.
+
+    Warnings:
+        If :data:`return_default` is set to :data:`True` the :class:`ModalityExtractor` will return an enumerated
+        default :class:`~pyradise.data.modality.Modality` for each file for which no modality could be extracted.
+        This will have the effect that no error will be raised during loading. However, this functionality is intended
+        to be used exlusively for experimenting and debugging purposes such that the user can load data without
+        implementing a complete extractor. It's not recommended to use this feature for production purposes.
+        Subsequent errors may arise.
+
+    Notes:
+        If using the :class:`ModalityExtractor` in combination with a :class:`~pyradise.fileio.crawling.Crawler` all
+        paths to the discrete image files are provided sequentially to extract the
+        :class:`~pyradise.data.modality.Modality`. In case of working with DICOM data the
+        :class:`~pyradise.fileio.crawling.Crawler` will provide just one arbitrary file path to the
+        :class:`ModalityExtractor`.
+
+    Example:
+
+        Example of a :class:`ModalityExtractor` implementation to identify detailed modalities:
+
+        >>> from typing import (Any, Dict, Optional)
+        >>>
+        >>> from pyradise.fileio import (ModalityExtractor, Tag)
+        >>> from pyradise.data import Modality
+        >>>
+        >>>
+        >>> class ExampleModalityExtractor(ModalityExtractor):
+        >>>
+        >>>     @staticmethod
+        >>>     def _get_mr_modality(ds_dict: Dict[str, Any]) -> Optional[Modality]:
+        >>>         # check for different variants of attributes to get the sequence
+        >>>         # identification
+        >>>         scanning_sq = ds_dict.get('Scanning Sequence', {}).get('value', [])
+        >>>         scanning_sq = [scanning_sq] if isinstance(scanning_sq, str) else scanning_sq
+        >>>         contrast = ds_dict.get('Contrast/Bolus Agent', {}).get('value', '')
+        >>>
+        >>>         if all(val in scanning_sq for val in ('SE', 'IR')):
+        >>>             return Modality('FLAIR')
+        >>>         elif all(val in scanning_sq for val in ('GR', 'IR')) and len(contrast) > 0:
+        >>>             return Modality('T1c')
+        >>>         elif all(val in scanning_sq for val in ('GR', 'IR')) and len(contrast) == 0:
+        >>>             return Modality('T1w')
+        >>>         elif all(val == 'SE' for val in scanning_sq):
+        >>>             return Modality('T2w')
+        >>>         else:
+        >>>             return None
+        >>>
+        >>>     def extract_from_dicom(self, path: str) -> Optional[Modality]:
+        >>>         # extract the necessary attributes from the file
+        >>>         tags = (Tag(0x0008, 0x0060),  # Modality
+        >>>                 Tag(0x0018, 0x0010),  # ContrastBolusAgent
+        >>>                 Tag(0x0018, 0x0020))  # ScanningSequence
+        >>>         dataset_dict = self._load_dicom_attributes(tags, path)
+        >>>
+        >>>         # identify the modality
+        >>>         extracted_modality = dataset_dict.get('Modality', {}).get('value', None)
+        >>>         if extracted_modality == 'CT':
+        >>>             return Modality('CT')
+        >>>         elif extracted_modality == 'MR':
+        >>>             return self._get_mr_modality(dataset_dict)
+        >>>         else:
+        >>>             return None
+        >>>
+        >>>     def extract_from_path(self, path: str) -> Optional[Modality]:
+        >>>         # extract the necessary attributes from the file name
+        >>>         file_name = os.path.basename(path)
+        >>>         if 'T1c' in file_name:
+        >>>             return Modality('T1c')
+        >>>         elif 'T1w' in file_name:
+        >>>             return Modality('T1w')
+        >>>         elif 'T2w' in file_name:
+        >>>             return Modality('T2w')
+        >>>         elif 'FLAIR' in file_name:
+        >>>             return Modality('FLAIR')
+        >>>         elif 'CT' in file_name:
+        >>>             return Modality('CT')
+        >>>         else:
+        >>>             return None
+
+    Args:
+        return_default (bool): Indicates if an enumerated default :class:`~pyradise.data.modality.Modality` should be
+         returned if the extraction was not successful. Use this option exclusively for experimentation and debugging
+         because it can cause severe damage (default: False).
+    """
+
+    modality_default_idx = 0
+    default_modality_name = "UnknownModality"
+
+    def __init__(self, return_default: bool = False) -> None:
+        super().__init__()
+
+        self.return_default = return_default
+
+    @staticmethod
+    def _load_dicom_attributes(tags: Union[Tuple[Tuple[int, int], ...], Tuple[Tag, ...]], path: str) -> Dict[str, Any]:
+        """Load the DICOM attributes for the specified tags.
+
+        Args:
+            tags (Union[Tuple[Tuple[int, int], ...], Tuple[Tag, ...]]): The DICOM tags to extract the attributes for.
+            path (str): The path to the DICOM file to extract the attributes from.
+
+        Returns:
+            Dict[str, Any]: The loaded DICOM attributes.
+        """
+        tags_ = [Tag(tag) for tag in tags]
+        dataset = load_dataset_tag(path, tags_)
+
+        data = {}
+        for tag in tags_:
+            item = dataset.get(tag, None)
+            if item is not None:
+                data[item.name] = {"name": item.name, "value": item.value, "vr": item.VR}
+
+        return data
+
+    def _get_next_default_modality_name(self) -> str:
+        """Get the next enumerated modality name for unrecognized modalities.
+
+        Returns:
+            str: The next enumerated modality name.
+        """
+        name = self.default_modality_name + str(self.modality_default_idx)
+        self.modality_default_idx += 1
+        return name
+
+    def is_enumerated_default_modality(self, modality: Optional[Union[Modality, str]]) -> bool:
+        """Check if the specified modality is an enumerated default modality.
+
+        Args:
+            modality (Optional[Union[Modality, str]]): The modality to check.
+
+        Returns:
+            bool: True if the modality is an enumerated default modality, False otherwise.
+        """
+        if modality is None:
+            return False
+
+        if isinstance(modality, Modality):
+            modality = modality.name
+        return self.default_modality_name in modality
+
+    @abstractmethod
+    def extract_from_dicom(self, path: str) -> Optional[Modality]:
+        """Extract the :class:`~pyradise.data.modality.Modality` from the DICOM file at the specified path.
+        If the modality can not be detected :data:`None` must be returned.
+
+        Notes:
+            For your implementation you can load the DICOM file or specific DICOM attributes using the
+            :meth:`load_dataset` or :meth:`load_dataset_tag` functions from the :mod:`pyradise.utils` module.
+            For a detailed description of the DICOM attributes we refer to the `DICOM Standard
+            <https://www.dicomstandard.org/>`_ and the `DICOM Standard Browser <https://dicom.innolitics.com/>`_.
+
+        Args:
+            path (str): The path to the DICOM file to extract the :class:`~pyradise.data.modality.Modality` from.
+
+        Returns:
+            Optional[Modality]: The extracted :class:`~pyradise.data.modality.Modality` or :data:`None`.
+        """
+        raise NotImplementedError()
+
+    @abstractmethod
+    def extract_from_path(self, path: str) -> Optional[Modality]:
+        """Extract the :class:`~pyradise.data.modality.Modality` from the file path to a discrete image file or
+        from another other data source. If the modality can not be detected :data:`None` must be returned.
+
+        Args:
+            path (str): The path to the file to extract the :class:`~pyradise.data.modality.Modality` for.
+
+        Returns:
+            Optional[Modality]: The extracted :class:`~pyradise.data.modality.Modality` or :data:`None`.
+        """
+        raise NotImplementedError()
+
+    def extract(self, path: str) -> Optional[Modality]:
+        """Extract the :class:`~pyradise.data.modality.Modality` for either a DICOM or a discrete medical image file.
+
+        Args:
+            path (str): The path to the file to extract the :class:`~pyradise.data.modality.Modality` for.
+
+        Returns:
+            Optional[Modality]: The extracted :class:`~pyradise.data.modality.Modality` or :data:`None`.
+        """
+        if is_dicom_file(path):
+            modality = self.extract_from_dicom(path)
+        else:
+            modality = self.extract_from_path(path)
+
+        if self.return_default and modality is None:
+            return Modality(self._get_next_default_modality_name())
+
+        return modality
+
+
+class SimpleModalityExtractor(ModalityExtractor):
+    """A simple :class:`ModalityExtractor` implementation that uses the 'Modality' attribute in the provided DICOM
+    image or searches for a provided set of modality names (``modalities``) in the file name in case of a
+    discrete image file to generate a :class:`~pyradise.data.modality.Modality` with the same name. If no match is
+    found :data:`None` is returned.
+
+    Args:
+        modalities (Tuple[str, ...]): The possible modality names for the intensity files which will also
+         be used to name the :class:`~pyradise.data.modality.Modality`.
+        return_default (bool): Indicates if an enumerated default :class:`~pyradise.data.modality.Modality` should be
+         returned if the extraction was not successfully. Use this option exclusively for experimentation and debugging
+         because it can cause severe damage (default: False).
+
+    """
+
+    def __init__(
+        self,
+        modalities: Tuple[str, ...],
+        return_default: bool = False,
+    ) -> None:
+        super().__init__(return_default)
+
+        self.modalities = modalities
+
+    def extract_from_path(self, path: str) -> Optional[Modality]:
+        """Extract the :class:`~pyradise.data.modality.Modality` from the file name using the provided
+        ``modalities``. If there is no match :data:`None` is returned.
+
+        Args:
+            path (str): The path to the file to extract the :class:`~pyradise.data.modality.Modality` for.
+
+        Returns:
+            Optional[Modality]: The extracted :class:`~pyradise.data.modality.Modality` or :data:`None`.
+        """
+        file_name = os.path.basename(path)
+
+        for modality in self.modalities:
+            if modality in file_name:
+                return Modality(modality)
+
+        return None
+
+    def extract_from_dicom(self, path: str) -> Optional[Modality]:
+        """Extract the DICOM attribute 'Modality' from the provided DICOM file. If no or an invalid 'Modality'
+        attribute is found, :data:`None` is returned.
+
+        Notes:
+            This method exclusively extracts the following top-level modalities: CT, MR, PT, and US.
+            For all other values of the DICOM 'Modality' attribute :data:`None` is returned.
+
+        Args:
+            path (str): The path to the DICOM file to extract the :class:`~pyradise.data.modality.Modality` from.
+
+        Returns:
+            Optional[Modality]: The extracted :class:`~pyradise.data.modality.Modality` or :data:`None`.
+        """
+        # extract the Modality attribute
+        tags = (Tag(0x0008, 0x0060),)  # Modality
+        dataset_dict = self._load_dicom_attributes(tags, path)
+
+        # get the general modality
+        extracted_modality = dataset_dict.get("Modality", {}).get("value", None)
+        if extracted_modality in ("CT", "MR", "PT", "US"):
+            return Modality(extracted_modality)
+        else:
+            return None
+
+
+class OrganExtractor(Extractor):
+    """A prototype class to extract an :class:`~pyradise.data.organ.Organ` from a discrete image file path. This class
+    must be implemented by the user and is intended to be used with a :class:`~pyradise.fileio.crawling.Crawler` for
+    discrete image formats.
+
+    Important:
+        If the file path does not specify a segmentation image the extractor must return :data:`None`.
+
+    Example:
+
+        Example of an :class:`OrganExtractor` implementation which takes search strings and associated organ names to
+        extract an :class:`Organ` from a file path:
+
+        >>> from typing import (Any, Dict, Optional)
+        >>>
+        >>> from pyradise.fileio import OrganExtractor
+        >>> from pyradise.data import Organ
+        >>>
+        >>>
+        >>> class ExampleOrganExtractor(OrganExtractor):
+        >>>
+        >>>     def __init__(self,
+        >>>                  search_strings: Dict[str, str],
+        >>>                  names: Tuple[str, ...]
+        >>>                  ) -> None:
+        >>>         super().__init__()
+        >>>
+        >>>         assert len(search_strings) == len(names), /
+        >>>         f'Number of search strings ({len(search_strings)}) must match the ' \
+        >>>         f'number of organ names ({len(names)})!'
+        >>>
+        >>>         self.search_strings = search_strings
+        >>>         self.names = names
+        >>>
+        >>>     def extract(self, path: str) -> Optional[Organ]:
+        >>>         file_name = os.path.basename(path)
+        >>>
+        >>>         for search_string, name in zip(self.search_strings, self.names):
+        >>>             if search_string in file_name:
+        >>>                 return Organ(name)
+        >>>
+        >>>         return None
+    """
+
+    def extract(self, path: str) -> Optional[Organ]:
+        """Extract the :class:`~pyradise.data.organ.Organ` from the file path.
+
+        Args:
+            path (str): The path to the file to extract the :class:`~pyradise.data.organ.Organ` for.
+
+        Returns:
+            Optional[Organ]: The extracted :class:`~pyradise.data.organ.Organ` or :data:`None`.
+        """
+        raise NotImplementedError("The extract method needs to be adopted for the intended use case!")
+
+
+class SimpleOrganExtractor(OrganExtractor):
+    """A simple :class:`OrganExtractor` implementation that searches for a provided set of organ names
+    (``organs``) in the file name and generates an :class:`~pyradise.data.organ.Organ` with the same name. If no
+    match is found :data:`None` is returned.
+
+    Args:
+        organs (Tuple[str, ...]): The possible organ names which will also be used to name the output
+         :class:`~pyradise.data.organ.Organ`.
+
+    """
+
+    def __init__(self, organs: Tuple[str, ...]) -> None:
+        super().__init__()
+        self.organs = organs
+
+    def extract(self, path: str) -> Optional[Organ]:
+        """Extract the :class:`~pyradise.data.organ.Organ` from the file name using the provided ``organs``. If
+        no :class:`~pyradise.data.organ.Organ` can be extracted or the file does not contain a segmentation image
+        :data:`None` is returned.
+
+        Args:
+            path (str): The path to the file to extract the :class:`~pyradise.data.organ.Organ` for.
+
+        Returns:
+            Optional[Organ]: The extracted :class:`~pyradise.data.organ.Organ` or :data:`None`.
+        """
+        file_name = os.path.basename(path)
+
+        for organ in reversed(self.organs):
+            if organ in file_name:
+                return Organ(organ)
+
+        return None
+
+
+class AnnotatorExtractor(Extractor):
+    """A prototype class to extract an :class:`~pyradise.data.annotator.Annotator` from a discrete image file path.
+    This class must be implemented by the user and is intended to be used with a
+    :class:`~pyradise.fileio.crawling.Crawler` for discrete image formats.
+
+    Important:
+        If the file path does not specify a segmentation image the extractor must return :data:`None`.
+
+    Example:
+
+        Example of an :class:`AnnotatorExtractor` implementation which takes search strings and associated annotator
+        names to extract a :class:`~pyradise.data.annotator.Annotator` from a file path:
+
+        >>> from typing import (Any, Dict, Optional)
+        >>>
+        >>> from pyradise.fileio import AnnotatorExtractor
+        >>> from pyradise.data import Annotator
+        >>>
+        >>>
+        >>> class ExampleAnnotatorExtractor(AnnotatorExtractor):
+        >>>
+        >>>     def __init__(self,
+        >>>                  search_strings: Dict[str, str],
+        >>>                  names: Tuple[str, ...]
+        >>>                  ) -> None:
+        >>>         super().__init__()
+        >>>
+        >>>         assert len(search_strings) == len(names), /
+        >>>         f'Number of search strings ({len(search_strings)}) must match the' \
+        >>>         f'number of annotator names ({len(names)})!'
+        >>>
+        >>>         self.search_strings = search_strings
+        >>>         self.names = names
+        >>>
+        >>>     def extract(self, path: str) -> Optional[Annotator]:
+        >>>         file_name = os.path.basename(path)
+        >>>
+        >>>         for search_string, name in zip(self.search_strings, self.names):
+        >>>             if search_string in file_name:
+        >>>                 return Annotator(name)
+        >>>
+        >>>         return None
+    """
+
+    def extract(self, path: str) -> Optional[Annotator]:
+        """Extract the :class:`~pyradise.data.annotator.Annotator` from the file path.
+
+        Args:
+            path (str): The path to the file to extract the :class:`~pyradise.data.annotator.Annotator` for.
+
+        Returns:
+            Optional[Annotator]: The extracted :class:`~pyradise.data.annotator.Annotator` or :data:`None`.
+        """
+        raise NotImplementedError("The extract method needs to be adopted for the intended use case!")
+
+
+class SimpleAnnotatorExtractor(AnnotatorExtractor):
+    """A simple :class:`AnnotatorExtractor` implementation that searches for a provided set of annotator names
+    (``annotators``) in the file name and generates a :class:`~pyradise.data.annotator.Annotator` with the same name.
+    If no match is found :data:`None` is returned.
+
+    Args:
+        annotators (Tuple[str, ...]): The possible annotator names which will also be used to name the output
+         :class:`Annotator`.
+
+    """
+
+    def __init__(self, annotators: Tuple[str, ...]) -> None:
+        super().__init__()
+
+        self.annotators = annotators
+
+    def extract(self, path: str) -> Optional[Annotator]:
+        """Extract the :class:`~pyradise.data.annotator.Annotator` from the file name using the provided ``annotators``.
+        If no :class:`~pyradise.data.annotator.Annotator` can be extracted or the file does not contain a segmentation
+        image :data:`None` is returned.
+
+        Args:
+            path (str): The path to the file to extract the :class:`~pyradise.data.annotator.Annotator` for.
+
+        Returns:
+            Optional[Annotator]: The extracted :class:`~pyradise.data.annotator.Annotator` or :data:`None`.
+        """
+        file_name = os.path.basename(path)
+
+        for annotator in self.annotators:
+            if annotator in file_name:
+                return Annotator(annotator)
+
+        return None
```

### Comparing `pyradise-0.2.2/pyradise/fileio/loading.py` & `pyradise-0.2.3/pyradise/fileio/loading.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,495 +1,495 @@
-from abc import ABC, abstractmethod
-from typing import List, Sequence, Tuple
-
-import SimpleITK as sitk
-
-from pyradise.data import IntensityImage, SegmentationImage, Subject
-
-from .dicom_conversion import (DicomImageSeriesConverter,
-                               DicomRTSSSeriesConverter)
-from .series_info import (DicomSeriesImageInfo, DicomSeriesRegistrationInfo,
-                          DicomSeriesRTSSInfo, IntensityFileSeriesInfo,
-                          SegmentationFileSeriesInfo, SeriesInfo)
-
-__all__ = ["Loader", "ExplicitLoader", "SubjectLoader", "IterableSubjectLoader"]
-
-
-class Loader(ABC):
-    """An abstract base class for all :class:`Loader` classes. A :class:`Loader` class typically takes a sequence of
-    :class:`~pyradise.fileio.series_info.SeriesInfo` entries and loads the data based on the information
-    provided by the :class:`~pyradise.fileio.series_info.SeriesInfo` entries. The data is then returned as a
-    :class:`~pyradise.data.subject.Subject` such that it can be used directly for further processing with for example
-    the :mod:`~pyradise.process` package or the :mod:`~pyradise.fileio.writing` module.
-    """
-
-    @staticmethod
-    def _extract_info_by_type(info: Sequence[SeriesInfo], type_: type) -> Tuple:
-        """Extract all :class:`~pyradise.fileio.series_info.SeriesInfo` entries of the specified type from the
-        provided sequence of :class:`~pyradise.fileio.series_info.SeriesInfo`.
-
-        Args:
-            info (Sequence[SeriesInfo]): The sequence of :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-            type_ (type): The specific sub-type of the :class:`~pyradise.fileio.series_info.SeriesInfo` class to be
-             extracted.
-
-        Returns:
-            Tuple[SeriesInfo]: The extracted :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-        """
-        return tuple(filter(lambda x: isinstance(x, type_), info))
-
-
-class ExplicitLoader(Loader, ABC):
-    """An abstract :class:`Loader` class that implements a :meth:`load` method such that multiple sets of
-    :class:`~pyradise.fileio.series_info.SeriesInfo` entries can be loaded with the same :class:`Loader` instance."""
-
-    @abstractmethod
-    def load(self, info: Tuple[SeriesInfo, ...]) -> Subject:
-        """Load the :class:`~pyradise.data.subject.Subject`.
-
-        Args:
-            info (Tuple[SeriesInfo, ...]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to be loaded.
-
-        Returns:
-            Subject: The loaded :class:`~pyradise.data.subject.Subject`.
-        """
-        raise NotImplementedError()
-
-
-class SubjectLoader(ExplicitLoader):
-    """An :class:`ExplicitLoader` for loading a :class:`~pyradise.data.subject.Subject` based on its
-    :class:`~pyradise.fileio.series_info.SeriesInfo` entries. This loader can load both DICOM data (i.e.
-    :class:`~pyradise.fileio.series_info.DicomSeriesInfo`) and discrete image data (i.e.
-    :class:`~pyradise.fileio.series_info.FileSeriesInfo`). The loader validates the provided
-    :class:`~pyradise.fileio.series_info.SeriesInfo` entries before loading and raises appropriate errors if the
-    information is not valid.
-
-    Examples:
-
-        Load and normalize NIFTI files and save the subject as NRRD files:
-
-        >>> from argparse import ArgumentParser
-        >>> from pyradise.fileio import (SubjectFileCrawler, SubjectLoader,
-        >>>                              SubjectWriter, ImageFileFormat)
-        >>> from pyradise.process import (ZScoreNormFilter,
-        >>>                               ZScoreNormFilterParams)
-        >>>
-        >>>
-        >>> def main(input_path: str, output_path: str, subject_name: str) -> None:
-        >>>   # Crawl the input directory for compressed NIFTI files
-        >>>   info = SubjectFileCrawler(input_path, subject_name, 'nii.gz').execute()
-        >>>
-        >>>   # Load the subject
-        >>>   subject = SubjectLoader().load(info)
-        >>>
-        >>>   # Perform the normalization
-        >>>   normalization_params = ZScoreNormFilterParams(loop_axis=1)
-        >>>   normalization_filter = ZScoreNormFilter(normalization_params)
-        >>>   subject = normalization_filter.execute(subject)
-        >>>
-        >>>   # Write the subject to the output directory
-        >>>   writer = SubjectWriter(ImageFileFormat.NRRD)
-        >>>   writer.write(output_path, subject, write_transforms=False)
-        >>>
-        >>>
-        >>> if __name__ == '__main__':
-        >>>   parser = ArgumentParser()
-        >>>   parser.add_argument('input_path', type=str, help='The input directory.')
-        >>>   parser.add_argument('output_path', type=str, help='The output directory.')
-        >>>   parser.add_argument('subject_name', type=str, help='The name of the subject.')
-        >>>   args = parser.parse_args()
-        >>>
-        >>>   main(args.input_path, args.output_path, args.subject_name)
-
-
-        Load DICOM data and save the converted data as NIFTI files:
-
-        >>> from argparse import ArgumentParser
-        >>> from pyradise.fileio import SubjectDicomCrawler, SubjectLoader, SubjectWriter
-        >>>
-        >>>
-        >>> def main(input_path: str, output_path: str) -> None:
-        >>>   # Crawl the input directory for DICOM data
-        >>>   # Note: We assume that the modality configuration file (modality_config.json)
-        >>>   # is existing.
-        >>>   info = SubjectDicomCrawler(input_path).execute()
-        >>>
-        >>>   # Load the subject
-        >>>   subject = SubjectLoader().load(info)
-        >>>
-        >>>   # Write the subject to the output directory
-        >>>   writer = SubjectWriter()
-        >>>   writer.write(output_path, subject, write_transforms=False)
-        >>>
-        >>>
-        >>> if __name__ == '__main__':
-        >>>   parser = ArgumentParser()
-        >>>   parser.add_argument('input_path', type=str, help='The input directory.')
-        >>>   parser.add_argument('output_path', type=str, help='The output directory.')
-        >>>   args = parser.parse_args()
-        >>>
-        >>>   main(args.input_path, args.output_path)
-
-    Args:
-        intensity_pixel_value_type (int): The pixel value type of the intensity imagesm when loading discrete image
-         files (default: sitk.sitkFloat32).
-        segmentation_pixel_value_type (int): The pixel value type of the segmentation images when loading discrete
-         files (default: sitk.sitkUInt8).
-        fill_hole_search_distance (int): The search distance for the hole filling algorithm. If the search distance is
-         set to zero the hole filling algorithm is omitted. The search distance must be an odd number larger than 1
-         (default: 0).
-
-    """
-
-    def __init__(
-        self,
-        intensity_pixel_value_type: int = sitk.sitkFloat32,
-        segmentation_pixel_value_type: int = sitk.sitkUInt8,
-        fill_hole_search_distance: int = 0,
-    ) -> None:
-        super().__init__()
-
-        self.intensity_pixel_type = intensity_pixel_value_type
-        self.segmentation_pixel_type = segmentation_pixel_value_type
-
-        # store the fill hole search distance
-        if fill_hole_search_distance == 0:
-            self.fill_hole_distance = 0
-        elif fill_hole_search_distance % 2 == 0:
-            raise ValueError("The fill hole search distance must be an odd number.")
-        elif fill_hole_search_distance == 1:
-            raise ValueError("The fill hole search distance must be larger than 1.")
-        else:
-            self.fill_hole_distance = fill_hole_search_distance
-
-    @staticmethod
-    def _load_intensity_images(
-        info: Tuple[IntensityFileSeriesInfo], pixel_value_type: sitk.sitkFloat32
-    ) -> Tuple[IntensityImage]:
-        """Load the :class:`~pyradise.data.image.IntensityImage` s.
-
-        Args:
-            info (Tuple[IntensityFileSeriesInfo]): The :class:`~pyradise.data.image.IntensityFileSeriesInfo` entries
-             containing the file paths to the images.
-            pixel_value_type (int): The pixel value type for the intensity images.
-
-        Returns:
-            Tuple[IntensityImage]: The loaded intensity :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        images = []
-        for info_entry in info:
-            image = sitk.ReadImage(info_entry.get_path()[0], pixel_value_type)
-            images.append(IntensityImage(image, info_entry.get_modality()))
-
-        return tuple(images)
-
-    @staticmethod
-    def _load_segmentation_images(
-        info: Tuple[SegmentationFileSeriesInfo], pixel_value_type: sitk.sitkUInt8
-    ) -> Tuple[SegmentationImage]:
-        """Load the :class:`~pyradise.data.image.SegmentationImage` s.
-
-        Args:
-            info (Tuple[SegmentationFileSeriesInfo]): The
-             :class:`~pyradise.fileio.series_info.SegmentationFileSeriesInfo` entries containing the file paths to
-             the images.
-            pixel_value_type (int): The pixel value type for the segmentation images.
-
-        Returns:
-            Tuple[SegmentationImage]: The loaded :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-        images = []
-        for info_entry in info:
-            image = sitk.ReadImage(info_entry.get_path()[0], pixel_value_type)
-            images.append(SegmentationImage(image, info_entry.get_organ(), info_entry.get_annotator()))
-
-        return tuple(images)
-
-    @staticmethod
-    def _validate_patient_identification(info: Tuple[SeriesInfo]) -> bool:
-        """Validate the patient identification of the provided :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-
-        Args:
-            info (Tuple[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to check.
-
-        Returns:
-            bool: True if the patient identification is valid for all info entries, otherwise False.
-        """
-        if not info:
-            return False
-
-        names = [entry.get_patient_name() for entry in info]
-        ids = [entry.get_patient_id() for entry in info]
-
-        return all(name == names[0] for name in names) and all(id_ == ids[0] for id_ in ids)
-
-    @staticmethod
-    def _validate_registration(
-        reg_info: Tuple[DicomSeriesRegistrationInfo], image_info: Tuple[DicomSeriesImageInfo]
-    ) -> bool:
-        """Validate the ReferencedSeriesInstanceUIDs of the provided
-        :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries by checking if the referenced DICOM
-        image data is provided.
-
-        Args:
-            reg_info (Tuple[DicomSeriesRegistrationInfo]): The
-             :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries to check.
-            image_info (Tuple[DicomSeriesImageInfo]): The :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo`
-             entries containing the referenced SeriesInstanceUIDs.
-
-        Returns:
-            bool: True if the image infos for all registration infos is available, otherwise False.
-
-        """
-
-        def is_image_info_available(instance_uids: List[str], image_info_: Tuple[DicomSeriesImageInfo]) -> bool:
-            comparison = [[info.series_instance_uid == uid for info in image_info_] for uid in instance_uids]
-            return all(any(comparison_) for comparison_ in comparison)
-
-        if not reg_info:
-            return True
-
-        if not image_info:
-            return False
-
-        identity_uids = []
-        transform_uids = []
-        for reg_info_entry in reg_info:
-            reg_info_entry.update() if not reg_info_entry.is_updated() else None
-
-            identity = reg_info_entry.referenced_series_instance_uid_identity
-            if identity != "":
-                identity_uids.append(identity)
-
-            transform = reg_info_entry.referenced_series_instance_uid_transform
-            if transform != "":
-                transform_uids.append(transform)
-
-        if is_image_info_available(identity_uids, image_info) and is_image_info_available(transform_uids, image_info):
-            return True
-
-        return False
-
-    @staticmethod
-    def _validate_rtss_info(rtss_info: Tuple[DicomSeriesRTSSInfo], image_info: Tuple[DicomSeriesImageInfo]) -> bool:
-        """Validate if all SeriesInstanceUIDs referenced in the DICOM-RTSSs are provided.
-
-        Args:
-            rtss_info (Tuple[DicomSeriesRTSSInfo]): The :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo`
-             entries to check.
-            image_info (Tuple[DicomSeriesImageInfo]): The :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo`
-             entries containing the SeriesInstanceUIDs.
-
-        Returns:
-            bool: True if the referenced image infos for all RTSS infos are available, otherwise False.
-        """
-        if not rtss_info:
-            return True
-
-        if not image_info:
-            return False
-
-        comparison = [
-            any(info.series_instance_uid == rtss_info_entry.referenced_instance_uid for info in image_info)
-            for rtss_info_entry in rtss_info
-        ]
-
-        return all(comparison)
-
-    def load(self, info: Tuple[SeriesInfo, ...]) -> Subject:
-        """Load a :class:`~pyradise.data.subject.Subject` from the provided
-        :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-
-        Args:
-            info (Tuple[SeriesInfo, ...]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries containing the
-             necessary information for loading the subject.
-
-        Raises:
-            ValueError: If ``info`` is an empty tuple.
-            ValueError: If ``info`` is not a tuple of :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-            ValueError: If the patient name and patient id of the provided
-             :class:`~pyradise.fileio.series_info.SeriesInfo` entries are not equal.
-            ValueError: If not all referenced :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries are
-             provided for registration.
-            ValueError: If not all referenced :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries are
-             provided for RTSS loading.
-
-        Returns:
-            Subject: The loaded subject.
-
-        """
-        # check if the info entries have the correct structure
-        if not info:
-            raise ValueError("The provided info entries are empty.")
-
-        if not all(isinstance(entry, SeriesInfo) for entry in info):
-            raise ValueError(
-                "The provided info entries are not of type SeriesInfo. "
-                "Make sure to provide a tuple of SeriesInfo entries."
-            )
-
-        # separate the info entries
-        dicom_image_info = self._extract_info_by_type(info, DicomSeriesImageInfo)
-        dicom_reg_info = self._extract_info_by_type(info, DicomSeriesRegistrationInfo)
-        dicom_rtss_info = self._extract_info_by_type(info, DicomSeriesRTSSInfo)
-        intensity_image_info = self._extract_info_by_type(info, IntensityFileSeriesInfo)
-        segmentation_image_info = self._extract_info_by_type(info, SegmentationFileSeriesInfo)
-
-        # validate the info entries
-        if not self._validate_patient_identification(info):
-            raise ValueError("The patient identification (patient_name and patient_id) is not unique!")
-
-        if not self._validate_registration(dicom_reg_info, dicom_image_info):
-            raise ValueError("At least one referenced image in the registration is missing!")
-
-        if not self._validate_rtss_info(dicom_rtss_info, dicom_image_info):
-            raise ValueError("The referenced image in the RTSS is not available!")
-
-        # create the subject
-        if dicom_image_info:
-            subject = Subject(dicom_image_info[0].get_patient_name())
-        elif intensity_image_info:
-            subject = Subject(intensity_image_info[0].get_patient_name())
-        elif segmentation_image_info:
-            subject = Subject(segmentation_image_info[0].get_patient_name())
-        else:
-            raise ValueError("Subject can not be constructed because a subject name is missing!")
-
-        # load the images and add them to the subject
-        if dicom_image_info:
-            dicom_images = DicomImageSeriesConverter(dicom_image_info, dicom_reg_info).convert()
-            subject.add_images(dicom_images)
-
-        if dicom_rtss_info:
-            dicom_segmentations = DicomRTSSSeriesConverter(
-                dicom_rtss_info, dicom_image_info, dicom_reg_info, self.fill_hole_distance
-            ).convert()
-            subject.add_images(dicom_segmentations, force=True)
-
-        intensity_images = self._load_intensity_images(intensity_image_info, self.intensity_pixel_type)
-        segmentation_images = self._load_segmentation_images(segmentation_image_info, self.segmentation_pixel_type)
-        subject.add_images(intensity_images + segmentation_images, force=True)
-
-        return subject
-
-
-class IterableSubjectLoader(Loader):
-    """An :class:`Loader` for loading a sequence of :class:`~pyradise.data.subject.Subject` s based on their
-    :class:`~pyradise.fileio.series_info.SeriesInfo` entries. This loader can load both DICOM data (i.e.
-    :class:`~pyradise.fileio.series_info.DicomSeriesInfo`) and discrete image data (i.e.
-    :class:`~pyradise.fileio.series_info.FileSeriesInfo`). The loader validates the provided
-    :class:`~pyradise.fileio.series_info.SeriesInfo` entries before loading and raises appropriate errors if the
-    information is not valid.
-
-    Notes:
-        For loading large DICOM dataset we recommend to use the :class:`SubjectLoader` instead because the antecedent
-        crawling process can require a lot of computation time and memory.
-
-    Raises:
-        ValueError: If ``info`` is an empty tuple.
-        ValueError: If ``info`` is not a tuple of tuples of :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-
-    Args:
-        info (Tuple[Tuple[SeriesInfo, ...], ...]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries for all
-         subjects to load.
-        intensity_pixel_value_type (int): The pixel value type of the intensity imagesm when loading discrete image
-         files (default: sitk.sitkFloat32).
-        segmentation_pixel_value_type (int): The pixel value type of the segmentation images when loading discrete
-         files (default: sitk.sitkUInt8).
-        fill_hole_search_distance (int): The search distance for the hole filling algorithm. If the search distance is
-         set to zero the hole filling algorithm is omitted. The search distance must be an odd number larger than 1
-         (default: 0).
-
-    Examples:
-
-        Load, normalize and save a NIFTI dataset with multiple subjects:
-
-        >>> from argparse import ArgumentParser
-        >>> from pyradise.fileio import (DatasetFileCrawler, IterableSubjectLoader,
-        >>>                              SubjectWriter)
-        >>> from pyradise.process import (ZScoreNormFilter,
-        >>>                               ZScoreNormFilterParams)
-        >>>
-        >>>
-        >>> def main(input_path: str, output_path: str) -> None:
-        >>>     # Crawl the dataset info
-        >>>     info = DatasetFileCrawler(input_path, '.nii.gz').execute()
-        >>>
-        >>>     # Construct the loader
-        >>>     loader = IterableSubjectLoader(info)
-        >>>
-        >>>     # Construct the normalization filter
-        >>>     normalization_params = ZScoreNormFilterParams(loop_axis=1)
-        >>>     normalization_filter = ZScoreNormFilter(normalization_params)
-        >>>
-        >>>     # Construct the writer
-        >>>     writer = SubjectWriter()
-        >>>
-        >>>     # Iteratively load the subjects
-        >>>     for subject in loader:
-        >>>         # Normalize the images
-        >>>         subject = normalization_filter.execute(subject)
-        >>>
-        >>>         # Save the subject
-        >>>         writer.write_to_subject_folder(output_path, subject, write_transforms=False)
-        >>>
-        >>>
-        >>> if __name__ == '__main__':
-        >>>     parser = ArgumentParser()
-        >>>     parser.add_argument('--input_path', type=str,
-        >>>                         help='The dataset input directory.')
-        >>>     parser.add_argument('--output_path', type=str,
-        >>>                         help='The dataset output directory.')
-        >>>     args = parser.parse_args()
-        >>>
-        >>>     main(args.input_path, args.output_path)
-    """
-
-    def __init__(
-        self,
-        info: Tuple[Tuple[SeriesInfo, ...], ...],
-        intensity_pixel_value_type: int = sitk.sitkFloat32,
-        segmentation_pixel_value_type: int = sitk.sitkUInt8,
-        fill_hole_search_distance: int = 0,
-    ):
-        super().__init__()
-
-        if not info:
-            raise ValueError("The provided infos are empty.")
-        if not all(isinstance(entry, tuple) for entry in info):
-            raise ValueError(
-                "The provided first level info entries are not of type tuple. "
-                "Make sure that the info is a tuple of tuples."
-            )
-        self.info = info
-
-        self.intensity_pixel_type = intensity_pixel_value_type
-        self.segmentation_pixel_type = segmentation_pixel_value_type
-
-        # store the fill hole search distance
-        if fill_hole_search_distance == 0:
-            self.fill_hole_distance = 0
-        elif fill_hole_search_distance % 2 == 0:
-            raise ValueError("The fill hole search distance must be an odd number.")
-        elif fill_hole_search_distance == 1:
-            raise ValueError("The fill hole search distance must be larger than 1.")
-        else:
-            self.fill_hole_distance = fill_hole_search_distance
-
-        self.current_idx = 0
-        self.num_subjects = len(self.info)
-
-    def __iter__(self):
-        self.current_idx = 0
-        return self
-
-    def __next__(self) -> Subject:
-        if self.current_idx < self.num_subjects:
-            loader = SubjectLoader(self.intensity_pixel_type, self.segmentation_pixel_type, self.fill_hole_distance)
-            subject = loader.load(self.info[self.current_idx])
-            self.current_idx += 1
-            return subject
-
-        raise StopIteration()
-
-    def __len__(self):
-        return self.num_subjects
+from abc import ABC, abstractmethod
+from typing import List, Sequence, Tuple
+
+import SimpleITK as sitk
+
+from pyradise.data import IntensityImage, SegmentationImage, Subject
+
+from .dicom_conversion import (DicomImageSeriesConverter,
+                               DicomRTSSSeriesConverter)
+from .series_info import (DicomSeriesImageInfo, DicomSeriesRegistrationInfo,
+                          DicomSeriesRTSSInfo, IntensityFileSeriesInfo,
+                          SegmentationFileSeriesInfo, SeriesInfo)
+
+__all__ = ["Loader", "ExplicitLoader", "SubjectLoader", "IterableSubjectLoader"]
+
+
+class Loader(ABC):
+    """An abstract base class for all :class:`Loader` classes. A :class:`Loader` class typically takes a sequence of
+    :class:`~pyradise.fileio.series_info.SeriesInfo` entries and loads the data based on the information
+    provided by the :class:`~pyradise.fileio.series_info.SeriesInfo` entries. The data is then returned as a
+    :class:`~pyradise.data.subject.Subject` such that it can be used directly for further processing with for example
+    the :mod:`~pyradise.process` package or the :mod:`~pyradise.fileio.writing` module.
+    """
+
+    @staticmethod
+    def _extract_info_by_type(info: Sequence[SeriesInfo], type_: type) -> Tuple:
+        """Extract all :class:`~pyradise.fileio.series_info.SeriesInfo` entries of the specified type from the
+        provided sequence of :class:`~pyradise.fileio.series_info.SeriesInfo`.
+
+        Args:
+            info (Sequence[SeriesInfo]): The sequence of :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+            type_ (type): The specific sub-type of the :class:`~pyradise.fileio.series_info.SeriesInfo` class to be
+             extracted.
+
+        Returns:
+            Tuple[SeriesInfo]: The extracted :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+        """
+        return tuple(filter(lambda x: isinstance(x, type_), info))
+
+
+class ExplicitLoader(Loader, ABC):
+    """An abstract :class:`Loader` class that implements a :meth:`load` method such that multiple sets of
+    :class:`~pyradise.fileio.series_info.SeriesInfo` entries can be loaded with the same :class:`Loader` instance."""
+
+    @abstractmethod
+    def load(self, info: Tuple[SeriesInfo, ...]) -> Subject:
+        """Load the :class:`~pyradise.data.subject.Subject`.
+
+        Args:
+            info (Tuple[SeriesInfo, ...]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to be loaded.
+
+        Returns:
+            Subject: The loaded :class:`~pyradise.data.subject.Subject`.
+        """
+        raise NotImplementedError()
+
+
+class SubjectLoader(ExplicitLoader):
+    """An :class:`ExplicitLoader` for loading a :class:`~pyradise.data.subject.Subject` based on its
+    :class:`~pyradise.fileio.series_info.SeriesInfo` entries. This loader can load both DICOM data (i.e.
+    :class:`~pyradise.fileio.series_info.DicomSeriesInfo`) and discrete image data (i.e.
+    :class:`~pyradise.fileio.series_info.FileSeriesInfo`). The loader validates the provided
+    :class:`~pyradise.fileio.series_info.SeriesInfo` entries before loading and raises appropriate errors if the
+    information is not valid.
+
+    Examples:
+
+        Load and normalize NIFTI files and save the subject as NRRD files:
+
+        >>> from argparse import ArgumentParser
+        >>> from pyradise.fileio import (SubjectFileCrawler, SubjectLoader,
+        >>>                              SubjectWriter, ImageFileFormat)
+        >>> from pyradise.process import (ZScoreNormFilter,
+        >>>                               ZScoreNormFilterParams)
+        >>>
+        >>>
+        >>> def main(input_path: str, output_path: str, subject_name: str) -> None:
+        >>>   # Crawl the input directory for compressed NIFTI files
+        >>>   info = SubjectFileCrawler(input_path, subject_name, 'nii.gz').execute()
+        >>>
+        >>>   # Load the subject
+        >>>   subject = SubjectLoader().load(info)
+        >>>
+        >>>   # Perform the normalization
+        >>>   normalization_params = ZScoreNormFilterParams(loop_axis=1)
+        >>>   normalization_filter = ZScoreNormFilter(normalization_params)
+        >>>   subject = normalization_filter.execute(subject)
+        >>>
+        >>>   # Write the subject to the output directory
+        >>>   writer = SubjectWriter(ImageFileFormat.NRRD)
+        >>>   writer.write(output_path, subject, write_transforms=False)
+        >>>
+        >>>
+        >>> if __name__ == '__main__':
+        >>>   parser = ArgumentParser()
+        >>>   parser.add_argument('input_path', type=str, help='The input directory.')
+        >>>   parser.add_argument('output_path', type=str, help='The output directory.')
+        >>>   parser.add_argument('subject_name', type=str, help='The name of the subject.')
+        >>>   args = parser.parse_args()
+        >>>
+        >>>   main(args.input_path, args.output_path, args.subject_name)
+
+
+        Load DICOM data and save the converted data as NIFTI files:
+
+        >>> from argparse import ArgumentParser
+        >>> from pyradise.fileio import SubjectDicomCrawler, SubjectLoader, SubjectWriter
+        >>>
+        >>>
+        >>> def main(input_path: str, output_path: str) -> None:
+        >>>   # Crawl the input directory for DICOM data
+        >>>   # Note: We assume that the modality configuration file (modality_config.json)
+        >>>   # is existing.
+        >>>   info = SubjectDicomCrawler(input_path).execute()
+        >>>
+        >>>   # Load the subject
+        >>>   subject = SubjectLoader().load(info)
+        >>>
+        >>>   # Write the subject to the output directory
+        >>>   writer = SubjectWriter()
+        >>>   writer.write(output_path, subject, write_transforms=False)
+        >>>
+        >>>
+        >>> if __name__ == '__main__':
+        >>>   parser = ArgumentParser()
+        >>>   parser.add_argument('input_path', type=str, help='The input directory.')
+        >>>   parser.add_argument('output_path', type=str, help='The output directory.')
+        >>>   args = parser.parse_args()
+        >>>
+        >>>   main(args.input_path, args.output_path)
+
+    Args:
+        intensity_pixel_value_type (int): The pixel value type of the intensity imagesm when loading discrete image
+         files (default: sitk.sitkFloat32).
+        segmentation_pixel_value_type (int): The pixel value type of the segmentation images when loading discrete
+         files (default: sitk.sitkUInt8).
+        fill_hole_search_distance (int): The search distance for the hole filling algorithm. If the search distance is
+         set to zero the hole filling algorithm is omitted. The search distance must be an odd number larger than 1
+         (default: 0).
+
+    """
+
+    def __init__(
+        self,
+        intensity_pixel_value_type: int = sitk.sitkFloat32,
+        segmentation_pixel_value_type: int = sitk.sitkUInt8,
+        fill_hole_search_distance: int = 0,
+    ) -> None:
+        super().__init__()
+
+        self.intensity_pixel_type = intensity_pixel_value_type
+        self.segmentation_pixel_type = segmentation_pixel_value_type
+
+        # store the fill hole search distance
+        if fill_hole_search_distance == 0:
+            self.fill_hole_distance = 0
+        elif fill_hole_search_distance % 2 == 0:
+            raise ValueError("The fill hole search distance must be an odd number.")
+        elif fill_hole_search_distance == 1:
+            raise ValueError("The fill hole search distance must be larger than 1.")
+        else:
+            self.fill_hole_distance = fill_hole_search_distance
+
+    @staticmethod
+    def _load_intensity_images(
+        info: Tuple[IntensityFileSeriesInfo], pixel_value_type: sitk.sitkFloat32
+    ) -> Tuple[IntensityImage]:
+        """Load the :class:`~pyradise.data.image.IntensityImage` s.
+
+        Args:
+            info (Tuple[IntensityFileSeriesInfo]): The :class:`~pyradise.data.image.IntensityFileSeriesInfo` entries
+             containing the file paths to the images.
+            pixel_value_type (int): The pixel value type for the intensity images.
+
+        Returns:
+            Tuple[IntensityImage]: The loaded intensity :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        images = []
+        for info_entry in info:
+            image = sitk.ReadImage(info_entry.get_path()[0], pixel_value_type)
+            images.append(IntensityImage(image, info_entry.get_modality()))
+
+        return tuple(images)
+
+    @staticmethod
+    def _load_segmentation_images(
+        info: Tuple[SegmentationFileSeriesInfo], pixel_value_type: sitk.sitkUInt8
+    ) -> Tuple[SegmentationImage]:
+        """Load the :class:`~pyradise.data.image.SegmentationImage` s.
+
+        Args:
+            info (Tuple[SegmentationFileSeriesInfo]): The
+             :class:`~pyradise.fileio.series_info.SegmentationFileSeriesInfo` entries containing the file paths to
+             the images.
+            pixel_value_type (int): The pixel value type for the segmentation images.
+
+        Returns:
+            Tuple[SegmentationImage]: The loaded :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+        images = []
+        for info_entry in info:
+            image = sitk.ReadImage(info_entry.get_path()[0], pixel_value_type)
+            images.append(SegmentationImage(image, info_entry.get_organ(), info_entry.get_annotator()))
+
+        return tuple(images)
+
+    @staticmethod
+    def _validate_patient_identification(info: Tuple[SeriesInfo]) -> bool:
+        """Validate the patient identification of the provided :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+
+        Args:
+            info (Tuple[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to check.
+
+        Returns:
+            bool: True if the patient identification is valid for all info entries, otherwise False.
+        """
+        if not info:
+            return False
+
+        names = [entry.get_patient_name() for entry in info]
+        ids = [entry.get_patient_id() for entry in info]
+
+        return all(name == names[0] for name in names) and all(id_ == ids[0] for id_ in ids)
+
+    @staticmethod
+    def _validate_registration(
+        reg_info: Tuple[DicomSeriesRegistrationInfo], image_info: Tuple[DicomSeriesImageInfo]
+    ) -> bool:
+        """Validate the ReferencedSeriesInstanceUIDs of the provided
+        :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries by checking if the referenced DICOM
+        image data is provided.
+
+        Args:
+            reg_info (Tuple[DicomSeriesRegistrationInfo]): The
+             :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries to check.
+            image_info (Tuple[DicomSeriesImageInfo]): The :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo`
+             entries containing the referenced SeriesInstanceUIDs.
+
+        Returns:
+            bool: True if the image infos for all registration infos is available, otherwise False.
+
+        """
+
+        def is_image_info_available(instance_uids: List[str], image_info_: Tuple[DicomSeriesImageInfo]) -> bool:
+            comparison = [[info.series_instance_uid == uid for info in image_info_] for uid in instance_uids]
+            return all(any(comparison_) for comparison_ in comparison)
+
+        if not reg_info:
+            return True
+
+        if not image_info:
+            return False
+
+        identity_uids = []
+        transform_uids = []
+        for reg_info_entry in reg_info:
+            reg_info_entry.update() if not reg_info_entry.is_updated() else None
+
+            identity = reg_info_entry.referenced_series_instance_uid_identity
+            if identity != "":
+                identity_uids.append(identity)
+
+            transform = reg_info_entry.referenced_series_instance_uid_transform
+            if transform != "":
+                transform_uids.append(transform)
+
+        if is_image_info_available(identity_uids, image_info) and is_image_info_available(transform_uids, image_info):
+            return True
+
+        return False
+
+    @staticmethod
+    def _validate_rtss_info(rtss_info: Tuple[DicomSeriesRTSSInfo], image_info: Tuple[DicomSeriesImageInfo]) -> bool:
+        """Validate if all SeriesInstanceUIDs referenced in the DICOM-RTSSs are provided.
+
+        Args:
+            rtss_info (Tuple[DicomSeriesRTSSInfo]): The :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo`
+             entries to check.
+            image_info (Tuple[DicomSeriesImageInfo]): The :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo`
+             entries containing the SeriesInstanceUIDs.
+
+        Returns:
+            bool: True if the referenced image infos for all RTSS infos are available, otherwise False.
+        """
+        if not rtss_info:
+            return True
+
+        if not image_info:
+            return False
+
+        comparison = [
+            any(info.series_instance_uid == rtss_info_entry.referenced_instance_uid for info in image_info)
+            for rtss_info_entry in rtss_info
+        ]
+
+        return all(comparison)
+
+    def load(self, info: Tuple[SeriesInfo, ...]) -> Subject:
+        """Load a :class:`~pyradise.data.subject.Subject` from the provided
+        :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+
+        Args:
+            info (Tuple[SeriesInfo, ...]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries containing the
+             necessary information for loading the subject.
+
+        Raises:
+            ValueError: If ``info`` is an empty tuple.
+            ValueError: If ``info`` is not a tuple of :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+            ValueError: If the patient name and patient id of the provided
+             :class:`~pyradise.fileio.series_info.SeriesInfo` entries are not equal.
+            ValueError: If not all referenced :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries are
+             provided for registration.
+            ValueError: If not all referenced :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries are
+             provided for RTSS loading.
+
+        Returns:
+            Subject: The loaded subject.
+
+        """
+        # check if the info entries have the correct structure
+        if not info:
+            raise ValueError("The provided info entries are empty.")
+
+        if not all(isinstance(entry, SeriesInfo) for entry in info):
+            raise ValueError(
+                "The provided info entries are not of type SeriesInfo. "
+                "Make sure to provide a tuple of SeriesInfo entries."
+            )
+
+        # separate the info entries
+        dicom_image_info = self._extract_info_by_type(info, DicomSeriesImageInfo)
+        dicom_reg_info = self._extract_info_by_type(info, DicomSeriesRegistrationInfo)
+        dicom_rtss_info = self._extract_info_by_type(info, DicomSeriesRTSSInfo)
+        intensity_image_info = self._extract_info_by_type(info, IntensityFileSeriesInfo)
+        segmentation_image_info = self._extract_info_by_type(info, SegmentationFileSeriesInfo)
+
+        # validate the info entries
+        if not self._validate_patient_identification(info):
+            raise ValueError("The patient identification (patient_name and patient_id) is not unique!")
+
+        if not self._validate_registration(dicom_reg_info, dicom_image_info):
+            raise ValueError("At least one referenced image in the registration is missing!")
+
+        if not self._validate_rtss_info(dicom_rtss_info, dicom_image_info):
+            raise ValueError("The referenced image in the RTSS is not available!")
+
+        # create the subject
+        if dicom_image_info:
+            subject = Subject(dicom_image_info[0].get_patient_name())
+        elif intensity_image_info:
+            subject = Subject(intensity_image_info[0].get_patient_name())
+        elif segmentation_image_info:
+            subject = Subject(segmentation_image_info[0].get_patient_name())
+        else:
+            raise ValueError("Subject can not be constructed because a subject name is missing!")
+
+        # load the images and add them to the subject
+        if dicom_image_info:
+            dicom_images = DicomImageSeriesConverter(dicom_image_info, dicom_reg_info).convert()
+            subject.add_images(dicom_images)
+
+        if dicom_rtss_info:
+            dicom_segmentations = DicomRTSSSeriesConverter(
+                dicom_rtss_info, dicom_image_info, dicom_reg_info, self.fill_hole_distance
+            ).convert()
+            subject.add_images(dicom_segmentations, force=True)
+
+        intensity_images = self._load_intensity_images(intensity_image_info, self.intensity_pixel_type)
+        segmentation_images = self._load_segmentation_images(segmentation_image_info, self.segmentation_pixel_type)
+        subject.add_images(intensity_images + segmentation_images, force=True)
+
+        return subject
+
+
+class IterableSubjectLoader(Loader):
+    """An :class:`Loader` for loading a sequence of :class:`~pyradise.data.subject.Subject` s based on their
+    :class:`~pyradise.fileio.series_info.SeriesInfo` entries. This loader can load both DICOM data (i.e.
+    :class:`~pyradise.fileio.series_info.DicomSeriesInfo`) and discrete image data (i.e.
+    :class:`~pyradise.fileio.series_info.FileSeriesInfo`). The loader validates the provided
+    :class:`~pyradise.fileio.series_info.SeriesInfo` entries before loading and raises appropriate errors if the
+    information is not valid.
+
+    Notes:
+        For loading large DICOM dataset we recommend to use the :class:`SubjectLoader` instead because the antecedent
+        crawling process can require a lot of computation time and memory.
+
+    Raises:
+        ValueError: If ``info`` is an empty tuple.
+        ValueError: If ``info`` is not a tuple of tuples of :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+
+    Args:
+        info (Tuple[Tuple[SeriesInfo, ...], ...]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries for all
+         subjects to load.
+        intensity_pixel_value_type (int): The pixel value type of the intensity imagesm when loading discrete image
+         files (default: sitk.sitkFloat32).
+        segmentation_pixel_value_type (int): The pixel value type of the segmentation images when loading discrete
+         files (default: sitk.sitkUInt8).
+        fill_hole_search_distance (int): The search distance for the hole filling algorithm. If the search distance is
+         set to zero the hole filling algorithm is omitted. The search distance must be an odd number larger than 1
+         (default: 0).
+
+    Examples:
+
+        Load, normalize and save a NIFTI dataset with multiple subjects:
+
+        >>> from argparse import ArgumentParser
+        >>> from pyradise.fileio import (DatasetFileCrawler, IterableSubjectLoader,
+        >>>                              SubjectWriter)
+        >>> from pyradise.process import (ZScoreNormFilter,
+        >>>                               ZScoreNormFilterParams)
+        >>>
+        >>>
+        >>> def main(input_path: str, output_path: str) -> None:
+        >>>     # Crawl the dataset info
+        >>>     info = DatasetFileCrawler(input_path, '.nii.gz').execute()
+        >>>
+        >>>     # Construct the loader
+        >>>     loader = IterableSubjectLoader(info)
+        >>>
+        >>>     # Construct the normalization filter
+        >>>     normalization_params = ZScoreNormFilterParams(loop_axis=1)
+        >>>     normalization_filter = ZScoreNormFilter(normalization_params)
+        >>>
+        >>>     # Construct the writer
+        >>>     writer = SubjectWriter()
+        >>>
+        >>>     # Iteratively load the subjects
+        >>>     for subject in loader:
+        >>>         # Normalize the images
+        >>>         subject = normalization_filter.execute(subject)
+        >>>
+        >>>         # Save the subject
+        >>>         writer.write_to_subject_folder(output_path, subject, write_transforms=False)
+        >>>
+        >>>
+        >>> if __name__ == '__main__':
+        >>>     parser = ArgumentParser()
+        >>>     parser.add_argument('--input_path', type=str,
+        >>>                         help='The dataset input directory.')
+        >>>     parser.add_argument('--output_path', type=str,
+        >>>                         help='The dataset output directory.')
+        >>>     args = parser.parse_args()
+        >>>
+        >>>     main(args.input_path, args.output_path)
+    """
+
+    def __init__(
+        self,
+        info: Tuple[Tuple[SeriesInfo, ...], ...],
+        intensity_pixel_value_type: int = sitk.sitkFloat32,
+        segmentation_pixel_value_type: int = sitk.sitkUInt8,
+        fill_hole_search_distance: int = 0,
+    ):
+        super().__init__()
+
+        if not info:
+            raise ValueError("The provided infos are empty.")
+        if not all(isinstance(entry, tuple) for entry in info):
+            raise ValueError(
+                "The provided first level info entries are not of type tuple. "
+                "Make sure that the info is a tuple of tuples."
+            )
+        self.info = info
+
+        self.intensity_pixel_type = intensity_pixel_value_type
+        self.segmentation_pixel_type = segmentation_pixel_value_type
+
+        # store the fill hole search distance
+        if fill_hole_search_distance == 0:
+            self.fill_hole_distance = 0
+        elif fill_hole_search_distance % 2 == 0:
+            raise ValueError("The fill hole search distance must be an odd number.")
+        elif fill_hole_search_distance == 1:
+            raise ValueError("The fill hole search distance must be larger than 1.")
+        else:
+            self.fill_hole_distance = fill_hole_search_distance
+
+        self.current_idx = 0
+        self.num_subjects = len(self.info)
+
+    def __iter__(self):
+        self.current_idx = 0
+        return self
+
+    def __next__(self) -> Subject:
+        if self.current_idx < self.num_subjects:
+            loader = SubjectLoader(self.intensity_pixel_type, self.segmentation_pixel_type, self.fill_hole_distance)
+            subject = loader.load(self.info[self.current_idx])
+            self.current_idx += 1
+            return subject
+
+        raise StopIteration()
+
+    def __len__(self):
+        return self.num_subjects
```

### Comparing `pyradise-0.2.2/pyradise/fileio/selection.py` & `pyradise-0.2.3/pyradise/fileio/selection.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,301 +1,301 @@
-from abc import ABC, abstractmethod
-from typing import List, Sequence, Tuple, Union
-
-from pyradise.data import (Annotator, Modality, Organ, seq_to_annotators,
-                           seq_to_modalities, seq_to_organs)
-
-from .series_info import (DicomSeriesImageInfo, DicomSeriesInfo,
-                          DicomSeriesRegistrationInfo, DicomSeriesRTSSInfo,
-                          IntensityFileSeriesInfo, SegmentationFileSeriesInfo,
-                          SeriesInfo)
-
-__all__ = [
-    "SeriesInfoSelector",
-    "SeriesInfoSelectorPipeline",
-    "ModalityInfoSelector",
-    "OrganInfoSelector",
-    "AnnotatorInfoSelector",
-    "NoRegistrationInfoSelector",
-    "NoRTSSInfoSelector",
-]
-
-
-class SeriesInfoSelector(ABC):
-    """An abstract base class for all :class:`SeriesInfoSelector` classes. A selector is used to select a subset of
-    :class:`~pyradise.fileio.series_info.SeriesInfo` entries from a list of
-    :class:`~pyradise.fileio.series_info.SeriesInfo` entries such that unused entries will be excluded from the loading
-    and probable conversion procedures. The aim of using a selector is to improve speed and reduce memory usage while
-    allowing the input directory to contain unused data.
-    """
-
-    @abstractmethod
-    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
-        """Perform the selection procedure such that the appropriate :class:`~pyradise.fileio.series_info.SeriesInfo`
-        entries are kept.
-
-        Args:
-            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select from.
-
-        Returns:
-            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-        """
-        raise NotImplementedError()
-
-
-class SeriesInfoSelectorPipeline:
-    """A class for constructing :class:`SeriesInfoSelector` pipelines. A pipeline is a sequence of
-    :class:`SeriesInfoSelector` s that are executed sequentially in a given order. The output of one selector is the
-    input of the next selector.
-
-    Args:
-        selectors (Sequence[SeriesInfoSelector]): The :class:`SeriesInfoSelector` s of the pipeline in a given order.
-    """
-
-    def __init__(self, selectors: Sequence[SeriesInfoSelector]) -> None:
-        super().__init__()
-
-        self.selectors: List[SeriesInfoSelector] = [selector for selector in selectors]
-
-    def add_selector(self, selector: SeriesInfoSelector) -> None:
-        """Add a :class:`SeriesInfoSelector` to the pipeline.
-
-        Args:
-            selector (SeriesInfoSelector): The :class:`SeriesInfoSelector` to add.
-        """
-        self.selectors.append(selector)
-
-    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
-        """Perform the selection of the :class:`~pyradise.fileio.series_info.SeriesInfo` entries according to
-        the :class:`SeriesInfoSelector` s specified.
-
-        Args:
-            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select
-             from.
-
-        Returns:
-            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-        """
-        for selector in self.selectors:
-            infos = selector.execute(infos)
-        return infos
-
-
-class ModalityInfoSelector(SeriesInfoSelector):
-    """A :class:`SeriesInfoSelector` to remove all :class:`~pyradise.fileio.series_info.IntensityFileSeriesInfo` and
-    :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries that do not have a matching
-    :class:`~pyradise.data.modality.Modality`.
-
-     Note:
-         If a :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entry is removed, the associated
-         :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entry is also removed because a
-         registration always requires both referenced registration images.
-
-
-     Args:
-         keep (Tuple[Union[Modality, str], ...]): The :class:`~pyradise.data.modality.Modality` entries of
-          the :class:`~pyradise.fileio.series_info.SeriesInfo` entries to keep.
-    """
-
-    def __init__(self, keep: Tuple[Union[Modality, str], ...]) -> None:
-        super().__init__()
-
-        assert keep, "The modalities to keep must not be empty!"
-        self.keep: Tuple[Modality, ...] = seq_to_modalities(keep)
-
-    # noinspection DuplicatedCode
-    # pylint: disable=duplicate-code
-    @staticmethod
-    def _remove_unused_registration_infos(infos: Tuple[SeriesInfo]) -> Tuple[SeriesInfo]:
-        """Remove all :class:`DicomSeriesRegistrationInfo` entries that are not used anymore.
-
-        Args:
-            infos (List[DicomSeriesInfo]): The :class:`DicomSeriesInfo` entries to analyze.
-        """
-
-        registration_infos = [entry for entry in infos if isinstance(entry, DicomSeriesRegistrationInfo)]
-        image_infos = [entry for entry in infos if isinstance(entry, DicomSeriesImageInfo)]
-
-        remove_indices = []
-        for i, registration_info in enumerate(registration_infos):
-            criteria = [
-                entry.series_instance_uid == registration_info.referenced_series_instance_uid_transform
-                for entry in image_infos
-            ]
-
-            if not any(criteria):
-                remove_indices.append(i)
-
-        for index in reversed(remove_indices):
-            registration_infos.pop(index)
-
-        keep = [entry for entry in infos if not isinstance(entry, DicomSeriesRegistrationInfo)]
-        keep.extend(registration_infos)
-        return tuple(keep)
-
-    # noinspection DuplicatedCode
-    # pylint: disable=duplicate-code
-    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
-        """Remove all :class:`~pyradise.fileio.series_info.IntensityFileSeriesInfo` and
-        :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries that do not contain
-        one of the specified :class:`~pyradise.data.modality.Modality` entries.
-
-        Args:
-            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select
-             from.
-
-        Returns:
-            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-        """
-        assert infos, "The series infos must not be empty!"
-
-        selected: List[SeriesInfo] = []
-        for info in infos:
-            if isinstance(info, IntensityFileSeriesInfo):
-                if info.modality in self.keep:
-                    selected.append(info)
-
-            elif isinstance(info, DicomSeriesImageInfo):
-                if info.get_modality() in self.keep:
-                    selected.append(info)
-            else:
-                selected.append(info)
-
-        return self._remove_unused_registration_infos(tuple(selected))
-
-
-class OrganInfoSelector(SeriesInfoSelector):
-    """A :class:`SeriesInfoSelector` to remove all :class:`~pyradise.fileio.series_info.SegmentationFileSeriesInfo`
-    entries that do not have a matching :class:`~pyradise.data.organ.Organ`.
-
-    Important:
-        This selector does not remove :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` entries
-        because a DICOM-RTSS contains multiple organs and the information about the organs is not retrieved before
-        loading.
-
-    Args:
-        keep (Tuple[Union[Organ, str], ...]): The :class:`~pyradise.data.organ.Organ` entries of the
-         :class:`~pyradise.fileio.series_info.SeriesInfo` entries to keep.
-
-    """
-
-    def __init__(self, keep: Tuple[Union[Organ, str], ...]) -> None:
-        super().__init__()
-
-        assert keep, "The organs to keep must not be empty!"
-        self.keep: Tuple[Organ, ...] = seq_to_organs(keep)
-
-    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
-        """Remove all :class:`~pyradise.fileio.series_info.SegmentationFileSeriesInfo` entries that do not contain
-        one of the specified :class:`~pyradise.data.organ.Organ` entries.
-
-        Args:
-            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select from.
-
-        Returns:
-            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-        """
-        assert infos, "The series infos must not be empty!"
-
-        selected: List[SeriesInfo] = []
-        for info in infos:
-            if isinstance(info, SegmentationFileSeriesInfo):
-                if info.organ in self.keep:
-                    selected.append(info)
-            else:
-                selected.append(info)
-
-        return tuple(selected)
-
-
-class AnnotatorInfoSelector(SeriesInfoSelector):
-    """A :class:`SeriesInfoSelector` to remove all :class:`~pyradise.fileio.series_info.SegmentationFileSeriesInfo` and
-    :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` entries that do not have a matching
-    :class:`~pyradise.data.annotator.Annotator`.
-
-    Args:
-        keep (Tuple[Union[Annotator, str], ...]): The :class:`~pyradise.data.annotator.Annotator` entries of the
-         :class:`~pyradise.fileio.series_info.SeriesInfo` entries to keep.
-    """
-
-    def __init__(self, keep: Tuple[Union[Annotator, str], ...]) -> None:
-        super().__init__()
-
-        assert keep, "The annotators to keep must not be empty!"
-        self.keep: Tuple[Annotator, ...] = seq_to_annotators(keep)
-
-    # noinspection DuplicatedCode
-    # pylint: disable=duplicate-code
-    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
-        """Remove all :class:`~pyradise.fileio.series_info.SegmentationFileSeriesInfo` and
-        :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` entries that do not contain one of the specified
-        :class:`~pyradise.data.annotator.Annotator` entries.
-
-        Args:
-            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select from.
-
-        Returns:
-            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-        """
-        assert infos, "The series infos must not be empty!"
-
-        selected: List[SeriesInfo] = []
-        for info in infos:
-            if isinstance(info, SegmentationFileSeriesInfo):
-                if info.get_annotator() in self.keep:
-                    selected.append(info)
-
-            elif isinstance(info, DicomSeriesRTSSInfo):
-                if info.annotator in self.keep:
-                    selected.append(info)
-            else:
-                selected.append(info)
-
-        return tuple(selected)
-
-
-class NoRegistrationInfoSelector(SeriesInfoSelector):
-    """A :class:`SeriesInfoSelector` to remove all :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo`
-    entries such that no registration is applied during loading."""
-
-    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
-        """Remove all :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries from the provided
-        :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-
-        Args:
-            infos (Tuple[SeriesInfo, ...]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select from.
-
-        Returns:
-            Sequence[SeriesInfo]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-        """
-        assert infos, "The series infos must not be empty!"
-
-        selected: List[SeriesInfo] = []
-        for info in infos:
-            if not isinstance(info, DicomSeriesRegistrationInfo):
-                selected.append(info)
-
-        return tuple(selected)
-
-
-class NoRTSSInfoSelector(SeriesInfoSelector):
-    """A :class:`SeriesInfoSelector` to remove all :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo`
-    entries such that all DICOM-RTSS data is excluded from loading."""
-
-    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
-        """Remove all :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` entries from the provided
-        :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-
-        Args:
-            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select from.
-
-        Returns:
-            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
-        """
-        assert infos, "The series infos must not be empty!"
-
-        selected: List[SeriesInfo] = []
-        for info in infos:
-            if not isinstance(info, DicomSeriesRTSSInfo):
-                selected.append(info)
-
-        return tuple(selected)
+from abc import ABC, abstractmethod
+from typing import List, Sequence, Tuple, Union
+
+from pyradise.data import (Annotator, Modality, Organ, seq_to_annotators,
+                           seq_to_modalities, seq_to_organs)
+
+from .series_info import (DicomSeriesImageInfo, DicomSeriesInfo,
+                          DicomSeriesRegistrationInfo, DicomSeriesRTSSInfo,
+                          IntensityFileSeriesInfo, SegmentationFileSeriesInfo,
+                          SeriesInfo)
+
+__all__ = [
+    "SeriesInfoSelector",
+    "SeriesInfoSelectorPipeline",
+    "ModalityInfoSelector",
+    "OrganInfoSelector",
+    "AnnotatorInfoSelector",
+    "NoRegistrationInfoSelector",
+    "NoRTSSInfoSelector",
+]
+
+
+class SeriesInfoSelector(ABC):
+    """An abstract base class for all :class:`SeriesInfoSelector` classes. A selector is used to select a subset of
+    :class:`~pyradise.fileio.series_info.SeriesInfo` entries from a list of
+    :class:`~pyradise.fileio.series_info.SeriesInfo` entries such that unused entries will be excluded from the loading
+    and probable conversion procedures. The aim of using a selector is to improve speed and reduce memory usage while
+    allowing the input directory to contain unused data.
+    """
+
+    @abstractmethod
+    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
+        """Perform the selection procedure such that the appropriate :class:`~pyradise.fileio.series_info.SeriesInfo`
+        entries are kept.
+
+        Args:
+            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select from.
+
+        Returns:
+            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+        """
+        raise NotImplementedError()
+
+
+class SeriesInfoSelectorPipeline:
+    """A class for constructing :class:`SeriesInfoSelector` pipelines. A pipeline is a sequence of
+    :class:`SeriesInfoSelector` s that are executed sequentially in a given order. The output of one selector is the
+    input of the next selector.
+
+    Args:
+        selectors (Sequence[SeriesInfoSelector]): The :class:`SeriesInfoSelector` s of the pipeline in a given order.
+    """
+
+    def __init__(self, selectors: Sequence[SeriesInfoSelector]) -> None:
+        super().__init__()
+
+        self.selectors: List[SeriesInfoSelector] = [selector for selector in selectors]
+
+    def add_selector(self, selector: SeriesInfoSelector) -> None:
+        """Add a :class:`SeriesInfoSelector` to the pipeline.
+
+        Args:
+            selector (SeriesInfoSelector): The :class:`SeriesInfoSelector` to add.
+        """
+        self.selectors.append(selector)
+
+    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
+        """Perform the selection of the :class:`~pyradise.fileio.series_info.SeriesInfo` entries according to
+        the :class:`SeriesInfoSelector` s specified.
+
+        Args:
+            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select
+             from.
+
+        Returns:
+            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+        """
+        for selector in self.selectors:
+            infos = selector.execute(infos)
+        return infos
+
+
+class ModalityInfoSelector(SeriesInfoSelector):
+    """A :class:`SeriesInfoSelector` to remove all :class:`~pyradise.fileio.series_info.IntensityFileSeriesInfo` and
+    :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries that do not have a matching
+    :class:`~pyradise.data.modality.Modality`.
+
+     Note:
+         If a :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entry is removed, the associated
+         :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entry is also removed because a
+         registration always requires both referenced registration images.
+
+
+     Args:
+         keep (Tuple[Union[Modality, str], ...]): The :class:`~pyradise.data.modality.Modality` entries of
+          the :class:`~pyradise.fileio.series_info.SeriesInfo` entries to keep.
+    """
+
+    def __init__(self, keep: Tuple[Union[Modality, str], ...]) -> None:
+        super().__init__()
+
+        assert keep, "The modalities to keep must not be empty!"
+        self.keep: Tuple[Modality, ...] = seq_to_modalities(keep)
+
+    # noinspection DuplicatedCode
+    # pylint: disable=duplicate-code
+    @staticmethod
+    def _remove_unused_registration_infos(infos: Tuple[SeriesInfo]) -> Tuple[SeriesInfo]:
+        """Remove all :class:`DicomSeriesRegistrationInfo` entries that are not used anymore.
+
+        Args:
+            infos (List[DicomSeriesInfo]): The :class:`DicomSeriesInfo` entries to analyze.
+        """
+
+        registration_infos = [entry for entry in infos if isinstance(entry, DicomSeriesRegistrationInfo)]
+        image_infos = [entry for entry in infos if isinstance(entry, DicomSeriesImageInfo)]
+
+        remove_indices = []
+        for i, registration_info in enumerate(registration_infos):
+            criteria = [
+                entry.series_instance_uid == registration_info.referenced_series_instance_uid_transform
+                for entry in image_infos
+            ]
+
+            if not any(criteria):
+                remove_indices.append(i)
+
+        for index in reversed(remove_indices):
+            registration_infos.pop(index)
+
+        keep = [entry for entry in infos if not isinstance(entry, DicomSeriesRegistrationInfo)]
+        keep.extend(registration_infos)
+        return tuple(keep)
+
+    # noinspection DuplicatedCode
+    # pylint: disable=duplicate-code
+    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
+        """Remove all :class:`~pyradise.fileio.series_info.IntensityFileSeriesInfo` and
+        :class:`~pyradise.fileio.series_info.DicomSeriesImageInfo` entries that do not contain
+        one of the specified :class:`~pyradise.data.modality.Modality` entries.
+
+        Args:
+            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select
+             from.
+
+        Returns:
+            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+        """
+        assert infos, "The series infos must not be empty!"
+
+        selected: List[SeriesInfo] = []
+        for info in infos:
+            if isinstance(info, IntensityFileSeriesInfo):
+                if info.modality in self.keep:
+                    selected.append(info)
+
+            elif isinstance(info, DicomSeriesImageInfo):
+                if info.get_modality() in self.keep:
+                    selected.append(info)
+            else:
+                selected.append(info)
+
+        return self._remove_unused_registration_infos(tuple(selected))
+
+
+class OrganInfoSelector(SeriesInfoSelector):
+    """A :class:`SeriesInfoSelector` to remove all :class:`~pyradise.fileio.series_info.SegmentationFileSeriesInfo`
+    entries that do not have a matching :class:`~pyradise.data.organ.Organ`.
+
+    Important:
+        This selector does not remove :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` entries
+        because a DICOM-RTSS contains multiple organs and the information about the organs is not retrieved before
+        loading.
+
+    Args:
+        keep (Tuple[Union[Organ, str], ...]): The :class:`~pyradise.data.organ.Organ` entries of the
+         :class:`~pyradise.fileio.series_info.SeriesInfo` entries to keep.
+
+    """
+
+    def __init__(self, keep: Tuple[Union[Organ, str], ...]) -> None:
+        super().__init__()
+
+        assert keep, "The organs to keep must not be empty!"
+        self.keep: Tuple[Organ, ...] = seq_to_organs(keep)
+
+    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
+        """Remove all :class:`~pyradise.fileio.series_info.SegmentationFileSeriesInfo` entries that do not contain
+        one of the specified :class:`~pyradise.data.organ.Organ` entries.
+
+        Args:
+            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select from.
+
+        Returns:
+            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+        """
+        assert infos, "The series infos must not be empty!"
+
+        selected: List[SeriesInfo] = []
+        for info in infos:
+            if isinstance(info, SegmentationFileSeriesInfo):
+                if info.organ in self.keep:
+                    selected.append(info)
+            else:
+                selected.append(info)
+
+        return tuple(selected)
+
+
+class AnnotatorInfoSelector(SeriesInfoSelector):
+    """A :class:`SeriesInfoSelector` to remove all :class:`~pyradise.fileio.series_info.SegmentationFileSeriesInfo` and
+    :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` entries that do not have a matching
+    :class:`~pyradise.data.annotator.Annotator`.
+
+    Args:
+        keep (Tuple[Union[Annotator, str], ...]): The :class:`~pyradise.data.annotator.Annotator` entries of the
+         :class:`~pyradise.fileio.series_info.SeriesInfo` entries to keep.
+    """
+
+    def __init__(self, keep: Tuple[Union[Annotator, str], ...]) -> None:
+        super().__init__()
+
+        assert keep, "The annotators to keep must not be empty!"
+        self.keep: Tuple[Annotator, ...] = seq_to_annotators(keep)
+
+    # noinspection DuplicatedCode
+    # pylint: disable=duplicate-code
+    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
+        """Remove all :class:`~pyradise.fileio.series_info.SegmentationFileSeriesInfo` and
+        :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` entries that do not contain one of the specified
+        :class:`~pyradise.data.annotator.Annotator` entries.
+
+        Args:
+            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select from.
+
+        Returns:
+            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+        """
+        assert infos, "The series infos must not be empty!"
+
+        selected: List[SeriesInfo] = []
+        for info in infos:
+            if isinstance(info, SegmentationFileSeriesInfo):
+                if info.get_annotator() in self.keep:
+                    selected.append(info)
+
+            elif isinstance(info, DicomSeriesRTSSInfo):
+                if info.annotator in self.keep:
+                    selected.append(info)
+            else:
+                selected.append(info)
+
+        return tuple(selected)
+
+
+class NoRegistrationInfoSelector(SeriesInfoSelector):
+    """A :class:`SeriesInfoSelector` to remove all :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo`
+    entries such that no registration is applied during loading."""
+
+    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
+        """Remove all :class:`~pyradise.fileio.series_info.DicomSeriesRegistrationInfo` entries from the provided
+        :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+
+        Args:
+            infos (Tuple[SeriesInfo, ...]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select from.
+
+        Returns:
+            Sequence[SeriesInfo]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+        """
+        assert infos, "The series infos must not be empty!"
+
+        selected: List[SeriesInfo] = []
+        for info in infos:
+            if not isinstance(info, DicomSeriesRegistrationInfo):
+                selected.append(info)
+
+        return tuple(selected)
+
+
+class NoRTSSInfoSelector(SeriesInfoSelector):
+    """A :class:`SeriesInfoSelector` to remove all :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo`
+    entries such that all DICOM-RTSS data is excluded from loading."""
+
+    def execute(self, infos: Sequence[SeriesInfo]) -> Tuple[SeriesInfo, ...]:
+        """Remove all :class:`~pyradise.fileio.series_info.DicomSeriesRTSSInfo` entries from the provided
+        :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+
+        Args:
+            infos (Sequence[SeriesInfo]): The :class:`~pyradise.fileio.series_info.SeriesInfo` entries to select from.
+
+        Returns:
+            Tuple[SeriesInfo, ...]: The selected :class:`~pyradise.fileio.series_info.SeriesInfo` entries.
+        """
+        assert infos, "The series infos must not be empty!"
+
+        selected: List[SeriesInfo] = []
+        for info in infos:
+            if not isinstance(info, DicomSeriesRTSSInfo):
+                selected.append(info)
+
+        return tuple(selected)
```

### Comparing `pyradise-0.2.2/pyradise/fileio/series_info.py` & `pyradise-0.2.3/pyradise/fileio/series_info.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,912 +1,912 @@
-import re
-import warnings
-from abc import ABC, abstractmethod
-from dataclasses import dataclass
-from typing import List, Optional, Sequence, Tuple, Union
-
-import numpy as np
-import SimpleITK as sitk
-from pydicom import Dataset
-from pydicom.tag import Tag
-
-from pyradise.data import (Annotator, Modality, Organ, str_to_annotator,
-                           str_to_modality, str_to_organ)
-from pyradise.utils import (is_dir_and_exists, is_file_and_exists,
-                            load_dataset, load_dataset_tag)
-
-__all__ = [
-    "SeriesInfo",
-    "FileSeriesInfo",
-    "IntensityFileSeriesInfo",
-    "SegmentationFileSeriesInfo",
-    "DicomSeriesInfo",
-    "DicomSeriesImageInfo",
-    "DicomSeriesRegistrationInfo",
-    "DicomSeriesRTSSInfo",
-    "ReferenceInfo",
-    "RegistrationInfo",
-    "RegistrationSequenceInfo",
-]
-
-
-class SeriesInfo(ABC):
-    """An abstract base class for all :class:`SeriesInfo` classes. A :class:`SeriesInfo` class is used to retrieve and
-    store content-specific information which is required by the :class:`~pyradise.fileio.loading.SubjectLoader` in
-    order to correctly load the data and to construct a :class:`~pyradise.data.subject.Subject`.
-
-    Depending on the type of data, the :class:`SeriesInfo` subclasses retrieve different information which is essential
-    for loading and :class:`~pyradise.data.subject.Subject` construction. For example, the
-    :class:`DicomSeriesImageInfo` retrieves and holds data about the :class:`~pyradise.data.modality.Modality`
-    whereas the :class:`DicomSeriesRTSSInfo` manages information about the :class:`~pyradise.data.annotator.Annotator`
-    and information about the referenced DICOM image series.
-
-    Args:
-        path (Union[str, Tuple[str, ...]]): The path or paths to the files to load.
-    """
-
-    def __init__(self, path: Union[str, Tuple[str, ...]]) -> None:
-        super().__init__()
-
-        if isinstance(path, str):
-            self.path = (path,)
-        else:
-            self.path = path
-
-        self._check_paths(self.path)
-
-        self.patient_name = ""
-        self.patient_id = ""
-
-        self._is_updated = False
-
-    @staticmethod
-    def _check_paths(paths: Union[str, Tuple[str, ...]], should_be_dir: bool = False) -> None:
-        """Check if the provided paths are files/directories.
-
-        Args:
-            paths (Union[str, Tuple[str, ...]]): The paths for checking.
-            should_be_dir (bool): If True the paths will be checked if they are directories.
-
-        Returns:
-            None
-        """
-        if isinstance(paths, str):
-            internal_path = (paths,)
-        else:
-            internal_path = paths
-
-        for path in internal_path:
-            if should_be_dir:
-                is_dir_and_exists(path)
-
-            else:
-                is_file_and_exists(path)
-
-    def get_path(self) -> Tuple[str]:
-        """Get the file paths assigned to the :class:`SeriesInfo` instance.
-
-        Returns:
-            Tuple[str]: The file paths assigned to the :class:`SeriesInfo` instance.
-        """
-        return self.path
-
-    def get_patient_name(self) -> str:
-        """Get the patient name.
-
-        Returns:
-            str: The patient name.
-        """
-        return self.patient_name
-
-    def get_patient_id(self) -> str:
-        """Get the patient ID.
-
-        Returns:
-            str: The patient ID.
-        """
-        return self.patient_id
-
-    def is_updated(self) -> bool:
-        """Check if is updated.
-
-        Returns:
-            bool: True if is updated, False otherwise.
-        """
-        return self._is_updated
-
-    @abstractmethod
-    def update(self) -> None:
-        """Update the :class:`SeriesInfo` instance.
-
-        Returns:
-            None
-        """
-        raise NotImplementedError()
-
-
-class FileSeriesInfo(SeriesInfo):
-    """An abstract base :class:`SeriesInfo` class for all discrete image files (e.g. NIFTI, NRRD, MHA, etc.).
-
-    Important:
-        For DICOM files use a  :class:`DicomSeriesInfo` subclass instead.
-
-    Args:
-        path (str): The path to the discrete image file to load.
-        subject_name (str): The name of the subject.
-    """
-
-    def __init__(self, path: str, subject_name: str) -> None:
-        super().__init__(path)
-
-        # remove illegal characters in the subject name
-        subject_name_ = subject_name.replace(" ", "_")
-        pattern = r"""[^\da-zA-Z_-]+"""
-        regex = re.compile(pattern)
-
-        # to stay consistent the subject name is called patient name as for DICOM info
-        self.patient_name = regex.sub(r"", subject_name_)
-        self.patient_id = self.patient_name
-
-    @abstractmethod
-    def update(self) -> None:
-        """Update the :class:`FileSeriesInfo` instance.
-
-        Returns:
-            None
-        """
-        raise NotImplementedError()
-
-
-class IntensityFileSeriesInfo(FileSeriesInfo):
-    """A :class:`FileSeriesInfo` class for intensity images. In addition to the information provided by the
-    :class:`FileSeriesInfo` class, this class contains also a :class:`~pyradise.data.modality.Modality` instance.
-
-    Args:
-        path (str): The path to the discrete intensity image file to load.
-        subject_name (str): The name of the subject.
-        modality (Union[str, Modality]): The modality of the intensity image.
-    """
-
-    def __init__(self, path: str, subject_name: str, modality: Union[Modality, str]) -> None:
-        if not isinstance(path, str):
-            raise TypeError(f"Expected a string for the path but got {type(path)} instead.")
-        super().__init__(path, subject_name)
-
-        self.modality: Modality = str_to_modality(modality)
-
-        self.update()
-
-    def get_modality(self) -> Modality:
-        """Get the :class:`~pyradise.data.modality.Modality`.
-
-        Returns:
-            Modality: The :class:`~pyradise.data.modality.Modality`.
-        """
-        return self.modality
-
-    def set_modality(self, modality: Modality) -> None:
-        """Set the :class:`~pyradise.data.modality.Modality`.
-
-        Args:
-            modality (Modality): The :class:`~pyradise.data.modality.Modality` to be set.
-
-        Returns:
-            None
-        """
-        self.modality: Modality = modality
-
-    def update(self) -> None:
-        """Update the :class:`IntensityFileSeriesInfo`.
-
-        Returns:
-            None
-        """
-        self._is_updated = True
-
-
-class SegmentationFileSeriesInfo(FileSeriesInfo):
-    """A :class:`FileSeriesInfo` class for segmentation images. In addition to the information provided by the
-    :class:`FileSeriesInfo` class, this class contains also an :class:`~pyradise.data.organ.Organ` instance and a
-    :class:`~pyradise.data.annotator.Annotator` instance.
-
-    Note:
-        We assume that the segmentation image is a binary image with the foreground having the value 1 and the
-        background being 0. If your images are different we recommend to separate the segmentation masks into separate
-        files because in RT practice segmentations may overlap.
-
-    Args:
-        path (str): The path to the discrete segmentation image file to load.
-        subject_name (str): The name of the subject.
-        organ (Union[Organ, str]): The organ the segmentation is representing.
-        annotator (Union[Annotator, str]): The annotator who created the segmentation.
-    """
-
-    def __init__(
-        self, path: str, subject_name: str, organ: Union[Organ, str], annotator: Union[Annotator, str]
-    ) -> None:
-        if not isinstance(path, str):
-            raise TypeError(f"Expected a single path as a string but got {type(path)}.")
-        super().__init__(path, subject_name)
-
-        self.organ: Organ = str_to_organ(organ)
-        self.annotator: Annotator = str_to_annotator(annotator)
-
-        self.update()
-
-    def get_organ(self) -> Organ:
-        """Get the :class:`~pyradise.data.organ.Organ`.
-
-        Returns:
-            Organ: The :class:`~pyradise.data.organ.Organ`.
-        """
-        return self.organ
-
-    def set_organ(self, organ: Organ) -> None:
-        """Set the :class:`~pyradise.data.organ.Organ`.
-
-        Args:
-            organ (Organ): The :class:`~pyradise.data.organ.Organ` to be set.
-
-        Returns:
-            None
-        """
-        self.organ: Organ = organ
-
-    def get_annotator(self) -> Annotator:
-        """Get the :class:`~pyradise.data.annotator.Annotator`.
-
-        Returns:
-            Annotator: The :class:`~pyradise.data.annotator.Annotator`.
-        """
-        return self.annotator
-
-    def set_annotator(self, annotator: Annotator) -> None:
-        """Set the :class:`~pyradise.data.annotator.Annotator`.
-
-        Args:
-            annotator (Annotator): The :class:`~pyradise.data.annotator.Annotator` to be set.
-
-        Returns:
-            None
-        """
-        self.annotator: Annotator = annotator
-
-    def update(self) -> None:
-        """Update the :class:`SegmentationFileSeriesInfo` instance.
-
-        Returns:
-            None
-        """
-        self._is_updated = True
-
-
-class DicomSeriesInfo(SeriesInfo):
-    """An abstract base :class:`SeriesInfo` class for all DICOM data (i.e. DICOM image, DICOM registration, DICOM-RTSS).
-
-    Important:
-        For discrete image files use a  :class:`FileSeriesInfo` subclass instead.
-
-    Args:
-        path (Union[str, Tuple[str, ...]]): The path or paths specifying DICOM files to load.
-    """
-
-    def __init__(
-        self,
-        path: Union[str, Tuple[str, ...]],
-    ) -> None:
-        super().__init__(path)
-
-        self.patient_id = ""
-        self.patient_name = ""
-        self.study_instance_uid = ""
-        self.study_description = ""
-        self.series_instance_uid = ""
-        self.series_description = ""
-        self.series_number = -1
-        self.sop_class_uid = ""
-        self.dicom_modality = ""
-        self.frame_of_reference_uid = ""
-
-        self._get_dicom_base_info()
-
-        self._is_updated = False
-
-    # noinspection DuplicatedCode
-    def _get_dicom_base_info(self, additional_tags: Optional[Sequence[Tag]] = None) -> Dataset:
-        """Get the basic information from the initial DICOM file path.
-
-        Args:
-            additional_tags (Optional[Sequence[Tag]]): Additional tags to retrieve from the DICOM file.
-
-        Returns:
-            Dataset: The dataset loaded.
-        """
-        tags = [
-            Tag(0x0010, 0x0020),  # PatientID
-            Tag(0x0010, 0x0010),  # PatientName
-            Tag(0x0020, 0x000D),  # StudyInstanceUID
-            Tag(0x0008, 0x1030),  # StudyDescription
-            Tag(0x0020, 0x000E),  # SeriesInstanceUID
-            Tag(0x0008, 0x103E),  # SeriesDescription
-            Tag(0x0020, 0x0011),  # SeriesNumber
-            Tag(0x0008, 0x0016),  # SOPClassUID
-            Tag(0x0008, 0x0060),  # Modality
-            Tag(0x0020, 0x0052),  # FrameOfReferenceUID
-            Tag(0x3006, 0x0002),
-        ]  # StructureSetLabel
-
-        if additional_tags:
-            tags.extend(additional_tags)
-
-        dataset = load_dataset_tag(self.path[0], tags)
-
-        self.patient_id = str(dataset.get("PatientID", ""))
-        self.patient_name = str(dataset.get("PatientName", ""))
-        self.study_instance_uid = str(dataset.get("StudyInstanceUID", ""))
-        self.study_description = str(dataset.get("StudyDescription", ""))
-        self.series_instance_uid = str(dataset.get("SeriesInstanceUID", ""))
-        self.series_description = str(dataset.get("SeriesDescription", "Unnamed_Series"))
-        self.series_number = str(dataset.get("SeriesNumber", 0) if dataset.get("SeriesNumber", 0) is not None else "")
-        self.sop_class_uid = str(dataset.get("SOPClassUID", ""))
-        self.dicom_modality = str(dataset.get("Modality", ""))
-        self.frame_of_reference_uid = str(dataset.get("FrameOfReferenceUID", ""))
-        self.structure_set_label = str(dataset.get("StructureSetLabel", ""))
-
-        minimum_criterion = (
-            self.patient_id != "",
-            self.patient_name != "",
-            self.study_instance_uid != "",
-            self.series_instance_uid != "",
-            self.sop_class_uid != "",
-            self.dicom_modality != "",
-        )
-
-        if not all(minimum_criterion):
-            raise ValueError(f"At least one necessary DICOM information is not provided for subject {self.patient_id}!")
-
-        return dataset
-
-    @abstractmethod
-    def update(self) -> None:
-        """Update the :class:`DicomSeriesInfo` instance.
-
-        Returns:
-            None
-        """
-        raise NotImplementedError()
-
-
-class DicomSeriesImageInfo(DicomSeriesInfo):
-    """A :class:`DicomSeriesInfo` class for DICOM images. In addition to the information provided by the
-    :class:`DicomSeriesInfo` class, this class contains also a :class:`~pyradise.data.modality.Modality` instance.
-
-    Args:
-        paths (Tuple[str, ...]): The paths to the DICOM image files to load.
-    """
-
-    def __init__(self, paths: Tuple[str, ...]) -> None:
-        super().__init__(paths)
-
-        self.modality = Modality.get_default()
-
-    def get_modality(self) -> Modality:
-        """Get the :class:`~pyradise.data.modality.Modality` property.
-
-        Returns:
-            Modality: The :class:`~pyradise.data.modality.Modality` property.
-        """
-        return self.modality
-
-    def set_modality(self, modality: Modality) -> None:
-        """Set the :class:`~pyradise.data.modality.Modality`.
-
-        Args:
-            modality (Modality): The :class:`~pyradise.data.modality.Modality` to be assigned.
-
-        Returns:
-            None
-        """
-        self.modality = modality
-
-    def update(self) -> None:
-        """Update the :class:`DicomSeriesImageInfo` instance.
-
-        Returns:
-            None
-        """
-        self._is_updated = True
-
-
-# noinspection PyUnresolvedReferences
-@dataclass
-class ReferenceInfo:
-    """A class storing one of multiple reference infos from a DICOM registration file.
-
-    Warning:
-        This class is intended for internal use only.
-
-    Args:
-        series_instance_uid (str): The SeriesInstanceUID.
-        study_instance_uid (str): The StudyInstanceUID.
-        is_same_study (bool): Indicates if the series is from the same study as the reference.
-    """
-
-    series_instance_uid: str
-    study_instance_uid: str
-    is_same_study: bool
-
-
-# noinspection PyUnresolvedReferences
-@dataclass
-class RegistrationSequenceInfo:
-    """A class storing one of multiple registration sequence infos from a DICOM registration file.
-
-    Warning:
-        This class is intended for internal use only.
-
-    Args:
-        frame_of_reference_uid (str): The FrameOfReferenceUID.
-        transforms (Tuple[sitk.AffineTransform, ...]): The transforms.
-        transform_parameters (Tuple[List, ...]): The transformation parameters.
-    """
-
-    frame_of_reference_uid: str
-    transforms: Tuple[sitk.AffineTransform, ...]
-    transform_parameters: Tuple[List, ...]
-
-
-# noinspection PyUnresolvedReferences
-@dataclass
-class RegistrationInfo:
-    """A class storing all necessary infos for applying a registration transformation to a DICOM image.
-
-    Warning:
-        This class is intended for internal use only.
-
-    Args:
-        registration_info (RegistrationSequenceInfo): The registration sequence info.
-        reference_info (ReferenceInfo): The reference info.
-        is_reference_image (bool): Indicates if the image is the reference image.
-    """
-
-    registration_info: RegistrationSequenceInfo
-    reference_info: ReferenceInfo
-    is_reference_image: bool
-
-
-class DicomSeriesRegistrationInfo(DicomSeriesInfo):
-    """A :class:`DicomSeriesInfo` class for DICOM registrations. In addition to the information provided by the
-    :class:`DicomSeriesInfo` class, this class contains transformation parameters and references to the pair of DICOM
-    images associated with the registration.
-
-    Args:
-        path (str): The path to the DICOM registration file to load.
-        image_infos (Tuple[DicomSeriesImageInfo, ...]): The :class:`DicomSeriesImageInfo` used.
-        persistent_image_infos (bool): If True the class holds to the image_infos after updating, otherwise not
-         (default: False).
-    """
-
-    def __init__(
-        self, path: str, image_infos: Tuple[DicomSeriesImageInfo, ...], persistent_image_infos: bool = False
-    ) -> None:
-        self.dataset = None
-
-        super().__init__(path)
-
-        self.image_infos = image_infos
-        self.persistent_image_infos = persistent_image_infos
-
-        self.transform: Optional[sitk.Transform] = None
-        self.transform_parameters = tuple()
-        self.referenced_series_instance_uid_transform = ""
-        self.referenced_series_instance_uid_identity = ""
-
-        # since the update is lightweight let's update this class upon instantiation
-        self.update()
-
-    def _get_dicom_base_info(self, additional_tags: Optional[Sequence[Tag]] = None) -> Dataset:
-        """Get the basic information from the initial DICOM file path.
-
-        Args:
-            additional_tags (Optional[Sequence[Tag]]): Additional tags to retrieve from the DICOM file.
-
-        Returns:
-            Dataset: The dataset loaded.
-        """
-        additional_tags_ = [
-            Tag(0x0008, 0x1115),  # ReferencedSeriesSequence
-            Tag(0x0008, 0x1200),
-        ]  # StudiesContainingOtherReferencedInstancesSequence
-
-        if additional_tags:
-            additional_tags_.extend(additional_tags)
-
-        super()._get_dicom_base_info(additional_tags)
-
-        self.dataset = load_dataset(self.path[0])
-        return self.dataset
-
-    @staticmethod
-    def get_referenced_series_info(registration_dataset: Dataset) -> Tuple[ReferenceInfo, ...]:
-        """Get the :class:`ReferenceInfo` entries from a dataset.
-
-        Args:
-            registration_dataset (Dataset): The registration dataset to extract the infos from.
-
-        Returns:
-            Tuple[ReferenceInfo, ...]: The :class:`ReferenceInfo` retrieved from the Dataset.
-        """
-        referenced_series_instance_uids = []
-
-        referenced_series_sq = registration_dataset.get("ReferencedSeriesSequence", [])
-        for item in referenced_series_sq:
-            referenced_series_instance_uids.append(
-                ReferenceInfo(
-                    str(item.get("SeriesInstanceUID", "")), str(registration_dataset.get("StudyInstanceUID", "")), True
-                )
-            )
-
-        other_referenced_series_sq = registration_dataset.get("StudiesContainingOtherReferencedInstancesSequence", [])
-        for item in other_referenced_series_sq:
-            referenced_series_sq = item.get("ReferencedSeriesSequence", [])
-            for referenced_series_item in referenced_series_sq:
-                referenced_series_instance_uids.append(
-                    ReferenceInfo(
-                        str(referenced_series_item.get("SeriesInstanceUID", "")),
-                        str(item.get("StudyInstanceUID", "")),
-                        False,
-                    )
-                )
-
-        return tuple(referenced_series_instance_uids)
-
-    @staticmethod
-    def _get_registration_sequence_info(registration_dataset: Dataset) -> Tuple[RegistrationSequenceInfo, ...]:
-        """Get the :class:`RegistrationSequenceInfo` entries from a dataset.
-
-        Args:
-            registration_dataset (Dataset): The registration dataset to extract the information from.
-
-        Returns:
-            Tuple[RegistrationSequenceInfo, ...]: The :class:`RegistrationSequenceInfo` entries retrieved.
-        """
-        registration_info = []
-
-        for item in registration_dataset.get("RegistrationSequence", []):
-            frame_of_reference_uid = str(item.get("FrameOfReferenceUID", ""))
-            transforms = []
-            transform_parameters = []
-
-            for matrix_reg_item in item.get("MatrixRegistrationSequence", []):
-                for matrix_item in matrix_reg_item.get("MatrixSequence", []):
-                    transform_type = str(matrix_item.get("FrameOfReferenceTransformationMatrixType"))
-                    transform_matrix = matrix_item.get("FrameOfReferenceTransformationMatrix")
-
-                    if transform_type == "RIGID":
-                        transform_params = [float(param) for param in transform_matrix]
-                        transform_matrix = np.array(transform_params).reshape(4, 4)
-
-                        transform = sitk.AffineTransform(3)
-                        transform.SetMatrix(transform_matrix[:3, :3].flatten().tolist())
-                        transform.SetTranslation(transform_matrix[:-1, 3:].flatten().tolist())
-
-                        transforms.append(transform.GetInverse())
-                        transform_parameters.append(transform_params)
-
-                    else:
-                        print(
-                            "Invalid transform type registered in subject "
-                            f'{registration_dataset.get("PatientID", "n/a")} ({transform_type})!'
-                        )
-
-            registration_info.append(
-                RegistrationSequenceInfo(frame_of_reference_uid, tuple(transforms), tuple(transform_parameters))
-            )
-
-        return tuple(registration_info)
-
-    @staticmethod
-    def _get_unique_series_instance_uid_entries(
-        infos: Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]
-    ) -> Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]:
-        """Get the unique SeriesInstanceUID entries from a list of :class:`DicomSeriesImageInfo` or datasets.
-
-        Args:
-            infos (Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]): The infos to extract the unique
-             entries from.
-
-        Returns:
-            Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]: The unique entries.
-        """
-        unique_infos = []
-
-        if isinstance(infos[0], DicomSeriesImageInfo):
-            unique_instance_uids = list({info.series_instance_uid for info in infos})
-        else:
-            unique_instance_uids = list({str(info.get("SeriesInstanceUID")) for info in infos})
-
-        for info in infos:
-            if isinstance(info, DicomSeriesImageInfo):
-                if info.series_instance_uid in unique_instance_uids:
-                    unique_infos.append(info)
-
-                    index = unique_instance_uids.index(info.series_instance_uid)
-                    unique_instance_uids.pop(index)
-            else:
-                if str(info.get("SeriesInstanceUID")) in unique_instance_uids:
-                    unique_infos.append(info)
-
-                    index = unique_instance_uids.index(str(info.get("SeriesInstanceUID")))
-                    unique_instance_uids.pop(index)
-
-        return tuple(unique_infos)
-
-    @staticmethod
-    def get_registration_infos(
-        registration_dataset: Dataset, image_infos: Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]
-    ) -> Tuple[RegistrationInfo, ...]:
-        """Extract the :class:`RegistrationInfo` entries with the corresponding :class:`ReferenceInfo`.
-
-        Args:
-            registration_dataset (Dataset): The registration dataset to extract the registration infos from.
-            image_infos (Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]): The image infos or datasets
-             to use for the combination.
-
-        Returns:
-            Tuple[RegistrationInfo, ...]: The combined :class:`RegistrationInfo`.
-        """
-
-        registration_infos = DicomSeriesRegistrationInfo._get_registration_sequence_info(registration_dataset)
-
-        reference_sequence_infos = DicomSeriesRegistrationInfo.get_referenced_series_info(registration_dataset)
-
-        internal_image_infos = DicomSeriesRegistrationInfo._get_unique_series_instance_uid_entries(image_infos)
-
-        identity_transform = (1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0)
-
-        def is_ident(transform: Tuple[list]):
-            for trans in transform:
-                yield tuple(trans) == identity_transform
-
-        combined_info = []
-
-        for image_info in internal_image_infos:
-            if isinstance(image_info, Dataset):
-                if not any(
-                    uid in str(image_info.get("SOPClassUID", "")) + "."
-                    for uid in ("1.2.840.10008.5.1.4.1.1.2.", "1.2.840.10008.5.1.4.1.1.4.")
-                ):
-                    raise ValueError(
-                        f'The provided image info SOPClassUID ({str(image_info.get("SOPClassUID", ""))})' " is invalid!"
-                    )
-
-                image_series_instance_uid = image_info.get("SeriesInstanceUID")
-                image_study_instance_uid = image_info.get("StudyInstanceUID")
-                image_frame_of_reference_uid = image_info.get("FrameOfReferenceUID")
-
-            else:
-                image_series_instance_uid = image_info.series_instance_uid
-                image_study_instance_uid = image_info.study_instance_uid
-                image_frame_of_reference_uid = image_info.frame_of_reference_uid
-
-            for reference_sequence_info in reference_sequence_infos:
-                if not all(
-                    (
-                        reference_sequence_info.series_instance_uid == image_series_instance_uid,
-                        reference_sequence_info.study_instance_uid == image_study_instance_uid,
-                    )
-                ):
-                    continue
-
-                for registration_info in registration_infos:
-                    if registration_info.frame_of_reference_uid != image_frame_of_reference_uid:
-                        continue
-
-                    combined_info.append(
-                        RegistrationInfo(
-                            registration_info,
-                            reference_sequence_info,
-                            all(is_ident(registration_info.transform_parameters)),
-                        )
-                    )
-
-        if len(combined_info) > 2:
-            warnings.warn("There are more than two DICOM images assigned to a registration!")
-
-        return tuple(combined_info)
-
-    def set_image_infos(self, image_infos: Tuple[DicomSeriesImageInfo, ...]) -> None:
-        """Set the :class:`DicomSeriesImageInfo` entries.
-
-        Args:
-            image_infos (Tuple[DicomSeriesImageInfo, ...]): The :class:`DicomSeriesImageInfo` entries to set.
-
-        Returns:
-            None
-        """
-        self.image_infos = image_infos
-
-        self._is_updated = False
-
-    def get_image_infos(self) -> Tuple[DicomSeriesImageInfo, ...]:
-        """Get the :class:`DicomSeriesImageInfo` entries.
-
-        Returns:
-            Tuple[DicomSeriesImageInfo, ...]: The :class:`DicomSeriesImageInfo` entries.
-        """
-        return self.image_infos
-
-    def update(self) -> None:
-        """Update the :class:`DicomSeriesRegistrationInfo`.
-
-        Returns:
-            None
-        """
-        if len(self.path) != 1:
-            raise ValueError("Only one registration file path is allowed, but multiple or none are provided!")
-
-        if not self.image_infos:
-            raise ValueError("No image infos are provided and thus no registration is possible!")
-
-        if not self.dataset:
-            self.dataset = load_dataset(self.path[0])
-
-        combined_info = self.get_registration_infos(self.dataset, self.image_infos)
-
-        for info in combined_info:
-            if info.is_reference_image:
-                self.referenced_series_instance_uid_identity = info.reference_info.series_instance_uid
-
-            else:
-                self.referenced_series_instance_uid_transform = info.reference_info.series_instance_uid
-
-                if len(info.registration_info.transforms) != 1:
-                    raise ValueError(
-                        f"The current implementation only supports registration files with "
-                        f"one transformation, but there are {len(info.registration_info.transforms)}!"
-                    )
-
-                self.transform = info.registration_info.transforms[0]
-                self.transform_parameters = info.registration_info.transform_parameters[0]
-
-        if not self.persistent_image_infos:
-            self.image_infos = tuple()
-
-        self._is_updated = True
-
-
-class DicomSeriesRTSSInfo(DicomSeriesInfo):
-    """A :class:`DicomSeriesInfo` class for DICOM-RTSS. In addition to the information provided by the
-    :class:`DicomSeriesInfo` class, this class contains a :class:`~pyradise.data.annotator.Annotator` instance and a
-    reference to the DICOM image associated with the DICOM-RTSS.
-
-    Args:
-        path (str): The path to the DICOM-RTSS file to load.
-    """
-
-    def __init__(self, path: str) -> None:
-        self.dataset: Optional[Dataset] = None
-        self.annotator: Annotator = Annotator.get_default()
-        self.referenced_instance_uid = ""
-        self.roi_names = []
-
-        super().__init__(path)
-
-        self.update()
-
-    def _get_dicom_base_info(self, additional_tags: Optional[Sequence[Tag]] = None) -> Dataset:
-        """Get the basic information from the initial DICOM file path.
-
-        Args:
-            additional_tags (Optional[Sequence[Tag]]): Additional tags to retrieve from the DICOM file.
-
-        Returns:
-            Dataset: The Dataset loaded.
-        """
-        additional_tags_ = [
-            Tag(0x3006, 0x0002),  # StructureSetLabel
-            Tag(0x0008, 0x1070),  # OperatorName
-            Tag(0x3006, 0x0010),  # ReferencedFrameOfReferenceSequence
-            Tag(0x3006, 0x0080),  # RTROIObservationsSequence
-            Tag(0x3006, 0x0020),
-        ]  # StructureSetROISequence
-
-        if additional_tags:
-            additional_tags_.extend(additional_tags)
-
-        self.dataset = super()._get_dicom_base_info(additional_tags_)
-
-        self.annotator = self._get_annotator_from_dicom(self.dataset)
-        self.referenced_instance_uid = self._get_referenced_series_instance_uid(self.dataset)
-        self.roi_names = self._get_roi_names()
-
-        self._is_updated = True
-
-        return self.dataset
-
-    @staticmethod
-    def _get_annotator_from_dicom(dataset: Dataset) -> Annotator:
-        """Get the :class:`~pyradise.data.annotator.Annotator` from the provided dataset.
-
-        Args:
-            dataset (Dataset): The dataset to retrieve the :class:`~pyradise.data.annotator.Annotator` from.
-
-        Returns:
-            Annotator: The annotator.
-        """
-        operator_name = str(dataset.get("OperatorsName", ""))
-
-        if operator_name:
-            operator_name = operator_name.replace(" ", "_")
-            pattern = r"""[^\da-zA-Z_-]+"""
-            regex = re.compile(pattern)
-            operator_name = regex.sub(r"", operator_name)
-
-            search_pattern = r"""[A-Z]+"""
-            abbreviation = "".join(re.findall(search_pattern, operator_name))
-            abbreviation = abbreviation if abbreviation else None
-
-            return Annotator(operator_name, abbreviation)
-
-        return Annotator.get_default()
-
-    def get_annotator(self) -> Annotator:
-        """Get the :class:`~pyradise.data.annotator.Annotator`.
-
-        Returns:
-            Annotator: The annotator.
-        """
-        return self.annotator
-
-    @staticmethod
-    def _get_referenced_series_instance_uid(dataset: Dataset) -> str:
-        """Get the referenced SeriesInstanceUID from the dataset.
-
-        Args:
-            dataset (Dataset): The dataset to retrieve the referenced SeriesInstanceUID from.
-
-        Returns:
-            str: The referenced SeriesInstanceUID
-        """
-        referenced_series_instance_uids = []
-
-        ref_frame_of_ref_sq = dataset.get("ReferencedFrameOfReferenceSequence", [])
-        for ref_frame_ref_item in ref_frame_of_ref_sq:
-            rt_ref_study_sq = ref_frame_ref_item.get("RTReferencedStudySequence", [])
-
-            for rt_ref_study_item in rt_ref_study_sq:
-                rt_ref_series_sq = rt_ref_study_item.get("RTReferencedSeriesSequence", [])
-
-                for rt_ref_series_item in rt_ref_series_sq:
-                    referenced_series_instance_uids.append(str(rt_ref_series_item.get("SeriesInstanceUID")))
-
-        if len(referenced_series_instance_uids) != 1:
-            raise ValueError(
-                f"There are multiple or no ({len(referenced_series_instance_uids)}) referenced "
-                f"SeriesInstanceUIDs, but only one is allowed!"
-            )
-
-        return referenced_series_instance_uids[0]
-
-    def _get_roi_names(self) -> List[str]:
-        """Get the ROI names from the dataset.
-
-        Returns:
-            List[str]: The ROI names.
-        """
-        roi_names = []
-
-        roi_sq = self.dataset.get("StructureSetROISequence", [])
-        for roi_item in roi_sq:
-            roi_names.append(str(roi_item.get("ROIName")))
-
-        return roi_names
-
-    # pylint: disable=unnecessary-pass
-    def update(self) -> None:
-        """Update the :class:`DicomSeriesRTSSInfo`.
-
-        Returns:
-            None
-        """
-        self._is_updated = True
+import re
+import warnings
+from abc import ABC, abstractmethod
+from dataclasses import dataclass
+from typing import List, Optional, Sequence, Tuple, Union
+
+import numpy as np
+import SimpleITK as sitk
+from pydicom import Dataset
+from pydicom.tag import Tag
+
+from pyradise.data import (Annotator, Modality, Organ, str_to_annotator,
+                           str_to_modality, str_to_organ)
+from pyradise.utils import (is_dir_and_exists, is_file_and_exists,
+                            load_dataset, load_dataset_tag)
+
+__all__ = [
+    "SeriesInfo",
+    "FileSeriesInfo",
+    "IntensityFileSeriesInfo",
+    "SegmentationFileSeriesInfo",
+    "DicomSeriesInfo",
+    "DicomSeriesImageInfo",
+    "DicomSeriesRegistrationInfo",
+    "DicomSeriesRTSSInfo",
+    "ReferenceInfo",
+    "RegistrationInfo",
+    "RegistrationSequenceInfo",
+]
+
+
+class SeriesInfo(ABC):
+    """An abstract base class for all :class:`SeriesInfo` classes. A :class:`SeriesInfo` class is used to retrieve and
+    store content-specific information which is required by the :class:`~pyradise.fileio.loading.SubjectLoader` in
+    order to correctly load the data and to construct a :class:`~pyradise.data.subject.Subject`.
+
+    Depending on the type of data, the :class:`SeriesInfo` subclasses retrieve different information which is essential
+    for loading and :class:`~pyradise.data.subject.Subject` construction. For example, the
+    :class:`DicomSeriesImageInfo` retrieves and holds data about the :class:`~pyradise.data.modality.Modality`
+    whereas the :class:`DicomSeriesRTSSInfo` manages information about the :class:`~pyradise.data.annotator.Annotator`
+    and information about the referenced DICOM image series.
+
+    Args:
+        path (Union[str, Tuple[str, ...]]): The path or paths to the files to load.
+    """
+
+    def __init__(self, path: Union[str, Tuple[str, ...]]) -> None:
+        super().__init__()
+
+        if isinstance(path, str):
+            self.path = (path,)
+        else:
+            self.path = path
+
+        self._check_paths(self.path)
+
+        self.patient_name = ""
+        self.patient_id = ""
+
+        self._is_updated = False
+
+    @staticmethod
+    def _check_paths(paths: Union[str, Tuple[str, ...]], should_be_dir: bool = False) -> None:
+        """Check if the provided paths are files/directories.
+
+        Args:
+            paths (Union[str, Tuple[str, ...]]): The paths for checking.
+            should_be_dir (bool): If True the paths will be checked if they are directories.
+
+        Returns:
+            None
+        """
+        if isinstance(paths, str):
+            internal_path = (paths,)
+        else:
+            internal_path = paths
+
+        for path in internal_path:
+            if should_be_dir:
+                is_dir_and_exists(path)
+
+            else:
+                is_file_and_exists(path)
+
+    def get_path(self) -> Tuple[str]:
+        """Get the file paths assigned to the :class:`SeriesInfo` instance.
+
+        Returns:
+            Tuple[str]: The file paths assigned to the :class:`SeriesInfo` instance.
+        """
+        return self.path
+
+    def get_patient_name(self) -> str:
+        """Get the patient name.
+
+        Returns:
+            str: The patient name.
+        """
+        return self.patient_name
+
+    def get_patient_id(self) -> str:
+        """Get the patient ID.
+
+        Returns:
+            str: The patient ID.
+        """
+        return self.patient_id
+
+    def is_updated(self) -> bool:
+        """Check if is updated.
+
+        Returns:
+            bool: True if is updated, False otherwise.
+        """
+        return self._is_updated
+
+    @abstractmethod
+    def update(self) -> None:
+        """Update the :class:`SeriesInfo` instance.
+
+        Returns:
+            None
+        """
+        raise NotImplementedError()
+
+
+class FileSeriesInfo(SeriesInfo):
+    """An abstract base :class:`SeriesInfo` class for all discrete image files (e.g. NIFTI, NRRD, MHA, etc.).
+
+    Important:
+        For DICOM files use a  :class:`DicomSeriesInfo` subclass instead.
+
+    Args:
+        path (str): The path to the discrete image file to load.
+        subject_name (str): The name of the subject.
+    """
+
+    def __init__(self, path: str, subject_name: str) -> None:
+        super().__init__(path)
+
+        # remove illegal characters in the subject name
+        subject_name_ = subject_name.replace(" ", "_")
+        pattern = r"""[^\da-zA-Z_-]+"""
+        regex = re.compile(pattern)
+
+        # to stay consistent the subject name is called patient name as for DICOM info
+        self.patient_name = regex.sub(r"", subject_name_)
+        self.patient_id = self.patient_name
+
+    @abstractmethod
+    def update(self) -> None:
+        """Update the :class:`FileSeriesInfo` instance.
+
+        Returns:
+            None
+        """
+        raise NotImplementedError()
+
+
+class IntensityFileSeriesInfo(FileSeriesInfo):
+    """A :class:`FileSeriesInfo` class for intensity images. In addition to the information provided by the
+    :class:`FileSeriesInfo` class, this class contains also a :class:`~pyradise.data.modality.Modality` instance.
+
+    Args:
+        path (str): The path to the discrete intensity image file to load.
+        subject_name (str): The name of the subject.
+        modality (Union[str, Modality]): The modality of the intensity image.
+    """
+
+    def __init__(self, path: str, subject_name: str, modality: Union[Modality, str]) -> None:
+        if not isinstance(path, str):
+            raise TypeError(f"Expected a string for the path but got {type(path)} instead.")
+        super().__init__(path, subject_name)
+
+        self.modality: Modality = str_to_modality(modality)
+
+        self.update()
+
+    def get_modality(self) -> Modality:
+        """Get the :class:`~pyradise.data.modality.Modality`.
+
+        Returns:
+            Modality: The :class:`~pyradise.data.modality.Modality`.
+        """
+        return self.modality
+
+    def set_modality(self, modality: Modality) -> None:
+        """Set the :class:`~pyradise.data.modality.Modality`.
+
+        Args:
+            modality (Modality): The :class:`~pyradise.data.modality.Modality` to be set.
+
+        Returns:
+            None
+        """
+        self.modality: Modality = modality
+
+    def update(self) -> None:
+        """Update the :class:`IntensityFileSeriesInfo`.
+
+        Returns:
+            None
+        """
+        self._is_updated = True
+
+
+class SegmentationFileSeriesInfo(FileSeriesInfo):
+    """A :class:`FileSeriesInfo` class for segmentation images. In addition to the information provided by the
+    :class:`FileSeriesInfo` class, this class contains also an :class:`~pyradise.data.organ.Organ` instance and a
+    :class:`~pyradise.data.annotator.Annotator` instance.
+
+    Note:
+        We assume that the segmentation image is a binary image with the foreground having the value 1 and the
+        background being 0. If your images are different we recommend to separate the segmentation masks into separate
+        files because in RT practice segmentations may overlap.
+
+    Args:
+        path (str): The path to the discrete segmentation image file to load.
+        subject_name (str): The name of the subject.
+        organ (Union[Organ, str]): The organ the segmentation is representing.
+        annotator (Union[Annotator, str]): The annotator who created the segmentation.
+    """
+
+    def __init__(
+        self, path: str, subject_name: str, organ: Union[Organ, str], annotator: Union[Annotator, str]
+    ) -> None:
+        if not isinstance(path, str):
+            raise TypeError(f"Expected a single path as a string but got {type(path)}.")
+        super().__init__(path, subject_name)
+
+        self.organ: Organ = str_to_organ(organ)
+        self.annotator: Annotator = str_to_annotator(annotator)
+
+        self.update()
+
+    def get_organ(self) -> Organ:
+        """Get the :class:`~pyradise.data.organ.Organ`.
+
+        Returns:
+            Organ: The :class:`~pyradise.data.organ.Organ`.
+        """
+        return self.organ
+
+    def set_organ(self, organ: Organ) -> None:
+        """Set the :class:`~pyradise.data.organ.Organ`.
+
+        Args:
+            organ (Organ): The :class:`~pyradise.data.organ.Organ` to be set.
+
+        Returns:
+            None
+        """
+        self.organ: Organ = organ
+
+    def get_annotator(self) -> Annotator:
+        """Get the :class:`~pyradise.data.annotator.Annotator`.
+
+        Returns:
+            Annotator: The :class:`~pyradise.data.annotator.Annotator`.
+        """
+        return self.annotator
+
+    def set_annotator(self, annotator: Annotator) -> None:
+        """Set the :class:`~pyradise.data.annotator.Annotator`.
+
+        Args:
+            annotator (Annotator): The :class:`~pyradise.data.annotator.Annotator` to be set.
+
+        Returns:
+            None
+        """
+        self.annotator: Annotator = annotator
+
+    def update(self) -> None:
+        """Update the :class:`SegmentationFileSeriesInfo` instance.
+
+        Returns:
+            None
+        """
+        self._is_updated = True
+
+
+class DicomSeriesInfo(SeriesInfo):
+    """An abstract base :class:`SeriesInfo` class for all DICOM data (i.e. DICOM image, DICOM registration, DICOM-RTSS).
+
+    Important:
+        For discrete image files use a  :class:`FileSeriesInfo` subclass instead.
+
+    Args:
+        path (Union[str, Tuple[str, ...]]): The path or paths specifying DICOM files to load.
+    """
+
+    def __init__(
+        self,
+        path: Union[str, Tuple[str, ...]],
+    ) -> None:
+        super().__init__(path)
+
+        self.patient_id = ""
+        self.patient_name = ""
+        self.study_instance_uid = ""
+        self.study_description = ""
+        self.series_instance_uid = ""
+        self.series_description = ""
+        self.series_number = -1
+        self.sop_class_uid = ""
+        self.dicom_modality = ""
+        self.frame_of_reference_uid = ""
+
+        self._get_dicom_base_info()
+
+        self._is_updated = False
+
+    # noinspection DuplicatedCode
+    def _get_dicom_base_info(self, additional_tags: Optional[Sequence[Tag]] = None) -> Dataset:
+        """Get the basic information from the initial DICOM file path.
+
+        Args:
+            additional_tags (Optional[Sequence[Tag]]): Additional tags to retrieve from the DICOM file.
+
+        Returns:
+            Dataset: The dataset loaded.
+        """
+        tags = [
+            Tag(0x0010, 0x0020),  # PatientID
+            Tag(0x0010, 0x0010),  # PatientName
+            Tag(0x0020, 0x000D),  # StudyInstanceUID
+            Tag(0x0008, 0x1030),  # StudyDescription
+            Tag(0x0020, 0x000E),  # SeriesInstanceUID
+            Tag(0x0008, 0x103E),  # SeriesDescription
+            Tag(0x0020, 0x0011),  # SeriesNumber
+            Tag(0x0008, 0x0016),  # SOPClassUID
+            Tag(0x0008, 0x0060),  # Modality
+            Tag(0x0020, 0x0052),  # FrameOfReferenceUID
+            Tag(0x3006, 0x0002),
+        ]  # StructureSetLabel
+
+        if additional_tags:
+            tags.extend(additional_tags)
+
+        dataset = load_dataset_tag(self.path[0], tags)
+
+        self.patient_id = str(dataset.get("PatientID", ""))
+        self.patient_name = str(dataset.get("PatientName", ""))
+        self.study_instance_uid = str(dataset.get("StudyInstanceUID", ""))
+        self.study_description = str(dataset.get("StudyDescription", ""))
+        self.series_instance_uid = str(dataset.get("SeriesInstanceUID", ""))
+        self.series_description = str(dataset.get("SeriesDescription", "Unnamed_Series"))
+        self.series_number = str(dataset.get("SeriesNumber", 0) if dataset.get("SeriesNumber", 0) is not None else "")
+        self.sop_class_uid = str(dataset.get("SOPClassUID", ""))
+        self.dicom_modality = str(dataset.get("Modality", ""))
+        self.frame_of_reference_uid = str(dataset.get("FrameOfReferenceUID", ""))
+        self.structure_set_label = str(dataset.get("StructureSetLabel", ""))
+
+        minimum_criterion = (
+            self.patient_id != "",
+            self.patient_name != "",
+            self.study_instance_uid != "",
+            self.series_instance_uid != "",
+            self.sop_class_uid != "",
+            self.dicom_modality != "",
+        )
+
+        if not all(minimum_criterion):
+            raise ValueError(f"At least one necessary DICOM information is not provided for subject {self.patient_id}!")
+
+        return dataset
+
+    @abstractmethod
+    def update(self) -> None:
+        """Update the :class:`DicomSeriesInfo` instance.
+
+        Returns:
+            None
+        """
+        raise NotImplementedError()
+
+
+class DicomSeriesImageInfo(DicomSeriesInfo):
+    """A :class:`DicomSeriesInfo` class for DICOM images. In addition to the information provided by the
+    :class:`DicomSeriesInfo` class, this class contains also a :class:`~pyradise.data.modality.Modality` instance.
+
+    Args:
+        paths (Tuple[str, ...]): The paths to the DICOM image files to load.
+    """
+
+    def __init__(self, paths: Tuple[str, ...]) -> None:
+        super().__init__(paths)
+
+        self.modality = Modality.get_default()
+
+    def get_modality(self) -> Modality:
+        """Get the :class:`~pyradise.data.modality.Modality` property.
+
+        Returns:
+            Modality: The :class:`~pyradise.data.modality.Modality` property.
+        """
+        return self.modality
+
+    def set_modality(self, modality: Modality) -> None:
+        """Set the :class:`~pyradise.data.modality.Modality`.
+
+        Args:
+            modality (Modality): The :class:`~pyradise.data.modality.Modality` to be assigned.
+
+        Returns:
+            None
+        """
+        self.modality = modality
+
+    def update(self) -> None:
+        """Update the :class:`DicomSeriesImageInfo` instance.
+
+        Returns:
+            None
+        """
+        self._is_updated = True
+
+
+# noinspection PyUnresolvedReferences
+@dataclass
+class ReferenceInfo:
+    """A class storing one of multiple reference infos from a DICOM registration file.
+
+    Warning:
+        This class is intended for internal use only.
+
+    Args:
+        series_instance_uid (str): The SeriesInstanceUID.
+        study_instance_uid (str): The StudyInstanceUID.
+        is_same_study (bool): Indicates if the series is from the same study as the reference.
+    """
+
+    series_instance_uid: str
+    study_instance_uid: str
+    is_same_study: bool
+
+
+# noinspection PyUnresolvedReferences
+@dataclass
+class RegistrationSequenceInfo:
+    """A class storing one of multiple registration sequence infos from a DICOM registration file.
+
+    Warning:
+        This class is intended for internal use only.
+
+    Args:
+        frame_of_reference_uid (str): The FrameOfReferenceUID.
+        transforms (Tuple[sitk.AffineTransform, ...]): The transforms.
+        transform_parameters (Tuple[List, ...]): The transformation parameters.
+    """
+
+    frame_of_reference_uid: str
+    transforms: Tuple[sitk.AffineTransform, ...]
+    transform_parameters: Tuple[List, ...]
+
+
+# noinspection PyUnresolvedReferences
+@dataclass
+class RegistrationInfo:
+    """A class storing all necessary infos for applying a registration transformation to a DICOM image.
+
+    Warning:
+        This class is intended for internal use only.
+
+    Args:
+        registration_info (RegistrationSequenceInfo): The registration sequence info.
+        reference_info (ReferenceInfo): The reference info.
+        is_reference_image (bool): Indicates if the image is the reference image.
+    """
+
+    registration_info: RegistrationSequenceInfo
+    reference_info: ReferenceInfo
+    is_reference_image: bool
+
+
+class DicomSeriesRegistrationInfo(DicomSeriesInfo):
+    """A :class:`DicomSeriesInfo` class for DICOM registrations. In addition to the information provided by the
+    :class:`DicomSeriesInfo` class, this class contains transformation parameters and references to the pair of DICOM
+    images associated with the registration.
+
+    Args:
+        path (str): The path to the DICOM registration file to load.
+        image_infos (Tuple[DicomSeriesImageInfo, ...]): The :class:`DicomSeriesImageInfo` used.
+        persistent_image_infos (bool): If True the class holds to the image_infos after updating, otherwise not
+         (default: False).
+    """
+
+    def __init__(
+        self, path: str, image_infos: Tuple[DicomSeriesImageInfo, ...], persistent_image_infos: bool = False
+    ) -> None:
+        self.dataset = None
+
+        super().__init__(path)
+
+        self.image_infos = image_infos
+        self.persistent_image_infos = persistent_image_infos
+
+        self.transform: Optional[sitk.Transform] = None
+        self.transform_parameters = tuple()
+        self.referenced_series_instance_uid_transform = ""
+        self.referenced_series_instance_uid_identity = ""
+
+        # since the update is lightweight let's update this class upon instantiation
+        self.update()
+
+    def _get_dicom_base_info(self, additional_tags: Optional[Sequence[Tag]] = None) -> Dataset:
+        """Get the basic information from the initial DICOM file path.
+
+        Args:
+            additional_tags (Optional[Sequence[Tag]]): Additional tags to retrieve from the DICOM file.
+
+        Returns:
+            Dataset: The dataset loaded.
+        """
+        additional_tags_ = [
+            Tag(0x0008, 0x1115),  # ReferencedSeriesSequence
+            Tag(0x0008, 0x1200),
+        ]  # StudiesContainingOtherReferencedInstancesSequence
+
+        if additional_tags:
+            additional_tags_.extend(additional_tags)
+
+        super()._get_dicom_base_info(additional_tags)
+
+        self.dataset = load_dataset(self.path[0])
+        return self.dataset
+
+    @staticmethod
+    def get_referenced_series_info(registration_dataset: Dataset) -> Tuple[ReferenceInfo, ...]:
+        """Get the :class:`ReferenceInfo` entries from a dataset.
+
+        Args:
+            registration_dataset (Dataset): The registration dataset to extract the infos from.
+
+        Returns:
+            Tuple[ReferenceInfo, ...]: The :class:`ReferenceInfo` retrieved from the Dataset.
+        """
+        referenced_series_instance_uids = []
+
+        referenced_series_sq = registration_dataset.get("ReferencedSeriesSequence", [])
+        for item in referenced_series_sq:
+            referenced_series_instance_uids.append(
+                ReferenceInfo(
+                    str(item.get("SeriesInstanceUID", "")), str(registration_dataset.get("StudyInstanceUID", "")), True
+                )
+            )
+
+        other_referenced_series_sq = registration_dataset.get("StudiesContainingOtherReferencedInstancesSequence", [])
+        for item in other_referenced_series_sq:
+            referenced_series_sq = item.get("ReferencedSeriesSequence", [])
+            for referenced_series_item in referenced_series_sq:
+                referenced_series_instance_uids.append(
+                    ReferenceInfo(
+                        str(referenced_series_item.get("SeriesInstanceUID", "")),
+                        str(item.get("StudyInstanceUID", "")),
+                        False,
+                    )
+                )
+
+        return tuple(referenced_series_instance_uids)
+
+    @staticmethod
+    def _get_registration_sequence_info(registration_dataset: Dataset) -> Tuple[RegistrationSequenceInfo, ...]:
+        """Get the :class:`RegistrationSequenceInfo` entries from a dataset.
+
+        Args:
+            registration_dataset (Dataset): The registration dataset to extract the information from.
+
+        Returns:
+            Tuple[RegistrationSequenceInfo, ...]: The :class:`RegistrationSequenceInfo` entries retrieved.
+        """
+        registration_info = []
+
+        for item in registration_dataset.get("RegistrationSequence", []):
+            frame_of_reference_uid = str(item.get("FrameOfReferenceUID", ""))
+            transforms = []
+            transform_parameters = []
+
+            for matrix_reg_item in item.get("MatrixRegistrationSequence", []):
+                for matrix_item in matrix_reg_item.get("MatrixSequence", []):
+                    transform_type = str(matrix_item.get("FrameOfReferenceTransformationMatrixType"))
+                    transform_matrix = matrix_item.get("FrameOfReferenceTransformationMatrix")
+
+                    if transform_type == "RIGID":
+                        transform_params = [float(param) for param in transform_matrix]
+                        transform_matrix = np.array(transform_params).reshape(4, 4)
+
+                        transform = sitk.AffineTransform(3)
+                        transform.SetMatrix(transform_matrix[:3, :3].flatten().tolist())
+                        transform.SetTranslation(transform_matrix[:-1, 3:].flatten().tolist())
+
+                        transforms.append(transform.GetInverse())
+                        transform_parameters.append(transform_params)
+
+                    else:
+                        print(
+                            "Invalid transform type registered in subject "
+                            f'{registration_dataset.get("PatientID", "n/a")} ({transform_type})!'
+                        )
+
+            registration_info.append(
+                RegistrationSequenceInfo(frame_of_reference_uid, tuple(transforms), tuple(transform_parameters))
+            )
+
+        return tuple(registration_info)
+
+    @staticmethod
+    def _get_unique_series_instance_uid_entries(
+        infos: Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]
+    ) -> Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]:
+        """Get the unique SeriesInstanceUID entries from a list of :class:`DicomSeriesImageInfo` or datasets.
+
+        Args:
+            infos (Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]): The infos to extract the unique
+             entries from.
+
+        Returns:
+            Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]: The unique entries.
+        """
+        unique_infos = []
+
+        if isinstance(infos[0], DicomSeriesImageInfo):
+            unique_instance_uids = list({info.series_instance_uid for info in infos})
+        else:
+            unique_instance_uids = list({str(info.get("SeriesInstanceUID")) for info in infos})
+
+        for info in infos:
+            if isinstance(info, DicomSeriesImageInfo):
+                if info.series_instance_uid in unique_instance_uids:
+                    unique_infos.append(info)
+
+                    index = unique_instance_uids.index(info.series_instance_uid)
+                    unique_instance_uids.pop(index)
+            else:
+                if str(info.get("SeriesInstanceUID")) in unique_instance_uids:
+                    unique_infos.append(info)
+
+                    index = unique_instance_uids.index(str(info.get("SeriesInstanceUID")))
+                    unique_instance_uids.pop(index)
+
+        return tuple(unique_infos)
+
+    @staticmethod
+    def get_registration_infos(
+        registration_dataset: Dataset, image_infos: Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]
+    ) -> Tuple[RegistrationInfo, ...]:
+        """Extract the :class:`RegistrationInfo` entries with the corresponding :class:`ReferenceInfo`.
+
+        Args:
+            registration_dataset (Dataset): The registration dataset to extract the registration infos from.
+            image_infos (Union[Tuple[DicomSeriesImageInfo, ...], Tuple[Dataset, ...]]): The image infos or datasets
+             to use for the combination.
+
+        Returns:
+            Tuple[RegistrationInfo, ...]: The combined :class:`RegistrationInfo`.
+        """
+
+        registration_infos = DicomSeriesRegistrationInfo._get_registration_sequence_info(registration_dataset)
+
+        reference_sequence_infos = DicomSeriesRegistrationInfo.get_referenced_series_info(registration_dataset)
+
+        internal_image_infos = DicomSeriesRegistrationInfo._get_unique_series_instance_uid_entries(image_infos)
+
+        identity_transform = (1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0)
+
+        def is_ident(transform: Tuple[list]):
+            for trans in transform:
+                yield tuple(trans) == identity_transform
+
+        combined_info = []
+
+        for image_info in internal_image_infos:
+            if isinstance(image_info, Dataset):
+                if not any(
+                    uid in str(image_info.get("SOPClassUID", "")) + "."
+                    for uid in ("1.2.840.10008.5.1.4.1.1.2.", "1.2.840.10008.5.1.4.1.1.4.")
+                ):
+                    raise ValueError(
+                        f'The provided image info SOPClassUID ({str(image_info.get("SOPClassUID", ""))})' " is invalid!"
+                    )
+
+                image_series_instance_uid = image_info.get("SeriesInstanceUID")
+                image_study_instance_uid = image_info.get("StudyInstanceUID")
+                image_frame_of_reference_uid = image_info.get("FrameOfReferenceUID")
+
+            else:
+                image_series_instance_uid = image_info.series_instance_uid
+                image_study_instance_uid = image_info.study_instance_uid
+                image_frame_of_reference_uid = image_info.frame_of_reference_uid
+
+            for reference_sequence_info in reference_sequence_infos:
+                if not all(
+                    (
+                        reference_sequence_info.series_instance_uid == image_series_instance_uid,
+                        reference_sequence_info.study_instance_uid == image_study_instance_uid,
+                    )
+                ):
+                    continue
+
+                for registration_info in registration_infos:
+                    if registration_info.frame_of_reference_uid != image_frame_of_reference_uid:
+                        continue
+
+                    combined_info.append(
+                        RegistrationInfo(
+                            registration_info,
+                            reference_sequence_info,
+                            all(is_ident(registration_info.transform_parameters)),
+                        )
+                    )
+
+        if len(combined_info) > 2:
+            warnings.warn("There are more than two DICOM images assigned to a registration!")
+
+        return tuple(combined_info)
+
+    def set_image_infos(self, image_infos: Tuple[DicomSeriesImageInfo, ...]) -> None:
+        """Set the :class:`DicomSeriesImageInfo` entries.
+
+        Args:
+            image_infos (Tuple[DicomSeriesImageInfo, ...]): The :class:`DicomSeriesImageInfo` entries to set.
+
+        Returns:
+            None
+        """
+        self.image_infos = image_infos
+
+        self._is_updated = False
+
+    def get_image_infos(self) -> Tuple[DicomSeriesImageInfo, ...]:
+        """Get the :class:`DicomSeriesImageInfo` entries.
+
+        Returns:
+            Tuple[DicomSeriesImageInfo, ...]: The :class:`DicomSeriesImageInfo` entries.
+        """
+        return self.image_infos
+
+    def update(self) -> None:
+        """Update the :class:`DicomSeriesRegistrationInfo`.
+
+        Returns:
+            None
+        """
+        if len(self.path) != 1:
+            raise ValueError("Only one registration file path is allowed, but multiple or none are provided!")
+
+        if not self.image_infos:
+            raise ValueError("No image infos are provided and thus no registration is possible!")
+
+        if not self.dataset:
+            self.dataset = load_dataset(self.path[0])
+
+        combined_info = self.get_registration_infos(self.dataset, self.image_infos)
+
+        for info in combined_info:
+            if info.is_reference_image:
+                self.referenced_series_instance_uid_identity = info.reference_info.series_instance_uid
+
+            else:
+                self.referenced_series_instance_uid_transform = info.reference_info.series_instance_uid
+
+                if len(info.registration_info.transforms) != 1:
+                    raise ValueError(
+                        f"The current implementation only supports registration files with "
+                        f"one transformation, but there are {len(info.registration_info.transforms)}!"
+                    )
+
+                self.transform = info.registration_info.transforms[0]
+                self.transform_parameters = info.registration_info.transform_parameters[0]
+
+        if not self.persistent_image_infos:
+            self.image_infos = tuple()
+
+        self._is_updated = True
+
+
+class DicomSeriesRTSSInfo(DicomSeriesInfo):
+    """A :class:`DicomSeriesInfo` class for DICOM-RTSS. In addition to the information provided by the
+    :class:`DicomSeriesInfo` class, this class contains a :class:`~pyradise.data.annotator.Annotator` instance and a
+    reference to the DICOM image associated with the DICOM-RTSS.
+
+    Args:
+        path (str): The path to the DICOM-RTSS file to load.
+    """
+
+    def __init__(self, path: str) -> None:
+        self.dataset: Optional[Dataset] = None
+        self.annotator: Annotator = Annotator.get_default()
+        self.referenced_instance_uid = ""
+        self.roi_names = []
+
+        super().__init__(path)
+
+        self.update()
+
+    def _get_dicom_base_info(self, additional_tags: Optional[Sequence[Tag]] = None) -> Dataset:
+        """Get the basic information from the initial DICOM file path.
+
+        Args:
+            additional_tags (Optional[Sequence[Tag]]): Additional tags to retrieve from the DICOM file.
+
+        Returns:
+            Dataset: The Dataset loaded.
+        """
+        additional_tags_ = [
+            Tag(0x3006, 0x0002),  # StructureSetLabel
+            Tag(0x0008, 0x1070),  # OperatorName
+            Tag(0x3006, 0x0010),  # ReferencedFrameOfReferenceSequence
+            Tag(0x3006, 0x0080),  # RTROIObservationsSequence
+            Tag(0x3006, 0x0020),
+        ]  # StructureSetROISequence
+
+        if additional_tags:
+            additional_tags_.extend(additional_tags)
+
+        self.dataset = super()._get_dicom_base_info(additional_tags_)
+
+        self.annotator = self._get_annotator_from_dicom(self.dataset)
+        self.referenced_instance_uid = self._get_referenced_series_instance_uid(self.dataset)
+        self.roi_names = self._get_roi_names()
+
+        self._is_updated = True
+
+        return self.dataset
+
+    @staticmethod
+    def _get_annotator_from_dicom(dataset: Dataset) -> Annotator:
+        """Get the :class:`~pyradise.data.annotator.Annotator` from the provided dataset.
+
+        Args:
+            dataset (Dataset): The dataset to retrieve the :class:`~pyradise.data.annotator.Annotator` from.
+
+        Returns:
+            Annotator: The annotator.
+        """
+        operator_name = str(dataset.get("OperatorsName", ""))
+
+        if operator_name:
+            operator_name = operator_name.replace(" ", "_")
+            pattern = r"""[^\da-zA-Z_-]+"""
+            regex = re.compile(pattern)
+            operator_name = regex.sub(r"", operator_name)
+
+            search_pattern = r"""[A-Z]+"""
+            abbreviation = "".join(re.findall(search_pattern, operator_name))
+            abbreviation = abbreviation if abbreviation else None
+
+            return Annotator(operator_name, abbreviation)
+
+        return Annotator.get_default()
+
+    def get_annotator(self) -> Annotator:
+        """Get the :class:`~pyradise.data.annotator.Annotator`.
+
+        Returns:
+            Annotator: The annotator.
+        """
+        return self.annotator
+
+    @staticmethod
+    def _get_referenced_series_instance_uid(dataset: Dataset) -> str:
+        """Get the referenced SeriesInstanceUID from the dataset.
+
+        Args:
+            dataset (Dataset): The dataset to retrieve the referenced SeriesInstanceUID from.
+
+        Returns:
+            str: The referenced SeriesInstanceUID
+        """
+        referenced_series_instance_uids = []
+
+        ref_frame_of_ref_sq = dataset.get("ReferencedFrameOfReferenceSequence", [])
+        for ref_frame_ref_item in ref_frame_of_ref_sq:
+            rt_ref_study_sq = ref_frame_ref_item.get("RTReferencedStudySequence", [])
+
+            for rt_ref_study_item in rt_ref_study_sq:
+                rt_ref_series_sq = rt_ref_study_item.get("RTReferencedSeriesSequence", [])
+
+                for rt_ref_series_item in rt_ref_series_sq:
+                    referenced_series_instance_uids.append(str(rt_ref_series_item.get("SeriesInstanceUID")))
+
+        if len(referenced_series_instance_uids) != 1:
+            raise ValueError(
+                f"There are multiple or no ({len(referenced_series_instance_uids)}) referenced "
+                f"SeriesInstanceUIDs, but only one is allowed!"
+            )
+
+        return referenced_series_instance_uids[0]
+
+    def _get_roi_names(self) -> List[str]:
+        """Get the ROI names from the dataset.
+
+        Returns:
+            List[str]: The ROI names.
+        """
+        roi_names = []
+
+        roi_sq = self.dataset.get("StructureSetROISequence", [])
+        for roi_item in roi_sq:
+            roi_names.append(str(roi_item.get("ROIName")))
+
+        return roi_names
+
+    # pylint: disable=unnecessary-pass
+    def update(self) -> None:
+        """Update the :class:`DicomSeriesRTSSInfo`.
+
+        Returns:
+            None
+        """
+        self._is_updated = True
```

### Comparing `pyradise-0.2.2/pyradise/fileio/writing.py` & `pyradise-0.2.3/pyradise/fileio/writing.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,589 +1,589 @@
-import os
-from distutils.dir_util import copy_tree
-from enum import Enum
-from io import BytesIO
-from pathlib import Path
-from shutil import copy2
-from typing import Callable, Optional, Tuple, Union
-from zipfile import ZipFile
-
-import itk
-import SimpleITK as sitk
-from pydicom import Dataset
-
-from pyradise.data import Annotator, IntensityImage, SegmentationImage, Subject
-from pyradise.utils import remove_illegal_folder_chars
-
-from .series_info import DicomSeriesInfo, SeriesInfo
-
-__all__ = [
-    "SubjectWriter",
-    "DirectorySubjectWriter",
-    "DicomSeriesSubjectWriter",
-    "ImageFileFormat",
-    "default_intensity_file_name_fn",
-    "default_segmentation_file_name_fn",
-]
-
-
-def default_intensity_file_name_fn(subject: Subject, image: IntensityImage) -> str:
-    """The default intensity file name generation function.
-
-    Important:
-        The file name must not contain the file extension because this is provided by the writer.
-
-    Args:
-        subject (Subject): The subject.
-        image (IntensityImage): The intensity image.
-
-    Returns:
-        str: The file name.
-    """
-    subject_name = remove_illegal_folder_chars(subject.name)
-    modality = remove_illegal_folder_chars(image.get_modality(as_str=True))
-    return f"img_{subject_name}_{modality}"
-
-
-def default_segmentation_file_name_fn(subject: Subject, image: SegmentationImage) -> str:
-    """The default segmentation file name generation function.
-
-    Important:
-        The file name must not contain the file extension because this is provided by the writer.
-
-    Args:
-        subject (Subject): The subject.
-        image (SegmentationImage): The segmentation image.
-
-    Returns:
-        str: The file name.
-    """
-    subject_name = remove_illegal_folder_chars(subject.name)
-    annotator_name = (
-        remove_illegal_folder_chars(image.get_annotator(as_str=True))
-        if isinstance(image.get_annotator(), Annotator)
-        else "NA"
-    )
-    organ_name = remove_illegal_folder_chars(image.get_organ(as_str=True))
-    return f"seg_{subject_name}_{annotator_name}_{organ_name}"
-
-
-class ImageFileFormat(Enum):
-    """An enumeration of possible output image file formats.
-
-    Notes:
-        The current implementation supports the following formats:
-
-            - NIFTI (.nii, .nii.gz)
-            - NRRD (.nrrd)
-            - MHA (.mha)
-
-        More image file formats will be added in the future.
-    """
-
-    NIFTI = ".nii"
-    """Image format NIFTI / extension .nii"""
-
-    NIFTI_GZ = ".nii.gz"
-    """Image format NIFTI GZ / extension .nii.gz"""
-
-    NRRD = ".nrrd"
-    """Image format NRRD / extension .nrrd"""
-
-    MHA = ".mha"
-    """Image format MHA / extension .mha"""
-
-
-class SubjectWriter:
-    """A class for writing the content of a :class:`~pyradise.data.subject.Subject` instance to a directory.
-
-    Notes:
-        This writer provides interfaces for file name generation functions which can be used to customize the file names
-        of the intensity and segmentation images. Please be aware that certain patterns may cause problems if
-        the data should be reloaded again (e.g. separation of information by underline while separating the annotators
-        name also with underline). Thus, check carefully if the file name generation function is suitable for your use
-        case.
-
-        Currently, the serialization of :class:`~pyradise.data.image.IntensityImage` s,
-        :class:`~pyradise.data.image.SegmentationImage` s, and transformations from the
-        :class:`~pyradise.data.taping.TransformTape` is supported. Other data types may be added in the future.
-
-    Args:
-        file_format (ImageFileFormat): The output file format (default: ImageFileFormat.NIFTI_GZ).
-        intensity_file_name_fn (Callable[[Subject, IntensityImage], str]): The function for generating the file names
-         of the intensity images (default: default_intensity_file_name_fn).
-        segmentation_file_name_fn (Callable[[Subject, SegmentationImage], str]): The function for generating the file
-         names of the segmentation images (default: default_segmentation_file_name_fn).
-        allow_override (bool): If True the writer can overwrite existing files, otherwise not (default: False).
-    """
-
-    def __init__(
-        self,
-        file_format: ImageFileFormat = ImageFileFormat.NIFTI_GZ,
-        intensity_file_name_fn: Callable[[Subject, IntensityImage], str] = default_intensity_file_name_fn,
-        segmentation_file_name_fn: Callable[[Subject, SegmentationImage], str] = default_segmentation_file_name_fn,
-        allow_override: bool = False,
-    ) -> None:
-        super().__init__()
-
-        self.image_file_format = file_format
-        self.intensity_file_name_fn = intensity_file_name_fn
-        self.segmentation_file_name_fn = segmentation_file_name_fn
-        self.allow_override = allow_override
-
-    def _generate_image_file_name(
-        self, subject: Subject, image: Union[IntensityImage, SegmentationImage], with_extension: bool = False
-    ) -> str:
-        """Generate an image file name.
-
-        Args:
-            subject (Subject): The subject of the image.
-            image (Union[IntensityImage, SegmentationImage]): The image for which the file name should be generated.
-            with_extension (bool): If True adds the file extension to the file name otherwise not.
-
-        Raises:
-            ValueError: If the image is not an :class:`IntensityImage` or :class:`SegmentationImage`.
-
-        Returns:
-            str: The file name of the image file.
-        """
-        if isinstance(image, IntensityImage):
-            file_name = self.intensity_file_name_fn(subject, image)
-
-        elif isinstance(image, SegmentationImage):
-            file_name = self.segmentation_file_name_fn(subject, image)
-
-        else:
-            raise ValueError(f"Unsupported data type {type(image)} received for serialization.")
-
-        if with_extension:
-            return file_name + str(self.image_file_format.value)
-
-        return file_name
-
-    def _generate_transform_file_name(
-        self,
-        subject: Subject,
-        image: Union[IntensityImage, SegmentationImage],
-        index: Union[int, str],
-        extension: str = ".tfm",
-    ) -> str:
-        """Generate a transformation file name.
-
-        Args:
-            subject (Subject): The subject where the transformation belongs to.
-            image (Union[IntensityImage, SegmentationImage]): The image to which the transformation belongs to.
-            index (Union[int, str]): The index of the transformation.
-            extension (str): The file extension for the transformation file (default: '.tfm').
-
-        Returns:
-            str: The file name of the transformation file.
-        """
-        if isinstance(image, IntensityImage):
-            file_name = "tfm_" + self.intensity_file_name_fn(subject, image) + f"_{str(index)}{extension}"
-        elif isinstance(image, SegmentationImage):
-            file_name = "tfm_" + self.segmentation_file_name_fn(subject, image) + f"_{str(index)}{extension}"
-        else:
-            raise ValueError(f"Unsupported data type {type(image)} received for serialization.")
-
-        return file_name
-
-    def _check_file_path(self, path: str) -> None:
-        """Check if the file path is valid.
-
-        Args:
-            path (str): The file path to check.
-
-        Returns:
-            None
-        """
-        if os.path.exists(path):
-            if self.allow_override:
-                os.remove(path)
-            else:
-                raise FileExistsError(
-                    f"The file with path {path} is already existing and " "allow_override is set to false!"
-                )
-
-    def write(self, path: str, subject: Subject, write_transforms: bool = True) -> None:
-        """Write a :class:`~pyradise.data.subject.Subject` instance to the specified directory.
-
-        Args:
-            path (str): The path to the subject directory.
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` to be written.
-            write_transforms (bool): If True writes the transformation files for each
-             :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instance,
-             otherwise not (default: True).
-
-        Returns:
-            None
-        """
-        if not os.path.exists(path):
-            raise NotADirectoryError(f"The directory {path} does not exist!")
-
-        images = []
-        images.extend(subject.intensity_images)
-        images.extend(subject.segmentation_images)
-
-        for image in images:
-            image_file_name = self._generate_image_file_name(subject, image)
-            image_file_path = os.path.join(path, image_file_name + str(self.image_file_format.value))
-
-            self._check_file_path(image_file_path)
-
-            itk.imwrite(image.get_image_data(as_sitk=False), image_file_path)
-
-            if write_transforms:
-                for i, transform_info in enumerate(image.get_transform_tape().get_recorded_elements()):
-                    transform = transform_info.get_transform()
-                    transform_file_name = self._generate_transform_file_name(subject, image, i)
-                    transform_file_path = os.path.join(path, transform_file_name)
-
-                    self._check_file_path(transform_file_path)
-
-                    sitk.WriteTransform(transform, transform_file_path)
-
-    def write_to_subject_folder(self, base_dir_path: str, subject: Subject, write_transforms: bool = True) -> None:
-        """Write a :class:`~pyradise.data.subject.Subject` instance to a separate subject directory within the
-        specified base directory. The newly created subject directory will be named with the subjects name.
-
-        Notes:
-            This is function is just a wrapper around the write function and reduces the amount of code which is
-            required to write each subject to a separate directory.
-
-        Args:
-            base_dir_path (str): The path to the base directory where the subject directory will be placed.
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` to be written.
-            write_transforms (bool): If True writes the transformation files for each
-             :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instance,
-             otherwise not (default: True).
-
-        Returns:
-            None
-        """
-        subject_path = os.path.normpath(os.path.join(base_dir_path, subject.name))
-        if not os.path.exists(subject_path):
-            os.mkdir(subject_path)
-        else:
-            raise FileExistsError(f"The subject directory {subject_path} is already existing!")
-
-        self.write(subject_path, subject, write_transforms)
-
-
-class DicomSeriesSubjectWriter:
-    """A writer class for writing DICOM :class:`~pydicom.dataset.Dataset` instances to disk. In addition, it is feasible
-    to copy DICOM data (specified by :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries) from a source
-    directory to the target directory. This writer is also feasible to save all data within a zip file instead of
-    a directory.
-
-    Note:
-        In contrast to the :class:`DirectorySubjectWriter` the :class:`DicomSeriesSubjectWriter` provides a different
-        interface which takes a tuple of :class:`~pyradise.fileio.series_info.DicomSeriesInfo` instead of a directory
-        path for copying existing data.
-
-        The additional copying functionality is useful if the input DICOM data should be copied to the output directory
-        as it is often the case when building processing pipelines.
-
-    Args:
-        as_zip (bool): Indicates if the output should be a zip file or a normal directory (default: False).
-    """
-
-    def __init__(self, as_zip: bool = False) -> None:
-        super().__init__()
-
-        self.as_zip = as_zip
-
-    @staticmethod
-    def _write_to_folder(
-        series_infos: Tuple[DicomSeriesInfo],
-        datasets: Tuple[Tuple[str, Dataset], ...],
-        output_path: str,
-        folder_name: Optional[str],
-    ) -> None:
-        """Write the provided datasets to the specified folder while copying also the files associated with the
-        ``series_infos`` to the ``output_path``.
-
-        Args:
-            series_infos (Tuple[DicomSeriesInfo]): The DICOM series infos which will be copied.
-            datasets (Tuple[Tuple[str, Dataset], ...]): The datasets which will be written to the folder.
-            output_path (str): The path to the output folder.
-            folder_name (Optional[str]): The name of the folder where the data will be written to. If None no new
-             folder will be generated and the data will be directly be written into the specified ``output_path``.
-
-        Returns:
-            None
-        """
-        # prepare the output directory
-        if folder_name:
-            output_dir_path = os.path.join(output_path, folder_name)
-        else:
-            output_dir_path = output_path
-
-        if not os.path.exists(output_dir_path):
-            os.mkdir(output_dir_path)
-
-        # prepare for copying the data
-        source_file_paths = []
-        target_file_paths = []
-
-        for series_info in series_infos:
-            paths = series_info.get_path()
-            source_file_paths.extend(paths)
-
-            for path in paths:
-                target_path = os.path.join(output_dir_path, Path(path).name)
-                target_file_paths.append(target_path)
-
-        # copy the files
-        for source_path, target_path in zip(source_file_paths, target_file_paths):
-            copy2(source_path, target_path)
-
-        # write the datasets
-        if datasets:
-            for name, dataset in datasets:
-                if not name.endswith(".dcm"):
-                    name += ".dcm"
-
-                dataset.save_as(os.path.join(output_dir_path, name))
-
-    @staticmethod
-    def _write_to_zip(
-        series_infos: Tuple[DicomSeriesInfo],
-        datasets: Tuple[Tuple[str, Dataset], ...],
-        output_path: str,
-        folder_name: str,
-    ) -> None:
-        """Write the provided datasets to the specified folder as a zip file while also copying the files associated
-        with the ``series_infos`` into the zip file.
-
-        Args:
-            series_infos (Tuple[DicomSeriesInfo]): The DICOM series infos which will be copied into the zip file.
-            datasets (Tuple[Tuple[str, Dataset], ...]): The datasets which will be written to the zip file.
-            output_path (str): The path to the output folder.
-            folder_name (str): The name of the zip file where the data will be written to.
-
-        Returns:
-            None
-        """
-        if not folder_name:
-            raise ValueError("For zipping an folder name must be provided!")
-
-        if not folder_name.endswith(".zip"):
-            folder_name += ".zip"
-
-        output_path = os.path.join(output_path, folder_name)
-
-        if os.path.exists(output_path):
-            raise Exception(f"The output file {output_path} is already existing!")
-
-        with ZipFile(output_path, "w") as file:
-            # write / copy the series infos
-            for series_info in series_infos:
-                source_paths = series_info.get_path()
-
-                for path in source_paths:
-                    file.write(path, os.path.basename(path))
-
-            if datasets:
-                for name, dataset in datasets:
-                    if name.endswith(".dcm"):
-                        file_name = name
-                    else:
-                        file_name = name + ".dcm"
-
-                    out = BytesIO()
-                    dataset.save_as(out)
-
-                    file.writestr(file_name, out.getvalue())
-
-    def write(
-        self,
-        datasets: Tuple[Tuple[str, Dataset], ...],
-        output_path: str,
-        folder_name: Optional[str] = None,
-        series_infos: Optional[Tuple[SeriesInfo, ...]] = None,
-    ) -> None:
-        """Write the provided data to a directory or a zip file.
-
-        Args:
-            datasets (Tuple[Tuple[str, Dataset], ...]): The :class:`~pydicom.dataset.Dataset` instances to write and
-             its file names.
-            output_path (str): The output path.
-            folder_name (str): The name of the output folder or the zip file (default: None).
-            series_infos (Optional[Tuple[SeriesInfo, ...]]): The :class:`~pyradise.fileio.series_info.DicomSeriesInfo`
-             instances containing the path for DICOM files to copy (default: None).
-
-        Returns:
-            None
-        """
-        if not os.path.exists(output_path):
-            raise Exception(f"The output path {output_path} is already existing!")
-
-        if not os.path.isdir(output_path):
-            raise NotADirectoryError(f"The output path {output_path} is not a directory!")
-
-        if folder_name is not None:
-            folder_name = remove_illegal_folder_chars(folder_name)
-
-        if not series_infos:
-            series_infos = []
-        series_infos_ = tuple([info for info in series_infos if isinstance(info, DicomSeriesInfo)])
-
-        if self.as_zip:
-            if not folder_name:
-                raise ValueError("For zipping an folder name must be provided!")
-            self._write_to_zip(series_infos_, datasets, output_path, folder_name)
-        else:
-            self._write_to_folder(series_infos_, datasets, output_path, folder_name)
-
-
-class DirectorySubjectWriter:
-    """A writer class for writing DICOM :class:`~pydicom.dataset.Dataset` instances to disk. In addition, it is feasible
-    to copy data (specified by a directory path) from a source directory to the target directory. This writer is also
-    feasible to save all data within a zip file instead of a directory.
-
-    Note:
-        In contrast to the :class:`DicomSeriesSubjectWriter` the :class:`DirectorySubjectWriter` provides a different
-        interface which takes a directory path instead of a tuple of
-        :class:`~pyradise.fileio.series_info.DicomSeriesInfo` instances for copying existing data.
-
-        The additional copying functionality is useful if the input DICOM data should be copied to the output directory
-        as it is often the case when building processing pipelines.
-
-    Args:
-        as_zip (bool): Indicates if the output should be a zip file or a normal directory (default: False).
-    """
-
-    def __init__(self, as_zip: bool = False) -> None:
-        super().__init__()
-
-        self.as_zip = as_zip
-
-    @staticmethod
-    def _write_to_zip(
-        datasets: Tuple[Tuple[str, Dataset], ...],
-        copy_dir_path: Optional[str],
-        output_path: str,
-        folder_name: str,
-    ) -> None:
-        """Write the provided datasets to the specified folder as a zip file while also copying the files located in
-        the ``copy_dir_path`` into the zip file.
-
-        Args:
-            copy_dir_path (Optional[str]): The path to the directory which will be copied to the output.
-            datasets (Tuple[Tuple[str, Dataset], ...]): The datasets which will be written to the zip file.
-            output_path (str): The path to the output folder.
-            folder_name (str): The name of the zip file where the data will be written to.
-
-        Returns:
-            None
-        """
-        if not folder_name.endswith(".zip"):
-            folder_name += ".zip"
-
-        output_path = os.path.join(output_path, folder_name)
-
-        if os.path.exists(output_path):
-            raise Exception(f"The output file {output_path} is already existing!")
-
-        with ZipFile(output_path, "w") as zip_file:
-            # write / copy the files and folders
-            if copy_dir_path:
-                for root, _, files in os.walk(copy_dir_path, topdown=True):
-                    for file in files:
-                        zip_file.write(os.path.join(root, file), os.path.join(root.replace(copy_dir_path, ""), file))
-
-            if datasets:
-                for name, dataset in datasets:
-                    if name.endswith(".dcm"):
-                        file_name = name
-                    else:
-                        file_name = name + ".dcm"
-
-                    out = BytesIO()
-                    dataset.save_as(out)
-
-                    zip_file.writestr(file_name, out.getvalue())
-
-    @staticmethod
-    def _write_to_folder(
-        datasets: Tuple[Tuple[str, Dataset], ...],
-        copy_dir_path: Optional[str],
-        output_path: str,
-        folder_name: Optional[str],
-    ) -> None:
-        """Write the provided datasets to the specified folder while copying also the files associated with the
-        ``copy_dir_path`` to the ``output_path``.
-
-        Args:
-            datasets (Tuple[Tuple[str, Dataset], ...]): The datasets which will be written to the folder.
-            copy_dir_path (Optional[str]): The path to the directory which will be copied to the output.
-            output_path (str): The output path.
-            folder_name (Optional[str]): The name of the folder where the data will be written to. If None no new
-             folder will be generated and the data will be directly be written into the specified ``output_path``.
-
-        Returns:
-            None
-        """
-        # prepare the output directory
-        if folder_name:
-            output_dir_path = os.path.join(output_path, folder_name)
-        else:
-            output_dir_path = output_path
-
-        if not os.path.exists(output_dir_path):
-            os.mkdir(output_dir_path)
-
-        # copy the files
-        if copy_dir_path:
-            copy_tree(copy_dir_path, output_dir_path, preserve_mode=True, preserve_times=True)
-
-        # write the datasets
-        if datasets:
-            for name, dataset in datasets:
-                if not name.endswith(".dcm"):
-                    name += ".dcm"
-
-                output_path = os.path.join(output_dir_path, name)
-                dataset.save_as(output_path)
-
-    def write(
-        self,
-        datasets: Tuple[Tuple[str, Dataset], ...],
-        output_path: str,
-        folder_name: Optional[str] = None,
-        copy_dir_path: Optional[str] = None,
-    ) -> None:
-        """Write the provided data to a directory or a zip file.
-
-        Args:
-            datasets (Tuple[Tuple[str, Dataset], ...]): The :class:`~pydicom.dataset.Dataset` instances to write and
-             its file names.
-            output_path (str): The path to the output base directory.
-            folder_name (Optional[str]): The name of the folder or the zip file (default: None).
-            copy_dir_path (str): The path to the directory from which all data should be copied (default: None).
-
-        Returns:
-            None
-        """
-        if copy_dir_path is not None:
-            if not os.path.exists(copy_dir_path):
-                raise Exception(f"The copy directory path {copy_dir_path} is invalid!")
-
-            if not os.path.isdir(copy_dir_path):
-                raise NotADirectoryError(f"The copy directory path {copy_dir_path} is not a directory!")
-
-        if not os.path.exists(output_path):
-            raise Exception(f"The output path {output_path} is already existing!")
-
-        if not os.path.isdir(output_path):
-            raise NotADirectoryError(f"The output path {output_path} is not a directory!")
-
-        if isinstance(folder_name, str):
-            folder_name = remove_illegal_folder_chars(folder_name)
-
-        if self.as_zip:
-            if not folder_name:
-                raise ValueError("For zipping an folder name must be provided!")
-            self._write_to_zip(datasets, copy_dir_path, output_path, folder_name)
-        else:
-            self._write_to_folder(datasets, copy_dir_path, output_path, folder_name)
+import os
+from distutils.dir_util import copy_tree
+from enum import Enum
+from io import BytesIO
+from pathlib import Path
+from shutil import copy2
+from typing import Callable, Optional, Tuple, Union
+from zipfile import ZipFile
+
+import itk
+import SimpleITK as sitk
+from pydicom import Dataset
+
+from pyradise.data import Annotator, IntensityImage, SegmentationImage, Subject
+from pyradise.utils import remove_illegal_folder_chars
+
+from .series_info import DicomSeriesInfo, SeriesInfo
+
+__all__ = [
+    "SubjectWriter",
+    "DirectorySubjectWriter",
+    "DicomSeriesSubjectWriter",
+    "ImageFileFormat",
+    "default_intensity_file_name_fn",
+    "default_segmentation_file_name_fn",
+]
+
+
+def default_intensity_file_name_fn(subject: Subject, image: IntensityImage) -> str:
+    """The default intensity file name generation function.
+
+    Important:
+        The file name must not contain the file extension because this is provided by the writer.
+
+    Args:
+        subject (Subject): The subject.
+        image (IntensityImage): The intensity image.
+
+    Returns:
+        str: The file name.
+    """
+    subject_name = remove_illegal_folder_chars(subject.name)
+    modality = remove_illegal_folder_chars(image.get_modality(as_str=True))
+    return f"img_{subject_name}_{modality}"
+
+
+def default_segmentation_file_name_fn(subject: Subject, image: SegmentationImage) -> str:
+    """The default segmentation file name generation function.
+
+    Important:
+        The file name must not contain the file extension because this is provided by the writer.
+
+    Args:
+        subject (Subject): The subject.
+        image (SegmentationImage): The segmentation image.
+
+    Returns:
+        str: The file name.
+    """
+    subject_name = remove_illegal_folder_chars(subject.name)
+    annotator_name = (
+        remove_illegal_folder_chars(image.get_annotator(as_str=True))
+        if isinstance(image.get_annotator(), Annotator)
+        else "NA"
+    )
+    organ_name = remove_illegal_folder_chars(image.get_organ(as_str=True))
+    return f"seg_{subject_name}_{annotator_name}_{organ_name}"
+
+
+class ImageFileFormat(Enum):
+    """An enumeration of possible output image file formats.
+
+    Notes:
+        The current implementation supports the following formats:
+
+            - NIFTI (.nii, .nii.gz)
+            - NRRD (.nrrd)
+            - MHA (.mha)
+
+        More image file formats will be added in the future.
+    """
+
+    NIFTI = ".nii"
+    """Image format NIFTI / extension .nii"""
+
+    NIFTI_GZ = ".nii.gz"
+    """Image format NIFTI GZ / extension .nii.gz"""
+
+    NRRD = ".nrrd"
+    """Image format NRRD / extension .nrrd"""
+
+    MHA = ".mha"
+    """Image format MHA / extension .mha"""
+
+
+class SubjectWriter:
+    """A class for writing the content of a :class:`~pyradise.data.subject.Subject` instance to a directory.
+
+    Notes:
+        This writer provides interfaces for file name generation functions which can be used to customize the file names
+        of the intensity and segmentation images. Please be aware that certain patterns may cause problems if
+        the data should be reloaded again (e.g. separation of information by underline while separating the annotators
+        name also with underline). Thus, check carefully if the file name generation function is suitable for your use
+        case.
+
+        Currently, the serialization of :class:`~pyradise.data.image.IntensityImage` s,
+        :class:`~pyradise.data.image.SegmentationImage` s, and transformations from the
+        :class:`~pyradise.data.taping.TransformTape` is supported. Other data types may be added in the future.
+
+    Args:
+        file_format (ImageFileFormat): The output file format (default: ImageFileFormat.NIFTI_GZ).
+        intensity_file_name_fn (Callable[[Subject, IntensityImage], str]): The function for generating the file names
+         of the intensity images (default: default_intensity_file_name_fn).
+        segmentation_file_name_fn (Callable[[Subject, SegmentationImage], str]): The function for generating the file
+         names of the segmentation images (default: default_segmentation_file_name_fn).
+        allow_override (bool): If True the writer can overwrite existing files, otherwise not (default: False).
+    """
+
+    def __init__(
+        self,
+        file_format: ImageFileFormat = ImageFileFormat.NIFTI_GZ,
+        intensity_file_name_fn: Callable[[Subject, IntensityImage], str] = default_intensity_file_name_fn,
+        segmentation_file_name_fn: Callable[[Subject, SegmentationImage], str] = default_segmentation_file_name_fn,
+        allow_override: bool = False,
+    ) -> None:
+        super().__init__()
+
+        self.image_file_format = file_format
+        self.intensity_file_name_fn = intensity_file_name_fn
+        self.segmentation_file_name_fn = segmentation_file_name_fn
+        self.allow_override = allow_override
+
+    def _generate_image_file_name(
+        self, subject: Subject, image: Union[IntensityImage, SegmentationImage], with_extension: bool = False
+    ) -> str:
+        """Generate an image file name.
+
+        Args:
+            subject (Subject): The subject of the image.
+            image (Union[IntensityImage, SegmentationImage]): The image for which the file name should be generated.
+            with_extension (bool): If True adds the file extension to the file name otherwise not.
+
+        Raises:
+            ValueError: If the image is not an :class:`IntensityImage` or :class:`SegmentationImage`.
+
+        Returns:
+            str: The file name of the image file.
+        """
+        if isinstance(image, IntensityImage):
+            file_name = self.intensity_file_name_fn(subject, image)
+
+        elif isinstance(image, SegmentationImage):
+            file_name = self.segmentation_file_name_fn(subject, image)
+
+        else:
+            raise ValueError(f"Unsupported data type {type(image)} received for serialization.")
+
+        if with_extension:
+            return file_name + str(self.image_file_format.value)
+
+        return file_name
+
+    def _generate_transform_file_name(
+        self,
+        subject: Subject,
+        image: Union[IntensityImage, SegmentationImage],
+        index: Union[int, str],
+        extension: str = ".tfm",
+    ) -> str:
+        """Generate a transformation file name.
+
+        Args:
+            subject (Subject): The subject where the transformation belongs to.
+            image (Union[IntensityImage, SegmentationImage]): The image to which the transformation belongs to.
+            index (Union[int, str]): The index of the transformation.
+            extension (str): The file extension for the transformation file (default: '.tfm').
+
+        Returns:
+            str: The file name of the transformation file.
+        """
+        if isinstance(image, IntensityImage):
+            file_name = "tfm_" + self.intensity_file_name_fn(subject, image) + f"_{str(index)}{extension}"
+        elif isinstance(image, SegmentationImage):
+            file_name = "tfm_" + self.segmentation_file_name_fn(subject, image) + f"_{str(index)}{extension}"
+        else:
+            raise ValueError(f"Unsupported data type {type(image)} received for serialization.")
+
+        return file_name
+
+    def _check_file_path(self, path: str) -> None:
+        """Check if the file path is valid.
+
+        Args:
+            path (str): The file path to check.
+
+        Returns:
+            None
+        """
+        if os.path.exists(path):
+            if self.allow_override:
+                os.remove(path)
+            else:
+                raise FileExistsError(
+                    f"The file with path {path} is already existing and " "allow_override is set to false!"
+                )
+
+    def write(self, path: str, subject: Subject, write_transforms: bool = True) -> None:
+        """Write a :class:`~pyradise.data.subject.Subject` instance to the specified directory.
+
+        Args:
+            path (str): The path to the subject directory.
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` to be written.
+            write_transforms (bool): If True writes the transformation files for each
+             :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instance,
+             otherwise not (default: True).
+
+        Returns:
+            None
+        """
+        if not os.path.exists(path):
+            raise NotADirectoryError(f"The directory {path} does not exist!")
+
+        images = []
+        images.extend(subject.intensity_images)
+        images.extend(subject.segmentation_images)
+
+        for image in images:
+            image_file_name = self._generate_image_file_name(subject, image)
+            image_file_path = os.path.join(path, image_file_name + str(self.image_file_format.value))
+
+            self._check_file_path(image_file_path)
+
+            itk.imwrite(image.get_image_data(as_sitk=False), image_file_path)
+
+            if write_transforms:
+                for i, transform_info in enumerate(image.get_transform_tape().get_recorded_elements()):
+                    transform = transform_info.get_transform()
+                    transform_file_name = self._generate_transform_file_name(subject, image, i)
+                    transform_file_path = os.path.join(path, transform_file_name)
+
+                    self._check_file_path(transform_file_path)
+
+                    sitk.WriteTransform(transform, transform_file_path)
+
+    def write_to_subject_folder(self, base_dir_path: str, subject: Subject, write_transforms: bool = True) -> None:
+        """Write a :class:`~pyradise.data.subject.Subject` instance to a separate subject directory within the
+        specified base directory. The newly created subject directory will be named with the subjects name.
+
+        Notes:
+            This is function is just a wrapper around the write function and reduces the amount of code which is
+            required to write each subject to a separate directory.
+
+        Args:
+            base_dir_path (str): The path to the base directory where the subject directory will be placed.
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` to be written.
+            write_transforms (bool): If True writes the transformation files for each
+             :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instance,
+             otherwise not (default: True).
+
+        Returns:
+            None
+        """
+        subject_path = os.path.normpath(os.path.join(base_dir_path, subject.name))
+        if not os.path.exists(subject_path):
+            os.mkdir(subject_path)
+        else:
+            raise FileExistsError(f"The subject directory {subject_path} is already existing!")
+
+        self.write(subject_path, subject, write_transforms)
+
+
+class DicomSeriesSubjectWriter:
+    """A writer class for writing DICOM :class:`~pydicom.dataset.Dataset` instances to disk. In addition, it is feasible
+    to copy DICOM data (specified by :class:`~pyradise.fileio.series_info.DicomSeriesInfo` entries) from a source
+    directory to the target directory. This writer is also feasible to save all data within a zip file instead of
+    a directory.
+
+    Note:
+        In contrast to the :class:`DirectorySubjectWriter` the :class:`DicomSeriesSubjectWriter` provides a different
+        interface which takes a tuple of :class:`~pyradise.fileio.series_info.DicomSeriesInfo` instead of a directory
+        path for copying existing data.
+
+        The additional copying functionality is useful if the input DICOM data should be copied to the output directory
+        as it is often the case when building processing pipelines.
+
+    Args:
+        as_zip (bool): Indicates if the output should be a zip file or a normal directory (default: False).
+    """
+
+    def __init__(self, as_zip: bool = False) -> None:
+        super().__init__()
+
+        self.as_zip = as_zip
+
+    @staticmethod
+    def _write_to_folder(
+        series_infos: Tuple[DicomSeriesInfo],
+        datasets: Tuple[Tuple[str, Dataset], ...],
+        output_path: str,
+        folder_name: Optional[str],
+    ) -> None:
+        """Write the provided datasets to the specified folder while copying also the files associated with the
+        ``series_infos`` to the ``output_path``.
+
+        Args:
+            series_infos (Tuple[DicomSeriesInfo]): The DICOM series infos which will be copied.
+            datasets (Tuple[Tuple[str, Dataset], ...]): The datasets which will be written to the folder.
+            output_path (str): The path to the output folder.
+            folder_name (Optional[str]): The name of the folder where the data will be written to. If None no new
+             folder will be generated and the data will be directly be written into the specified ``output_path``.
+
+        Returns:
+            None
+        """
+        # prepare the output directory
+        if folder_name:
+            output_dir_path = os.path.join(output_path, folder_name)
+        else:
+            output_dir_path = output_path
+
+        if not os.path.exists(output_dir_path):
+            os.mkdir(output_dir_path)
+
+        # prepare for copying the data
+        source_file_paths = []
+        target_file_paths = []
+
+        for series_info in series_infos:
+            paths = series_info.get_path()
+            source_file_paths.extend(paths)
+
+            for path in paths:
+                target_path = os.path.join(output_dir_path, Path(path).name)
+                target_file_paths.append(target_path)
+
+        # copy the files
+        for source_path, target_path in zip(source_file_paths, target_file_paths):
+            copy2(source_path, target_path)
+
+        # write the datasets
+        if datasets:
+            for name, dataset in datasets:
+                if not name.endswith(".dcm"):
+                    name += ".dcm"
+
+                dataset.save_as(os.path.join(output_dir_path, name))
+
+    @staticmethod
+    def _write_to_zip(
+        series_infos: Tuple[DicomSeriesInfo],
+        datasets: Tuple[Tuple[str, Dataset], ...],
+        output_path: str,
+        folder_name: str,
+    ) -> None:
+        """Write the provided datasets to the specified folder as a zip file while also copying the files associated
+        with the ``series_infos`` into the zip file.
+
+        Args:
+            series_infos (Tuple[DicomSeriesInfo]): The DICOM series infos which will be copied into the zip file.
+            datasets (Tuple[Tuple[str, Dataset], ...]): The datasets which will be written to the zip file.
+            output_path (str): The path to the output folder.
+            folder_name (str): The name of the zip file where the data will be written to.
+
+        Returns:
+            None
+        """
+        if not folder_name:
+            raise ValueError("For zipping an folder name must be provided!")
+
+        if not folder_name.endswith(".zip"):
+            folder_name += ".zip"
+
+        output_path = os.path.join(output_path, folder_name)
+
+        if os.path.exists(output_path):
+            raise Exception(f"The output file {output_path} is already existing!")
+
+        with ZipFile(output_path, "w") as file:
+            # write / copy the series infos
+            for series_info in series_infos:
+                source_paths = series_info.get_path()
+
+                for path in source_paths:
+                    file.write(path, os.path.basename(path))
+
+            if datasets:
+                for name, dataset in datasets:
+                    if name.endswith(".dcm"):
+                        file_name = name
+                    else:
+                        file_name = name + ".dcm"
+
+                    out = BytesIO()
+                    dataset.save_as(out)
+
+                    file.writestr(file_name, out.getvalue())
+
+    def write(
+        self,
+        datasets: Tuple[Tuple[str, Dataset], ...],
+        output_path: str,
+        folder_name: Optional[str] = None,
+        series_infos: Optional[Tuple[SeriesInfo, ...]] = None,
+    ) -> None:
+        """Write the provided data to a directory or a zip file.
+
+        Args:
+            datasets (Tuple[Tuple[str, Dataset], ...]): The :class:`~pydicom.dataset.Dataset` instances to write and
+             its file names.
+            output_path (str): The output path.
+            folder_name (str): The name of the output folder or the zip file (default: None).
+            series_infos (Optional[Tuple[SeriesInfo, ...]]): The :class:`~pyradise.fileio.series_info.DicomSeriesInfo`
+             instances containing the path for DICOM files to copy (default: None).
+
+        Returns:
+            None
+        """
+        if not os.path.exists(output_path):
+            raise Exception(f"The output path {output_path} is already existing!")
+
+        if not os.path.isdir(output_path):
+            raise NotADirectoryError(f"The output path {output_path} is not a directory!")
+
+        if folder_name is not None:
+            folder_name = remove_illegal_folder_chars(folder_name)
+
+        if not series_infos:
+            series_infos = []
+        series_infos_ = tuple([info for info in series_infos if isinstance(info, DicomSeriesInfo)])
+
+        if self.as_zip:
+            if not folder_name:
+                raise ValueError("For zipping an folder name must be provided!")
+            self._write_to_zip(series_infos_, datasets, output_path, folder_name)
+        else:
+            self._write_to_folder(series_infos_, datasets, output_path, folder_name)
+
+
+class DirectorySubjectWriter:
+    """A writer class for writing DICOM :class:`~pydicom.dataset.Dataset` instances to disk. In addition, it is feasible
+    to copy data (specified by a directory path) from a source directory to the target directory. This writer is also
+    feasible to save all data within a zip file instead of a directory.
+
+    Note:
+        In contrast to the :class:`DicomSeriesSubjectWriter` the :class:`DirectorySubjectWriter` provides a different
+        interface which takes a directory path instead of a tuple of
+        :class:`~pyradise.fileio.series_info.DicomSeriesInfo` instances for copying existing data.
+
+        The additional copying functionality is useful if the input DICOM data should be copied to the output directory
+        as it is often the case when building processing pipelines.
+
+    Args:
+        as_zip (bool): Indicates if the output should be a zip file or a normal directory (default: False).
+    """
+
+    def __init__(self, as_zip: bool = False) -> None:
+        super().__init__()
+
+        self.as_zip = as_zip
+
+    @staticmethod
+    def _write_to_zip(
+        datasets: Tuple[Tuple[str, Dataset], ...],
+        copy_dir_path: Optional[str],
+        output_path: str,
+        folder_name: str,
+    ) -> None:
+        """Write the provided datasets to the specified folder as a zip file while also copying the files located in
+        the ``copy_dir_path`` into the zip file.
+
+        Args:
+            copy_dir_path (Optional[str]): The path to the directory which will be copied to the output.
+            datasets (Tuple[Tuple[str, Dataset], ...]): The datasets which will be written to the zip file.
+            output_path (str): The path to the output folder.
+            folder_name (str): The name of the zip file where the data will be written to.
+
+        Returns:
+            None
+        """
+        if not folder_name.endswith(".zip"):
+            folder_name += ".zip"
+
+        output_path = os.path.join(output_path, folder_name)
+
+        if os.path.exists(output_path):
+            raise Exception(f"The output file {output_path} is already existing!")
+
+        with ZipFile(output_path, "w") as zip_file:
+            # write / copy the files and folders
+            if copy_dir_path:
+                for root, _, files in os.walk(copy_dir_path, topdown=True):
+                    for file in files:
+                        zip_file.write(os.path.join(root, file), os.path.join(root.replace(copy_dir_path, ""), file))
+
+            if datasets:
+                for name, dataset in datasets:
+                    if name.endswith(".dcm"):
+                        file_name = name
+                    else:
+                        file_name = name + ".dcm"
+
+                    out = BytesIO()
+                    dataset.save_as(out)
+
+                    zip_file.writestr(file_name, out.getvalue())
+
+    @staticmethod
+    def _write_to_folder(
+        datasets: Tuple[Tuple[str, Dataset], ...],
+        copy_dir_path: Optional[str],
+        output_path: str,
+        folder_name: Optional[str],
+    ) -> None:
+        """Write the provided datasets to the specified folder while copying also the files associated with the
+        ``copy_dir_path`` to the ``output_path``.
+
+        Args:
+            datasets (Tuple[Tuple[str, Dataset], ...]): The datasets which will be written to the folder.
+            copy_dir_path (Optional[str]): The path to the directory which will be copied to the output.
+            output_path (str): The output path.
+            folder_name (Optional[str]): The name of the folder where the data will be written to. If None no new
+             folder will be generated and the data will be directly be written into the specified ``output_path``.
+
+        Returns:
+            None
+        """
+        # prepare the output directory
+        if folder_name:
+            output_dir_path = os.path.join(output_path, folder_name)
+        else:
+            output_dir_path = output_path
+
+        if not os.path.exists(output_dir_path):
+            os.mkdir(output_dir_path)
+
+        # copy the files
+        if copy_dir_path:
+            copy_tree(copy_dir_path, output_dir_path, preserve_mode=True, preserve_times=True)
+
+        # write the datasets
+        if datasets:
+            for name, dataset in datasets:
+                if not name.endswith(".dcm"):
+                    name += ".dcm"
+
+                output_path = os.path.join(output_dir_path, name)
+                dataset.save_as(output_path)
+
+    def write(
+        self,
+        datasets: Tuple[Tuple[str, Dataset], ...],
+        output_path: str,
+        folder_name: Optional[str] = None,
+        copy_dir_path: Optional[str] = None,
+    ) -> None:
+        """Write the provided data to a directory or a zip file.
+
+        Args:
+            datasets (Tuple[Tuple[str, Dataset], ...]): The :class:`~pydicom.dataset.Dataset` instances to write and
+             its file names.
+            output_path (str): The path to the output base directory.
+            folder_name (Optional[str]): The name of the folder or the zip file (default: None).
+            copy_dir_path (str): The path to the directory from which all data should be copied (default: None).
+
+        Returns:
+            None
+        """
+        if copy_dir_path is not None:
+            if not os.path.exists(copy_dir_path):
+                raise Exception(f"The copy directory path {copy_dir_path} is invalid!")
+
+            if not os.path.isdir(copy_dir_path):
+                raise NotADirectoryError(f"The copy directory path {copy_dir_path} is not a directory!")
+
+        if not os.path.exists(output_path):
+            raise Exception(f"The output path {output_path} is already existing!")
+
+        if not os.path.isdir(output_path):
+            raise NotADirectoryError(f"The output path {output_path} is not a directory!")
+
+        if isinstance(folder_name, str):
+            folder_name = remove_illegal_folder_chars(folder_name)
+
+        if self.as_zip:
+            if not folder_name:
+                raise ValueError("For zipping an folder name must be provided!")
+            self._write_to_zip(datasets, copy_dir_path, output_path, folder_name)
+        else:
+            self._write_to_folder(datasets, copy_dir_path, output_path, folder_name)
```

### Comparing `pyradise-0.2.2/pyradise/process/__init__.py` & `pyradise-0.2.3/pyradise/process/__init__.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,37 +1,37 @@
-from .base import (Filter, FilterParams, FilterPipeline, LoopEntryFilter,
-                   LoopEntryFilterParams)
-from .inference import (IndexingStrategy, InferenceFilter,
-                        InferenceFilterParams, PatchIndexingStrategy,
-                        SliceIndexingStrategy)
-from .intensity import (ClipIntensityFilter, ClipIntensityFilterParams,
-                        GaussianFilter, GaussianFilterParams, IntensityFilter,
-                        IntensityFilterParams, IntensityLoopFilter,
-                        IntensityLoopFilterParams, LaplacianFilter,
-                        LaplacianFilterParams, MedianFilter,
-                        MedianFilterParams, RescaleIntensityFilter,
-                        RescaleIntensityFilterParams, ZeroOneNormFilter,
-                        ZeroOneNormFilterParams, ZScoreNormFilter,
-                        ZScoreNormFilterParams)
-from .invertibility import (PlaybackTransformTapeFilter,
-                            PlaybackTransformTapeFilterParams)
-from .modification import (AddImageFilter, AddImageFilterParams,
-                           MergeSegmentationFilter,
-                           MergeSegmentationFilterParams,
-                           RemoveImageByAnnotatorFilter,
-                           RemoveImageByAnnotatorFilterParams,
-                           RemoveImageByModalityFilter,
-                           RemoveImageByModalityFilterParams,
-                           RemoveImageByOrganFilter,
-                           RemoveImageByOrganFilterParams)
-from .orientation import (OrientationFilter, OrientationFilterParams,
-                          SpatialOrientation, _Coord, _MajorTerms)
-from .postprocess import (AlphabeticOrganSortingFilter,
-                          AlphabeticOrganSortingFilterParams,
-                          SingleConnectedComponentFilter,
-                          SingleConnectedComponentFilterParams)
-from .registration import (InterSubjectRegistrationFilter,
-                           InterSubjectRegistrationFilterParams,
-                           IntraSubjectRegistrationFilter,
-                           IntraSubjectRegistrationFilterParams,
-                           RegistrationType)
-from .resampling import ResampleFilter, ResampleFilterParams
+from .base import (Filter, FilterParams, FilterPipeline, LoopEntryFilter,
+                   LoopEntryFilterParams)
+from .inference import (IndexingStrategy, InferenceFilter,
+                        InferenceFilterParams, PatchIndexingStrategy,
+                        SliceIndexingStrategy)
+from .intensity import (ClipIntensityFilter, ClipIntensityFilterParams,
+                        GaussianFilter, GaussianFilterParams, IntensityFilter,
+                        IntensityFilterParams, IntensityLoopFilter,
+                        IntensityLoopFilterParams, LaplacianFilter,
+                        LaplacianFilterParams, MedianFilter,
+                        MedianFilterParams, RescaleIntensityFilter,
+                        RescaleIntensityFilterParams, ZeroOneNormFilter,
+                        ZeroOneNormFilterParams, ZScoreNormFilter,
+                        ZScoreNormFilterParams)
+from .invertibility import (PlaybackTransformTapeFilter,
+                            PlaybackTransformTapeFilterParams)
+from .modification import (AddImageFilter, AddImageFilterParams,
+                           MergeSegmentationFilter,
+                           MergeSegmentationFilterParams,
+                           RemoveImageByAnnotatorFilter,
+                           RemoveImageByAnnotatorFilterParams,
+                           RemoveImageByModalityFilter,
+                           RemoveImageByModalityFilterParams,
+                           RemoveImageByOrganFilter,
+                           RemoveImageByOrganFilterParams)
+from .orientation import (OrientationFilter, OrientationFilterParams,
+                          SpatialOrientation, _Coord, _MajorTerms)
+from .postprocess import (AlphabeticOrganSortingFilter,
+                          AlphabeticOrganSortingFilterParams,
+                          SingleConnectedComponentFilter,
+                          SingleConnectedComponentFilterParams)
+from .registration import (InterSubjectRegistrationFilter,
+                           InterSubjectRegistrationFilterParams,
+                           IntraSubjectRegistrationFilter,
+                           IntraSubjectRegistrationFilterParams,
+                           RegistrationType)
+from .resampling import ResampleFilter, ResampleFilterParams
```

### Comparing `pyradise-0.2.2/pyradise/process/base.py` & `pyradise-0.2.3/pyradise/process/base.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,578 +1,578 @@
-import logging
-from abc import ABC, abstractmethod
-from copy import deepcopy
-from typing import Any, Callable, Dict, List, Optional, Tuple, Union
-
-import itk
-import numpy as np
-import SimpleITK as sitk
-
-from pyradise.data import (Image, ImageProperties, IntensityImage,
-                           SegmentationImage, Subject, TransformInfo)
-
-__all__ = ["FilterParams", "Filter", "LoopEntryFilterParams", "LoopEntryFilter", "FilterPipeline"]
-
-
-# pylint: disable=too-few-public-methods
-class FilterParams(ABC):
-    """An abstract filter parameter class which provides the parameters used for the configuration of a certain
-    filter. The derived subclasses can hold any set of parameters and is provided to the corresponding
-    :class:`~pyradise.process.base.Filter` via the :meth:`~pyradise.process.base.Filter.execute` method.
-    The :class:`~pyradise.process.base.FilterParams` subclasses may incorporate also methods to calculate
-    certain parameter values based on the given set of parameters.
-
-    The instances of :class:`~pyradise.process.base.FilterParams` subclasses are stored inside a
-    :class:`~pyradise.data.taping.TransformInfo` instance to keep track of the parameters used during the execution
-    of a certain :class:`~pyradise.process.base.Filter` such that invertibility can be guaranteed for
-    :class:`~pyradise.process.base.Filter` s feasible to be inverted. However, for the reason of reproducibility the
-    :class:`~pyradise.process.base.FilterParams` instances should be tracked always.
-
-    Example:
-
-        An example of a :class:`~pyradise.process.base.FilterParams` implementation for an intensity rescaling filter:
-
-        >>> from pyradise.process import FilterParams
-        >>>
-        >>>
-        >>> class ExampleRescaleFilterParams(FilterParams):
-        >>>
-        >>>     def __init__(self, min_out: float, max_out: float) -> None:
-        >>>         super().__init__()
-        >>>
-        >>>         # reverse the values if min_out > max_out
-        >>>         if min_out > max_out:
-        >>>             min_out, max_out = max_out, min_out
-        >>>
-        >>>         # the minimum and maximum output intensity values
-        >>>         self.min_out = min_out
-        >>>         self.max_out = max_out
-
-    """
-
-    @abstractmethod
-    def __init__(self) -> None:
-        pass
-
-
-class Filter(ABC):
-    """An abstract filter base class which is used to process a subject and its content. In PyRaDiSe a
-    :class:`~pyradise.process.base.Filter` is the main data processing object which is feasible to modify the structure
-    and content of a :class:`~pyradise.data.subject.Subject`, the content of the subject-associated
-    :class:`~pyradise.data.image.Image` and other subject-associated data. Thus, filters can be used for
-    pre-processing, DL-model inference, and post-processing.
-
-    The implemented filter design provides a standardized interface such that filters can be chained together in a
-    :class:`~pyradise.process.base.FilterPipeline` to form a processing pipeline. Furthermore, the extensible
-    implementation renders the tracking of content changes feasible for the purpose of reproducibility and
-    invertibility on invertible :class:`~pyradise.process.base.Filter`.
-
-    The :mod:`~pyradise.process` package provides a set of implemented :class:`~pyradise.process.base.Filter` s and
-    associated :class:`~pyradise.process.base.FilterParams`. However, the user may implement its own
-    :class:`~pyradise.process.base.Filter` s depending on the task specific needs. We recommend to share the
-    user-implemented :class:`~pyradise.process.base.Filter` s with the community via GitHub or by generating pull
-    requests to the `PyRaDiSe GitHub repository <https://github.com/ubern-mia/pyradise>`_. We thank all contributors
-    in advance for sharing their filter implementations!
-
-    In order to implement a new :class:`~pyradise.process.base.Filter` the following steps are required:
-
-    1. Always derive from the :class:`~pyradise.process.base.Filter` class.
-
-    2. Implement the :meth:`~pyradise.process.base.Filter.execute` method and possible subsequent methods
-       which are used to process the :class:`~pyradise.data.subject.Subject`.
-
-    3. Make sure that your implementation tracks the changes and assign it to the
-       :class:`~pyradise.data.taping.TransformTape` instance of the corresponding :class:`~pyradise.data.image.Image`
-       instance.
-
-    4. Implement the :meth:`~pyradise.process.base.Filter.execute_inverse` and
-       :meth:`~pyradise.process.base.Filter.is_invertible` methods if the filter is invertible. Please note that
-       the implementation can access all information which was previously recorded on the corresponding
-       :class:`~pyradise.data.taping.TransformTape` instance.
-
-    5. Test the new :class:`~pyradise.process.base.Filter` implementation and make sure that it works as expected.
-
-
-    Example:
-
-        Example implementation of an intensity rescaling filter:
-
-        >>> import SimpleITK as sitk
-        >>> import numpy as np
-        >>>
-        >>> from pyradise.process import Filter, FilterParams
-        >>> from pyradise.data import Subject, IntensityImage, TransformInfo
-        >>>
-        >>>
-        >>> class ExampleRescaleFilterParams(FilterParams):
-        >>>
-        >>>     def __init__(self, min_out: float, max_out: float) -> None:
-        >>>         super().__init__()
-        >>>
-        >>>         # reverse the values if min_out > max_out
-        >>>         if min_out > max_out:
-        >>>             min_out, max_out = max_out, min_out
-        >>>
-        >>>         # the minimum and maximum output intensity values
-        >>>         self.min_out = min_out
-        >>>         self.max_out = max_out
-        >>>
-        >>>
-        >>> class ExampleRescaleFilter(Filter):
-        >>>
-        >>>     @staticmethod
-        >>>     def is_invertible() -> bool:
-        >>>         # return True because the filter is invertible
-        >>>         return True
-        >>>
-        >>>     def execute(self,
-        >>>                 subject: Subject,
-        >>>                 params: ExampleRescaleFilterParams
-        >>>                 ) -> Subject:
-        >>>         # loop through the images
-        >>>         for image in subject.get_images():
-        >>>
-        >>>             # exclude segmentation images
-        >>>             if not isinstance(image, IntensityImage):
-        >>>                 continue
-        >>>
-        >>>             # retrieve the image data
-        >>>             original_image_sitk = image.get_image_data()
-        >>>
-        >>>             # rescale the intensity
-        >>>             new_image_sitk = sitk.RescaleIntensity(original_image_sitk,
-        >>>                                                    params.min_out,
-        >>>                                                    params.max_out)
-        >>>
-        >>>             # update the image data
-        >>>             image.set_image_data(new_image_sitk)
-        >>>
-        >>>             # track the necessary information
-        >>>             original_image_np = sitk.GetArrayFromImage(original_image_sitk)
-        >>>             self.tracking_data['min_'] = float(np.min(original_image_np))
-        >>>             self.tracking_data['max_'] = float(np.max(original_image_np))
-        >>>             self._register_tracked_data(image, original_image_sitk,
-        >>>                                         new_image_sitk, params)
-        >>>
-        >>>         return subject
-        >>>
-        >>>     def execute_inverse(self,
-        >>>                         subject: Subject,
-        >>>                         transform_info: TransformInfo,
-        >>>                         target_image: Optional[Union[SegmentationImage, IntensityImage]] = None
-        >>>                         ) -> Subject:
-        >>>         # loop through the images
-        >>>         for image in subject.get_images():
-        >>>
-        >>>             # exclude segmentation images
-        >>>             if not isinstance(image, IntensityImage):
-        >>>                 continue
-        >>>
-        >>>             # retrieve the tracked data
-        >>>             min_intensity = transform_info.get_data('min_')
-        >>>             max_intensity = transform_info.get_data('max_')
-        >>>
-        >>>             # undo the intensity rescaling
-        >>>             original_image_sitk = image.get_image_data()
-        >>>             new_image_sitk = sitk.RescaleIntensity(original_image_sitk,
-        >>>                                                    min_intensity,
-        >>>                                                    max_intensity)
-        >>>
-        >>>             # update the image data
-        >>>             image.set_image_data(new_image_sitk)
-        >>>
-        >>>             # there is no need to track information because
-        >>>             # the operation is inverted
-        >>>
-        >>>         return subject
-
-    Args:
-        warning_on_non_invertible (bool): If True, a warning is printed to the console if a filter is called to
-         execute the invertible process but is not invertible (default: False).
-
-    """
-
-    def __init__(self, warning_on_non_invertible: bool = False) -> None:
-        super().__init__()
-
-        self.warn_on_non_invertible = warning_on_non_invertible
-
-        self.verbose = False
-
-        # register here all filter arguments such that the filter can be reconstructed
-        self.filter_args: Dict[str, Any] = {}
-
-        # data to be tracked for the inverse transformation
-        self.tracking_data: Dict[str, Any] = {}
-
-    @staticmethod
-    @abstractmethod
-    def is_invertible() -> bool:
-        """Check if the filter is invertible.
-
-        Returns:
-            bool: True if the filter is invertible, otherwise False.
-        """
-        raise NotImplementedError()
-
-    def set_verbose(self, verbose: bool) -> None:
-        """Set the verbose state.
-
-        Args:
-            verbose (bool): If True, the filter outputs information to the console, otherwise not.
-
-        Returns:
-            None
-        """
-        self.verbose = verbose
-
-    def set_warning_on_non_invertible(self, warn: bool) -> None:
-        """Set the warning state.
-
-        Args:
-            warn (bool): If True, the filter outputs a warning if the filter is called and is not invertible,
-             otherwise not.
-
-        Returns:
-            None
-        """
-        self.warn_on_non_invertible = warn
-
-    def _register_tracked_data(
-        self,
-        image: Image,
-        pre_transform_image: Union[sitk.Image, itk.Image],
-        post_transform_image: Union[sitk.Image, itk.Image],
-        params: Optional[FilterParams],
-        transform: Optional[sitk.Transform] = None,
-    ) -> None:
-        """Create the :class:`~pyradise.data.taping.TransformInfo` instance which is used to store the information
-        about the performed transformation.
-
-        Args:
-            pre_transform_image (Union[sitk.Image, itk.Image]): The image before the transformation.
-            post_transform_image (Union[sitk.Image, itk.Image]): The image after the transformation.
-            params (Optional[FilterParams]): The filter parameters used for the transformation.
-            transform (Optional[sitk.Transform]): The transformation which was applied to the image (default: None).
-        """
-        filter_args_ = self.filter_args if self.filter_args is not None else {}
-        additional_data_ = self.tracking_data if self.tracking_data is not None else {}
-
-        pre_image_props = ImageProperties(pre_transform_image)
-        post_image_props = ImageProperties(post_transform_image)
-
-        transform_info = TransformInfo(
-            self.__class__.__name__,
-            params,
-            pre_image_props,
-            post_image_props,
-            deepcopy(filter_args_),
-            deepcopy(additional_data_),
-            deepcopy(transform),
-        )
-        image.add_transform_info(transform_info)
-
-        self.tracking_data.clear()
-
-    @abstractmethod
-    def execute(self, subject: Subject, params: Optional[FilterParams]) -> Subject:
-        """Execute the filter on the provided :class:`~pyradise.data.subject.Subject` instance.
-
-        Note:
-            For the ease of use, the filter provides a private :meth:`_create_transform_info` method which can be used
-            to create the :class:`~pyradise.data.taping.TransformInfo` instances.
-
-        Important:
-            The filter is responsible to record the transformations applied to each image such that the invertibility
-            is ensured. Even if the filter is not invertible, the transformations should be recorded such that the
-            order of filter applications can be reconstructed from the transform tapes of the images. In case the
-            filter is not invertible, the :meth:`~pyradise.process.base.Filter.is_invertible` must return ``False``.
-
-        Args:
-            subject (Subject): The subject to be processed.
-            params (Optional[FilterParams]): The filter parameters, if required.
-
-        Returns:
-            Subject: The processed subject.
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Execute the filter inversely if possible. Typically, this method gets a temporary subject which contains
-        a single image because the recording of the transformations is image dependent and inappropriate inverse
-        transformations would be applied to the other images. However, this method can also be applied to a whole
-        subject to apply the inverse transformations to all images. This approach provides a more flexible way to
-        handle invertibility of transformations.
-
-        Important:
-            If the filter is not invertible, the subject must be returned unchanged and the
-            :meth:`~pyradise.process.base.Filter.is_invertible` must return ``False``.
-
-        Args:
-            subject (Subject): The subject to be processed.
-            transform_info (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The processed subject.
-        """
-        raise NotImplementedError()
-
-
-class LoopEntryFilterParams(FilterParams):
-    """An abstract filter parameter class which provides in addition to :class:`~pyradise.process.base.FilterParams`
-    the ``loop_axis`` parameter which is used to specify the axis to loop over in the
-    :class:`~pyradise.process.base.LoopEntryFilter`.
-
-    Args:
-        loop_axis (Optional[int]): The axis along which the data transformation is performed. If ``None``, the
-         transformation is performed on the whole image at once. If a value is given, the transformation is performed
-         by looping over the corresponding image dimension.
-    """
-
-    def __init__(self, loop_axis: Optional[int]) -> None:
-        super().__init__()
-
-        if loop_axis is not None:
-            assert loop_axis >= 0, "The loop axis must be a non-negative integer."
-            assert loop_axis < 3, (
-                "The loop axis must be smaller than 3 because PyRaDiSe only supports 2D and " "3D images."
-            )
-
-        self.loop_axis: Optional[int] = loop_axis
-
-
-class LoopEntryFilter(Filter):
-    """An abstract filter base class which is feasible to process images slice-wise in a loop over a defined
-    ``loop_axis``. The ``loop_axis`` must be specified in the appropriate
-    :class:`~pyradise.process.base.FilterParams` instance and if it takes a value of ``None``, the filter is
-    executed on the whole image extent at once.
-
-    Reference:
-        The implementation of this class is inspired by an earlier version of the `pymia package
-        <https://pymia.readthedocs.io/en/latest>`_.
-    """
-
-    @staticmethod
-    @abstractmethod
-    def is_invertible() -> bool:
-        """Check if the filter is invertible.
-
-        Returns:
-            bool: True if the filter is invertible, otherwise False.
-        """
-        raise NotImplementedError()
-
-    @staticmethod
-    def loop_entries(
-        data: np.ndarray, params: Any, filter_fn: Callable[[np.ndarray, Any], np.ndarray], loop_axis: Optional[int]
-    ) -> np.ndarray:
-        """Apply the function :meth:`filter_fn` by looping over the image using the provided parameters
-        (i.e. ``params``).
-
-        Args:
-            data (np.ndarray): The data to be processed.
-            params (Any): The parameters for the filter function.
-            filter_fn (Callable[[np.ndarray, Any], np.ndarray]): The filter function.
-            loop_axis (Optional[int]): The axis to loop over. If ``None`` the whole image is taken, otherwise the
-             respective dimension.
-
-        Returns:
-            np.ndarray: The processed data.
-        """
-        if loop_axis is None:
-            new_data = filter_fn(data, params)
-
-        else:
-            new_data = np.zeros_like(data)
-
-            slicing: List[Union[slice, int]] = [slice(None) for _ in range(data.ndim)]
-            for i in range(data.shape[loop_axis]):
-                slicing[loop_axis] = i
-                new_data[tuple(slicing)] = filter_fn(data[tuple(slicing)], params)
-
-        return new_data
-
-    @abstractmethod
-    def execute(self, subject: Subject, params: Optional[LoopEntryFilterParams]) -> Subject:
-        """Execute the filter on the provided :class:`~pyradise.data.subject.Subject` instance.
-
-        Note:
-            For the ease of use, the filter provides a private :meth:`_create_transform_info` method which can be used
-            to create the :class:`~pyradise.data.taping.TransformInfo` instances.
-
-        Important:
-            The filter is responsible to record the transformations applied to each image such that the invertibility
-            is ensured. Even if the filter is not invertible, the transformations should be recorded such that the
-            order of filter applications can be reconstructed from the transform tapes of the images. In case the
-            filter is not invertible, the :meth:`~pyradise.process.base.Filter.is_invertible` must return ``False``.
-
-        Args:
-            subject (Subject): The subject to be processed.
-            params (Optional[LoopEntryFilterParams]): The filter parameters, if required.
-
-        Returns:
-            Subject: The processed subject.
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Execute the filter inversely if possible. Typically, this method gets a temporary subject which contains
-        a single image because the recording of the transformations is image dependent and inappropriate inverse
-        transformations would be applied to the other images. However, this method can also be applied to a whole
-        subject to apply the inverse transformations to all images. This approach provides a more flexible way to
-        handle invertibility of transformations.
-
-        Important:
-            If the filter is not invertible, the subject must be returned unchanged and the
-            :meth:`~pyradise.process.base.Filter.is_invertible` must return ``False``.
-
-        Args:
-            subject (Subject): The subject to be processed.
-            transform_info (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The processed subject.
-        """
-        raise NotImplementedError()
-
-
-class FilterPipeline:
-    """A filter pipeline class which can combine multiple :class:`~pyradise.process.base.Filter` instances into one
-    pipeline of sequential filter. This reduces the amount of boilerplate code for the user and provides a nice way to
-    chain multiple filters together.
-
-    Args:
-        filters (Optional[Tuple[Filter, ...]]): The filters of the pipeline (default: None).
-        params (Optional[Tuple[FilterParams, ...]]): The parameters for the filters in the pipeline.
-        warning_on_non_invertible (bool): If True, a warning is printed to the console if a filter is called to
-         execute the invertible process but is not invertible (default: False).
-    """
-
-    def __init__(
-        self,
-        filters: Optional[Tuple[Filter, ...]] = None,
-        params: Optional[Tuple[FilterParams, ...]] = None,
-        warning_on_non_invertible: bool = False,
-    ) -> None:
-        super().__init__()
-
-        self.filters: List[Filter, ...] = []
-        self.params: List[FilterParams, ...] = []
-        self.warn_on_non_invertible = warning_on_non_invertible
-
-        if filters:
-            if not params:
-                params = [None] * len(filters)
-
-            else:
-                assert len(params) == len(filters), (
-                    f"The number of filters ({len(filters)}) must be equal "
-                    f"to the number of filter parameters ({len(params)})!"
-                )
-
-            for filter_, param in zip(filters, params):
-                self.add_filter(filter_, param)
-
-        self.logger: Optional[logging.Logger] = None
-
-    def set_verbose_all(self, verbose: bool) -> None:
-        """Set the verbose state for all :class:`~pyradise.process.base.Filter` instances.
-
-        Args:
-            verbose (bool): If True the filters print information to the console, otherwise not.
-
-        Returns:
-            None
-        """
-        for filter_ in self.filters:
-            filter_.set_verbose(verbose)
-
-    def add_filter(self, filter_: Filter, params: Optional[FilterParams] = None) -> None:
-        """Add a :class:`~pyradise.process.base.Filter` instance and its corresponding
-        :class:`~pyradise.process.base.FilterParams` to the pipeline.
-
-        Args:
-            filter_ (Filter): The :class:`~pyradise.process.base.Filter` instance to add.
-            params (Optional[FilterParams]): The :class:`~pyradise.process.base.FilterParams` instance to add,
-             if necessary (default: None).
-
-        Returns:
-            None
-        """
-        self.filters.append(filter_)
-        self.params.append(params)
-
-    def set_param(self, params: FilterParams, filter_index: int) -> None:
-        """Set the :class:`~pyradise.process.base.FilterParams` for a specific
-        :class:`~pyradise.process.base.Filter` instance at index ``filter_index``.
-
-        Args:
-            params (FilterParams): The :class:`~pyradise.process.base.FilterParams` instance.
-            filter_index (int): The index of the :class:`~pyradise.process.base.Filter` to add the parameters to.
-
-        Returns:
-            None
-        """
-        if filter_index == -1:
-            filter_idx = len(self.filters) - 1
-        else:
-            filter_idx = filter_index
-
-        self.params[filter_idx] = params
-
-    def add_logger(self, logger: logging.Logger) -> None:
-        """Add a logger to the filter pipeline.
-
-        Args:
-            logger (logging.Logger): The logger to use with the pipeline.
-
-        Returns:
-            None
-        """
-        self.logger = logger
-
-    def execute(self, subject: Subject) -> Subject:
-        """Execute the filter pipeline on the provided :class:`~pyradise.data.subject.Subject` instance.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed by the pipeline.
-
-        Returns:
-            Subject: The processed subject.
-        """
-        assert len(self.filters) == len(self.params), (
-            f"The filter pipeline can not be executed due to unequal "
-            f"numbers of filters ({len(self.filters)}) and "
-            f"parameters ({len(self.params)})!"
-        )
-
-        for filter_, param in zip(self.filters, self.params):
-            if self.logger:
-                self.logger.info(f"{subject.get_name()}: Pipeline executing {filter_.__class__.__name__}...")
-
-            # set the warning on and off
-            if self.warn_on_non_invertible:
-                filter_.set_warning_on_non_invertible(True)
-            else:
-                filter_.set_warning_on_non_invertible(False)
-
-            subject = filter_.execute(subject, param)
-
-        return subject
+import logging
+from abc import ABC, abstractmethod
+from copy import deepcopy
+from typing import Any, Callable, Dict, List, Optional, Tuple, Union
+
+import itk
+import numpy as np
+import SimpleITK as sitk
+
+from pyradise.data import (Image, ImageProperties, IntensityImage,
+                           SegmentationImage, Subject, TransformInfo)
+
+__all__ = ["FilterParams", "Filter", "LoopEntryFilterParams", "LoopEntryFilter", "FilterPipeline"]
+
+
+# pylint: disable=too-few-public-methods
+class FilterParams(ABC):
+    """An abstract filter parameter class which provides the parameters used for the configuration of a certain
+    filter. The derived subclasses can hold any set of parameters and is provided to the corresponding
+    :class:`~pyradise.process.base.Filter` via the :meth:`~pyradise.process.base.Filter.execute` method.
+    The :class:`~pyradise.process.base.FilterParams` subclasses may incorporate also methods to calculate
+    certain parameter values based on the given set of parameters.
+
+    The instances of :class:`~pyradise.process.base.FilterParams` subclasses are stored inside a
+    :class:`~pyradise.data.taping.TransformInfo` instance to keep track of the parameters used during the execution
+    of a certain :class:`~pyradise.process.base.Filter` such that invertibility can be guaranteed for
+    :class:`~pyradise.process.base.Filter` s feasible to be inverted. However, for the reason of reproducibility the
+    :class:`~pyradise.process.base.FilterParams` instances should be tracked always.
+
+    Example:
+
+        An example of a :class:`~pyradise.process.base.FilterParams` implementation for an intensity rescaling filter:
+
+        >>> from pyradise.process import FilterParams
+        >>>
+        >>>
+        >>> class ExampleRescaleFilterParams(FilterParams):
+        >>>
+        >>>     def __init__(self, min_out: float, max_out: float) -> None:
+        >>>         super().__init__()
+        >>>
+        >>>         # reverse the values if min_out > max_out
+        >>>         if min_out > max_out:
+        >>>             min_out, max_out = max_out, min_out
+        >>>
+        >>>         # the minimum and maximum output intensity values
+        >>>         self.min_out = min_out
+        >>>         self.max_out = max_out
+
+    """
+
+    @abstractmethod
+    def __init__(self) -> None:
+        pass
+
+
+class Filter(ABC):
+    """An abstract filter base class which is used to process a subject and its content. In PyRaDiSe a
+    :class:`~pyradise.process.base.Filter` is the main data processing object which is feasible to modify the structure
+    and content of a :class:`~pyradise.data.subject.Subject`, the content of the subject-associated
+    :class:`~pyradise.data.image.Image` and other subject-associated data. Thus, filters can be used for
+    pre-processing, DL-model inference, and post-processing.
+
+    The implemented filter design provides a standardized interface such that filters can be chained together in a
+    :class:`~pyradise.process.base.FilterPipeline` to form a processing pipeline. Furthermore, the extensible
+    implementation renders the tracking of content changes feasible for the purpose of reproducibility and
+    invertibility on invertible :class:`~pyradise.process.base.Filter`.
+
+    The :mod:`~pyradise.process` package provides a set of implemented :class:`~pyradise.process.base.Filter` s and
+    associated :class:`~pyradise.process.base.FilterParams`. However, the user may implement its own
+    :class:`~pyradise.process.base.Filter` s depending on the task specific needs. We recommend to share the
+    user-implemented :class:`~pyradise.process.base.Filter` s with the community via GitHub or by generating pull
+    requests to the `PyRaDiSe GitHub repository <https://github.com/ubern-mia/pyradise>`_. We thank all contributors
+    in advance for sharing their filter implementations!
+
+    In order to implement a new :class:`~pyradise.process.base.Filter` the following steps are required:
+
+    1. Always derive from the :class:`~pyradise.process.base.Filter` class.
+
+    2. Implement the :meth:`~pyradise.process.base.Filter.execute` method and possible subsequent methods
+       which are used to process the :class:`~pyradise.data.subject.Subject`.
+
+    3. Make sure that your implementation tracks the changes and assign it to the
+       :class:`~pyradise.data.taping.TransformTape` instance of the corresponding :class:`~pyradise.data.image.Image`
+       instance.
+
+    4. Implement the :meth:`~pyradise.process.base.Filter.execute_inverse` and
+       :meth:`~pyradise.process.base.Filter.is_invertible` methods if the filter is invertible. Please note that
+       the implementation can access all information which was previously recorded on the corresponding
+       :class:`~pyradise.data.taping.TransformTape` instance.
+
+    5. Test the new :class:`~pyradise.process.base.Filter` implementation and make sure that it works as expected.
+
+
+    Example:
+
+        Example implementation of an intensity rescaling filter:
+
+        >>> import SimpleITK as sitk
+        >>> import numpy as np
+        >>>
+        >>> from pyradise.process import Filter, FilterParams
+        >>> from pyradise.data import Subject, IntensityImage, TransformInfo
+        >>>
+        >>>
+        >>> class ExampleRescaleFilterParams(FilterParams):
+        >>>
+        >>>     def __init__(self, min_out: float, max_out: float) -> None:
+        >>>         super().__init__()
+        >>>
+        >>>         # reverse the values if min_out > max_out
+        >>>         if min_out > max_out:
+        >>>             min_out, max_out = max_out, min_out
+        >>>
+        >>>         # the minimum and maximum output intensity values
+        >>>         self.min_out = min_out
+        >>>         self.max_out = max_out
+        >>>
+        >>>
+        >>> class ExampleRescaleFilter(Filter):
+        >>>
+        >>>     @staticmethod
+        >>>     def is_invertible() -> bool:
+        >>>         # return True because the filter is invertible
+        >>>         return True
+        >>>
+        >>>     def execute(self,
+        >>>                 subject: Subject,
+        >>>                 params: ExampleRescaleFilterParams
+        >>>                 ) -> Subject:
+        >>>         # loop through the images
+        >>>         for image in subject.get_images():
+        >>>
+        >>>             # exclude segmentation images
+        >>>             if not isinstance(image, IntensityImage):
+        >>>                 continue
+        >>>
+        >>>             # retrieve the image data
+        >>>             original_image_sitk = image.get_image_data()
+        >>>
+        >>>             # rescale the intensity
+        >>>             new_image_sitk = sitk.RescaleIntensity(original_image_sitk,
+        >>>                                                    params.min_out,
+        >>>                                                    params.max_out)
+        >>>
+        >>>             # update the image data
+        >>>             image.set_image_data(new_image_sitk)
+        >>>
+        >>>             # track the necessary information
+        >>>             original_image_np = sitk.GetArrayFromImage(original_image_sitk)
+        >>>             self.tracking_data['min_'] = float(np.min(original_image_np))
+        >>>             self.tracking_data['max_'] = float(np.max(original_image_np))
+        >>>             self._register_tracked_data(image, original_image_sitk,
+        >>>                                         new_image_sitk, params)
+        >>>
+        >>>         return subject
+        >>>
+        >>>     def execute_inverse(self,
+        >>>                         subject: Subject,
+        >>>                         transform_info: TransformInfo,
+        >>>                         target_image: Optional[Union[SegmentationImage, IntensityImage]] = None
+        >>>                         ) -> Subject:
+        >>>         # loop through the images
+        >>>         for image in subject.get_images():
+        >>>
+        >>>             # exclude segmentation images
+        >>>             if not isinstance(image, IntensityImage):
+        >>>                 continue
+        >>>
+        >>>             # retrieve the tracked data
+        >>>             min_intensity = transform_info.get_data('min_')
+        >>>             max_intensity = transform_info.get_data('max_')
+        >>>
+        >>>             # undo the intensity rescaling
+        >>>             original_image_sitk = image.get_image_data()
+        >>>             new_image_sitk = sitk.RescaleIntensity(original_image_sitk,
+        >>>                                                    min_intensity,
+        >>>                                                    max_intensity)
+        >>>
+        >>>             # update the image data
+        >>>             image.set_image_data(new_image_sitk)
+        >>>
+        >>>             # there is no need to track information because
+        >>>             # the operation is inverted
+        >>>
+        >>>         return subject
+
+    Args:
+        warning_on_non_invertible (bool): If True, a warning is printed to the console if a filter is called to
+         execute the invertible process but is not invertible (default: False).
+
+    """
+
+    def __init__(self, warning_on_non_invertible: bool = False) -> None:
+        super().__init__()
+
+        self.warn_on_non_invertible = warning_on_non_invertible
+
+        self.verbose = False
+
+        # register here all filter arguments such that the filter can be reconstructed
+        self.filter_args: Dict[str, Any] = {}
+
+        # data to be tracked for the inverse transformation
+        self.tracking_data: Dict[str, Any] = {}
+
+    @staticmethod
+    @abstractmethod
+    def is_invertible() -> bool:
+        """Check if the filter is invertible.
+
+        Returns:
+            bool: True if the filter is invertible, otherwise False.
+        """
+        raise NotImplementedError()
+
+    def set_verbose(self, verbose: bool) -> None:
+        """Set the verbose state.
+
+        Args:
+            verbose (bool): If True, the filter outputs information to the console, otherwise not.
+
+        Returns:
+            None
+        """
+        self.verbose = verbose
+
+    def set_warning_on_non_invertible(self, warn: bool) -> None:
+        """Set the warning state.
+
+        Args:
+            warn (bool): If True, the filter outputs a warning if the filter is called and is not invertible,
+             otherwise not.
+
+        Returns:
+            None
+        """
+        self.warn_on_non_invertible = warn
+
+    def _register_tracked_data(
+        self,
+        image: Image,
+        pre_transform_image: Union[sitk.Image, itk.Image],
+        post_transform_image: Union[sitk.Image, itk.Image],
+        params: Optional[FilterParams],
+        transform: Optional[sitk.Transform] = None,
+    ) -> None:
+        """Create the :class:`~pyradise.data.taping.TransformInfo` instance which is used to store the information
+        about the performed transformation.
+
+        Args:
+            pre_transform_image (Union[sitk.Image, itk.Image]): The image before the transformation.
+            post_transform_image (Union[sitk.Image, itk.Image]): The image after the transformation.
+            params (Optional[FilterParams]): The filter parameters used for the transformation.
+            transform (Optional[sitk.Transform]): The transformation which was applied to the image (default: None).
+        """
+        filter_args_ = self.filter_args if self.filter_args is not None else {}
+        additional_data_ = self.tracking_data if self.tracking_data is not None else {}
+
+        pre_image_props = ImageProperties(pre_transform_image)
+        post_image_props = ImageProperties(post_transform_image)
+
+        transform_info = TransformInfo(
+            self.__class__.__name__,
+            params,
+            pre_image_props,
+            post_image_props,
+            deepcopy(filter_args_),
+            deepcopy(additional_data_),
+            deepcopy(transform),
+        )
+        image.add_transform_info(transform_info)
+
+        self.tracking_data.clear()
+
+    @abstractmethod
+    def execute(self, subject: Subject, params: Optional[FilterParams]) -> Subject:
+        """Execute the filter on the provided :class:`~pyradise.data.subject.Subject` instance.
+
+        Note:
+            For the ease of use, the filter provides a private :meth:`_create_transform_info` method which can be used
+            to create the :class:`~pyradise.data.taping.TransformInfo` instances.
+
+        Important:
+            The filter is responsible to record the transformations applied to each image such that the invertibility
+            is ensured. Even if the filter is not invertible, the transformations should be recorded such that the
+            order of filter applications can be reconstructed from the transform tapes of the images. In case the
+            filter is not invertible, the :meth:`~pyradise.process.base.Filter.is_invertible` must return ``False``.
+
+        Args:
+            subject (Subject): The subject to be processed.
+            params (Optional[FilterParams]): The filter parameters, if required.
+
+        Returns:
+            Subject: The processed subject.
+        """
+        raise NotImplementedError()
+
+    @abstractmethod
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Execute the filter inversely if possible. Typically, this method gets a temporary subject which contains
+        a single image because the recording of the transformations is image dependent and inappropriate inverse
+        transformations would be applied to the other images. However, this method can also be applied to a whole
+        subject to apply the inverse transformations to all images. This approach provides a more flexible way to
+        handle invertibility of transformations.
+
+        Important:
+            If the filter is not invertible, the subject must be returned unchanged and the
+            :meth:`~pyradise.process.base.Filter.is_invertible` must return ``False``.
+
+        Args:
+            subject (Subject): The subject to be processed.
+            transform_info (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The processed subject.
+        """
+        raise NotImplementedError()
+
+
+class LoopEntryFilterParams(FilterParams):
+    """An abstract filter parameter class which provides in addition to :class:`~pyradise.process.base.FilterParams`
+    the ``loop_axis`` parameter which is used to specify the axis to loop over in the
+    :class:`~pyradise.process.base.LoopEntryFilter`.
+
+    Args:
+        loop_axis (Optional[int]): The axis along which the data transformation is performed. If ``None``, the
+         transformation is performed on the whole image at once. If a value is given, the transformation is performed
+         by looping over the corresponding image dimension.
+    """
+
+    def __init__(self, loop_axis: Optional[int]) -> None:
+        super().__init__()
+
+        if loop_axis is not None:
+            assert loop_axis >= 0, "The loop axis must be a non-negative integer."
+            assert loop_axis < 3, (
+                "The loop axis must be smaller than 3 because PyRaDiSe only supports 2D and " "3D images."
+            )
+
+        self.loop_axis: Optional[int] = loop_axis
+
+
+class LoopEntryFilter(Filter):
+    """An abstract filter base class which is feasible to process images slice-wise in a loop over a defined
+    ``loop_axis``. The ``loop_axis`` must be specified in the appropriate
+    :class:`~pyradise.process.base.FilterParams` instance and if it takes a value of ``None``, the filter is
+    executed on the whole image extent at once.
+
+    Reference:
+        The implementation of this class is inspired by an earlier version of the `pymia package
+        <https://pymia.readthedocs.io/en/latest>`_.
+    """
+
+    @staticmethod
+    @abstractmethod
+    def is_invertible() -> bool:
+        """Check if the filter is invertible.
+
+        Returns:
+            bool: True if the filter is invertible, otherwise False.
+        """
+        raise NotImplementedError()
+
+    @staticmethod
+    def loop_entries(
+        data: np.ndarray, params: Any, filter_fn: Callable[[np.ndarray, Any], np.ndarray], loop_axis: Optional[int]
+    ) -> np.ndarray:
+        """Apply the function :meth:`filter_fn` by looping over the image using the provided parameters
+        (i.e. ``params``).
+
+        Args:
+            data (np.ndarray): The data to be processed.
+            params (Any): The parameters for the filter function.
+            filter_fn (Callable[[np.ndarray, Any], np.ndarray]): The filter function.
+            loop_axis (Optional[int]): The axis to loop over. If ``None`` the whole image is taken, otherwise the
+             respective dimension.
+
+        Returns:
+            np.ndarray: The processed data.
+        """
+        if loop_axis is None:
+            new_data = filter_fn(data, params)
+
+        else:
+            new_data = np.zeros_like(data)
+
+            slicing: List[Union[slice, int]] = [slice(None) for _ in range(data.ndim)]
+            for i in range(data.shape[loop_axis]):
+                slicing[loop_axis] = i
+                new_data[tuple(slicing)] = filter_fn(data[tuple(slicing)], params)
+
+        return new_data
+
+    @abstractmethod
+    def execute(self, subject: Subject, params: Optional[LoopEntryFilterParams]) -> Subject:
+        """Execute the filter on the provided :class:`~pyradise.data.subject.Subject` instance.
+
+        Note:
+            For the ease of use, the filter provides a private :meth:`_create_transform_info` method which can be used
+            to create the :class:`~pyradise.data.taping.TransformInfo` instances.
+
+        Important:
+            The filter is responsible to record the transformations applied to each image such that the invertibility
+            is ensured. Even if the filter is not invertible, the transformations should be recorded such that the
+            order of filter applications can be reconstructed from the transform tapes of the images. In case the
+            filter is not invertible, the :meth:`~pyradise.process.base.Filter.is_invertible` must return ``False``.
+
+        Args:
+            subject (Subject): The subject to be processed.
+            params (Optional[LoopEntryFilterParams]): The filter parameters, if required.
+
+        Returns:
+            Subject: The processed subject.
+        """
+        raise NotImplementedError()
+
+    @abstractmethod
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Execute the filter inversely if possible. Typically, this method gets a temporary subject which contains
+        a single image because the recording of the transformations is image dependent and inappropriate inverse
+        transformations would be applied to the other images. However, this method can also be applied to a whole
+        subject to apply the inverse transformations to all images. This approach provides a more flexible way to
+        handle invertibility of transformations.
+
+        Important:
+            If the filter is not invertible, the subject must be returned unchanged and the
+            :meth:`~pyradise.process.base.Filter.is_invertible` must return ``False``.
+
+        Args:
+            subject (Subject): The subject to be processed.
+            transform_info (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The processed subject.
+        """
+        raise NotImplementedError()
+
+
+class FilterPipeline:
+    """A filter pipeline class which can combine multiple :class:`~pyradise.process.base.Filter` instances into one
+    pipeline of sequential filter. This reduces the amount of boilerplate code for the user and provides a nice way to
+    chain multiple filters together.
+
+    Args:
+        filters (Optional[Tuple[Filter, ...]]): The filters of the pipeline (default: None).
+        params (Optional[Tuple[FilterParams, ...]]): The parameters for the filters in the pipeline.
+        warning_on_non_invertible (bool): If True, a warning is printed to the console if a filter is called to
+         execute the invertible process but is not invertible (default: False).
+    """
+
+    def __init__(
+        self,
+        filters: Optional[Tuple[Filter, ...]] = None,
+        params: Optional[Tuple[FilterParams, ...]] = None,
+        warning_on_non_invertible: bool = False,
+    ) -> None:
+        super().__init__()
+
+        self.filters: List[Filter, ...] = []
+        self.params: List[FilterParams, ...] = []
+        self.warn_on_non_invertible = warning_on_non_invertible
+
+        if filters:
+            if not params:
+                params = [None] * len(filters)
+
+            else:
+                assert len(params) == len(filters), (
+                    f"The number of filters ({len(filters)}) must be equal "
+                    f"to the number of filter parameters ({len(params)})!"
+                )
+
+            for filter_, param in zip(filters, params):
+                self.add_filter(filter_, param)
+
+        self.logger: Optional[logging.Logger] = None
+
+    def set_verbose_all(self, verbose: bool) -> None:
+        """Set the verbose state for all :class:`~pyradise.process.base.Filter` instances.
+
+        Args:
+            verbose (bool): If True the filters print information to the console, otherwise not.
+
+        Returns:
+            None
+        """
+        for filter_ in self.filters:
+            filter_.set_verbose(verbose)
+
+    def add_filter(self, filter_: Filter, params: Optional[FilterParams] = None) -> None:
+        """Add a :class:`~pyradise.process.base.Filter` instance and its corresponding
+        :class:`~pyradise.process.base.FilterParams` to the pipeline.
+
+        Args:
+            filter_ (Filter): The :class:`~pyradise.process.base.Filter` instance to add.
+            params (Optional[FilterParams]): The :class:`~pyradise.process.base.FilterParams` instance to add,
+             if necessary (default: None).
+
+        Returns:
+            None
+        """
+        self.filters.append(filter_)
+        self.params.append(params)
+
+    def set_param(self, params: FilterParams, filter_index: int) -> None:
+        """Set the :class:`~pyradise.process.base.FilterParams` for a specific
+        :class:`~pyradise.process.base.Filter` instance at index ``filter_index``.
+
+        Args:
+            params (FilterParams): The :class:`~pyradise.process.base.FilterParams` instance.
+            filter_index (int): The index of the :class:`~pyradise.process.base.Filter` to add the parameters to.
+
+        Returns:
+            None
+        """
+        if filter_index == -1:
+            filter_idx = len(self.filters) - 1
+        else:
+            filter_idx = filter_index
+
+        self.params[filter_idx] = params
+
+    def add_logger(self, logger: logging.Logger) -> None:
+        """Add a logger to the filter pipeline.
+
+        Args:
+            logger (logging.Logger): The logger to use with the pipeline.
+
+        Returns:
+            None
+        """
+        self.logger = logger
+
+    def execute(self, subject: Subject) -> Subject:
+        """Execute the filter pipeline on the provided :class:`~pyradise.data.subject.Subject` instance.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed by the pipeline.
+
+        Returns:
+            Subject: The processed subject.
+        """
+        assert len(self.filters) == len(self.params), (
+            f"The filter pipeline can not be executed due to unequal "
+            f"numbers of filters ({len(self.filters)}) and "
+            f"parameters ({len(self.params)})!"
+        )
+
+        for filter_, param in zip(self.filters, self.params):
+            if self.logger:
+                self.logger.info(f"{subject.get_name()}: Pipeline executing {filter_.__class__.__name__}...")
+
+            # set the warning on and off
+            if self.warn_on_non_invertible:
+                filter_.set_warning_on_non_invertible(True)
+            else:
+                filter_.set_warning_on_non_invertible(False)
+
+            subject = filter_.execute(subject, param)
+
+        return subject
```

### Comparing `pyradise-0.2.2/pyradise/process/inference.py` & `pyradise-0.2.3/pyradise/process/inference.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,595 +1,595 @@
-import os.path
-import warnings
-from abc import ABC, abstractmethod
-from copy import deepcopy
-from itertools import product
-from math import ceil
-from typing import Any, Dict, Optional, Tuple, Union
-
-import numpy as np
-import SimpleITK as sitk
-
-from pyradise.data import (Annotator, IntensityImage, Modality, Organ,
-                           SegmentationImage, Subject, TransformInfo,
-                           seq_to_modalities, seq_to_organs, str_to_annotator,
-                           str_to_modality)
-
-from .base import Filter, FilterParams
-
-__all__ = [
-    "InferenceFilterParams",
-    "InferenceFilter",
-    "IndexingStrategy",
-    "SliceIndexingStrategy",
-    "PatchIndexingStrategy",
-]
-
-
-class IndexingStrategy(ABC):
-    """An abstract class that defines the strategy for indexing / looping over the image data content during model
-    inference with an :class:`~pyradise.process.inference.InferenceFilter`. The :class:`IndexingStrategy` is typically
-    assigned to the :attr:`~pyradise.process.inference.InferenceFilterParams` for getting used by the
-    :class:`~pyradise.process.inference.InferenceFilter`.
-
-    Args:
-        loop_axis (Optional[int]): The axis along which the image data should be processed. If None, the image data
-         will be processed as a whole.
-
-    .. automethod:: __call__
-    """
-
-    def __init__(self, loop_axis: Optional[int]) -> None:
-        self.loop_axis: Optional[int] = loop_axis
-
-    @abstractmethod
-    def __call__(self, shape: Tuple[int, ...]) -> Tuple[Tuple[slice, ...], ...]:
-        """Compute the indexing expressions based on the given shape of the image data and the ``loop_axis`` attribute.
-
-        Args:
-            shape (Tuple[int, ...]): The shape of the image data for which the indexing expressions should be computed.
-
-        Returns:
-            Tuple[Tuple[slice, ...], ...]: The indexing expressions.
-        """
-        raise NotImplementedError()
-
-
-class SliceIndexingStrategy(IndexingStrategy):
-    """An indexing strategy class that computes the indexing expressions for slice-wise looping over the image data
-    content.
-
-    Args:
-        slice_axis (int): The axis along which the image data should be sliced.
-
-    .. automethod:: __call__
-    """
-
-    def __init__(self, slice_axis: int) -> None:
-        super().__init__(slice_axis)
-
-    def __call__(self, shape: Tuple[int, ...]) -> Tuple[Tuple[slice, ...], ...]:
-        """Compute the indexing expressions for each slice based on the given shape of the image data and the
-        ``loop_axis`` attribute.
-
-        Args:
-            shape (Tuple[int, ...]): The shape of the image data for which the indexing expressions should be computed.
-
-        Returns:
-            Tuple[Tuple[slice, ...], ...]: The indexing expressions.
-        """
-        # get the number of slices
-        num_slices = shape[self.loop_axis]
-
-        # create the indexing expressions
-        index_expressions = []
-        for i in range(num_slices):
-            # loop through the axis to build the indexing expression of a single slice
-            index_expression = []
-            for axis_idx in range(len(shape)):
-                # for the slice axis, we want to have just the current slice
-                if axis_idx == self.loop_axis:
-                    index_expression.append(slice(i, i + 1))
-
-                # for all other axes, we want to have the full image extent
-                else:
-                    index_expression.append(slice(None))
-
-            index_expressions.append(tuple(index_expression))
-
-        return tuple(index_expressions)
-
-
-class PatchIndexingStrategy(IndexingStrategy):
-    """An indexing strategy class that computes the indexing expressions for patch-wise looping over the image data
-    content.
-
-    Args:
-        patch_shape (Tuple[int, ...]): The shape of the patches.
-        stride (Optional[Tuple[int, ...]]): The stride of the patches. If None, the patches will be extracted with the
-         same stride as the patch shape.
-
-    .. automethod:: __call__
-    """
-
-    def __init__(self, patch_shape: Tuple[int, ...], stride: Optional[Tuple[int, ...]] = None) -> None:
-        super().__init__(None)
-
-        if stride is None:
-            stride_ = patch_shape
-        else:
-            stride_ = stride
-
-        if len(patch_shape) != len(stride_):
-            raise ValueError(
-                f"Invalid patch shape {patch_shape} and stride {stride_}. "
-                "Patch shape and stride must have the same length."
-            )
-
-        if any([patch_size <= 0 for patch_size in patch_shape]):
-            raise ValueError(f"Invalid patch shape {patch_shape}. Patch shape must be positive.")
-        self.patch_shape = patch_shape
-
-        if any([stride_size <= 0 for stride_size in stride_]):
-            raise ValueError(f"Invalid stride {stride_}. Stride must be positive.")
-        self.stride = stride_
-
-    def __call__(self, shape: Tuple[int, ...]) -> Tuple[Tuple[slice, ...], ...]:
-        """Compute the indexing expressions for each patch based on the given shape of the image data and the
-        ``patch_shape`` and ``stride`` attributes.
-
-        Args:
-            shape (Tuple[int, ...]): The shape of the image data for which the indexing expressions should be computed.
-
-        Returns:
-            Tuple[Tuple[slice, ...], ...]: The indexing expressions.
-        """
-        # get the number of patches in each dimension
-        num_patches = tuple(
-            range(ceil((shape[i] - self.patch_shape[i]) / self.stride[i]) + 1) for i in range(len(self.patch_shape))
-        )
-
-        # get the combinations of patch indices
-        patch_indexes = tuple(product(*num_patches))
-
-        # create the indexing expressions
-        index_expressions = []
-        for patch_index in patch_indexes:
-            index_expression = []
-
-            for axis_idx in range(len(self.patch_shape)):
-                patch_start = patch_index[axis_idx] * self.stride[axis_idx]
-                patch_end = min(patch_start + self.patch_shape[axis_idx], shape[axis_idx])
-
-                # correct the patch start such that each patch is of equal size
-                if patch_end - patch_start < self.patch_shape[axis_idx]:
-                    patch_start = patch_end - self.patch_shape[axis_idx]
-
-                index_expression.append(slice(patch_start, patch_end))
-
-            index_expressions.append(tuple(index_expression))
-
-        return tuple(index_expressions)
-
-
-class InferenceFilterParams(FilterParams):
-    """A filter parameter class for the prototype :class:`~pyradise.process.inference.InferenceFilter` class.
-
-    Args:
-        model (Any): The model to apply.
-        model_path (Optional[str]): The path to the model parameters.
-        modalities (Tuple[Union[str, Modality], ...]): The :class:`~pyradise.data.modality.Modality` s of the
-         :class:`~pyradise.data.image.IntensityImage` instances to use for inference.
-        reference_modality (Union[str, Modality]): The :class:`~pyradise.data.modality.Modality` that is used as the
-         reference to define the output properties of the created :class:`~pyradise.data.image.SegmentationImage`
-         instances.
-        output_organs (Tuple[Union[str, Organ], ...]): The organs that get assigned to the created
-         :class:`~pyradise.data.image.SegmentationImage` instances.
-        output_annotator (Union[str, Annotator]): The annotator that get assigned to the created
-         :class:`~pyradise.data.image.SegmentationImage` instances.
-        organ_indices (Tuple[int, ...]): The indices of the organs on the output mask of the `model`
-         (must match `output_organs` and `output_annotators`).
-        batch_size (int): The batch size to use for inference.
-        indexing_strategy (IndexingStrategy): The :class:`~pyradise.process.inference.IndexingStrategy` defining how
-         the data is fed to the `model`.
-    """
-
-    def __init__(
-        self,
-        model: Any,
-        model_path: Optional[str],
-        modalities: Tuple[Union[str, Modality], ...],
-        reference_modality: Union[str, Modality],
-        output_organs: Tuple[Union[str, Organ], ...],
-        output_annotator: Union[str, Annotator],
-        organ_indices: Tuple[int, ...],
-        batch_size: int,
-        indexing_strategy: IndexingStrategy,
-    ) -> None:
-        # adjust the loop_axis because the first axis will be the channel axis
-        super().__init__()
-
-        # the model to apply
-        self.model = model
-
-        # the path to the model parameters
-        if model_path is not None:
-            if not os.path.exists(model_path):
-                raise FileNotFoundError(f"Model path '{model_path}' is invalid.")
-            self.model_path: Optional[str] = model_path
-        else:
-            self.model_path: Optional[str] = None
-
-        # the modalities to use for inference
-        # -> the modalities must be in the correct order to construct the model input
-        self.modalities = seq_to_modalities(modalities)
-
-        # the modality that is used as the reference to define the output properties of the created
-        # segmentation images
-        self.reference_modality: Modality = str_to_modality(reference_modality)
-
-        # the organs that get assigned to the created segmentation images
-        self.output_organs: Tuple[Organ, ...] = seq_to_organs(output_organs)
-
-        # the annotator that get assigned to the created segmentation images
-        self.output_annotator: Annotator = str_to_annotator(output_annotator)
-
-        # the indexes of the organs on the output mask of the model (must match output_organs)
-        if len(output_organs) != len(organ_indices):
-            raise ValueError("Invalid number of organ indices. Must match the number of output_organs.")
-        self.organ_indices = organ_indices
-
-        # the batch size
-        self.batch_size = batch_size
-
-        # the indexing strategy
-        self.indexing_strategy = indexing_strategy
-
-
-class InferenceFilter(Filter):
-    """A prototype filter class for applying a DL-model to a :class:`~pyradise.data.subject.Subject` instance.
-
-    This class is a prototype for applying a DL-model to a :class:`~pyradise.data.subject.Subject` instance. PyRaDiSe
-    provides just a prototype for this filter such that it stays DL framework-agnostic. Therefore, the actual
-    implementation of the DL-framework specific methods must be implemented in a subclass.
-
-    For implementing a DL-framework specific :class:`InferenceFilter`, the following methods must be implemented:
-
-    * :meth:`~pyradise.process.inference.InferenceFilter._prepare_model`: Prepare the model for inference (e.g. load
-      the parameters from a model file).
-
-    * :meth:`~pyradise.process.inference.InferenceFilter._infer_on_batch`: Apply the model to a batch of data such
-      that the output shape can be inserted into the new image via the indexing expressions provided by the
-      chosen :class:`~pyradise.process.inference.IndexingStrategy`.
-
-
-    Example:
-
-           Implementation example of a PyTorch-based :class:`InferenceFilter` subclass:
-
-           >>> import torch
-           >>> import torch.nn as nn
-           >>>
-           >>> class ExampleInferenceFilter(InferenceFilter):
-           >>>
-           >>>  def __init__(self):
-           >>>      super().__init__()
-           >>>
-           >>>      # Define the device on which the model should be run
-           >>>      self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
-           >>>
-           >>>      # Define a class attribute for the model
-           >>>      self.model: Optional[nn.Module] = None
-           >>>
-           >>>  def _prepare_model(self, model: nn.Module, model_path: str) -> nn.Module:
-           >>>
-           >>>      # Load model parameters
-           >>>      model.load_state_dict(torch.load(model_path, map_location=self.device))
-           >>>
-           >>>      # Assign the model to the class
-           >>>      self.model = model.to(self.device)
-           >>>
-           >>>      # Set model to evaluation mode
-           >>>      self.model.eval()
-           >>>
-           >>>      return model
-           >>>
-           >>>  def _infer_on_batch(self,
-           >>>                      batch: Dict[str, Any],
-           >>>                      params: InferenceFilterParams
-           >>>                      ) -> Dict[str, Any]:
-           >>>      # Stack and adjust the numpy array such that it fits the
-           >>>      # [batch, channel / images, height, width, (depth)] format
-           >>>      # Note: The following statement works for slice-wise and patch-wise processing
-           >>>      if (loop_axis := params.indexing_strategy.loop_axis) is None:
-           >>>          adjusted_input = np.stack(batch['data'], axis=0)
-           >>>      else:
-           >>>          adjusted_input = np.stack(batch['data'], axis=0).squeeze(loop_axis + 2)
-           >>>
-           >>>      # Generate a tensor from the numpy array
-           >>>      input_tensor = torch.from_numpy(adjusted_input)
-           >>>
-           >>>      # Move the batch to the same device as the model
-           >>>      input_tensor = input_tensor.to(self.device, dtype=torch.float32)
-           >>>
-           >>>      # Apply the model to the batch
-           >>>      with torch.no_grad():
-           >>>          output_tensor = self.model(input_tensor)
-           >>>
-           >>>      # Retrieve the predicted classes from the output
-           >>>      if type(params.indexing_strategy) is SliceIndexingStrategy:
-           >>>          # Slice-wise processing
-           >>>
-           >>>          if len(params.output_organs) > 1:
-           >>>              # For multi-class segmentation
-           >>>              final_activation_fn = nn.Softmax2d()
-           >>>              output_tensor = torch.argmax(final_activation_fn(output_tensor), dim=1)
-           >>>
-           >>>          else:
-           >>>              # For binary segmentation
-           >>>              final_activation_fn = nn.Sigmoid()
-           >>>              output_tensor = (final_activation_fn(output_tensor) > 0.5).bool()
-           >>>
-           >>>      elif type(params.indexing_strategy) is PatchIndexingStrategy:
-           >>>
-           >>>          if len(params.output_organs) > 1:
-           >>>              # For multi-class segmentation
-           >>>              final_activation_fn = nn.Softmax(dim=1)
-           >>>              output_tensor = torch.argmax(final_activation_fn(output_tensor), dim=1)
-           >>>
-           >>>          else:
-           >>>              # For binary segmentation
-           >>>              final_activation_fn = nn.Sigmoid()
-           >>>              output_tensor = (final_activation_fn(output_tensor) > 0.5).bool()
-           >>>
-           >>>      else:
-           >>>          raise NotImplementedError(f'Indexing strategy {type(params.indexing_strategy).__name__} not'
-           >>>                                    'implemented.')
-           >>>
-           >>>      # Convert the output to a numpy array
-           >>>      # Note: The output shape must be [batch, height, width, (depth)]
-           >>>      output_array = output_tensor.cpu().numpy()
-           >>>
-           >>>      # Construct a list of output arrays such that it fits the index expressions
-           >>>      batch_output_list = []
-           >>>      for i in range(output_array.shape[0]):
-           >>>          batch_output_list.append(output_array[i, ...])
-           >>>
-           >>>      # Combine the output arrays into a dictionary
-           >>>      output = {'data': batch_output_list,
-           >>>                'index_expr': batch['index_expr']}
-           >>>
-           >>>      return output
-
-    .. automethod:: _get_input_array
-    .. automethod:: _prepare_model
-    .. automethod:: _infer_on_batch
-    .. automethod:: _apply_model
-    .. automethod:: _array_to_subject
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Returns whether the filter is invertible or not.
-
-        Note:
-            If your DL model is invertible, you should override this method and return ``True``.
-
-        Returns:
-            bool: False because the inference filter is typically not invertible.
-        """
-        return False
-
-    @staticmethod
-    def _get_input_array(subject: Subject, params: InferenceFilterParams) -> np.ndarray:
-        """Return the input array for the DL-model.
-
-        Note:
-            This function returns the concatenated data in C (channels) x H (height) x W (width) x D (depth) order.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance.
-            params (InferenceFilterParams): The filter parameters.
-
-        Returns:
-            np.ndarray: The input array for the DL-model.
-        """
-        # get the images for the modalities
-        images = [subject.get_image_by_modality(modality) for modality in params.modalities]
-
-        # check if images have the same shape
-        if not all(image.get_size() == images[0].get_size() for image in images):
-            raise ValueError(
-                "All images selected for inference must have the same shape. " "Please resample accordingly."
-            )
-
-        # get the image arrays and stack them
-        input_array = np.stack([image.get_image_data_as_np() for image in images], axis=0)
-
-        return input_array
-
-    @abstractmethod
-    def _prepare_model(self, model: Any, model_path: str) -> None:
-        """Prepare the model for inference (e.g. loading the model parameters). The loaded model must be added to
-        a class attribute such that it can be accessed by all methods.
-
-        This method must be implemented for the specific DL-framework.
-
-        Args:
-            model (Any): The model instance.
-            model_path (str): The path to the model parameters.
-
-        Returns:
-            Any: The model prepared for inference.
-        """
-        raise NotImplementedError("This method must be implemented for the specific DL-framework.")
-
-    @abstractmethod
-    def _infer_on_batch(self, batch: Dict[str, Any], params: InferenceFilterParams) -> Dict[str, Any]:
-        """Apply the model to a batch of data.
-
-        This method must be implemented for the specific DL-framework and is called with a batch of data. The batch
-        is a dictionary with the following keys:
-
-        * ``data``: A list of numpy arrays with the input data.
-
-        * ``index_expr``: A list of index expressions for the input data.
-
-
-        Note:
-            The output data in the dictionary must be a list of numpy arrays with the same length as the input data.
-            Each ``data`` entry must be a numpy array with the shape [C (channels) x H (height) x W (width) x
-            (D (depth))].
-
-
-        Args:
-            batch (Dict[str, Any]): The batch of data.
-            params (InferenceFilterParams): The filter parameters.
-
-        Returns:
-            Dict[str, Any]: The output of the model.
-        """
-        raise NotImplementedError("This method must be implemented for the specific DL-framework.")
-
-    def _apply_model(self, input_array: np.ndarray, params: InferenceFilterParams) -> np.ndarray:
-        """Apply the model to the input array to predict the segmentation.
-
-        Args:
-            input_array (np.ndarray): The input array for the DL-model.
-            params (InferenceFilterParams): The filter parameters.
-
-        Returns:
-            np.ndarray: The output array of the DL-model.
-        """
-        # Get the indexes of the data subset for processing
-        content_shape = input_array.shape[1:]
-        index_expressions = list(params.indexing_strategy(content_shape))
-
-        # Generate an empty array to store the output
-        output_array = np.zeros(content_shape, dtype=np.uint8)
-
-        # Iterate over the indexes in batches
-        while index_expressions:
-            # Construct the batch
-            batch = {"data": list(), "index_expr": list()}
-            for i in range(params.batch_size):
-                if len(index_expressions) <= 0:
-                    break
-
-                # Extend the index expression to include the image / channel axis
-                index_expr = index_expressions.pop(0)
-                ext_index_expr = (slice(None), *index_expr)
-
-                # Add the data to the batch
-                batch["data"].append(input_array[ext_index_expr])
-                batch["index_expr"].append(index_expr)
-
-            # Apply the model to the batch
-            processed_batch = self._infer_on_batch(batch, params)
-
-            # Insert the output batch into the output array
-            for i in range(len(processed_batch["data"])):
-                index_expr = processed_batch["index_expr"][i]
-                output_data = processed_batch["data"][i]
-                output_array[index_expr] = output_data
-
-        return output_array
-
-    @staticmethod
-    def _array_to_subject(output_array: np.ndarray, subject: Subject, params: InferenceFilterParams) -> Subject:
-        """Convert the output array of the DL-model to one or multiple :class:`~pyradise.data.image.SegmentationImage`
-        instances and add them to the provided :class:`~pyradise.data.subject.Subject` instance.
-
-        Args:
-            output_array (np.ndarray): The output array of the DL-model.
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to which the new
-             :class:`~pyradise.data.image.SegmentationImage` instances will be added.
-            params (InferenceFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with the new
-            :class:`~pyradise.data.image.SegmentationImage` instances added.
-        """
-        # Get the reference image
-        reference_image = subject.get_image_by_modality(params.reference_modality)
-
-        if reference_image is None:
-            raise ValueError("The reference image is not available.")
-
-        reference_image_sitk = reference_image.get_image_data()
-
-        # Separate the output array according to the provided organ indices
-        # and create images from the arrays
-        for idx in range(len(params.organ_indices)):
-            organ_array = np.zeros_like(output_array, dtype=np.uint8)
-            organ_array[output_array == params.organ_indices[idx]] = 1
-
-            # Create an image from the array
-            image = sitk.GetImageFromArray(organ_array)
-            image.CopyInformation(reference_image_sitk)
-
-            # Create a segmentation image from the image
-            segmentation_image = SegmentationImage(image, params.output_organs[idx], params.output_annotator)
-
-            # Copy the transform tape from the reference image such that the segmentation image
-            # can be transformed in the same way as the reference image
-            segmentation_image.transform_tape = deepcopy(reference_image.transform_tape)
-
-            # Add the segmentation image to the subject
-            subject.add_image(segmentation_image, force=True)
-
-        return subject
-
-    def execute(self, subject: Subject, params: InferenceFilterParams) -> Subject:
-        """Execute the filter on the provided :class:`~pyradise.data.subject.Subject` instance.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance.
-            params (InferenceFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with the newly added
-            :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-
-        # get the input array for the DL-model
-        input_array = self._get_input_array(subject, params)
-
-        # prepare the model for inference (e.g. load the model parameters)
-        self._prepare_model(params.model, params.model_path)
-
-        # apply the model
-        output_array = self._apply_model(input_array, params)
-
-        # construct the output image
-        subject = self._array_to_subject(output_array, subject, params)
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided :class:`~pyradise.data.subject.Subject` instance without any processing because
-        the inference of a DL-model is typically not invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-
-        # potentially warn the user that the operation is not invertible
-        if self.warn_on_non_invertible:
-            warnings.warn(
-                f"The {self.__class__.__name__} filter is called but is not invertible. "
-                "The provided subject is returned without modification."
-            )
-
-        return subject
+import os.path
+import warnings
+from abc import ABC, abstractmethod
+from copy import deepcopy
+from itertools import product
+from math import ceil
+from typing import Any, Dict, Optional, Tuple, Union
+
+import numpy as np
+import SimpleITK as sitk
+
+from pyradise.data import (Annotator, IntensityImage, Modality, Organ,
+                           SegmentationImage, Subject, TransformInfo,
+                           seq_to_modalities, seq_to_organs, str_to_annotator,
+                           str_to_modality)
+
+from .base import Filter, FilterParams
+
+__all__ = [
+    "InferenceFilterParams",
+    "InferenceFilter",
+    "IndexingStrategy",
+    "SliceIndexingStrategy",
+    "PatchIndexingStrategy",
+]
+
+
+class IndexingStrategy(ABC):
+    """An abstract class that defines the strategy for indexing / looping over the image data content during model
+    inference with an :class:`~pyradise.process.inference.InferenceFilter`. The :class:`IndexingStrategy` is typically
+    assigned to the :attr:`~pyradise.process.inference.InferenceFilterParams` for getting used by the
+    :class:`~pyradise.process.inference.InferenceFilter`.
+
+    Args:
+        loop_axis (Optional[int]): The axis along which the image data should be processed. If None, the image data
+         will be processed as a whole.
+
+    .. automethod:: __call__
+    """
+
+    def __init__(self, loop_axis: Optional[int]) -> None:
+        self.loop_axis: Optional[int] = loop_axis
+
+    @abstractmethod
+    def __call__(self, shape: Tuple[int, ...]) -> Tuple[Tuple[slice, ...], ...]:
+        """Compute the indexing expressions based on the given shape of the image data and the ``loop_axis`` attribute.
+
+        Args:
+            shape (Tuple[int, ...]): The shape of the image data for which the indexing expressions should be computed.
+
+        Returns:
+            Tuple[Tuple[slice, ...], ...]: The indexing expressions.
+        """
+        raise NotImplementedError()
+
+
+class SliceIndexingStrategy(IndexingStrategy):
+    """An indexing strategy class that computes the indexing expressions for slice-wise looping over the image data
+    content.
+
+    Args:
+        slice_axis (int): The axis along which the image data should be sliced.
+
+    .. automethod:: __call__
+    """
+
+    def __init__(self, slice_axis: int) -> None:
+        super().__init__(slice_axis)
+
+    def __call__(self, shape: Tuple[int, ...]) -> Tuple[Tuple[slice, ...], ...]:
+        """Compute the indexing expressions for each slice based on the given shape of the image data and the
+        ``loop_axis`` attribute.
+
+        Args:
+            shape (Tuple[int, ...]): The shape of the image data for which the indexing expressions should be computed.
+
+        Returns:
+            Tuple[Tuple[slice, ...], ...]: The indexing expressions.
+        """
+        # get the number of slices
+        num_slices = shape[self.loop_axis]
+
+        # create the indexing expressions
+        index_expressions = []
+        for i in range(num_slices):
+            # loop through the axis to build the indexing expression of a single slice
+            index_expression = []
+            for axis_idx in range(len(shape)):
+                # for the slice axis, we want to have just the current slice
+                if axis_idx == self.loop_axis:
+                    index_expression.append(slice(i, i + 1))
+
+                # for all other axes, we want to have the full image extent
+                else:
+                    index_expression.append(slice(None))
+
+            index_expressions.append(tuple(index_expression))
+
+        return tuple(index_expressions)
+
+
+class PatchIndexingStrategy(IndexingStrategy):
+    """An indexing strategy class that computes the indexing expressions for patch-wise looping over the image data
+    content.
+
+    Args:
+        patch_shape (Tuple[int, ...]): The shape of the patches.
+        stride (Optional[Tuple[int, ...]]): The stride of the patches. If None, the patches will be extracted with the
+         same stride as the patch shape.
+
+    .. automethod:: __call__
+    """
+
+    def __init__(self, patch_shape: Tuple[int, ...], stride: Optional[Tuple[int, ...]] = None) -> None:
+        super().__init__(None)
+
+        if stride is None:
+            stride_ = patch_shape
+        else:
+            stride_ = stride
+
+        if len(patch_shape) != len(stride_):
+            raise ValueError(
+                f"Invalid patch shape {patch_shape} and stride {stride_}. "
+                "Patch shape and stride must have the same length."
+            )
+
+        if any([patch_size <= 0 for patch_size in patch_shape]):
+            raise ValueError(f"Invalid patch shape {patch_shape}. Patch shape must be positive.")
+        self.patch_shape = patch_shape
+
+        if any([stride_size <= 0 for stride_size in stride_]):
+            raise ValueError(f"Invalid stride {stride_}. Stride must be positive.")
+        self.stride = stride_
+
+    def __call__(self, shape: Tuple[int, ...]) -> Tuple[Tuple[slice, ...], ...]:
+        """Compute the indexing expressions for each patch based on the given shape of the image data and the
+        ``patch_shape`` and ``stride`` attributes.
+
+        Args:
+            shape (Tuple[int, ...]): The shape of the image data for which the indexing expressions should be computed.
+
+        Returns:
+            Tuple[Tuple[slice, ...], ...]: The indexing expressions.
+        """
+        # get the number of patches in each dimension
+        num_patches = tuple(
+            range(ceil((shape[i] - self.patch_shape[i]) / self.stride[i]) + 1) for i in range(len(self.patch_shape))
+        )
+
+        # get the combinations of patch indices
+        patch_indexes = tuple(product(*num_patches))
+
+        # create the indexing expressions
+        index_expressions = []
+        for patch_index in patch_indexes:
+            index_expression = []
+
+            for axis_idx in range(len(self.patch_shape)):
+                patch_start = patch_index[axis_idx] * self.stride[axis_idx]
+                patch_end = min(patch_start + self.patch_shape[axis_idx], shape[axis_idx])
+
+                # correct the patch start such that each patch is of equal size
+                if patch_end - patch_start < self.patch_shape[axis_idx]:
+                    patch_start = patch_end - self.patch_shape[axis_idx]
+
+                index_expression.append(slice(patch_start, patch_end))
+
+            index_expressions.append(tuple(index_expression))
+
+        return tuple(index_expressions)
+
+
+class InferenceFilterParams(FilterParams):
+    """A filter parameter class for the prototype :class:`~pyradise.process.inference.InferenceFilter` class.
+
+    Args:
+        model (Any): The model to apply.
+        model_path (Optional[str]): The path to the model parameters.
+        modalities (Tuple[Union[str, Modality], ...]): The :class:`~pyradise.data.modality.Modality` s of the
+         :class:`~pyradise.data.image.IntensityImage` instances to use for inference.
+        reference_modality (Union[str, Modality]): The :class:`~pyradise.data.modality.Modality` that is used as the
+         reference to define the output properties of the created :class:`~pyradise.data.image.SegmentationImage`
+         instances.
+        output_organs (Tuple[Union[str, Organ], ...]): The organs that get assigned to the created
+         :class:`~pyradise.data.image.SegmentationImage` instances.
+        output_annotator (Union[str, Annotator]): The annotator that get assigned to the created
+         :class:`~pyradise.data.image.SegmentationImage` instances.
+        organ_indices (Tuple[int, ...]): The indices of the organs on the output mask of the `model`
+         (must match `output_organs` and `output_annotators`).
+        batch_size (int): The batch size to use for inference.
+        indexing_strategy (IndexingStrategy): The :class:`~pyradise.process.inference.IndexingStrategy` defining how
+         the data is fed to the `model`.
+    """
+
+    def __init__(
+        self,
+        model: Any,
+        model_path: Optional[str],
+        modalities: Tuple[Union[str, Modality], ...],
+        reference_modality: Union[str, Modality],
+        output_organs: Tuple[Union[str, Organ], ...],
+        output_annotator: Union[str, Annotator],
+        organ_indices: Tuple[int, ...],
+        batch_size: int,
+        indexing_strategy: IndexingStrategy,
+    ) -> None:
+        # adjust the loop_axis because the first axis will be the channel axis
+        super().__init__()
+
+        # the model to apply
+        self.model = model
+
+        # the path to the model parameters
+        if model_path is not None:
+            if not os.path.exists(model_path):
+                raise FileNotFoundError(f"Model path '{model_path}' is invalid.")
+            self.model_path: Optional[str] = model_path
+        else:
+            self.model_path: Optional[str] = None
+
+        # the modalities to use for inference
+        # -> the modalities must be in the correct order to construct the model input
+        self.modalities = seq_to_modalities(modalities)
+
+        # the modality that is used as the reference to define the output properties of the created
+        # segmentation images
+        self.reference_modality: Modality = str_to_modality(reference_modality)
+
+        # the organs that get assigned to the created segmentation images
+        self.output_organs: Tuple[Organ, ...] = seq_to_organs(output_organs)
+
+        # the annotator that get assigned to the created segmentation images
+        self.output_annotator: Annotator = str_to_annotator(output_annotator)
+
+        # the indexes of the organs on the output mask of the model (must match output_organs)
+        if len(output_organs) != len(organ_indices):
+            raise ValueError("Invalid number of organ indices. Must match the number of output_organs.")
+        self.organ_indices = organ_indices
+
+        # the batch size
+        self.batch_size = batch_size
+
+        # the indexing strategy
+        self.indexing_strategy = indexing_strategy
+
+
+class InferenceFilter(Filter):
+    """A prototype filter class for applying a DL-model to a :class:`~pyradise.data.subject.Subject` instance.
+
+    This class is a prototype for applying a DL-model to a :class:`~pyradise.data.subject.Subject` instance. PyRaDiSe
+    provides just a prototype for this filter such that it stays DL framework-agnostic. Therefore, the actual
+    implementation of the DL-framework specific methods must be implemented in a subclass.
+
+    For implementing a DL-framework specific :class:`InferenceFilter`, the following methods must be implemented:
+
+    * :meth:`~pyradise.process.inference.InferenceFilter._prepare_model`: Prepare the model for inference (e.g. load
+      the parameters from a model file).
+
+    * :meth:`~pyradise.process.inference.InferenceFilter._infer_on_batch`: Apply the model to a batch of data such
+      that the output shape can be inserted into the new image via the indexing expressions provided by the
+      chosen :class:`~pyradise.process.inference.IndexingStrategy`.
+
+
+    Example:
+
+           Implementation example of a PyTorch-based :class:`InferenceFilter` subclass:
+
+           >>> import torch
+           >>> import torch.nn as nn
+           >>>
+           >>> class ExampleInferenceFilter(InferenceFilter):
+           >>>
+           >>>  def __init__(self):
+           >>>      super().__init__()
+           >>>
+           >>>      # Define the device on which the model should be run
+           >>>      self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
+           >>>
+           >>>      # Define a class attribute for the model
+           >>>      self.model: Optional[nn.Module] = None
+           >>>
+           >>>  def _prepare_model(self, model: nn.Module, model_path: str) -> nn.Module:
+           >>>
+           >>>      # Load model parameters
+           >>>      model.load_state_dict(torch.load(model_path, map_location=self.device))
+           >>>
+           >>>      # Assign the model to the class
+           >>>      self.model = model.to(self.device)
+           >>>
+           >>>      # Set model to evaluation mode
+           >>>      self.model.eval()
+           >>>
+           >>>      return model
+           >>>
+           >>>  def _infer_on_batch(self,
+           >>>                      batch: Dict[str, Any],
+           >>>                      params: InferenceFilterParams
+           >>>                      ) -> Dict[str, Any]:
+           >>>      # Stack and adjust the numpy array such that it fits the
+           >>>      # [batch, channel / images, height, width, (depth)] format
+           >>>      # Note: The following statement works for slice-wise and patch-wise processing
+           >>>      if (loop_axis := params.indexing_strategy.loop_axis) is None:
+           >>>          adjusted_input = np.stack(batch['data'], axis=0)
+           >>>      else:
+           >>>          adjusted_input = np.stack(batch['data'], axis=0).squeeze(loop_axis + 2)
+           >>>
+           >>>      # Generate a tensor from the numpy array
+           >>>      input_tensor = torch.from_numpy(adjusted_input)
+           >>>
+           >>>      # Move the batch to the same device as the model
+           >>>      input_tensor = input_tensor.to(self.device, dtype=torch.float32)
+           >>>
+           >>>      # Apply the model to the batch
+           >>>      with torch.no_grad():
+           >>>          output_tensor = self.model(input_tensor)
+           >>>
+           >>>      # Retrieve the predicted classes from the output
+           >>>      if type(params.indexing_strategy) is SliceIndexingStrategy:
+           >>>          # Slice-wise processing
+           >>>
+           >>>          if len(params.output_organs) > 1:
+           >>>              # For multi-class segmentation
+           >>>              final_activation_fn = nn.Softmax2d()
+           >>>              output_tensor = torch.argmax(final_activation_fn(output_tensor), dim=1)
+           >>>
+           >>>          else:
+           >>>              # For binary segmentation
+           >>>              final_activation_fn = nn.Sigmoid()
+           >>>              output_tensor = (final_activation_fn(output_tensor) > 0.5).bool()
+           >>>
+           >>>      elif type(params.indexing_strategy) is PatchIndexingStrategy:
+           >>>
+           >>>          if len(params.output_organs) > 1:
+           >>>              # For multi-class segmentation
+           >>>              final_activation_fn = nn.Softmax(dim=1)
+           >>>              output_tensor = torch.argmax(final_activation_fn(output_tensor), dim=1)
+           >>>
+           >>>          else:
+           >>>              # For binary segmentation
+           >>>              final_activation_fn = nn.Sigmoid()
+           >>>              output_tensor = (final_activation_fn(output_tensor) > 0.5).bool()
+           >>>
+           >>>      else:
+           >>>          raise NotImplementedError(f'Indexing strategy {type(params.indexing_strategy).__name__} not'
+           >>>                                    'implemented.')
+           >>>
+           >>>      # Convert the output to a numpy array
+           >>>      # Note: The output shape must be [batch, height, width, (depth)]
+           >>>      output_array = output_tensor.cpu().numpy()
+           >>>
+           >>>      # Construct a list of output arrays such that it fits the index expressions
+           >>>      batch_output_list = []
+           >>>      for i in range(output_array.shape[0]):
+           >>>          batch_output_list.append(output_array[i, ...])
+           >>>
+           >>>      # Combine the output arrays into a dictionary
+           >>>      output = {'data': batch_output_list,
+           >>>                'index_expr': batch['index_expr']}
+           >>>
+           >>>      return output
+
+    .. automethod:: _get_input_array
+    .. automethod:: _prepare_model
+    .. automethod:: _infer_on_batch
+    .. automethod:: _apply_model
+    .. automethod:: _array_to_subject
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Returns whether the filter is invertible or not.
+
+        Note:
+            If your DL model is invertible, you should override this method and return ``True``.
+
+        Returns:
+            bool: False because the inference filter is typically not invertible.
+        """
+        return False
+
+    @staticmethod
+    def _get_input_array(subject: Subject, params: InferenceFilterParams) -> np.ndarray:
+        """Return the input array for the DL-model.
+
+        Note:
+            This function returns the concatenated data in C (channels) x H (height) x W (width) x D (depth) order.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance.
+            params (InferenceFilterParams): The filter parameters.
+
+        Returns:
+            np.ndarray: The input array for the DL-model.
+        """
+        # get the images for the modalities
+        images = [subject.get_image_by_modality(modality) for modality in params.modalities]
+
+        # check if images have the same shape
+        if not all(image.get_size() == images[0].get_size() for image in images):
+            raise ValueError(
+                "All images selected for inference must have the same shape. " "Please resample accordingly."
+            )
+
+        # get the image arrays and stack them
+        input_array = np.stack([image.get_image_data_as_np() for image in images], axis=0)
+
+        return input_array
+
+    @abstractmethod
+    def _prepare_model(self, model: Any, model_path: str) -> None:
+        """Prepare the model for inference (e.g. loading the model parameters). The loaded model must be added to
+        a class attribute such that it can be accessed by all methods.
+
+        This method must be implemented for the specific DL-framework.
+
+        Args:
+            model (Any): The model instance.
+            model_path (str): The path to the model parameters.
+
+        Returns:
+            Any: The model prepared for inference.
+        """
+        raise NotImplementedError("This method must be implemented for the specific DL-framework.")
+
+    @abstractmethod
+    def _infer_on_batch(self, batch: Dict[str, Any], params: InferenceFilterParams) -> Dict[str, Any]:
+        """Apply the model to a batch of data.
+
+        This method must be implemented for the specific DL-framework and is called with a batch of data. The batch
+        is a dictionary with the following keys:
+
+        * ``data``: A list of numpy arrays with the input data.
+
+        * ``index_expr``: A list of index expressions for the input data.
+
+
+        Note:
+            The output data in the dictionary must be a list of numpy arrays with the same length as the input data.
+            Each ``data`` entry must be a numpy array with the shape [C (channels) x H (height) x W (width) x
+            (D (depth))].
+
+
+        Args:
+            batch (Dict[str, Any]): The batch of data.
+            params (InferenceFilterParams): The filter parameters.
+
+        Returns:
+            Dict[str, Any]: The output of the model.
+        """
+        raise NotImplementedError("This method must be implemented for the specific DL-framework.")
+
+    def _apply_model(self, input_array: np.ndarray, params: InferenceFilterParams) -> np.ndarray:
+        """Apply the model to the input array to predict the segmentation.
+
+        Args:
+            input_array (np.ndarray): The input array for the DL-model.
+            params (InferenceFilterParams): The filter parameters.
+
+        Returns:
+            np.ndarray: The output array of the DL-model.
+        """
+        # Get the indexes of the data subset for processing
+        content_shape = input_array.shape[1:]
+        index_expressions = list(params.indexing_strategy(content_shape))
+
+        # Generate an empty array to store the output
+        output_array = np.zeros(content_shape, dtype=np.uint8)
+
+        # Iterate over the indexes in batches
+        while index_expressions:
+            # Construct the batch
+            batch = {"data": list(), "index_expr": list()}
+            for i in range(params.batch_size):
+                if len(index_expressions) <= 0:
+                    break
+
+                # Extend the index expression to include the image / channel axis
+                index_expr = index_expressions.pop(0)
+                ext_index_expr = (slice(None), *index_expr)
+
+                # Add the data to the batch
+                batch["data"].append(input_array[ext_index_expr])
+                batch["index_expr"].append(index_expr)
+
+            # Apply the model to the batch
+            processed_batch = self._infer_on_batch(batch, params)
+
+            # Insert the output batch into the output array
+            for i in range(len(processed_batch["data"])):
+                index_expr = processed_batch["index_expr"][i]
+                output_data = processed_batch["data"][i]
+                output_array[index_expr] = output_data
+
+        return output_array
+
+    @staticmethod
+    def _array_to_subject(output_array: np.ndarray, subject: Subject, params: InferenceFilterParams) -> Subject:
+        """Convert the output array of the DL-model to one or multiple :class:`~pyradise.data.image.SegmentationImage`
+        instances and add them to the provided :class:`~pyradise.data.subject.Subject` instance.
+
+        Args:
+            output_array (np.ndarray): The output array of the DL-model.
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to which the new
+             :class:`~pyradise.data.image.SegmentationImage` instances will be added.
+            params (InferenceFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with the new
+            :class:`~pyradise.data.image.SegmentationImage` instances added.
+        """
+        # Get the reference image
+        reference_image = subject.get_image_by_modality(params.reference_modality)
+
+        if reference_image is None:
+            raise ValueError("The reference image is not available.")
+
+        reference_image_sitk = reference_image.get_image_data()
+
+        # Separate the output array according to the provided organ indices
+        # and create images from the arrays
+        for idx in range(len(params.organ_indices)):
+            organ_array = np.zeros_like(output_array, dtype=np.uint8)
+            organ_array[output_array == params.organ_indices[idx]] = 1
+
+            # Create an image from the array
+            image = sitk.GetImageFromArray(organ_array)
+            image.CopyInformation(reference_image_sitk)
+
+            # Create a segmentation image from the image
+            segmentation_image = SegmentationImage(image, params.output_organs[idx], params.output_annotator)
+
+            # Copy the transform tape from the reference image such that the segmentation image
+            # can be transformed in the same way as the reference image
+            segmentation_image.transform_tape = deepcopy(reference_image.transform_tape)
+
+            # Add the segmentation image to the subject
+            subject.add_image(segmentation_image, force=True)
+
+        return subject
+
+    def execute(self, subject: Subject, params: InferenceFilterParams) -> Subject:
+        """Execute the filter on the provided :class:`~pyradise.data.subject.Subject` instance.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance.
+            params (InferenceFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with the newly added
+            :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+
+        # get the input array for the DL-model
+        input_array = self._get_input_array(subject, params)
+
+        # prepare the model for inference (e.g. load the model parameters)
+        self._prepare_model(params.model, params.model_path)
+
+        # apply the model
+        output_array = self._apply_model(input_array, params)
+
+        # construct the output image
+        subject = self._array_to_subject(output_array, subject, params)
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided :class:`~pyradise.data.subject.Subject` instance without any processing because
+        the inference of a DL-model is typically not invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+
+        # potentially warn the user that the operation is not invertible
+        if self.warn_on_non_invertible:
+            warnings.warn(
+                f"The {self.__class__.__name__} filter is called but is not invertible. "
+                "The provided subject is returned without modification."
+            )
+
+        return subject
```

### Comparing `pyradise-0.2.2/pyradise/process/intensity.py` & `pyradise-0.2.3/pyradise/process/intensity.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,1397 +1,1397 @@
-from abc import abstractmethod
-from typing import Any, Optional, Tuple, Union
-from warnings import warn
-
-import numpy as np
-import SimpleITK as sitk
-
-from pyradise.data import (IntensityImage, Modality, SegmentationImage,
-                           Subject, TransformInfo, seq_to_modalities)
-
-from .base import Filter, FilterParams, LoopEntryFilter, LoopEntryFilterParams
-
-__all__ = [
-    "IntensityFilterParams",
-    "IntensityFilter",
-    "IntensityLoopFilterParams",
-    "IntensityLoopFilter",
-    "ZScoreNormFilterParams",
-    "ZScoreNormFilter",
-    "ZeroOneNormFilterParams",
-    "ZeroOneNormFilter",
-    "RescaleIntensityFilterParams",
-    "RescaleIntensityFilter",
-    "ClipIntensityFilterParams",
-    "ClipIntensityFilter",
-    "GaussianFilterParams",
-    "GaussianFilter",
-    "MedianFilterParams",
-    "MedianFilter",
-    "LaplacianFilterParams",
-    "LaplacianFilter",
-]
-
-
-class IntensityFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.intensity.IntensityFilter` base class. In addition to
-    the :class:`~pyradise.process.base.FilterParams` class, this class also provides a ``modalities`` parameter to
-    specify the images to be processed by the filters.
-
-    Args:
-        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities associated with the corresponding
-         :class:`~pyradise.data.image.IntensityImage` instances that should be processed. If ``None`` is provided,
-         all :class:`~pyradise.data.image.IntensityImage` instances will be processed (default: None).
-    """
-
-    def __init__(self, modalities: Optional[Tuple[Union[Modality, str], ...]] = None) -> None:
-        if modalities is not None:
-            self.modalities = seq_to_modalities(modalities)
-        else:
-            self.modalities: Optional[Tuple[Modality, ...]] = None
-
-
-class IntensityFilter(Filter):
-    """An abstract filter base class for intensity modifying filters which process the whole image content. In contrast
-    to the :class:`~pyradise.process.base.Filter` base class, this class provides two additional abstract methods (
-    i.e. :meth:`~pyradise.process.intensity.IntensityFilter._process_image` and
-    :meth:`~pyradise.process.intensity.IntensityFilter._process_image_inverse`) for processing the image content as
-    whole. Thus, this base class is intended to be used for intensity modifying filters which process the whole image
-    content at once.
-
-    Note:
-        The selection of the :class:`~pyradise.data.image.IntensityImage` instances to be processed is specified by the
-        :class:`~pyradise.process.intensity.IntensityFilterParams` instance. If the ``modalities`` parameter is set to
-        ``None``, all :class:`~pyradise.data.image.IntensityImage` instances will be processed. Otherwise, only the
-        :class:`~pyradise.data.image.IntensityImage` instances with the specified modalities will be processed. If the
-        user wants to implement its own intensity modifying filter, the user do not need to implement the
-        selection of the images to be processed. The selection mechanism is already provided in the implemented
-        :meth:`~pyradise.process.intensity.IntensityFilter.execute` and
-        :meth:`~pyradise.process.intensity.IntensityFilter.execute_inverse` methods.
-
-    Example:
-
-        An example implementation of an intensity clippling filter:
-
-        >>> class ClipFilterParams(IntensityFilterParams):
-        >>>     def __init__(self,
-        >>>                  min_out: float,
-        >>>                  max_out: float,
-        >>>                  modalities: Optional[Tuple[Union[Modality, str], ...]] = None
-        >>>                  ) -> None:
-        >>>         super().__init__(modalities)
-        >>>
-        >>>         if min_out == max_out:
-        >>>             raise ValueError('The min and max output intensity '
-        >>>                              'values must not be equal because '
-        >>>                              'the resulting image '
-        >>>                              'will have constant intensity.')
-        >>>
-        >>>         if min_out > max_out:
-        >>>             min_out, max_out = max_out, min_out
-        >>>
-        >>>         self.min_value: float = min_out
-        >>>         self.max_value: float = max_out
-        >>>
-        >>>
-        >>> class ClipFilter(IntensityFilter):
-        >>>
-        >>>     @staticmethod
-        >>>     def is_invertible() -> bool:
-        >>>         # return False because the clipping is not invertible
-        >>>         return False
-        >>>
-        >>>     def _process_image(self,
-        >>>                        image: IntensityImage,
-        >>>                        params: ClipFilterParams
-        >>>                        ) -> IntensityImage:
-        >>>         # get the image data
-        >>>         sitk_image = image.get_image_data()
-        >>>
-        >>>         # apply the clipping
-        >>>         clipped_image_sitk = sitk.Clamp(sitk_image,
-        >>>                                         sitk_image.GetPixelIDValue(),
-        >>>                                         params.min_value,
-        >>>                                         params.max_value)
-        >>>
-        >>>         # add the clipped SimpleITK image to the image
-        >>>         image.set_image_data(clipped_image_sitk)
-        >>>
-        >>>         # track the necessary information
-        >>>         self._register_tracked_data(image, sitk_image,
-        >>>                                     clipped_image_sitk, params)
-        >>>
-        >>>         return image
-        >>>
-        >>>     def _process_image_inverse(self,
-        >>>                                image: IntensityImage,
-        >>>                                transform_info: TransformInfo
-        >>>                                ) -> IntensityImage:
-        >>>         # return the original image because the clipping
-        >>>         # is not invertible
-        >>>         return image
-        >>>
-        >>>     def execute(self,
-        >>>                 subject: Subject,
-        >>>                 params: ClipFilterParams
-        >>>                 ) -> Subject:
-        >>>         # implement exclusively due to type adaptation for params
-        >>>         return super().execute(subject, params)
-
-    """
-
-    @abstractmethod
-    def _process_image(self, image: IntensityImage, params: IntensityFilterParams) -> IntensityImage:
-        """Process the content of an image.
-
-        Args:
-            image (IntensityImage): The :class:`~pyradise.data.image.IntensityImage` instance to be processed.
-            params (IntensityFilterParams): The filter parameters.
-
-        Returns:
-            IntensityImage: The processed :class:`~pyradise.data.image.IntensityImage` instance.
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
-        """Process the content of an image inversely.
-
-        Args:
-            image (IntensityImage): The :class:`~pyradise.data.image.IntensityImage` instance to be processed.
-            transform_info (TransformInfo): The transform information.
-
-        Returns:
-            IntensityImage: The inversely processed :class:`~pyradise.data.image.IntensityImage` instance.
-        """
-        raise NotImplementedError()
-
-    def execute(self, subject: Subject, params: IntensityFilterParams) -> Subject:
-        """Execute the intensity modifying procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            params (IntensityFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with processed
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        for image in subject.get_images():
-            if isinstance(image, IntensityImage):
-                # check if the image is specified for processing
-                if params.modalities is not None and image.modality not in params.modalities:
-                    image_sitk = image.get_image_data()
-                    self._register_tracked_data(image, image_sitk, image_sitk, params)
-
-                else:
-                    self._process_image(image, params)
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Execute the inverse intensity modifying procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with processed
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-
-        # potentially warn the user that the operation is not invertible
-        if self.warn_on_non_invertible and not self.is_invertible():
-            warn(
-                "WARNING: "
-                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
-                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
-                "is returned without modification."
-            )
-
-        for image in subject.get_images():
-            if target_image is not None and image != target_image:
-                continue
-
-            if isinstance(image, IntensityImage):
-                if (
-                    transform_info.params.modalities is not None
-                    and image.get_modality() not in transform_info.params.modalities
-                ):
-                    continue
-
-                self._process_image_inverse(image, transform_info)
-
-        return subject
-
-
-class IntensityLoopFilterParams(LoopEntryFilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.intensity.IntensityLoopFilter` base class.
-    In addition to the :class:`~pyradise.process.base.LoopEntryFilterParams` class, this class also provides a
-    ``modalities`` parameter to specify the images to be processed by the filters.
-
-    Args:
-        loop_axis (Optional[int]): The axis along which the data transformation is performed. If ``None``, the
-         transformation is performed on the whole image at once. If a value is given, the transformation is performed
-         by looping over the corresponding image dimension.
-        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities associated with the corresponding
-         :class:`~pyradise.data.image.IntensityImage` instances that should be processed. If ``None`` is provided,
-         all :class:`~pyradise.data.image.IntensityImage` instances will be processed (default: None).
-    """
-
-    def __init__(self, loop_axis: Optional[int], modalities: Optional[Tuple[Union[Modality, str], ...]] = None) -> None:
-        super().__init__(loop_axis)
-
-        if modalities is not None:
-            self.modalities = seq_to_modalities(modalities)
-        else:
-            self.modalities = None
-
-
-class IntensityLoopFilter(LoopEntryFilter):
-    """An abstract base class for intensity modifying filters that can process the provided image content by looping
-    over a specific axis or by using the whole image extent at once. This base class is intended to be used for
-    implementing flexible intensity modifying filters that can iteratively process subsets of the image content such as
-    for example normalization filters which may be applied slice-wise to the image content.
-
-    For the implementation of a new :class:`~pyradise.process.intensity.IntensityLoopFilter` subclass implement the
-    provided :meth:`~pyradise.process.intensity.IntensityLoopFilter._modify_array` and
-    :meth:`~pyradise.process.intensity.IntensityLoopFilter._modify_array_inverse` methods. Both methods are called
-    iteratively for each loop axis position. The :meth:`~pyradise.process.intensity.IntensityLoopFilter._modify_array`
-    method is called for the forward processing and the
-    :meth:`~pyradise.process.intensity.IntensityLoopFilter._modify_array_inverse` method is called for the inverse
-    processing.
-
-    Note:
-        The selection of the :class:`~pyradise.data.image.IntensityImage` instances to be processed is specified by the
-        :class:`~pyradise.process.intensity.IntensityLoopFilterParams` instance. If the ``modalities`` parameter is set
-        to ``None``, all :class:`~pyradise.data.image.IntensityImage` instances will be processed. Otherwise, only the
-        :class:`~pyradise.data.image.IntensityImage` instances with the specified modalities will be processed. If the
-        user wants to implement its own intensity modifying filter, the user do not need to implement the
-        selection of the images to be processed. The selection mechanism is already provided in the implemented
-        :meth:`~pyradise.process.intensity.IntensityLoopFilter.execute` and
-        :meth:`~pyradise.process.intensity.IntensityLoopFilter.execute_inverse` methods.
-    """
-
-    def __init__(self):
-        super().__init__()
-
-        # provides an index for the position along the loop axis
-        self.loop_axis_pos_idx = 0
-
-    @abstractmethod
-    def _modify_array(self, array: np.ndarray, params: IntensityLoopFilterParams) -> np.ndarray:
-        """The intensity modification function which is applied to the provided array. The provided array can be of
-        n-dimensions whereby the dimensionality depend on the provided data and the ``loop_axis`` parameter as
-        specified in the appropriate :class:`~pyradise.process.intensity.IntensityFilterParams` instance.
-
-        Args:
-            array (np.ndarray): The array to be processed.
-            params (IntensityLoopFilterParams): The parameters used for the processing.
-
-        Returns:
-            np.ndarray: The processed array.
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def _modify_array_inverse(self, array: np.ndarray, params: TransformInfo) -> np.ndarray:
-        """The inverse intensity modification function which is applied to the provided array. The provided array can
-        be of n-dimensions whereby the dimensionality depend on the provided data and the ``loop_axis`` parameter as
-        specified in the appropriate :class:`~pyradise.process.intensity.IntensityFilterParams` instance which is
-        contained in the provided :class:`~pyradise.data.taping.TransformInfo` instance.
-
-        Args:
-            array (np.ndarray): The array to be processed.
-            params (TransformInfo): The transform information.
-
-        Returns:
-            np.ndarray: The processed array.
-        """
-        raise NotImplementedError()
-
-    def _process_image(self, image: IntensityImage, params: Union[IntensityLoopFilterParams, Any]) -> IntensityImage:
-        """Execute the intensity modifying procedure on the provided image by looping over the image accordingly.
-
-        Args:
-            image (IntensityImage): The image to be processed.
-            params (Union[IntensityLoopFilterParams, Any]): The filter parameters.
-
-        Returns:
-            IntensityImage: The processed image.
-        """
-
-        # set the loop axis position index to zero because of processing a new image
-        self.loop_axis_pos_idx = 0
-
-        # get the image data for computation
-        image_sitk = image.get_image_data()
-        if "integer" in image_sitk.GetPixelIDTypeAsString():
-            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
-
-        image_np = sitk.GetArrayFromImage(image_sitk)
-
-        # perform the intensity modifying procedure
-        new_image_np = self.loop_entries(image_np, params, self._modify_array, params.loop_axis)
-
-        # construct the new image
-        new_image_sitk = sitk.GetImageFromArray(new_image_np)
-        new_image_sitk.CopyInformation(image_sitk)
-
-        # set the new image data to the image
-        image.set_image_data(new_image_sitk)
-
-        # keep track of the transformation
-        self._register_tracked_data(image, image_sitk, new_image_sitk, params)
-
-        return image
-
-    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
-        """Execute the inverse intensity modifying procedure on the provided image by looping over the image
-        accordingly.
-
-        Args:
-            image (IntensityImage): The image to be processed.
-            transform_info (TransformInfo): The transform information.
-
-        Returns:
-            IntensityImage: The processed image.
-        """
-        # return the image as is if the filter is not invertible
-        if not self.is_invertible():
-            return image
-
-        # set the loop axis position index to zero because of processing a new image
-        self.loop_axis_pos_idx = 0
-
-        # get the image data for inverse processing
-        image_sitk = image.get_image_data()
-        if "integer" in image_sitk.GetPixelIDTypeAsString():
-            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
-        image_np = sitk.GetArrayFromImage(image_sitk)
-
-        # perform the inverse intensity modifying procedure
-        new_image_np = self.loop_entries(
-            image_np, transform_info, self._modify_array_inverse, transform_info.params.loop_axis
-        )
-
-        # construct the new image
-        new_image_sitk = sitk.GetImageFromArray(new_image_np)
-        new_image_sitk.CopyInformation(image_sitk)
-
-        # set the new image data to the image
-        image.set_image_data(new_image_sitk)
-
-        return image
-
-    def execute(self, subject: Subject, params: IntensityLoopFilterParams) -> Subject:
-        """Execute the intensity modifying procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            params (IntensityLoopFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with processed
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        for image in subject.get_images():
-            if isinstance(image, IntensityImage):
-                # check if the image is specified for processing
-                if params.modalities is not None and image.get_modality() not in params.modalities:
-                    image_sitk = image.get_image_data()
-                    self._register_tracked_data(image, image_sitk, image_sitk, params)
-
-                else:
-                    self._process_image(image, params)
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Execute the inverse intensity modifying procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with processed
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        for image in subject.get_images():
-            if target_image is not None and image != target_image:
-                continue
-
-            if isinstance(image, IntensityImage):
-                if (
-                    transform_info.params.modalities is not None
-                    and image.get_modality() not in transform_info.params.modalities
-                ):
-                    continue
-
-                self._process_image_inverse(image, transform_info)
-
-        return subject
-
-
-# pylint: disable=too-few-public-methods
-class ZScoreNormFilterParams(IntensityLoopFilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.intensity.ZScoreNormFilter` class.
-
-    Args:
-        loop_axis (Optional[int]): The axis along which the intensity normalization is performed. If None, the
-         intensity normalization is performed on the whole image extent at once. If a value is given, the intensity
-         normalization is performed by looping over the corresponding image dimension (default: None).
-        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be rescaled. If
-         ``None`` is provided all images of the provided subject are rescaled (default: None).
-    """
-
-    def __init__(
-        self, loop_axis: Optional[int] = None, modalities: Optional[Tuple[Union[Modality, str], ...]] = None
-    ) -> None:
-        super().__init__(loop_axis, modalities)
-
-
-class ZScoreNormFilter(IntensityLoopFilter):
-    """A normalization filter class performing an invertible z-score normalization on all
-    :class:`~pyradise.data.image.IntensityImage` instances of the provided :class:`~pyradise.data.subject.Subject`
-    instance.
-
-    For the normalization the following formula is applied to the image extent or its subsets:
-
-    .. math::
-        I_{norm} = \\frac{I_{orig} - \\mu(I_{orig})}{\\sigma(I_{orig})}
-
-    For the inverse normalization the following formula is applied to the image extent or its subsets:
-
-    .. math::
-        I_{orig} = I_{norm} \\cdot \\sigma(I_{orig}) + \\mu(I_{orig})
-
-    During the normalization procedure, the intensity mean and standard deviation of the original image or its subsets
-    are tracked such that these values are available for the inverse normalization.
-
-    Warning:
-        The inverse normalization procedure may not yield the expected results if successive
-        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
-        Thus, it's recommended to use the invertibility feature with appropriate caution.
-
-    Note:
-        Due to the limited precision of floating point numbers, the inverse normalization may not be exact.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Check if the filter is invertible.
-
-        Returns:
-            bool: True because the z-score normalization procedure is invertible.
-        """
-        return True
-
-    def _modify_array(self, array: np.ndarray, params: Any) -> np.ndarray:
-        """Apply the z-score normalization function to the provided data array.
-
-        Args:
-            array (np.ndarray): The array to be normalized.
-            params (Any): The parameters used for the normalization.
-
-        Returns:
-            np.ndarray: The z-score normalized array.
-        """
-        # get the mean and standard deviation of the array
-        mean = np.mean(array)
-        std = np.std(array)
-
-        # track the changes
-        self.tracking_data[f"mean_{self.loop_axis_pos_idx}"] = mean
-        self.tracking_data[f"std_{self.loop_axis_pos_idx}"] = std
-
-        self.loop_axis_pos_idx += 1
-
-        # compute the normalization function
-        return (array - np.mean(array)) / np.std(array)
-
-    def _modify_array_inverse(self, array: np.ndarray, params: TransformInfo) -> np.ndarray:
-        """Apply the de-normalization function to the provided data array.
-
-        Args:
-            array (np.ndarray): The array to be denormalized.
-            params (TransformInfo): The parameters used for the de-normalization.
-
-        Returns:
-            np.ndarray: The denormalized array.
-
-        """
-        # get the tracked data
-        original_mean = params.get_data(f"mean_{self.loop_axis_pos_idx}")
-        original_std = params.get_data(f"std_{self.loop_axis_pos_idx}")
-
-        self.loop_axis_pos_idx += 1
-
-        # compute the inverse normalization function
-        return array * original_std + original_mean
-
-    def execute(self, subject: Subject, params: ZScoreNormFilterParams) -> Subject:
-        """Execute the z-score normalization procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            params (ZScoreNormFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with z-score normalized
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        return super().execute(subject, params)
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Execute the inverse z-score normalization procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with denormalized
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        return super().execute_inverse(subject, transform_info)
-
-
-# pylint: disable=too-few-public-methods
-class ZeroOneNormFilterParams(IntensityLoopFilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.intensity.ZeroOneNormFilter` class.
-
-    Args:
-        loop_axis (Optional[int]): The axis along which the intensity normalization is performed. If None, the
-         intensity normalization is performed on the whole image extent at once. If a value is given, the intensity
-         normalization is performed by looping over the corresponding image dimension (default: None).
-        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be rescaled. If
-         ``None`` is provided all images of the provided subject are rescaled (default: None).
-    """
-
-    def __init__(
-        self, loop_axis: Optional[int] = None, modalities: Optional[Tuple[Union[Modality, str], ...]] = None
-    ) -> None:
-        super().__init__(loop_axis, modalities)
-
-
-class ZeroOneNormFilter(IntensityLoopFilter):
-    """A normalization filter class performing an invertible zero-one (1-0) normalization on all
-    :class:`~pyradise.data.image.IntensityImage` instances of the provided :class:`~pyradise.data.subject.Subject`
-    instance.
-
-    For the normalization the following formula is applied to the image extent or its subsets:
-
-    .. math::
-        I_{norm} = \\frac{I_{orig} - \\min(I_{orig})}{\\max(I_{orig}) - \\min(I_{orig})}
-
-    For the inverse normalization the following formula is applied to the image extent or its subsets:
-
-    .. math::
-        I_{orig} = I_{norm} \\cdot (\\max(I_{orig}) - \\min(I_{orig})) + \\min(I_{orig})
-
-    During the normalization procedure, the min and max intensity values of the image or its subsets are tracked to be
-    available for inverse normalization.
-
-    Warning:
-        The inverse normalization procedure may not yield the expected results if successive
-        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
-        Thus, it's recommended to use the invertibility feature with appropriate caution.
-
-    Note:
-        Due to the limited precision of floating point numbers, the inverse normalization may not be exact.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Check if the filter is invertible.
-
-        Returns:
-            bool: True because the zero-one normalization procedure is invertible.
-        """
-        return True
-
-    def _modify_array(self, array: np.ndarray, params: Any) -> np.ndarray:
-        """Apply the zero-one normalization function to the provided data array.
-
-        Args:
-            array (np.ndarray): The array to be normalized.
-            params (Any): The parameters used for the normalization.
-
-        Returns:
-            np.ndarray: The zero-one normalized array.
-        """
-        # get the min and max of the array
-        min_val = np.min(array)
-        max_val = np.max(array)
-
-        # track the changes
-        self.tracking_data[f"min_{self.loop_axis_pos_idx}"] = min_val
-        self.tracking_data[f"max_{self.loop_axis_pos_idx}"] = max_val
-
-        self.loop_axis_pos_idx += 1
-
-        # compute the normalization function
-        return (array - min_val) / (max_val - min_val)
-
-    def _modify_array_inverse(self, array: np.ndarray, params: TransformInfo) -> np.ndarray:
-        """Apply the de-normalization function to the provided data array.
-
-        Args:
-            array (np.ndarray): The array to be denormalized.
-            params (Any): The parameters used for the de-normalization.
-
-        Returns:
-            np.ndarray: The min-max normalized array.
-        """
-        # get the tracked data
-        original_min = params.get_data(f"min_{self.loop_axis_pos_idx}")
-        original_max = params.get_data(f"max_{self.loop_axis_pos_idx}")
-
-        self.loop_axis_pos_idx += 1
-
-        # compute the inverse normalization function
-        return array * (original_max - original_min) + original_min
-
-    def execute(self, subject: Subject, params: ZeroOneNormFilterParams) -> Subject:
-        """Execute the zero-one normalization procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            params (ZeroOneNormFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with zero-one normalized
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        return super().execute(subject, params)
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Execute the inverse zero-one normalization procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with denormalized
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        return super().execute_inverse(subject, transform_info)
-
-
-# pylint: disable=too-few-public-methods
-class RescaleIntensityFilterParams(IntensityFilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.intensity.RescaleIntensityFilter` class.
-
-    Args:
-        min_out (Optional[float]): The minimum value of the rescaled image. If ``None`` is provided the filter takes
-         the minimum intensity value of the image.
-        max_out (Optional[float]): The maximum value of the rescaled image. If ``None`` is provided the filter takes
-         the maximum intensity value of the image.
-        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be rescaled. If
-         ``None`` is provided all images of the provided subject are rescaled (default: None).
-    """
-
-    def __init__(
-        self,
-        min_out: Optional[float],
-        max_out: Optional[float],
-        modalities: Optional[Tuple[Union[Modality, str], ...]] = None,
-    ) -> None:
-        super().__init__(modalities)
-
-        # check the provided min and max values
-        if min_out == max_out:
-            raise ValueError(
-                "The specified min and max output values are equal. The resulting image would have "
-                "constant intensity."
-            )
-
-        if min_out > max_out:
-            min_out, max_out = max_out, min_out
-
-        self.min_out: Optional[float] = min_out
-        self.max_out: Optional[float] = max_out
-
-
-class RescaleIntensityFilter(IntensityFilter):
-    """A filter class performing an invertible intensity rescaling on all selected
-    :class:`~pyradise.data.image.IntensityImage` instances of the provided :class:`~pyradise.data.subject.Subject`
-    instance.
-
-    For the rescaling the following formula is applied to the image extent or its subsets:
-
-    .. math::
-        I_{resc} = \\frac{I_{orig} - \\min(I_{orig})}{\\max(I_{orig}) - \\min(I_{orig})} \\cdot (max_{out} - min_{out})
-        + min_{out}
-
-    For the inverse rescaling the following formula is applied to the image extent or its subsets:
-
-    .. math::
-        I_{orig} = \\frac{I_{resc} - \\min(I_{resc})}{\\max(I_{resc}) - \\min(I_{resc})} \\cdot (\\max(I_{orig}) -
-        \\min(I_{orig})) + \\min(I_{orig})
-
-    During the rescaling procedure, the min and max intensity of the original image or its subsets are tracked to be
-    available for inverse rescaling.
-
-    Warning:
-        The inverse rescaling procedure may not yield the expected results if successive
-        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
-        Thus, it's recommended to use the invertibility feature with appropriate caution.
-
-    Note:
-        Due to the limited precision of floating point numbers, the inverse normalization may not be exact.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Check if the filter is invertible.
-
-        Returns:
-            bool: True because the rescaling procedure is invertible.
-        """
-        return True
-
-    def _process_image(self, image: IntensityImage, params: RescaleIntensityFilterParams) -> IntensityImage:
-        """Apply the rescaling function to the provided image.
-
-        Args:
-            image (IntensityImage): The image to be rescaled.
-            params (RescaleIntensityFilterParams): The filter parameters.
-
-        Returns:
-            IntensityImage: The processed image with rescaled intensity values.
-        """
-        # get the image data as numpy array
-        image_sitk = image.get_image_data()
-        image_np = image.get_image_data_as_np(False).astype(float)
-
-        # get the min and max values
-        min_i_o = np.min(image_np)
-        max_i_o = np.max(image_np)
-        range_i_o = max_i_o - min_i_o
-
-        # track the min and max intensity
-        self.tracking_data["min"] = min_i_o
-        self.tracking_data["max"] = max_i_o
-
-        # get the range of the output values
-        param_range = params.max_out - params.min_out
-
-        # check if the range of the input array is larger than zero
-        if range_i_o < 1e-10:
-            warn(
-                "The range of the input image or its subset is smaller than 1e-10. The rescaled image or subset"
-                "will contain the specified minimum intensity value including the provided noise (input - min(input) "
-                "+ min_out)."
-            )
-            new_image_np = image_np - min_i_o + params.min_out
-
-        # rescale the intensity values
-        else:
-            new_image_np = (image_np - min_i_o) / range_i_o * param_range + params.min_out
-
-        # add the new SimpleITK image to the PyRaDiSe image
-        new_image_sitk = sitk.GetImageFromArray(new_image_np)
-        new_image_sitk.CopyInformation(image_sitk)
-        image.set_image_data(new_image_sitk)
-
-        # track the necessary data for invertibility
-        self._register_tracked_data(image, image_sitk, new_image_sitk, params)
-
-        return image
-
-    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
-        """Apply the inverse scaling function to the provided data array.
-
-        Args:
-            image (IntensityImage): The image to be inversely rescaled.
-            transform_info (TransformInfo): The transform information.
-
-        Returns:
-            IntensityImage: The inversely processed :class:`~pyradise.data.image.IntensityImage` instance.
-        """
-        # get the data as numpy array
-        image_sitk = image.get_image_data()
-        image_np = image.get_image_data_as_np(False).astype(float)
-
-        # get the tracked data
-        min_i_o = transform_info.get_data(f"min")
-        max_i_o = transform_info.get_data(f"max")
-        range_i_o = max_i_o - min_i_o
-
-        # compute the min and max values of the provided array
-        min_i_r = np.min(image_np)
-        max_i_r = np.max(image_np)
-        range_i_r = max_i_r - min_i_r
-
-        # check if the range of the input array is larger than zero
-        if range_i_r < 1e-10:
-            warn(
-                "The range of the input image or its subset is smaller than 1e-10. The rescaled image or subset"
-                "will contain the originally provided values (rescaled_input - min(rescaled_input) + min_original)."
-            )
-            new_image_np = image_np - min_i_r + min_i_o
-
-        # inversely rescale the intensity values
-        else:
-            new_image_np = (image_np - min_i_r) / range_i_r * range_i_o + min_i_o
-
-        # add the new SimpleITK image to the PyRaDiSe image
-        new_image_sitk = sitk.GetImageFromArray(new_image_np)
-        new_image_sitk.CopyInformation(image_sitk)
-        image.set_image_data(new_image_sitk)
-
-        return image
-
-    def execute(self, subject: Subject, params: RescaleIntensityFilterParams) -> Subject:
-        """Execute the rescaling procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be rescaled.
-            params (RescaleIntensityFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with rescaled
-            :class:`~pyradise.data.image.IntensityImage` entries.
-        """
-        return super().execute(subject, params)
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Execute the inverse rescaling procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be inversely rescaled.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with inversely rescaled
-            :class:`~pyradise.data.image.IntensityImage` entries.
-        """
-        return super().execute_inverse(subject, transform_info)
-
-
-class ClipIntensityFilterParams(IntensityFilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.intensity.ClipIntensityFilter` class.
-
-    Args:
-        min_out (float): The minimum intensity value of the processed image.
-        max_out (float): The maximum intensity value of the processed image.
-        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be clipped. If
-         ``None`` is provided all images of the provided subject are clipped (default: None).
-    """
-
-    def __init__(
-        self, min_out: float, max_out: float, modalities: Optional[Tuple[Union[Modality, str], ...]] = None
-    ) -> None:
-        super().__init__(modalities)
-
-        # check the provided min and max values
-        if min_out == max_out:
-            raise ValueError(
-                "The min and max output intensity values must not be equal because the resulting image "
-                "will have constant intensity."
-            )
-
-        if min_out > max_out:
-            min_out, max_out = max_out, min_out
-
-        self.min_value: float = min_out
-        self.max_value: float = max_out
-
-
-class ClipIntensityFilter(IntensityFilter):
-    """A filter class performing a clipping of intensity values on all selected
-    :class:`~pyradise.data.image.IntensityImage` instances of the provided :class:`~pyradise.data.subject.Subject`
-    instance. The clipping procedure sets the intensity values outside the specified range to the specified minimum
-    and maximum values.
-
-    For the clipping procedure the following formula is applied to the image data:
-
-    .. math::
-        I_{out} = \\begin{cases}
-            min_{out} & I_{in} < min_{out} \\\\
-            max_{out} & I_{in} > max_{out} \\\\
-            I_{in} & min_{out} \\leq I_{in} \\leq max_{out}
-        \\end{cases}
-
-    Note:
-        The clipping procedure causes a loss of information which can not be recovered. Thus, the clipping procedure
-        is not invertible.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Check if the filter is invertible.
-
-        Returns:
-            bool: False because the clipping procedure is not invertible.
-        """
-        return False
-
-    def _process_image(self, image: IntensityImage, params: ClipIntensityFilterParams) -> IntensityImage:
-        """Apply the clipping to the provided image.
-
-        Args:
-            image (IntensityImage): The image to be processed.
-            params (ClipIntensityFilterParams): The filter parameters.
-
-        Returns:
-            IntensityImage: The processed image.
-        """
-        # get the image data
-        sitk_image = image.get_image_data()
-
-        # apply the clipping
-        clipped_image_sitk = sitk.Clamp(sitk_image, sitk_image.GetPixelIDValue(), params.min_value, params.max_value)
-
-        # add the clipped SimpleITK image to the image
-        image.set_image_data(clipped_image_sitk)
-
-        # track the necessary information
-        self._register_tracked_data(image, sitk_image, clipped_image_sitk, params)
-
-        return image
-
-    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
-        """Return the provided image without any processing because the clipping procedure is not invertible.
-
-        Args:
-            image (IntensityImage): The image to be returned.
-            transform_info (TransformInfo): The transform information.
-
-        Returns:
-            IntensityImage: The provided image.
-        """
-        return image
-
-    def execute(self, subject: Subject, params: ClipIntensityFilterParams) -> Subject:
-        """Execute the clipping procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            params (ClipIntensityFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with clipped
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        return super().execute(subject, params)
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided subject without any processing because the clipping procedure is not invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-
-        return super().execute_inverse(subject, transform_info)
-
-
-class GaussianFilterParams(IntensityFilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.intensity.GaussianFilter` class.
-
-    Args:
-        variance (float): The variance of the Gaussian kernel.
-        kernel_size (int): The kernel size of the Gaussian kernel.
-        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be filtered. If
-         ``None`` is provided all images of the provided subject are filtered (default: None).
-    """
-
-    def __init__(
-        self, variance: float, kernel_size: int, modalities: Optional[Tuple[Union[Modality, str], ...]] = None
-    ) -> None:
-        super().__init__(modalities)
-
-        # check the statistical values
-        if variance <= 0:
-            raise ValueError("The variance must be greater than zero.")
-
-        if kernel_size <= 0:
-            raise ValueError("The kernel size must be greater than zero.")
-
-        self.variance = variance
-        self.kernel_size = kernel_size
-
-
-class GaussianFilter(IntensityFilter):
-    """A filter class performing a Gaussian smoothing on all :class:`~pyradise.data.image.IntensityImage` instances of
-    the provided :class:`~pyradise.data.subject.Subject` instance.
-
-    Reference:
-        The implementation is based on the SimpleITK implementation of the `SimpleITK DiscreteGaussianImageFilter
-        <https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1DiscreteGaussianImageFilter.html>`_.
-
-    Note:
-        The Gaussian smoothing procedure is not invertible.
-    """
-
-    def is_invertible(self) -> bool:
-        """Check if the filter is invertible.
-
-        Returns:
-            bool: False because the Gaussian filter is not invertible.
-        """
-        return False
-
-    def _process_image(self, image: IntensityImage, params: GaussianFilterParams) -> IntensityImage:
-        """Apply the Gaussian filter to the provided image.
-
-        Args:
-            image (IntensityImage): The image to be filtered.
-            params (GaussianFilterParams): The filter parameters.
-
-        Returns:
-            IntensityImage: The Gaussian filtered image.
-        """
-        # get the image data as sitk image
-        image_sitk = image.get_image_data()
-
-        # cast the image if necessary
-        if "integer" in image_sitk.GetPixelIDTypeAsString():
-            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
-
-        # apply the gaussian filter
-        gaussian_filter = sitk.DiscreteGaussianImageFilter()
-        gaussian_filter.SetVariance(params.variance)
-        gaussian_filter.SetMaximumKernelWidth(params.kernel_size)
-        gaussian_filter.SetUseImageSpacing(True)
-        new_image_sitk = gaussian_filter.Execute(image_sitk)
-
-        # add the new SimpleITK image to the PyRaDiSe image
-        image.set_image_data(new_image_sitk)
-
-        # track the necessary data
-        self._register_tracked_data(image, image_sitk, new_image_sitk, params)
-
-        return image
-
-    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
-        """Return the provided image because the Gaussian filter is not invertible.
-
-        Args:
-            image (IntensityImage): The image to be returned.
-            transform_info (TransformInfo): The transform information.
-
-        Returns:
-            IntensityImage: The provided image.
-        """
-        return image
-
-    def execute(self, subject: Subject, params: GaussianFilterParams) -> Subject:
-        """Execute the Gaussian filter.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be filtered.
-            params (GaussianFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with Gaussian filtered
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        for image in subject.get_images():
-            if isinstance(image, IntensityImage):
-                self._process_image(image, params)
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided subject without any processing because the Gaussian filtering procedure is not
-        invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-        return super().execute_inverse(subject, transform_info)
-
-
-class MedianFilterParams(IntensityFilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.intensity.MedianFilter` class.
-
-    Args:
-        radius (int): The radius of the median filter.
-        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be filtered. If
-         ``None`` is provided all images of the provided subject are filtered (default: None).
-    """
-
-    def __init__(self, radius: int, modalities: Optional[Tuple[Union[Modality, str], ...]] = None) -> None:
-        super().__init__(modalities)
-
-        self.radius = radius
-
-
-class MedianFilter(IntensityFilter):
-    """A filter class performing a median filtering on all :class:`~pyradise.data.image.IntensityImage` instances of
-    the provided :class:`~pyradise.data.subject.Subject` instance.
-
-    Reference:
-        The implementation is based on the SimpleITK implementation of the `SimpleITK MedianImageFilter
-        <https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1MedianImageFilter.html>`_.
-
-    Note:
-        The median filter is not invertible.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Check if the filter is invertible.
-
-        Returns:
-            bool: False because the median filter is not invertible.
-        """
-        return False
-
-    def _process_image(self, image: IntensityImage, params: MedianFilterParams) -> IntensityImage:
-        """Apply the median filter to the provided image.
-
-        Args:
-            image (IntensityImage): The image to be filtered.
-            params (MedianFilterParams): The filter parameters.
-
-        Returns:
-            IntensityImage: The median filtered image.
-        """
-        # get the image data as sitk image
-        image_sitk = image.get_image_data()
-
-        # cast the image if necessary
-        if "integer" in image_sitk.GetPixelIDTypeAsString():
-            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
-
-        # apply the median filter
-        median_filter = sitk.MedianImageFilter()
-        median_filter.SetRadius(params.radius)
-        new_image_sitk = median_filter.Execute(image.get_image_data())
-
-        # add the new SimpleITK image to the PyRaDiSe image
-        image.set_image_data(new_image_sitk)
-
-        # track the necessary data
-        self._register_tracked_data(image, image_sitk, new_image_sitk, params)
-
-        return image
-
-    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
-        """Return the provided image because the median filter is not invertible.
-
-        Args:
-            image (IntensityImage): The image to be returned.
-            transform_info (TransformInfo): The transform information.
-
-        Returns:
-            IntensityImage: The provided image.
-        """
-        return image
-
-    def execute(self, subject: Subject, params: MedianFilterParams) -> Subject:
-        """Execute the median filter.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be filtered.
-            params (MedianFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with filtered
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        return super().execute(subject, params)
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided subject without any processing because the median filtering procedure is not
-        invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-        return super().execute_inverse(subject, transform_info)
-
-
-class LaplacianFilterParams(IntensityFilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.intensity.LaplacianFilter` class.
-
-    Args:
-        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be filtered. If
-         ``None`` is provided all images of the provided subject are filtered (default: None).
-    """
-
-    def __init__(self, modalities: Optional[Tuple[Union[Modality, str], ...]] = None) -> None:
-        super().__init__(modalities)
-
-
-class LaplacianFilter(IntensityFilter):
-    """A filter class performing a Laplacian sharpening on all :class:`~pyradise.data.image.IntensityImage` instances of
-    the provided :class:`~pyradise.data.subject.Subject` instance.
-
-    Reference:
-        The implementation is based on the SimpleITK implementation of the `SimpleITK LaplacianSharpeningImageFilter
-        <https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1LaplacianSharpeningImageFilter.html>`_.
-
-    Note:
-        The Laplacian filter is not invertible.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Check if the filter is invertible.
-
-        Returns:
-            bool: False because the Laplacian filter is not invertible.
-        """
-        return False
-
-    def _process_image(self, image: IntensityImage, params: LaplacianFilterParams) -> IntensityImage:
-        """Apply the Laplacian sharpening filter to the provided image.
-
-        Args:
-            image (IntensityImage): The image to be filtered.
-            params (LaplacianFilterParams): The filter parameters.
-
-        Returns:
-            IntensityImage: The Laplacian filtered image.
-        """
-        # get the image data as sitk image
-        image_sitk = image.get_image_data()
-
-        # cast the image if necessary
-        if "integer" in image_sitk.GetPixelIDTypeAsString():
-            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
-
-        # apply the laplace filter
-        laplacian_filter = sitk.LaplacianSharpeningImageFilter()
-        laplacian_filter.SetUseImageSpacing(True)
-        new_image_sitk = laplacian_filter.Execute(image_sitk)
-
-        # add the new SimpleITK image to the PyRaDiSe image
-        image.set_image_data(new_image_sitk)
-
-        # track the necessary data
-        self._register_tracked_data(image, image_sitk, new_image_sitk, params)
-
-        return image
-
-    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
-        """Return the provided image because the Laplacian filter is not invertible.
-
-        Args:
-            image (IntensityImage): The image to be returned.
-            transform_info (TransformInfo): The transform information.
-
-        Returns:
-            IntensityImage: The provided image.
-        """
-        return image
-
-    def execute(self, subject: Subject, params: Optional[LaplacianFilterParams] = None) -> Subject:
-        """Execute the Laplacian sharpening filter.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be filtered.
-            params (Optional[LaplacianFilterParams]): The unused filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with Laplace filtered
-            :class:`~pyradise.data.image.IntensityImage` instances.
-
-        Note:
-            The Laplacian filter does not need any parameters.
-        """
-        return super().execute(subject, params)
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided subject without any processing because the Laplace filtering procedure is not
-        invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-        return super().execute_inverse(subject, transform_info)
+from abc import abstractmethod
+from typing import Any, Optional, Tuple, Union
+from warnings import warn
+
+import numpy as np
+import SimpleITK as sitk
+
+from pyradise.data import (IntensityImage, Modality, SegmentationImage,
+                           Subject, TransformInfo, seq_to_modalities)
+
+from .base import Filter, FilterParams, LoopEntryFilter, LoopEntryFilterParams
+
+__all__ = [
+    "IntensityFilterParams",
+    "IntensityFilter",
+    "IntensityLoopFilterParams",
+    "IntensityLoopFilter",
+    "ZScoreNormFilterParams",
+    "ZScoreNormFilter",
+    "ZeroOneNormFilterParams",
+    "ZeroOneNormFilter",
+    "RescaleIntensityFilterParams",
+    "RescaleIntensityFilter",
+    "ClipIntensityFilterParams",
+    "ClipIntensityFilter",
+    "GaussianFilterParams",
+    "GaussianFilter",
+    "MedianFilterParams",
+    "MedianFilter",
+    "LaplacianFilterParams",
+    "LaplacianFilter",
+]
+
+
+class IntensityFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.intensity.IntensityFilter` base class. In addition to
+    the :class:`~pyradise.process.base.FilterParams` class, this class also provides a ``modalities`` parameter to
+    specify the images to be processed by the filters.
+
+    Args:
+        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities associated with the corresponding
+         :class:`~pyradise.data.image.IntensityImage` instances that should be processed. If ``None`` is provided,
+         all :class:`~pyradise.data.image.IntensityImage` instances will be processed (default: None).
+    """
+
+    def __init__(self, modalities: Optional[Tuple[Union[Modality, str], ...]] = None) -> None:
+        if modalities is not None:
+            self.modalities = seq_to_modalities(modalities)
+        else:
+            self.modalities: Optional[Tuple[Modality, ...]] = None
+
+
+class IntensityFilter(Filter):
+    """An abstract filter base class for intensity modifying filters which process the whole image content. In contrast
+    to the :class:`~pyradise.process.base.Filter` base class, this class provides two additional abstract methods (
+    i.e. :meth:`~pyradise.process.intensity.IntensityFilter._process_image` and
+    :meth:`~pyradise.process.intensity.IntensityFilter._process_image_inverse`) for processing the image content as
+    whole. Thus, this base class is intended to be used for intensity modifying filters which process the whole image
+    content at once.
+
+    Note:
+        The selection of the :class:`~pyradise.data.image.IntensityImage` instances to be processed is specified by the
+        :class:`~pyradise.process.intensity.IntensityFilterParams` instance. If the ``modalities`` parameter is set to
+        ``None``, all :class:`~pyradise.data.image.IntensityImage` instances will be processed. Otherwise, only the
+        :class:`~pyradise.data.image.IntensityImage` instances with the specified modalities will be processed. If the
+        user wants to implement its own intensity modifying filter, the user do not need to implement the
+        selection of the images to be processed. The selection mechanism is already provided in the implemented
+        :meth:`~pyradise.process.intensity.IntensityFilter.execute` and
+        :meth:`~pyradise.process.intensity.IntensityFilter.execute_inverse` methods.
+
+    Example:
+
+        An example implementation of an intensity clippling filter:
+
+        >>> class ClipFilterParams(IntensityFilterParams):
+        >>>     def __init__(self,
+        >>>                  min_out: float,
+        >>>                  max_out: float,
+        >>>                  modalities: Optional[Tuple[Union[Modality, str], ...]] = None
+        >>>                  ) -> None:
+        >>>         super().__init__(modalities)
+        >>>
+        >>>         if min_out == max_out:
+        >>>             raise ValueError('The min and max output intensity '
+        >>>                              'values must not be equal because '
+        >>>                              'the resulting image '
+        >>>                              'will have constant intensity.')
+        >>>
+        >>>         if min_out > max_out:
+        >>>             min_out, max_out = max_out, min_out
+        >>>
+        >>>         self.min_value: float = min_out
+        >>>         self.max_value: float = max_out
+        >>>
+        >>>
+        >>> class ClipFilter(IntensityFilter):
+        >>>
+        >>>     @staticmethod
+        >>>     def is_invertible() -> bool:
+        >>>         # return False because the clipping is not invertible
+        >>>         return False
+        >>>
+        >>>     def _process_image(self,
+        >>>                        image: IntensityImage,
+        >>>                        params: ClipFilterParams
+        >>>                        ) -> IntensityImage:
+        >>>         # get the image data
+        >>>         sitk_image = image.get_image_data()
+        >>>
+        >>>         # apply the clipping
+        >>>         clipped_image_sitk = sitk.Clamp(sitk_image,
+        >>>                                         sitk_image.GetPixelIDValue(),
+        >>>                                         params.min_value,
+        >>>                                         params.max_value)
+        >>>
+        >>>         # add the clipped SimpleITK image to the image
+        >>>         image.set_image_data(clipped_image_sitk)
+        >>>
+        >>>         # track the necessary information
+        >>>         self._register_tracked_data(image, sitk_image,
+        >>>                                     clipped_image_sitk, params)
+        >>>
+        >>>         return image
+        >>>
+        >>>     def _process_image_inverse(self,
+        >>>                                image: IntensityImage,
+        >>>                                transform_info: TransformInfo
+        >>>                                ) -> IntensityImage:
+        >>>         # return the original image because the clipping
+        >>>         # is not invertible
+        >>>         return image
+        >>>
+        >>>     def execute(self,
+        >>>                 subject: Subject,
+        >>>                 params: ClipFilterParams
+        >>>                 ) -> Subject:
+        >>>         # implement exclusively due to type adaptation for params
+        >>>         return super().execute(subject, params)
+
+    """
+
+    @abstractmethod
+    def _process_image(self, image: IntensityImage, params: IntensityFilterParams) -> IntensityImage:
+        """Process the content of an image.
+
+        Args:
+            image (IntensityImage): The :class:`~pyradise.data.image.IntensityImage` instance to be processed.
+            params (IntensityFilterParams): The filter parameters.
+
+        Returns:
+            IntensityImage: The processed :class:`~pyradise.data.image.IntensityImage` instance.
+        """
+        raise NotImplementedError()
+
+    @abstractmethod
+    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
+        """Process the content of an image inversely.
+
+        Args:
+            image (IntensityImage): The :class:`~pyradise.data.image.IntensityImage` instance to be processed.
+            transform_info (TransformInfo): The transform information.
+
+        Returns:
+            IntensityImage: The inversely processed :class:`~pyradise.data.image.IntensityImage` instance.
+        """
+        raise NotImplementedError()
+
+    def execute(self, subject: Subject, params: IntensityFilterParams) -> Subject:
+        """Execute the intensity modifying procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            params (IntensityFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with processed
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        for image in subject.get_images():
+            if isinstance(image, IntensityImage):
+                # check if the image is specified for processing
+                if params.modalities is not None and image.modality not in params.modalities:
+                    image_sitk = image.get_image_data()
+                    self._register_tracked_data(image, image_sitk, image_sitk, params)
+
+                else:
+                    self._process_image(image, params)
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Execute the inverse intensity modifying procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with processed
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+
+        # potentially warn the user that the operation is not invertible
+        if self.warn_on_non_invertible and not self.is_invertible():
+            warn(
+                "WARNING: "
+                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
+                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
+                "is returned without modification."
+            )
+
+        for image in subject.get_images():
+            if target_image is not None and image != target_image:
+                continue
+
+            if isinstance(image, IntensityImage):
+                if (
+                    transform_info.params.modalities is not None
+                    and image.get_modality() not in transform_info.params.modalities
+                ):
+                    continue
+
+                self._process_image_inverse(image, transform_info)
+
+        return subject
+
+
+class IntensityLoopFilterParams(LoopEntryFilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.intensity.IntensityLoopFilter` base class.
+    In addition to the :class:`~pyradise.process.base.LoopEntryFilterParams` class, this class also provides a
+    ``modalities`` parameter to specify the images to be processed by the filters.
+
+    Args:
+        loop_axis (Optional[int]): The axis along which the data transformation is performed. If ``None``, the
+         transformation is performed on the whole image at once. If a value is given, the transformation is performed
+         by looping over the corresponding image dimension.
+        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities associated with the corresponding
+         :class:`~pyradise.data.image.IntensityImage` instances that should be processed. If ``None`` is provided,
+         all :class:`~pyradise.data.image.IntensityImage` instances will be processed (default: None).
+    """
+
+    def __init__(self, loop_axis: Optional[int], modalities: Optional[Tuple[Union[Modality, str], ...]] = None) -> None:
+        super().__init__(loop_axis)
+
+        if modalities is not None:
+            self.modalities = seq_to_modalities(modalities)
+        else:
+            self.modalities = None
+
+
+class IntensityLoopFilter(LoopEntryFilter):
+    """An abstract base class for intensity modifying filters that can process the provided image content by looping
+    over a specific axis or by using the whole image extent at once. This base class is intended to be used for
+    implementing flexible intensity modifying filters that can iteratively process subsets of the image content such as
+    for example normalization filters which may be applied slice-wise to the image content.
+
+    For the implementation of a new :class:`~pyradise.process.intensity.IntensityLoopFilter` subclass implement the
+    provided :meth:`~pyradise.process.intensity.IntensityLoopFilter._modify_array` and
+    :meth:`~pyradise.process.intensity.IntensityLoopFilter._modify_array_inverse` methods. Both methods are called
+    iteratively for each loop axis position. The :meth:`~pyradise.process.intensity.IntensityLoopFilter._modify_array`
+    method is called for the forward processing and the
+    :meth:`~pyradise.process.intensity.IntensityLoopFilter._modify_array_inverse` method is called for the inverse
+    processing.
+
+    Note:
+        The selection of the :class:`~pyradise.data.image.IntensityImage` instances to be processed is specified by the
+        :class:`~pyradise.process.intensity.IntensityLoopFilterParams` instance. If the ``modalities`` parameter is set
+        to ``None``, all :class:`~pyradise.data.image.IntensityImage` instances will be processed. Otherwise, only the
+        :class:`~pyradise.data.image.IntensityImage` instances with the specified modalities will be processed. If the
+        user wants to implement its own intensity modifying filter, the user do not need to implement the
+        selection of the images to be processed. The selection mechanism is already provided in the implemented
+        :meth:`~pyradise.process.intensity.IntensityLoopFilter.execute` and
+        :meth:`~pyradise.process.intensity.IntensityLoopFilter.execute_inverse` methods.
+    """
+
+    def __init__(self):
+        super().__init__()
+
+        # provides an index for the position along the loop axis
+        self.loop_axis_pos_idx = 0
+
+    @abstractmethod
+    def _modify_array(self, array: np.ndarray, params: IntensityLoopFilterParams) -> np.ndarray:
+        """The intensity modification function which is applied to the provided array. The provided array can be of
+        n-dimensions whereby the dimensionality depend on the provided data and the ``loop_axis`` parameter as
+        specified in the appropriate :class:`~pyradise.process.intensity.IntensityFilterParams` instance.
+
+        Args:
+            array (np.ndarray): The array to be processed.
+            params (IntensityLoopFilterParams): The parameters used for the processing.
+
+        Returns:
+            np.ndarray: The processed array.
+        """
+        raise NotImplementedError()
+
+    @abstractmethod
+    def _modify_array_inverse(self, array: np.ndarray, params: TransformInfo) -> np.ndarray:
+        """The inverse intensity modification function which is applied to the provided array. The provided array can
+        be of n-dimensions whereby the dimensionality depend on the provided data and the ``loop_axis`` parameter as
+        specified in the appropriate :class:`~pyradise.process.intensity.IntensityFilterParams` instance which is
+        contained in the provided :class:`~pyradise.data.taping.TransformInfo` instance.
+
+        Args:
+            array (np.ndarray): The array to be processed.
+            params (TransformInfo): The transform information.
+
+        Returns:
+            np.ndarray: The processed array.
+        """
+        raise NotImplementedError()
+
+    def _process_image(self, image: IntensityImage, params: Union[IntensityLoopFilterParams, Any]) -> IntensityImage:
+        """Execute the intensity modifying procedure on the provided image by looping over the image accordingly.
+
+        Args:
+            image (IntensityImage): The image to be processed.
+            params (Union[IntensityLoopFilterParams, Any]): The filter parameters.
+
+        Returns:
+            IntensityImage: The processed image.
+        """
+
+        # set the loop axis position index to zero because of processing a new image
+        self.loop_axis_pos_idx = 0
+
+        # get the image data for computation
+        image_sitk = image.get_image_data()
+        if "integer" in image_sitk.GetPixelIDTypeAsString():
+            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
+
+        image_np = sitk.GetArrayFromImage(image_sitk)
+
+        # perform the intensity modifying procedure
+        new_image_np = self.loop_entries(image_np, params, self._modify_array, params.loop_axis)
+
+        # construct the new image
+        new_image_sitk = sitk.GetImageFromArray(new_image_np)
+        new_image_sitk.CopyInformation(image_sitk)
+
+        # set the new image data to the image
+        image.set_image_data(new_image_sitk)
+
+        # keep track of the transformation
+        self._register_tracked_data(image, image_sitk, new_image_sitk, params)
+
+        return image
+
+    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
+        """Execute the inverse intensity modifying procedure on the provided image by looping over the image
+        accordingly.
+
+        Args:
+            image (IntensityImage): The image to be processed.
+            transform_info (TransformInfo): The transform information.
+
+        Returns:
+            IntensityImage: The processed image.
+        """
+        # return the image as is if the filter is not invertible
+        if not self.is_invertible():
+            return image
+
+        # set the loop axis position index to zero because of processing a new image
+        self.loop_axis_pos_idx = 0
+
+        # get the image data for inverse processing
+        image_sitk = image.get_image_data()
+        if "integer" in image_sitk.GetPixelIDTypeAsString():
+            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
+        image_np = sitk.GetArrayFromImage(image_sitk)
+
+        # perform the inverse intensity modifying procedure
+        new_image_np = self.loop_entries(
+            image_np, transform_info, self._modify_array_inverse, transform_info.params.loop_axis
+        )
+
+        # construct the new image
+        new_image_sitk = sitk.GetImageFromArray(new_image_np)
+        new_image_sitk.CopyInformation(image_sitk)
+
+        # set the new image data to the image
+        image.set_image_data(new_image_sitk)
+
+        return image
+
+    def execute(self, subject: Subject, params: IntensityLoopFilterParams) -> Subject:
+        """Execute the intensity modifying procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            params (IntensityLoopFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with processed
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        for image in subject.get_images():
+            if isinstance(image, IntensityImage):
+                # check if the image is specified for processing
+                if params.modalities is not None and image.get_modality() not in params.modalities:
+                    image_sitk = image.get_image_data()
+                    self._register_tracked_data(image, image_sitk, image_sitk, params)
+
+                else:
+                    self._process_image(image, params)
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Execute the inverse intensity modifying procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with processed
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        for image in subject.get_images():
+            if target_image is not None and image != target_image:
+                continue
+
+            if isinstance(image, IntensityImage):
+                if (
+                    transform_info.params.modalities is not None
+                    and image.get_modality() not in transform_info.params.modalities
+                ):
+                    continue
+
+                self._process_image_inverse(image, transform_info)
+
+        return subject
+
+
+# pylint: disable=too-few-public-methods
+class ZScoreNormFilterParams(IntensityLoopFilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.intensity.ZScoreNormFilter` class.
+
+    Args:
+        loop_axis (Optional[int]): The axis along which the intensity normalization is performed. If None, the
+         intensity normalization is performed on the whole image extent at once. If a value is given, the intensity
+         normalization is performed by looping over the corresponding image dimension (default: None).
+        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be rescaled. If
+         ``None`` is provided all images of the provided subject are rescaled (default: None).
+    """
+
+    def __init__(
+        self, loop_axis: Optional[int] = None, modalities: Optional[Tuple[Union[Modality, str], ...]] = None
+    ) -> None:
+        super().__init__(loop_axis, modalities)
+
+
+class ZScoreNormFilter(IntensityLoopFilter):
+    """A normalization filter class performing an invertible z-score normalization on all
+    :class:`~pyradise.data.image.IntensityImage` instances of the provided :class:`~pyradise.data.subject.Subject`
+    instance.
+
+    For the normalization the following formula is applied to the image extent or its subsets:
+
+    .. math::
+        I_{norm} = \\frac{I_{orig} - \\mu(I_{orig})}{\\sigma(I_{orig})}
+
+    For the inverse normalization the following formula is applied to the image extent or its subsets:
+
+    .. math::
+        I_{orig} = I_{norm} \\cdot \\sigma(I_{orig}) + \\mu(I_{orig})
+
+    During the normalization procedure, the intensity mean and standard deviation of the original image or its subsets
+    are tracked such that these values are available for the inverse normalization.
+
+    Warning:
+        The inverse normalization procedure may not yield the expected results if successive
+        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
+        Thus, it's recommended to use the invertibility feature with appropriate caution.
+
+    Note:
+        Due to the limited precision of floating point numbers, the inverse normalization may not be exact.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Check if the filter is invertible.
+
+        Returns:
+            bool: True because the z-score normalization procedure is invertible.
+        """
+        return True
+
+    def _modify_array(self, array: np.ndarray, params: Any) -> np.ndarray:
+        """Apply the z-score normalization function to the provided data array.
+
+        Args:
+            array (np.ndarray): The array to be normalized.
+            params (Any): The parameters used for the normalization.
+
+        Returns:
+            np.ndarray: The z-score normalized array.
+        """
+        # get the mean and standard deviation of the array
+        mean = np.mean(array)
+        std = np.std(array)
+
+        # track the changes
+        self.tracking_data[f"mean_{self.loop_axis_pos_idx}"] = mean
+        self.tracking_data[f"std_{self.loop_axis_pos_idx}"] = std
+
+        self.loop_axis_pos_idx += 1
+
+        # compute the normalization function
+        return (array - np.mean(array)) / np.std(array)
+
+    def _modify_array_inverse(self, array: np.ndarray, params: TransformInfo) -> np.ndarray:
+        """Apply the de-normalization function to the provided data array.
+
+        Args:
+            array (np.ndarray): The array to be denormalized.
+            params (TransformInfo): The parameters used for the de-normalization.
+
+        Returns:
+            np.ndarray: The denormalized array.
+
+        """
+        # get the tracked data
+        original_mean = params.get_data(f"mean_{self.loop_axis_pos_idx}")
+        original_std = params.get_data(f"std_{self.loop_axis_pos_idx}")
+
+        self.loop_axis_pos_idx += 1
+
+        # compute the inverse normalization function
+        return array * original_std + original_mean
+
+    def execute(self, subject: Subject, params: ZScoreNormFilterParams) -> Subject:
+        """Execute the z-score normalization procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            params (ZScoreNormFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with z-score normalized
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        return super().execute(subject, params)
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Execute the inverse z-score normalization procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with denormalized
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        return super().execute_inverse(subject, transform_info)
+
+
+# pylint: disable=too-few-public-methods
+class ZeroOneNormFilterParams(IntensityLoopFilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.intensity.ZeroOneNormFilter` class.
+
+    Args:
+        loop_axis (Optional[int]): The axis along which the intensity normalization is performed. If None, the
+         intensity normalization is performed on the whole image extent at once. If a value is given, the intensity
+         normalization is performed by looping over the corresponding image dimension (default: None).
+        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be rescaled. If
+         ``None`` is provided all images of the provided subject are rescaled (default: None).
+    """
+
+    def __init__(
+        self, loop_axis: Optional[int] = None, modalities: Optional[Tuple[Union[Modality, str], ...]] = None
+    ) -> None:
+        super().__init__(loop_axis, modalities)
+
+
+class ZeroOneNormFilter(IntensityLoopFilter):
+    """A normalization filter class performing an invertible zero-one (1-0) normalization on all
+    :class:`~pyradise.data.image.IntensityImage` instances of the provided :class:`~pyradise.data.subject.Subject`
+    instance.
+
+    For the normalization the following formula is applied to the image extent or its subsets:
+
+    .. math::
+        I_{norm} = \\frac{I_{orig} - \\min(I_{orig})}{\\max(I_{orig}) - \\min(I_{orig})}
+
+    For the inverse normalization the following formula is applied to the image extent or its subsets:
+
+    .. math::
+        I_{orig} = I_{norm} \\cdot (\\max(I_{orig}) - \\min(I_{orig})) + \\min(I_{orig})
+
+    During the normalization procedure, the min and max intensity values of the image or its subsets are tracked to be
+    available for inverse normalization.
+
+    Warning:
+        The inverse normalization procedure may not yield the expected results if successive
+        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
+        Thus, it's recommended to use the invertibility feature with appropriate caution.
+
+    Note:
+        Due to the limited precision of floating point numbers, the inverse normalization may not be exact.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Check if the filter is invertible.
+
+        Returns:
+            bool: True because the zero-one normalization procedure is invertible.
+        """
+        return True
+
+    def _modify_array(self, array: np.ndarray, params: Any) -> np.ndarray:
+        """Apply the zero-one normalization function to the provided data array.
+
+        Args:
+            array (np.ndarray): The array to be normalized.
+            params (Any): The parameters used for the normalization.
+
+        Returns:
+            np.ndarray: The zero-one normalized array.
+        """
+        # get the min and max of the array
+        min_val = np.min(array)
+        max_val = np.max(array)
+
+        # track the changes
+        self.tracking_data[f"min_{self.loop_axis_pos_idx}"] = min_val
+        self.tracking_data[f"max_{self.loop_axis_pos_idx}"] = max_val
+
+        self.loop_axis_pos_idx += 1
+
+        # compute the normalization function
+        return (array - min_val) / (max_val - min_val)
+
+    def _modify_array_inverse(self, array: np.ndarray, params: TransformInfo) -> np.ndarray:
+        """Apply the de-normalization function to the provided data array.
+
+        Args:
+            array (np.ndarray): The array to be denormalized.
+            params (Any): The parameters used for the de-normalization.
+
+        Returns:
+            np.ndarray: The min-max normalized array.
+        """
+        # get the tracked data
+        original_min = params.get_data(f"min_{self.loop_axis_pos_idx}")
+        original_max = params.get_data(f"max_{self.loop_axis_pos_idx}")
+
+        self.loop_axis_pos_idx += 1
+
+        # compute the inverse normalization function
+        return array * (original_max - original_min) + original_min
+
+    def execute(self, subject: Subject, params: ZeroOneNormFilterParams) -> Subject:
+        """Execute the zero-one normalization procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            params (ZeroOneNormFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with zero-one normalized
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        return super().execute(subject, params)
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Execute the inverse zero-one normalization procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with denormalized
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        return super().execute_inverse(subject, transform_info)
+
+
+# pylint: disable=too-few-public-methods
+class RescaleIntensityFilterParams(IntensityFilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.intensity.RescaleIntensityFilter` class.
+
+    Args:
+        min_out (Optional[float]): The minimum value of the rescaled image. If ``None`` is provided the filter takes
+         the minimum intensity value of the image.
+        max_out (Optional[float]): The maximum value of the rescaled image. If ``None`` is provided the filter takes
+         the maximum intensity value of the image.
+        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be rescaled. If
+         ``None`` is provided all images of the provided subject are rescaled (default: None).
+    """
+
+    def __init__(
+        self,
+        min_out: Optional[float],
+        max_out: Optional[float],
+        modalities: Optional[Tuple[Union[Modality, str], ...]] = None,
+    ) -> None:
+        super().__init__(modalities)
+
+        # check the provided min and max values
+        if min_out == max_out:
+            raise ValueError(
+                "The specified min and max output values are equal. The resulting image would have "
+                "constant intensity."
+            )
+
+        if min_out > max_out:
+            min_out, max_out = max_out, min_out
+
+        self.min_out: Optional[float] = min_out
+        self.max_out: Optional[float] = max_out
+
+
+class RescaleIntensityFilter(IntensityFilter):
+    """A filter class performing an invertible intensity rescaling on all selected
+    :class:`~pyradise.data.image.IntensityImage` instances of the provided :class:`~pyradise.data.subject.Subject`
+    instance.
+
+    For the rescaling the following formula is applied to the image extent or its subsets:
+
+    .. math::
+        I_{resc} = \\frac{I_{orig} - \\min(I_{orig})}{\\max(I_{orig}) - \\min(I_{orig})} \\cdot (max_{out} - min_{out})
+        + min_{out}
+
+    For the inverse rescaling the following formula is applied to the image extent or its subsets:
+
+    .. math::
+        I_{orig} = \\frac{I_{resc} - \\min(I_{resc})}{\\max(I_{resc}) - \\min(I_{resc})} \\cdot (\\max(I_{orig}) -
+        \\min(I_{orig})) + \\min(I_{orig})
+
+    During the rescaling procedure, the min and max intensity of the original image or its subsets are tracked to be
+    available for inverse rescaling.
+
+    Warning:
+        The inverse rescaling procedure may not yield the expected results if successive
+        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
+        Thus, it's recommended to use the invertibility feature with appropriate caution.
+
+    Note:
+        Due to the limited precision of floating point numbers, the inverse normalization may not be exact.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Check if the filter is invertible.
+
+        Returns:
+            bool: True because the rescaling procedure is invertible.
+        """
+        return True
+
+    def _process_image(self, image: IntensityImage, params: RescaleIntensityFilterParams) -> IntensityImage:
+        """Apply the rescaling function to the provided image.
+
+        Args:
+            image (IntensityImage): The image to be rescaled.
+            params (RescaleIntensityFilterParams): The filter parameters.
+
+        Returns:
+            IntensityImage: The processed image with rescaled intensity values.
+        """
+        # get the image data as numpy array
+        image_sitk = image.get_image_data()
+        image_np = image.get_image_data_as_np(False).astype(float)
+
+        # get the min and max values
+        min_i_o = np.min(image_np)
+        max_i_o = np.max(image_np)
+        range_i_o = max_i_o - min_i_o
+
+        # track the min and max intensity
+        self.tracking_data["min"] = min_i_o
+        self.tracking_data["max"] = max_i_o
+
+        # get the range of the output values
+        param_range = params.max_out - params.min_out
+
+        # check if the range of the input array is larger than zero
+        if range_i_o < 1e-10:
+            warn(
+                "The range of the input image or its subset is smaller than 1e-10. The rescaled image or subset"
+                "will contain the specified minimum intensity value including the provided noise (input - min(input) "
+                "+ min_out)."
+            )
+            new_image_np = image_np - min_i_o + params.min_out
+
+        # rescale the intensity values
+        else:
+            new_image_np = (image_np - min_i_o) / range_i_o * param_range + params.min_out
+
+        # add the new SimpleITK image to the PyRaDiSe image
+        new_image_sitk = sitk.GetImageFromArray(new_image_np)
+        new_image_sitk.CopyInformation(image_sitk)
+        image.set_image_data(new_image_sitk)
+
+        # track the necessary data for invertibility
+        self._register_tracked_data(image, image_sitk, new_image_sitk, params)
+
+        return image
+
+    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
+        """Apply the inverse scaling function to the provided data array.
+
+        Args:
+            image (IntensityImage): The image to be inversely rescaled.
+            transform_info (TransformInfo): The transform information.
+
+        Returns:
+            IntensityImage: The inversely processed :class:`~pyradise.data.image.IntensityImage` instance.
+        """
+        # get the data as numpy array
+        image_sitk = image.get_image_data()
+        image_np = image.get_image_data_as_np(False).astype(float)
+
+        # get the tracked data
+        min_i_o = transform_info.get_data(f"min")
+        max_i_o = transform_info.get_data(f"max")
+        range_i_o = max_i_o - min_i_o
+
+        # compute the min and max values of the provided array
+        min_i_r = np.min(image_np)
+        max_i_r = np.max(image_np)
+        range_i_r = max_i_r - min_i_r
+
+        # check if the range of the input array is larger than zero
+        if range_i_r < 1e-10:
+            warn(
+                "The range of the input image or its subset is smaller than 1e-10. The rescaled image or subset"
+                "will contain the originally provided values (rescaled_input - min(rescaled_input) + min_original)."
+            )
+            new_image_np = image_np - min_i_r + min_i_o
+
+        # inversely rescale the intensity values
+        else:
+            new_image_np = (image_np - min_i_r) / range_i_r * range_i_o + min_i_o
+
+        # add the new SimpleITK image to the PyRaDiSe image
+        new_image_sitk = sitk.GetImageFromArray(new_image_np)
+        new_image_sitk.CopyInformation(image_sitk)
+        image.set_image_data(new_image_sitk)
+
+        return image
+
+    def execute(self, subject: Subject, params: RescaleIntensityFilterParams) -> Subject:
+        """Execute the rescaling procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be rescaled.
+            params (RescaleIntensityFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with rescaled
+            :class:`~pyradise.data.image.IntensityImage` entries.
+        """
+        return super().execute(subject, params)
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Execute the inverse rescaling procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be inversely rescaled.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with inversely rescaled
+            :class:`~pyradise.data.image.IntensityImage` entries.
+        """
+        return super().execute_inverse(subject, transform_info)
+
+
+class ClipIntensityFilterParams(IntensityFilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.intensity.ClipIntensityFilter` class.
+
+    Args:
+        min_out (float): The minimum intensity value of the processed image.
+        max_out (float): The maximum intensity value of the processed image.
+        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be clipped. If
+         ``None`` is provided all images of the provided subject are clipped (default: None).
+    """
+
+    def __init__(
+        self, min_out: float, max_out: float, modalities: Optional[Tuple[Union[Modality, str], ...]] = None
+    ) -> None:
+        super().__init__(modalities)
+
+        # check the provided min and max values
+        if min_out == max_out:
+            raise ValueError(
+                "The min and max output intensity values must not be equal because the resulting image "
+                "will have constant intensity."
+            )
+
+        if min_out > max_out:
+            min_out, max_out = max_out, min_out
+
+        self.min_value: float = min_out
+        self.max_value: float = max_out
+
+
+class ClipIntensityFilter(IntensityFilter):
+    """A filter class performing a clipping of intensity values on all selected
+    :class:`~pyradise.data.image.IntensityImage` instances of the provided :class:`~pyradise.data.subject.Subject`
+    instance. The clipping procedure sets the intensity values outside the specified range to the specified minimum
+    and maximum values.
+
+    For the clipping procedure the following formula is applied to the image data:
+
+    .. math::
+        I_{out} = \\begin{cases}
+            min_{out} & I_{in} < min_{out} \\\\
+            max_{out} & I_{in} > max_{out} \\\\
+            I_{in} & min_{out} \\leq I_{in} \\leq max_{out}
+        \\end{cases}
+
+    Note:
+        The clipping procedure causes a loss of information which can not be recovered. Thus, the clipping procedure
+        is not invertible.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Check if the filter is invertible.
+
+        Returns:
+            bool: False because the clipping procedure is not invertible.
+        """
+        return False
+
+    def _process_image(self, image: IntensityImage, params: ClipIntensityFilterParams) -> IntensityImage:
+        """Apply the clipping to the provided image.
+
+        Args:
+            image (IntensityImage): The image to be processed.
+            params (ClipIntensityFilterParams): The filter parameters.
+
+        Returns:
+            IntensityImage: The processed image.
+        """
+        # get the image data
+        sitk_image = image.get_image_data()
+
+        # apply the clipping
+        clipped_image_sitk = sitk.Clamp(sitk_image, sitk_image.GetPixelIDValue(), params.min_value, params.max_value)
+
+        # add the clipped SimpleITK image to the image
+        image.set_image_data(clipped_image_sitk)
+
+        # track the necessary information
+        self._register_tracked_data(image, sitk_image, clipped_image_sitk, params)
+
+        return image
+
+    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
+        """Return the provided image without any processing because the clipping procedure is not invertible.
+
+        Args:
+            image (IntensityImage): The image to be returned.
+            transform_info (TransformInfo): The transform information.
+
+        Returns:
+            IntensityImage: The provided image.
+        """
+        return image
+
+    def execute(self, subject: Subject, params: ClipIntensityFilterParams) -> Subject:
+        """Execute the clipping procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            params (ClipIntensityFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with clipped
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        return super().execute(subject, params)
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided subject without any processing because the clipping procedure is not invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+
+        return super().execute_inverse(subject, transform_info)
+
+
+class GaussianFilterParams(IntensityFilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.intensity.GaussianFilter` class.
+
+    Args:
+        variance (float): The variance of the Gaussian kernel.
+        kernel_size (int): The kernel size of the Gaussian kernel.
+        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be filtered. If
+         ``None`` is provided all images of the provided subject are filtered (default: None).
+    """
+
+    def __init__(
+        self, variance: float, kernel_size: int, modalities: Optional[Tuple[Union[Modality, str], ...]] = None
+    ) -> None:
+        super().__init__(modalities)
+
+        # check the statistical values
+        if variance <= 0:
+            raise ValueError("The variance must be greater than zero.")
+
+        if kernel_size <= 0:
+            raise ValueError("The kernel size must be greater than zero.")
+
+        self.variance = variance
+        self.kernel_size = kernel_size
+
+
+class GaussianFilter(IntensityFilter):
+    """A filter class performing a Gaussian smoothing on all :class:`~pyradise.data.image.IntensityImage` instances of
+    the provided :class:`~pyradise.data.subject.Subject` instance.
+
+    Reference:
+        The implementation is based on the SimpleITK implementation of the `SimpleITK DiscreteGaussianImageFilter
+        <https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1DiscreteGaussianImageFilter.html>`_.
+
+    Note:
+        The Gaussian smoothing procedure is not invertible.
+    """
+
+    def is_invertible(self) -> bool:
+        """Check if the filter is invertible.
+
+        Returns:
+            bool: False because the Gaussian filter is not invertible.
+        """
+        return False
+
+    def _process_image(self, image: IntensityImage, params: GaussianFilterParams) -> IntensityImage:
+        """Apply the Gaussian filter to the provided image.
+
+        Args:
+            image (IntensityImage): The image to be filtered.
+            params (GaussianFilterParams): The filter parameters.
+
+        Returns:
+            IntensityImage: The Gaussian filtered image.
+        """
+        # get the image data as sitk image
+        image_sitk = image.get_image_data()
+
+        # cast the image if necessary
+        if "integer" in image_sitk.GetPixelIDTypeAsString():
+            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
+
+        # apply the gaussian filter
+        gaussian_filter = sitk.DiscreteGaussianImageFilter()
+        gaussian_filter.SetVariance(params.variance)
+        gaussian_filter.SetMaximumKernelWidth(params.kernel_size)
+        gaussian_filter.SetUseImageSpacing(True)
+        new_image_sitk = gaussian_filter.Execute(image_sitk)
+
+        # add the new SimpleITK image to the PyRaDiSe image
+        image.set_image_data(new_image_sitk)
+
+        # track the necessary data
+        self._register_tracked_data(image, image_sitk, new_image_sitk, params)
+
+        return image
+
+    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
+        """Return the provided image because the Gaussian filter is not invertible.
+
+        Args:
+            image (IntensityImage): The image to be returned.
+            transform_info (TransformInfo): The transform information.
+
+        Returns:
+            IntensityImage: The provided image.
+        """
+        return image
+
+    def execute(self, subject: Subject, params: GaussianFilterParams) -> Subject:
+        """Execute the Gaussian filter.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be filtered.
+            params (GaussianFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with Gaussian filtered
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        for image in subject.get_images():
+            if isinstance(image, IntensityImage):
+                self._process_image(image, params)
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided subject without any processing because the Gaussian filtering procedure is not
+        invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+        return super().execute_inverse(subject, transform_info)
+
+
+class MedianFilterParams(IntensityFilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.intensity.MedianFilter` class.
+
+    Args:
+        radius (int): The radius of the median filter.
+        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be filtered. If
+         ``None`` is provided all images of the provided subject are filtered (default: None).
+    """
+
+    def __init__(self, radius: int, modalities: Optional[Tuple[Union[Modality, str], ...]] = None) -> None:
+        super().__init__(modalities)
+
+        self.radius = radius
+
+
+class MedianFilter(IntensityFilter):
+    """A filter class performing a median filtering on all :class:`~pyradise.data.image.IntensityImage` instances of
+    the provided :class:`~pyradise.data.subject.Subject` instance.
+
+    Reference:
+        The implementation is based on the SimpleITK implementation of the `SimpleITK MedianImageFilter
+        <https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1MedianImageFilter.html>`_.
+
+    Note:
+        The median filter is not invertible.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Check if the filter is invertible.
+
+        Returns:
+            bool: False because the median filter is not invertible.
+        """
+        return False
+
+    def _process_image(self, image: IntensityImage, params: MedianFilterParams) -> IntensityImage:
+        """Apply the median filter to the provided image.
+
+        Args:
+            image (IntensityImage): The image to be filtered.
+            params (MedianFilterParams): The filter parameters.
+
+        Returns:
+            IntensityImage: The median filtered image.
+        """
+        # get the image data as sitk image
+        image_sitk = image.get_image_data()
+
+        # cast the image if necessary
+        if "integer" in image_sitk.GetPixelIDTypeAsString():
+            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
+
+        # apply the median filter
+        median_filter = sitk.MedianImageFilter()
+        median_filter.SetRadius(params.radius)
+        new_image_sitk = median_filter.Execute(image.get_image_data())
+
+        # add the new SimpleITK image to the PyRaDiSe image
+        image.set_image_data(new_image_sitk)
+
+        # track the necessary data
+        self._register_tracked_data(image, image_sitk, new_image_sitk, params)
+
+        return image
+
+    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
+        """Return the provided image because the median filter is not invertible.
+
+        Args:
+            image (IntensityImage): The image to be returned.
+            transform_info (TransformInfo): The transform information.
+
+        Returns:
+            IntensityImage: The provided image.
+        """
+        return image
+
+    def execute(self, subject: Subject, params: MedianFilterParams) -> Subject:
+        """Execute the median filter.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be filtered.
+            params (MedianFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with filtered
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        return super().execute(subject, params)
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided subject without any processing because the median filtering procedure is not
+        invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+        return super().execute_inverse(subject, transform_info)
+
+
+class LaplacianFilterParams(IntensityFilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.intensity.LaplacianFilter` class.
+
+    Args:
+        modalities (Optional[Tuple[Union[Modality, str], ...]]): The modalities of the images to be filtered. If
+         ``None`` is provided all images of the provided subject are filtered (default: None).
+    """
+
+    def __init__(self, modalities: Optional[Tuple[Union[Modality, str], ...]] = None) -> None:
+        super().__init__(modalities)
+
+
+class LaplacianFilter(IntensityFilter):
+    """A filter class performing a Laplacian sharpening on all :class:`~pyradise.data.image.IntensityImage` instances of
+    the provided :class:`~pyradise.data.subject.Subject` instance.
+
+    Reference:
+        The implementation is based on the SimpleITK implementation of the `SimpleITK LaplacianSharpeningImageFilter
+        <https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1LaplacianSharpeningImageFilter.html>`_.
+
+    Note:
+        The Laplacian filter is not invertible.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Check if the filter is invertible.
+
+        Returns:
+            bool: False because the Laplacian filter is not invertible.
+        """
+        return False
+
+    def _process_image(self, image: IntensityImage, params: LaplacianFilterParams) -> IntensityImage:
+        """Apply the Laplacian sharpening filter to the provided image.
+
+        Args:
+            image (IntensityImage): The image to be filtered.
+            params (LaplacianFilterParams): The filter parameters.
+
+        Returns:
+            IntensityImage: The Laplacian filtered image.
+        """
+        # get the image data as sitk image
+        image_sitk = image.get_image_data()
+
+        # cast the image if necessary
+        if "integer" in image_sitk.GetPixelIDTypeAsString():
+            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
+
+        # apply the laplace filter
+        laplacian_filter = sitk.LaplacianSharpeningImageFilter()
+        laplacian_filter.SetUseImageSpacing(True)
+        new_image_sitk = laplacian_filter.Execute(image_sitk)
+
+        # add the new SimpleITK image to the PyRaDiSe image
+        image.set_image_data(new_image_sitk)
+
+        # track the necessary data
+        self._register_tracked_data(image, image_sitk, new_image_sitk, params)
+
+        return image
+
+    def _process_image_inverse(self, image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
+        """Return the provided image because the Laplacian filter is not invertible.
+
+        Args:
+            image (IntensityImage): The image to be returned.
+            transform_info (TransformInfo): The transform information.
+
+        Returns:
+            IntensityImage: The provided image.
+        """
+        return image
+
+    def execute(self, subject: Subject, params: Optional[LaplacianFilterParams] = None) -> Subject:
+        """Execute the Laplacian sharpening filter.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be filtered.
+            params (Optional[LaplacianFilterParams]): The unused filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with Laplace filtered
+            :class:`~pyradise.data.image.IntensityImage` instances.
+
+        Note:
+            The Laplacian filter does not need any parameters.
+        """
+        return super().execute(subject, params)
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided subject without any processing because the Laplace filtering procedure is not
+        invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+        return super().execute_inverse(subject, transform_info)
```

### Comparing `pyradise-0.2.2/pyradise/process/invertibility.py` & `pyradise-0.2.3/pyradise/process/invertibility.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,140 +1,140 @@
-import warnings
-from copy import deepcopy
-from typing import Optional, Tuple, Union
-
-from pyradise.data import (IntensityImage, Modality, OrganAnnotatorCombination,
-                           SegmentationImage, Subject, TransformInfo,
-                           seq_to_modalities,
-                           seq_to_organ_annotator_combinations)
-from pyradise.process import Filter, FilterParams
-
-__all__ = ["PlaybackTransformTapeFilterParams", "PlaybackTransformTapeFilter"]
-
-
-class PlaybackTransformTapeFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.invertibility.PlaybackTransformTapeFilter` class.
-
-    Args:
-        modalities (Optional[Tuple[Union[str, Modality], ...]]): A tuple of modalities for which the transform tape
-         should be played back. If None, the transform tape will be played back for all modalities (default: None).
-        organ_annotator_combinations (Optional[Tuple[Union[Tuple[str, str], OrganRaterCombination], ...]]): A tuple of
-         organ-annotator combinations for which the transform tape should be played back. If None, the transform tape
-         will be played back for all organ-annotator combinations (default: None).
-    """
-
-    def __init__(
-        self,
-        modalities: Optional[Tuple[Union[str, Modality], ...]] = None,
-        organ_annotator_combinations: Optional[Tuple[Union[Tuple[str, str], OrganAnnotatorCombination], ...]] = None,
-    ) -> None:
-        super().__init__()
-
-        if modalities is not None:
-            self.modalities = seq_to_modalities(modalities)
-        else:
-            self.modalities = None
-
-        if organ_annotator_combinations is not None:
-            self.organ_annotator_combinations = seq_to_organ_annotator_combinations(organ_annotator_combinations)
-        else:
-            self.organ_annotator_combinations = organ_annotator_combinations
-
-
-class PlaybackTransformTapeFilter(Filter):
-    """A filter class for playing back the transform tape of specific or all :class:`~pyradise.data.image.Image`
-    instances of the provided :class:`~pyradise.data.subject.Subject` instance.
-
-    This filter is helpful for restoring the spatial properties of the loaded data such that the output data of the
-    processing pipeline has identical spatial properties as the input data.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Return False because the filter is not invertible.
-
-        Returns:
-            bool: False.
-        """
-        return False
-
-    def execute(self, subject: Subject, params: Optional[PlaybackTransformTapeFilterParams] = None) -> Subject:
-        """Execute the filter on the provided :class:`~pyradise.data.subject.Subject` instance.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance.
-            params (Optional[FilterParams]): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with played back images.
-        """
-        original_images = []
-        changed_images = []
-
-        images = subject.get_images()
-        for image in images:
-            # exclude images not matching the provided criteria
-            if isinstance(image, IntensityImage) and params.modalities is not None:
-                if not image.get_modality() in params.modalities:
-                    continue
-
-            if isinstance(image, SegmentationImage) and params.organ_annotator_combinations is not None:
-                if not image.get_organ_annotator_combination() in params.organ_annotator_combinations:
-                    continue
-
-            # copy the original subject
-            temp_subject = deepcopy(subject)
-            transform_tape = image.get_transform_tape()
-            transform_infos = transform_tape.get_recorded_elements(reverse=True)
-
-            # play back the transform tape
-            for transform_info in transform_infos:
-                filter_ = transform_info.get_filter()
-
-                # activate warnings if the filter is not invertible
-                if self.warn_on_non_invertible:
-                    filter_.set_warning_on_non_invertible(True)
-
-                temp_subject = filter_.execute_inverse(temp_subject, transform_info, image)
-
-            # collect the modified images
-            changed_image_candidates = [img for img in temp_subject.get_images() if img == image]
-            changed_images.append(changed_image_candidates[0])
-            original_images.append(image)
-
-        # replace the original images with the modified images and reset the transform tape
-        for original_image, changed_image in zip(original_images, changed_images):
-            original_image.set_image_data(changed_image.get_image_data())
-            original_image.get_transform_tape().reset()
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided :class:`~pyradise.data.subject.Subject` instance without any processing because
-        :class:`~pyradise.data.taping.TransformTape` playback is not invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance.
-            transform_info (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-
-        # potentially warn the user that the operation is not invertible
-        if self.warn_on_non_invertible and not self.is_invertible():
-            warnings.warn(
-                "WARNING: "
-                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
-                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
-                "is returned without modification."
-            )
-
-        return subject
+import warnings
+from copy import deepcopy
+from typing import Optional, Tuple, Union
+
+from pyradise.data import (IntensityImage, Modality, OrganAnnotatorCombination,
+                           SegmentationImage, Subject, TransformInfo,
+                           seq_to_modalities,
+                           seq_to_organ_annotator_combinations)
+from pyradise.process import Filter, FilterParams
+
+__all__ = ["PlaybackTransformTapeFilterParams", "PlaybackTransformTapeFilter"]
+
+
+class PlaybackTransformTapeFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.invertibility.PlaybackTransformTapeFilter` class.
+
+    Args:
+        modalities (Optional[Tuple[Union[str, Modality], ...]]): A tuple of modalities for which the transform tape
+         should be played back. If None, the transform tape will be played back for all modalities (default: None).
+        organ_annotator_combinations (Optional[Tuple[Union[Tuple[str, str], OrganRaterCombination], ...]]): A tuple of
+         organ-annotator combinations for which the transform tape should be played back. If None, the transform tape
+         will be played back for all organ-annotator combinations (default: None).
+    """
+
+    def __init__(
+        self,
+        modalities: Optional[Tuple[Union[str, Modality], ...]] = None,
+        organ_annotator_combinations: Optional[Tuple[Union[Tuple[str, str], OrganAnnotatorCombination], ...]] = None,
+    ) -> None:
+        super().__init__()
+
+        if modalities is not None:
+            self.modalities = seq_to_modalities(modalities)
+        else:
+            self.modalities = None
+
+        if organ_annotator_combinations is not None:
+            self.organ_annotator_combinations = seq_to_organ_annotator_combinations(organ_annotator_combinations)
+        else:
+            self.organ_annotator_combinations = organ_annotator_combinations
+
+
+class PlaybackTransformTapeFilter(Filter):
+    """A filter class for playing back the transform tape of specific or all :class:`~pyradise.data.image.Image`
+    instances of the provided :class:`~pyradise.data.subject.Subject` instance.
+
+    This filter is helpful for restoring the spatial properties of the loaded data such that the output data of the
+    processing pipeline has identical spatial properties as the input data.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Return False because the filter is not invertible.
+
+        Returns:
+            bool: False.
+        """
+        return False
+
+    def execute(self, subject: Subject, params: Optional[PlaybackTransformTapeFilterParams] = None) -> Subject:
+        """Execute the filter on the provided :class:`~pyradise.data.subject.Subject` instance.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance.
+            params (Optional[FilterParams]): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with played back images.
+        """
+        original_images = []
+        changed_images = []
+
+        images = subject.get_images()
+        for image in images:
+            # exclude images not matching the provided criteria
+            if isinstance(image, IntensityImage) and params.modalities is not None:
+                if not image.get_modality() in params.modalities:
+                    continue
+
+            if isinstance(image, SegmentationImage) and params.organ_annotator_combinations is not None:
+                if not image.get_organ_annotator_combination() in params.organ_annotator_combinations:
+                    continue
+
+            # copy the original subject
+            temp_subject = deepcopy(subject)
+            transform_tape = image.get_transform_tape()
+            transform_infos = transform_tape.get_recorded_elements(reverse=True)
+
+            # play back the transform tape
+            for transform_info in transform_infos:
+                filter_ = transform_info.get_filter()
+
+                # activate warnings if the filter is not invertible
+                if self.warn_on_non_invertible:
+                    filter_.set_warning_on_non_invertible(True)
+
+                temp_subject = filter_.execute_inverse(temp_subject, transform_info, image)
+
+            # collect the modified images
+            changed_image_candidates = [img for img in temp_subject.get_images() if img == image]
+            changed_images.append(changed_image_candidates[0])
+            original_images.append(image)
+
+        # replace the original images with the modified images and reset the transform tape
+        for original_image, changed_image in zip(original_images, changed_images):
+            original_image.set_image_data(changed_image.get_image_data())
+            original_image.get_transform_tape().reset()
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided :class:`~pyradise.data.subject.Subject` instance without any processing because
+        :class:`~pyradise.data.taping.TransformTape` playback is not invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance.
+            transform_info (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+
+        # potentially warn the user that the operation is not invertible
+        if self.warn_on_non_invertible and not self.is_invertible():
+            warnings.warn(
+                "WARNING: "
+                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
+                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
+                "is returned without modification."
+            )
+
+        return subject
```

### Comparing `pyradise-0.2.2/pyradise/process/modification.py` & `pyradise-0.2.3/pyradise/process/modification.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,625 +1,625 @@
-import warnings
-from copy import deepcopy
-from typing import Optional, Sequence, Tuple, Union
-
-import numpy as np
-import SimpleITK as sitk
-
-from pyradise.data import (Annotator, IntensityImage, Modality, Organ,
-                           SegmentationImage, Subject, TransformInfo,
-                           seq_to_annotators, seq_to_modalities, seq_to_organs,
-                           str_to_annotator, str_to_organ)
-
-from .base import Filter, FilterParams
-from .orientation import SpatialOrientation
-
-__all__ = [
-    "AddImageFilterParams",
-    "AddImageFilter",
-    "RemoveImageByOrganFilterParams",
-    "RemoveImageByOrganFilter",
-    "RemoveImageByAnnotatorFilterParams",
-    "RemoveImageByAnnotatorFilter",
-    "RemoveImageByModalityFilterParams",
-    "RemoveImageByModalityFilter",
-    "MergeSegmentationFilterParams",
-    "MergeSegmentationFilter",
-]
-
-
-class AddImageFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.modification.AddImageFilter` class.
-
-    Args:
-        images (Union[IntensityImage, SegmentationImage, Tuple[Union[IntensityImage, SegmentationImage], ...]): The
-         :class:`~pyradise.data.image.Image` instances to add to the provided :class:`~pyradise.data.subject.Subject`
-         instance.
-    """
-
-    def __init__(
-        self, images: Union[IntensityImage, SegmentationImage, Tuple[Union[IntensityImage, SegmentationImage], ...]]
-    ) -> None:
-        if isinstance(images, tuple):
-            self.images: Tuple[Union[IntensityImage, SegmentationImage], ...] = images
-        else:
-            self.images: Tuple[Union[IntensityImage, SegmentationImage], ...] = (images,)
-
-
-class AddImageFilter(Filter):
-    """A filter class to add :class:`~pyradise.data.image.Image` instances to the provided
-    :class:`~pyradise.data.subject.Subject` instance.
-
-    Note:
-        This filter currently does not support the inverse operation (the removal of the added images). This feature
-        will be added in the future.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Return whether the filter is invertible or not.
-
-        Note:
-        This filter currently does not support the inverse operation (the removal of the added images). This feature
-        will be added in the future.
-
-        Returns:
-            bool: False because the addition of :class:`~pyradise.data.image.Image` instances is currently not
-            supported.
-        """
-        return False
-
-    def execute(self, subject: Subject, params: AddImageFilterParams) -> Subject:
-        """Execute the addition procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to add the appropriate
-             :class:`~pyradise.data.image.Image` instances to.
-            params (AddImageFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance including the added
-            :class:`~pyradise.data.image.Image` instances.
-        """
-        for image in params.images:
-            # add the image to the subject
-            subject.add_image(image)
-
-            # track the necessary information
-            image_sitk = image.get_image_data()
-            self.tracking_data["organ"] = deepcopy(image.get_organ())
-            self.tracking_data["annotator"] = deepcopy(image.get_annotator())
-            self._register_tracked_data(image, image_sitk, image_sitk, params)
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided subject without any processing because the inverse addition procedure (the removal)
-        is currently not supported.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-
-        # potentially warn the user that the operation is not invertible
-        if self.warn_on_non_invertible and not self.is_invertible():
-            warnings.warn(
-                "WARNING: "
-                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
-                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
-                "is returned without modification."
-            )
-
-        return subject
-
-
-class RemoveImageByOrganFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.modification.RemoveImageByOrganFilter` class.
-
-    Args:
-        organs (Sequence[Union[Organ, str]]): The organs to remove from the provided
-         :class:`~pyradise.data.subject.Subject` instance.
-    """
-
-    def __init__(self, organs: Sequence[Union[Organ, str]]) -> None:
-        self.organs: Tuple[Organ, ...] = seq_to_organs(organs)
-
-
-class RemoveImageByOrganFilter(Filter):
-    """A filter class to remove :class:`~pyradise.data.image.SegmentationImage` instances from the provided
-    :class:`~pyradise.data.subject.Subject` instance. The :class:`~pyradise.data.image.SegmentationImage` instances
-    are identified by their :class:`~pyradise.data.organ.Organ` instance.
-
-    Note:
-        If multiple :class:`~pyradise.data.image.SegmentationImage` instances exist with the same
-        :class:`~pyradise.data.organ.Organ` instance all of them will be removed.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Return whether the filter is invertible or not.
-
-        Returns:
-            bool: False because the removal of :class:`~pyradise.data.image.SegmentationImage` instances is not
-            invertible.
-        """
-        return False
-
-    def execute(self, subject: Subject, params: RemoveImageByOrganFilterParams) -> Subject:
-        """Execute the removal procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to remove the appropriate
-             :class:`~pyradise.data.image.SegmentationImage` instances from.
-            params (RemoveImageByOrganFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance excluding the removed
-            :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-        for organ in params.organs:
-            subject.remove_image_by_organ(organ)
-
-            # track the necessary information
-            # --> do not track the removal of entities
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided subject without any processing because the removal procedure is not invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-
-        # potentially warn the user that the operation is not invertible
-        if self.warn_on_non_invertible and not self.is_invertible():
-            warnings.warn(
-                "WARNING: "
-                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
-                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
-                "is returned without modification."
-            )
-
-        return subject
-
-
-class RemoveImageByAnnotatorFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.modification.RemoveImageByAnnotatorFilter` class.
-
-    Args:
-        annotators (Sequence[Union[Annotator, str]]): The annotators identifying the
-         :class:`~pyradise.data.image.SegmentationImage` instances to remove from the provided
-         :class:`~pyradise.data.subject.Subject` instance.
-    """
-
-    def __init__(self, annotators: Sequence[Union[Annotator, str]]) -> None:
-        self.annotators: Tuple[Annotator, ...] = seq_to_annotators(annotators)
-
-
-class RemoveImageByAnnotatorFilter(Filter):
-    """A filter class to remove :class:`~pyradise.data.image.SegmentationImage` instances from the provided
-    :class:`~pyradise.data.subject.Subject` instance. The :class:`~pyradise.data.image.SegmentationImage` instances
-    are identified by their :class:`~pyradise.data.annotator.Annotator` instance.
-
-    Note:
-        If multiple :class:`~pyradise.data.image.SegmentationImage` instances exist with the same
-        :class:`~pyradise.data.annotator.Annotator` instance all of them will be removed.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Return whether the filter is invertible or not.
-
-        Returns:
-            bool: False because the removal of :class:`~pyradise.data.image.SegmentationImage` instances is not
-            invertible.
-        """
-        return False
-
-    def execute(self, subject: Subject, params: RemoveImageByAnnotatorFilterParams) -> Subject:
-        """Execute the removal procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to remove the appropriate
-             :class:`~pyradise.data.image.SegmentationImage` instances from.
-            params (RemoveImageByAnnotatorFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance excluding the removed
-            :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-        for annotator in params.annotators:
-            subject.remove_image_by_annotator(annotator)
-
-            # track the necessary information
-            # --> do not track the removal of entities
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided subject without any processing because the removal procedure is not invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-
-        # potentially warn the user that the operation is not invertible
-        if self.warn_on_non_invertible and not self.is_invertible():
-            warnings.warn(
-                "WARNING: "
-                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
-                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
-                "is returned without modification."
-            )
-
-        return subject
-
-
-class RemoveImageByModalityFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.modification.RemoveImageByModalityFilter` class.
-
-    Args:
-        modalities (Sequence[Union[Modality, str]]): The modalities identifying the
-         :class:`~pyradise.data.image.IntensityImage` instances to remove from the provided
-         :class:`~pyradise.data.subject.Subject` instance.
-    """
-
-    def __init__(self, modalities: Sequence[Union[Modality, str]]) -> None:
-        self.modalities: Tuple[Modality, ...] = seq_to_modalities(modalities)
-
-
-class RemoveImageByModalityFilter(Filter):
-    """A filter class to remove :class:`~pyradise.data.image.IntensityImage` instances from the provided
-    :class:`~pyradise.data.subject.Subject` instance. The :class:`~pyradise.data.image.IntensityImage` instances
-    are identified by their :class:`~pyradise.data.modality.Modality` instance.
-
-    Note:
-        If multiple :class:`~pyradise.data.image.SegmentationImage` instances exist with the same
-        :class:`~pyradise.data.modality.Modality` instance all of them will be removed.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Return whether the filter is invertible or not.
-
-        Returns:
-            bool: False because the removal of :class:`~pyradise.data.image.IntensityImage` instances is not
-            invertible.
-        """
-        return False
-
-    def execute(self, subject: Subject, params: RemoveImageByModalityFilterParams) -> Subject:
-        """Execute the removal procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to remove the appropriate
-             :class:`~pyradise.data.image.IntensityImage` instances from.
-            params (RemoveImageByModalityFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance excluding the removed
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        for modality in params.modalities:
-            subject.remove_image_by_modality(modality)
-
-            # track the necessary information
-            # --> do not track the removal of entities
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided subject without any processing because the removal procedure is not invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-            transformation should be applied. If None, the inverse transformation is applied to all images (default:
-            None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-
-        # potentially warn the user that the operation is not invertible
-        if self.warn_on_non_invertible and not self.is_invertible():
-            warnings.warn(
-                "WARNING: "
-                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
-                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
-                "is returned without modification."
-            )
-
-        return subject
-
-
-class MergeSegmentationFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.modification.MergeSegmentationFilter` class.
-
-    Note:
-        The order of the provided organs determines the merging order. The first organ will be inserted into the
-        resulting segmentation first, the second one second, etc. Therefore, if the segmentations overlap the
-        segmentation of the first organ will be overwritten by the segmentation of the second organ, etc.
-
-    Args:
-        organs (Sequence[Union[Organ, str]]): The :class:`~pyradise.data.organ.Organ` instances to merge.
-        output_organ_indexes (Sequence[int]): The indexes of the organs at the output (must be of equal length as
-         organs). If ```None`` is provided the organs will be enumerated from 1 to n (default: None).
-        output_organ (Union[Organ, str]): The :class:`~pyradise.data.organ.Organ` instance of the resulting
-         segmentation.
-        output_annotator (Union[Annotator, str]): The :class:`~pyradise.data.annotator.Annotator` instance of the
-         resulting segmentation.
-        output_orientation (Union[SpatialOrientation, str]): The orientation of the output segmentation (default: LPS).
-    """
-
-    def __init__(
-        self,
-        organs: Sequence[Union[Organ, str]],
-        output_organ_indexes: Optional[Sequence[int]],
-        output_organ: Union[Organ, str],
-        output_annotator: Union[Annotator, str],
-        output_orientation: Union[SpatialOrientation, str] = SpatialOrientation.LPS,
-    ) -> None:
-        self.organs: Tuple[Organ, ...] = seq_to_organs(organs)
-
-        if output_organ_indexes is None:
-            self.organ_indexes: Tuple[int, ...] = tuple(range(1, len(self.organs) + 1))
-        else:
-            if len(output_organ_indexes) != len(self.organs):
-                raise ValueError("The length of the provided organ indexes must be equal to the number of organs.")
-
-            if len(set(output_organ_indexes)) != len(output_organ_indexes):
-                raise ValueError("The provided organ indexes must be unique.")
-
-            self.organ_indexes: Tuple[int, ...] = tuple(output_organ_indexes)
-
-        if isinstance(output_orientation, str):
-            try:
-                self.output_orientation: SpatialOrientation = SpatialOrientation[output_orientation]
-            except KeyError:
-                raise ValueError(f"Invalid output orientation: {output_orientation}")
-        else:
-            self.output_orientation: SpatialOrientation = output_orientation
-
-        self.output_organ: Organ = str_to_organ(output_organ)
-        self.output_annotator: Annotator = str_to_annotator(output_annotator)
-
-
-class MergeSegmentationFilter(Filter):
-    """A filter class for merging multiple :class:`~pyradise.data.image.SegmentationImage` instances into
-    a new :class:`~pyradise.data.image.SegmentationImage` instance assigned to the provided
-    :class:`~pyradise.data.subject.Subject` instance.
-
-    Note:
-        If the provided :class:`~pyradise.data.image.SegmentationImage` instances are non-binary all non-zero label
-        values will be set to the provided organ index of the corresponding organ. Thus, non-binary segmentations will
-        be treated as binary ones with all non-zero values being considered as foreground.
-
-        Note that the merging order is defined by the order of the provided organs. However, the resulting segmentation
-        will contain the organ indexes associated with the provided organs.
-
-        The separation of segmentations is technically feasible to some extent. However, in radiotherapy the
-        separation of merged segmentations can have adverse effects because it may lead to corrupted segmentations if
-        segmentations overlap. Therefore, this filter does not provide the inverse procedure.
-
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Returns whether the filter is invertible or not.
-
-        Note:
-            The separation of segmentations is technically feasible to some extent. However, in radiotherapy the
-            separation of merged segmentations can have adverse effects because it may lead to corrupted segmentations
-            if segmentations overlap. Therefore, this filter does not provide the inverse procedure.
-
-        Returns:
-            bool: False because the merging of segmentations is not fully invertible.
-        """
-        return False
-
-    def _merge_segmentations(
-        self,
-        target_image: sitk.Image,
-        images: Tuple[SegmentationImage, ...],
-        images_sitk: Tuple[sitk.Image, ...],
-        organs: Tuple[Organ, ...],
-        params: MergeSegmentationFilterParams,
-    ) -> sitk.Image:
-        """Merges the given segmentations into one segmentation.
-
-        Args:
-            target_image (sitk.Image): An empty image for the merging.
-            images (Tuple[SegmentationImage, ...]): The :class:`~pyradise.data.segmentation_image.SegmentationImage`
-             instances associated with the ``images_sitk`` and the ``organs``.
-            images_sitk (Tuple[sitk.Image, ...]): The SimpleITK segmentation images to merge.
-            organs (Tuple[Organ, ...]): The :class:`~pyradise.data.organ.Organ` instances.
-            params (MergeSegmentationFilterParams): The filter parameters.
-
-        Returns:
-            sitk.Image: The merged segmentation.
-        """
-        target_image_np = sitk.GetArrayFromImage(target_image)
-
-        for image, image_sitk, organ, organ_idx in zip(images, images_sitk, organs, params.organ_indexes):
-            # resample the image to the empty image
-            resampled_image_sitk = sitk.Resample(
-                image_sitk, target_image, sitk.Transform(), sitk.sitkNearestNeighbor, 0.0, sitk.sitkUInt8
-            )
-
-            # merge the resampled image into the empty image
-            resampled_image_np = sitk.GetArrayFromImage(resampled_image_sitk)
-            target_image_np[resampled_image_np > 0] = int(organ_idx)
-
-            # track the necessary information
-            self._register_tracked_data(image, image_sitk, resampled_image_sitk, params)
-
-        # restore the target SimpleITK image
-        new_target_image = sitk.GetImageFromArray(target_image_np.astype(np.uint8))
-        new_target_image.CopyInformation(target_image)
-
-        return new_target_image
-
-    @staticmethod
-    def _get_empty_image(images: Tuple[sitk.Image, ...]) -> sitk.Image:
-        """Returns an empty image with the same size and spacing as the provided images.
-
-        Args:
-            images (Tuple[sitk.Image, ...]): The images to get the size and spacing from.
-
-        Returns:
-            sitk.Image: The empty image.
-        """
-        # get the physical properties of the images
-        origins = np.array([image.GetOrigin() for image in images])
-        spacings = np.array([image.GetSpacing() for image in images])
-        sizes = np.array([image.GetSize() for image in images])
-        max_coords = origins + sizes * spacings
-
-        # get the physical limits
-        limits = np.stack((np.min(origins, axis=0), np.max(max_coords, axis=0)))
-        min_physical_coord = np.min(limits, axis=0)
-        max_physical_coord = np.max(limits, axis=0)
-
-        # generate the empty numpy image
-        min_spacing = np.min(spacings, axis=0)
-        shape = np.ceil((max_physical_coord - min_physical_coord) / min_spacing).astype(int)
-        shape_np = shape[2], shape[0], shape[1]
-        empty_image_np = np.zeros(shape_np, dtype=np.uint8)
-
-        # generate the empty sitk image
-        empty_image_sitk = sitk.GetImageFromArray(empty_image_np)
-        empty_image_sitk.SetOrigin(min_physical_coord)
-        empty_image_sitk.SetSpacing(min_spacing)
-        empty_image_sitk.SetDirection(images[0].GetDirection())
-
-        return empty_image_sitk
-
-    def execute(self, subject: Subject, params: MergeSegmentationFilterParams) -> Subject:
-        """Execute the merging procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance containing the segmentations to
-             merge.
-            params (MergeSegmentationFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The subject with the merged :class:`~pyradise.data.image.SegmentationImage` instance added.
-        """
-        # adjust the images accordingly
-        images = []
-        images_sitk = []
-        organs = []
-        for image in subject.segmentation_images:
-            if image.get_organ() not in params.organs:
-                continue
-
-            image_sitk = deepcopy(image.get_image_data())
-            image_sitk = sitk.DICOMOrient(image_sitk, str(params.output_orientation.name))
-
-            # make sure that the image is binary
-            image_np = sitk.GetArrayFromImage(image_sitk)
-            image_np[image_np > 0] = 1
-            image_np[image_np < 1] = 0
-            binary_image_sitk = sitk.GetImageFromArray(image_np)
-            binary_image_sitk.CopyInformation(image_sitk)
-
-            images.append(image)
-            images_sitk.append(binary_image_sitk)
-            organs.append(image.get_organ())
-
-        # sort the images according to the provided organs
-        sorted_organs = []
-        sorted_images = []
-        sorted_images_sitk = []
-        for param_organ in params.organs:
-            if param_organ not in organs:
-                continue
-
-            local_idx = organs.index(param_organ)
-            sorted_organs.append(organs[local_idx])
-            sorted_images.append(images[local_idx])
-            sorted_images_sitk.append(images_sitk[local_idx])
-
-        # get an empty image
-        empty_image = self._get_empty_image(tuple(images_sitk))
-
-        # merge the segmentations
-        merged_image = self._merge_segmentations(
-            empty_image, tuple(sorted_images), tuple(sorted_images_sitk), tuple(sorted_organs), params
-        )
-
-        # create the new segmentation image
-        merged_segmentation = SegmentationImage(merged_image, params.output_organ, params.output_annotator)
-        subject.add_image(merged_segmentation)
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided subject without any processing because the merging procedure is not invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-
-        # potentially warn the user that the operation is not invertible
-        if self.warn_on_non_invertible and not self.is_invertible():
-            warnings.warn(
-                "WARNING: "
-                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
-                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
-                "is returned without modification."
-            )
-
-        return subject
+import warnings
+from copy import deepcopy
+from typing import Optional, Sequence, Tuple, Union
+
+import numpy as np
+import SimpleITK as sitk
+
+from pyradise.data import (Annotator, IntensityImage, Modality, Organ,
+                           SegmentationImage, Subject, TransformInfo,
+                           seq_to_annotators, seq_to_modalities, seq_to_organs,
+                           str_to_annotator, str_to_organ)
+
+from .base import Filter, FilterParams
+from .orientation import SpatialOrientation
+
+__all__ = [
+    "AddImageFilterParams",
+    "AddImageFilter",
+    "RemoveImageByOrganFilterParams",
+    "RemoveImageByOrganFilter",
+    "RemoveImageByAnnotatorFilterParams",
+    "RemoveImageByAnnotatorFilter",
+    "RemoveImageByModalityFilterParams",
+    "RemoveImageByModalityFilter",
+    "MergeSegmentationFilterParams",
+    "MergeSegmentationFilter",
+]
+
+
+class AddImageFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.modification.AddImageFilter` class.
+
+    Args:
+        images (Union[IntensityImage, SegmentationImage, Tuple[Union[IntensityImage, SegmentationImage], ...]): The
+         :class:`~pyradise.data.image.Image` instances to add to the provided :class:`~pyradise.data.subject.Subject`
+         instance.
+    """
+
+    def __init__(
+        self, images: Union[IntensityImage, SegmentationImage, Tuple[Union[IntensityImage, SegmentationImage], ...]]
+    ) -> None:
+        if isinstance(images, tuple):
+            self.images: Tuple[Union[IntensityImage, SegmentationImage], ...] = images
+        else:
+            self.images: Tuple[Union[IntensityImage, SegmentationImage], ...] = (images,)
+
+
+class AddImageFilter(Filter):
+    """A filter class to add :class:`~pyradise.data.image.Image` instances to the provided
+    :class:`~pyradise.data.subject.Subject` instance.
+
+    Note:
+        This filter currently does not support the inverse operation (the removal of the added images). This feature
+        will be added in the future.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Return whether the filter is invertible or not.
+
+        Note:
+        This filter currently does not support the inverse operation (the removal of the added images). This feature
+        will be added in the future.
+
+        Returns:
+            bool: False because the addition of :class:`~pyradise.data.image.Image` instances is currently not
+            supported.
+        """
+        return False
+
+    def execute(self, subject: Subject, params: AddImageFilterParams) -> Subject:
+        """Execute the addition procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to add the appropriate
+             :class:`~pyradise.data.image.Image` instances to.
+            params (AddImageFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance including the added
+            :class:`~pyradise.data.image.Image` instances.
+        """
+        for image in params.images:
+            # add the image to the subject
+            subject.add_image(image)
+
+            # track the necessary information
+            image_sitk = image.get_image_data()
+            self.tracking_data["organ"] = deepcopy(image.get_organ())
+            self.tracking_data["annotator"] = deepcopy(image.get_annotator())
+            self._register_tracked_data(image, image_sitk, image_sitk, params)
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided subject without any processing because the inverse addition procedure (the removal)
+        is currently not supported.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+
+        # potentially warn the user that the operation is not invertible
+        if self.warn_on_non_invertible and not self.is_invertible():
+            warnings.warn(
+                "WARNING: "
+                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
+                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
+                "is returned without modification."
+            )
+
+        return subject
+
+
+class RemoveImageByOrganFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.modification.RemoveImageByOrganFilter` class.
+
+    Args:
+        organs (Sequence[Union[Organ, str]]): The organs to remove from the provided
+         :class:`~pyradise.data.subject.Subject` instance.
+    """
+
+    def __init__(self, organs: Sequence[Union[Organ, str]]) -> None:
+        self.organs: Tuple[Organ, ...] = seq_to_organs(organs)
+
+
+class RemoveImageByOrganFilter(Filter):
+    """A filter class to remove :class:`~pyradise.data.image.SegmentationImage` instances from the provided
+    :class:`~pyradise.data.subject.Subject` instance. The :class:`~pyradise.data.image.SegmentationImage` instances
+    are identified by their :class:`~pyradise.data.organ.Organ` instance.
+
+    Note:
+        If multiple :class:`~pyradise.data.image.SegmentationImage` instances exist with the same
+        :class:`~pyradise.data.organ.Organ` instance all of them will be removed.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Return whether the filter is invertible or not.
+
+        Returns:
+            bool: False because the removal of :class:`~pyradise.data.image.SegmentationImage` instances is not
+            invertible.
+        """
+        return False
+
+    def execute(self, subject: Subject, params: RemoveImageByOrganFilterParams) -> Subject:
+        """Execute the removal procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to remove the appropriate
+             :class:`~pyradise.data.image.SegmentationImage` instances from.
+            params (RemoveImageByOrganFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance excluding the removed
+            :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+        for organ in params.organs:
+            subject.remove_image_by_organ(organ)
+
+            # track the necessary information
+            # --> do not track the removal of entities
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided subject without any processing because the removal procedure is not invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+
+        # potentially warn the user that the operation is not invertible
+        if self.warn_on_non_invertible and not self.is_invertible():
+            warnings.warn(
+                "WARNING: "
+                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
+                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
+                "is returned without modification."
+            )
+
+        return subject
+
+
+class RemoveImageByAnnotatorFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.modification.RemoveImageByAnnotatorFilter` class.
+
+    Args:
+        annotators (Sequence[Union[Annotator, str]]): The annotators identifying the
+         :class:`~pyradise.data.image.SegmentationImage` instances to remove from the provided
+         :class:`~pyradise.data.subject.Subject` instance.
+    """
+
+    def __init__(self, annotators: Sequence[Union[Annotator, str]]) -> None:
+        self.annotators: Tuple[Annotator, ...] = seq_to_annotators(annotators)
+
+
+class RemoveImageByAnnotatorFilter(Filter):
+    """A filter class to remove :class:`~pyradise.data.image.SegmentationImage` instances from the provided
+    :class:`~pyradise.data.subject.Subject` instance. The :class:`~pyradise.data.image.SegmentationImage` instances
+    are identified by their :class:`~pyradise.data.annotator.Annotator` instance.
+
+    Note:
+        If multiple :class:`~pyradise.data.image.SegmentationImage` instances exist with the same
+        :class:`~pyradise.data.annotator.Annotator` instance all of them will be removed.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Return whether the filter is invertible or not.
+
+        Returns:
+            bool: False because the removal of :class:`~pyradise.data.image.SegmentationImage` instances is not
+            invertible.
+        """
+        return False
+
+    def execute(self, subject: Subject, params: RemoveImageByAnnotatorFilterParams) -> Subject:
+        """Execute the removal procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to remove the appropriate
+             :class:`~pyradise.data.image.SegmentationImage` instances from.
+            params (RemoveImageByAnnotatorFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance excluding the removed
+            :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+        for annotator in params.annotators:
+            subject.remove_image_by_annotator(annotator)
+
+            # track the necessary information
+            # --> do not track the removal of entities
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided subject without any processing because the removal procedure is not invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+
+        # potentially warn the user that the operation is not invertible
+        if self.warn_on_non_invertible and not self.is_invertible():
+            warnings.warn(
+                "WARNING: "
+                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
+                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
+                "is returned without modification."
+            )
+
+        return subject
+
+
+class RemoveImageByModalityFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.modification.RemoveImageByModalityFilter` class.
+
+    Args:
+        modalities (Sequence[Union[Modality, str]]): The modalities identifying the
+         :class:`~pyradise.data.image.IntensityImage` instances to remove from the provided
+         :class:`~pyradise.data.subject.Subject` instance.
+    """
+
+    def __init__(self, modalities: Sequence[Union[Modality, str]]) -> None:
+        self.modalities: Tuple[Modality, ...] = seq_to_modalities(modalities)
+
+
+class RemoveImageByModalityFilter(Filter):
+    """A filter class to remove :class:`~pyradise.data.image.IntensityImage` instances from the provided
+    :class:`~pyradise.data.subject.Subject` instance. The :class:`~pyradise.data.image.IntensityImage` instances
+    are identified by their :class:`~pyradise.data.modality.Modality` instance.
+
+    Note:
+        If multiple :class:`~pyradise.data.image.SegmentationImage` instances exist with the same
+        :class:`~pyradise.data.modality.Modality` instance all of them will be removed.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Return whether the filter is invertible or not.
+
+        Returns:
+            bool: False because the removal of :class:`~pyradise.data.image.IntensityImage` instances is not
+            invertible.
+        """
+        return False
+
+    def execute(self, subject: Subject, params: RemoveImageByModalityFilterParams) -> Subject:
+        """Execute the removal procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to remove the appropriate
+             :class:`~pyradise.data.image.IntensityImage` instances from.
+            params (RemoveImageByModalityFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance excluding the removed
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        for modality in params.modalities:
+            subject.remove_image_by_modality(modality)
+
+            # track the necessary information
+            # --> do not track the removal of entities
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided subject without any processing because the removal procedure is not invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+            transformation should be applied. If None, the inverse transformation is applied to all images (default:
+            None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+
+        # potentially warn the user that the operation is not invertible
+        if self.warn_on_non_invertible and not self.is_invertible():
+            warnings.warn(
+                "WARNING: "
+                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
+                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
+                "is returned without modification."
+            )
+
+        return subject
+
+
+class MergeSegmentationFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.modification.MergeSegmentationFilter` class.
+
+    Note:
+        The order of the provided organs determines the merging order. The first organ will be inserted into the
+        resulting segmentation first, the second one second, etc. Therefore, if the segmentations overlap the
+        segmentation of the first organ will be overwritten by the segmentation of the second organ, etc.
+
+    Args:
+        organs (Sequence[Union[Organ, str]]): The :class:`~pyradise.data.organ.Organ` instances to merge.
+        output_organ_indexes (Sequence[int]): The indexes of the organs at the output (must be of equal length as
+         organs). If ```None`` is provided the organs will be enumerated from 1 to n (default: None).
+        output_organ (Union[Organ, str]): The :class:`~pyradise.data.organ.Organ` instance of the resulting
+         segmentation.
+        output_annotator (Union[Annotator, str]): The :class:`~pyradise.data.annotator.Annotator` instance of the
+         resulting segmentation.
+        output_orientation (Union[SpatialOrientation, str]): The orientation of the output segmentation (default: LPS).
+    """
+
+    def __init__(
+        self,
+        organs: Sequence[Union[Organ, str]],
+        output_organ_indexes: Optional[Sequence[int]],
+        output_organ: Union[Organ, str],
+        output_annotator: Union[Annotator, str],
+        output_orientation: Union[SpatialOrientation, str] = SpatialOrientation.LPS,
+    ) -> None:
+        self.organs: Tuple[Organ, ...] = seq_to_organs(organs)
+
+        if output_organ_indexes is None:
+            self.organ_indexes: Tuple[int, ...] = tuple(range(1, len(self.organs) + 1))
+        else:
+            if len(output_organ_indexes) != len(self.organs):
+                raise ValueError("The length of the provided organ indexes must be equal to the number of organs.")
+
+            if len(set(output_organ_indexes)) != len(output_organ_indexes):
+                raise ValueError("The provided organ indexes must be unique.")
+
+            self.organ_indexes: Tuple[int, ...] = tuple(output_organ_indexes)
+
+        if isinstance(output_orientation, str):
+            try:
+                self.output_orientation: SpatialOrientation = SpatialOrientation[output_orientation]
+            except KeyError:
+                raise ValueError(f"Invalid output orientation: {output_orientation}")
+        else:
+            self.output_orientation: SpatialOrientation = output_orientation
+
+        self.output_organ: Organ = str_to_organ(output_organ)
+        self.output_annotator: Annotator = str_to_annotator(output_annotator)
+
+
+class MergeSegmentationFilter(Filter):
+    """A filter class for merging multiple :class:`~pyradise.data.image.SegmentationImage` instances into
+    a new :class:`~pyradise.data.image.SegmentationImage` instance assigned to the provided
+    :class:`~pyradise.data.subject.Subject` instance.
+
+    Note:
+        If the provided :class:`~pyradise.data.image.SegmentationImage` instances are non-binary all non-zero label
+        values will be set to the provided organ index of the corresponding organ. Thus, non-binary segmentations will
+        be treated as binary ones with all non-zero values being considered as foreground.
+
+        Note that the merging order is defined by the order of the provided organs. However, the resulting segmentation
+        will contain the organ indexes associated with the provided organs.
+
+        The separation of segmentations is technically feasible to some extent. However, in radiotherapy the
+        separation of merged segmentations can have adverse effects because it may lead to corrupted segmentations if
+        segmentations overlap. Therefore, this filter does not provide the inverse procedure.
+
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Returns whether the filter is invertible or not.
+
+        Note:
+            The separation of segmentations is technically feasible to some extent. However, in radiotherapy the
+            separation of merged segmentations can have adverse effects because it may lead to corrupted segmentations
+            if segmentations overlap. Therefore, this filter does not provide the inverse procedure.
+
+        Returns:
+            bool: False because the merging of segmentations is not fully invertible.
+        """
+        return False
+
+    def _merge_segmentations(
+        self,
+        target_image: sitk.Image,
+        images: Tuple[SegmentationImage, ...],
+        images_sitk: Tuple[sitk.Image, ...],
+        organs: Tuple[Organ, ...],
+        params: MergeSegmentationFilterParams,
+    ) -> sitk.Image:
+        """Merges the given segmentations into one segmentation.
+
+        Args:
+            target_image (sitk.Image): An empty image for the merging.
+            images (Tuple[SegmentationImage, ...]): The :class:`~pyradise.data.segmentation_image.SegmentationImage`
+             instances associated with the ``images_sitk`` and the ``organs``.
+            images_sitk (Tuple[sitk.Image, ...]): The SimpleITK segmentation images to merge.
+            organs (Tuple[Organ, ...]): The :class:`~pyradise.data.organ.Organ` instances.
+            params (MergeSegmentationFilterParams): The filter parameters.
+
+        Returns:
+            sitk.Image: The merged segmentation.
+        """
+        target_image_np = sitk.GetArrayFromImage(target_image)
+
+        for image, image_sitk, organ, organ_idx in zip(images, images_sitk, organs, params.organ_indexes):
+            # resample the image to the empty image
+            resampled_image_sitk = sitk.Resample(
+                image_sitk, target_image, sitk.Transform(), sitk.sitkNearestNeighbor, 0.0, sitk.sitkUInt8
+            )
+
+            # merge the resampled image into the empty image
+            resampled_image_np = sitk.GetArrayFromImage(resampled_image_sitk)
+            target_image_np[resampled_image_np > 0] = int(organ_idx)
+
+            # track the necessary information
+            self._register_tracked_data(image, image_sitk, resampled_image_sitk, params)
+
+        # restore the target SimpleITK image
+        new_target_image = sitk.GetImageFromArray(target_image_np.astype(np.uint8))
+        new_target_image.CopyInformation(target_image)
+
+        return new_target_image
+
+    @staticmethod
+    def _get_empty_image(images: Tuple[sitk.Image, ...]) -> sitk.Image:
+        """Returns an empty image with the same size and spacing as the provided images.
+
+        Args:
+            images (Tuple[sitk.Image, ...]): The images to get the size and spacing from.
+
+        Returns:
+            sitk.Image: The empty image.
+        """
+        # get the physical properties of the images
+        origins = np.array([image.GetOrigin() for image in images])
+        spacings = np.array([image.GetSpacing() for image in images])
+        sizes = np.array([image.GetSize() for image in images])
+        max_coords = origins + sizes * spacings
+
+        # get the physical limits
+        limits = np.stack((np.min(origins, axis=0), np.max(max_coords, axis=0)))
+        min_physical_coord = np.min(limits, axis=0)
+        max_physical_coord = np.max(limits, axis=0)
+
+        # generate the empty numpy image
+        min_spacing = np.min(spacings, axis=0)
+        shape = np.ceil((max_physical_coord - min_physical_coord) / min_spacing).astype(int)
+        shape_np = shape[2], shape[0], shape[1]
+        empty_image_np = np.zeros(shape_np, dtype=np.uint8)
+
+        # generate the empty sitk image
+        empty_image_sitk = sitk.GetImageFromArray(empty_image_np)
+        empty_image_sitk.SetOrigin(min_physical_coord)
+        empty_image_sitk.SetSpacing(min_spacing)
+        empty_image_sitk.SetDirection(images[0].GetDirection())
+
+        return empty_image_sitk
+
+    def execute(self, subject: Subject, params: MergeSegmentationFilterParams) -> Subject:
+        """Execute the merging procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance containing the segmentations to
+             merge.
+            params (MergeSegmentationFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The subject with the merged :class:`~pyradise.data.image.SegmentationImage` instance added.
+        """
+        # adjust the images accordingly
+        images = []
+        images_sitk = []
+        organs = []
+        for image in subject.segmentation_images:
+            if image.get_organ() not in params.organs:
+                continue
+
+            image_sitk = deepcopy(image.get_image_data())
+            image_sitk = sitk.DICOMOrient(image_sitk, str(params.output_orientation.name))
+
+            # make sure that the image is binary
+            image_np = sitk.GetArrayFromImage(image_sitk)
+            image_np[image_np > 0] = 1
+            image_np[image_np < 1] = 0
+            binary_image_sitk = sitk.GetImageFromArray(image_np)
+            binary_image_sitk.CopyInformation(image_sitk)
+
+            images.append(image)
+            images_sitk.append(binary_image_sitk)
+            organs.append(image.get_organ())
+
+        # sort the images according to the provided organs
+        sorted_organs = []
+        sorted_images = []
+        sorted_images_sitk = []
+        for param_organ in params.organs:
+            if param_organ not in organs:
+                continue
+
+            local_idx = organs.index(param_organ)
+            sorted_organs.append(organs[local_idx])
+            sorted_images.append(images[local_idx])
+            sorted_images_sitk.append(images_sitk[local_idx])
+
+        # get an empty image
+        empty_image = self._get_empty_image(tuple(images_sitk))
+
+        # merge the segmentations
+        merged_image = self._merge_segmentations(
+            empty_image, tuple(sorted_images), tuple(sorted_images_sitk), tuple(sorted_organs), params
+        )
+
+        # create the new segmentation image
+        merged_segmentation = SegmentationImage(merged_image, params.output_organ, params.output_annotator)
+        subject.add_image(merged_segmentation)
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided subject without any processing because the merging procedure is not invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+
+        # potentially warn the user that the operation is not invertible
+        if self.warn_on_non_invertible and not self.is_invertible():
+            warnings.warn(
+                "WARNING: "
+                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
+                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
+                "is returned without modification."
+            )
+
+        return subject
```

### Comparing `pyradise-0.2.2/pyradise/process/orientation.py` & `pyradise-0.2.3/pyradise/process/orientation.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,513 +1,513 @@
-from enum import Enum
-from typing import Optional, Union
-
-import SimpleITK as sitk
-
-from pyradise.data import (IntensityImage, SegmentationImage, Subject,
-                           TransformInfo)
-
-from .base import Filter, FilterParams
-
-__all_ = ["OrientationFilterParameters", "OrientationFilter", "SpatialOrientation"]
-
-
-class _Coord(Enum):
-    """An enum class containing all available medical directions to build the :class:`SpatialOrientation` entries."""
-
-    ITK_COORDINATE_UNKNOWN = 0
-    """Default value for a unidentifiable coordinate direction."""
-
-    RIGHT = 2
-    """Coordinate direction right."""
-
-    LEFT = 3
-    """Coordinate direction left."""
-
-    POSTERIOR = 4  # back
-    """Coordinate direction posterior."""
-
-    ANTERIOR = 5  # front
-    """Coordinate direction anterior."""
-
-    INFERIOR = 8  # below
-    """Coordinate direction inferior."""
-
-    SUPERIOR = 9  # above
-    """Coordinate direction superior."""
-
-
-class _MajorTerms(Enum):
-    """An enum class for the possible axes within an image to describe the orientation. This enum is used to build
-    the :class:`SpatialOrientation`"""
-
-    PRIMARY_MINOR = 0
-    """The primary minor axis."""
-
-    SECONDARY_MINOR = 8
-    """The secondary minor axis."""
-
-    TERTIARY_MINOR = 16
-    """The tertiary minor axis."""
-
-
-class SpatialOrientation(Enum):
-    """An enum class for all possible medical image orientations an image can possess."""
-
-    INVALID = _Coord.ITK_COORDINATE_UNKNOWN
-    """The default value for an unidentifiable image orientation."""
-
-    RIP = (
-        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The right inferior posterior (RIP) orientation."""
-
-    LIP = (
-        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The left inferior posterior (LIP) orientation."""
-
-    RSP = (
-        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The right superior posterior (RSP) orientation."""
-
-    LSP = (
-        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The left superior posterior (LSP) orientation."""
-
-    RIA = (
-        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The right inferior anterior (RIA) orientation."""
-
-    LIA = (
-        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The left inferior anterior (LIA) orientation."""
-
-    RSA = (
-        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The right superior anterior (RSA) orientation."""
-
-    LSA = (
-        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The left superior anterior (LSA) orientation."""
-
-    IRP = (
-        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The inferior right posterior (IRP) orientation."""
-
-    ILP = (
-        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The inferior left posterior (ILP) orientation."""
-
-    SRP = (
-        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The superior right posterior (SRP) orientation."""
-
-    SLP = (
-        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The superior left posterior (SLP) orientation."""
-
-    IRA = (
-        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The inferior right anterior (IRA) orientation."""
-
-    ILA = (
-        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The inferior left anterior (ILA) orientation."""
-
-    SRA = (
-        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The superior right anterior (SRA) orientation."""
-
-    SLA = (
-        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The superior left anterior (SLA) orientation."""
-
-    RPI = (
-        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The right posterior inferior (RPI) orientation."""
-
-    LPI = (
-        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The left posterior inferior (LPI) orientation."""
-
-    RAI = (
-        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The right anterior inferior (RAI) orientation."""
-
-    LAI = (
-        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The left anterior inferior (LAI) orientation."""
-
-    RPS = (
-        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The right posterior superior (RPS) orientation."""
-
-    LPS = (
-        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The left posterior superior (LPS) orientation."""
-
-    RAS = (
-        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The right anterior superior (RAS) orientation."""
-
-    LAS = (
-        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The left anterior superior (LAS) orientation."""
-
-    PRI = (
-        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The posterior right inferior (PRI) orientation."""
-
-    PLI = (
-        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The posterior left inferior (PLI) orientation."""
-
-    ARI = (
-        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The anterior right inferior (ARI) orientation."""
-
-    ALI = (
-        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The anterior left inferior (ALI) orientation."""
-
-    PRS = (
-        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The posterior right superior (PRS) orientation."""
-
-    PLS = (
-        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The posterior left superior (PLS) orientation."""
-
-    ARS = (
-        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The anterior right superior (ARS) orientation."""
-
-    ALS = (
-        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The anterior left superior (ALS) orientation."""
-
-    IPR = (
-        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The inferior posterior right (IPR) orientation."""
-
-    SPR = (
-        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The superior posterior right (SPR) orientation."""
-
-    IAR = (
-        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The inferior anterior right (IAR) orientation."""
-
-    SAR = (
-        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The superior anterior right (SAR) orientation."""
-
-    IPL = (
-        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The inferior posterior left (IPL) orientation."""
-
-    SPL = (
-        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The superior posterior left (SPL) orientation."""
-
-    IAL = (
-        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The inferior anterior left (IAL) orientation."""
-
-    SAL = (
-        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The superior anterior left (SAL) orientation."""
-
-    PIR = (
-        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The posterior inferior right (PIR) orientation."""
-
-    PSR = (
-        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The posterior superior right (PSR) orientation."""
-
-    AIR = (
-        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The anterior inferior right (AIR) orientation."""
-
-    ASR = (
-        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The anterior superior right (ASR) orientation."""
-
-    PIL = (
-        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The posterior inferior left (PIL) orientation."""
-
-    PSL = (
-        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The posterior superior left (PSL) orientation."""
-
-    AIL = (
-        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The anterior inferior left (AIL) orientation."""
-
-    ASL = (
-        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
-        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
-        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
-    )
-    """The anterior superior left (ASL) orientation."""
-
-
-# pylint: disable = too-few-public-methods
-class OrientationFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.orientation.OrientationFilter`.
-
-    The orientation is a string or :class:`~pyradise.process.orientation.SpatialOrientation` value consisting of three
-    characters. These three characters describe the orientation of the image with the following values:
-
-    * ``I``: Inferior
-    * ``S``: Superior
-    * ``A``: Anterior
-    * ``P``: Posterior
-    * ``R``: Right
-    * ``L``: Left
-
-    The orientation of the image is described by the order of the characters. The first character describes the primary
-    orientation of patient in the positive x-axis direction. The second character describes the secondary orientation of
-    patient in the positive y-axis direction. The third character describes the tertiary orientation of patient in the
-    positive z-axis direction. For example, the orientation ``RAS`` means that the patient is facing right in the
-    positive x-axis direction, facing anterior in the positive y-axis direction, and facing superior in the positive
-    z-axis direction. For more details we refer to appropriate literature (e.g.
-    `website <http://www.grahamwideman.com/gw/brain/orientation/orientterms.htm>`_).
-
-
-    Args:
-        output_orientation (Union[SpatialOrientation, str]): The desired output orientation of all provided images.
-    """
-
-    def __init__(self, output_orientation: Union[SpatialOrientation, str]) -> None:
-        super().__init__()
-        if isinstance(output_orientation, str):
-            try:
-                self.output_orientation: SpatialOrientation = SpatialOrientation[output_orientation]
-            except KeyError:
-                raise ValueError(f"Invalid output orientation: {output_orientation}")
-        else:
-            self.output_orientation: SpatialOrientation = output_orientation
-
-
-class OrientationFilter(Filter):
-    """A filter class for reorienting all :class:`~pyradise.data.image.Image` instances of a
-    :class:`~pyradise.data.subject.Subject` instance to a specified
-    :class:`~pyradise.process.orientation.SpatialOrientation`.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Returns whether the filter is invertible or not.
-
-        Returns:
-            bool: True because the reorientation of images is invertible.
-        """
-        return True
-
-    def execute(self, subject: Subject, params: OrientationFilterParams) -> Subject:
-        """Execute the image reorientation procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            params (OrientationFilterParams): The filters parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with oriented
-            :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-        for image in subject.get_images():
-            # get the image data as SimpleITK image
-            sitk_image = image.get_image_data()
-
-            # reorient the image
-            orient_filter = sitk.DICOMOrientImageFilter()
-            orient_filter.SetDesiredCoordinateOrientation(params.output_orientation.name)
-            oriented_sitk_image = orient_filter.Execute(sitk_image)
-
-            # set the oriented image data to the image
-            image.set_image_data(oriented_sitk_image)
-
-            # track the necessary information
-            pre_orientation = orient_filter.GetOrientationFromDirectionCosines(sitk_image.GetDirection())
-            self.tracking_data["original_orientation"] = pre_orientation
-            self._register_tracked_data(image, sitk_image, oriented_sitk_image, params)
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Execute the inverse image reorientation procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            transform_info (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with reoriented
-            :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-        for image in subject.get_images():
-            if target_image is not None and image != target_image:
-                continue
-
-            # get the original orientation
-            original_orient = transform_info.get_data("original_orientation")
-
-            # reorient the image
-            orient_filter = sitk.DICOMOrientImageFilter()
-            orient_filter.SetDesiredCoordinateOrientation(original_orient)
-            oriented_sitk_image = orient_filter.Execute(image.get_image_data())
-
-            # set the oriented image data to the image
-            image.set_image_data(oriented_sitk_image)
-
-        return subject
+from enum import Enum
+from typing import Optional, Union
+
+import SimpleITK as sitk
+
+from pyradise.data import (IntensityImage, SegmentationImage, Subject,
+                           TransformInfo)
+
+from .base import Filter, FilterParams
+
+__all_ = ["OrientationFilterParameters", "OrientationFilter", "SpatialOrientation"]
+
+
+class _Coord(Enum):
+    """An enum class containing all available medical directions to build the :class:`SpatialOrientation` entries."""
+
+    ITK_COORDINATE_UNKNOWN = 0
+    """Default value for a unidentifiable coordinate direction."""
+
+    RIGHT = 2
+    """Coordinate direction right."""
+
+    LEFT = 3
+    """Coordinate direction left."""
+
+    POSTERIOR = 4  # back
+    """Coordinate direction posterior."""
+
+    ANTERIOR = 5  # front
+    """Coordinate direction anterior."""
+
+    INFERIOR = 8  # below
+    """Coordinate direction inferior."""
+
+    SUPERIOR = 9  # above
+    """Coordinate direction superior."""
+
+
+class _MajorTerms(Enum):
+    """An enum class for the possible axes within an image to describe the orientation. This enum is used to build
+    the :class:`SpatialOrientation`"""
+
+    PRIMARY_MINOR = 0
+    """The primary minor axis."""
+
+    SECONDARY_MINOR = 8
+    """The secondary minor axis."""
+
+    TERTIARY_MINOR = 16
+    """The tertiary minor axis."""
+
+
+class SpatialOrientation(Enum):
+    """An enum class for all possible medical image orientations an image can possess."""
+
+    INVALID = _Coord.ITK_COORDINATE_UNKNOWN
+    """The default value for an unidentifiable image orientation."""
+
+    RIP = (
+        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The right inferior posterior (RIP) orientation."""
+
+    LIP = (
+        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The left inferior posterior (LIP) orientation."""
+
+    RSP = (
+        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The right superior posterior (RSP) orientation."""
+
+    LSP = (
+        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The left superior posterior (LSP) orientation."""
+
+    RIA = (
+        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The right inferior anterior (RIA) orientation."""
+
+    LIA = (
+        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The left inferior anterior (LIA) orientation."""
+
+    RSA = (
+        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The right superior anterior (RSA) orientation."""
+
+    LSA = (
+        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The left superior anterior (LSA) orientation."""
+
+    IRP = (
+        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The inferior right posterior (IRP) orientation."""
+
+    ILP = (
+        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The inferior left posterior (ILP) orientation."""
+
+    SRP = (
+        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The superior right posterior (SRP) orientation."""
+
+    SLP = (
+        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The superior left posterior (SLP) orientation."""
+
+    IRA = (
+        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The inferior right anterior (IRA) orientation."""
+
+    ILA = (
+        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The inferior left anterior (ILA) orientation."""
+
+    SRA = (
+        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The superior right anterior (SRA) orientation."""
+
+    SLA = (
+        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The superior left anterior (SLA) orientation."""
+
+    RPI = (
+        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The right posterior inferior (RPI) orientation."""
+
+    LPI = (
+        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The left posterior inferior (LPI) orientation."""
+
+    RAI = (
+        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The right anterior inferior (RAI) orientation."""
+
+    LAI = (
+        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The left anterior inferior (LAI) orientation."""
+
+    RPS = (
+        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The right posterior superior (RPS) orientation."""
+
+    LPS = (
+        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The left posterior superior (LPS) orientation."""
+
+    RAS = (
+        (_Coord.RIGHT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The right anterior superior (RAS) orientation."""
+
+    LAS = (
+        (_Coord.LEFT.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The left anterior superior (LAS) orientation."""
+
+    PRI = (
+        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The posterior right inferior (PRI) orientation."""
+
+    PLI = (
+        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The posterior left inferior (PLI) orientation."""
+
+    ARI = (
+        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The anterior right inferior (ARI) orientation."""
+
+    ALI = (
+        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The anterior left inferior (ALI) orientation."""
+
+    PRS = (
+        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The posterior right superior (PRS) orientation."""
+
+    PLS = (
+        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The posterior left superior (PLS) orientation."""
+
+    ARS = (
+        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The anterior right superior (ARS) orientation."""
+
+    ALS = (
+        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The anterior left superior (ALS) orientation."""
+
+    IPR = (
+        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The inferior posterior right (IPR) orientation."""
+
+    SPR = (
+        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The superior posterior right (SPR) orientation."""
+
+    IAR = (
+        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The inferior anterior right (IAR) orientation."""
+
+    SAR = (
+        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The superior anterior right (SAR) orientation."""
+
+    IPL = (
+        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The inferior posterior left (IPL) orientation."""
+
+    SPL = (
+        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.POSTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The superior posterior left (SPL) orientation."""
+
+    IAL = (
+        (_Coord.INFERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The inferior anterior left (IAL) orientation."""
+
+    SAL = (
+        (_Coord.SUPERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.ANTERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The superior anterior left (SAL) orientation."""
+
+    PIR = (
+        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The posterior inferior right (PIR) orientation."""
+
+    PSR = (
+        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The posterior superior right (PSR) orientation."""
+
+    AIR = (
+        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The anterior inferior right (AIR) orientation."""
+
+    ASR = (
+        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.RIGHT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The anterior superior right (ASR) orientation."""
+
+    PIL = (
+        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The posterior inferior left (PIL) orientation."""
+
+    PSL = (
+        (_Coord.POSTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The posterior superior left (PSL) orientation."""
+
+    AIL = (
+        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.INFERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The anterior inferior left (AIL) orientation."""
+
+    ASL = (
+        (_Coord.ANTERIOR.value << _MajorTerms.PRIMARY_MINOR.value)
+        + (_Coord.SUPERIOR.value << _MajorTerms.SECONDARY_MINOR.value)
+        + (_Coord.LEFT.value << _MajorTerms.TERTIARY_MINOR.value)
+    )
+    """The anterior superior left (ASL) orientation."""
+
+
+# pylint: disable = too-few-public-methods
+class OrientationFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.orientation.OrientationFilter`.
+
+    The orientation is a string or :class:`~pyradise.process.orientation.SpatialOrientation` value consisting of three
+    characters. These three characters describe the orientation of the image with the following values:
+
+    * ``I``: Inferior
+    * ``S``: Superior
+    * ``A``: Anterior
+    * ``P``: Posterior
+    * ``R``: Right
+    * ``L``: Left
+
+    The orientation of the image is described by the order of the characters. The first character describes the primary
+    orientation of patient in the positive x-axis direction. The second character describes the secondary orientation of
+    patient in the positive y-axis direction. The third character describes the tertiary orientation of patient in the
+    positive z-axis direction. For example, the orientation ``RAS`` means that the patient is facing right in the
+    positive x-axis direction, facing anterior in the positive y-axis direction, and facing superior in the positive
+    z-axis direction. For more details we refer to appropriate literature (e.g.
+    `website <http://www.grahamwideman.com/gw/brain/orientation/orientterms.htm>`_).
+
+
+    Args:
+        output_orientation (Union[SpatialOrientation, str]): The desired output orientation of all provided images.
+    """
+
+    def __init__(self, output_orientation: Union[SpatialOrientation, str]) -> None:
+        super().__init__()
+        if isinstance(output_orientation, str):
+            try:
+                self.output_orientation: SpatialOrientation = SpatialOrientation[output_orientation]
+            except KeyError:
+                raise ValueError(f"Invalid output orientation: {output_orientation}")
+        else:
+            self.output_orientation: SpatialOrientation = output_orientation
+
+
+class OrientationFilter(Filter):
+    """A filter class for reorienting all :class:`~pyradise.data.image.Image` instances of a
+    :class:`~pyradise.data.subject.Subject` instance to a specified
+    :class:`~pyradise.process.orientation.SpatialOrientation`.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Returns whether the filter is invertible or not.
+
+        Returns:
+            bool: True because the reorientation of images is invertible.
+        """
+        return True
+
+    def execute(self, subject: Subject, params: OrientationFilterParams) -> Subject:
+        """Execute the image reorientation procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            params (OrientationFilterParams): The filters parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with oriented
+            :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+        for image in subject.get_images():
+            # get the image data as SimpleITK image
+            sitk_image = image.get_image_data()
+
+            # reorient the image
+            orient_filter = sitk.DICOMOrientImageFilter()
+            orient_filter.SetDesiredCoordinateOrientation(params.output_orientation.name)
+            oriented_sitk_image = orient_filter.Execute(sitk_image)
+
+            # set the oriented image data to the image
+            image.set_image_data(oriented_sitk_image)
+
+            # track the necessary information
+            pre_orientation = orient_filter.GetOrientationFromDirectionCosines(sitk_image.GetDirection())
+            self.tracking_data["original_orientation"] = pre_orientation
+            self._register_tracked_data(image, sitk_image, oriented_sitk_image, params)
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Execute the inverse image reorientation procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            transform_info (TransformInfo): The :class:`~pyradise.data.taping.TransformInfo` instance.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with reoriented
+            :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+        for image in subject.get_images():
+            if target_image is not None and image != target_image:
+                continue
+
+            # get the original orientation
+            original_orient = transform_info.get_data("original_orientation")
+
+            # reorient the image
+            orient_filter = sitk.DICOMOrientImageFilter()
+            orient_filter.SetDesiredCoordinateOrientation(original_orient)
+            oriented_sitk_image = orient_filter.Execute(image.get_image_data())
+
+            # set the oriented image data to the image
+            image.set_image_data(oriented_sitk_image)
+
+        return subject
```

### Comparing `pyradise-0.2.2/pyradise/process/postprocess.py` & `pyradise-0.2.3/pyradise/process/postprocess.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,293 +1,293 @@
-import warnings
-from copy import deepcopy
-from typing import Optional, Tuple, Union
-
-import numpy as np
-import SimpleITK as sitk
-
-from pyradise.data import (IntensityImage, Organ, SegmentationImage, Subject,
-                           TransformInfo)
-
-from .base import Filter, FilterParams
-
-__all__ = [
-    "SingleConnectedComponentFilterParams",
-    "SingleConnectedComponentFilter",
-    "AlphabeticOrganSortingFilterParams",
-    "AlphabeticOrganSortingFilter",
-]
-
-
-# pylint: disable = too-few-public-methods
-class SingleConnectedComponentFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.postprocess.SingleConnectedComponentFilter` class.
-
-    Args:
-        excluded_organs (Optional[Union[Organ, Tuple[Organ, ...]]]): The organs to be excluded from the connected
-         component filtering. If ``None`` all :class:`~pyradise.data.image.SegmentationImage` instances will be
-         filtered.
-    """
-
-    def __init__(self, excluded_organs: Optional[Union[Organ, Tuple[Organ, ...]]] = None) -> None:
-        if isinstance(excluded_organs, Organ):
-            self.excluded_organs = (excluded_organs,)
-        elif excluded_organs is None:
-            self.excluded_organs = tuple()
-        else:
-            self.excluded_organs = excluded_organs
-
-
-class SingleConnectedComponentFilter(Filter):
-    """A filter class for removing all but the largest connected component from the specified
-    :class:`~pyradise.data.image.SegmentationImage` instances in the provided :class:`~pyradise.data.subject.Subject`
-    instance.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Return whether the filter is invertible or not.
-
-        Returns:
-            bool: False because the :class:`~pyradise.process.postprocess.SingleConnectedComponentFilter` is
-            not invertible.
-        """
-        return False
-
-    def _get_single_label_images(
-        self,
-        image: SegmentationImage,
-    ) -> Tuple[Tuple[sitk.Image, ...], Tuple[int, ...]]:
-        """Splits a label image into multiple single/binary label images.
-
-        Args:
-            image (SegmentationImage): The image to separate into binary images.
-
-        Returns:
-            Tuple[Tuple[sitk.Image, ...], Tuple[int, ...]]: Returns the binary images and the original label indexes.
-        """
-        sitk_image = image.get_image_data()
-        np_image = sitk.GetArrayFromImage(sitk_image)
-
-        labels = self._get_unique_labels(sitk_image)
-
-        unique_images = []
-        unique_labels = []
-        for label in labels:
-            np_image_ = deepcopy(np_image)
-            np_image_[np_image_ != label] = 0
-            np_image_[np_image_ == label] = 1
-
-            sitk_image_ = sitk.GetImageFromArray(np_image_)
-            sitk_image_.CopyInformation(sitk_image)
-            unique_images.append(sitk_image_)
-
-            unique_labels.append(label)
-
-        return tuple(unique_images), tuple(unique_labels)
-
-    @staticmethod
-    def _combine_images(images: Tuple[sitk.Image, ...]) -> sitk.Image:
-        """Combines multiple label images to one image.
-
-        Args:
-            images (Tuple[sitk.Image, ...]): The images to combine.
-
-        Returns:
-            sitk.Image: The combined image.
-        """
-        if len(images) == 1:
-            return images[0]
-
-        final = sitk.GetArrayFromImage(images[0])
-        for i in range(1, len(images)):
-            np_image = sitk.GetArrayFromImage(images[i])
-            np.putmask(final, np_image != 0, np_image)
-
-        combined = sitk.GetImageFromArray(final)
-        combined.CopyInformation(images[0])
-
-        return combined
-
-    @staticmethod
-    def _get_single_connected_component_image(image: SegmentationImage, label: int) -> sitk.Image:
-        """Removes all connected components except for the largest and adjusts the label index.
-
-        Args:
-            image (sitk.Image): The image to process.
-            label (int): The label index of the output image.
-
-        Returns:
-            sitk.Image: The image with only one single connected component.
-        """
-        original_image = image.get_image_data()
-        cc_filter = sitk.ConnectedComponentImageFilter()
-        cc_filter.SetFullyConnected(True)
-        sitk_image = cc_filter.Execute(original_image)
-        sitk_image = sitk.RelabelComponent(sitk_image, sortByObjectSize=True)
-        sitk_image = sitk.BinaryThreshold(sitk_image, 1, 1)
-
-        np_image = sitk.GetArrayFromImage(sitk_image)
-        np_image[np_image == 1] = label
-        sitk_image = sitk.GetImageFromArray(np_image)
-        sitk_image.CopyInformation(original_image)
-
-        return sitk_image
-
-    @staticmethod
-    def _get_unique_labels(image: sitk.Image, exclude_bg: bool = True) -> Tuple[int, ...]:
-        image_np = sitk.GetArrayFromImage(image)
-        unique_labels = np.unique(image_np)
-
-        if exclude_bg:
-            unique_labels = unique_labels[unique_labels != 0]
-
-        return tuple(unique_labels)
-
-    def execute(self, subject: Subject, params: SingleConnectedComponentFilterParams) -> Subject:
-        """Execute the single connected component filter procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            params (SingleConnectedComponentFilterParams): The filters parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with filtered
-            :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-        for image in subject.segmentation_images:
-            if image.get_organ() in params.excluded_organs:
-                continue
-
-            image_sitk = image.get_image_data()
-            if image.is_binary():
-                single_label_images = (image,)
-                labels = self._get_unique_labels(image_sitk)
-            else:
-                single_label_images, labels = self._get_single_label_images(image)
-
-            cc_images = []
-            for single_label_image, label in zip(single_label_images, labels):
-                single_cc_image = self._get_single_connected_component_image(single_label_image, label)
-                cc_images.append(single_cc_image)
-
-            if cc_images:
-                cc_image = self._combine_images(tuple(cc_images))
-                cc_image = sitk.Cast(cc_image, sitk.sitkUInt8)
-
-                image.set_image_data(cc_image)
-
-                self._register_tracked_data(image, image_sitk, image.get_image_data(), params)
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided :class:`~pyradise.data.subject.Subject` instance without any processing because
-        the single connected component filtering procedure is not invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-
-        # potentially warn the user that the operation is not invertible
-        if self.warn_on_non_invertible and not self.is_invertible():
-            warnings.warn(
-                "WARNING: "
-                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
-                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
-                "is returned without modification."
-            )
-
-        return subject
-
-
-class AlphabeticOrganSortingFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.postprocess.AlphabeticOrganSortingFilter` class.
-
-    Args:
-        ascending (bool): If the organs should be sorted in ascending order or not (default: True).
-    """
-
-    def __init__(self, ascending: bool = True) -> None:
-        self.ascending = ascending
-
-
-class AlphabeticOrganSortingFilter(Filter):
-    """A filter class performing an alphabetic sorting of the :class:`~pyradise.data.image.SegmentationImage` instances
-    according to their assigned :class:`~pyradise.data.organ.Organ` names.
-
-    Note:
-        This filter is helpful when ordering of the output matters such as for example if constructing a DICOM-RTSS
-        :class:`~pydicom.dataset.Dataset` instance.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Return whether the filter is invertible or not.
-
-        Returns:
-            bool: False because the :class:`~pyradise.process.postprocess.AlphabeticOrganSortingFilter` is
-            not invertible.
-        """
-        return False
-
-    def execute(self, subject: Subject, params: AlphabeticOrganSortingFilterParams) -> Subject:
-        """Execute the alphabetical sorting of the :class:`~pyradise.data.image.SegmentationImage` instances according
-        to their associated :class:`~pyradise.data.organ.Organ` instances.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be sorted.
-            params (AlphabeticOrganSortingFilterParams): The filter parameters
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with the alphabetically sorted
-            :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-        subject.segmentation_images = sorted(subject.segmentation_images, key=lambda x: x.get_organ(as_str=True))
-
-        if not params.ascending:
-            subject.segmentation_images = subject.segmentation_images[::-1]
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Return the provided image without any processing because the alphabetical sorting procedure is not
-        invertible.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
-        """
-
-        # potentially warn the user that the operation is not invertible
-        if self.warn_on_non_invertible and not self.is_invertible():
-            warnings.warn(
-                "WARNING: "
-                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
-                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
-                "is returned without modification."
-            )
-
-        return subject
+import warnings
+from copy import deepcopy
+from typing import Optional, Tuple, Union
+
+import numpy as np
+import SimpleITK as sitk
+
+from pyradise.data import (IntensityImage, Organ, SegmentationImage, Subject,
+                           TransformInfo)
+
+from .base import Filter, FilterParams
+
+__all__ = [
+    "SingleConnectedComponentFilterParams",
+    "SingleConnectedComponentFilter",
+    "AlphabeticOrganSortingFilterParams",
+    "AlphabeticOrganSortingFilter",
+]
+
+
+# pylint: disable = too-few-public-methods
+class SingleConnectedComponentFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.postprocess.SingleConnectedComponentFilter` class.
+
+    Args:
+        excluded_organs (Optional[Union[Organ, Tuple[Organ, ...]]]): The organs to be excluded from the connected
+         component filtering. If ``None`` all :class:`~pyradise.data.image.SegmentationImage` instances will be
+         filtered.
+    """
+
+    def __init__(self, excluded_organs: Optional[Union[Organ, Tuple[Organ, ...]]] = None) -> None:
+        if isinstance(excluded_organs, Organ):
+            self.excluded_organs = (excluded_organs,)
+        elif excluded_organs is None:
+            self.excluded_organs = tuple()
+        else:
+            self.excluded_organs = excluded_organs
+
+
+class SingleConnectedComponentFilter(Filter):
+    """A filter class for removing all but the largest connected component from the specified
+    :class:`~pyradise.data.image.SegmentationImage` instances in the provided :class:`~pyradise.data.subject.Subject`
+    instance.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Return whether the filter is invertible or not.
+
+        Returns:
+            bool: False because the :class:`~pyradise.process.postprocess.SingleConnectedComponentFilter` is
+            not invertible.
+        """
+        return False
+
+    def _get_single_label_images(
+        self,
+        image: SegmentationImage,
+    ) -> Tuple[Tuple[sitk.Image, ...], Tuple[int, ...]]:
+        """Splits a label image into multiple single/binary label images.
+
+        Args:
+            image (SegmentationImage): The image to separate into binary images.
+
+        Returns:
+            Tuple[Tuple[sitk.Image, ...], Tuple[int, ...]]: Returns the binary images and the original label indexes.
+        """
+        sitk_image = image.get_image_data()
+        np_image = sitk.GetArrayFromImage(sitk_image)
+
+        labels = self._get_unique_labels(sitk_image)
+
+        unique_images = []
+        unique_labels = []
+        for label in labels:
+            np_image_ = deepcopy(np_image)
+            np_image_[np_image_ != label] = 0
+            np_image_[np_image_ == label] = 1
+
+            sitk_image_ = sitk.GetImageFromArray(np_image_)
+            sitk_image_.CopyInformation(sitk_image)
+            unique_images.append(sitk_image_)
+
+            unique_labels.append(label)
+
+        return tuple(unique_images), tuple(unique_labels)
+
+    @staticmethod
+    def _combine_images(images: Tuple[sitk.Image, ...]) -> sitk.Image:
+        """Combines multiple label images to one image.
+
+        Args:
+            images (Tuple[sitk.Image, ...]): The images to combine.
+
+        Returns:
+            sitk.Image: The combined image.
+        """
+        if len(images) == 1:
+            return images[0]
+
+        final = sitk.GetArrayFromImage(images[0])
+        for i in range(1, len(images)):
+            np_image = sitk.GetArrayFromImage(images[i])
+            np.putmask(final, np_image != 0, np_image)
+
+        combined = sitk.GetImageFromArray(final)
+        combined.CopyInformation(images[0])
+
+        return combined
+
+    @staticmethod
+    def _get_single_connected_component_image(image: SegmentationImage, label: int) -> sitk.Image:
+        """Removes all connected components except for the largest and adjusts the label index.
+
+        Args:
+            image (sitk.Image): The image to process.
+            label (int): The label index of the output image.
+
+        Returns:
+            sitk.Image: The image with only one single connected component.
+        """
+        original_image = image.get_image_data()
+        cc_filter = sitk.ConnectedComponentImageFilter()
+        cc_filter.SetFullyConnected(True)
+        sitk_image = cc_filter.Execute(original_image)
+        sitk_image = sitk.RelabelComponent(sitk_image, sortByObjectSize=True)
+        sitk_image = sitk.BinaryThreshold(sitk_image, 1, 1)
+
+        np_image = sitk.GetArrayFromImage(sitk_image)
+        np_image[np_image == 1] = label
+        sitk_image = sitk.GetImageFromArray(np_image)
+        sitk_image.CopyInformation(original_image)
+
+        return sitk_image
+
+    @staticmethod
+    def _get_unique_labels(image: sitk.Image, exclude_bg: bool = True) -> Tuple[int, ...]:
+        image_np = sitk.GetArrayFromImage(image)
+        unique_labels = np.unique(image_np)
+
+        if exclude_bg:
+            unique_labels = unique_labels[unique_labels != 0]
+
+        return tuple(unique_labels)
+
+    def execute(self, subject: Subject, params: SingleConnectedComponentFilterParams) -> Subject:
+        """Execute the single connected component filter procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            params (SingleConnectedComponentFilterParams): The filters parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with filtered
+            :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+        for image in subject.segmentation_images:
+            if image.get_organ() in params.excluded_organs:
+                continue
+
+            image_sitk = image.get_image_data()
+            if image.is_binary():
+                single_label_images = (image,)
+                labels = self._get_unique_labels(image_sitk)
+            else:
+                single_label_images, labels = self._get_single_label_images(image)
+
+            cc_images = []
+            for single_label_image, label in zip(single_label_images, labels):
+                single_cc_image = self._get_single_connected_component_image(single_label_image, label)
+                cc_images.append(single_cc_image)
+
+            if cc_images:
+                cc_image = self._combine_images(tuple(cc_images))
+                cc_image = sitk.Cast(cc_image, sitk.sitkUInt8)
+
+                image.set_image_data(cc_image)
+
+                self._register_tracked_data(image, image_sitk, image.get_image_data(), params)
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided :class:`~pyradise.data.subject.Subject` instance without any processing because
+        the single connected component filtering procedure is not invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+
+        # potentially warn the user that the operation is not invertible
+        if self.warn_on_non_invertible and not self.is_invertible():
+            warnings.warn(
+                "WARNING: "
+                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
+                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
+                "is returned without modification."
+            )
+
+        return subject
+
+
+class AlphabeticOrganSortingFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.postprocess.AlphabeticOrganSortingFilter` class.
+
+    Args:
+        ascending (bool): If the organs should be sorted in ascending order or not (default: True).
+    """
+
+    def __init__(self, ascending: bool = True) -> None:
+        self.ascending = ascending
+
+
+class AlphabeticOrganSortingFilter(Filter):
+    """A filter class performing an alphabetic sorting of the :class:`~pyradise.data.image.SegmentationImage` instances
+    according to their assigned :class:`~pyradise.data.organ.Organ` names.
+
+    Note:
+        This filter is helpful when ordering of the output matters such as for example if constructing a DICOM-RTSS
+        :class:`~pydicom.dataset.Dataset` instance.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Return whether the filter is invertible or not.
+
+        Returns:
+            bool: False because the :class:`~pyradise.process.postprocess.AlphabeticOrganSortingFilter` is
+            not invertible.
+        """
+        return False
+
+    def execute(self, subject: Subject, params: AlphabeticOrganSortingFilterParams) -> Subject:
+        """Execute the alphabetical sorting of the :class:`~pyradise.data.image.SegmentationImage` instances according
+        to their associated :class:`~pyradise.data.organ.Organ` instances.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be sorted.
+            params (AlphabeticOrganSortingFilterParams): The filter parameters
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with the alphabetically sorted
+            :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+        subject.segmentation_images = sorted(subject.segmentation_images, key=lambda x: x.get_organ(as_str=True))
+
+        if not params.ascending:
+            subject.segmentation_images = subject.segmentation_images[::-1]
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Return the provided image without any processing because the alphabetical sorting procedure is not
+        invertible.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be returned.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The provided :class:`~pyradise.data.subject.Subject` instance.
+        """
+
+        # potentially warn the user that the operation is not invertible
+        if self.warn_on_non_invertible and not self.is_invertible():
+            warnings.warn(
+                "WARNING: "
+                f"The {self.__class__.__name__} is called to invert its operation for the following image: \n"
+                f"\t{target_image.__str__()} \nHowever, the filter is not invertible. The provided subject "
+                "is returned without modification."
+            )
+
+        return subject
```

### Comparing `pyradise-0.2.2/pyradise/process/registration.py` & `pyradise-0.2.3/pyradise/process/registration.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,660 +1,677 @@
-from enum import Enum
-from typing import Optional, Tuple, Union
-
-import numpy as np
-import SimpleITK as sitk
-
-from pyradise.data import (Image, IntensityImage, Modality, SegmentationImage,
-                           Subject, TransformInfo, str_to_modality)
-
-from .base import Filter, FilterParams
-
-__all__ = [
-    "IntraSubjectRegistrationFilterParams",
-    "IntraSubjectRegistrationFilter",
-    "InterSubjectRegistrationFilterParams",
-    "InterSubjectRegistrationFilter",
-    "RegistrationType",
-]
-
-
-class RegistrationType(Enum):
-    """An enum class representing the different registration transform types."""
-
-    AFFINE = 1
-    """Affine registration."""
-
-    SIMILARITY = 2
-    """Similarity registration."""
-
-    RIGID = 3
-    """Rigid registration."""
-
-    BSPLINE = 4
-    """BSpline registration."""
-
-
-def get_interpolator(image: Image) -> Optional[int]:
-    """Get the appropriate interpolator for the given image depending on the image type.
-
-    Args:
-        image (Image): The image.
-
-    Returns:
-        Optional[int]: The interpolator.
-    """
-    if isinstance(image, IntensityImage):
-        return sitk.sitkBSpline
-    elif isinstance(image, SegmentationImage):
-        return sitk.sitkNearestNeighbor
-    else:
-        return None
-
-
-def get_registration_method(
-    registration_type: RegistrationType = RegistrationType.RIGID,
-    number_of_histogram_bins: int = 200,
-    learning_rate: float = 1.0,
-    step_size: float = 0.001,
-    number_of_iterations: int = 1500,
-    relaxation_factor: float = 0.5,
-    shrink_factors: Tuple[int, ...] = (2, 2, 1),
-    smoothing_sigmas: Tuple[float, ...] = (2, 1, 0),
-    sampling_percentage: float = 0.2,
-) -> sitk.ImageRegistrationMethod:
-    """Get the registration method based on the provided parameters.
-
-    Args:
-        registration_type (RegistrationType): The type of registration (default: RegistrationType.RIGID).
-        number_of_histogram_bins (int): The number of histogram bins for registration (default: 200).
-        learning_rate (float): The learning rate of the optimizer (default: 1.0).
-        step_size (float): The step size of the optimizer (default: 0.001).
-        number_of_iterations (int): The maximal number of optimization iterations (default: 1500).
-        relaxation_factor (float): The relaxation factor (default: 0.5).
-        shrink_factors (Tuple[int, ...): The shrink factors for the image pyramid (default: (2, 2, 1))).
-        smoothing_sigmas (Tuple[float, ...]): The smoothing sigmas (default: (2, 1, 0))).
-        sampling_percentage (float): The sampling percentage of the voxels to incorporate into the optimization
-         (default: 0.2).
-
-    Returns:
-        sitk.ImageRegistrationMethod: The registration method.
-    """
-    registration = sitk.ImageRegistrationMethod()
-
-    registration.SetMetricAsMattesMutualInformation(number_of_histogram_bins)
-    registration.SetMetricSamplingStrategy(registration.RANDOM)
-    registration.SetMetricSamplingPercentage(sampling_percentage, sitk.sitkWallClock)
-
-    registration.SetMetricUseFixedImageGradientFilter(False)
-    registration.SetMetricUseMovingImageGradientFilter(False)
-
-    registration.SetInterpolator(sitk.sitkLinear)
-
-    if registration_type == RegistrationType.BSPLINE:
-        registration.SetOptimizerAsLBFGSB()
-    else:
-        registration.SetOptimizerAsRegularStepGradientDescent(
-            learningRate=learning_rate,
-            minStep=step_size,
-            numberOfIterations=number_of_iterations,
-            relaxationFactor=relaxation_factor,
-            gradientMagnitudeTolerance=1e-4,
-            estimateLearningRate=registration.EachIteration,
-            maximumStepSizeInPhysicalUnits=0.0,
-        )
-
-    registration.SetOptimizerScalesFromPhysicalShift()
-
-    # Setup for the multi-resolution framework
-    registration.SetShrinkFactorsPerLevel(shrink_factors)
-    registration.SetSmoothingSigmasPerLevel(smoothing_sigmas)
-    registration.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()
-
-    return registration
-
-
-def register_images(
-    moving_image: sitk.Image,
-    fixed_image: sitk.Image,
-    registration_type: RegistrationType,
-    registration_method: sitk.ImageRegistrationMethod,
-) -> sitk.Transform:
-    """Register the moving image to the fixed image and return the transformation.
-
-    Args:
-        moving_image (sitk.Image): The moving image.
-        fixed_image (sitk.Image): The fixed image.
-        registration_type (RegistrationType): The registration type.
-        registration_method (sitk.ImageRegistrationMethod): The registration method.
-
-    Returns:
-        sitk.Transform: The registration transformation.
-    """
-    if moving_image.GetDimension() != fixed_image.GetDimension():
-        raise ValueError("The floating and fixed image dimensions do not match!")
-
-    dims = moving_image.GetDimension()
-    if dims not in (2, 3):
-        raise ValueError("The image must have 2 or 3 dimensions. Different number of dimensions are not supported!")
-
-    moving_image_f32 = sitk.Cast(moving_image, sitk.sitkFloat32)
-    fixed_image_f32 = sitk.Cast(fixed_image, sitk.sitkFloat32)
-
-    if registration_type == RegistrationType.BSPLINE:
-        transform_domain_mesh_size = [10] * dims
-        initial_transform = sitk.BSplineTransformInitializer(fixed_image, transform_domain_mesh_size)
-    else:
-        if registration_type == RegistrationType.RIGID:
-            transform_type = sitk.VersorRigid3DTransform() if dims == 3 else sitk.Euler2DTransform()
-
-        elif registration_type == RegistrationType.AFFINE:
-            transform_type = sitk.AffineTransform(dims)
-
-        elif registration_type == RegistrationType.SIMILARITY:
-            transform_type = sitk.Similarity3DTransform() if dims == 3 else sitk.Similarity2DTransform()
-
-        else:
-            raise ValueError(f"The registration type ({registration_type.name}) is not supported!")
-
-        initial_transform = sitk.CenteredTransformInitializer(
-            fixed_image_f32, moving_image_f32, transform_type, sitk.CenteredTransformInitializerFilter.GEOMETRY
-        )
-
-    registration_method.SetInitialTransform(initial_transform, inPlace=True)
-
-    transform = registration_method.Execute(fixed_image_f32, moving_image_f32)
-
-    return transform
-
-
-# pylint: disable = too-few-public-methods
-class IntraSubjectRegistrationFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.registration.IntraSubjectRegistrationFilter` class.
-
-    Args:
-        reference_modality (Union[Modality, str]): The reference modality.
-        registration_type (RegistrationType): The type of registration (default: RegistrationType.RIGID).
-        number_of_histogram_bins (int): The number of histogram bins for registration (default: 200).
-        learning_rate (float): The learning rate of the optimizer (default: 1.0).
-        step_size (float): The step size of the optimizer (default: 0.001).
-        number_of_iterations (int): The maximal number of optimization iterations (default: 1500).
-        relaxation_factor (float): The relaxation factor (default: 0.5).
-        shrink_factors (Tuple[int, ...): The shrink factors for the image pyramid (default: (2, 2, 1))).
-        smoothing_sigmas (Tuple[float, ...]): The smoothing sigmas (default: (2, 1, 0))).
-        sampling_percentage (float): The sampling percentage of the voxels to incorporate into the optimization
-         (default: 0.2).
-        resampling_interpolator (int): The resampling interpolator (default: sitk.sitkBSpline).
-    """
-
-    def __init__(
-        self,
-        reference_modality: Union[Modality, str],
-        registration_type: RegistrationType = RegistrationType.RIGID,
-        number_of_histogram_bins: int = 200,
-        learning_rate: float = 1.0,
-        step_size: float = 0.001,
-        number_of_iterations: int = 1500,
-        relaxation_factor: float = 0.5,
-        shrink_factors: Tuple[int, ...] = (2, 2, 1),
-        smoothing_sigmas: Tuple[float, ...] = (2, 1, 0),
-        sampling_percentage: float = 0.2,
-        resampling_interpolator: int = sitk.sitkBSpline,
-    ) -> None:
-        super().__init__()
-
-        if len(shrink_factors) != len(smoothing_sigmas):
-            raise ValueError("The shrink_factors and smoothing_sigmas need to have the same length!")
-
-        self.reference_modality: Modality = str_to_modality(reference_modality)
-        self.registration_type = registration_type
-        self.number_of_histogram_bins = number_of_histogram_bins
-        self.learning_rate = learning_rate
-        self.step_size = step_size
-        self.number_of_iterations = number_of_iterations
-        self.relaxation_factor = relaxation_factor
-        self.shrink_factors: Tuple[int, ...] = shrink_factors
-        self.smoothing_sigmas: Tuple[float, ...] = smoothing_sigmas
-        self.sampling_percentage = sampling_percentage
-        self.resampling_interpolator = resampling_interpolator
-
-
-class IntraSubjectRegistrationFilter(Filter):
-    """An invertible intra-subject registration filter class which registers all
-    :class:`~pyradise.data.image.IntensityImage` instances to a reference :class:`~pyradise.data.image.IntensityImage`
-    instance.
-
-    Important:
-        This filter assumes that the :class:`~pyradise.data.image.SegmentationImage` instances are already registered
-        to the reference :class:`~pyradise.data.image.IntensityImage` instance. No transformation will be applied to
-        the :class:`~pyradise.data.image.SegmentationImage` instances.
-
-    Warning:
-        The inverse registration procedure may not yield the expected results if successive
-        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
-        Thus, it's recommended to use the invertibility feature with appropriate caution.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Return whether the filter is invertible or not.
-
-        Returns:
-            bool: True because the registration filter is invertible.
-        """
-        return True
-
-    # noinspection DuplicatedCode
-    def _process_image(
-        self,
-        moving_image: Image,
-        fixed_image: sitk.Image,
-        params: IntraSubjectRegistrationFilterParams,
-        transform: Optional[sitk.Transform] = None,
-        track_infos: bool = True,
-    ) -> Image:
-        """Apply the transformation or register the image to the reference image.
-
-        Args:
-            moving_image (Image): The moving image.
-            fixed_image (sitk.Image): The fixed image.
-            params (IntraSubjectRegistrationFilterParams): The filter parameters.
-            transform (Optional[sitk.Transform]): The transformation to apply to the image (default: None).
-            track_infos (bool): Whether to track the processing information or not (default: True).
-
-        Returns:
-            Image: The registered image.
-        """
-        # get the moving image as SimpleITK image
-        moving_image_sitk = moving_image.get_image_data()
-
-        # cast the image if its pixels are not of type float32
-        if isinstance(moving_image, IntensityImage):
-            moving_image_sitk = sitk.Cast(moving_image_sitk, sitk.sitkFloat32)
-            fixed_image = sitk.Cast(fixed_image, sitk.sitkFloat32)
-
-        # register the moving image to the fixed image if no transform is given
-        if transform is None:
-            # get the registration method
-            registration_method = get_registration_method(
-                params.registration_type,
-                params.number_of_histogram_bins,
-                params.learning_rate,
-                params.step_size,
-                params.number_of_iterations,
-                params.relaxation_factor,
-                params.shrink_factors,
-                params.smoothing_sigmas,
-                params.sampling_percentage,
-            )
-
-            transform = register_images(moving_image_sitk, fixed_image, params.registration_type, registration_method)
-
-        # get the interpolator according to the image type
-        interpolator = get_interpolator(moving_image)
-        if interpolator is None:
-            return moving_image
-
-        # resample the moving image
-        min_intensity = float(np.min(sitk.GetArrayFromImage(moving_image_sitk)))
-        new_image_sitk = sitk.Resample(
-            moving_image_sitk, fixed_image, transform, interpolator, min_intensity, moving_image_sitk.GetPixelIDValue()
-        )
-
-        # set the new image data to the image
-        moving_image.set_image_data(new_image_sitk)
-
-        # track the necessary information
-        if track_infos:
-            self.tracking_data.update(
-                {
-                    "original_origin": moving_image_sitk.GetOrigin(),
-                    "original_spacing": moving_image_sitk.GetSpacing(),
-                    "original_direction": moving_image_sitk.GetDirection(),
-                    "original_size": moving_image_sitk.GetSize(),
-                }
-            )
-            self._register_tracked_data(moving_image, moving_image_sitk, new_image_sitk, params, transform)
-
-        return moving_image
-
-    def execute(self, subject: Subject, params: IntraSubjectRegistrationFilterParams) -> Subject:
-        """Execute the intra-subject registration procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            params (IntraSubjectRegistrationFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with registered
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        # get the reference image
-        reference_image = subject.get_image_by_modality(params.reference_modality)
-        reference_image_sitk = reference_image.get_image_data()
-
-        # perform the registration
-        for image in subject.get_images():
-            if isinstance(image, IntensityImage):
-                if image.get_modality() == params.reference_modality:
-                    continue
-
-                self._process_image(image, reference_image_sitk, params, track_infos=True)
-
-        return subject
-
-    # noinspection DuplicatedCode
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Execute the inverse of the intra-subject registration procedure.
-
-        Args:
-            subject: The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            transform_info: The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with unregistered
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        # construct the original image as a reference
-        original_image_props = transform_info.get_image_properties(pre_transform=True)
-
-        reference_image_np = np.zeros(original_image_props.size[::-1], dtype=float)
-        reference_image_sitk = sitk.GetImageFromArray(reference_image_np)
-        reference_image_sitk.SetOrigin(original_image_props.origin)
-        reference_image_sitk.SetSpacing(original_image_props.spacing)
-        reference_image_sitk.SetDirection(original_image_props.direction)
-
-        # get the inverse transform
-        transform = transform_info.get_transform(True)
-
-        # perform the inverse registration
-        for image in subject.get_images():
-            if target_image is not None and image != target_image:
-                continue
-
-            if isinstance(image, IntensityImage):
-                if image.get_modality() == transform_info.params.reference_modality:
-                    continue
-
-                self._process_image(
-                    image, reference_image_sitk, transform_info.get_params(), transform, track_infos=False
-                )
-
-        return subject
-
-
-# pylint: disable = too-few-public-methods
-class InterSubjectRegistrationFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.registration.InterSubjectRegistrationFilter` class.
-
-    Args:
-        reference_subject (Subject): The reference subject to which the subject will be registered.
-        reference_modality (Union[Modality, str]): The modality of the reference image (fixed image) to be used for
-         registration.
-        subject_modality (Optional[Union[Modality, str]]): The modality of the subject image (moving image) to be used
-         for registration. If ``None``, the same modality as the reference image will be used (default: None).
-        registration_type (RegistrationType): The type of registration (default: RegistrationType.RIGID).
-        number_of_histogram_bins (int): The number of histogram bins for registration (default: 200).
-        learning_rate (float): The learning rate of the optimizer (default: 1.0).
-        step_size (float): The step size of the optimizer (default: 0.001).
-        number_of_iterations (int): The maximal number of optimization iterations (default: 1500).
-        relaxation_factor (float): The relaxation factor (default: 0.5).
-        shrink_factors (Tuple[int, ...): The shrink factors for the image pyramid (default: (2, 2, 1))).
-        smoothing_sigmas (Tuple[float, ...]): The smoothing sigmas (default: (2, 1, 0))).
-        sampling_percentage (float): The sampling percentage of the voxels to incorporate into the optimization
-         (default: 0.2).
-        resampling_interpolator (int): The interpolator to use for resampling the image
-    """
-
-    # pylint: disable=too-many-instance-attributes, too-many-arguments
-    def __init__(
-        self,
-        reference_subject: Subject,
-        reference_modality: Union[Modality, str],
-        subject_modality: Optional[Union[Modality, str]] = None,
-        registration_type: RegistrationType = RegistrationType.RIGID,
-        number_of_histogram_bins: int = 200,
-        learning_rate: float = 1.0,
-        step_size: float = 0.001,
-        number_of_iterations: int = 1500,
-        relaxation_factor: float = 0.5,
-        shrink_factors: Tuple[int, ...] = (2, 2, 1),
-        smoothing_sigmas: Tuple[float, ...] = (2, 1, 0),
-        sampling_percentage: float = 0.2,
-        resampling_interpolator: int = sitk.sitkBSpline,
-    ) -> None:
-        super().__init__()
-
-        if len(shrink_factors) != len(smoothing_sigmas):
-            raise ValueError("The shrink_factors and smoothing_sigmas need to have the same length!")
-
-        self.reference_subject = reference_subject
-        self.reference_modality: Modality = str_to_modality(reference_modality)
-        self.subject_modality: Modality = (
-            str_to_modality(subject_modality) if subject_modality is not None else reference_modality
-        )
-        self.registration_type = registration_type
-        self.number_of_histogram_bins = number_of_histogram_bins
-        self.learning_rate = learning_rate
-        self.step_size = step_size
-        self.number_of_iterations = number_of_iterations
-        self.relaxation_factor = relaxation_factor
-        self.shrink_factors: Tuple[int, ...] = shrink_factors
-        self.smoothing_sigmas: Tuple[float, ...] = smoothing_sigmas
-        self.sampling_percentage = sampling_percentage
-        self.resampling_interpolator = resampling_interpolator
-
-
-class InterSubjectRegistrationFilter(Filter):
-    """An invertible inter-subject registration filter class which registers all
-    :class:`~pyradise.data.image.IntensityImage` instances of the provided :class:`~pyradise.data.subject.Subject` to a
-    reference :class:`~pyradise.data.image.IntensityImage` instance of another :class:`~pyradise.data.subject.Subject`.
-
-    Important:
-        This filter assumes that all :class:`~pyradise.data.image.Image` instances of the provided
-        :class:`~pyradise.data.subject.Subject` are co-registered such that the
-        :class:`~pyradise.data.image.SegmentationImage` instances do not require special treatment.
-
-    Warning:
-        The inverse registration procedure may not yield the expected results if successive
-        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
-        Thus, it's recommended to use the invertibility feature with appropriate caution.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Return whether the filter is invertible.
-
-        Returns:
-            bool: True because the inter-subject registration is invertible.
-        """
-        return True
-
-    # noinspection DuplicatedCode
-    def _apply_transform(
-        self,
-        subject: Subject,
-        transform: sitk.Transform,
-        reference_image: sitk.Image,
-        params: InterSubjectRegistrationFilterParams,
-    ) -> Subject:
-        """Apply the provided transformation to the subject.
-
-        Args:
-            subject (Subject): The subject.
-            transform (sitk.Transform): The transformation to apply to the subject.
-            reference_image (sitk.Image): The reference image.
-            params (InterSubjectRegistrationFilterParams): The filters parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with transformed
-            :class:`~pyradise.data.image.Image` instances.
-        """
-        # transform and resample the images
-        for image in subject.get_images():
-            interpolator = get_interpolator(image)
-            if interpolator is None:
-                continue
-
-            # get the image data and cast if necessary
-            image_sitk = image.get_image_data()
-            if isinstance(image, IntensityImage):
-                image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
-
-            # resample the image
-            min_intensity = float(np.min(sitk.GetArrayFromImage(image_sitk)))
-            new_image_sitk = sitk.Resample(
-                image_sitk, reference_image, transform, interpolator, min_intensity, image_sitk.GetPixelIDValue()
-            )
-
-            # set the new image data to the image
-            image.set_image_data(new_image_sitk)
-
-            # track the necessary data
-            self._register_tracked_data(image, image_sitk, new_image_sitk, params, transform)
-
-        return subject
-
-    # noinspection DuplicatedCode
-    @staticmethod
-    def _apply_inverse_transform(
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Apply the inverse transformation to the subject.
-
-        Args:
-            subject (Subject): The subject.
-            transform_info (TransformInfo): The transformation information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with back-transformed
-            :class:`~pyradise.data.image.Image` instances.
-        """
-        # construct the original image as a reference
-        original_image_props = transform_info.get_image_properties(pre_transform=True)
-
-        reference_image_np = np.zeros(original_image_props.size[::-1], dtype=float)
-        reference_image_sitk = sitk.GetImageFromArray(reference_image_np)
-        reference_image_sitk.SetOrigin(original_image_props.origin)
-        reference_image_sitk.SetSpacing(original_image_props.spacing)
-        reference_image_sitk.SetDirection(original_image_props.direction)
-
-        # get the inverse transform
-        transform = transform_info.get_transform(True)
-
-        # transform and resample the images
-        for image in subject.get_images():
-            if target_image is not None and image != target_image:
-                continue
-
-            # get the image data and cast if necessary
-            image_sitk = image.get_image_data()
-            if isinstance(image, IntensityImage):
-                image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
-
-            # the interpolator
-            interpolator = get_interpolator(image)
-            if interpolator is None:
-                continue
-
-            # resample the image
-            min_intensity = float(np.min(sitk.GetArrayFromImage(image_sitk)))
-            new_image_sitk = sitk.Resample(
-                image_sitk, reference_image_sitk, transform, interpolator, min_intensity, image_sitk.GetPixelIDValue()
-            )
-
-            # set the new image data to the image
-            image.set_image_data(new_image_sitk)
-
-        return subject
-
-    @staticmethod
-    def _register_image(
-        subject: Subject, reference_image: sitk.Image, params: InterSubjectRegistrationFilterParams
-    ) -> sitk.Transform:
-        """Register the subject image to the specific modality of the reference subject.
-
-        Args:
-            subject (Subject): The subject to register.
-            reference_image (sitk.Image): The reference image.
-            params (InterSubjectRegistrationFilterParams): The filters parameters.
-
-        Returns:
-            sitk.Transform: The registration transformation.
-        """
-        moving_image = subject.get_image_by_modality(params.subject_modality)
-        moving_image_sitk = moving_image.get_image_data()
-
-        # get the registration method
-        registration_method = get_registration_method(
-            params.registration_type,
-            params.number_of_histogram_bins,
-            params.learning_rate,
-            params.step_size,
-            params.number_of_iterations,
-            params.relaxation_factor,
-            params.shrink_factors,
-            params.smoothing_sigmas,
-            params.sampling_percentage,
-        )
-
-        return register_images(moving_image_sitk, reference_image, params.registration_type, registration_method)
-
-    def execute(self, subject: Subject, params: InterSubjectRegistrationFilterParams) -> Subject:
-        """Executes the inter-subject registration procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            params (InterSubjectRegistrationFilterParams): The filter parameters.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with all
-            :class:`~pyradise.data.image.IntensityImage` instances registered to the reference subject
-            :class:`~pyradise.data.image.IntensityImage` instance.
-        """
-        # get the reference image
-        reference_image = params.reference_subject.get_image_by_modality(params.reference_modality)
-        reference_image_sitk = reference_image.get_image_data()
-
-        # register the subject to the reference image
-        transform = self._register_image(subject, reference_image_sitk, params)
-
-        # apply the transform to the other images of the subject
-        subject = self._apply_transform(subject, transform, reference_image_sitk, params)
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Execute the inverse of the inter-subject registration procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with unregistered
-            :class:`~pyradise.data.image.IntensityImage` instances.
-        """
-        subject = self._apply_inverse_transform(subject, transform_info, target_image)
-
-        return subject
+from enum import Enum
+from typing import Optional, Tuple, Union
+
+import numpy as np
+import SimpleITK as sitk
+
+from pyradise.data import (Image, IntensityImage, Modality, SegmentationImage,
+                           Subject, TransformInfo, str_to_modality)
+
+from .base import Filter, FilterParams
+
+__all__ = [
+    "IntraSubjectRegistrationFilterParams",
+    "IntraSubjectRegistrationFilter",
+    "InterSubjectRegistrationFilterParams",
+    "InterSubjectRegistrationFilter",
+    "RegistrationType",
+]
+
+
+class RegistrationType(Enum):
+    """An enum class representing the different registration transform types."""
+
+    AFFINE = 1
+    """Affine registration."""
+
+    SIMILARITY = 2
+    """Similarity registration."""
+
+    RIGID = 3
+    """Rigid registration."""
+
+    BSPLINE = 4
+    """BSpline registration."""
+
+
+def get_interpolator(image: Image) -> Optional[int]:
+    """Get the appropriate interpolator for the given image depending on the image type.
+
+    Args:
+        image (Image): The image.
+
+    Returns:
+        Optional[int]: The interpolator.
+    """
+    if isinstance(image, IntensityImage):
+        return sitk.sitkBSpline
+    elif isinstance(image, SegmentationImage):
+        return sitk.sitkNearestNeighbor
+    else:
+        return None
+
+
+def get_registration_method(
+    registration_type: RegistrationType = RegistrationType.RIGID,
+    number_of_histogram_bins: int = 200,
+    learning_rate: float = 1.0,
+    step_size: float = 0.001,
+    number_of_iterations: int = 1500,
+    relaxation_factor: float = 0.5,
+    shrink_factors: Tuple[int, ...] = (2, 2, 1),
+    smoothing_sigmas: Tuple[float, ...] = (2, 1, 0),
+    sampling_percentage: float = 0.2,
+    deterministic: bool = True,
+) -> sitk.ImageRegistrationMethod:
+    """Get the registration method based on the provided parameters.
+
+    Args:
+        registration_type (RegistrationType): The type of registration (default: RegistrationType.RIGID).
+        number_of_histogram_bins (int): The number of histogram bins for registration (default: 200).
+        learning_rate (float): The learning rate of the optimizer (default: 1.0).
+        step_size (float): The step size of the optimizer (default: 0.001).
+        number_of_iterations (int): The maximal number of optimization iterations (default: 1500).
+        relaxation_factor (float): The relaxation factor (default: 0.5).
+        shrink_factors (Tuple[int, ...): The shrink factors for the image pyramid (default: (2, 2, 1))).
+        smoothing_sigmas (Tuple[float, ...]): The smoothing sigmas (default: (2, 1, 0))).
+        sampling_percentage (float): The sampling percentage of the voxels to incorporate into the optimization
+         (default: 0.2).
+        deterministic (bool): Deterministic processing with a fixed seed and a single thread (default: True).
+
+    Returns:
+        sitk.ImageRegistrationMethod: The registration method.
+    """
+    registration = sitk.ImageRegistrationMethod()
+
+    registration.SetMetricAsMattesMutualInformation(number_of_histogram_bins)
+
+    if deterministic:
+        # https://simpleitk.readthedocs.io/en/master/registrationOverview.html
+        registration.SetGlobalDefaultNumberOfThreads(0)
+        sampling_seed = 42
+        registration.SetMetricSamplingPercentage(sampling_percentage, sampling_seed)
+    else:
+        registration.SetMetricSamplingStrategy(registration.RANDOM)
+        registration.SetMetricSamplingPercentage(sampling_percentage, sitk.sitkWallClock)
+
+    registration.SetMetricUseFixedImageGradientFilter(False)
+    registration.SetMetricUseMovingImageGradientFilter(False)
+
+    registration.SetInterpolator(sitk.sitkLinear)
+
+    if registration_type == RegistrationType.BSPLINE:
+        registration.SetOptimizerAsLBFGSB()
+    else:
+        registration.SetOptimizerAsRegularStepGradientDescent(
+            learningRate=learning_rate,
+            minStep=step_size,
+            numberOfIterations=number_of_iterations,
+            relaxationFactor=relaxation_factor,
+            gradientMagnitudeTolerance=1e-4,
+            estimateLearningRate=registration.EachIteration,
+            maximumStepSizeInPhysicalUnits=0.0,
+        )
+
+    registration.SetOptimizerScalesFromPhysicalShift()
+
+    # Setup for the multi-resolution framework
+    registration.SetShrinkFactorsPerLevel(shrink_factors)
+    registration.SetSmoothingSigmasPerLevel(smoothing_sigmas)
+    registration.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()
+
+    return registration
+
+
+def register_images(
+    moving_image: sitk.Image,
+    fixed_image: sitk.Image,
+    registration_type: RegistrationType,
+    registration_method: sitk.ImageRegistrationMethod,
+) -> sitk.Transform:
+    """Register the moving image to the fixed image and return the transformation.
+
+    Args:
+        moving_image (sitk.Image): The moving image.
+        fixed_image (sitk.Image): The fixed image.
+        registration_type (RegistrationType): The registration type.
+        registration_method (sitk.ImageRegistrationMethod): The registration method.
+
+    Returns:
+        sitk.Transform: The registration transformation.
+    """
+    if moving_image.GetDimension() != fixed_image.GetDimension():
+        raise ValueError("The floating and fixed image dimensions do not match!")
+
+    dims = moving_image.GetDimension()
+    if dims not in (2, 3):
+        raise ValueError("The image must have 2 or 3 dimensions. Different number of dimensions are not supported!")
+
+    moving_image_f32 = sitk.Cast(moving_image, sitk.sitkFloat32)
+    fixed_image_f32 = sitk.Cast(fixed_image, sitk.sitkFloat32)
+
+    if registration_type == RegistrationType.BSPLINE:
+        transform_domain_mesh_size = [10] * dims
+        initial_transform = sitk.BSplineTransformInitializer(fixed_image, transform_domain_mesh_size)
+    else:
+        if registration_type == RegistrationType.RIGID:
+            transform_type = sitk.VersorRigid3DTransform() if dims == 3 else sitk.Euler2DTransform()
+
+        elif registration_type == RegistrationType.AFFINE:
+            transform_type = sitk.AffineTransform(dims)
+
+        elif registration_type == RegistrationType.SIMILARITY:
+            transform_type = sitk.Similarity3DTransform() if dims == 3 else sitk.Similarity2DTransform()
+
+        else:
+            raise ValueError(f"The registration type ({registration_type.name}) is not supported!")
+
+        initial_transform = sitk.CenteredTransformInitializer(
+            fixed_image_f32, moving_image_f32, transform_type, sitk.CenteredTransformInitializerFilter.GEOMETRY
+        )
+
+    registration_method.SetInitialTransform(initial_transform, inPlace=True)
+
+    transform = registration_method.Execute(fixed_image_f32, moving_image_f32)
+
+    return transform
+
+
+# pylint: disable = too-few-public-methods
+class IntraSubjectRegistrationFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.registration.IntraSubjectRegistrationFilter` class.
+
+    Args:
+        reference_modality (Union[Modality, str]): The reference modality.
+        registration_type (RegistrationType): The type of registration (default: RegistrationType.RIGID).
+        number_of_histogram_bins (int): The number of histogram bins for registration (default: 200).
+        learning_rate (float): The learning rate of the optimizer (default: 1.0).
+        step_size (float): The step size of the optimizer (default: 0.001).
+        number_of_iterations (int): The maximal number of optimization iterations (default: 1500).
+        relaxation_factor (float): The relaxation factor (default: 0.5).
+        shrink_factors (Tuple[int, ...): The shrink factors for the image pyramid (default: (2, 2, 1))).
+        smoothing_sigmas (Tuple[float, ...]): The smoothing sigmas (default: (2, 1, 0))).
+        sampling_percentage (float): The sampling percentage of the voxels to incorporate into the optimization
+         (default: 0.2).
+        resampling_interpolator (int): The resampling interpolator (default: sitk.sitkBSpline).
+        deterministic (bool): Deterministic processing with a fixed seed and a single thread (default: True).
+    """
+
+    def __init__(
+        self,
+        reference_modality: Union[Modality, str],
+        registration_type: RegistrationType = RegistrationType.RIGID,
+        number_of_histogram_bins: int = 200,
+        learning_rate: float = 1.0,
+        step_size: float = 0.001,
+        number_of_iterations: int = 1500,
+        relaxation_factor: float = 0.5,
+        shrink_factors: Tuple[int, ...] = (2, 2, 1),
+        smoothing_sigmas: Tuple[float, ...] = (2, 1, 0),
+        sampling_percentage: float = 0.2,
+        resampling_interpolator: int = sitk.sitkBSpline,
+        deterministic: bool = True,
+    ) -> None:
+        super().__init__()
+
+        if len(shrink_factors) != len(smoothing_sigmas):
+            raise ValueError("The shrink_factors and smoothing_sigmas need to have the same length!")
+
+        self.reference_modality: Modality = str_to_modality(reference_modality)
+        self.registration_type = registration_type
+        self.number_of_histogram_bins = number_of_histogram_bins
+        self.learning_rate = learning_rate
+        self.step_size = step_size
+        self.number_of_iterations = number_of_iterations
+        self.relaxation_factor = relaxation_factor
+        self.shrink_factors: Tuple[int, ...] = shrink_factors
+        self.smoothing_sigmas: Tuple[float, ...] = smoothing_sigmas
+        self.sampling_percentage = sampling_percentage
+        self.resampling_interpolator = resampling_interpolator
+        self.deterministic = deterministic
+
+
+class IntraSubjectRegistrationFilter(Filter):
+    """An invertible intra-subject registration filter class which registers all
+    :class:`~pyradise.data.image.IntensityImage` instances to a reference :class:`~pyradise.data.image.IntensityImage`
+    instance.
+
+    Important:
+        This filter assumes that the :class:`~pyradise.data.image.SegmentationImage` instances are already registered
+        to the reference :class:`~pyradise.data.image.IntensityImage` instance. No transformation will be applied to
+        the :class:`~pyradise.data.image.SegmentationImage` instances.
+
+    Warning:
+        The inverse registration procedure may not yield the expected results if successive
+        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
+        Thus, it's recommended to use the invertibility feature with appropriate caution.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Return whether the filter is invertible or not.
+
+        Returns:
+            bool: True because the registration filter is invertible.
+        """
+        return True
+
+    # noinspection DuplicatedCode
+    def _process_image(
+        self,
+        moving_image: Image,
+        fixed_image: sitk.Image,
+        params: IntraSubjectRegistrationFilterParams,
+        transform: Optional[sitk.Transform] = None,
+        track_infos: bool = True,
+    ) -> Image:
+        """Apply the transformation or register the image to the reference image.
+
+        Args:
+            moving_image (Image): The moving image.
+            fixed_image (sitk.Image): The fixed image.
+            params (IntraSubjectRegistrationFilterParams): The filter parameters.
+            transform (Optional[sitk.Transform]): The transformation to apply to the image (default: None).
+            track_infos (bool): Whether to track the processing information or not (default: True).
+
+        Returns:
+            Image: The registered image.
+        """
+        # get the moving image as SimpleITK image
+        moving_image_sitk = moving_image.get_image_data()
+
+        # cast the image if its pixels are not of type float32
+        if isinstance(moving_image, IntensityImage):
+            moving_image_sitk = sitk.Cast(moving_image_sitk, sitk.sitkFloat32)
+            fixed_image = sitk.Cast(fixed_image, sitk.sitkFloat32)
+
+        # register the moving image to the fixed image if no transform is given
+        if transform is None:
+            # get the registration method
+            registration_method = get_registration_method(
+                params.registration_type,
+                params.number_of_histogram_bins,
+                params.learning_rate,
+                params.step_size,
+                params.number_of_iterations,
+                params.relaxation_factor,
+                params.shrink_factors,
+                params.smoothing_sigmas,
+                params.sampling_percentage,
+                params.deterministic,
+            )
+
+            transform = register_images(moving_image_sitk, fixed_image, params.registration_type, registration_method)
+
+        # get the interpolator according to the image type
+        interpolator = get_interpolator(moving_image)
+        if interpolator is None:
+            return moving_image
+
+        # resample the moving image
+        min_intensity = float(np.min(sitk.GetArrayFromImage(moving_image_sitk)))
+        new_image_sitk = sitk.Resample(
+            moving_image_sitk, fixed_image, transform, interpolator, min_intensity, moving_image_sitk.GetPixelIDValue()
+        )
+
+        # set the new image data to the image
+        moving_image.set_image_data(new_image_sitk)
+
+        # track the necessary information
+        if track_infos:
+            self.tracking_data.update(
+                {
+                    "original_origin": moving_image_sitk.GetOrigin(),
+                    "original_spacing": moving_image_sitk.GetSpacing(),
+                    "original_direction": moving_image_sitk.GetDirection(),
+                    "original_size": moving_image_sitk.GetSize(),
+                }
+            )
+            self._register_tracked_data(moving_image, moving_image_sitk, new_image_sitk, params, transform)
+
+        return moving_image
+
+    def execute(self, subject: Subject, params: IntraSubjectRegistrationFilterParams) -> Subject:
+        """Execute the intra-subject registration procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            params (IntraSubjectRegistrationFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with registered
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        # get the reference image
+        reference_image = subject.get_image_by_modality(params.reference_modality)
+        reference_image_sitk = reference_image.get_image_data()
+
+        # perform the registration
+        for image in subject.get_images():
+            if isinstance(image, IntensityImage):
+                if image.get_modality() == params.reference_modality:
+                    continue
+
+                self._process_image(image, reference_image_sitk, params, track_infos=True)
+
+        return subject
+
+    # noinspection DuplicatedCode
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Execute the inverse of the intra-subject registration procedure.
+
+        Args:
+            subject: The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            transform_info: The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with unregistered
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        # construct the original image as a reference
+        original_image_props = transform_info.get_image_properties(pre_transform=True)
+
+        reference_image_np = np.zeros(original_image_props.size[::-1], dtype=float)
+        reference_image_sitk = sitk.GetImageFromArray(reference_image_np)
+        reference_image_sitk.SetOrigin(original_image_props.origin)
+        reference_image_sitk.SetSpacing(original_image_props.spacing)
+        reference_image_sitk.SetDirection(original_image_props.direction)
+
+        # get the inverse transform
+        transform = transform_info.get_transform(True)
+
+        # perform the inverse registration
+        for image in subject.get_images():
+            if target_image is not None and image != target_image:
+                continue
+
+            if isinstance(image, IntensityImage):
+                if image.get_modality() == transform_info.params.reference_modality:
+                    continue
+
+                self._process_image(
+                    image, reference_image_sitk, transform_info.get_params(), transform, track_infos=False
+                )
+
+        return subject
+
+
+# pylint: disable = too-few-public-methods
+class InterSubjectRegistrationFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.registration.InterSubjectRegistrationFilter` class.
+
+    Args:
+        reference_subject (Subject): The reference subject to which the subject will be registered.
+        reference_modality (Union[Modality, str]): The modality of the reference image (fixed image) to be used for
+         registration.
+        subject_modality (Optional[Union[Modality, str]]): The modality of the subject image (moving image) to be used
+         for registration. If ``None``, the same modality as the reference image will be used (default: None).
+        registration_type (RegistrationType): The type of registration (default: RegistrationType.RIGID).
+        number_of_histogram_bins (int): The number of histogram bins for registration (default: 200).
+        learning_rate (float): The learning rate of the optimizer (default: 1.0).
+        step_size (float): The step size of the optimizer (default: 0.001).
+        number_of_iterations (int): The maximal number of optimization iterations (default: 1500).
+        relaxation_factor (float): The relaxation factor (default: 0.5).
+        shrink_factors (Tuple[int, ...): The shrink factors for the image pyramid (default: (2, 2, 1))).
+        smoothing_sigmas (Tuple[float, ...]): The smoothing sigmas (default: (2, 1, 0))).
+        sampling_percentage (float): The sampling percentage of the voxels to incorporate into the optimization
+         (default: 0.2).
+        resampling_interpolator (int): The interpolator to use for resampling the image.
+        deterministic (bool): Deterministic processing with a fixed seed and a single thread (default: True).
+    """
+
+    # pylint: disable=too-many-instance-attributes, too-many-arguments
+    def __init__(
+        self,
+        reference_subject: Subject,
+        reference_modality: Union[Modality, str],
+        subject_modality: Optional[Union[Modality, str]] = None,
+        registration_type: RegistrationType = RegistrationType.RIGID,
+        number_of_histogram_bins: int = 200,
+        learning_rate: float = 1.0,
+        step_size: float = 0.001,
+        number_of_iterations: int = 1500,
+        relaxation_factor: float = 0.5,
+        shrink_factors: Tuple[int, ...] = (2, 2, 1),
+        smoothing_sigmas: Tuple[float, ...] = (2, 1, 0),
+        sampling_percentage: float = 0.2,
+        resampling_interpolator: int = sitk.sitkBSpline,
+        deterministic: bool = True,
+    ) -> None:
+        super().__init__()
+
+        if len(shrink_factors) != len(smoothing_sigmas):
+            raise ValueError("The shrink_factors and smoothing_sigmas need to have the same length!")
+
+        self.reference_subject = reference_subject
+        self.reference_modality: Modality = str_to_modality(reference_modality)
+        self.subject_modality: Modality = (
+            str_to_modality(subject_modality) if subject_modality is not None else reference_modality
+        )
+        self.registration_type = registration_type
+        self.number_of_histogram_bins = number_of_histogram_bins
+        self.learning_rate = learning_rate
+        self.step_size = step_size
+        self.number_of_iterations = number_of_iterations
+        self.relaxation_factor = relaxation_factor
+        self.shrink_factors: Tuple[int, ...] = shrink_factors
+        self.smoothing_sigmas: Tuple[float, ...] = smoothing_sigmas
+        self.sampling_percentage = sampling_percentage
+        self.resampling_interpolator = resampling_interpolator
+        self.deterministic = deterministic
+
+
+class InterSubjectRegistrationFilter(Filter):
+    """An invertible inter-subject registration filter class which registers all
+    :class:`~pyradise.data.image.IntensityImage` instances of the provided :class:`~pyradise.data.subject.Subject` to a
+    reference :class:`~pyradise.data.image.IntensityImage` instance of another :class:`~pyradise.data.subject.Subject`.
+
+    Important:
+        This filter assumes that all :class:`~pyradise.data.image.Image` instances of the provided
+        :class:`~pyradise.data.subject.Subject` are co-registered such that the
+        :class:`~pyradise.data.image.SegmentationImage` instances do not require special treatment.
+
+    Warning:
+        The inverse registration procedure may not yield the expected results if successive
+        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
+        Thus, it's recommended to use the invertibility feature with appropriate caution.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Return whether the filter is invertible.
+
+        Returns:
+            bool: True because the inter-subject registration is invertible.
+        """
+        return True
+
+    # noinspection DuplicatedCode
+    def _apply_transform(
+        self,
+        subject: Subject,
+        transform: sitk.Transform,
+        reference_image: sitk.Image,
+        params: InterSubjectRegistrationFilterParams,
+    ) -> Subject:
+        """Apply the provided transformation to the subject.
+
+        Args:
+            subject (Subject): The subject.
+            transform (sitk.Transform): The transformation to apply to the subject.
+            reference_image (sitk.Image): The reference image.
+            params (InterSubjectRegistrationFilterParams): The filters parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with transformed
+            :class:`~pyradise.data.image.Image` instances.
+        """
+        # transform and resample the images
+        for image in subject.get_images():
+            interpolator = get_interpolator(image)
+            if interpolator is None:
+                continue
+
+            # get the image data and cast if necessary
+            image_sitk = image.get_image_data()
+            if isinstance(image, IntensityImage):
+                image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
+
+            # resample the image
+            min_intensity = float(np.min(sitk.GetArrayFromImage(image_sitk)))
+            new_image_sitk = sitk.Resample(
+                image_sitk, reference_image, transform, interpolator, min_intensity, image_sitk.GetPixelIDValue()
+            )
+
+            # set the new image data to the image
+            image.set_image_data(new_image_sitk)
+
+            # track the necessary data
+            self._register_tracked_data(image, image_sitk, new_image_sitk, params, transform)
+
+        return subject
+
+    # noinspection DuplicatedCode
+    @staticmethod
+    def _apply_inverse_transform(
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Apply the inverse transformation to the subject.
+
+        Args:
+            subject (Subject): The subject.
+            transform_info (TransformInfo): The transformation information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with back-transformed
+            :class:`~pyradise.data.image.Image` instances.
+        """
+        # construct the original image as a reference
+        original_image_props = transform_info.get_image_properties(pre_transform=True)
+
+        reference_image_np = np.zeros(original_image_props.size[::-1], dtype=float)
+        reference_image_sitk = sitk.GetImageFromArray(reference_image_np)
+        reference_image_sitk.SetOrigin(original_image_props.origin)
+        reference_image_sitk.SetSpacing(original_image_props.spacing)
+        reference_image_sitk.SetDirection(original_image_props.direction)
+
+        # get the inverse transform
+        transform = transform_info.get_transform(True)
+
+        # transform and resample the images
+        for image in subject.get_images():
+            if target_image is not None and image != target_image:
+                continue
+
+            # get the image data and cast if necessary
+            image_sitk = image.get_image_data()
+            if isinstance(image, IntensityImage):
+                image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
+
+            # the interpolator
+            interpolator = get_interpolator(image)
+            if interpolator is None:
+                continue
+
+            # resample the image
+            min_intensity = float(np.min(sitk.GetArrayFromImage(image_sitk)))
+            new_image_sitk = sitk.Resample(
+                image_sitk, reference_image_sitk, transform, interpolator, min_intensity, image_sitk.GetPixelIDValue()
+            )
+
+            # set the new image data to the image
+            image.set_image_data(new_image_sitk)
+
+        return subject
+
+    @staticmethod
+    def _register_image(
+        subject: Subject, reference_image: sitk.Image, params: InterSubjectRegistrationFilterParams
+    ) -> sitk.Transform:
+        """Register the subject image to the specific modality of the reference subject.
+
+        Args:
+            subject (Subject): The subject to register.
+            reference_image (sitk.Image): The reference image.
+            params (InterSubjectRegistrationFilterParams): The filters parameters.
+
+        Returns:
+            sitk.Transform: The registration transformation.
+        """
+        moving_image = subject.get_image_by_modality(params.subject_modality)
+        moving_image_sitk = moving_image.get_image_data()
+
+        # get the registration method
+        registration_method = get_registration_method(
+            params.registration_type,
+            params.number_of_histogram_bins,
+            params.learning_rate,
+            params.step_size,
+            params.number_of_iterations,
+            params.relaxation_factor,
+            params.shrink_factors,
+            params.smoothing_sigmas,
+            params.sampling_percentage,
+            params.deterministic,
+        )
+
+        return register_images(moving_image_sitk, reference_image, params.registration_type, registration_method)
+
+    def execute(self, subject: Subject, params: InterSubjectRegistrationFilterParams) -> Subject:
+        """Executes the inter-subject registration procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            params (InterSubjectRegistrationFilterParams): The filter parameters.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with all
+            :class:`~pyradise.data.image.IntensityImage` instances registered to the reference subject
+            :class:`~pyradise.data.image.IntensityImage` instance.
+        """
+        # get the reference image
+        reference_image = params.reference_subject.get_image_by_modality(params.reference_modality)
+        reference_image_sitk = reference_image.get_image_data()
+
+        # register the subject to the reference image
+        transform = self._register_image(subject, reference_image_sitk, params)
+
+        # apply the transform to the other images of the subject
+        subject = self._apply_transform(subject, transform, reference_image_sitk, params)
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Execute the inverse of the inter-subject registration procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with unregistered
+            :class:`~pyradise.data.image.IntensityImage` instances.
+        """
+        subject = self._apply_inverse_transform(subject, transform_info, target_image)
+
+        return subject
```

### Comparing `pyradise-0.2.2/pyradise/process/resampling.py` & `pyradise-0.2.3/pyradise/process/resampling.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,490 +1,490 @@
-from typing import Optional, Sequence, Tuple, Union
-
-import itk
-import numpy as np
-import SimpleITK as sitk
-
-from pyradise.data import (IntensityImage, Modality, SegmentationImage,
-                           Subject, TransformInfo, str_to_modality)
-
-from .base import Filter, FilterParams
-
-__all__ = ["ResampleFilterParams", "ResampleFilter"]
-
-
-# pylint: disable = too-few-public-methods
-class ResampleFilterParams(FilterParams):
-    """A filter parameter class for the :class:`~pyradise.process.resampling.ResampleFilter` class.
-
-    The associated filter provides the following three ``centering_methods`` for resampling images:
-
-    * The ``none`` centering_method resamples an image such that the output origin and direction does not change.
-    * The ``reference`` centering_method resamples an image such that the output origin and direction is the same as
-      the reference image (identified by the reference images modality).
-    * The ``label_moment`` centering_method resamples an image such that the center of the resampled image is the
-      average between the label center and the gravity center of the reference image. This method is a good approach
-      for resampling data with bilateral and symmetric segmentations. However, it is an experimental method and should
-      be used with caution.
-
-    Args:
-        output_size (Optional[Tuple[int, ...]]) : The output size of the images.
-        output_spacing (Optional[Tuple[float, ...]]): The output spacing of the images.
-        reference_modality (Optional[Union[Modality, str]]): The reference modality used if ``centering_method =
-         'reference'`` or ``centering_method = 'label_moment'`` (default: None).
-        transform (sitk.Transform): The transformation applied during resampling
-         (default: sitk.AffineTransform(3) (identity transform)).
-        centering_method (str): The method to center the image (options: 'none', 'reference', 'label_moment')
-         (default: 'none').
-        rescaling_intensity_images (bool): If True the intensity images will be automatically rescaled to the original
-         intensity range (default: True).
-    """
-
-    def __init__(
-        self,
-        output_size: Optional[Tuple[int, ...]],
-        output_spacing: Optional[Tuple[float, ...]],
-        reference_modality: Optional[Union[Modality, str]] = None,
-        transform: sitk.Transform = sitk.AffineTransform(3),
-        centering_method: str = "none",
-        rescaling_intensity_images: bool = True,
-    ) -> None:
-        super().__init__()
-
-        if centering_method not in ("none", "reference", "label_moment"):
-            raise ValueError(f"The centering method ({centering_method}) is invalid!")
-
-        if centering_method in ("reference", "label_moment") and reference_modality is None:
-            raise ValueError(f"A reference modality must be provided!")
-
-        self.output_size = output_size
-        self.output_spacing = output_spacing
-
-        if reference_modality is not None:
-            self.reference_modality: Optional[Modality] = str_to_modality(reference_modality)
-        else:
-            self.reference_modality: Optional[Modality] = reference_modality
-
-        self.transform = transform
-        self.centering_method = centering_method
-        self.rescaling_intensity_images = rescaling_intensity_images
-
-
-class ResampleFilter(Filter):
-    """An invertible filter class for resampling all :class:`~pyradise.data.image.IntensityImage` and
-    :class:`~pyradise.data.image.SegmentationImage` instances of a :class:`~pyradise.data.subject.Subject` instance.
-
-    Warning:
-        The inverse resampling procedure may not yield the expected results if successive
-        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
-        Thus, it's recommended to use the invertibility feature with appropriate caution.
-
-    Note:
-        Due to the limited precision of floating point numbers, the inverse normalization may not be exact.
-    """
-
-    @staticmethod
-    def is_invertible() -> bool:
-        """Returns whether the filter is invertible or not.
-
-        Returns:
-            bool: True because the resampling of images is invertible.
-        """
-        return True
-
-    @staticmethod
-    def _get_label_center(images: Optional[Sequence[SegmentationImage]]) -> np.ndarray:
-        """Get the label center of the provided segmentation images.
-
-        This method computes the label center by calculating first the bounding box limits of all labels. Subsequently,
-        for each label the center of both points is computed by averaging the coordinates. Finally, the center of all
-        labels is computed by averaging the coordinates of all label centers.
-
-        Args:
-            images (Optional[Sequence[SegmentationImage]]): The segmentation images used for calculating the label
-             center.
-
-        Returns:
-            np.ndarray: An array with the physical coordinates of label center.
-        """
-        # if no segmentation images are provided raise an error
-        if not images:
-            raise ValueError("No segmentation images are provided for the label center computation!")
-
-        # compute the average label center
-        bounding_box = []
-        for image in images:
-            image_sitk = image.get_image_data()
-            num_dims = image_sitk.GetDimension()
-
-            filter_ = sitk.LabelShapeStatisticsImageFilter()
-            filter_.Execute(image_sitk)
-
-            label_ids = filter_.GetLabels()
-            for label_idx in label_ids:
-                bounds = filter_.GetBoundingBox(label_idx)
-                physical_bound_0 = image_sitk.TransformIndexToPhysicalPoint(bounds[0:num_dims])
-                physical_bound_1 = image_sitk.TransformIndexToPhysicalPoint(bounds[num_dims : 2 * num_dims])
-                bounding_box.append([physical_bound_0, physical_bound_1])
-
-        bounding_box = np.array(bounding_box)
-        label_centers = (bounding_box[:, 0, :] + bounding_box[:, 1, :]) / 2
-        label_center = np.mean(label_centers, axis=0)
-
-        return label_center
-
-    @staticmethod
-    def _get_label_moment_origin(
-        image: IntensityImage, params: ResampleFilterParams, label_center: np.ndarray
-    ) -> np.ndarray:
-        """Get the origin of the label moment centering.
-
-        This method computes the average between the image gravity center and the label center and calculates the
-        corresponding image origin.
-
-        Args:
-            image (IntensityImage): The intensity image used for the moment calculation.
-            params (ResampleFilterParams): The resampling filter parameters.
-            label_center (np.ndarray): The label center.
-
-        Returns:
-            np.ndarray: The moment around the center.
-        """
-        # compute the image center of gravity
-        image_itk = image.get_image_data(as_sitk=False)
-        image_type = image.get_image_itk_type()
-        moment_calc = itk.ImageMomentsCalculator[image_type].New()
-        moment_calc.SetImage(image_itk)
-        moment_calc.Compute()
-        image_moment_center = np.array(moment_calc.GetCenterOfGravity())
-
-        # compute the average between the image center of gravity and the label center
-        center = (image_moment_center + label_center) / 2
-
-        # compute the origin
-        physical_image_center = np.array(params.output_spacing) * (np.array(params.output_size) // 2)
-        origin = center - np.dot(image.get_direction(), physical_image_center)
-
-        return origin
-
-    # noinspection DuplicatedCode
-    def _process_intensity_image(
-        self,
-        image: IntensityImage,
-        reference_image: Optional[IntensityImage],
-        params: ResampleFilterParams,
-        segmentation_images: Optional[Sequence[SegmentationImage]] = None,
-    ) -> IntensityImage:
-        """Apply the resampling on an :class:`~pyradise.data.image.IntensityImage` instance.
-
-        Args:
-            image (IntensityImage): The intensity image to resample.
-            reference_image (Optional[IntensityImage]): The reference image.
-            params (ResampleFilterParams): The parameters for the resampling.
-            segmentation_images (Optional[Sequence[SegmentationImage]]): Segmentation images used for the moment
-             calculation (default: None).
-
-        Returns:
-            IntensityImage: The resampled intensity image.
-        """
-        # get the image data of the moving and fixed image as SimpleITK images
-        image_sitk = image.get_image_data()
-
-        # cast the image to a float image
-        if image_sitk.GetPixelID() != sitk.sitkFloat32:
-            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
-
-        # get the minimum and maximum intensity values
-        image_np = sitk.GetArrayFromImage(image_sitk)
-        min_intensity = float(np.min(image_np))
-        max_intensity = float(np.max(image_np))
-
-        # get the output origin and direction
-        if params.centering_method == "none":
-            output_origin = image_sitk.GetOrigin()
-            output_direction = image_sitk.GetDirection()
-            output_size = image_sitk.GetSize()
-            output_spacing = image_sitk.GetSpacing()
-
-        elif params.centering_method == "reference":
-            if reference_image is None:
-                raise ValueError(
-                    'The reference image must be provided for the centering method "reference" and ' '"label_moment"!'
-                )
-            reference_image_sitk = reference_image.get_image_data()
-            output_origin = reference_image_sitk.GetOrigin()
-            output_direction = reference_image_sitk.GetDirection()
-            output_size = reference_image_sitk.GetSize()
-            output_spacing = reference_image_sitk.GetSpacing()
-
-        elif params.centering_method == "label_moment":
-            if reference_image is None:
-                raise ValueError(
-                    'The reference image must be provided for the centering method "reference" and ' '"label_moment"!'
-                )
-            reference_image_sitk = reference_image.get_image_data()
-            output_size = reference_image_sitk.GetSize()
-            output_spacing = reference_image_sitk.GetSpacing()
-
-            if reference_image == image:
-                label_center = self._get_label_center(segmentation_images)
-                label_moment_origin = self._get_label_moment_origin(image, params, label_center)
-
-                output_origin = label_moment_origin
-                output_direction = reference_image_sitk.GetDirection()
-            else:
-                output_origin = reference_image_sitk.GetOrigin()
-                output_direction = reference_image_sitk.GetDirection()
-
-        else:
-            raise NotImplementedError(f"The centering method ({params.centering_method}) is not supported!")
-
-        # apply the resampling filter
-        resample_filter = sitk.ResampleImageFilter()
-        resample_filter.SetInterpolator(sitk.sitkBSpline)
-        resample_filter.SetTransform(params.transform)
-        resample_filter.SetDefaultPixelValue(min_intensity)
-        resample_filter.SetOutputOrigin(output_origin)
-        resample_filter.SetOutputDirection(output_direction)
-
-        if params.output_spacing:
-            resample_filter.SetOutputSpacing(params.output_spacing)
-        else:
-            resample_filter.SetOutputSpacing(output_spacing)
-
-        if params.output_size:
-            resample_filter.SetSize(params.output_size)
-        else:
-            resample_filter.SetSize(output_size)
-
-        new_image_sitk = resample_filter.Execute(image_sitk)
-
-        # rescale the image to the original intensity range
-        if params.rescaling_intensity_images:
-            rescale_filter = sitk.RescaleIntensityImageFilter()
-            rescale_filter.SetOutputMinimum(min_intensity)
-            rescale_filter.SetOutputMaximum(max_intensity)
-            new_image_sitk = rescale_filter.Execute(new_image_sitk)
-
-        # add the new image data to the intensity image
-        image.set_image_data(new_image_sitk)
-
-        # track the necessary parameters
-        self.tracking_data["min_intensity"] = min_intensity
-        self.tracking_data["max_intensity"] = max_intensity
-        self.tracking_data["is_intensity"] = True
-        self._register_tracked_data(image, image_sitk, new_image_sitk, params, params.transform)
-
-        return image
-
-    @staticmethod
-    def _inverse_process_intensity_image(image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
-        """Apply the inverse resampling on an :class:`~pyradise.data.image.IntensityImage` instance.
-
-        Args:
-            image (IntensityImage): The intensity image to inversely resample.
-            transform_info (TransformInfo): The transform information.
-
-        Returns:
-            IntensityImage: The inversely resampled intensity image.
-        """
-        # get the image data and the pre-transform image properties
-        image_sik = image.get_image_data()
-        pre_transform_props = transform_info.get_image_properties(True)
-
-        # apply the resampling filter
-        resample_filter = sitk.ResampleImageFilter()
-        resample_filter.SetInterpolator(sitk.sitkBSpline)
-        resample_filter.SetTransform(transform_info.get_transform(True))
-        resample_filter.SetDefaultPixelValue(float(transform_info.get_data("min_intensity")))
-        resample_filter.SetOutputOrigin(pre_transform_props.origin)
-        resample_filter.SetOutputDirection(pre_transform_props.direction)
-        resample_filter.SetOutputSpacing(pre_transform_props.spacing)
-        resample_filter.SetSize(pre_transform_props.size)
-
-        new_image_sitk = resample_filter.Execute(image_sik)
-
-        # rescale the image to the original intensity range (if necessary)
-        params = transform_info.get_params()
-        if params.rescaling_intensity_images:
-            rescale_filter = sitk.RescaleIntensityImageFilter()
-            rescale_filter.SetOutputMinimum(transform_info.get_data("min_intensity"))
-            rescale_filter.SetOutputMaximum(transform_info.get_data("max_intensity"))
-            new_image_sitk = rescale_filter.Execute(new_image_sitk)
-
-        # set the new image data to the intensity image
-        image.set_image_data(new_image_sitk)
-
-        return image
-
-    # noinspection DuplicatedCode
-    def _process_segmentation_image(
-        self,
-        image: SegmentationImage,
-        reference_image: Optional[IntensityImage],
-        params: ResampleFilterParams,
-    ) -> SegmentationImage:
-        """Apply the resampling on an :class:`~pyradise.data.image.SegmentationImage` instance.
-
-        Args:
-            image (SegmentationImage): The image to resample.
-            reference_image (Optional[IntensityImage]): The reference image.
-            params (ResampleFilterParams): The parameters for the resampling.
-
-        Returns:
-            SegmentationImage: The resampled segmentation image.
-        """
-        # get the image data of the moving and fixed image as SimpleITK images
-        image_sitk = image.get_image_data()
-
-        # get the output origin and direction
-        if params.centering_method == "none":
-            output_origin = image_sitk.GetOrigin()
-            output_direction = image_sitk.GetDirection()
-            output_size = image_sitk.GetSize()
-            output_spacing = image_sitk.GetSpacing()
-
-        elif params.centering_method in ("reference", "label_moment"):
-            if reference_image is None:
-                raise ValueError(
-                    'The reference image must be provided for the centering method "reference" and ' '"label_moment"!'
-                )
-            reference_image_sitk = reference_image.get_image_data()
-            output_origin = reference_image_sitk.GetOrigin()
-            output_direction = reference_image_sitk.GetDirection()
-            output_size = reference_image_sitk.GetSize()
-            output_spacing = reference_image_sitk.GetSpacing()
-
-        else:
-            raise NotImplementedError(f"The centering method ({params.centering_method}) is invalid!")
-
-        # apply the resampling filter
-        resample_filter = sitk.ResampleImageFilter()
-        resample_filter.SetInterpolator(sitk.sitkNearestNeighbor)
-        resample_filter.SetTransform(params.transform)
-        resample_filter.SetDefaultPixelValue(0)
-        resample_filter.SetOutputOrigin(output_origin)
-        resample_filter.SetOutputDirection(output_direction)
-
-        if params.output_spacing:
-            resample_filter.SetOutputSpacing(params.output_spacing)
-        else:
-            resample_filter.SetOutputSpacing(output_spacing)
-
-        if params.output_size:
-            resample_filter.SetSize(params.output_size)
-        else:
-            resample_filter.SetSize(output_size)
-
-        new_image_sitk = resample_filter.Execute(image_sitk)
-
-        # add the new image data to the segmentation image
-        image.set_image_data(new_image_sitk)
-
-        # track the necessary parameters
-        self.tracking_data["min_intensity"] = 0.0
-        self.tracking_data["max_intensity"] = 1.0
-        self.tracking_data["is_intensity"] = False
-        self._register_tracked_data(image, image_sitk, new_image_sitk, params, params.transform)
-
-        return image
-
-    @staticmethod
-    def _inverse_process_segmentation_image(
-        image: SegmentationImage, transform_info: TransformInfo
-    ) -> SegmentationImage:
-        """Apply the inverse resampling on an :class:`~pyradise.data.image.SegmentationImage` instance.
-
-        Args:
-            image (SegmentationImage): The image to resample.
-            transform_info (TransformInfo): The transform information.
-
-        Returns:
-            SegmentationImage: The inversely resampled segmentation image.
-        """
-        # get the image data and the pre-transform image properties
-        image_sik = image.get_image_data()
-        pre_transform_props = transform_info.get_image_properties(True)
-
-        # apply the resampling filter
-        resample_filter = sitk.ResampleImageFilter()
-        resample_filter.SetInterpolator(sitk.sitkNearestNeighbor)
-        resample_filter.SetTransform(transform_info.get_transform(True))
-        resample_filter.SetDefaultPixelValue(0)
-        resample_filter.SetOutputOrigin(pre_transform_props.origin)
-        resample_filter.SetOutputDirection(pre_transform_props.direction)
-        resample_filter.SetOutputSpacing(pre_transform_props.spacing)
-        resample_filter.SetSize(pre_transform_props.size)
-
-        new_image_sitk = resample_filter.Execute(image_sik)
-
-        # set the new image data to the intensity image
-        image.set_image_data(new_image_sitk)
-
-        return image
-
-    def execute(self, subject: Subject, params: ResampleFilterParams) -> Subject:
-        """Executes the resampling filter procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            params (ResampleFilterParams): The parameters used for the resampling.
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with resampled
-            :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-        # get the segmentation images
-        segmentation_images = subject.get_images_by_type(SegmentationImage)
-        segmentation_images = [img for img in segmentation_images if isinstance(img, SegmentationImage)]
-
-        # get the reference images if necessary
-        if params.centering_method != "none":
-            # resample the reference intensity image
-            ref_image = subject.get_image_by_modality(params.reference_modality)
-            self._process_intensity_image(ref_image, ref_image, params, segmentation_images)
-        else:
-            ref_image = None
-
-        # resample the intensity images
-        for image in subject.intensity_images:
-            # exclude the reference image if not centering_method == 'none'
-            if params.centering_method != "none":
-                if image.get_modality() == params.reference_modality:
-                    continue
-
-            self._process_intensity_image(image, ref_image, params, segmentation_images)
-
-        # resample the segmentation images
-        for image in subject.segmentation_images:
-            self._process_segmentation_image(image, ref_image, params)
-
-        return subject
-
-    def execute_inverse(
-        self,
-        subject: Subject,
-        transform_info: TransformInfo,
-        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
-    ) -> Subject:
-        """Executes the inverse resampling filter procedure.
-
-        Args:
-            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
-            transform_info (TransformInfo): The transform information.
-            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
-             transformation should be applied. If None, the inverse transformation is applied to all images (default:
-             None).
-
-        Returns:
-            Subject: The :class:`~pyradise.data.subject.Subject` instance with inversely resampled
-            :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instances.
-        """
-        for image in subject.intensity_images:
-            if target_image is None or image == target_image:
-                self._inverse_process_intensity_image(image, transform_info)
-
-        for image in subject.segmentation_images:
-            if target_image is None or image == target_image:
-                self._inverse_process_segmentation_image(image, transform_info)
-
-        return subject
+from typing import Optional, Sequence, Tuple, Union
+
+import itk
+import numpy as np
+import SimpleITK as sitk
+
+from pyradise.data import (IntensityImage, Modality, SegmentationImage,
+                           Subject, TransformInfo, str_to_modality)
+
+from .base import Filter, FilterParams
+
+__all__ = ["ResampleFilterParams", "ResampleFilter"]
+
+
+# pylint: disable = too-few-public-methods
+class ResampleFilterParams(FilterParams):
+    """A filter parameter class for the :class:`~pyradise.process.resampling.ResampleFilter` class.
+
+    The associated filter provides the following three ``centering_methods`` for resampling images:
+
+    * The ``none`` centering_method resamples an image such that the output origin and direction does not change.
+    * The ``reference`` centering_method resamples an image such that the output origin and direction is the same as
+      the reference image (identified by the reference images modality).
+    * The ``label_moment`` centering_method resamples an image such that the center of the resampled image is the
+      average between the label center and the gravity center of the reference image. This method is a good approach
+      for resampling data with bilateral and symmetric segmentations. However, it is an experimental method and should
+      be used with caution.
+
+    Args:
+        output_size (Optional[Tuple[int, ...]]) : The output size of the images.
+        output_spacing (Optional[Tuple[float, ...]]): The output spacing of the images.
+        reference_modality (Optional[Union[Modality, str]]): The reference modality used if ``centering_method =
+         'reference'`` or ``centering_method = 'label_moment'`` (default: None).
+        transform (sitk.Transform): The transformation applied during resampling
+         (default: sitk.AffineTransform(3) (identity transform)).
+        centering_method (str): The method to center the image (options: 'none', 'reference', 'label_moment')
+         (default: 'none').
+        rescaling_intensity_images (bool): If True the intensity images will be automatically rescaled to the original
+         intensity range (default: True).
+    """
+
+    def __init__(
+        self,
+        output_size: Optional[Tuple[int, ...]],
+        output_spacing: Optional[Tuple[float, ...]],
+        reference_modality: Optional[Union[Modality, str]] = None,
+        transform: sitk.Transform = sitk.AffineTransform(3),
+        centering_method: str = "none",
+        rescaling_intensity_images: bool = True,
+    ) -> None:
+        super().__init__()
+
+        if centering_method not in ("none", "reference", "label_moment"):
+            raise ValueError(f"The centering method ({centering_method}) is invalid!")
+
+        if centering_method in ("reference", "label_moment") and reference_modality is None:
+            raise ValueError(f"A reference modality must be provided!")
+
+        self.output_size = output_size
+        self.output_spacing = output_spacing
+
+        if reference_modality is not None:
+            self.reference_modality: Optional[Modality] = str_to_modality(reference_modality)
+        else:
+            self.reference_modality: Optional[Modality] = reference_modality
+
+        self.transform = transform
+        self.centering_method = centering_method
+        self.rescaling_intensity_images = rescaling_intensity_images
+
+
+class ResampleFilter(Filter):
+    """An invertible filter class for resampling all :class:`~pyradise.data.image.IntensityImage` and
+    :class:`~pyradise.data.image.SegmentationImage` instances of a :class:`~pyradise.data.subject.Subject` instance.
+
+    Warning:
+        The inverse resampling procedure may not yield the expected results if successive
+        :class:`~pyradise.process.base.Filter` s are applied to the same :class:`~pyradise.data.image.Image` instances.
+        Thus, it's recommended to use the invertibility feature with appropriate caution.
+
+    Note:
+        Due to the limited precision of floating point numbers, the inverse normalization may not be exact.
+    """
+
+    @staticmethod
+    def is_invertible() -> bool:
+        """Returns whether the filter is invertible or not.
+
+        Returns:
+            bool: True because the resampling of images is invertible.
+        """
+        return True
+
+    @staticmethod
+    def _get_label_center(images: Optional[Sequence[SegmentationImage]]) -> np.ndarray:
+        """Get the label center of the provided segmentation images.
+
+        This method computes the label center by calculating first the bounding box limits of all labels. Subsequently,
+        for each label the center of both points is computed by averaging the coordinates. Finally, the center of all
+        labels is computed by averaging the coordinates of all label centers.
+
+        Args:
+            images (Optional[Sequence[SegmentationImage]]): The segmentation images used for calculating the label
+             center.
+
+        Returns:
+            np.ndarray: An array with the physical coordinates of label center.
+        """
+        # if no segmentation images are provided raise an error
+        if not images:
+            raise ValueError("No segmentation images are provided for the label center computation!")
+
+        # compute the average label center
+        bounding_box = []
+        for image in images:
+            image_sitk = image.get_image_data()
+            num_dims = image_sitk.GetDimension()
+
+            filter_ = sitk.LabelShapeStatisticsImageFilter()
+            filter_.Execute(image_sitk)
+
+            label_ids = filter_.GetLabels()
+            for label_idx in label_ids:
+                bounds = filter_.GetBoundingBox(label_idx)
+                physical_bound_0 = image_sitk.TransformIndexToPhysicalPoint(bounds[0:num_dims])
+                physical_bound_1 = image_sitk.TransformIndexToPhysicalPoint(bounds[num_dims : 2 * num_dims])
+                bounding_box.append([physical_bound_0, physical_bound_1])
+
+        bounding_box = np.array(bounding_box)
+        label_centers = (bounding_box[:, 0, :] + bounding_box[:, 1, :]) / 2
+        label_center = np.mean(label_centers, axis=0)
+
+        return label_center
+
+    @staticmethod
+    def _get_label_moment_origin(
+        image: IntensityImage, params: ResampleFilterParams, label_center: np.ndarray
+    ) -> np.ndarray:
+        """Get the origin of the label moment centering.
+
+        This method computes the average between the image gravity center and the label center and calculates the
+        corresponding image origin.
+
+        Args:
+            image (IntensityImage): The intensity image used for the moment calculation.
+            params (ResampleFilterParams): The resampling filter parameters.
+            label_center (np.ndarray): The label center.
+
+        Returns:
+            np.ndarray: The moment around the center.
+        """
+        # compute the image center of gravity
+        image_itk = image.get_image_data(as_sitk=False)
+        image_type = image.get_image_itk_type()
+        moment_calc = itk.ImageMomentsCalculator[image_type].New()
+        moment_calc.SetImage(image_itk)
+        moment_calc.Compute()
+        image_moment_center = np.array(moment_calc.GetCenterOfGravity())
+
+        # compute the average between the image center of gravity and the label center
+        center = (image_moment_center + label_center) / 2
+
+        # compute the origin
+        physical_image_center = np.array(params.output_spacing) * (np.array(params.output_size) // 2)
+        origin = center - np.dot(image.get_direction(), physical_image_center)
+
+        return origin
+
+    # noinspection DuplicatedCode
+    def _process_intensity_image(
+        self,
+        image: IntensityImage,
+        reference_image: Optional[IntensityImage],
+        params: ResampleFilterParams,
+        segmentation_images: Optional[Sequence[SegmentationImage]] = None,
+    ) -> IntensityImage:
+        """Apply the resampling on an :class:`~pyradise.data.image.IntensityImage` instance.
+
+        Args:
+            image (IntensityImage): The intensity image to resample.
+            reference_image (Optional[IntensityImage]): The reference image.
+            params (ResampleFilterParams): The parameters for the resampling.
+            segmentation_images (Optional[Sequence[SegmentationImage]]): Segmentation images used for the moment
+             calculation (default: None).
+
+        Returns:
+            IntensityImage: The resampled intensity image.
+        """
+        # get the image data of the moving and fixed image as SimpleITK images
+        image_sitk = image.get_image_data()
+
+        # cast the image to a float image
+        if image_sitk.GetPixelID() != sitk.sitkFloat32:
+            image_sitk = sitk.Cast(image_sitk, sitk.sitkFloat32)
+
+        # get the minimum and maximum intensity values
+        image_np = sitk.GetArrayFromImage(image_sitk)
+        min_intensity = float(np.min(image_np))
+        max_intensity = float(np.max(image_np))
+
+        # get the output origin and direction
+        if params.centering_method == "none":
+            output_origin = image_sitk.GetOrigin()
+            output_direction = image_sitk.GetDirection()
+            output_size = image_sitk.GetSize()
+            output_spacing = image_sitk.GetSpacing()
+
+        elif params.centering_method == "reference":
+            if reference_image is None:
+                raise ValueError(
+                    'The reference image must be provided for the centering method "reference" and ' '"label_moment"!'
+                )
+            reference_image_sitk = reference_image.get_image_data()
+            output_origin = reference_image_sitk.GetOrigin()
+            output_direction = reference_image_sitk.GetDirection()
+            output_size = reference_image_sitk.GetSize()
+            output_spacing = reference_image_sitk.GetSpacing()
+
+        elif params.centering_method == "label_moment":
+            if reference_image is None:
+                raise ValueError(
+                    'The reference image must be provided for the centering method "reference" and ' '"label_moment"!'
+                )
+            reference_image_sitk = reference_image.get_image_data()
+            output_size = reference_image_sitk.GetSize()
+            output_spacing = reference_image_sitk.GetSpacing()
+
+            if reference_image == image:
+                label_center = self._get_label_center(segmentation_images)
+                label_moment_origin = self._get_label_moment_origin(image, params, label_center)
+
+                output_origin = label_moment_origin
+                output_direction = reference_image_sitk.GetDirection()
+            else:
+                output_origin = reference_image_sitk.GetOrigin()
+                output_direction = reference_image_sitk.GetDirection()
+
+        else:
+            raise NotImplementedError(f"The centering method ({params.centering_method}) is not supported!")
+
+        # apply the resampling filter
+        resample_filter = sitk.ResampleImageFilter()
+        resample_filter.SetInterpolator(sitk.sitkBSpline)
+        resample_filter.SetTransform(params.transform)
+        resample_filter.SetDefaultPixelValue(min_intensity)
+        resample_filter.SetOutputOrigin(output_origin)
+        resample_filter.SetOutputDirection(output_direction)
+
+        if params.output_spacing:
+            resample_filter.SetOutputSpacing(params.output_spacing)
+        else:
+            resample_filter.SetOutputSpacing(output_spacing)
+
+        if params.output_size:
+            resample_filter.SetSize(params.output_size)
+        else:
+            resample_filter.SetSize(output_size)
+
+        new_image_sitk = resample_filter.Execute(image_sitk)
+
+        # rescale the image to the original intensity range
+        if params.rescaling_intensity_images:
+            rescale_filter = sitk.RescaleIntensityImageFilter()
+            rescale_filter.SetOutputMinimum(min_intensity)
+            rescale_filter.SetOutputMaximum(max_intensity)
+            new_image_sitk = rescale_filter.Execute(new_image_sitk)
+
+        # add the new image data to the intensity image
+        image.set_image_data(new_image_sitk)
+
+        # track the necessary parameters
+        self.tracking_data["min_intensity"] = min_intensity
+        self.tracking_data["max_intensity"] = max_intensity
+        self.tracking_data["is_intensity"] = True
+        self._register_tracked_data(image, image_sitk, new_image_sitk, params, params.transform)
+
+        return image
+
+    @staticmethod
+    def _inverse_process_intensity_image(image: IntensityImage, transform_info: TransformInfo) -> IntensityImage:
+        """Apply the inverse resampling on an :class:`~pyradise.data.image.IntensityImage` instance.
+
+        Args:
+            image (IntensityImage): The intensity image to inversely resample.
+            transform_info (TransformInfo): The transform information.
+
+        Returns:
+            IntensityImage: The inversely resampled intensity image.
+        """
+        # get the image data and the pre-transform image properties
+        image_sik = image.get_image_data()
+        pre_transform_props = transform_info.get_image_properties(True)
+
+        # apply the resampling filter
+        resample_filter = sitk.ResampleImageFilter()
+        resample_filter.SetInterpolator(sitk.sitkBSpline)
+        resample_filter.SetTransform(transform_info.get_transform(True))
+        resample_filter.SetDefaultPixelValue(float(transform_info.get_data("min_intensity")))
+        resample_filter.SetOutputOrigin(pre_transform_props.origin)
+        resample_filter.SetOutputDirection(pre_transform_props.direction)
+        resample_filter.SetOutputSpacing(pre_transform_props.spacing)
+        resample_filter.SetSize(pre_transform_props.size)
+
+        new_image_sitk = resample_filter.Execute(image_sik)
+
+        # rescale the image to the original intensity range (if necessary)
+        params = transform_info.get_params()
+        if params.rescaling_intensity_images:
+            rescale_filter = sitk.RescaleIntensityImageFilter()
+            rescale_filter.SetOutputMinimum(transform_info.get_data("min_intensity"))
+            rescale_filter.SetOutputMaximum(transform_info.get_data("max_intensity"))
+            new_image_sitk = rescale_filter.Execute(new_image_sitk)
+
+        # set the new image data to the intensity image
+        image.set_image_data(new_image_sitk)
+
+        return image
+
+    # noinspection DuplicatedCode
+    def _process_segmentation_image(
+        self,
+        image: SegmentationImage,
+        reference_image: Optional[IntensityImage],
+        params: ResampleFilterParams,
+    ) -> SegmentationImage:
+        """Apply the resampling on an :class:`~pyradise.data.image.SegmentationImage` instance.
+
+        Args:
+            image (SegmentationImage): The image to resample.
+            reference_image (Optional[IntensityImage]): The reference image.
+            params (ResampleFilterParams): The parameters for the resampling.
+
+        Returns:
+            SegmentationImage: The resampled segmentation image.
+        """
+        # get the image data of the moving and fixed image as SimpleITK images
+        image_sitk = image.get_image_data()
+
+        # get the output origin and direction
+        if params.centering_method == "none":
+            output_origin = image_sitk.GetOrigin()
+            output_direction = image_sitk.GetDirection()
+            output_size = image_sitk.GetSize()
+            output_spacing = image_sitk.GetSpacing()
+
+        elif params.centering_method in ("reference", "label_moment"):
+            if reference_image is None:
+                raise ValueError(
+                    'The reference image must be provided for the centering method "reference" and ' '"label_moment"!'
+                )
+            reference_image_sitk = reference_image.get_image_data()
+            output_origin = reference_image_sitk.GetOrigin()
+            output_direction = reference_image_sitk.GetDirection()
+            output_size = reference_image_sitk.GetSize()
+            output_spacing = reference_image_sitk.GetSpacing()
+
+        else:
+            raise NotImplementedError(f"The centering method ({params.centering_method}) is invalid!")
+
+        # apply the resampling filter
+        resample_filter = sitk.ResampleImageFilter()
+        resample_filter.SetInterpolator(sitk.sitkNearestNeighbor)
+        resample_filter.SetTransform(params.transform)
+        resample_filter.SetDefaultPixelValue(0)
+        resample_filter.SetOutputOrigin(output_origin)
+        resample_filter.SetOutputDirection(output_direction)
+
+        if params.output_spacing:
+            resample_filter.SetOutputSpacing(params.output_spacing)
+        else:
+            resample_filter.SetOutputSpacing(output_spacing)
+
+        if params.output_size:
+            resample_filter.SetSize(params.output_size)
+        else:
+            resample_filter.SetSize(output_size)
+
+        new_image_sitk = resample_filter.Execute(image_sitk)
+
+        # add the new image data to the segmentation image
+        image.set_image_data(new_image_sitk)
+
+        # track the necessary parameters
+        self.tracking_data["min_intensity"] = 0.0
+        self.tracking_data["max_intensity"] = 1.0
+        self.tracking_data["is_intensity"] = False
+        self._register_tracked_data(image, image_sitk, new_image_sitk, params, params.transform)
+
+        return image
+
+    @staticmethod
+    def _inverse_process_segmentation_image(
+        image: SegmentationImage, transform_info: TransformInfo
+    ) -> SegmentationImage:
+        """Apply the inverse resampling on an :class:`~pyradise.data.image.SegmentationImage` instance.
+
+        Args:
+            image (SegmentationImage): The image to resample.
+            transform_info (TransformInfo): The transform information.
+
+        Returns:
+            SegmentationImage: The inversely resampled segmentation image.
+        """
+        # get the image data and the pre-transform image properties
+        image_sik = image.get_image_data()
+        pre_transform_props = transform_info.get_image_properties(True)
+
+        # apply the resampling filter
+        resample_filter = sitk.ResampleImageFilter()
+        resample_filter.SetInterpolator(sitk.sitkNearestNeighbor)
+        resample_filter.SetTransform(transform_info.get_transform(True))
+        resample_filter.SetDefaultPixelValue(0)
+        resample_filter.SetOutputOrigin(pre_transform_props.origin)
+        resample_filter.SetOutputDirection(pre_transform_props.direction)
+        resample_filter.SetOutputSpacing(pre_transform_props.spacing)
+        resample_filter.SetSize(pre_transform_props.size)
+
+        new_image_sitk = resample_filter.Execute(image_sik)
+
+        # set the new image data to the intensity image
+        image.set_image_data(new_image_sitk)
+
+        return image
+
+    def execute(self, subject: Subject, params: ResampleFilterParams) -> Subject:
+        """Executes the resampling filter procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            params (ResampleFilterParams): The parameters used for the resampling.
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with resampled
+            :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+        # get the segmentation images
+        segmentation_images = subject.get_images_by_type(SegmentationImage)
+        segmentation_images = [img for img in segmentation_images if isinstance(img, SegmentationImage)]
+
+        # get the reference images if necessary
+        if params.centering_method != "none":
+            # resample the reference intensity image
+            ref_image = subject.get_image_by_modality(params.reference_modality)
+            self._process_intensity_image(ref_image, ref_image, params, segmentation_images)
+        else:
+            ref_image = None
+
+        # resample the intensity images
+        for image in subject.intensity_images:
+            # exclude the reference image if not centering_method == 'none'
+            if params.centering_method != "none":
+                if image.get_modality() == params.reference_modality:
+                    continue
+
+            self._process_intensity_image(image, ref_image, params, segmentation_images)
+
+        # resample the segmentation images
+        for image in subject.segmentation_images:
+            self._process_segmentation_image(image, ref_image, params)
+
+        return subject
+
+    def execute_inverse(
+        self,
+        subject: Subject,
+        transform_info: TransformInfo,
+        target_image: Optional[Union[SegmentationImage, IntensityImage]] = None,
+    ) -> Subject:
+        """Executes the inverse resampling filter procedure.
+
+        Args:
+            subject (Subject): The :class:`~pyradise.data.subject.Subject` instance to be processed.
+            transform_info (TransformInfo): The transform information.
+            target_image (Optional[Union[SegmentationImage, IntensityImage]]): The target image to which the inverse
+             transformation should be applied. If None, the inverse transformation is applied to all images (default:
+             None).
+
+        Returns:
+            Subject: The :class:`~pyradise.data.subject.Subject` instance with inversely resampled
+            :class:`~pyradise.data.image.IntensityImage` and :class:`~pyradise.data.image.SegmentationImage` instances.
+        """
+        for image in subject.intensity_images:
+            if target_image is None or image == target_image:
+                self._inverse_process_intensity_image(image, transform_info)
+
+        for image in subject.segmentation_images:
+            if target_image is None or image == target_image:
+                self._inverse_process_segmentation_image(image, transform_info)
+
+        return subject
```

### Comparing `pyradise-0.2.2/pyradise/utils.py` & `pyradise-0.2.3/pyradise/utils.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,307 +1,307 @@
-import os
-from re import sub
-from typing import Iterable, Sequence, Sized, Tuple
-
-import itk
-import numpy as np
-import SimpleITK as sitk
-from pydicom import Dataset, dcmread
-from pydicom.tag import Tag
-
-
-def is_dir_and_exists(path: str) -> str:
-    """Check if the provided path specifies a directory and if it exists.
-
-    Args:
-        path (str): The path to test.
-
-    Returns:
-        str: The normalized path.
-    """
-    if not os.path.exists(path):
-        raise NotADirectoryError(f"The path {path} is not existing!")
-
-    if not os.path.isdir(path):
-        raise NotADirectoryError(f"The path {path} is not a directory!")
-
-    return os.path.normpath(path)
-
-
-def is_file_and_exists(path: str) -> str:
-    """Check if the provided path specifies a file and if it exists.
-
-    Args:
-        path (str): The path to test.
-
-    Returns:
-        str: The normalized path.
-    """
-    if not os.path.exists(path):
-        raise FileNotFoundError(f"The path {path} is not existing!")
-
-    if not os.path.isfile(path):
-        raise FileNotFoundError(f"The path {path} is not a file!")
-
-    return os.path.normpath(path)
-
-
-def is_dicom_file(path: str) -> bool:
-    """Check if a path is specifying a DICOM file.
-
-    Args:
-        path (str): The path to test.
-
-    Returns:
-        bool: True if the path is specifying a DICOM file, False otherwise.
-    """
-
-    file_name = os.path.basename(path)
-    if "." in file_name:
-        file_extension = file_name.split(".")[-1]
-        return file_extension.lower() == "dcm"
-
-    with open(path, "rb") as fp:
-        fp.seek(128)
-        return fp.read(4).decode("utf-8") == "DICM"
-
-
-def assume_is_segmentation(path: str) -> bool:
-    """Assume if the image is a segmentation image based on the pixel data type or the SOPClassUID for DICOM files.
-
-    Notes:
-        Assume that a segmentation image has the pixel data type unsigned char.
-
-    Args:
-        path (str): The path to the image file.
-
-    Returns:
-        bool: True if the image is assumed to be a segmentation image, False otherwise.
-    """
-    if any([entry in path for entry in (".nii", ".nrrd", ".mha")]):
-        reader = sitk.ImageFileReader()
-        reader.LoadPrivateTagsOn()
-        reader.SetFileName(path)
-        reader.ReadImageInformation()
-        if reader.GetPixelIDValue() == 1:
-            return True
-        return False
-
-    elif is_dicom_file(path):
-        dataset = load_dataset_tag(path, (Tag(0x0008, 0x0016),))
-        sop_class_uid = str(dataset.SOPClassUID)
-        if sop_class_uid == "1.2.840.10008.5.1.4.1.1.66.4":
-            return True
-        return False
-
-    else:
-        raise ValueError(f"The path {path} specifies a not supported file type!")
-
-
-def convert_to_sitk_image(image: itk.Image) -> sitk.Image:
-    """Convert an :class:`itk.Image` to a :class:`SimpleITK.Image`.
-
-    Args:
-        image (itk.Image): The :class:`itk.Image` to be converted.
-
-    Returns:
-        sitk.Image: The converted :class:`SimpleITK.Image`.
-    """
-    if image.GetImageDimension() > 3:
-        raise NotImplementedError(f"Conversion of {image.GetDimension()}D images is not supported!")
-
-    is_vector_image = image.GetNumberOfComponentsPerPixel() > 1
-    image_sitk = sitk.GetImageFromArray(itk.GetArrayFromImage(image), isVector=is_vector_image)
-    image_sitk.SetOrigin(tuple(image.GetOrigin()))
-    image_sitk.SetSpacing(tuple(image.GetSpacing()))
-    image_sitk.SetDirection(itk.GetArrayFromMatrix(image.GetDirection()).flatten())
-    return image_sitk
-
-
-def convert_to_itk_image(image: sitk.Image) -> itk.Image:
-    """Convert a :class:`SimpleITK.Image` to an :class:`itk.Image`.
-
-    Args:
-        image (sitk.Image): The :class:`SimpleITK.Image` to be converted.
-
-    Returns:
-        itk.Image: The converted :class:`itk.Image`.
-    """
-    if image.GetDimension() > 3:
-        raise NotImplementedError(f"Conversion of {image.GetDimension()}D images is not supported!")
-
-    is_vector_image = image.GetNumberOfComponentsPerPixel() > 1
-    image_itk = itk.GetImageFromArray(sitk.GetArrayFromImage(image), is_vector=is_vector_image)
-    image_itk.SetOrigin(image.GetOrigin())
-    image_itk.SetSpacing(image.GetSpacing())
-    image_itk.SetDirection(itk.GetMatrixFromArray(np.reshape(np.array(image.GetDirection()), [3] * 2)))
-    return image_itk
-
-
-def assume_is_intensity_image(path: str) -> bool:
-    """Assume if the image is an intensity image based on the pixel data type or the SOPClassUID for DICOM files.
-
-    Notes:
-        Assume that an intensity image has a pixel data type which is different from unsigned char.
-
-    Args:
-        path (str): The path to the image file.
-
-    Returns:
-        bool: True if the image is assumed to be an intensity image, False otherwise.
-    """
-    if any([entry in path for entry in (".nii", ".nrrd", ".mha")]):
-        reader = sitk.ImageFileReader()
-        reader.LoadPrivateTagsOn()
-        reader.SetFileName(path)
-        reader.ReadImageInformation()
-        if reader.GetPixelIDValue() != 1:
-            return True
-        return False
-
-    elif is_dicom_file(path):
-        dataset = load_dataset_tag(path, (Tag(0x0008, 0x0016),))
-        sop_class_uid = str(dataset.SOPClassUID)
-        sop_class_last_uid = int(sop_class_uid.split(".")[9])
-        if "1.2.840.10008.5.1.4.1.1" in sop_class_uid and sop_class_last_uid <= 20:
-            return True
-        return False
-
-    else:
-        raise ValueError(f"The path {path} specifies a not supported file type!")
-
-
-def remove_illegal_folder_chars(name: str) -> str:
-    """Removes illegal characters from a folder name.
-
-    Args:
-        name (str): The folder name with potential illegal characters.
-
-    Returns:
-        str: The folder name without illegal characters.
-    """
-    illegal_characters = r"""[<>:/\\|?*\']|[\0-\31]"""
-    return sub(illegal_characters, "", name)
-
-
-def load_dataset(path: str, stop_before_pixels: bool = True) -> Dataset:
-    """Loads a DICOM dataset from a path.
-
-    Args:
-        path (str): The path to the DICOM file.
-        stop_before_pixels (bool): If True the loading process will not be performed for the image data.
-
-    Returns:
-        Dataset: The :class:`Dataset` loaded.
-    """
-    dataset = dcmread(path, stop_before_pixels=stop_before_pixels)
-    dataset.decode()
-    return dataset
-
-
-def load_datasets(paths: Sequence[str], stop_before_pixels: bool = True) -> Tuple[Dataset, ...]:
-    """Load multiple DICOM datasets from multiple paths.
-
-    Args:
-        paths (Tuple[str]): The paths to the DICOM files.
-        stop_before_pixels (bool): Indicates if the loading process should stop before the pixel data.
-
-    Returns:
-        Tuple[Dataset, ...]: The loaded :class:`Dataset` s.
-    """
-    datasets = []
-    for path in paths:
-        dataset = load_dataset(path, stop_before_pixels)
-        datasets.append(dataset)
-
-    return tuple(datasets)
-
-
-def load_dataset_tag(path: str, tags: Sequence[Tag], stop_before_pixels: bool = True) -> Dataset:
-    """Loads a DICOM dataset from a file with specific tags only.
-
-    Args:
-        path (str): The path to the DICOM file.
-        tags (Sequence[Tag]): One or multiple tags to load from the file.
-        stop_before_pixels (bool): If True the loading process will not be performed for the image data.
-
-    Returns:
-        Dataset: The :class:`Dataset` loaded with specific tags.
-    """
-    dataset = dcmread(path, stop_before_pixels=stop_before_pixels, specific_tags=list(tags))
-    dataset.decode()
-    return dataset
-
-
-def chunkify(iterable: Sized, size: int) -> Iterable:
-    """Separate data from an iterable into chunks of a certain size.
-
-    Args:
-        iterable (Sized): The iterable to separate.
-        size (int): The size of the chunks.
-
-    Returns:
-        Iterable: A chunk.
-    """
-    assert size > 1, "The size for chunking the data can not be smaller than 1!"
-
-    for i in range(0, len(iterable), size):
-        yield iterable[i : i + size]
-
-
-def get_slice_direction(image_dataset: Dataset) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
-    """Get the slice direction from the :class:`Dataset`.
-
-    Args:
-        image_dataset (Dataset): The :class:`Dataset` from which the slice direction should be determined.
-
-    Returns:
-        Tuple[np.ndarray, np.ndarray, np.ndarray]: The directions in all three dimensions.
-    """
-    orientation = image_dataset.get("ImageOrientationPatient")
-
-    row_direction = np.array(orientation[:3])
-    column_direction = np.array(orientation[3:])
-    slice_direction = np.cross(row_direction, column_direction)
-
-    validate_directions = (
-        np.allclose(np.dot(row_direction, column_direction), 0.0, atol=1e-3),
-        np.allclose(np.linalg.norm(slice_direction), 1.0, atol=1e-3),
-    )
-
-    if not all(validate_directions):
-        raise Exception(f'Invalid ImageOrientationPatient attribute in {image_dataset.get("PatientID")}!')
-
-    return row_direction, column_direction, slice_direction
-
-
-def get_slice_position(image_dataset: Dataset) -> np.ndarray:
-    """Get the slice position from a :class:`Dataset`.
-
-    Args:
-        image_dataset (Dataset): The :class:`Dataset` from which the slice position should be determined.
-
-    Returns:
-        np.ndarray: The position of the slice in space.
-    """
-    orientation = image_dataset.get("ImagePositionPatient")
-
-    _, _, slice_direction = get_slice_direction(image_dataset)
-
-    return np.dot(slice_direction, orientation)
-
-
-def get_spacing_between_slices(image_datasets: Tuple[Dataset, ...]) -> float:
-    """Get the spacing between the slices based on the first and last slice positions.
-
-    Args:
-        image_datasets (Tuple[Dataset, ...]): The :class:`Dataset` s to get the spacing from
-
-    Returns:
-        float: The spacing between the slices.
-    """
-    if len(image_datasets) > 1:
-        first = get_slice_position(image_datasets[0])
-        last = get_slice_position(image_datasets[-1])
-        return (last - first) / (len(image_datasets) - 1)
-
-    return 1.0
+import os
+from re import sub
+from typing import Iterable, Sequence, Sized, Tuple
+
+import itk
+import numpy as np
+import SimpleITK as sitk
+from pydicom import Dataset, dcmread
+from pydicom.tag import Tag
+
+
+def is_dir_and_exists(path: str) -> str:
+    """Check if the provided path specifies a directory and if it exists.
+
+    Args:
+        path (str): The path to test.
+
+    Returns:
+        str: The normalized path.
+    """
+    if not os.path.exists(path):
+        raise NotADirectoryError(f"The path {path} is not existing!")
+
+    if not os.path.isdir(path):
+        raise NotADirectoryError(f"The path {path} is not a directory!")
+
+    return os.path.normpath(path)
+
+
+def is_file_and_exists(path: str) -> str:
+    """Check if the provided path specifies a file and if it exists.
+
+    Args:
+        path (str): The path to test.
+
+    Returns:
+        str: The normalized path.
+    """
+    if not os.path.exists(path):
+        raise FileNotFoundError(f"The path {path} is not existing!")
+
+    if not os.path.isfile(path):
+        raise FileNotFoundError(f"The path {path} is not a file!")
+
+    return os.path.normpath(path)
+
+
+def is_dicom_file(path: str) -> bool:
+    """Check if a path is specifying a DICOM file.
+
+    Args:
+        path (str): The path to test.
+
+    Returns:
+        bool: True if the path is specifying a DICOM file, False otherwise.
+    """
+
+    file_name = os.path.basename(path)
+    if "." in file_name:
+        file_extension = file_name.split(".")[-1]
+        return file_extension.lower() == "dcm"
+
+    with open(path, "rb") as fp:
+        fp.seek(128)
+        return fp.read(4).decode("utf-8") == "DICM"
+
+
+def assume_is_segmentation(path: str) -> bool:
+    """Assume if the image is a segmentation image based on the pixel data type or the SOPClassUID for DICOM files.
+
+    Notes:
+        Assume that a segmentation image has the pixel data type unsigned char.
+
+    Args:
+        path (str): The path to the image file.
+
+    Returns:
+        bool: True if the image is assumed to be a segmentation image, False otherwise.
+    """
+    if any([entry in path for entry in (".nii", ".nrrd", ".mha")]):
+        reader = sitk.ImageFileReader()
+        reader.LoadPrivateTagsOn()
+        reader.SetFileName(path)
+        reader.ReadImageInformation()
+        if reader.GetPixelIDValue() == 1:
+            return True
+        return False
+
+    elif is_dicom_file(path):
+        dataset = load_dataset_tag(path, (Tag(0x0008, 0x0016),))
+        sop_class_uid = str(dataset.SOPClassUID)
+        if sop_class_uid == "1.2.840.10008.5.1.4.1.1.66.4":
+            return True
+        return False
+
+    else:
+        raise ValueError(f"The path {path} specifies a not supported file type!")
+
+
+def convert_to_sitk_image(image: itk.Image) -> sitk.Image:
+    """Convert an :class:`itk.Image` to a :class:`SimpleITK.Image`.
+
+    Args:
+        image (itk.Image): The :class:`itk.Image` to be converted.
+
+    Returns:
+        sitk.Image: The converted :class:`SimpleITK.Image`.
+    """
+    if image.GetImageDimension() > 3:
+        raise NotImplementedError(f"Conversion of {image.GetDimension()}D images is not supported!")
+
+    is_vector_image = image.GetNumberOfComponentsPerPixel() > 1
+    image_sitk = sitk.GetImageFromArray(itk.GetArrayFromImage(image), isVector=is_vector_image)
+    image_sitk.SetOrigin(tuple(image.GetOrigin()))
+    image_sitk.SetSpacing(tuple(image.GetSpacing()))
+    image_sitk.SetDirection(itk.GetArrayFromMatrix(image.GetDirection()).flatten())
+    return image_sitk
+
+
+def convert_to_itk_image(image: sitk.Image) -> itk.Image:
+    """Convert a :class:`SimpleITK.Image` to an :class:`itk.Image`.
+
+    Args:
+        image (sitk.Image): The :class:`SimpleITK.Image` to be converted.
+
+    Returns:
+        itk.Image: The converted :class:`itk.Image`.
+    """
+    if image.GetDimension() > 3:
+        raise NotImplementedError(f"Conversion of {image.GetDimension()}D images is not supported!")
+
+    is_vector_image = image.GetNumberOfComponentsPerPixel() > 1
+    image_itk = itk.GetImageFromArray(sitk.GetArrayFromImage(image), is_vector=is_vector_image)
+    image_itk.SetOrigin(image.GetOrigin())
+    image_itk.SetSpacing(image.GetSpacing())
+    image_itk.SetDirection(itk.GetMatrixFromArray(np.reshape(np.array(image.GetDirection()), [3] * 2)))
+    return image_itk
+
+
+def assume_is_intensity_image(path: str) -> bool:
+    """Assume if the image is an intensity image based on the pixel data type or the SOPClassUID for DICOM files.
+
+    Notes:
+        Assume that an intensity image has a pixel data type which is different from unsigned char.
+
+    Args:
+        path (str): The path to the image file.
+
+    Returns:
+        bool: True if the image is assumed to be an intensity image, False otherwise.
+    """
+    if any([entry in path for entry in (".nii", ".nrrd", ".mha")]):
+        reader = sitk.ImageFileReader()
+        reader.LoadPrivateTagsOn()
+        reader.SetFileName(path)
+        reader.ReadImageInformation()
+        if reader.GetPixelIDValue() != 1:
+            return True
+        return False
+
+    elif is_dicom_file(path):
+        dataset = load_dataset_tag(path, (Tag(0x0008, 0x0016),))
+        sop_class_uid = str(dataset.SOPClassUID)
+        sop_class_last_uid = int(sop_class_uid.split(".")[9])
+        if "1.2.840.10008.5.1.4.1.1" in sop_class_uid and sop_class_last_uid <= 20:
+            return True
+        return False
+
+    else:
+        raise ValueError(f"The path {path} specifies a not supported file type!")
+
+
+def remove_illegal_folder_chars(name: str) -> str:
+    """Removes illegal characters from a folder name.
+
+    Args:
+        name (str): The folder name with potential illegal characters.
+
+    Returns:
+        str: The folder name without illegal characters.
+    """
+    illegal_characters = r"""[<>:/\\|?*\']|[\0-\31]"""
+    return sub(illegal_characters, "", name)
+
+
+def load_dataset(path: str, stop_before_pixels: bool = True) -> Dataset:
+    """Loads a DICOM dataset from a path.
+
+    Args:
+        path (str): The path to the DICOM file.
+        stop_before_pixels (bool): If True the loading process will not be performed for the image data.
+
+    Returns:
+        Dataset: The :class:`Dataset` loaded.
+    """
+    dataset = dcmread(path, stop_before_pixels=stop_before_pixels)
+    dataset.decode()
+    return dataset
+
+
+def load_datasets(paths: Sequence[str], stop_before_pixels: bool = True) -> Tuple[Dataset, ...]:
+    """Load multiple DICOM datasets from multiple paths.
+
+    Args:
+        paths (Tuple[str]): The paths to the DICOM files.
+        stop_before_pixels (bool): Indicates if the loading process should stop before the pixel data.
+
+    Returns:
+        Tuple[Dataset, ...]: The loaded :class:`Dataset` s.
+    """
+    datasets = []
+    for path in paths:
+        dataset = load_dataset(path, stop_before_pixels)
+        datasets.append(dataset)
+
+    return tuple(datasets)
+
+
+def load_dataset_tag(path: str, tags: Sequence[Tag], stop_before_pixels: bool = True) -> Dataset:
+    """Loads a DICOM dataset from a file with specific tags only.
+
+    Args:
+        path (str): The path to the DICOM file.
+        tags (Sequence[Tag]): One or multiple tags to load from the file.
+        stop_before_pixels (bool): If True the loading process will not be performed for the image data.
+
+    Returns:
+        Dataset: The :class:`Dataset` loaded with specific tags.
+    """
+    dataset = dcmread(path, stop_before_pixels=stop_before_pixels, specific_tags=list(tags))
+    dataset.decode()
+    return dataset
+
+
+def chunkify(iterable: Sized, size: int) -> Iterable:
+    """Separate data from an iterable into chunks of a certain size.
+
+    Args:
+        iterable (Sized): The iterable to separate.
+        size (int): The size of the chunks.
+
+    Returns:
+        Iterable: A chunk.
+    """
+    assert size > 1, "The size for chunking the data can not be smaller than 1!"
+
+    for i in range(0, len(iterable), size):
+        yield iterable[i : i + size]
+
+
+def get_slice_direction(image_dataset: Dataset) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
+    """Get the slice direction from the :class:`Dataset`.
+
+    Args:
+        image_dataset (Dataset): The :class:`Dataset` from which the slice direction should be determined.
+
+    Returns:
+        Tuple[np.ndarray, np.ndarray, np.ndarray]: The directions in all three dimensions.
+    """
+    orientation = image_dataset.get("ImageOrientationPatient")
+
+    row_direction = np.array(orientation[:3])
+    column_direction = np.array(orientation[3:])
+    slice_direction = np.cross(row_direction, column_direction)
+
+    validate_directions = (
+        np.allclose(np.dot(row_direction, column_direction), 0.0, atol=1e-3),
+        np.allclose(np.linalg.norm(slice_direction), 1.0, atol=1e-3),
+    )
+
+    if not all(validate_directions):
+        raise Exception(f'Invalid ImageOrientationPatient attribute in {image_dataset.get("PatientID")}!')
+
+    return row_direction, column_direction, slice_direction
+
+
+def get_slice_position(image_dataset: Dataset) -> np.ndarray:
+    """Get the slice position from a :class:`Dataset`.
+
+    Args:
+        image_dataset (Dataset): The :class:`Dataset` from which the slice position should be determined.
+
+    Returns:
+        np.ndarray: The position of the slice in space.
+    """
+    orientation = image_dataset.get("ImagePositionPatient")
+
+    _, _, slice_direction = get_slice_direction(image_dataset)
+
+    return np.dot(slice_direction, orientation)
+
+
+def get_spacing_between_slices(image_datasets: Tuple[Dataset, ...]) -> float:
+    """Get the spacing between the slices based on the first and last slice positions.
+
+    Args:
+        image_datasets (Tuple[Dataset, ...]): The :class:`Dataset` s to get the spacing from
+
+    Returns:
+        float: The spacing between the slices.
+    """
+    if len(image_datasets) > 1:
+        first = get_slice_position(image_datasets[0])
+        last = get_slice_position(image_datasets[-1])
+        return (last - first) / (len(image_datasets) - 1)
+
+    return 1.0
```

### Comparing `pyradise-0.2.2/pyradise.egg-info/PKG-INFO` & `pyradise-0.2.3/pyradise.egg-info/PKG-INFO`

 * *Files 9% similar despite different names*

```diff
@@ -1,107 +1,107 @@
-Metadata-Version: 2.1
-Name: pyradise
-Version: 0.2.2
-Summary: PyRaDiSe: A Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion
-Home-page: https://pyradise.readthedocs.io/
-Author: Elias Ruefenacht
-Author-email: Elias Ruefenacht <elias.ruefenacht@unibe.ch>
-License: Apache-2.0
-Project-URL: Homepage, https://pyradise.readthedocs.io/
-Project-URL: Bug Tracker, https://github.com/ubern-mia/pyradise/issues
-Project-URL: GitHub, https://github.com/ubern-mia/pyradise/
-Keywords: medical image analysis,deep learning,auto-segmentation,radiotherapy,DICOM conversion,DICOM data handling,DICOM-RT Structure Sets
-Classifier: Development Status :: 3 - Alpha
-Classifier: Intended Audience :: Developers
-Classifier: Intended Audience :: Science/Research
-Classifier: License :: OSI Approved :: Apache Software License
-Classifier: Natural Language :: English
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11
-Classifier: Topic :: Scientific/Engineering :: Image Recognition
-Classifier: Topic :: Scientific/Engineering :: Mathematics
-Classifier: Topic :: Scientific/Engineering :: Medical Science Apps.
-Classifier: Topic :: Software Development :: Libraries :: Python Modules
-Classifier: Topic :: Software Development :: Libraries
-Requires-Python: >=3.8
-Description-Content-Type: text/markdown
-License-File: LICENSE
-
-PyRaDiSe
-========
-
-[![Documentation Status](https://readthedocs.org/projects/pyradise/badge/?version=latest)](https://pyradise.readthedocs.io/en/latest/?badge=latest)
-
-PyRaDiSe is an open-source Python (Py) package for developing deployable, radiotherapy-oriented (Ra), DICOM-based (Di) 
-auto-segmentation (Se) solutions. PyRaDiSe is DL framework-independent but can easily integrate most DL frameworks, 
-such as PyTorch or TensorFlow. The package addresses the following challenges for building radiotherapy-oriented 
-auto-segmentation solutions: handling DICOM data, managing and converting DICOM-RTSS data (incl. a 2D-based and 
-a 3D-based conversion algorithm), invertible pre-processing, and post-processing. In addition to building 
-auto-segmentation solutions, PyRaDiSe allows for converting and curating DICOM image series and DICOM-RTSS data to 
-simplify segmentation training dataset construction. Therefore, PyRaDiSe is highly flexible, allows for fast 
-prototyping, and facilitates a fast transition of data science research results into clinical radiotherapy research.
-
-<img alt="PyRaDiSe_Meme" src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/meme.jpg" width="300">
-
-Main Features
--------------
-The main features of PyRaDiSe are data handling, conversion from and to DICOM-RTSS, and data processing, including deep 
-learning model inference. The intended use of PyRaDiSe in the radiotherapy environment is depicted below. The 
-DICOM and other discrete medical image file formats, such as NIfTI, are imported into the provided data model using 
-the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html). In contrast to the 
-standard way of loading DICOM data, this package provides comprehensive and flexible import routines that consider 
-data relation details and automate import steps, such as registering DICOM images if DICOM registration files are 
-available. However, in some cases, the DICOM standard does not provide sufficient information for automation, 
-requiring minimal human interaction for resolution. In addition, discrete medical images also suffer from the lack of 
-identification data needed for automation. However, the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) 
-package offers the necessary methods to address these issues with flexible approaches and prototypes. Furthermore, 
-the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) provides 
-routines to select specific entities from the available data before loading by generating filterable pre-loading 
-information (so-called [`SeriesInfo`](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.series_info.html#pyradise.fileio.series_info.SeriesInfo))
-so that the computation time and memory usage for loading is minimal. Finally, after the data is loaded, it is 
-represented using the data model implemented in the [`data` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.data.html). 
-All downstream tasks are performed using the simple and extensible radiotherapy-oriented data model from this step on.
-
-After loading, the data is either converted and written to a file or processed using routines from the 
-[`process` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.process.html). This package includes 
-functionality and prototypes for pre-processing, deep learning model inference, and post-processing with a similar mode 
-of operations as well-known medical image libraries, such as SimpleITK or ITK. However, in contrast to other libraries, 
-the process package offers a mechanism for guaranteeing reproducibility and limited invertibility.
-
-After processing or loading, the altered data can be written to disk using a versatile writer from the 
-[`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) to save the data as either 
-a discrete image file or as DICOM-RTSS. In addition, specific writers provide the additional functionality to copy 
-the input data from the source to the target directory. This feature is handy if the developed auto-segmentation 
-solution will be deployed to the clinical environment or the cloud, where the original input data should remain 
-unmodified.
-
-<img src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/architecture_overview_v2.png" alt="Schematic illustration of PyRaDiSe in the radiotherapy environment">
-
-
-Getting Started
----------------
-
-If you are new to PyRaDiSe, here are a few guides to get you up to speed right away:
-
- - [Installation](https://pyradise.readthedocs.io/en/latest/installation.html) for installation instructions - or simply run `pip install pyradise`
- - [Examples](https://pyradise.readthedocs.io/en/latest/examples.html) give you an overview of PyRaDiSe's intended use. Jupyter notebooks are available in the directory [./examples](https://github.com/ubern-mia/pyradise/tree/main/examples/).
- - [Change history](https://pyradise.readthedocs.io/en/latest/change_history.html)
- - [Acknowledgments](https://pyradise.readthedocs.io/en/latest/acknowledgment.html)
-
-
-Citation
---------
-
-If you use PyRaDiSe for your research, please acknowledge it accordingly by citing our paper:
-
-BibTeX entry:
-
-    @article{Ruefenacht2023,
-    author = {Rüfenacht, Elias and Kamath, Amith and Suter, Yannick and Poel, Robert and Ermis, Ekin and Scheib, Stefan and Reyes, Mauricio},
-    title = {{PyRaDiSe: A Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion}},
-    journal = {Computer Methods and Programs in Biomedicine},
-    doi = {10.1016/j.cmpb.2023.107374},
-    issn = {0169-2607},
-    year = {2023}
-    }
+Metadata-Version: 2.1
+Name: pyradise
+Version: 0.2.3
+Summary: PyRaDiSe: A Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion
+Home-page: https://pyradise.readthedocs.io/
+Author: Elias Ruefenacht
+Author-email: Elias Ruefenacht <elias.ruefenacht@unibe.ch>
+License: Apache-2.0
+Project-URL: Homepage, https://pyradise.readthedocs.io/
+Project-URL: Bug Tracker, https://github.com/ubern-mia/pyradise/issues
+Project-URL: GitHub, https://github.com/ubern-mia/pyradise/
+Keywords: medical image analysis,deep learning,auto-segmentation,radiotherapy,DICOM conversion,DICOM data handling,DICOM-RT Structure Sets
+Classifier: Development Status :: 3 - Alpha
+Classifier: Intended Audience :: Developers
+Classifier: Intended Audience :: Science/Research
+Classifier: License :: OSI Approved :: Apache Software License
+Classifier: Natural Language :: English
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Topic :: Scientific/Engineering :: Image Recognition
+Classifier: Topic :: Scientific/Engineering :: Mathematics
+Classifier: Topic :: Scientific/Engineering :: Medical Science Apps.
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Classifier: Topic :: Software Development :: Libraries
+Requires-Python: >=3.8
+Description-Content-Type: text/markdown
+License-File: LICENSE
+
+PyRaDiSe
+========
+
+[![Documentation Status](https://readthedocs.org/projects/pyradise/badge/?version=latest)](https://pyradise.readthedocs.io/en/latest/?badge=latest)
+
+PyRaDiSe is an open-source Python (Py) package for developing deployable, radiotherapy-oriented (Ra), DICOM-based (Di) 
+auto-segmentation (Se) solutions. PyRaDiSe is DL framework-independent but can easily integrate most DL frameworks, 
+such as PyTorch or TensorFlow. The package addresses the following challenges for building radiotherapy-oriented 
+auto-segmentation solutions: handling DICOM data, managing and converting DICOM-RTSS data (incl. a 2D-based and 
+a 3D-based conversion algorithm), invertible pre-processing, and post-processing. In addition to building 
+auto-segmentation solutions, PyRaDiSe allows for converting and curating DICOM image series and DICOM-RTSS data to 
+simplify segmentation training dataset construction. Therefore, PyRaDiSe is highly flexible, allows for fast 
+prototyping, and facilitates a fast transition of data science research results into clinical radiotherapy research.
+
+<img alt="PyRaDiSe_Meme" src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/meme.jpg" width="300">
+
+Main Features
+-------------
+The main features of PyRaDiSe are data handling, conversion from and to DICOM-RTSS, and data processing, including deep 
+learning model inference. The intended use of PyRaDiSe in the radiotherapy environment is depicted below. The 
+DICOM and other discrete medical image file formats, such as NIfTI, are imported into the provided data model using 
+the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html). In contrast to the 
+standard way of loading DICOM data, this package provides comprehensive and flexible import routines that consider 
+data relation details and automate import steps, such as registering DICOM images if DICOM registration files are 
+available. However, in some cases, the DICOM standard does not provide sufficient information for automation, 
+requiring minimal human interaction for resolution. In addition, discrete medical images also suffer from the lack of 
+identification data needed for automation. However, the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) 
+package offers the necessary methods to address these issues with flexible approaches and prototypes. Furthermore, 
+the [`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) provides 
+routines to select specific entities from the available data before loading by generating filterable pre-loading 
+information (so-called [`SeriesInfo`](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.series_info.html#pyradise.fileio.series_info.SeriesInfo))
+so that the computation time and memory usage for loading is minimal. Finally, after the data is loaded, it is 
+represented using the data model implemented in the [`data` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.data.html). 
+All downstream tasks are performed using the simple and extensible radiotherapy-oriented data model from this step on.
+
+After loading, the data is either converted and written to a file or processed using routines from the 
+[`process` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.process.html). This package includes 
+functionality and prototypes for pre-processing, deep learning model inference, and post-processing with a similar mode 
+of operations as well-known medical image libraries, such as SimpleITK or ITK. However, in contrast to other libraries, 
+the process package offers a mechanism for guaranteeing reproducibility and limited invertibility.
+
+After processing or loading, the altered data can be written to disk using a versatile writer from the 
+[`fileio` package](https://pyradise.readthedocs.io/en/latest/reference/pyradise.fileio.html) to save the data as either 
+a discrete image file or as DICOM-RTSS. In addition, specific writers provide the additional functionality to copy 
+the input data from the source to the target directory. This feature is handy if the developed auto-segmentation 
+solution will be deployed to the clinical environment or the cloud, where the original input data should remain 
+unmodified.
+
+<img src="https://github.com/ubern-mia/pyradise/raw/main/docs/_static/architecture_overview_v2.png" alt="Schematic illustration of PyRaDiSe in the radiotherapy environment">
+
+
+Getting Started
+---------------
+
+If you are new to PyRaDiSe, here are a few guides to get you up to speed right away:
+
+ - [Installation](https://pyradise.readthedocs.io/en/latest/installation.html) for installation instructions - or simply run `pip install pyradise`
+ - [Examples](https://pyradise.readthedocs.io/en/latest/examples.html) give you an overview of PyRaDiSe's intended use. Jupyter notebooks are available in the directory [./examples](https://github.com/ubern-mia/pyradise/tree/main/examples/).
+ - [Change history](https://pyradise.readthedocs.io/en/latest/change_history.html)
+ - [Acknowledgments](https://pyradise.readthedocs.io/en/latest/acknowledgment.html)
+
+
+Citation
+--------
+
+If you use PyRaDiSe for your research, please acknowledge it accordingly by citing our paper:
+
+BibTeX entry:
+
+    @article{Ruefenacht2023,
+    author = {Rüfenacht, Elias and Kamath, Amith and Suter, Yannick and Poel, Robert and Ermis, Ekin and Scheib, Stefan and Reyes, Mauricio},
+    title = {{PyRaDiSe: A Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion}},
+    journal = {Computer Methods and Programs in Biomedicine},
+    doi = {10.1016/j.cmpb.2023.107374},
+    issn = {0169-2607},
+    year = {2023}
+    }
```

### Comparing `pyradise-0.2.2/pyradise.egg-info/SOURCES.txt` & `pyradise-0.2.3/pyradise.egg-info/SOURCES.txt`

 * *Files identical despite different names*

### Comparing `pyradise-0.2.2/setup.py` & `pyradise-0.2.3/setup.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,75 +1,75 @@
-import os
-import sys
-
-from setuptools import find_packages, setup
-
-if sys.version_info < (3, 8):
-    sys.exit("Requires Python 3.8 or higher")
-
-directory = os.path.abspath(os.path.dirname(__file__))
-
-about = {}
-with open(os.path.join(directory, "pyradise", "__version__.py"), "r", encoding="utf-8") as f:
-    exec(f.read(), about)
-
-with open(os.path.join(directory, "README.md"), "r", encoding="utf-8") as f:
-    readme = f.read()
-
-REQUIRED_PACKAGES = [
-    "pydicom",
-    "numpy",
-    "itk>=5.3rc4.post3",
-    "SimpleITK",
-    "opencv-python",
-    "scipy",
-    "vtk",
-]
-
-TEST_PACKAGES = [
-    "tox >= 3.4.0",
-    "tox-pipenv >= 1.10.1",
-    "pytest >= 7.0.0",
-    "pytest-cov >= 4.0.0",
-    "pipenv >= 2022.10.12",
-]
-
-setup(
-    name=about["__title__"],
-    version=about["__version__"],
-    description=about["__description__"],
-    long_description=readme,
-    long_description_content_type="text/markdown",
-    author=about["__author__"],
-    author_email=about["__author_email__"],
-    url=about["__url__"],
-    license=about["__license__"],
-    python_requires=">=3.8",
-    packages=find_packages(exclude=["docs", "examples", "test"]),
-    install_requires=REQUIRED_PACKAGES,
-    tests_require=REQUIRED_PACKAGES + TEST_PACKAGES,
-    classifiers=[
-        "Development Status :: 3 - Alpha",
-        "Intended Audience :: Developers",
-        "Intended Audience :: Science/Research",
-        "License :: OSI Approved :: Apache Software License",
-        "Natural Language :: English",
-        "Programming Language :: Python :: 3.8",
-        "Programming Language :: Python :: 3.9",
-        "Programming Language :: Python :: 3.10",
-        "Programming Language :: Python :: 3.11",
-        "Topic :: Scientific/Engineering :: Image Recognition",
-        "Topic :: Scientific/Engineering :: Mathematics",
-        "Topic :: Scientific/Engineering :: Medical Science Apps.",
-        "Topic :: Software Development :: Libraries :: Python Modules",
-        "Topic :: Software Development :: Libraries",
-    ],
-    keywords=[
-        "medical image analysis",
-        "deep learning",
-        "auto-segmentation",
-        "radiotherapy",
-        "DICOM conversion",
-        "DICOM data handling",
-        "DICOM-RT Structure Sets",
-    ],
-)
+import os
+import sys
+
+from setuptools import find_packages, setup
+
+if sys.version_info < (3, 8):
+    sys.exit("Requires Python 3.8 or higher")
+
+directory = os.path.abspath(os.path.dirname(__file__))
+
+about = {}
+with open(os.path.join(directory, "pyradise", "__version__.py"), "r", encoding="utf-8") as f:
+    exec(f.read(), about)
+
+with open(os.path.join(directory, "README.md"), "r", encoding="utf-8") as f:
+    readme = f.read()
+
+REQUIRED_PACKAGES = [
+    "pydicom",
+    "numpy",
+    "itk>=5.3rc4.post3",
+    "SimpleITK",
+    "opencv-python",
+    "scipy",
+    "vtk",
+]
+
+TEST_PACKAGES = [
+    "tox >= 3.4.0",
+    "tox-pipenv >= 1.10.1",
+    "pytest >= 7.0.0",
+    "pytest-cov >= 4.0.0",
+    "pipenv >= 2022.10.12",
+]
+
+setup(
+    name=about["__title__"],
+    version=about["__version__"],
+    description=about["__description__"],
+    long_description=readme,
+    long_description_content_type="text/markdown",
+    author=about["__author__"],
+    author_email=about["__author_email__"],
+    url=about["__url__"],
+    license=about["__license__"],
+    python_requires=">=3.8",
+    packages=find_packages(exclude=["docs", "examples", "test"]),
+    install_requires=REQUIRED_PACKAGES,
+    tests_require=REQUIRED_PACKAGES + TEST_PACKAGES,
+    classifiers=[
+        "Development Status :: 3 - Alpha",
+        "Intended Audience :: Developers",
+        "Intended Audience :: Science/Research",
+        "License :: OSI Approved :: Apache Software License",
+        "Natural Language :: English",
+        "Programming Language :: Python :: 3.8",
+        "Programming Language :: Python :: 3.9",
+        "Programming Language :: Python :: 3.10",
+        "Programming Language :: Python :: 3.11",
+        "Topic :: Scientific/Engineering :: Image Recognition",
+        "Topic :: Scientific/Engineering :: Mathematics",
+        "Topic :: Scientific/Engineering :: Medical Science Apps.",
+        "Topic :: Software Development :: Libraries :: Python Modules",
+        "Topic :: Software Development :: Libraries",
+    ],
+    keywords=[
+        "medical image analysis",
+        "deep learning",
+        "auto-segmentation",
+        "radiotherapy",
+        "DICOM conversion",
+        "DICOM data handling",
+        "DICOM-RT Structure Sets",
+    ],
+)
```

