# Comparing `tmp/pynidm-3.9.7.tar.gz` & `tmp/pynidm-4.0.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "pynidm-3.9.7.tar", last modified: Wed Jul 27 01:04:30 2022, max compression
+gzip compressed data, was "pynidm-4.0.0.tar", last modified: Tue May 30 18:26:26 2023, max compression
```

## Comparing `pynidm-3.9.7.tar` & `pynidm-4.0.0.tar`

### file list

```diff
@@ -1,104 +1,144 @@
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.938727 pynidm-3.9.7/
--rw-r--r--   0 runner    (1001) docker     (121)      600 2022-07-27 01:04:23.000000 pynidm-3.9.7/LICENSE
--rw-r--r--   0 runner    (1001) docker     (121)     1086 2022-07-27 01:04:30.938727 pynidm-3.9.7/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (121)    27401 2022-07-27 01:04:23.000000 pynidm-3.9.7/README.rst
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.926726 pynidm-3.9.7/bin/
--rwxr-xr-x   0 runner    (1001) docker     (121)      120 2022-07-27 01:04:23.000000 pynidm-3.9.7/bin/bidsmri2nidm
--rw-r--r--   0 runner    (1001) docker     (121)      116 2022-07-27 01:04:23.000000 pynidm-3.9.7/bin/csv2nidm
--rw-r--r--   0 runner    (1001) docker     (121)      118 2022-07-27 01:04:23.000000 pynidm-3.9.7/bin/nidm_query
--rwxr-xr-x   0 runner    (1001) docker     (121)      118 2022-07-27 01:04:23.000000 pynidm-3.9.7/bin/nidm_utils
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.930726 pynidm-3.9.7/nidm/
--rw-r--r--   0 runner    (1001) docker     (121)      245 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.930726 pynidm-3.9.7/nidm/core/
--rw-r--r--   0 runner    (1001) docker     (121)     5681 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/core/BIDS_Constants.py
--rw-r--r--   0 runner    (1001) docker     (121)    27450 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/core/Constants.py
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/core/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    15340 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/core/dot.py
--rw-r--r--   0 runner    (1001) docker     (121)    27638 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/core/provone.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.930726 pynidm-3.9.7/nidm/core/serializers/
--rw-r--r--   0 runner    (1001) docker     (121)     2161 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/core/serializers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)    30454 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/core/serializers/provonerdf.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.930726 pynidm-3.9.7/nidm/core/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/core/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4798 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/core/tests/test_provone.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.930726 pynidm-3.9.7/nidm/experiment/
--rw-r--r--   0 runner    (1001) docker     (121)     3158 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/Acquisition.py
--rw-r--r--   0 runner    (1001) docker     (121)     1914 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/AcquisitionObject.py
--rw-r--r--   0 runner    (1001) docker     (121)     1456 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/AssessmentAcquisition.py
--rw-r--r--   0 runner    (1001) docker     (121)     1999 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/AssessmentObject.py
--rw-r--r--   0 runner    (1001) docker     (121)     1763 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/CDE.py
--rw-r--r--   0 runner    (1001) docker     (121)    22703 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/Core.py
--rw-r--r--   0 runner    (1001) docker     (121)     1989 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/DataElement.py
--rw-r--r--   0 runner    (1001) docker     (121)     1793 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/DemographicsObject.py
--rw-r--r--   0 runner    (1001) docker     (121)     2767 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/Derivative.py
--rw-r--r--   0 runner    (1001) docker     (121)     1776 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/DerivativeObject.py
--rw-r--r--   0 runner    (1001) docker     (121)     1308 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/MRAcquisition.py
--rw-r--r--   0 runner    (1001) docker     (121)     1610 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/MRObject.py
--rw-r--r--   0 runner    (1001) docker     (121)    18318 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/Navigate.py
--rw-r--r--   0 runner    (1001) docker     (121)     1310 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/PETAcquisition.py
--rw-r--r--   0 runner    (1001) docker     (121)     1612 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/PETObject.py
--rw-r--r--   0 runner    (1001) docker     (121)     5386 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/Project.py
--rw-r--r--   0 runner    (1001) docker     (121)    52740 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/Query.py
--rw-r--r--   0 runner    (1001) docker     (121)     2601 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/Session.py
--rw-r--r--   0 runner    (1001) docker     (121)   118491 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/Utils.py
--rw-r--r--   0 runner    (1001) docker     (121)      589 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.934726 pynidm-3.9.7/nidm/experiment/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3246 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tests/create_testfile.py
--rw-r--r--   0 runner    (1001) docker     (121)     1551 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tests/read_nidm.py
--rw-r--r--   0 runner    (1001) docker     (121)     2366 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tests/termsearch.py
--rw-r--r--   0 runner    (1001) docker     (121)     4209 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tests/test_experiment.py
--rw-r--r--   0 runner    (1001) docker     (121)     6931 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tests/test_experiment_basic.py
--rw-r--r--   0 runner    (1001) docker     (121)      373 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tests/test_load_nidmowl.py
--rw-r--r--   0 runner    (1001) docker     (121)    10687 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tests/test_map_vars_to_terms.py
--rw-r--r--   0 runner    (1001) docker     (121)     4392 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tests/test_navigate.py
--rw-r--r--   0 runner    (1001) docker     (121)    15740 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tests/test_query.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.934726 pynidm-3.9.7/nidm/experiment/tools/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (121)    51913 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/bidsmri2nidm.py
--rw-r--r--   0 runner    (1001) docker     (121)       49 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/click_base.py
--rw-r--r--   0 runner    (1001) docker     (121)      387 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/click_main.py
--rw-r--r--   0 runner    (1001) docker     (121)    19874 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/csv2nidm.py
--rw-r--r--   0 runner    (1001) docker     (121)    38301 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm2bids.py
--rw-r--r--   0 runner    (1001) docker     (121)    17449 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_affinity_propagation.py
--rw-r--r--   0 runner    (1001) docker     (121)    17133 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_agglomerative_clustering.py
--rw-r--r--   0 runner    (1001) docker     (121)     2641 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_concat.py
--rw-r--r--   0 runner    (1001) docker     (121)     4195 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_convert.py
--rw-r--r--   0 runner    (1001) docker     (121)    22870 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_gmm.py
--rw-r--r--   0 runner    (1001) docker     (121)    24911 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_kmeans.py
--rw-r--r--   0 runner    (1001) docker     (121)    40082 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_linreg.py
--rw-r--r--   0 runner    (1001) docker     (121)     6630 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_merge.py
--rw-r--r--   0 runner    (1001) docker     (121)     9849 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_query.py
--rw-r--r--   0 runner    (1001) docker     (121)     4985 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_utils.py
--rw-r--r--   0 runner    (1001) docker     (121)      332 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_version.py
--rw-r--r--   0 runner    (1001) docker     (121)     2603 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/nidm_visualize.py
--rw-r--r--   0 runner    (1001) docker     (121)    29081 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/repronim_simple2_brainvolumes.py
--rw-r--r--   0 runner    (1001) docker     (121)    34797 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/rest.py
--rw-r--r--   0 runner    (1001) docker     (121)     2537 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/rest_statistics.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.934726 pynidm-3.9.7/nidm/experiment/tools/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     8227 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/tests/test_nidm_lingreg.py
--rw-r--r--   0 runner    (1001) docker     (121)      307 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/tests/test_nidm_query.py
--rw-r--r--   0 runner    (1001) docker     (121)    27019 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/tests/test_rest.py
--rw-r--r--   0 runner    (1001) docker     (121)     5271 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/tests/test_rest_dataelements.py
--rw-r--r--   0 runner    (1001) docker     (121)     5758 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/tests/test_rest_statistics.py
--rw-r--r--   0 runner    (1001) docker     (121)     3412 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/experiment/tools/tests/test_rest_subjects.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.934726 pynidm-3.9.7/nidm/terms/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/terms/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2442 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/version.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.934726 pynidm-3.9.7/nidm/workflows/
--rw-r--r--   0 runner    (1001) docker     (121)     1273 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/workflows/ProcessExecution.py
--rw-r--r--   0 runner    (1001) docker     (121)     1344 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/workflows/ProcessSpecification.py
--rw-r--r--   0 runner    (1001) docker     (121)      101 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/workflows/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.934726 pynidm-3.9.7/nidm/workflows/tests/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/workflows/tests/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      739 2022-07-27 01:04:23.000000 pynidm-3.9.7/nidm/workflows/tests/test_workflows.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2022-07-27 01:04:30.938727 pynidm-3.9.7/pynidm.egg-info/
--rw-r--r--   0 runner    (1001) docker     (121)     1086 2022-07-27 01:04:30.000000 pynidm-3.9.7/pynidm.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (121)     2897 2022-07-27 01:04:30.000000 pynidm-3.9.7/pynidm.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (121)        1 2022-07-27 01:04:30.000000 pynidm-3.9.7/pynidm.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (121)      105 2022-07-27 01:04:30.000000 pynidm-3.9.7/pynidm.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (121)      278 2022-07-27 01:04:30.000000 pynidm-3.9.7/pynidm.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (121)        5 2022-07-27 01:04:30.000000 pynidm-3.9.7/pynidm.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (121)       38 2022-07-27 01:04:30.938727 pynidm-3.9.7/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (121)      989 2022-07-27 01:04:23.000000 pynidm-3.9.7/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.452654 pynidm-4.0.0/
+-rw-r--r--   0 runner    (1001) docker     (123)     6782 2023-05-30 18:23:55.000000 pynidm-4.0.0/CHANGELOG.md
+-rw-r--r--   0 runner    (1001) docker     (123)      600 2023-05-30 18:23:22.000000 pynidm-4.0.0/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (123)      109 2023-05-30 18:23:22.000000 pynidm-4.0.0/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (123)    28540 2023-05-30 18:26:26.452654 pynidm-4.0.0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    27721 2023-05-30 18:23:22.000000 pynidm-4.0.0/README.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.424654 pynidm-4.0.0/docs/
+-rw-r--r--   0 runner    (1001) docker     (123)      608 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/Makefile
+-rw-r--r--   0 runner    (1001) docker     (123)     8127 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/REST_API_definition.openapi.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)      814 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/make.bat
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.420654 pynidm-4.0.0/docs/manuscripts/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.424654 pynidm-4.0.0/docs/manuscripts/linreg_joss/
+-rw-r--r--   0 runner    (1001) docker     (123)    33017 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/manuscripts/linreg_joss/fig-1.png
+-rw-r--r--   0 runner    (1001) docker     (123)    22892 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/manuscripts/linreg_joss/fig-2.png
+-rw-r--r--   0 runner    (1001) docker     (123)    62098 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/manuscripts/linreg_joss/fig-3.png
+-rw-r--r--   0 runner    (1001) docker     (123)    14415 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/manuscripts/linreg_joss/fig-4.png
+-rw-r--r--   0 runner    (1001) docker     (123)    22801 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/manuscripts/linreg_joss/paper.bib
+-rw-r--r--   0 runner    (1001) docker     (123)    15968 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/manuscripts/linreg_joss/paper.md
+-rw-r--r--   0 runner    (1001) docker     (123)       24 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/requirements.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.424654 pynidm-4.0.0/docs/source/
+-rw-r--r--   0 runner    (1001) docker     (123)     5048 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/source/conf.py
+-rw-r--r--   0 runner    (1001) docker     (123)    35260 2023-05-30 18:23:22.000000 pynidm-4.0.0/docs/source/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      128 2023-05-30 18:23:22.000000 pynidm-4.0.0/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (123)     1571 2023-05-30 18:26:26.452654 pynidm-4.0.0/setup.cfg
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.420654 pynidm-4.0.0/src/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.428654 pynidm-4.0.0/src/nidm/
+-rw-r--r--   0 runner    (1001) docker     (123)      204 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.428654 pynidm-4.0.0/src/nidm/core/
+-rw-r--r--   0 runner    (1001) docker     (123)     5656 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/core/BIDS_Constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27786 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/core/Constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/core/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.432654 pynidm-4.0.0/src/nidm/core/cde_dir/
+-rw-r--r--   0 runner    (1001) docker     (123)   114047 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/core/cde_dir/ants_cde.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)  1762832 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/core/cde_dir/fs_cde.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)    15004 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/core/cde_dir/fsl_cde.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)    15051 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/core/dot.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32283 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/core/provone.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.432654 pynidm-4.0.0/src/nidm/core/serializers/
+-rw-r--r--   0 runner    (1001) docker     (123)     2003 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/core/serializers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    30556 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/core/serializers/provonerdf.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.440654 pynidm-4.0.0/src/nidm/experiment/
+-rw-r--r--   0 runner    (1001) docker     (123)     3143 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/Acquisition.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1930 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/AcquisitionObject.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1221 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/AssessmentAcquisition.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1876 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/AssessmentObject.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1748 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/CDE.py
+-rw-r--r--   0 runner    (1001) docker     (123)    23391 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/Core.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1878 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/DataElement.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1679 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/DemographicsObject.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2648 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/Derivative.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1652 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/DerivativeObject.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1119 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/MRAcquisition.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1523 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/MRObject.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19843 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/Navigate.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1120 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/PETAcquisition.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1524 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/PETObject.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5090 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/Project.py
+-rw-r--r--   0 runner    (1001) docker     (123)    55218 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/Query.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2672 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/Session.py
+-rw-r--r--   0 runner    (1001) docker     (123)   132960 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/Utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1042 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.444654 pynidm-4.0.0/src/nidm/experiment/tools/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4107 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/agent.ttl
+-rwxr-xr-x   0 runner    (1001) docker     (123)    65168 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/bidsmri2nidm.py
+-rw-r--r--   0 runner    (1001) docker     (123)       50 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/click_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      242 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/click_main.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19563 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/csv2nidm.py
+-rw-r--r--   0 runner    (1001) docker     (123)    40521 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm2bids.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16573 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_affinity_propagation.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16230 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_agglomerative_clustering.py
+-rw-r--r--   0 runner    (1001) docker     (123)      967 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_concat.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2720 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_convert.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22214 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_gmm.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24780 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_kmeans.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32494 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_linreg.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5049 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_merge.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8871 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_query.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3790 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)      297 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_version.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1063 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/nidm_visualize.py
+-rw-r--r--   0 runner    (1001) docker     (123)    38609 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/repronim_simple2_brainvolumes.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1998 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/repronim_simple2_query.txt
+-rw-r--r--   0 runner    (1001) docker     (123)    37953 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/rest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2775 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/rest_statistics.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1215 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/experiment/tools/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.444654 pynidm-4.0.0/src/nidm/terms/
+-rw-r--r--   0 runner    (1001) docker     (123)       19 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.444654 pynidm-4.0.0/src/nidm/terms/imports/
+-rw-r--r--   0 runner    (1001) docker     (123)     1053 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/crypto_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)     3081 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/dc_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)    21156 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/iao_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)     1546 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/nfo_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)     5909 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/nlx_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)     4042 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/obi_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)    32076 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/ontoneurolog_instruments_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)    17082 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/pato_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)    68790 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/prov-o
+-rw-r--r--   0 runner    (1001) docker     (123)     9738 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/prv_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)     1880 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/qibo_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)    43335 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/sio_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)    29175 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/terms/imports/stato_import.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)      402 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/util.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.448654 pynidm-4.0.0/src/nidm/workflows/
+-rw-r--r--   0 runner    (1001) docker     (123)     1119 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/workflows/ProcessExecution.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1176 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/workflows/ProcessSpecification.py
+-rw-r--r--   0 runner    (1001) docker     (123)      290 2023-05-30 18:23:22.000000 pynidm-4.0.0/src/nidm/workflows/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.448654 pynidm-4.0.0/src/pynidm.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)    28540 2023-05-30 18:26:26.000000 pynidm-4.0.0/src/pynidm.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     4211 2023-05-30 18:26:26.000000 pynidm-4.0.0/src/pynidm.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-05-30 18:26:26.000000 pynidm-4.0.0/src/pynidm.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      269 2023-05-30 18:26:26.000000 pynidm-4.0.0/src/pynidm.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      280 2023-05-30 18:26:26.000000 pynidm-4.0.0/src/pynidm.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        5 2023-05-30 18:26:26.000000 pynidm-4.0.0/src/pynidm.egg-info/top_level.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.424654 pynidm-4.0.0/tests/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.448654 pynidm-4.0.0/tests/core/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/core/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4651 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/core/test_provone.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.452654 pynidm-4.0.0/tests/experiment/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2506 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3428 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/create_testfile.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1418 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/read_nidm.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2378 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/termsearch.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4499 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/test_experiment.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7003 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/test_experiment_basic.py
+-rw-r--r--   0 runner    (1001) docker     (123)      216 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/test_load_nidmowl.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11678 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/test_map_vars_to_terms.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4006 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/test_navigate.py
+-rw-r--r--   0 runner    (1001) docker     (123)   260961 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/test_nidm.png
+-rw-r--r--   0 runner    (1001) docker     (123)     4998 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/test_nidm.ttl
+-rw-r--r--   0 runner    (1001) docker     (123)    13219 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/test_query.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.452654 pynidm-4.0.0/tests/experiment/tools/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/tools/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6156 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/tools/test_nidm_lingreg.py
+-rw-r--r--   0 runner    (1001) docker     (123)      283 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/tools/test_nidm_query.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26479 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/tools/test_rest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3992 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/tools/test_rest_dataelements.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4038 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/tools/test_rest_statistics.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1925 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/experiment/tools/test_rest_subjects.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-30 18:26:26.452654 pynidm-4.0.0/tests/workflows/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/workflows/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      839 2023-05-30 18:23:22.000000 pynidm-4.0.0/tests/workflows/test_workflows.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1402 2023-05-30 18:23:22.000000 pynidm-4.0.0/tox.ini
```

### Comparing `pynidm-3.9.7/LICENSE` & `pynidm-4.0.0/LICENSE`

 * *Files identical despite different names*

### Comparing `pynidm-3.9.7/README.rst` & `pynidm-4.0.0/README.rst`

 * *Files 10% similar despite different names*

```diff
@@ -1,86 +1,93 @@
 .. image:: Logo.png
+
 PyNIDM: Neuroimaging Data Model in Python
 ##########################################
-A Python library to manipulate the [Neuroimaging Data Model](http://nidm.nidash.org). 
 
+A Python library to manipulate the `Neuroimaging Data Model <http://nidm.nidash.org>`_.
 
 |PyNIDM Testing| |Docs|
 
+.. |PyNIDM Testing| image:: https://github.com/incf-nidash/PyNIDM/actions/workflows/pythontest.yml/badge.svg
+    :target: https://github.com/incf-nidash/PyNIDM/actions/workflows/pythontest.yml
+    :alt: Status of PyNIDM Testing
+
+.. |Docs| image:: https://readthedocs.org/projects/pynidm/badge/?version=latest&style=plastic
+    :target: https://pynidm.readthedocs.io/en/latest/
+    :alt: ReadTheDocs Documentation of master branch
+
 .. contents::
 .. section-numbering::
 
-
 Dependencies
 ============
-* Git-annex <https://git-annex.branchable.com/install/>
-* Graphviz <http://graphviz.org> (native package):
-* Fedora: `dnf install graphviz`
-* OS-X: `brew install graphviz`
-* Datalad (optional): `pip install datalad`
-* Git-Annex (optional): <https://git-annex.branchable.com/>
+* `Git-annex <https://git-annex.branchable.com/install/>`_
+* `Graphviz <http://graphviz.org>`_ (native package):
+
+  * Fedora: `dnf install graphviz`
+  * OS-X: `brew install graphviz`
 
 Installation
 ============
 
-.. code-block:: bash
+.. code:: bash
 
 	$ pip install pynidm
 
-Creating a conda environment and installing the library (tested with OSX)
-=========================================================================
-
-macOS
------  
-.. code-block:: bash
-
-	$ conda create -n pynidm_py3 python=3
-	$ source activate pynidm_py3
-	$ cd PyNIDM
- 	$ pip install datalad
-	$ pip install neurdflib
-	$ pip install -e .
-
-You can try to run a test: `pytest`
-
-
 Contributing to the Software
 =============================
-This software is open source and community developed.  As such, we encourage anyone and everyone intersted in semantic web and neuroimaging to contribute.  To begin contributing code to the repository, please fork the main repo into your user space and use the pull request GitHub feature to submit code for review.  Please provide a reasonably detailed description of what was changed and why in the pull request.
+This software is open source and community developed.  As such, we encourage
+anyone and everyone interested in semantic web and neuroimaging to contribute.
+To begin contributing code to the repository, please fork the main repo into
+your user space and use the pull request GitHub feature to submit code for
+review.  Please provide a reasonably detailed description of what was changed
+and why in the pull request.
 
 Reporting Issues or Problems
 ============================
-If you encounter a bug, you can directly report it in the issues section. Please describe how to reproduce the issue and include as much information as possible that can be helpful for fixing it. If you would like to suggest a fix, please open a new pull request or include your suggested fix in the issue.
+If you encounter a bug, you can directly report it in the issues section.
+Please describe how to reproduce the issue and include as much information as
+possible that can be helpful for fixing it. If you would like to suggest a fix,
+please open a new pull request or include your suggested fix in the issue.
 
 Support and Feedback
 ====================
-We would love to hear your thoughts on our Python toolbox. Feedback, questions, or feature requests can also be submitted as issues. Note, we are a small band of researchers who mostly volunteer our time to this project.  We will respond as quickly as possible.
+We would love to hear your thoughts on our Python toolbox. Feedback, questions,
+or feature requests can also be submitted as issues. Note, we are a small band
+of researchers who mostly volunteer our time to this project.  We will respond
+as quickly as possible.
 
 NIDM-Experiment Tools
 =====================
 
 BIDS MRI Conversion to NIDM
 ---------------------------
 
-This program will convert a BIDS MRI dataset to a NIDM-Experiment RDF document.  It will parse phenotype information and simply store variables/values and link to the associated json data dictionary file.  To use this tool please set your INTERLEX_API_KEY environment variable to your unique API key.  To get an Interlex API key you visit [SciCrunch](http://scicrunch.org/nidm-terms), register for an account, then click on "MyAccount" and "API Keys" to add a new API key for your account.
+This program will convert a BIDS MRI dataset to a NIDM-Experiment RDF document.
+It will parse phenotype information and simply store variables/values and link
+to the associated json data dictionary file.  To use this tool please set your
+INTERLEX_API_KEY environment variable to your unique API key.  To get an
+Interlex API key you visit `SciCrunch <http://scicrunch.org/nidm-terms>`_,
+register for an account, then click on "MyAccount" and "API Keys" to add a new
+API key for your account.
 
 
-.. code-block:: bash
+.. code:: bash
 
    $ bidsmri2nidm -d [ROOT BIDS DIRECT] -bidsignore
 
    usage: bidsmri2nidm [-h] -d DIRECTORY [-jsonld] [-bidsignore] [-no_concepts]
                     [-json_map JSON_MAP] [-log LOGFILE] [-o OUTPUTFILE]
 
    This program will represent a BIDS MRI dataset as a NIDM RDF document and provide user with opportunity to annotate
    the dataset (i.e. create sidecar files) and associate selected variables with broader concepts to make datasets more
-   FAIR. 
+   FAIR.
 
    Note, you must obtain an API key to Interlex by signing up for an account at scicrunch.org then going to My Account
-   and API Keys.  Then set the environment variable INTERLEX_API_KEY with your key. 
+   and API Keys.  Then set the environment variable INTERLEX_API_KEY with your key.
 
    optional arguments:
      -h, --help            show this help message and exit
      -d DIRECTORY          Full path to BIDS dataset directory
      -jsonld, --jsonld     If flag set, output is json-ld not TURTLE
      -bidsignore, --bidsignore
                         If flag set, tool will add NIDM-related files to .bidsignore file
@@ -93,22 +100,25 @@
    map variables to terms arguments:
      -json_map JSON_MAP, --json_map JSON_MAP
                         Optional full path to user-suppled JSON file containing data element defintitions.
 
 
 CSV File to NIDM Conversion
 ---------------------------
-This program will load in a CSV file and iterate over the header variable
-names performing an elastic search of https://scicrunch.org/nidm-terms for NIDM-ReproNim
-tagged terms that fuzzy match the variable names. The user will then
-interactively pick a term to associate with the variable name. The resulting
-annotated CSV data will then be written to a NIDM data file.  To use this tool please set your INTERLEX_API_KEY environment variable to your unique API key.  To get an Interlex API key you visit [SciCrunch](http://scicrunch.org/nidm-terms), register for an account, then click on "MyAccount" and "API Keys" to add a new API key for your account.
-
+This program will load in a CSV file and iterate over the header variable names
+performing an elastic search of https://scicrunch.org/nidm-terms for
+NIDM-ReproNim tagged terms that fuzzy match the variable names. The user will
+then interactively pick a term to associate with the variable name. The
+resulting annotated CSV data will then be written to a NIDM data file.  To use
+this tool please set your INTERLEX_API_KEY environment variable to your unique
+API key.  To get an Interlex API key you visit `SciCrunch
+<http://scicrunch.org/nidm-terms>`_, register for an account, then click on
+"MyAccount" and "API Keys" to add a new API key for your account.
 
-.. code-block:: bash
+.. code:: bash
 
   usage: csv2nidm [-h] -csv CSV_FILE [-json_map JSON_MAP | -redcap REDCAP]
                   [-nidm NIDM_FILE] [-no_concepts] [-log LOGFILE] -out
                   OUTPUT_FILE
 
   This program will load in a CSV file and iterate over the header variable
   names performing an elastic search of https://scicrunch.org/ for NIDM-ReproNim
@@ -138,74 +148,67 @@
     -log LOGFILE, --log LOGFILE
                           full path to directory to save log file. Log file name
                           is csv2nidm_[arg.csv_file].log
     -out OUTPUT_FILE      Full path with filename to save NIDM file
 
 convert
 -------
-This function will convert NIDM files to various RDF-supported formats and
-name then / put them in the same place as the input file.
+This function will convert NIDM files to various RDF-supported formats and name
+then / put them in the same place as the input file.
 
-.. code-block:: bash
+.. code:: bash
 
   Usage: pynidm convert [OPTIONS]
 
   Options:
     -nl, --nidm_file_list TEXT      A comma separated list of NIDM files with
                                   full path  [required]
     -t, --type [turtle|jsonld|xml-rdf|n3|trig]
                                   If parameter set then NIDM file will be
                                   exported as JSONLD  [required]
     --help                          Show this message and exit.
 
-.. |PyNIDM Testing| image:: https://github.com/incf-nidash/PyNIDM/actions/workflows/pythontest.yml/badge.svg
-   :target: https://github.com/incf-nidash/PyNIDM/actions/workflows/pythontest.yml
-   :alt: Status of PyNIDM Testing
-.. |Docs| image:: https://readthedocs.org/projects/pynidm/badge/?version=latest&style=plastic
-    :target: https://pynidm.readthedocs.io/en/latest/
-    :alt: ReadTheDocs Documentation of master branch
-
 concatenate
 -----------
-This function will concatenate NIDM files.  Warning, no merging will be
-done so you may end up with multiple prov:agents with the same subject id
-if you're concatenating NIDM files from multiple vists of the same study.
-If you want to merge NIDM files on subject ID see pynidm merge
+This function will concatenate NIDM files.  Warning, no merging will be done so
+you may end up with multiple prov:agents with the same subject id if you're
+concatenating NIDM files from multiple visits of the same study.  If you want
+to merge NIDM files on subject ID see pynidm merge
 
-.. code-block:: bash
+.. code:: bash
 
   Usage: pynidm concat [OPTIONS]
 
   Options:
     -nl, --nidm_file_list TEXT  A comma separated list of NIDM files with full
                               path  [required]
     -o, --out_file TEXT         File to write concatenated NIDM files
                               [required]
     --help                      Show this message and exit.
-  
+
 visualize
 ---------
-This command will produce a visualization(pdf) of the supplied NIDM files
-named the same as the input files and stored in the same directories.
+This command will produce a visualization(pdf) of the supplied NIDM files named
+the same as the input files and stored in the same directories.
 
-.. code-block:: bash
+.. code:: bash
 
   Usage: pynidm visualize [OPTIONS]
 
   Options:
     -nl, --nidm_file_list TEXT  A comma separated list of NIDM files with full
                               path  [required]
     --help                      Show this message and exit.
-  
+
 merge
 -----
-This function will merge NIDM files.  See command line parameters for
-supported merge operations.
+This function will merge NIDM files.  See command line parameters for supported
+merge operations.
 
-.. code-block:: bash
+.. code:: bash
 
    Usage: pynidm merge [OPTIONS]
 
    Options:
      -nl, --nidm_file_list TEXT  A comma separated list of NIDM files with full
                               path  [required]
      -s, --s                     If parameter set then files will be merged by
@@ -214,252 +217,302 @@
                               [required]
 	 --help                      Show this message and exit.
 
 Query
 -----
 This function provides query support for NIDM graphs.
 
-.. code-block:: bash
+.. code:: bash
 
-Usage: pynidm query [OPTIONS]
+    Usage: pynidm query [OPTIONS]
 
-Options:
-  -nl, --nidm_file_list TEXT      A comma separated list of NIDM files with
-                                  full path  [required]
-  -nc, --cde_file_list TEXT       A comma separated list of NIDM CDE files
-                                  with full path. Can also be set in the
-                                  CDE_DIR environment variable
-  -q, --query_file FILENAME       Text file containing a SPARQL query to
-                                  execute
-  -p, --get_participants          Parameter, if set, query will return
-                                  participant IDs and prov:agent entity IDs
-  -i, --get_instruments           Parameter, if set, query will return list of
-                                  onli:assessment-instrument:
-  -iv, --get_instrument_vars      Parameter, if set, query will return list of
-                                  onli:assessment-instrument: variables
-  -de, --get_dataelements         Parameter, if set, will return all
-                                  DataElements in NIDM file
-  -debv, --get_dataelements_brainvols
-                                  Parameter, if set, will return all brain
-                                  volume DataElements in NIDM file along with
-                                  details
-  -bv, --get_brainvols            Parameter, if set, will return all brain
-                                  volume data elements and values along with
-                                  participant IDs in NIDM file
-  -o, --output_file TEXT          Optional output file (CSV) to store results
-                                  of query
-  -u, --uri TEXT                  A REST API URI query
-  -j / -no_j                      Return result of a uri query as JSON
-  -v, --verbosity TEXT            Verbosity level 0-5, 0 is default
-  --help                          Show this message and exit.
+    Options:
+      -nl, --nidm_file_list TEXT      A comma separated list of NIDM files with
+                                      full path  [required]
+      -nc, --cde_file_list TEXT       A comma separated list of NIDM CDE files
+                                      with full path. Can also be set in the
+                                      CDE_DIR environment variable
+      -q, --query_file FILENAME       Text file containing a SPARQL query to
+                                      execute
+      -p, --get_participants          Parameter, if set, query will return
+                                      participant IDs and prov:agent entity IDs
+      -i, --get_instruments           Parameter, if set, query will return list of
+                                      onli:assessment-instrument:
+      -iv, --get_instrument_vars      Parameter, if set, query will return list of
+                                      onli:assessment-instrument: variables
+      -de, --get_dataelements         Parameter, if set, will return all
+                                      DataElements in NIDM file
+      -debv, --get_dataelements_brainvols
+                                      Parameter, if set, will return all brain
+                                      volume DataElements in NIDM file along with
+                                      details
+      -bv, --get_brainvols            Parameter, if set, will return all brain
+                                      volume data elements and values along with
+                                      participant IDs in NIDM file
+      -o, --output_file TEXT          Optional output file (CSV) to store results
+                                      of query
+      -u, --uri TEXT                  A REST API URI query
+      -j / -no_j                      Return result of a uri query as JSON
+      -v, --verbosity TEXT            Verbosity level 0-5, 0 is default
+      --help                          Show this message and exit.
 
-Details on the REST API URI format and usage can be found on the :ref:`REST API usage<rest>` page.
+Details on the REST API URI format and usage can be found on the REST API usage
+page.
 
 linear_regression
------
+-----------------
 This function provides linear regression support for NIDM graphs.
 
-.. code-block:: bash
-
-Usage: pynidm linear-regression [OPTIONS]
-
-Options:
-  -nl, --nidm_file_list TEXT      A comma-separated list of NIDM files with
-                                  full path  [required]
-  -r, --regularization TEXT       Parameter, if set, will return the results of
-  				  the linear regression with L1 or L2 regularization 
-				  depending on the type specified, and the weight 
-				  with the maximum likelihood solution. This will
-				  prevent overfitting. (Ex: -r L1)
-  -model, --ml TEXT 		  An equation representing the linear
-  				  regression. The dependent variable comes
-				  first, followed by "=" or "~", followed by
-				  the independent variables separated by "+"
-				  (Ex: -model "fs_003343 = age*sex + sex + 
-				  age + group + age*group + bmi") [required]
-  -contstant, --ctr TEXT       	  Parameter, if set, will return differences in
-  				  variable relationships by group. One or
-				  multiple parameters can be used (multiple 
-				  parameters should be separated by a comma-
-				  separated list) (Ex: -contrast group,age)
-  -o, --output_file TEXT          Optional output file (TXT) to store results
-                                  of query
-  --help                          Show this message and exit.
-  
-To use the linear regression algorithm successfully, structure, syntax, and querying is important. Here is how to maximize the usefulness of the tool:
-
-
-First, use pynidm query to discover the variables to use. PyNIDM allows for the use of either data elements (PIQ_tca9ck), specific URLs (http://uri.interlex.org/ilx_0100400), or source variables (DX_GROUP).
-
-An example of a potential query is: pynidm query -nl /simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_a/nidm.ttl,/simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_b/nidm.ttl -u /projects?fields=fs_000008,DX_GROUP,PIQ_tca9ck,http://uri.interlex.org/ilx_0100400
-
-You can also do:
-pynidm query -nl /simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_a/nidm.ttl,/Users/Ashu/Downloads/simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_b/nidm.ttl -gf fs_000008,DX_GROUP,PIQ_tca9ck,http://uri.interlex.org/ilx_0100400
-
-The query looks in the two files specified in the -nl parameter for the variables specified. In this case, we use fs_000008 and DX_GROUP (source variables), a URL (http://uri.interlex.org/ilx_0100400), and a data element (PIQ_tca9ck). The output of the file is slightly different depending on whether you use -gf or -u. With -gf, it will return the variables from both files separately, while -u combines them.
-
-Now that we have selected the variables, we can perform a linear regression. In this example, we will look at the effect of DX_GROUP, age at scan, and PIQ on supratentorial brain volume.
+.. code:: bash
 
-The command to use for this particular data is:
-pynidm linear-regression -nl /simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_a/nidm.ttl,/simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_b/nidm.ttl -model "fs_000008 = DX_GROUP + PIQ_tca9ck + http://uri.interlex.org/ilx_0100400" -contrast "DX_GROUP" -r L1
+    Usage: pynidm linear-regression [OPTIONS]
 
--nl specifies the file(s) to pull data from, while -model is the model to perform a linear regression model on. In this case, the variables are fs_000008 (the dependent variable, supratentorial brain volume), DX_GROUP (diagnostic group), PIQ_tca9ck (PIQ), and http://uri.interlex.org/ilx_0100400 (age at scan). The -contrast paramter says to contrast the data using DX_GROUP, and then do a L1 regularization to prevent overfitting. 
+    Options:
+      -nl, --nidm_file_list TEXT      A comma-separated list of NIDM files with
+                                      full path  [required]
+      -r, --regularization TEXT       Parameter, if set, will return the results of
+                                      the linear regression with L1 or L2 regularization
+                                      depending on the type specified, and the weight
+                                      with the maximum likelihood solution. This will
+                                      prevent overfitting. (Ex: -r L1)
+      -model, --ml TEXT 		  An equation representing the linear
+                                      regression. The dependent variable comes
+                                      first, followed by "=" or "~", followed by
+                                      the independent variables separated by "+"
+                                      (Ex: -model "fs_003343 = age*sex + sex +
+                                      age + group + age*group + bmi") [required]
+      -contstant, --ctr TEXT       	  Parameter, if set, will return differences in
+                                      variable relationships by group. One or
+                                      multiple parameters can be used (multiple
+                                      parameters should be separated by a comma-
+                                      separated list) (Ex: -contrast group,age)
+      -o, --output_file TEXT          Optional output file (TXT) to store results
+                                      of query
+      --help                          Show this message and exit.
+
+To use the linear regression algorithm successfully, structure, syntax, and
+querying is important. Here is how to maximize the usefulness of the tool:
+
+First, use pynidm query to discover the variables to use. PyNIDM allows for the
+use of either data elements (PIQ_tca9ck), specific URLs
+(http://uri.interlex.org/ilx_0100400), or source variables (DX_GROUP).
+
+An example of a potential query is::
+
+    pynidm query -nl /simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_a/nidm.ttl,/simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_b/nidm.ttl -u /projects?fields=fs_000008,DX_GROUP,PIQ_tca9ck,http://uri.interlex.org/ilx_0100400
+
+You can also do::
+
+    pynidm query -nl /simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_a/nidm.ttl,/Users/Ashu/Downloads/simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_b/nidm.ttl -gf fs_000008,DX_GROUP,PIQ_tca9ck,http://uri.interlex.org/ilx_0100400
+
+The query looks in the two files specified in the -nl parameter for the
+variables specified. In this case, we use fs_000008 and DX_GROUP (source
+variables), a URL (http://uri.interlex.org/ilx_0100400), and a data element
+(PIQ_tca9ck). The output of the file is slightly different depending on whether
+you use -gf or -u. With -gf, it will return the variables from both files
+separately, while -u combines them.
+
+Now that we have selected the variables, we can perform a linear regression. In
+this example, we will look at the effect of DX_GROUP, age at scan, and PIQ on
+supratentorial brain volume.
+
+The command to use for this particular data is::
+
+    pynidm linear-regression -nl /simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_a/nidm.ttl,/simple2_NIDM_examples/datasets.datalad.org/abide/RawDataBIDS/CMU_b/nidm.ttl -model "fs_000008 = DX_GROUP + PIQ_tca9ck + http://uri.interlex.org/ilx_0100400" -contrast "DX_GROUP" -r L1
+
+-nl specifies the file(s) to pull data from, while -model is the model to
+perform a linear regression model on. In this case, the variables are fs_000008
+(the dependent variable, supratentorial brain volume), DX_GROUP (diagnostic
+group), PIQ_tca9ck (PIQ), and http://uri.interlex.org/ilx_0100400 (age at
+scan). The -contrast parameter says to contrast the data using DX_GROUP, and
+then do a L1 regularization to prevent overfitting.
 
 Details on the REST API URI format and usage can be found below.
 
 PyNIDM: REST API and Command Line Usage
 ##########################################
 
 Introduction
 ============
 
-There are two main ways to interact with NIDM data using the PyNIDM REST API. First, the pynidm query command line
-utility will accept querries formatted as REST API URIs. Second, the rest-server.py script can be used to run a
-HTTP server to accept and process requests. This script can either be run directly or using a docker container
-defined in the docker directory of the project.
+There are two main ways to interact with NIDM data using the PyNIDM REST API.
+First, the pynidm query command line utility will accept queries formatted as
+REST API URIs. Second, the rest-server.py script can be used to run a HTTP
+server to accept and process requests. This script can either be run directly
+or using a docker container defined in the docker directory of the project.
 
 Example usage:
 
-.. code-block:: bash
+.. code:: bash
 
    $ pynidm query -nl "cmu_a.ttl,cmu_b.ttl" -u /projects
 
    dc1bf9be-10a3-11ea-8779-003ee1ce9545
    ebe112da-10a3-11ea-af83-003ee1ce9545
 
-   $
-
 Installation
 ============
 
 To use the REST API query syntax on the command line, follow the PyNIDM
 `installation instructions <https://github.com/incf-nidash/PyNIDM/>`_.
 
-The simplest way to deploy a HTTP REST API server would be with the provided docker container. You can find instructions
-for that process in the `README.md <https://github.com/incf-nidash/PyNIDM/tree/master/docker>`_ file in the docker
+The simplest way to deploy a HTTP REST API server would be with the provided
+docker container. You can find instructions for that process in the `README.md
+<https://github.com/incf-nidash/PyNIDM/tree/master/docker>`_ file in the docker
 directory of the Github repository.
 
 
 URI formats
 ===========
 
-You can find details on the REST API at the `SwaggerHub API Documentation <https://app.swaggerhub.com/apis-docs/albertcrowley/PyNIDM>`_.
-The OpenAPI specification file is part of the Github repository in 'docs/REST_API_definition.openapi.yaml'
+You can find details on the REST API at the `SwaggerHub API Documentation
+<https://app.swaggerhub.com/apis-docs/albertcrowley/PyNIDM>`_.  The OpenAPI
+specification file is part of the Github repository in
+'docs/REST_API_definition.openapi.yaml'
 
-Here is a list of the current operations. See the SwaggerHub page for more details and return formats.
+Here is a list of the current operations. See the SwaggerHub page for more
+details and return formats.
 
 ::
 
-- /projects
-- /projects/{project_id}
-- /projects/{project_id}/subjects
-- /projects/{project_id}/subjects?filter=[filter expression]
-- /projects/{project_id}/subjects/{subject_id}
-- /projects/{project_id}/subjects/{subject_id}/instruments/{instrument_id}
-- /projects/{project_id}/subjects/{subject_id}/derivatives/{derivative_id}
-- /statistics/projects/{project_id}
-
-You can append the following query parameters to many of the operations:
+    - /projects
+    - /projects/{project_id}
+    - /projects/{project_id}/subjects
+    - /projects/{project_id}/subjects?filter=[filter expression]
+    - /projects/{project_id}/subjects/{subject_id}
+    - /projects/{project_id}/subjects/{subject_id}/instruments/{instrument_id}
+    - /projects/{project_id}/subjects/{subject_id}/derivatives/{derivative_id}
+    - /statistics/projects/{project_id}
 
-::
+You can append the following query parameters to many of the operations::
 
-- filter
-- field
+    - filter
+    - field
 
 Operations
 -----------
 
-**/projects**
- | Get a list of all project IDs available.
- | Supported query parameters: none
-
-**/projects/{project_id}**
- | See some details for a project. This will include the list of subject IDs and data elements used in the project
- | Supported query parameters: fitler
-
-**/projects/{project_id}/subjects**
- | Get the list of subjects in a project
- | Supported query parameters: filter
-
-**/projects/{project_id}/subjects/{subject_id}**
- | Get the details for a particular subject. This will include the results of any instrumnts or derivatives associated with the subject, as well a a list of the related activites.
- | Supported query parameters: none
-
-**/projects/{project_id}/subjects/{subject_id}/instruments/{instrument_id}**
- | Get the values for a particular instrument
- | Supported query parameters: none
-
-**/projects/{project_id}/subjects/{subject_id}/derivatives/{derivative_id}**
- | Get the values for a particular derivative
- | Supported query parameters: none
-
-**/statistics/projects/{project_id}**
- | See project statistics. You can also use this operation to get statsitcs on a particular instrument or derivative entry by use a *field* query option.
- | Supported query parameters: filter, field
-
-**/statistics/projects/{project_id}/subjects/{subject_id}**
- | See some details for a project. This will include the list of subject IDs and data elements used in the project
- | Supported query parameters: none
+``/projects``
+    Get a list of all project IDs available.
+
+    Supported query parameters: none
+
+``/projects/{project_id}``
+    See some details for a project. This will include the list of subject IDs
+    and data elements used in the project
+
+    Supported query parameters: filter
+
+``/projects/{project_id}/subjects``
+    Get the list of subjects in a project
+
+    Supported query parameters: filter
+
+``/projects/{project_id}/subjects/{subject_id}``
+    Get the details for a particular subject. This will include the results of
+    any instrumnts or derivatives associated with the subject, as well as a
+    list of the related activities.
+
+    Supported query parameters: none
+
+``/projects/{project_id}/subjects/{subject_id}/instruments/{instrument_id}``
+    Get the values for a particular instrument
+
+    Supported query parameters: none
+
+``/projects/{project_id}/subjects/{subject_id}/derivatives/{derivative_id}``
+    Get the values for a particular derivative
+
+    Supported query parameters: none
+
+``/statistics/projects/{project_id}``
+    See project statistics. You can also use this operation to get statsitcs on
+    a particular instrument or derivative entry by use a *field* query option.
+
+    Supported query parameters: filter, field
+
+``/statistics/projects/{project_id}/subjects/{subject_id}``
+    See some details for a project. This will include the list of subject IDs
+    and data elements used in the project
+
+    Supported query parameters: none
 
 Query Parameters
 -----------------
 
-**filter**
- | The filter query parameter is ues when you want to receive data only on subjects that match some criteria.  The format for the fitler value should be of the form:
- |    *identifier op value [ and identifier op value and ... ]*
- | Identifers should be formatted as "instrument.ID" or "derivatives.ID"  You can use any value for the instrument ID that is shown for an instrument or in the data_elements section of the project details. For the derivative ID, you can use the last component of a derivative field URI (ex. for the URI http://purl.org/nidash/fsl#fsl_000007, the ID would be "fsl_000007") or the exact label shown when viewing derivative data (ex. "Left-Caudate (mm^3)")
- | The *op* can be one of "eq", "gt", "lt"
-
- | **Example filters:**
- |    *?filter=instruments.AGE_AT_SCAN gt 30*
- |    *?filter=instrument.AGE_AT_SCAN eq 21 and derivative.fsl_000007 lt 3500*
-
-**fields**
- | The fields query parameter is used to specify what fields should be detailed in a statistics operation. For each field specified the result will show minimum, maximum, average, median, and standard deviation for the values of that field across all subjects matching the operation and filter. Multiple fields can be specified by separating each field with a comma.
- | Fields should be formatted in the same way as identifiers are specified in the filter parameter.
+``filter``
+    The filter query parameter is used when you want to receive data only on
+    subjects that match some criteria.  The format for the filter value should
+    be of the form::
+
+        identifier op value [ and identifier op value and ... ]
+
+    Identifiers should be formatted as "instrument.ID" or "derivatives.ID"  You
+    can use any value for the instrument ID that is shown for an instrument or
+    in the data_elements section of the project details. For the derivative ID,
+    you can use the last component of a derivative field URI (ex. for the URI
+    http://purl.org/nidash/fsl#fsl_000007, the ID would be "fsl_000007") or the
+    exact label shown when viewing derivative data (ex. "Left-Caudate (mm^3)").
+
+    The ``op`` can be one of "eq", "gt", "lt".
+
+    Example filters:
+        ``?filter=instruments.AGE_AT_SCAN gt 30``
+        ``?filter=instrument.AGE_AT_SCAN eq 21 and derivative.fsl_000007 lt 3500``
+
+``fields``
+    The fields query parameter is used to specify what fields should be
+    detailed in a statistics operation. For each field specified the result
+    will show minimum, maximum, average, median, and standard deviation for the
+    values of that field across all subjects matching the operation and filter.
+    Multiple fields can be specified by separating each field with a comma.
 
- | **Example field query:**
- |    *http://localhost:5000/statistics/projects/abc123?field=instruments.AGE_AT_SCAN,derivatives.fsl_000020*
+    Fields should be formatted in the same way as identifiers are specified in
+    the filter parameter.
+
+    Example field query:
+        ``http://localhost:5000/statistics/projects/abc123?field=instruments.AGE_AT_SCAN,derivatives.fsl_000020``
 
 
 Return Formatting
 ==================
 
-By default the HTTP REST API server will return JSON formatted objects or arrays.  When using the pynidm query
-command line utility the default return format is text (when possible) or you can use the -j option to have the
-output formatted as JSON.
-
-
+By default the HTTP REST API server will return JSON formatted objects or
+arrays.  When using the pynidm query command line utility the default return
+format is text (when possible) or you can use the -j option to have the output
+formatted as JSON.
 
 Examples
 --------
 
-**Get the UUID for all the projects at this locaiton:**
+Get the UUID for all the projects at this location
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-.. code-block:: bash
+.. code:: bash
 
    curl http://localhost:5000/projects
 
 Example response:
 
-.. code-block:: JSON
+.. code:: JSON
 
    [
        "dc1bf9be-10a3-11ea-8779-003ee1ce9545"
    ]
 
-**Get the project summary details:**
+Get the project summary details
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-.. code-block:: HTML
+.. code:: bash
 
    curl http://localhost:5000/projects/dc1bf9be-10a3-11ea-8779-003ee1ce9545
 
 Example response:
 
-.. code-block:: JSON
+.. code:: JSON
 
    {
     "http://www.w3.org/1999/02/22-rdf-syntax-ns#type": "http://purl.org/nidash/nidm#Project",
     "dctypes:title": "ABIDE CMU_a Site",
     "http://www.w3.org/ns/prov#Location": "/datasets.datalad.org/abide/RawDataBIDS/CMU_a",
     "sio:Identifier": "1.0.1",
     "nidm:NIDM_0000171": 14,
@@ -472,23 +525,22 @@
     "obo:handedness": [
         "R",
         "L",
         "Ambi"
     ]
    }
 
-**Get the subjects in a project:**
+Get the subjects in a project
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-.. code-block:: HTML
+.. code:: bash
 
    pynidm query -nl "cmu_a.nidm.ttl" -u http://localhost:5000/projects/dc1bf9be-10a3-11ea-8779-003ee1ce9545/subjects
 
-Example response:
-
-.. code-block:: JSON
+Example response::
 
    deef8eb2-10a3-11ea-8779-003ee1ce9545
    df533e6c-10a3-11ea-8779-003ee1ce9545
    ddbfb454-10a3-11ea-8779-003ee1ce9545
    df21cada-10a3-11ea-8779-003ee1ce9545
    dcfa35b2-10a3-11ea-8779-003ee1ce9545
    de89ce4c-10a3-11ea-8779-003ee1ce9545
@@ -498,24 +550,22 @@
    de245134-10a3-11ea-8779-003ee1ce9545
    dd5f2f30-10a3-11ea-8779-003ee1ce9545
    dd8d4faa-10a3-11ea-8779-003ee1ce9545
    df87cbaa-10a3-11ea-8779-003ee1ce9545
    de55285e-10a3-11ea-8779-003ee1ce9545
 
 
-**Use the command line to get statistics on a project for the AGE_AT_SCAN and a FSL data element:**
+Use the command line to get statistics on a project for the AGE_AT_SCAN and a FSL data element
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-.. code-block:: HTML
+.. code:: bash
 
    pynidm query -nl ttl/cmu_a.nidm.ttl -u /statistics/projects/dc1bf9be-10a3-11ea-8779-003ee1ce9545?fields=instruments.AGE_AT_SCAN,derivatives.fsl_000001
 
-Example response:
-
-
-.. code-block:: bash
+Example response::
 
   -------------------------------------------------  ---------------------------------------------
   "http://www.w3.org/1999/02/22-rdf-syntax-ns#type"  http://www.w3.org/ns/prov#Activity
   "title"                                            ABIDE CMU_a Site
   "Identifier"                                       1.0.1
   "prov:Location"                                    /datasets.datalad.org/abide/RawDataBIDS/CMU_a
   "NIDM_0000171"                                     14
@@ -562,23 +612,26 @@
   fsl_000001  max                 1.14899e+07
   fsl_000001  min                 5.5193e+06
   fsl_000001  median              7.66115e+06
   fsl_000001  mean                8.97177e+06
   fsl_000001  standard_deviation  2.22465e+06
   ----------  ------------------  -----------
 
-**Get details on a subject. Use -j for a JSON formatted resonse:**
+Get details on a subject
+~~~~~~~~~~~~~~~~~~~~~~~~
+
+Use ``-j`` for a JSON-formatted response
 
-.. code-block:: HTML
+.. code:: bash
 
    pynidm query -j -nl "cmu_a.nidm.ttl" -u http://localhost:5000/projects/dc1bf9be-10a3-11ea-8779-003ee1ce9545/subjects/df21cada-10a3-11ea-8779-003ee1ce9545
 
 Example response:
 
-.. code-block:: JSON
+.. code:: JSON
 
    {
   "uuid": "df21cada-10a3-11ea-8779-003ee1ce9545",
   "id": "0050665",
   "activity": [
     "e28dc764-10a3-11ea-a7d3-003ee1ce9545",
     "df28e95a-10a3-11ea-8779-003ee1ce9545",
@@ -639,8 +692,7 @@
 =============================
 
 * NIDM-Terms <https://github.com/NIDM-Terms/terms>
 * NIDM-Terms Scicrunch Interface <https://scicrunch.org/nidm-terms>
 * Freesurfer stats -> NIDM <https://github.com/repronim/segstats_jsonld>
 * FSL structural segmentation -> NIDM <https://github.com/ReproNim/fsl_seg_to_nidm>
 * ANTS structural segmentation -> NIDM <https://github.com/ReproNim/ants_seg_to_nidm>
-
```

### Comparing `pynidm-3.9.7/nidm/core/BIDS_Constants.py` & `pynidm-4.0.0/src/nidm/core/BIDS_Constants.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,115 +1,119 @@
 #!/usr/bin/env python
-''' BIDS Terms -> NIDM-Exp Mappings
+""" BIDS Terms -> NIDM-Exp Mappings
 @author: David Keator <dbkeator@uci.edu>
-'''
+"""
 from . import Constants
-#BIDS dataset_description -> NIDM constants mappings
-dataset_description = {
-    "BIDSVersion" : Constants.NIDM_PROJECT_IDENTIFIER,
-    "Name" : Constants.NIDM_PROJECT_NAME,
-    "Procedure" : Constants.NIDM_PROJECT_DESCRIPTION,
-    "License" : Constants.NIDM_PROJECT_LICENSE,
-    "ReferencesAndLinks" : Constants.NIDM_PROJECT_REFERENCES,
-    "Authors" : Constants.NIDM_AUTHOR,
-    "DatasetDOI" : Constants.NIDM_DOI,
-    "Funding" : Constants.NIDM_FUNDING,
-    "HowToAcknowledge" : Constants.NIDM_ACKNOWLEDGEMENTS
 
+# BIDS dataset_description -> NIDM constants mappings
+dataset_description = {
+    "BIDSVersion": Constants.NIDM_PROJECT_IDENTIFIER,
+    "Name": Constants.NIDM_PROJECT_NAME,
+    "Procedure": Constants.NIDM_PROJECT_DESCRIPTION,
+    "License": Constants.NIDM_PROJECT_LICENSE,
+    "ReferencesAndLinks": Constants.NIDM_PROJECT_REFERENCES,
+    "Authors": Constants.NIDM_AUTHOR,
+    "DatasetDOI": Constants.NIDM_DOI,
+    "Funding": Constants.NIDM_FUNDING,
+    "HowToAcknowledge": Constants.NIDM_ACKNOWLEDGEMENTS,
 }
 
-#BIDS Participants file -> NIDM constants mappings
+# BIDS Participants file -> NIDM constants mappings
 participants = {
-    "participant_id" : Constants.NIDM_SUBJECTID
-    #"sex" : Constants.NIDM_GENDER,
-    #"age" : Constants.NIDM_AGE,
-    #"gender" : Constants.NIDM_GENDER,
-    #"diagnosis" : Constants.NIDM_DIAGNOSIS,
-    #"handedness" : Constants.NIDM_HANDEDNESS
+    "participant_id": Constants.NIDM_SUBJECTID
+    # "sex" : Constants.NIDM_GENDER,
+    # "age" : Constants.NIDM_AGE,
+    # "gender" : Constants.NIDM_GENDER,
+    # "diagnosis" : Constants.NIDM_DIAGNOSIS,
+    # "handedness" : Constants.NIDM_HANDEDNESS
 }
-#scan metadata -> NIDM constants mappings
+# scan metadata -> NIDM constants mappings
 scans = {
-    "anat" : Constants.NIDM_MRI_ANATOMIC_SCAN,
-    "func" : Constants.NIDM_MRI_FUNCTION_SCAN,
-    "dwi" : Constants.NIDM_MRI_DWI_SCAN,
-    "bval" : Constants.NIDM_MRI_DWI_BVAL,
-    "bvec" : Constants.NIDM_MRI_DWI_BVEC,
-    "T1w" : Constants.NIDM_MRI_T1,
-    "T2w" : Constants.NIDM_MRI_T2,
-    "inplaneT2" : Constants.NIDM_MRI_T2,
-    "bold" : Constants.NIDM_MRI_FLOW,
-    "dti" : Constants.NIDM_MRI_DIFFUSION_TENSOR,
-    "asl" : Constants.NIDM_MRI_ASL
+    "anat": Constants.NIDM_MRI_ANATOMIC_SCAN,
+    "func": Constants.NIDM_MRI_FUNCTION_SCAN,
+    "dwi": Constants.NIDM_MRI_DWI_SCAN,
+    "bval": Constants.NIDM_MRI_DWI_BVAL,
+    "bvec": Constants.NIDM_MRI_DWI_BVEC,
+    "T1w": Constants.NIDM_MRI_T1,
+    "T2w": Constants.NIDM_MRI_T2,
+    "inplaneT2": Constants.NIDM_MRI_T2,
+    "bold": Constants.NIDM_MRI_FLOW,
+    "dti": Constants.NIDM_MRI_DIFFUSION_TENSOR,
+    "asl": Constants.NIDM_MRI_ASL,
 }
-#JSON file keys
+# JSON file keys
 json_keys = {
-    ##Image terms
-    "run" : Constants.NIDM_ACQUISITION_ENTITY,
-    "ImageType" : Constants.DICOM["ImageType"],
-    "ManufacturerModelName" : Constants.DICOM["ManufacturerModelName"],
-    "Manufacturer" : Constants.DICOM["Manufacturer"],
-    "ScanningSequence" : Constants.DICOM["ScanningSequence"],
-    "SequenceVariant" : Constants.DICOM["SequenceVariant"],
-    "ScanOptions" : Constants.DICOM["ScanOptions"],
-    "MRAcquisitionType" : Constants.DICOM["MRAcquisitionType"],
-    "SequenceName" : Constants.DICOM["SequenceName"],
-    "RepetitionTime" : Constants.DICOM["RepetitionTime"],
-    "RepetitionTimePreparation" : Constants.BIDS["RepetitionTimePreparation"],
-    "ArterialSpinLabelingType" : Constants.BIDS["ArterialSpinLabelingType"],
-    "PostLabelingDelay" : Constants.BIDS["PostLabelingDelay"],
-    "BackgroundSuppression" : Constants.BIDS["BackgroundSuppression"],
-    "BackgroundSuppressionPulseTime" : Constants.BIDS["BackgroundSuppressionPulseTime"],
-    "BackgroundSuppressionNumberPulses" : Constants.BIDS["BackgroundSuppressionNumberPulses"],
-    "LabelingLocationDescription" : Constants.BIDS["LabelingLocationDescription"],
-    "LookLocker" : Constants.BIDS["LookLocker"],
-    "LabelingEfficiency" : Constants.BIDS["LabelingEfficiency"],
-    "LabelingDuration" : Constants.BIDS["LabelingDuration"],
-    "LabelingPulseAverageGradient" : Constants.BIDS["LabelingPulseAverageGradient"],
-    "LabelingPulseMaximumGradient" : Constants.BIDS["LabelingPulseMaximumGradient"],
-    "LabelingPulseDuration" : Constants.BIDS["LabelingPulseDuration"],
-    "LabelingPulseFlipAngle" : Constants.BIDS["LabelingPulseFlipAngle"],
-    "LabelingPulseInterval" : Constants.BIDS["LabelingPulseInterval"],
-    "PCASLType" : Constants.BIDS["PCASLType"],
-    "M0Type" : Constants.BIDS["M0Type"],
-    "TotalAcquiredPairs" : Constants.BIDS["TotalAcquiredPairs"],
-    "VascularCrushing" : Constants.BIDS["VascularCrushing"],
-    "EchoTime" : Constants.BIDS["EchoTime"],
-    "InversionTime" : Constants.DICOM["InversionTime"],
-    "NumberOfAverages" : Constants.DICOM["NumberOfAverages"],
-    "ImagingFrequency" : Constants.DICOM["ImagingFrequency"],
-    "MagneticFieldStrength" : Constants.DICOM["MagneticFieldStrength"],
-    "NumberOfPhaseEncodingSteps" : Constants.DICOM["NumberOfPhaseEncodingSteps"],
+    # Image terms
+    "run": Constants.NIDM_ACQUISITION_ENTITY,
+    "ImageType": Constants.DICOM["ImageType"],
+    "ManufacturerModelName": Constants.DICOM["ManufacturerModelName"],
+    "Manufacturer": Constants.DICOM["Manufacturer"],
+    "ScanningSequence": Constants.DICOM["ScanningSequence"],
+    "SequenceVariant": Constants.DICOM["SequenceVariant"],
+    "ScanOptions": Constants.DICOM["ScanOptions"],
+    "MRAcquisitionType": Constants.DICOM["MRAcquisitionType"],
+    "SequenceName": Constants.DICOM["SequenceName"],
+    "RepetitionTime": Constants.DICOM["RepetitionTime"],
+    "RepetitionTimePreparation": Constants.BIDS["RepetitionTimePreparation"],
+    "ArterialSpinLabelingType": Constants.BIDS["ArterialSpinLabelingType"],
+    "PostLabelingDelay": Constants.BIDS["PostLabelingDelay"],
+    "BackgroundSuppression": Constants.BIDS["BackgroundSuppression"],
+    "BackgroundSuppressionPulseTime": Constants.BIDS["BackgroundSuppressionPulseTime"],
+    "BackgroundSuppressionNumberPulses": Constants.BIDS[
+        "BackgroundSuppressionNumberPulses"
+    ],
+    "LabelingLocationDescription": Constants.BIDS["LabelingLocationDescription"],
+    "LookLocker": Constants.BIDS["LookLocker"],
+    "LabelingEfficiency": Constants.BIDS["LabelingEfficiency"],
+    "LabelingDuration": Constants.BIDS["LabelingDuration"],
+    "LabelingPulseAverageGradient": Constants.BIDS["LabelingPulseAverageGradient"],
+    "LabelingPulseMaximumGradient": Constants.BIDS["LabelingPulseMaximumGradient"],
+    "LabelingPulseDuration": Constants.BIDS["LabelingPulseDuration"],
+    "LabelingPulseFlipAngle": Constants.BIDS["LabelingPulseFlipAngle"],
+    "LabelingPulseInterval": Constants.BIDS["LabelingPulseInterval"],
+    "PCASLType": Constants.BIDS["PCASLType"],
+    "M0Type": Constants.BIDS["M0Type"],
+    "TotalAcquiredPairs": Constants.BIDS["TotalAcquiredPairs"],
+    "VascularCrushing": Constants.BIDS["VascularCrushing"],
+    "EchoTime": Constants.BIDS["EchoTime"],
+    "InversionTime": Constants.DICOM["InversionTime"],
+    "NumberOfAverages": Constants.DICOM["NumberOfAverages"],
+    "ImagingFrequency": Constants.DICOM["ImagingFrequency"],
+    "MagneticFieldStrength": Constants.DICOM["MagneticFieldStrength"],
+    "NumberOfPhaseEncodingSteps": Constants.DICOM["NumberOfPhaseEncodingSteps"],
     "EchoTrainLength": Constants.DICOM["EchoTrainLength"],
     "PercentSampling": Constants.DICOM["PercentSampling"],
     "PercentPhaseFieldOfView": Constants.DICOM["PercentPhaseFieldOfView"],
-    "PixelBandwidth":Constants.DICOM["PixelBandwidth"],
+    "PixelBandwidth": Constants.DICOM["PixelBandwidth"],
     "AccelerationFactorPE": Constants.DICOM["AccelerationFactorPE"],
     "AccelNumReferenceLines": Constants.DICOM["AccelNumReferenceLines"],
     "TotalScanTimeSec": Constants.DICOM["TotalScanTimeSec"],
     "ReceiveCoilName": Constants.DICOM["ReceiveCoilName"],
     "DeviceSerialNumber": Constants.DICOM["DeviceSerialNumber"],
     "SoftwareVersions": Constants.DICOM["SoftwareVersions"],
     "ProtocolName": Constants.DICOM["ProtocolName"],
     "TransmitCoilName": Constants.DICOM["TransmitCoilName"],
     "AcquisitionMatrix": Constants.DICOM["AcquisitionMatrix"],
-    "AcquisitionVoxelSize" : Constants.BIDS["AcquisitionVoxelSize"],
+    "AcquisitionVoxelSize": Constants.BIDS["AcquisitionVoxelSize"],
     "InPlanePhaseEncodingDirection": Constants.DICOM["InPlanePhaseEncodingDirection"],
     "FlipAngle": Constants.BIDS["FlipAngle"],
     "VariableFlipAngleFlag": Constants.DICOM["VariableFlipAngleFlag"],
     "PatientPosition": Constants.DICOM["PatientPosition"],
     "PhaseEncodingDirection": Constants.BIDS["PhaseEncodingDirection"],
     "SliceTiming": Constants.BIDS["SliceTiming"],
-    "TotalReadoutTime" : Constants.BIDS["TotalReadoutTime"],
-    "EffectiveEchoSpacing" : Constants.NIDM["EffectiveEchoSpacing"],
-    "NumberDiscardedVolumesByScanner" : Constants.NIDM["NumberDiscardedVolumesByScanner"],
-    "NumberDiscardedVolumesByUser" : Constants.NIDM["NumberDiscardedVolumesByUser"],
-    "DelayTime" : Constants.NIDM["DelayTime"],
-    "PulseSequenceType" : Constants.DICOM["PulseSequenceName"],
-    ###Task Stuff
-    "TaskName" : Constants.NIDM_MRI_FUNCTION_TASK
+    "TotalReadoutTime": Constants.BIDS["TotalReadoutTime"],
+    "EffectiveEchoSpacing": Constants.NIDM["EffectiveEchoSpacing"],
+    "NumberDiscardedVolumesByScanner": Constants.NIDM[
+        "NumberDiscardedVolumesByScanner"
+    ],
+    "NumberDiscardedVolumesByUser": Constants.NIDM["NumberDiscardedVolumesByUser"],
+    "DelayTime": Constants.NIDM["DelayTime"],
+    "PulseSequenceType": Constants.DICOM["PulseSequenceName"],
+    # Task Stuff
+    "TaskName": Constants.NIDM_MRI_FUNCTION_TASK
     # "CogAtlasID" :
     # "CogPOID" :
     # "TaskDescription" :
     # "Instructions" :
     # "TaskFullName" :
     # "TaskName" :
 }
```

### Comparing `pynidm-3.9.7/nidm/core/Constants.py` & `pynidm-4.0.0/src/nidm/core/Constants.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,52 +1,54 @@
 #!/usr/bin/env python
-''' Definition of constants
+""" Definition of constants
 
 @author: Camille Maumet <c.m.j.maumet@warwick.ac.uk>
 @copyright: University of Warwick 2014
 @author: David Keator <dbkeator@uci.edu>
     Added Python provtoolbox  support
     10/3/17 Modified Namespace to be QualifiedName for provtoolbox support...left most of the NIDM-Results Namespaces the same
 @author: Sanu Ann Abraham <sanuann@mit.edu>
-	05/04/2018 Added python ProvONE support
-'''
-import six
-from rdflib import Namespace, Graph
-from prov.model import ProvDocument, QualifiedName
+        05/04/2018 Added python ProvONE support
+"""
+from collections import namedtuple
+from prov.constants import PROV_ATTRIBUTE_LITERALS, PROV_ATTRIBUTE_QNAMES, PROV_N_MAP
 from prov.model import Namespace as provNamespace
-from prov.constants import PROV_ATTRIBUTE_QNAMES, PROV_ATTRIBUTE_LITERALS, \
-	PROV_N_MAP
+from prov.model import ProvDocument, QualifiedName
+from rdflib import Graph, Namespace
 
-from collections import namedtuple
 DD = namedtuple("DD", ["source", "variable"])
 
-PROV = Namespace('http://www.w3.org/ns/prov#')
-PROVONE = provNamespace('provone', 'http://purl.dataone.org/provone/2015/01/15/ontology#')
+PROV = Namespace("http://www.w3.org/ns/prov#")
+PROVONE = provNamespace(
+    "provone", "http://purl.dataone.org/provone/2015/01/15/ontology#"
+)
 
-NIDM_URL = 'http://purl.org/nidash/nidm#'
+NIDM_URL = "http://purl.org/nidash/nidm#"
 NIDM = Namespace(NIDM_URL)
 
-NIIRI = Namespace('http://iri.nidash.org/')
-AFNI = Namespace('http://purl.org/nidash/afni#')
-SPM = Namespace('http://purl.org/nidash/spm#')
-FSL = Namespace('http://purl.org/nidash/fsl#')
-FREESURFER = Namespace('https://surfer.nmr.mgh.harvard.edu/')
-ANTS = Namespace('http://stnava.github.io/ANTs/')
-RDFS = Namespace('http://www.w3.org/2000/01/rdf-schema#')
-CRYPTO = Namespace('http://id.loc.gov/vocabulary/preservation/\
-cryptographicHashFunctions#')
-DC = Namespace('http://purl.org/dc/elements/1.1/')
-DCT = Namespace('http://purl.org/dc/terms/')
-OWL = Namespace('http://www.w3.org/2002/07/owl#')
-XSD = Namespace('http://www.w3.org/2001/XMLSchema#')
+NIIRI = Namespace("http://iri.nidash.org/")
+AFNI = Namespace("http://purl.org/nidash/afni#")
+SPM = Namespace("http://purl.org/nidash/spm#")
+FSL = Namespace("http://purl.org/nidash/fsl#")
+FREESURFER = Namespace("https://surfer.nmr.mgh.harvard.edu/")
+ANTS = Namespace("http://stnava.github.io/ANTs/")
+RDFS = Namespace("http://www.w3.org/2000/01/rdf-schema#")
+CRYPTO = Namespace(
+    "http://id.loc.gov/vocabulary/preservation/\
+cryptographicHashFunctions#"
+)
+DC = Namespace("http://purl.org/dc/elements/1.1/")
+DCT = Namespace("http://purl.org/dc/terms/")
+OWL = Namespace("http://www.w3.org/2002/07/owl#")
+XSD = Namespace("http://www.w3.org/2001/XMLSchema#")
 
 OBO_URL = "http://purl.obolibrary.org/obo/"
 OBO = Namespace(OBO_URL)
-#Added by DBK for NIDM-Experiment 1/13/17
-NFO = Namespace('http://www.semanticdesktop.org/ontologies/2007/03/22/nfo#')
+# Added by DBK for NIDM-Experiment 1/13/17
+NFO = Namespace("http://www.semanticdesktop.org/ontologies/2007/03/22/nfo#")
 SCR = Namespace("http://scicrunch.org/resolver/")
 NLX = Namespace("http://uri.neuinfo.org/nif/nifstd/")
 SKOS = Namespace("http://www.w3.org/2004/02/skos/core#")
 FOAF = Namespace("http://xmlns.com/foaf/0.1/")
 VC = Namespace("http://www.w3.org/2006/vcard/ns#")
 DICOM = Namespace("http://neurolex.org/wiki/Category:DICOM_term/")
 DCTYPES = Namespace("http://purl.org/dc/dcmitype/")
@@ -61,578 +63,607 @@
 ONLI = Namespace("http://neurolog.unice.fr/ontoneurolog/v3.0/instrument.owl#")
 PATO = Namespace("http://purl.obolibrary.org/obo/pato#")
 DATALAD = Namespace("http://datasets.datalad.org/")
 INTERLEX = Namespace("http://uri.interlex.org/")
 EDAM = Namespace("https://bioportal.bioontology.org/ontologies/EDAM")
 
 namespaces = {
-   # "prov": PROV,
+    # "prov": PROV,
     "nidm": NIDM,
     "niiri": NIIRI,
     "afni": AFNI,
     "spm": SPM,
     "fsl": FSL,
-	"freesurfer": FREESURFER,
-	"ants": ANTS,
+    "freesurfer": FREESURFER,
+    "ants": ANTS,
     "rdfs": RDFS,
     "crypto": CRYPTO,
     "dct": DCT,
     "obo": OBO,
     "nfo": NFO,
     "dc": DC,
     "nlx": NLX,
     "scr": SCR,
     "foaf": FOAF,
     "vc": VC,
     "dicom": DICOM,
     "dctypes": DCTYPES,
     "ncit": NCIT,
     "dcat": DCAT,
-    "birnlex" : BIRNLEX,
-    "ndar" : NDAR,
-    "ncicb" : NCICB,
-    "sio" : SIO,
-    "bids" : BIDS,
-    "owl" : OWL,
-    "onli" : ONLI,
-    "pato" : PATO,
-	"datalad" : DATALAD,
-	"ilx" : INTERLEX,
-	"edam" : EDAM
-    }
+    "birnlex": BIRNLEX,
+    "ndar": NDAR,
+    "ncicb": NCICB,
+    "sio": SIO,
+    "bids": BIDS,
+    "owl": OWL,
+    "onli": ONLI,
+    "pato": PATO,
+    "datalad": DATALAD,
+    "ilx": INTERLEX,
+    "edam": EDAM,
+}
 
 # Empty graph used to compute qnames
 q_graph = Graph()
 for name, namespace in namespaces.items():
-	q_graph.bind(name, namespace)
+    q_graph.bind(name, namespace)
+
 
 # DBK Added - Empty graph using provtoolbox used to compute qnames
-# dj: chnaged to a new class
+# dj: changed to a new class
 class NIDMDocument(ProvDocument):
-	def __init__(self, namespaces=None):
-		if namespaces is not None:
-			super(NIDMDocument, self).__init__(namespaces=namespaces)
-		else:
-			super(NIDMDocument, self).__init__()
+    def __init__(self, namespaces=None):
+        if namespaces is not None:
+            super().__init__(namespaces=namespaces)
+        else:
+            super().__init__()
 
 
 # NIDM constants
-FSL_GAMMAHRF = FSL['FSL_0000007']
-FSL_FSLS_GAMMA_HRF = FSL['FSL_0000006']
-NIDM_HAS_MRI_PROTOCOL = NIDM['NIDM_0000172']
-NIDM_NUMBER_OF_SUBJECTS = NIDM['NIDM_0000171']
-NIDM_GROUP_NAME = NIDM['NIDM_0000170']
-NIDM_DATA = NIDM['NIDM_0000169']
-NIDM_SPM_RESULTS_NIDM = NIDM['NIDM_0000168']
-NIDM_NIDMFSL = NIDM['NIDM_0000167']
-NIDM_NIDM_RESULTS_EXPORT = NIDM['NIDM_0000166']
-NIDM_NIDM_RESULTS_EXPORTER = NIDM['NIDM_0000165']
-NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE = NIDM['NIDM_0000164']
-NIDM_CONTRAST_EXPLAINED_MEAN_SQUARE_MAP = NIDM['NIDM_0000163']
-NIDM_THRESHOLD = NIDM['NIDM_0000162']
-NIDM_EQUIVALENT_THRESHOLD = NIDM['NIDM_0000161']
-NIDM_P_VALUE_UNCORRECTED = NIDM['NIDM_0000160']
+FSL_GAMMAHRF = FSL["FSL_0000007"]
+FSL_FSLS_GAMMA_HRF = FSL["FSL_0000006"]
+NIDM_HAS_MRI_PROTOCOL = NIDM["NIDM_0000172"]
+NIDM_NUMBER_OF_SUBJECTS = NIDM["NIDM_0000171"]
+NIDM_GROUP_NAME = NIDM["NIDM_0000170"]
+NIDM_DATA = NIDM["NIDM_0000169"]
+NIDM_SPM_RESULTS_NIDM = NIDM["NIDM_0000168"]
+NIDM_NIDMFSL = NIDM["NIDM_0000167"]
+NIDM_NIDM_RESULTS_EXPORT = NIDM["NIDM_0000166"]
+NIDM_NIDM_RESULTS_EXPORTER = NIDM["NIDM_0000165"]
+NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE = NIDM["NIDM_0000164"]
+NIDM_CONTRAST_EXPLAINED_MEAN_SQUARE_MAP = NIDM["NIDM_0000163"]
+NIDM_THRESHOLD = NIDM["NIDM_0000162"]
+NIDM_EQUIVALENT_THRESHOLD = NIDM["NIDM_0000161"]
+NIDM_P_VALUE_UNCORRECTED = NIDM["NIDM_0000160"]
 NIDM_P_VALUE_UNCORRECTED_QNAME = q_graph.qname(NIDM_P_VALUE_UNCORRECTED)
-NIDM_NOISE_FWHM_IN_VOXELS = NIDM['NIDM_0000159']
-NIDM_NOISE_FWHM_IN_VERTICES = NIDM['NIDM_0000158']
-NIDM_NOISE_FWHM_IN_UNITS = NIDM['NIDM_0000157']
-FSL_FEAT_VERSION = FSL['FSL_0000005']
-FSL_DRIFT_CUTOFF_PERIOD = FSL['FSL_0000004']
-FSL_TEMPORAL_DERIVATIVE = FSL['FSL_0000003']
-FSL_GAUSSIAN_RUNNING_LINE_DRIFT_MODEL = FSL['FSL_0000002']
-FSL_FSLS_GAMMA_DIFFERENCE_HRF = FSL['FSL_0000001']
-SPM_PARTIAL_CONJUNCTION_DEGREE = SPM['SPM_0000015']
-SPM_SMALLEST_SUPRA_THRESHOLD_CLUSTER_SIZE_IN_VOXELS_FWE05 = SPM['SPM_0000014']
-SPM_SMALLEST_SUPRA_THRESHOLD_CLUSTER_SIZE_IN_VOXELS_FDR05 = SPM['SPM_0000013']
-SPM_SMALLEST_SUPRA_THRESHOLD_CLUSTER_SIZE_IN_VERTICES_FWE05 = SPM['SPM_0000012']
-SPM_SMALLEST_SUPRA_THRESHOLD_CLUSTER_SIZE_IN_VERTICES_FDR05 = SPM['SPM_0000011']
-SPM_SEARCH_VOLUME_RESELS_GEOMETRY = SPM['SPM_0000010']
-SPM_TEMPORAL_DERIVATIVE = SPM['SPM_0000006']
-SPM_KCONJUNCTION_INFERENCE = SPM['SPM_0000005']
-SPM_CANONICAL_HRF = SPM['SPM_0000004']
-SPM_DISPERSION_DERIVATIVE = SPM['SPM_0000003']
-SPM_DCT_DRIFT_MODEL = SPM['SPM_0000002']
-SPM_SPMS_DRIFT_CUT_OFF_PERIOD = SPM['SPM_0000001']
-NIDM_CLUSTERSIZEINRESELS = NIDM['NIDM_0000156']
-NIDM_F_MRI_DESIGN = NIDM['NIDM_0000155']
-NIDM_MIXED_DESIGN = NIDM['NIDM_0000154']
-NIDM_EVENT_RELATED_DESIGN = NIDM['NIDM_0000153']
-NIDM_BLOCK_BASED_DESIGN = NIDM['NIDM_0000152']
-NIDM_SINE_BASIS_SET = NIDM['NIDM_0000151']
-NIDM_LINEAR_SPLINE_BASIS_SET = NIDM['NIDM_0000150']
-NIDM_SEARCH_VOLUME_IN_RESELS = NIDM['NIDM_0000149']
-NIDM_RESEL_SIZE_IN_VOXELS = NIDM['NIDM_0000148']
-NIDM_HEIGHT_CRITICAL_THRESHOLD_FWE_05 = NIDM['NIDM_0000147']
-NIDM_HEIGHT_CRITICAL_THRESHOLD_FDR_05 = NIDM['NIDM_0000146']
-NIDM_NOISE_ROUGHNESS_IN_VOXELS = NIDM['NIDM_0000145']
-NIDM_RESELS_PER_VOXEL_MAP = NIDM['NIDM_0000144']
-NIDM_EXPECTED_NUMBER_OF_VOXELS_PER_CLUSTER = NIDM['NIDM_0000143']
-NIDM_EXPECTED_NUMBER_OF_VERTICES_PER_CLUSTER = NIDM['NIDM_0000142']
-NIDM_EXPECTED_NUMBER_OF_CLUSTERS = NIDM['NIDM_0000141']
-NIDM_CLUSTER_CENTER_OF_GRAVITY = NIDM['NIDM_0000140']
-NIDM_COORDINATE_VECTOR_IN_VOXELS = NIDM['NIDM_0000139']
-NIDM_HAS_MAXIMUM_INTENSITY_PROJECTION = NIDM['NIDM_0000138']
-NIDM_SEARCH_VOLUME_IN_VERTICES = NIDM['NIDM_0000137']
-NIDM_SEARCH_VOLUME_IN_UNITS = NIDM['NIDM_0000136']
-NIDM_CONTRAST_VARIANCE_MAP = NIDM['NIDM_0000135']
-NIDM_WITH_ESTIMATION_METHOD = NIDM['NIDM_0000134']
-NIDM_VOXEL_UNITS = NIDM['NIDM_0000133']
-NIDM_VOXEL_TO_WORLD_MAPPING = NIDM['NIDM_0000132']
-NIDM_VOXEL_SIZE = NIDM['NIDM_0000131']
-NIDM_VOXEL6CONNECTED = NIDM['NIDM_0000130']
-NIDM_VOXEL26CONNECTED = NIDM['NIDM_0000129']
-NIDM_VOXEL18CONNECTED = NIDM['NIDM_0000128']
-NIDM_VERSION = NIDM['NIDM_0000127']
-NIDM_VARIANCE_SPATIAL_MODEL = NIDM['NIDM_0000126']
-NIDM_USER_SPECIFIED_THRESHOLD_TYPE = NIDM['NIDM_0000125']
-NIDM_TARGET_INTENSITY = NIDM['NIDM_0000124']
-NIDM_STATISTIC_TYPE = NIDM['NIDM_0000123']
-NIDM_SOFTWARE_VERSION = NIDM['NIDM_0000122']
-NIDM_SEARCH_VOLUME_IN_VOXELS = NIDM['NIDM_0000121']
-NIDM_RANDOM_FIELD_STATIONARITY = NIDM['NIDM_0000120']
-NIDM_Q_VALUE_FDR = NIDM['NIDM_0000119']
-NIDM_PIXEL8CONNECTED = NIDM['NIDM_0000118']
-NIDM_PIXEL4CONNECTED = NIDM['NIDM_0000117']
-NIDM_P_VALUE_UNCORRECTED = NIDM['NIDM_0000116']
-NIDM_P_VALUE_FWER = NIDM['NIDM_0000115']
-NIDM_P_VALUE = NIDM['NIDM_0000114']
-NIDM_OBJECT_MODEL = NIDM['NIDM_0000113']
-NIDM_NUMBER_OF_DIMENSIONS = NIDM['NIDM_0000112']
-NIDM_NUMBER_OF_CLUSTERS = NIDM['NIDM_0000111']
-NIDM_GAUSSIAN_HRF = NIDM['NIDM_0000110']
-NIDM_MIN_DISTANCE_BETWEEN_PEAKS = NIDM['NIDM_0000109']
-NIDM_MAX_NUMBER_OF_PEAKS_PER_CLUSTER = NIDM['NIDM_0000108']
-NIDM_MASKED_MEDIAN = NIDM['NIDM_0000107']
-NIDM_IS_USER_DEFINED = NIDM['NIDM_0000106']
-NIDM_IN_WORLD_COORDINATE_SYSTEM = NIDM['NIDM_0000105']
-NIDM_IN_COORDINATE_SPACE = NIDM['NIDM_0000104']
-NIDM_HAS_MAP_HEADER = NIDM['NIDM_0000103']
-NIDM_HAS_HRF_BASIS = NIDM['NIDM_0000102']
-NIDM_HAS_ERROR_DISTRIBUTION = NIDM['NIDM_0000101']
-NIDM_HAS_ERROR_DEPENDENCE = NIDM['NIDM_0000100']
-NIDM_HAS_CONNECTIVITY_CRITERION = NIDM['NIDM_0000099']
-NIDM_HAS_CLUSTER_LABELS_MAP = NIDM['NIDM_0000098']
-NIDM_HAS_ALTERNATIVE_HYPOTHESIS = NIDM['NIDM_0000097']
-NIDM_GRAND_MEAN_SCALING = NIDM['NIDM_0000096']
-NIDM_ERROR_VARIANCE_HOMOGENEOUS = NIDM['NIDM_0000094']
-NIDM_ERROR_DEGREES_OF_FREEDOM = NIDM['NIDM_0000093']
-NIDM_EQUIVALENT_ZSTATISTIC = NIDM['NIDM_0000092']
-NIDM_EFFECT_DEGREES_OF_FREEDOM = NIDM['NIDM_0000091']
-NIDM_DIMENSIONS_IN_VOXELS = NIDM['NIDM_0000090']
-NIDM_DEPENDENCE_SPATIAL_MODEL = NIDM['NIDM_0000089']
-NIDM_HAS_DRIFT_MODEL = NIDM['NIDM_0000088']
-NIDM_DRIFT_MODEL = NIDM['NIDM_0000087']
-NIDM_COORDINATE_VECTOR = NIDM['NIDM_0000086']
-NIDM_CONTRAST_NAME = NIDM['NIDM_0000085']
-NIDM_CLUSTER_SIZE_IN_VOXELS = NIDM['NIDM_0000084']
-NIDM_CLUSTER_SIZE_IN_VERTICES = NIDM['NIDM_0000083']
-NIDM_CLUSTER_LABEL_ID = NIDM['NIDM_0000082']
-NIDM_WORLD_COORDINATE_SYSTEM = NIDM['NIDM_0000081']
-NIDM_VOXEL_CONNECTIVITY_CRITERION = NIDM['NIDM_0000080']
-NIDM_TWO_TAILED_TEST = NIDM['NIDM_0000079']
-NIDM_TALAIRACH_COORDINATE_SYSTEM = NIDM['NIDM_0000078']
-NIDM_SUBJECT_COORDINATE_SYSTEM = NIDM['NIDM_0000077']
-NIDM_STATISTIC_MAP = NIDM['NIDM_0000076']
-NIDM_STANDARDIZED_COORDINATE_SYSTEM = NIDM['NIDM_0000075']
-NIDM_SPATIALLY_REGULARIZED_MODEL = NIDM['NIDM_0000074']
-NIDM_SPATIALLY_LOCAL_MODEL = NIDM['NIDM_0000073']
-NIDM_SPATIALLY_GLOBAL_MODEL = NIDM['NIDM_0000072']
-NIDM_SPATIAL_MODEL = NIDM['NIDM_0000071']
-NIDM_SUPRA_THRESHOLD_CLUSTER = NIDM['NIDM_0000070']
-NIDM_FOURIER_BASIS_SET = NIDM['NIDM_0000069']
-NIDM_SEARCH_SPACE_MASK_MAP = NIDM['NIDM_0000068']
-NIDM_CUSTOM_BASIS_SET = NIDM['NIDM_0000067']
-NIDM_RESIDUAL_MEAN_SQUARES_MAP = NIDM['NIDM_0000066']
-NIDM_POISSON_DISTRIBUTION = NIDM['NIDM_0000065']
-NIDM_PIXEL_CONNECTIVITY_CRITERION = NIDM['NIDM_0000064']
-NIDM_PEAK_DEFINITION_CRITERIA = NIDM['NIDM_0000063']
-NIDM_PEAK = NIDM['NIDM_0000062']
-NIDM_PARAMETER_ESTIMATE_MAP = NIDM['NIDM_0000061']
-NIDM_ONE_TAILED_TEST = NIDM['NIDM_0000060']
-NIDM_NON_PARAMETRIC_SYMMETRIC_DISTRIBUTION = NIDM['NIDM_0000059']
-NIDM_NON_PARAMETRIC_DISTRIBUTION = NIDM['NIDM_0000058']
-NIDM_NIDM_OBJECT_MODEL = NIDM['NIDM_0000057']
-NIDM_MODEL_PARAMETERS_ESTIMATION = NIDM['NIDM_0000056']
-NIDM_MNI305_COORDINATE_SYSTEM = NIDM['NIDM_0000055']
-NIDM_MASK_MAP = NIDM['NIDM_0000054']
-NIDM_MAP_HEADER = NIDM['NIDM_0000053']
-NIDM_MAP = NIDM['NIDM_0000052']
-NIDM_MNI_COORDINATE_SYSTEM = NIDM['NIDM_0000051']
-NIDM_IXI549_COORDINATE_SYSTEM = NIDM['NIDM_0000050']
-NIDM_INFERENCE = NIDM['NIDM_0000049']
-NIDM_INDEPENDENT_ERROR = NIDM['NIDM_0000048']
-NIDM_ICBM_MNI152_NON_LINEAR6TH_GENERATION_COORDINATE_SYSTEM = NIDM['NIDM_0000047']
-NIDM_ICBM_MNI152_NON_LINEAR2009C_SYMMETRIC_COORDINATE_SYSTEM = NIDM['NIDM_0000046']
-NIDM_ICBM_MNI152_NON_LINEAR2009C_ASYMMETRIC_COORDINATE_SYSTEM = NIDM['NIDM_0000045']
-NIDM_ICBM_MNI152_NON_LINEAR2009B_SYMMETRIC_COORDINATE_SYSTEM = NIDM['NIDM_0000044']
-NIDM_ICBM_MNI152_NON_LINEAR2009B_ASYMMETRIC_COORDINATE_SYSTEM = NIDM['NIDM_0000043']
-NIDM_ICBM_MNI152_NON_LINEAR2009A_SYMMETRIC_COORDINATE_SYSTEM = NIDM['NIDM_0000042']
-NIDM_ICBM_MNI152_NON_LINEAR2009A_ASYMMETRIC_COORDINATE_SYSTEM = NIDM['NIDM_0000041']
-NIDM_ICBM_MNI152_LINEAR_COORDINATE_SYSTEM = NIDM['NIDM_0000040']
-NIDM_ICBM452_WARP5_COORDINATE_SYSTEM = NIDM['NIDM_0000039']
-NIDM_ICBM452_AIR_COORDINATE_SYSTEM = NIDM['NIDM_0000038']
-NIDM_HEMODYNAMIC_RESPONSE_FUNCTION_DERIVATIVE = NIDM['NIDM_0000037']
-NIDM_HEMODYNAMIC_RESPONSE_FUNCTION_BASIS = NIDM['NIDM_0000036']
-NIDM_HEMODYNAMIC_RESPONSE_FUNCTION = NIDM['NIDM_0000035']
-NIDM_HEIGHT_THRESHOLD = NIDM['NIDM_0000034']
-NIDM_GRAND_MEAN_MAP = NIDM['NIDM_0000033']
-NIDM_GAMMA_HRF = NIDM['NIDM_0000031']
-NIDM_GAMMA_HRB = NIDM['NIDM_0000030']
-NIDM_GAMMA_DIFFERENCE_HRF = NIDM['NIDM_0000029']
-NIDM_FINITE_IMPULSE_RESPONSE_HRB = NIDM['NIDM_0000028']
-NIDM_RESULTS = NIDM['NIDM_0000027']
-NIDM_EXTENT_THRESHOLD = NIDM['NIDM_0000026']
-NIDM_EXCURSION_SET_MAP = NIDM['NIDM_0000025']
-NIDM_EXCHANGEABLE_ERROR = NIDM['NIDM_0000024']
-NIDM_ERROR_MODEL = NIDM['NIDM_0000023']
-NIDM_ERROR_DISTRIBUTION = NIDM['NIDM_0000022']
-NIDM_REGRESSOR_NAMES = NIDM['NIDM_0000021']
-NIDM_DISPLAY_MASK_MAP = NIDM['NIDM_0000020']
-NIDM_DESIGN_MATRIX = NIDM['NIDM_0000019']
-NIDM_CUSTOM_COORDINATE_SYSTEM = NIDM['NIDM_0000017']
-NIDM_COORDINATE_SPACE = NIDM['NIDM_0000016']
-NIDM_COORDINATE = NIDM['NIDM_0000015']
-NIDM_LEGENDRE_POLYNOMIAL_ORDER = NIDM['NIDM_0000014']
-NIDM_CONTRAST_STANDARD_ERROR_MAP = NIDM['NIDM_0000013']
-NIDM_CONNECTIVITY_CRITERION = NIDM['NIDM_0000012']
-NIDM_CONJUNCTION_INFERENCE = NIDM['NIDM_0000011']
-NIDM_HAS_FMRI_DESIGN = NIDM['NIDM_0000010']
-NIDM_COLIN27_COORDINATE_SYSTEM = NIDM['NIDM_0000009']
-NIDM_CLUSTER_LABELS_MAP = NIDM['NIDM_0000008']
-NIDM_CLUSTER_DEFINITION_CRITERIA = NIDM['NIDM_0000007']
-NIDM_CLUSTER = NIDM['NIDM_0000006']
-NIDM_BINOMIAL_DISTRIBUTION = NIDM['NIDM_0000005']
-NIDM_BINARY_MAP = NIDM['NIDM_0000004']
-NIDM_CONTRAST_ESTIMATION = NIDM['NIDM_0000001']
-NIDM_CONTRAST_MAP = NIDM['NIDM_0000002']
+NIDM_NOISE_FWHM_IN_VOXELS = NIDM["NIDM_0000159"]
+NIDM_NOISE_FWHM_IN_VERTICES = NIDM["NIDM_0000158"]
+NIDM_NOISE_FWHM_IN_UNITS = NIDM["NIDM_0000157"]
+FSL_FEAT_VERSION = FSL["FSL_0000005"]
+FSL_DRIFT_CUTOFF_PERIOD = FSL["FSL_0000004"]
+FSL_TEMPORAL_DERIVATIVE = FSL["FSL_0000003"]
+FSL_GAUSSIAN_RUNNING_LINE_DRIFT_MODEL = FSL["FSL_0000002"]
+FSL_FSLS_GAMMA_DIFFERENCE_HRF = FSL["FSL_0000001"]
+SPM_PARTIAL_CONJUNCTION_DEGREE = SPM["SPM_0000015"]
+SPM_SMALLEST_SUPRA_THRESHOLD_CLUSTER_SIZE_IN_VOXELS_FWE05 = SPM["SPM_0000014"]
+SPM_SMALLEST_SUPRA_THRESHOLD_CLUSTER_SIZE_IN_VOXELS_FDR05 = SPM["SPM_0000013"]
+SPM_SMALLEST_SUPRA_THRESHOLD_CLUSTER_SIZE_IN_VERTICES_FWE05 = SPM["SPM_0000012"]
+SPM_SMALLEST_SUPRA_THRESHOLD_CLUSTER_SIZE_IN_VERTICES_FDR05 = SPM["SPM_0000011"]
+SPM_SEARCH_VOLUME_RESELS_GEOMETRY = SPM["SPM_0000010"]
+SPM_TEMPORAL_DERIVATIVE = SPM["SPM_0000006"]
+SPM_KCONJUNCTION_INFERENCE = SPM["SPM_0000005"]
+SPM_CANONICAL_HRF = SPM["SPM_0000004"]
+SPM_DISPERSION_DERIVATIVE = SPM["SPM_0000003"]
+SPM_DCT_DRIFT_MODEL = SPM["SPM_0000002"]
+SPM_SPMS_DRIFT_CUT_OFF_PERIOD = SPM["SPM_0000001"]
+NIDM_CLUSTERSIZEINRESELS = NIDM["NIDM_0000156"]
+NIDM_F_MRI_DESIGN = NIDM["NIDM_0000155"]
+NIDM_MIXED_DESIGN = NIDM["NIDM_0000154"]
+NIDM_EVENT_RELATED_DESIGN = NIDM["NIDM_0000153"]
+NIDM_BLOCK_BASED_DESIGN = NIDM["NIDM_0000152"]
+NIDM_SINE_BASIS_SET = NIDM["NIDM_0000151"]
+NIDM_LINEAR_SPLINE_BASIS_SET = NIDM["NIDM_0000150"]
+NIDM_SEARCH_VOLUME_IN_RESELS = NIDM["NIDM_0000149"]
+NIDM_RESEL_SIZE_IN_VOXELS = NIDM["NIDM_0000148"]
+NIDM_HEIGHT_CRITICAL_THRESHOLD_FWE_05 = NIDM["NIDM_0000147"]
+NIDM_HEIGHT_CRITICAL_THRESHOLD_FDR_05 = NIDM["NIDM_0000146"]
+NIDM_NOISE_ROUGHNESS_IN_VOXELS = NIDM["NIDM_0000145"]
+NIDM_RESELS_PER_VOXEL_MAP = NIDM["NIDM_0000144"]
+NIDM_EXPECTED_NUMBER_OF_VOXELS_PER_CLUSTER = NIDM["NIDM_0000143"]
+NIDM_EXPECTED_NUMBER_OF_VERTICES_PER_CLUSTER = NIDM["NIDM_0000142"]
+NIDM_EXPECTED_NUMBER_OF_CLUSTERS = NIDM["NIDM_0000141"]
+NIDM_CLUSTER_CENTER_OF_GRAVITY = NIDM["NIDM_0000140"]
+NIDM_COORDINATE_VECTOR_IN_VOXELS = NIDM["NIDM_0000139"]
+NIDM_HAS_MAXIMUM_INTENSITY_PROJECTION = NIDM["NIDM_0000138"]
+NIDM_SEARCH_VOLUME_IN_VERTICES = NIDM["NIDM_0000137"]
+NIDM_SEARCH_VOLUME_IN_UNITS = NIDM["NIDM_0000136"]
+NIDM_CONTRAST_VARIANCE_MAP = NIDM["NIDM_0000135"]
+NIDM_WITH_ESTIMATION_METHOD = NIDM["NIDM_0000134"]
+NIDM_VOXEL_UNITS = NIDM["NIDM_0000133"]
+NIDM_VOXEL_TO_WORLD_MAPPING = NIDM["NIDM_0000132"]
+NIDM_VOXEL_SIZE = NIDM["NIDM_0000131"]
+NIDM_VOXEL6CONNECTED = NIDM["NIDM_0000130"]
+NIDM_VOXEL26CONNECTED = NIDM["NIDM_0000129"]
+NIDM_VOXEL18CONNECTED = NIDM["NIDM_0000128"]
+NIDM_VERSION = NIDM["NIDM_0000127"]
+NIDM_VARIANCE_SPATIAL_MODEL = NIDM["NIDM_0000126"]
+NIDM_USER_SPECIFIED_THRESHOLD_TYPE = NIDM["NIDM_0000125"]
+NIDM_TARGET_INTENSITY = NIDM["NIDM_0000124"]
+NIDM_STATISTIC_TYPE = NIDM["NIDM_0000123"]
+NIDM_SOFTWARE_VERSION = NIDM["NIDM_0000122"]
+NIDM_SEARCH_VOLUME_IN_VOXELS = NIDM["NIDM_0000121"]
+NIDM_RANDOM_FIELD_STATIONARITY = NIDM["NIDM_0000120"]
+NIDM_Q_VALUE_FDR = NIDM["NIDM_0000119"]
+NIDM_PIXEL8CONNECTED = NIDM["NIDM_0000118"]
+NIDM_PIXEL4CONNECTED = NIDM["NIDM_0000117"]
+NIDM_P_VALUE_UNCORRECTED = NIDM["NIDM_0000116"]
+NIDM_P_VALUE_FWER = NIDM["NIDM_0000115"]
+NIDM_P_VALUE = NIDM["NIDM_0000114"]
+NIDM_OBJECT_MODEL = NIDM["NIDM_0000113"]
+NIDM_NUMBER_OF_DIMENSIONS = NIDM["NIDM_0000112"]
+NIDM_NUMBER_OF_CLUSTERS = NIDM["NIDM_0000111"]
+NIDM_GAUSSIAN_HRF = NIDM["NIDM_0000110"]
+NIDM_MIN_DISTANCE_BETWEEN_PEAKS = NIDM["NIDM_0000109"]
+NIDM_MAX_NUMBER_OF_PEAKS_PER_CLUSTER = NIDM["NIDM_0000108"]
+NIDM_MASKED_MEDIAN = NIDM["NIDM_0000107"]
+NIDM_IS_USER_DEFINED = NIDM["NIDM_0000106"]
+NIDM_IN_WORLD_COORDINATE_SYSTEM = NIDM["NIDM_0000105"]
+NIDM_IN_COORDINATE_SPACE = NIDM["NIDM_0000104"]
+NIDM_HAS_MAP_HEADER = NIDM["NIDM_0000103"]
+NIDM_HAS_HRF_BASIS = NIDM["NIDM_0000102"]
+NIDM_HAS_ERROR_DISTRIBUTION = NIDM["NIDM_0000101"]
+NIDM_HAS_ERROR_DEPENDENCE = NIDM["NIDM_0000100"]
+NIDM_HAS_CONNECTIVITY_CRITERION = NIDM["NIDM_0000099"]
+NIDM_HAS_CLUSTER_LABELS_MAP = NIDM["NIDM_0000098"]
+NIDM_HAS_ALTERNATIVE_HYPOTHESIS = NIDM["NIDM_0000097"]
+NIDM_GRAND_MEAN_SCALING = NIDM["NIDM_0000096"]
+NIDM_ERROR_VARIANCE_HOMOGENEOUS = NIDM["NIDM_0000094"]
+NIDM_ERROR_DEGREES_OF_FREEDOM = NIDM["NIDM_0000093"]
+NIDM_EQUIVALENT_ZSTATISTIC = NIDM["NIDM_0000092"]
+NIDM_EFFECT_DEGREES_OF_FREEDOM = NIDM["NIDM_0000091"]
+NIDM_DIMENSIONS_IN_VOXELS = NIDM["NIDM_0000090"]
+NIDM_DEPENDENCE_SPATIAL_MODEL = NIDM["NIDM_0000089"]
+NIDM_HAS_DRIFT_MODEL = NIDM["NIDM_0000088"]
+NIDM_DRIFT_MODEL = NIDM["NIDM_0000087"]
+NIDM_COORDINATE_VECTOR = NIDM["NIDM_0000086"]
+NIDM_CONTRAST_NAME = NIDM["NIDM_0000085"]
+NIDM_CLUSTER_SIZE_IN_VOXELS = NIDM["NIDM_0000084"]
+NIDM_CLUSTER_SIZE_IN_VERTICES = NIDM["NIDM_0000083"]
+NIDM_CLUSTER_LABEL_ID = NIDM["NIDM_0000082"]
+NIDM_WORLD_COORDINATE_SYSTEM = NIDM["NIDM_0000081"]
+NIDM_VOXEL_CONNECTIVITY_CRITERION = NIDM["NIDM_0000080"]
+NIDM_TWO_TAILED_TEST = NIDM["NIDM_0000079"]
+NIDM_TALAIRACH_COORDINATE_SYSTEM = NIDM["NIDM_0000078"]
+NIDM_SUBJECT_COORDINATE_SYSTEM = NIDM["NIDM_0000077"]
+NIDM_STATISTIC_MAP = NIDM["NIDM_0000076"]
+NIDM_STANDARDIZED_COORDINATE_SYSTEM = NIDM["NIDM_0000075"]
+NIDM_SPATIALLY_REGULARIZED_MODEL = NIDM["NIDM_0000074"]
+NIDM_SPATIALLY_LOCAL_MODEL = NIDM["NIDM_0000073"]
+NIDM_SPATIALLY_GLOBAL_MODEL = NIDM["NIDM_0000072"]
+NIDM_SPATIAL_MODEL = NIDM["NIDM_0000071"]
+NIDM_SUPRA_THRESHOLD_CLUSTER = NIDM["NIDM_0000070"]
+NIDM_FOURIER_BASIS_SET = NIDM["NIDM_0000069"]
+NIDM_SEARCH_SPACE_MASK_MAP = NIDM["NIDM_0000068"]
+NIDM_CUSTOM_BASIS_SET = NIDM["NIDM_0000067"]
+NIDM_RESIDUAL_MEAN_SQUARES_MAP = NIDM["NIDM_0000066"]
+NIDM_POISSON_DISTRIBUTION = NIDM["NIDM_0000065"]
+NIDM_PIXEL_CONNECTIVITY_CRITERION = NIDM["NIDM_0000064"]
+NIDM_PEAK_DEFINITION_CRITERIA = NIDM["NIDM_0000063"]
+NIDM_PEAK = NIDM["NIDM_0000062"]
+NIDM_PARAMETER_ESTIMATE_MAP = NIDM["NIDM_0000061"]
+NIDM_ONE_TAILED_TEST = NIDM["NIDM_0000060"]
+NIDM_NON_PARAMETRIC_SYMMETRIC_DISTRIBUTION = NIDM["NIDM_0000059"]
+NIDM_NON_PARAMETRIC_DISTRIBUTION = NIDM["NIDM_0000058"]
+NIDM_NIDM_OBJECT_MODEL = NIDM["NIDM_0000057"]
+NIDM_MODEL_PARAMETERS_ESTIMATION = NIDM["NIDM_0000056"]
+NIDM_MNI305_COORDINATE_SYSTEM = NIDM["NIDM_0000055"]
+NIDM_MASK_MAP = NIDM["NIDM_0000054"]
+NIDM_MAP_HEADER = NIDM["NIDM_0000053"]
+NIDM_MAP = NIDM["NIDM_0000052"]
+NIDM_MNI_COORDINATE_SYSTEM = NIDM["NIDM_0000051"]
+NIDM_IXI549_COORDINATE_SYSTEM = NIDM["NIDM_0000050"]
+NIDM_INFERENCE = NIDM["NIDM_0000049"]
+NIDM_INDEPENDENT_ERROR = NIDM["NIDM_0000048"]
+NIDM_ICBM_MNI152_NON_LINEAR6TH_GENERATION_COORDINATE_SYSTEM = NIDM["NIDM_0000047"]
+NIDM_ICBM_MNI152_NON_LINEAR2009C_SYMMETRIC_COORDINATE_SYSTEM = NIDM["NIDM_0000046"]
+NIDM_ICBM_MNI152_NON_LINEAR2009C_ASYMMETRIC_COORDINATE_SYSTEM = NIDM["NIDM_0000045"]
+NIDM_ICBM_MNI152_NON_LINEAR2009B_SYMMETRIC_COORDINATE_SYSTEM = NIDM["NIDM_0000044"]
+NIDM_ICBM_MNI152_NON_LINEAR2009B_ASYMMETRIC_COORDINATE_SYSTEM = NIDM["NIDM_0000043"]
+NIDM_ICBM_MNI152_NON_LINEAR2009A_SYMMETRIC_COORDINATE_SYSTEM = NIDM["NIDM_0000042"]
+NIDM_ICBM_MNI152_NON_LINEAR2009A_ASYMMETRIC_COORDINATE_SYSTEM = NIDM["NIDM_0000041"]
+NIDM_ICBM_MNI152_LINEAR_COORDINATE_SYSTEM = NIDM["NIDM_0000040"]
+NIDM_ICBM452_WARP5_COORDINATE_SYSTEM = NIDM["NIDM_0000039"]
+NIDM_ICBM452_AIR_COORDINATE_SYSTEM = NIDM["NIDM_0000038"]
+NIDM_HEMODYNAMIC_RESPONSE_FUNCTION_DERIVATIVE = NIDM["NIDM_0000037"]
+NIDM_HEMODYNAMIC_RESPONSE_FUNCTION_BASIS = NIDM["NIDM_0000036"]
+NIDM_HEMODYNAMIC_RESPONSE_FUNCTION = NIDM["NIDM_0000035"]
+NIDM_HEIGHT_THRESHOLD = NIDM["NIDM_0000034"]
+NIDM_GRAND_MEAN_MAP = NIDM["NIDM_0000033"]
+NIDM_GAMMA_HRF = NIDM["NIDM_0000031"]
+NIDM_GAMMA_HRB = NIDM["NIDM_0000030"]
+NIDM_GAMMA_DIFFERENCE_HRF = NIDM["NIDM_0000029"]
+NIDM_FINITE_IMPULSE_RESPONSE_HRB = NIDM["NIDM_0000028"]
+NIDM_RESULTS = NIDM["NIDM_0000027"]
+NIDM_EXTENT_THRESHOLD = NIDM["NIDM_0000026"]
+NIDM_EXCURSION_SET_MAP = NIDM["NIDM_0000025"]
+NIDM_EXCHANGEABLE_ERROR = NIDM["NIDM_0000024"]
+NIDM_ERROR_MODEL = NIDM["NIDM_0000023"]
+NIDM_ERROR_DISTRIBUTION = NIDM["NIDM_0000022"]
+NIDM_REGRESSOR_NAMES = NIDM["NIDM_0000021"]
+NIDM_DISPLAY_MASK_MAP = NIDM["NIDM_0000020"]
+NIDM_DESIGN_MATRIX = NIDM["NIDM_0000019"]
+NIDM_CUSTOM_COORDINATE_SYSTEM = NIDM["NIDM_0000017"]
+NIDM_COORDINATE_SPACE = NIDM["NIDM_0000016"]
+NIDM_COORDINATE = NIDM["NIDM_0000015"]
+NIDM_LEGENDRE_POLYNOMIAL_ORDER = NIDM["NIDM_0000014"]
+NIDM_CONTRAST_STANDARD_ERROR_MAP = NIDM["NIDM_0000013"]
+NIDM_CONNECTIVITY_CRITERION = NIDM["NIDM_0000012"]
+NIDM_CONJUNCTION_INFERENCE = NIDM["NIDM_0000011"]
+NIDM_HAS_FMRI_DESIGN = NIDM["NIDM_0000010"]
+NIDM_COLIN27_COORDINATE_SYSTEM = NIDM["NIDM_0000009"]
+NIDM_CLUSTER_LABELS_MAP = NIDM["NIDM_0000008"]
+NIDM_CLUSTER_DEFINITION_CRITERIA = NIDM["NIDM_0000007"]
+NIDM_CLUSTER = NIDM["NIDM_0000006"]
+NIDM_BINOMIAL_DISTRIBUTION = NIDM["NIDM_0000005"]
+NIDM_BINARY_MAP = NIDM["NIDM_0000004"]
+NIDM_CONTRAST_ESTIMATION = NIDM["NIDM_0000001"]
+NIDM_CONTRAST_MAP = NIDM["NIDM_0000002"]
 
 
 # NIDM-Experiment##############################################################
 
-NIDM_DATAELEMENT = QualifiedName(provNamespace("nidm", NIDM), 'DataElement')
-NIDM_PROJECT = QualifiedName(provNamespace("nidm", NIDM), 'Project')
-#NIDM_PROJECT_TYPE = QualifiedName(provNamespace("dctypes", DCTYPES),"Dataset")
-NIDM_PROJECT_IDENTIFIER = QualifiedName(provNamespace("sio", SIO),"Identifier")
-NIDM_PROJECT_NAME = QualifiedName(provNamespace("dctypes", DCTYPES),"title")
-NIDM_PROJECT_DESCRIPTION = QualifiedName(provNamespace("dct", DCT),"description")
-NIDM_DESCRIPTION = QualifiedName(provNamespace("dct", DCT),"description")
-NIDM_DEFINITION = QualifiedName(provNamespace("dct", DCT),"description")
-NIDM_PROJECT_LICENSE = QualifiedName(provNamespace("dct", DCT),"license")
-NIDM_PROJECT_URL = QualifiedName(provNamespace("sio", SIO),"URL")
-NIDM_PROJECT_REFERENCES = QualifiedName(provNamespace("dcat", DCAT),"creator")
-NIDM_AUTHOR = QualifiedName(provNamespace("ncit", DCAT),"author")
-NIDM_SESSION = QualifiedName(provNamespace("nidm", NIDM), 'Session')
+NIDM_DATAELEMENT = QualifiedName(provNamespace("nidm", NIDM), "DataElement")
+NIDM_PROJECT = QualifiedName(provNamespace("nidm", NIDM), "Project")
+# NIDM_PROJECT_TYPE = QualifiedName(provNamespace("dctypes", DCTYPES),"Dataset")
+NIDM_PROJECT_IDENTIFIER = QualifiedName(provNamespace("sio", SIO), "Identifier")
+NIDM_PROJECT_NAME = QualifiedName(provNamespace("dctypes", DCTYPES), "title")
+NIDM_PROJECT_DESCRIPTION = QualifiedName(provNamespace("dct", DCT), "description")
+NIDM_DESCRIPTION = QualifiedName(provNamespace("dct", DCT), "description")
+NIDM_DEFINITION = QualifiedName(provNamespace("dct", DCT), "description")
+NIDM_PROJECT_LICENSE = QualifiedName(provNamespace("dct", DCT), "license")
+NIDM_PROJECT_URL = QualifiedName(provNamespace("sio", SIO), "URL")
+NIDM_PROJECT_REFERENCES = QualifiedName(provNamespace("dcat", DCAT), "creator")
+NIDM_AUTHOR = QualifiedName(provNamespace("ncit", DCAT), "author")
+NIDM_SESSION = QualifiedName(provNamespace("nidm", NIDM), "Session")
 NIDM_ACQUISITION_ACTIVITY = QualifiedName(provNamespace("nidm", NIDM), "Acquisition")
-NIDM_ACQUISITION_MODALITY = QualifiedName(provNamespace("nidm",NIDM),"hadAcquisitionModality")
-NIDM_ASSESSMENT_ACQUISITION = QualifiedName(provNamespace("onli", ONLI), "instrument-based-assessment")
-NIDM_ACQUISITION_ENTITY = QualifiedName(provNamespace("nidm", NIDM), "AcquisitionObject")
+NIDM_ACQUISITION_MODALITY = QualifiedName(
+    provNamespace("nidm", NIDM), "hadAcquisitionModality"
+)
+NIDM_ASSESSMENT_ACQUISITION = QualifiedName(
+    provNamespace("onli", ONLI), "instrument-based-assessment"
+)
+NIDM_ACQUISITION_ENTITY = QualifiedName(
+    provNamespace("nidm", NIDM), "AcquisitionObject"
+)
 
 NIDM_PROJECT_SOURCE = QualifiedName(provNamespace("dctypes", DCTYPES), "source")
-NIDM_HAD_NUMERICAL_VALUE = QualifiedName(provNamespace("nidm", NIDM), "hadNumericalValue")
+NIDM_HAD_NUMERICAL_VALUE = QualifiedName(
+    provNamespace("nidm", NIDM), "hadNumericalValue"
+)
 NIDM_BATH_SOLUTION = QualifiedName(provNamespace("nidm", NIDM), "BathSolution")
 NIDM_CELL_TYPE = QualifiedName(provNamespace("nidm", NIDM), "CellType")
 NIDM_CHANNEL_NUMBER = QualifiedName(provNamespace("nidm", NIDM), "ChannelNumber")
-NIDM_ELECTRODE_IMPEDANCE = QualifiedName(provNamespace("nidm", NIDM), "ElectrodeImpedance")
+NIDM_ELECTRODE_IMPEDANCE = QualifiedName(
+    provNamespace("nidm", NIDM), "ElectrodeImpedance"
+)
 NIDM_GROUP_LABEL = QualifiedName(provNamespace("nidm", NIDM), "GroupLabel")
-NIDM_HOLLOW_ELECTRODE_SOLUTION = QualifiedName(provNamespace("nidm", NIDM), "HollowElectrodeSolution")
-NIDM_HAD_IMAGE_CONTRACT_TYPE = QualifiedName(provNamespace("nidm", NIDM), "hadImageContractType")
-NIDM_HAD_IMAGE_USAGE_TYPE = QualifiedName(provNamespace("nidm", NIDM), "hadImageUsageType")
+NIDM_HOLLOW_ELECTRODE_SOLUTION = QualifiedName(
+    provNamespace("nidm", NIDM), "HollowElectrodeSolution"
+)
+NIDM_HAD_IMAGE_CONTRACT_TYPE = QualifiedName(
+    provNamespace("nidm", NIDM), "hadImageContractType"
+)
+NIDM_HAD_IMAGE_USAGE_TYPE = QualifiedName(
+    provNamespace("nidm", NIDM), "hadImageUsageType"
+)
 NIDM_NUBMER_OF_CHANNELS = QualifiedName(provNamespace("nidm", NIDM), "NubmerOfChannels")
 NIDM_APPLIED_FILTER = QualifiedName(provNamespace("nidm", NIDM), "AppliedFilter")
-NIDM_SOLUTION_FLOW_SPEED = QualifiedName(provNamespace("nidm", NIDM), "SolutionFlowSpeed")
-NIDM_RECORDING_LOCATION = QualifiedName(provNamespace("nidm", NIDM), "RecordingLocation")
+NIDM_SOLUTION_FLOW_SPEED = QualifiedName(
+    provNamespace("nidm", NIDM), "SolutionFlowSpeed"
+)
+NIDM_RECORDING_LOCATION = QualifiedName(
+    provNamespace("nidm", NIDM), "RecordingLocation"
+)
 
-NIDM_DEMOGRAPHICS_ENTITY = QualifiedName(provNamespace("nidm", NIDM), "DemographicsInstrument")
-NIDM_ASSESSMENT_USAGE_TYPE = QualifiedName(provNamespace("nidm", NIDM),"AssessmentUsageType")
+NIDM_DEMOGRAPHICS_ENTITY = QualifiedName(
+    provNamespace("nidm", NIDM), "DemographicsInstrument"
+)
+NIDM_ASSESSMENT_USAGE_TYPE = QualifiedName(
+    provNamespace("nidm", NIDM), "AssessmentUsageType"
+)
 
 
-NIDM_ASSESSMENT_ENTITY = QualifiedName(provNamespace("onli", ONLI), "assessment-instrument")
-#files
+NIDM_ASSESSMENT_ENTITY = QualifiedName(
+    provNamespace("onli", ONLI), "assessment-instrument"
+)
+# files
 NIDM_FILENAME = QualifiedName(provNamespace("nfo", NFO), "filename")
 NIDM_FILE = QualifiedName(provNamespace("sio", SIO), "file")
-#Roles
+# Roles
 NIDM_PI = QualifiedName(provNamespace("birnlex", BIRNLEX), "birnlex_2152")
-NIDM_COI = QualifiedName(provNamespace("birnlex", BIRNLEX),"birnlex_2199")
-NIDM_PARTICIPANT = QualifiedName(provNamespace("sio", SIO),"Subject")
-#Demographics
-NIDM_AGE = QualifiedName(provNamespace("ncidb",NCICB),"Age")
-NIDM_GENDER = QualifiedName(provNamespace("ndar",NDAR),"gender")
-NIDM_SEX = QualifiedName(provNamespace("pato",PATO),"PhenotypicSex")
-NIDM_HANDEDNESS = QualifiedName(provNamespace("obo",OBO),"handedness")
-#NIDM_HANDEDNESS = OBO["PATO_0002201"] is correct term ID for handedness above
-NIDM_ETHNICITY = QualifiedName(provNamespace("sio",SIO),"ethnicity")
-NIDM_RACE = QualifiedName(provNamespace("sio",SIO),"race")
-
-#NCICB_ETHNICITY = NCICB["C16564"] is correct term ID for ethnic group
-NIDM_DIAGNOSIS = QualifiedName(provNamespace("ncit",NCIT),"Diagnosis")
-NIDM_FAMILY_NAME = QualifiedName(provNamespace("foaf",FOAF),"familyName")
-NIDM_GIVEN_NAME = QualifiedName(provNamespace("foaf",FOAF),"givenName")
-NIDM_SUBJECTID = QualifiedName(provNamespace("ndar",NDAR),"src_subject_id")
-#MRI scan types
-NIDM_IMAGE_CONTRAST_TYPE = QualifiedName(provNamespace("nidm", NIDM),"hadImageContrastType")
-NIDM_IMAGE_USAGE_TYPE = QualifiedName(provNamespace("nidm", NIDM),"hadImageUsageType")
-NIDM_PET = QualifiedName(provNamespace("nidm", NIDM),"PositronEmissionTomography")
-NIDM_MRI = QualifiedName(provNamespace("nidm", NIDM),"MagneticResonanceImaging")
-NIDM_MRI_ANATOMIC_SCAN = QualifiedName(provNamespace("nidm", NIDM),"Anatomical")
-NIDM_MRI_STRUCTURE_SCAN = QualifiedName(provNamespace("nidm", NIDM),"Structural")
-NIDM_MRI_FUNCTION_SCAN = QualifiedName(provNamespace("nidm", NIDM),"Functional")
-NIDM_MRI_DWI_SCAN = QualifiedName(provNamespace("nidm", NIDM),"DiffusionWeighted")
-NIDM_MRI_DWI_BVAL = QualifiedName(provNamespace("nidm", NIDM),"b-value")
-NIDM_MRI_DWI_BVEC = QualifiedName(provNamespace("nidm", NIDM),"b-vector")
-NIDM_MRI_FUNCTION_TASK = QualifiedName(provNamespace("nidm", NIDM),"Task")
-NIDM_MRI_T1 = QualifiedName(provNamespace("nidm", NIDM),"T1Weighted")
-NIDM_MRI_T2 = QualifiedName(provNamespace("nidm", NIDM),"T2Weighted")
-NIDM_MRI_T2_STAR = QualifiedName(provNamespace("nidm", NIDM),"T2StarWeighted")
-NIDM_MRI_DIFFUSION_TENSOR = QualifiedName(provNamespace("nidm", NIDM),"DiffusionTensor")
-NIDM_MRI_FLOW = QualifiedName(provNamespace("nidm", NIDM),"FlowWeighted")
-NIDM_MRI_BOLD_EVENTS = QualifiedName(provNamespace("nidm", NIDM),"StimulusResponseFile")
-NIDM_MRI_ASL = QualifiedName(provNamespace("nidm",NIDM),"ArterialSpinLabeling")
-CRYPTO_SHA512  =QualifiedName(provNamespace("crypto", CRYPTO),"sha512")
-DATALAD_LOCATION = QualifiedName(provNamespace("datalad", DATALAD),"Location")
-NIDM_DOI = QualifiedName(provNamespace("edam",EDAM),"data_1188")
-NIDM_FUNDING = QualifiedName(provNamespace("obo",OBO),"IAO_0000623")
-NIDM_ACKNOWLEDGEMENTS = QualifiedName(provNamespace("obo",OBO),"IAO_0000324")
+NIDM_COI = QualifiedName(provNamespace("birnlex", BIRNLEX), "birnlex_2199")
+NIDM_PARTICIPANT = QualifiedName(provNamespace("sio", SIO), "Subject")
+# Demographics
+NIDM_AGE = QualifiedName(provNamespace("ncidb", NCICB), "Age")
+NIDM_GENDER = QualifiedName(provNamespace("ndar", NDAR), "gender")
+NIDM_SEX = QualifiedName(provNamespace("pato", PATO), "PhenotypicSex")
+NIDM_HANDEDNESS = QualifiedName(provNamespace("obo", OBO), "handedness")
+# NIDM_HANDEDNESS = OBO["PATO_0002201"] is correct term ID for handedness above
+NIDM_ETHNICITY = QualifiedName(provNamespace("sio", SIO), "ethnicity")
+NIDM_RACE = QualifiedName(provNamespace("sio", SIO), "race")
+
+# NCICB_ETHNICITY = NCICB["C16564"] is correct term ID for ethnic group
+NIDM_DIAGNOSIS = QualifiedName(provNamespace("ncit", NCIT), "Diagnosis")
+NIDM_FAMILY_NAME = QualifiedName(provNamespace("foaf", FOAF), "familyName")
+NIDM_GIVEN_NAME = QualifiedName(provNamespace("foaf", FOAF), "givenName")
+NIDM_SUBJECTID = QualifiedName(provNamespace("ndar", NDAR), "src_subject_id")
+# MRI scan types
+NIDM_IMAGE_CONTRAST_TYPE = QualifiedName(
+    provNamespace("nidm", NIDM), "hadImageContrastType"
+)
+NIDM_IMAGE_USAGE_TYPE = QualifiedName(provNamespace("nidm", NIDM), "hadImageUsageType")
+NIDM_PET = QualifiedName(provNamespace("nidm", NIDM), "PositronEmissionTomography")
+NIDM_MRI = QualifiedName(provNamespace("nidm", NIDM), "MagneticResonanceImaging")
+NIDM_MRI_ANATOMIC_SCAN = QualifiedName(provNamespace("nidm", NIDM), "Anatomical")
+NIDM_MRI_STRUCTURE_SCAN = QualifiedName(provNamespace("nidm", NIDM), "Structural")
+NIDM_MRI_FUNCTION_SCAN = QualifiedName(provNamespace("nidm", NIDM), "Functional")
+NIDM_MRI_DWI_SCAN = QualifiedName(provNamespace("nidm", NIDM), "DiffusionWeighted")
+NIDM_MRI_DWI_BVAL = QualifiedName(provNamespace("nidm", NIDM), "b-value")
+NIDM_MRI_DWI_BVEC = QualifiedName(provNamespace("nidm", NIDM), "b-vector")
+NIDM_MRI_FUNCTION_TASK = QualifiedName(provNamespace("nidm", NIDM), "Task")
+NIDM_MRI_T1 = QualifiedName(provNamespace("nidm", NIDM), "T1Weighted")
+NIDM_MRI_T2 = QualifiedName(provNamespace("nidm", NIDM), "T2Weighted")
+NIDM_MRI_T2_STAR = QualifiedName(provNamespace("nidm", NIDM), "T2StarWeighted")
+NIDM_MRI_DIFFUSION_TENSOR = QualifiedName(
+    provNamespace("nidm", NIDM), "DiffusionTensor"
+)
+NIDM_MRI_FLOW = QualifiedName(provNamespace("nidm", NIDM), "FlowWeighted")
+NIDM_MRI_BOLD_EVENTS = QualifiedName(
+    provNamespace("nidm", NIDM), "StimulusResponseFile"
+)
+NIDM_MRI_ASL = QualifiedName(provNamespace("nidm", NIDM), "ArterialSpinLabeling")
+CRYPTO_SHA512 = QualifiedName(provNamespace("crypto", CRYPTO), "sha512")
+DATALAD_LOCATION = QualifiedName(provNamespace("datalad", DATALAD), "Location")
+NIDM_DOI = QualifiedName(provNamespace("edam", EDAM), "data_1188")
+NIDM_FUNDING = QualifiedName(provNamespace("obo", OBO), "IAO_0000623")
+NIDM_ACKNOWLEDGEMENTS = QualifiedName(provNamespace("obo", OBO), "IAO_0000324")
 ##############################################################################
 # OBO constants
-OBO_EXAMPLE = OBO['IAO_0000112']
-OBO_TERM_EDITOR = OBO['IAO_0000117']
-OBO_EDITOR_NOTE = OBO['IAO_0000116']
-
-OBO_PENDING_FINAL = OBO['IAO_0000125']
-OBO_METADATA_COMPLETE = OBO['IAO_0000120']
-OBO_METADATA_INCOMPLETE = OBO['IAO_0000123']
-OBO_REQUIRES_DISCUSSION = OBO['IAO_0000428']
-OBO_UNCURATED = OBO['IAO_0000124']
-OBO_TO_BE_REPLACED = OBO['IAO_0000423']
-OBO_READY = OBO['IAO_0000122']
-OBO_DEFINITION = OBO['IAO_0000115']
+OBO_EXAMPLE = OBO["IAO_0000112"]
+OBO_TERM_EDITOR = OBO["IAO_0000117"]
+OBO_EDITOR_NOTE = OBO["IAO_0000116"]
+
+OBO_PENDING_FINAL = OBO["IAO_0000125"]
+OBO_METADATA_COMPLETE = OBO["IAO_0000120"]
+OBO_METADATA_INCOMPLETE = OBO["IAO_0000123"]
+OBO_REQUIRES_DISCUSSION = OBO["IAO_0000428"]
+OBO_UNCURATED = OBO["IAO_0000124"]
+OBO_TO_BE_REPLACED = OBO["IAO_0000423"]
+OBO_READY = OBO["IAO_0000122"]
+OBO_DEFINITION = OBO["IAO_0000115"]
 
-OBO_STATISTIC = OBO['STATO_0000039']
+OBO_STATISTIC = OBO["STATO_0000039"]
 OBO_STATISTIC_QNAME = q_graph.qname(OBO_STATISTIC)
-OBO_P_VALUE_FWER = OBO['OBI_0001265']
+OBO_P_VALUE_FWER = OBO["OBI_0001265"]
 OBO_P_VALUE_FWER_QNAME = q_graph.qname(OBO_P_VALUE_FWER)
-OBO_Q_VALUE_FDR = OBO['OBI_0001442']
+OBO_Q_VALUE_FDR = OBO["OBI_0001442"]
 OBO_Q_VALUE_FDR_QNAME = q_graph.qname(OBO_Q_VALUE_FDR)
 
-HAS_CURATION_STATUS = OBO['IAO_0000114']
+HAS_CURATION_STATUS = OBO["IAO_0000114"]
 
-STATO_OLS = OBO['STATO_0000370']
+STATO_OLS = OBO["STATO_0000370"]
 STATO_OLS_STR = q_graph.qname(STATO_OLS)
 # TODO: labels should be grabbed automatically from the corresponding owl file
 STATO_OLS_LABEL = "obo:'ordinary least squares estimation'"
-STATO_GLS = OBO['STATO_0000372']
+STATO_GLS = OBO["STATO_0000372"]
 STATO_GLS_STR = q_graph.qname(STATO_GLS)
 STATO_GLS_LABEL = "obo:'generalized least squares estimation'"
-STATO_TSTATISTIC = OBO['STATO_0000176']
+STATO_TSTATISTIC = OBO["STATO_0000176"]
 STATO_TSTATISTIC_STR = q_graph.qname(STATO_TSTATISTIC)
 STATO_TSTATISTIC_LABEL = "obo:'t-statistic'"
-STATO_ZSTATISTIC = OBO['STATO_0000376']
+STATO_ZSTATISTIC = OBO["STATO_0000376"]
 STATO_ZSTATISTIC_STR = q_graph.qname(STATO_ZSTATISTIC)
 STATO_ZSTATISTIC_LABEL = "obo:'Z-statistic'"
-STATO_CONTRAST_WEIGHT_MATRIX = OBO['STATO_0000323']
-STATO_GAUSSIAN_DISTRIBUTION = OBO['STATO_0000227']
-STATO_UNSTRUCTURED_COVARIANCE = OBO['STATO_0000405']
-STATO_GROUP = OBO['STATO_0000193']
-
-SPM_SOFTWARE = SCR['SCR_007037']
-FSL_SOFTWARE = SCR['SCR_002823']
-
-NLX_MRI_SCANNER = NLX['birnlex_2100']
-NLX_FMRI_PROTOCOL = NLX['birnlex_2250']
-NLX_IMAGING_INSTRUMENT = NLX['birnlex_2094']
+STATO_CONTRAST_WEIGHT_MATRIX = OBO["STATO_0000323"]
+STATO_GAUSSIAN_DISTRIBUTION = OBO["STATO_0000227"]
+STATO_UNSTRUCTURED_COVARIANCE = OBO["STATO_0000405"]
+STATO_GROUP = OBO["STATO_0000193"]
+
+SPM_SOFTWARE = SCR["SCR_007037"]
+FSL_SOFTWARE = SCR["SCR_002823"]
+
+NLX_MRI_SCANNER = NLX["birnlex_2100"]
+NLX_FMRI_PROTOCOL = NLX["birnlex_2250"]
+NLX_IMAGING_INSTRUMENT = NLX["birnlex_2094"]
 
-SKOS_DEFINITION = SKOS['definition']
+SKOS_DEFINITION = SKOS["definition"]
 
 
 # ProvONE Constants for classes
-PROVONE_PROCESS = PROVONE['Process']
-PROVONE_USER = PROVONE['User']
-PROVONE_PROCESSEXEC = PROVONE['ProcessExec']
-PROVONE_DATA = PROVONE['Data']
-PROVONE_INPUTPORT = PROVONE['InputPort']
-PROVONE_OUTPUTPORT = PROVONE['OutputPort']
-PROVONE_DATALINK = PROVONE['DataLink']
-PROVONE_SEQCTRLLINK = PROVONE['seqCtrlLink']
+PROVONE_PROCESS = PROVONE["Process"]
+PROVONE_USER = PROVONE["User"]
+PROVONE_PROCESSEXEC = PROVONE["ProcessExec"]
+PROVONE_DATA = PROVONE["Data"]
+PROVONE_INPUTPORT = PROVONE["InputPort"]
+PROVONE_OUTPUTPORT = PROVONE["OutputPort"]
+PROVONE_DATALINK = PROVONE["DataLink"]
+PROVONE_SEQCTRLLINK = PROVONE["seqCtrlLink"]
 
 # ProvONE Constants for Associations
-PROVONE_HASOUTPORT = PROVONE['hasOutPort']
-PROVONE_HASINPORT = PROVONE['hasInPort']
-PROVONE_HASSUBPROCESS = PROVONE['hasSubProcess']
-PROVONE_INPORTTODL = PROVONE['inPortToDL']
-PROVONE_DLTOINPORT = PROVONE['DLToInPort']
-PROVONE_OUTPORTTODL = PROVONE['outPortToDL']
-PROVONE_DLTOOUTPORT = PROVONE['DLToOutPort']
-PROVONE_CLTODESTP = PROVONE['CLtoDestP']
-PROVONE_SOURCEPTOCL = PROVONE['sourcePToCL']
-PROVONE_DATAONLINK = PROVONE['dataOnLink']
-PROVONE_HASDEFAULTPARAM = PROVONE['hasDefaultParameter']
-PROVONE_ISPARTOF = PROVONE['isPartOf']
-PROVONE_MEMBERSHIP = PROVONE['hadMember']
+PROVONE_HASOUTPORT = PROVONE["hasOutPort"]
+PROVONE_HASINPORT = PROVONE["hasInPort"]
+PROVONE_HASSUBPROCESS = PROVONE["hasSubProcess"]
+PROVONE_INPORTTODL = PROVONE["inPortToDL"]
+PROVONE_DLTOINPORT = PROVONE["DLToInPort"]
+PROVONE_OUTPORTTODL = PROVONE["outPortToDL"]
+PROVONE_DLTOOUTPORT = PROVONE["DLToOutPort"]
+PROVONE_CLTODESTP = PROVONE["CLtoDestP"]
+PROVONE_SOURCEPTOCL = PROVONE["sourcePToCL"]
+PROVONE_DATAONLINK = PROVONE["dataOnLink"]
+PROVONE_HASDEFAULTPARAM = PROVONE["hasDefaultParameter"]
+PROVONE_ISPARTOF = PROVONE["isPartOf"]
+PROVONE_MEMBERSHIP = PROVONE["hadMember"]
 
 # ProvONE notation mapping
 PROVONE_N_MAP = {
-	PROVONE_PROCESS: 			u'process',
-	PROVONE_PROCESSEXEC: 		u'processExec',
-	PROVONE_USER: 				u'user',
-	PROVONE_DATA:				u'data',
-	PROVONE_HASINPORT:			u'hasInPort',
-	PROVONE_INPUTPORT:			u'inputPort',
-	PROVONE_OUTPUTPORT:			u'outputPort',
-	PROVONE_HASOUTPORT:			u'hasOutPort',
-	PROVONE_HASSUBPROCESS:		u'hasSubProcess',
-	PROVONE_INPORTTODL:			u'inPortToDL',
-	PROVONE_DATALINK:			u'dataLink',
-	PROVONE_SEQCTRLLINK:		u'seqCtrlLink',
-	PROVONE_CLTODESTP:			u'CLtoDestP',
-	PROVONE_SOURCEPTOCL:		u'sourcePtoCL',
-	PROVONE_OUTPORTTODL:		u'outPortToDL',
-	PROVONE_DLTOOUTPORT:		u'DLToOutPort',
-	PROVONE_DLTOINPORT:			u'DLToInPort',
-	PROVONE_DATAONLINK:			u'dataOnLink',
-	PROVONE_HASDEFAULTPARAM: 	u'hasDefaultParamter',
-	PROVONE_ISPARTOF:			u'isPartOf',
-	PROVONE_MEMBERSHIP:			u'hadMember',
-
+    PROVONE_PROCESS: "process",
+    PROVONE_PROCESSEXEC: "processExec",
+    PROVONE_USER: "user",
+    PROVONE_DATA: "data",
+    PROVONE_HASINPORT: "hasInPort",
+    PROVONE_INPUTPORT: "inputPort",
+    PROVONE_OUTPUTPORT: "outputPort",
+    PROVONE_HASOUTPORT: "hasOutPort",
+    PROVONE_HASSUBPROCESS: "hasSubProcess",
+    PROVONE_INPORTTODL: "inPortToDL",
+    PROVONE_DATALINK: "dataLink",
+    PROVONE_SEQCTRLLINK: "seqCtrlLink",
+    PROVONE_CLTODESTP: "CLtoDestP",
+    PROVONE_SOURCEPTOCL: "sourcePtoCL",
+    PROVONE_OUTPORTTODL: "outPortToDL",
+    PROVONE_DLTOOUTPORT: "DLToOutPort",
+    PROVONE_DLTOINPORT: "DLToInPort",
+    PROVONE_DATAONLINK: "dataOnLink",
+    PROVONE_HASDEFAULTPARAM: "hasDefaultParamter",
+    PROVONE_ISPARTOF: "isPartOf",
+    PROVONE_MEMBERSHIP: "hadMember",
 }
 
 # Identifiers for PROVONE's attributes
-PROVONE_ATTR_PROCESS = PROVONE['process']
-PROVONE_ATTR_USER = PROVONE['user']
-PROVONE_ATTR_PROCESSEXEC = PROVONE['processExec']
-PROVONE_ATTR_PLAN = PROVONE['plan']
-PROVONE_ATTR_GENERATED_DATA = PROVONE['generatedData']
-PROVONE_ATTR_USED_DATA = PROVONE['usedData']
-PROVONE_ATTR_GENERATION = PROVONE['generation']
-#PROVONE_ATTR_USAGE = PROVONE['usage']
-PROVONE_ATTR_DATA = PROVONE['data']
-PROVONE_ATTR_INFORMED = PROVONE['informed']
-PROVONE_ATTR_INFORMANT = PROVONE['informant']
-PROVONE_ATTR_HASINPORT = PROVONE['hasInPort']
-PROVONE_ATTR_HASOUTPORT = PROVONE['HasOutPort']
-PROVONE_ATTR_INPUTPORT = PROVONE['InputPort']
-PROVONE_ATTR_OUTPUTPORT = PROVONE['OutputPort']
-PROVONE_ATTR_GENERATED_PROCESS = PROVONE['generatedProcess']
-PROVONE_ATTR_USED_PROCESS = PROVONE['usedProcess']
-PROVONE_ATTR_HASSUBPROCESS = PROVONE['hasSubProcess']
-PROVONE_ATTR_DATALINK = PROVONE['dataLink']
-PROVONE_ATTR_SEQCTRLLINK = PROVONE['seqCtrlLink']
-PROVONE_ATTR_CLTODESTP = PROVONE['clToDestP']
-PROVONE_ATTR_SOURCEPTOCL = PROVONE['sourcePtoCL']
-PROVONE_ATTR_RELATED_PREXEC = PROVONE['relatedProcessExec'],
-PROVONE_ATTR_USED_PREXEC = PROVONE['usedProcessExec']
-PROVONE_ATTR_CHILD_PREXEC = PROVONE['childProcessExec']
+PROVONE_ATTR_PROCESS = PROVONE["process"]
+PROVONE_ATTR_USER = PROVONE["user"]
+PROVONE_ATTR_PROCESSEXEC = PROVONE["processExec"]
+PROVONE_ATTR_PLAN = PROVONE["plan"]
+PROVONE_ATTR_GENERATED_DATA = PROVONE["generatedData"]
+PROVONE_ATTR_USED_DATA = PROVONE["usedData"]
+PROVONE_ATTR_GENERATION = PROVONE["generation"]
+# PROVONE_ATTR_USAGE = PROVONE['usage']
+PROVONE_ATTR_DATA = PROVONE["data"]
+PROVONE_ATTR_INFORMED = PROVONE["informed"]
+PROVONE_ATTR_INFORMANT = PROVONE["informant"]
+PROVONE_ATTR_HASINPORT = PROVONE["hasInPort"]
+PROVONE_ATTR_HASOUTPORT = PROVONE["HasOutPort"]
+PROVONE_ATTR_INPUTPORT = PROVONE["InputPort"]
+PROVONE_ATTR_OUTPUTPORT = PROVONE["OutputPort"]
+PROVONE_ATTR_GENERATED_PROCESS = PROVONE["generatedProcess"]
+PROVONE_ATTR_USED_PROCESS = PROVONE["usedProcess"]
+PROVONE_ATTR_HASSUBPROCESS = PROVONE["hasSubProcess"]
+PROVONE_ATTR_DATALINK = PROVONE["dataLink"]
+PROVONE_ATTR_SEQCTRLLINK = PROVONE["seqCtrlLink"]
+PROVONE_ATTR_CLTODESTP = PROVONE["clToDestP"]
+PROVONE_ATTR_SOURCEPTOCL = PROVONE["sourcePtoCL"]
+PROVONE_ATTR_RELATED_PREXEC = (PROVONE["relatedProcessExec"],)
+PROVONE_ATTR_USED_PREXEC = PROVONE["usedProcessExec"]
+PROVONE_ATTR_CHILD_PREXEC = PROVONE["childProcessExec"]
 
 
 PROVONE_ATTRIBUTE_QNAMES = {
-	PROVONE_ATTR_PROCESS,
-	PROVONE_ATTR_USER,
-	PROVONE_ATTR_PROCESSEXEC,
-	PROVONE_ATTR_PLAN,
-	PROVONE_ATTR_GENERATED_DATA,
-	PROVONE_ATTR_USED_DATA,
-	PROVONE_ATTR_DATA,
-	PROVONE_ATTR_INFORMED,
-	PROVONE_ATTR_INFORMANT,
-	PROVONE_ATTR_HASINPORT,
-	PROVONE_ATTR_HASOUTPORT,
-	PROVONE_ATTR_INPUTPORT,
-	PROVONE_ATTR_OUTPUTPORT,
-	PROVONE_ATTR_GENERATED_PROCESS,
-	PROVONE_ATTR_USED_PROCESS,
-	PROVONE_ATTR_HASSUBPROCESS,
-	PROVONE_ATTR_DATALINK,
-	PROVONE_ATTR_SEQCTRLLINK,
-	PROVONE_ATTR_CLTODESTP,
-	PROVONE_ATTR_SOURCEPTOCL,
-	PROVONE_ATTR_RELATED_PREXEC,
-	PROVONE_ATTR_USED_PREXEC,
-	PROVONE_ATTR_CHILD_PREXEC,
-    #PROV_ATTR_COLLECTION
+    PROVONE_ATTR_PROCESS,
+    PROVONE_ATTR_USER,
+    PROVONE_ATTR_PROCESSEXEC,
+    PROVONE_ATTR_PLAN,
+    PROVONE_ATTR_GENERATED_DATA,
+    PROVONE_ATTR_USED_DATA,
+    PROVONE_ATTR_DATA,
+    PROVONE_ATTR_INFORMED,
+    PROVONE_ATTR_INFORMANT,
+    PROVONE_ATTR_HASINPORT,
+    PROVONE_ATTR_HASOUTPORT,
+    PROVONE_ATTR_INPUTPORT,
+    PROVONE_ATTR_OUTPUTPORT,
+    PROVONE_ATTR_GENERATED_PROCESS,
+    PROVONE_ATTR_USED_PROCESS,
+    PROVONE_ATTR_HASSUBPROCESS,
+    PROVONE_ATTR_DATALINK,
+    PROVONE_ATTR_SEQCTRLLINK,
+    PROVONE_ATTR_CLTODESTP,
+    PROVONE_ATTR_SOURCEPTOCL,
+    PROVONE_ATTR_RELATED_PREXEC,
+    PROVONE_ATTR_USED_PREXEC,
+    PROVONE_ATTR_CHILD_PREXEC,
+    # PROV_ATTR_COLLECTION
 }
 
 
 # Set of formal attributes of PROV records
-PROVONE_ATTRIBUTES = PROVONE_ATTRIBUTE_QNAMES | PROV_ATTRIBUTE_QNAMES | \
-											  PROV_ATTRIBUTE_LITERALS
-PROVONE_RECORD_ATTRIBUTES = list((attr, six.text_type(attr)) for attr in
-							  PROVONE_ATTRIBUTES)
-
-PROV_RECORD_IDS_MAP = dict(
-    (PROV_N_MAP[rec_type_id], rec_type_id) for rec_type_id in PROV_N_MAP
-)
-PROVONE_ID_ATTRIBUTES_MAP = dict(
-    (prov_id, attribute) for (prov_id, attribute) in PROVONE_RECORD_ATTRIBUTES
-)
-PROVONE_ATTRIBUTES_ID_MAP = dict(
-    (attribute, prov_id) for (prov_id, attribute) in PROVONE_RECORD_ATTRIBUTES
-)
-
-
-
-####ADDED BY DBK to make searching NIDM-Experiment Terms easier...temporary, should be done in the OWL file#####
-nidm_experiment_terms = [NIDM_PROJECT,
-NIDM_PROJECT_IDENTIFIER,
-NIDM_PROJECT_NAME,
-NIDM_PROJECT_DESCRIPTION,
-NIDM_PROJECT_LICENSE,
-NIDM_PROJECT_URL,
-NIDM_PROJECT_REFERENCES,
-NIDM_AUTHOR,
-NIDM_SESSION,
-NIDM_ACQUISITION_ACTIVITY,
-NIDM_ACQUISITION_MODALITY,
-NIDM_ASSESSMENT_ACQUISITION,
-NIDM_ACQUISITION_ENTITY,
-NIDM_DEMOGRAPHICS_ENTITY,
-NIDM_ASSESSMENT_ENTITY,
-NIDM_FILENAME,
-NIDM_FILE,
-NIDM_PI,
-NIDM_COI,
-NIDM_PARTICIPANT,
-NIDM_AGE,
-NIDM_GENDER,
-NIDM_SEX,
-NIDM_HANDEDNESS,
-NIDM_RACE,
-NIDM_ETHNICITY,
-NIDM_DIAGNOSIS,
-NIDM_FAMILY_NAME,
-NIDM_GIVEN_NAME,
-NIDM_SUBJECTID,
-NIDM_IMAGE_CONTRAST_TYPE,
-NIDM_IMAGE_USAGE_TYPE,
-NIDM_MRI,
-NIDM_MRI_ANATOMIC_SCAN,
-NIDM_MRI_STRUCTURE_SCAN,
-NIDM_MRI_FUNCTION_SCAN,
-NIDM_MRI_DWI_SCAN,
-NIDM_MRI_DWI_BVAL,
-NIDM_MRI_DWI_BVEC,
-NIDM_MRI_FUNCTION_TASK,
-NIDM_MRI_T1,
-NIDM_MRI_T2,
-NIDM_MRI_T2_STAR,
-NIDM_MRI_DIFFUSION_TENSOR,
-NIDM_MRI_FLOW,
-NIDM_MRI_BOLD_EVENTS,
-NIDM_DOI]
+PROVONE_ATTRIBUTES = (
+    PROVONE_ATTRIBUTE_QNAMES | PROV_ATTRIBUTE_QNAMES | PROV_ATTRIBUTE_LITERALS
+)
+PROVONE_RECORD_ATTRIBUTES = [(attr, str(attr)) for attr in PROVONE_ATTRIBUTES]
+
+PROV_RECORD_IDS_MAP = {value: rec_type_id for rec_type_id, value in PROV_N_MAP.items()}
+PROVONE_ID_ATTRIBUTES_MAP = dict(PROVONE_RECORD_ATTRIBUTES)
+PROVONE_ATTRIBUTES_ID_MAP = {
+    attribute: prov_id for (prov_id, attribute) in PROVONE_RECORD_ATTRIBUTES
+}
+
+
+# ADDED BY DBK to make searching NIDM-Experiment Terms easier...temporary, should be done in the OWL file #
+nidm_experiment_terms = [
+    NIDM_PROJECT,
+    NIDM_PROJECT_IDENTIFIER,
+    NIDM_PROJECT_NAME,
+    NIDM_PROJECT_DESCRIPTION,
+    NIDM_PROJECT_LICENSE,
+    NIDM_PROJECT_URL,
+    NIDM_PROJECT_REFERENCES,
+    NIDM_AUTHOR,
+    NIDM_SESSION,
+    NIDM_ACQUISITION_ACTIVITY,
+    NIDM_ACQUISITION_MODALITY,
+    NIDM_ASSESSMENT_ACQUISITION,
+    NIDM_ACQUISITION_ENTITY,
+    NIDM_DEMOGRAPHICS_ENTITY,
+    NIDM_ASSESSMENT_ENTITY,
+    NIDM_FILENAME,
+    NIDM_FILE,
+    NIDM_PI,
+    NIDM_COI,
+    NIDM_PARTICIPANT,
+    NIDM_AGE,
+    NIDM_GENDER,
+    NIDM_SEX,
+    NIDM_HANDEDNESS,
+    NIDM_RACE,
+    NIDM_ETHNICITY,
+    NIDM_DIAGNOSIS,
+    NIDM_FAMILY_NAME,
+    NIDM_GIVEN_NAME,
+    NIDM_SUBJECTID,
+    NIDM_IMAGE_CONTRAST_TYPE,
+    NIDM_IMAGE_USAGE_TYPE,
+    NIDM_MRI,
+    NIDM_MRI_ANATOMIC_SCAN,
+    NIDM_MRI_STRUCTURE_SCAN,
+    NIDM_MRI_FUNCTION_SCAN,
+    NIDM_MRI_DWI_SCAN,
+    NIDM_MRI_DWI_BVAL,
+    NIDM_MRI_DWI_BVEC,
+    NIDM_MRI_FUNCTION_TASK,
+    NIDM_MRI_T1,
+    NIDM_MRI_T2,
+    NIDM_MRI_T2_STAR,
+    NIDM_MRI_DIFFUSION_TENSOR,
+    NIDM_MRI_FLOW,
+    NIDM_MRI_BOLD_EVENTS,
+    NIDM_DOI,
+]
 
 # Common isAbout URIs
-NIDM_IS_ABOUT_AGE = str(INTERLEX['ilx_0100400'])
-NIDM_IS_ABOUT_HANDEDNESS = str(OBO['PATO_0002201'])
-NIDM_IS_ABOUT_GENDER = str(INTERLEX['ilx_0101292'])
+NIDM_IS_ABOUT_AGE = str(INTERLEX["ilx_0100400"])
+NIDM_IS_ABOUT_HANDEDNESS = str(OBO["PATO_0002201"])
+NIDM_IS_ABOUT_GENDER = str(INTERLEX["ilx_0101292"])
 
 # REST API constants
-NIDM_REST_NUM_SUBJECTS = 'number_of_subjects'
-NIDM_REST_MAX_AGE = 'age_max'
-NIDM_REST_MIN_AGE = 'age_min'
-NIDM_REST_GENDER = 'gender'
-NIDM_REST_AGE = 'age'
+NIDM_REST_NUM_SUBJECTS = "number_of_subjects"
+NIDM_REST_MAX_AGE = "age_max"
+NIDM_REST_MIN_AGE = "age_min"
+NIDM_REST_GENDER = "gender"
+NIDM_REST_AGE = "age"
 
 
-# cannonical CDE file locations
+# canonical CDE file locations
 CDE_FILE_LOCATIONS = [
-	"https://raw.githubusercontent.com/ReproNim/fsl_seg_to_nidm/master/fsl_seg_to_nidm/mapping_data/fsl_cde.ttl",
-	"https://raw.githubusercontent.com/ReproNim/ants_seg_to_nidm/master/ants_seg_to_nidm/mapping_data/ants_cde.ttl",
-	"https://raw.githubusercontent.com/ReproNim/segstats_jsonld/master/segstats_jsonld/mapping_data/fs_cde.ttl"
-]
+    "https://raw.githubusercontent.com/ReproNim/fsl_seg_to_nidm/master/fsl_seg_to_nidm/mapping_data/fsl_cde.ttl",
+    "https://raw.githubusercontent.com/ReproNim/ants_seg_to_nidm/master/ants_seg_to_nidm/mapping_data/ants_cde.ttl",
+    "https://raw.githubusercontent.com/ReproNim/segstats_jsonld/master/segstats_jsonld/mapping_data/fs_cde.ttl",
+]
```

### Comparing `pynidm-3.9.7/nidm/core/serializers/__init__.py` & `pynidm-4.0.0/src/nidm/core/serializers/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,21 +1,16 @@
-from __future__ import (absolute_import, division, print_function,
-                        unicode_literals)
-
 from prov import Error
 
-__author__ = 'Trung Dong Huynh'
-__email__ = 'trungdong@donggiang.com'
+__author__ = "Trung Dong Huynh"
+__email__ = "trungdong@donggiang.com"
 
-__all__ = [
-    'get'
-]
+__all__ = ["get"]
 
 
-class Serializer(object):
+class Serializer:
     """Serializer for PROVONE documents."""
 
     document = None
     """PROVONE document to serialise."""
 
     def __init__(self, document=None):
         """
@@ -38,15 +33,14 @@
 
         :param stream: Stream object to deserialize the document from.
         """
 
 
 class DoNotExist(Error):
     """Exception for the case a serializer is not available."""
-    pass
 
 
 class Registry:
     """Registry of serializers."""
 
     serializers = None
     """Property caching all available serializers in a dict."""
@@ -56,29 +50,25 @@
         """Loads all available serializers into the registry."""
         from prov.serializers.provjson import ProvJSONSerializer
         from prov.serializers.provn import ProvNSerializer
         from prov.serializers.provxml import ProvXMLSerializer
         from nidm.core.serializers.provonerdf import ProvONERDFSerializer
 
         Registry.serializers = {
-            'json': ProvJSONSerializer,
-            'rdf': ProvONERDFSerializer,
-            'provn': ProvNSerializer,
-            'xml': ProvXMLSerializer
+            "json": ProvJSONSerializer,
+            "rdf": ProvONERDFSerializer,
+            "provn": ProvNSerializer,
+            "xml": ProvXMLSerializer,
         }
 
 
 def get(format_name):
     """
     Returns the serializer class for the specified format. Raises a DoNotExist
     """
     # Lazily initialize the list of serializers to avoid cyclic imports
     if Registry.serializers is None:
         Registry.load_serializers()
     try:
         return Registry.serializers[format_name]
     except KeyError:
-        raise DoNotExist(
-            'No serializer available for the format "%s"' % format_name
-        )
-
-
+        raise DoNotExist(f'No serializer available for the format "{format_name}"')
```

### Comparing `pynidm-3.9.7/nidm/core/serializers/provonerdf.py` & `pynidm-4.0.0/src/nidm/core/serializers/provonerdf.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,78 +1,87 @@
 """PROVONE-RDF serializers for ProvONEDocument
 """
-from __future__ import (absolute_import, division, print_function,
-                        unicode_literals)
-
 import base64
 from collections import OrderedDict
 import datetime
 import io
-
 import dateutil.parser
-import six
-
-from rdflib.term import URIRef, BNode
-from rdflib.term import Literal as RDFLiteral
-from rdflib.graph import ConjunctiveGraph
-from rdflib.namespace import RDF, RDFS, XSD
-
-import prov.model as pm
 from prov.constants import (
-    PROV, PROV_ID_ATTRIBUTES_MAP, PROV_N_MAP, PROV_BASE_CLS, XSD_QNAME,
-    PROV_END, PROV_START, PROV_USAGE, PROV_GENERATION, PROV_DERIVATION, PROV_INVALIDATION,
-    PROV_ALTERNATE, PROV_MENTION, PROV_DELEGATION, PROV_ACTIVITY, PROV_ATTR_STARTTIME,
-    PROV_ATTR_ENDTIME, PROV_LOCATION, PROV_ATTR_TIME, PROV_ROLE, PROV_COMMUNICATION,
-    PROV_ATTR_INFORMANT, PROV_ATTR_RESPONSIBLE, PROV_ATTR_TRIGGER, PROV_ATTR_ENDER,
-    PROV_ATTR_STARTER, PROV_ATTR_USED_ENTITY, PROV_ASSOCIATION)
+    PROV,
+    PROV_ACTIVITY,
+    PROV_ALTERNATE,
+    PROV_ASSOCIATION,
+    PROV_ATTR_ENDER,
+    PROV_ATTR_ENDTIME,
+    PROV_ATTR_INFORMANT,
+    PROV_ATTR_RESPONSIBLE,
+    PROV_ATTR_STARTER,
+    PROV_ATTR_STARTTIME,
+    PROV_ATTR_TIME,
+    PROV_ATTR_TRIGGER,
+    PROV_ATTR_USED_ENTITY,
+    PROV_BASE_CLS,
+    PROV_COMMUNICATION,
+    PROV_DELEGATION,
+    PROV_DERIVATION,
+    PROV_END,
+    PROV_GENERATION,
+    PROV_INVALIDATION,
+    PROV_LOCATION,
+    PROV_MENTION,
+    PROV_N_MAP,
+    PROV_ROLE,
+    PROV_START,
+    PROV_USAGE,
+    XSD_QNAME,
+)
+import prov.model as pm
 from prov.serializers import Error
 import prov.serializers.provrdf
-
-from nidm.core.Constants import PROVONE_ID_ATTRIBUTES_MAP, PROVONE
-from nidm.core.serializers import Serializer
+from rdflib.graph import ConjunctiveGraph
+from rdflib.namespace import RDF, RDFS, XSD
+from rdflib.term import BNode
+from rdflib.term import Literal as RDFLiteral
+from rdflib.term import URIRef
+from nidm.core.Constants import PROVONE, PROVONE_ID_ATTRIBUTES_MAP
 from nidm.core.provone import PROVONE_N_MAP
+from nidm.core.serializers import Serializer
 
-__author__ = 'Sanu Ann Abraham'
-__email__ = 'sanuann@mit.edu'
+__author__ = "Sanu Ann Abraham"
+__email__ = "sanuann@mit.edu"
 
 
 class ProvRDFException(Error):
     pass
 
 
 class AnonymousIDGenerator:
     def __init__(self):
         self._cache = {}
         self._count = 0
 
     def get_anon_id(self, obj, local_prefix="id"):
         if obj not in self._cache:
             self._count += 1
-            self._cache[obj] = pm.Identifier(
-                '_:%s%d' % (local_prefix, self._count)
-            ).uri
+            self._cache[obj] = pm.Identifier(f"_:{local_prefix}{self._count}").uri
         return self._cache[obj]
 
 
 # Reverse map for prov.model.XSD_DATATYPE_PARSERS
 LITERAL_XSDTYPE_MAP = {
-    float: XSD['double'],
-    int: XSD['int'],
-    six.text_type: XSD['string'],
+    float: XSD["double"],
+    int: XSD["int"],
+    str: XSD["string"],
     # boolean, string values are supported natively by PROV-RDF
     # datetime values are converted separately
 }
 
-# Add long on Python 2
-if six.integer_types[-1] not in LITERAL_XSDTYPE_MAP:
-    LITERAL_XSDTYPE_MAP[six.integer_types[-1]] = XSD['long']
-
 
 def attr2rdf(attr):
-    return URIRef(PROVONE[PROVONE_ID_ATTRIBUTES_MAP[attr].split('provone:')[1]].uri)
+    return URIRef(PROVONE[PROVONE_ID_ATTRIBUTES_MAP[attr].split("provone:")[1]].uri)
 
 
 prov.serializers.provrdf.attr2rdf = attr2rdf
 
 
 def valid_qualified_name(bundle, value, xsd_qname=False):
     if value is None:
@@ -82,65 +91,50 @@
 
 
 class ProvONERDFSerializer(Serializer):
     """
     PROV-O serializer for :class:`~prov.model.ProvDocument`
     """
 
-    def serialize(self, stream=None, rdf_format='trig', **kwargs):
+    def serialize(self, stream=None, rdf_format="trig", **kwargs):
         """
         Serializes a :class:`~prov.model.ProvDocument` instance to
         `PROV-O <https://www.w3.org/TR/prov-o/>`_.
 
         :param stream: Where to save the output.
         :param rdf_format: The RDF format of the output, default to TRiG.
         """
         container = self.encode_document(self.document)
         newargs = kwargs.copy()
-        newargs['format'] = rdf_format
+        newargs["format"] = rdf_format
 
-        if six.PY2:
-            buf = io.BytesIO()
-            try:
-                container.serialize(buf, **newargs)
-                buf.seek(0, 0)
-                # Right now this is a bytestream. If the object to stream to is
-                # a text object is must be decoded. We assume utf-8 here which
-                # should be fine for almost every case.
-                if isinstance(stream, io.TextIOBase):
-                    stream.write(buf.read().decode('utf-8'))
-                else:
-                    stream.write(buf.read())
-            finally:
-                buf.close()
-        else:
-            buf = io.BytesIO()
-            try:
-                container.serialize(buf, **newargs)
-                buf.seek(0, 0)
-                # Right now this is a bytestream. If the object to stream to is
-                # a text object is must be decoded. We assume utf-8 here which
-                # should be fine for almost every case.
-                if isinstance(stream, io.TextIOBase):
-                    stream.write(buf.read().decode('utf-8'))
-                else:
-                    stream.write(buf.read())
-            finally:
-                buf.close()
+        buf = io.BytesIO()
+        try:
+            container.serialize(buf, **newargs)
+            buf.seek(0, 0)
+            # Right now this is a bytestream. If the object to stream to is
+            # a text object is must be decoded. We assume utf-8 here which
+            # should be fine for almost every case.
+            if isinstance(stream, io.TextIOBase):
+                stream.write(buf.read().decode("utf-8"))
+            else:
+                stream.write(buf.read())
+        finally:
+            buf.close()
 
-    def deserialize(self, stream, rdf_format='trig', **kwargs):
+    def deserialize(self, stream, rdf_format="trig", **kwargs):
         """
         Deserialize from the `PROV-O <https://www.w3.org/TR/prov-o/>`_
         representation to a :class:`~prov.model.ProvDocument` instance.
 
         :param stream: Input data.
         :param rdf_format: The RDF format of the input data, default: TRiG.
         """
         newargs = kwargs.copy()
-        newargs['format'] = rdf_format
+        newargs["format"] = rdf_format
         container = ConjunctiveGraph()
         container.parse(stream, **newargs)
         document = pm.ProvDocument()
         self.document = document
         self.decode_document(container, document)
         return document
 
@@ -149,55 +143,59 @@
 
     def encode_rdf_representation(self, value):
         if isinstance(value, URIRef):
             return value
         elif isinstance(value, pm.Literal):
             return literal_rdf_representation(value)
         elif isinstance(value, datetime.datetime):
-            return RDFLiteral(value.isoformat(), datatype=XSD['dateTime'])
+            return RDFLiteral(value.isoformat(), datatype=XSD["dateTime"])
         elif isinstance(value, pm.QualifiedName):
             return URIRef(value.uri)
         elif isinstance(value, pm.Identifier):
-            return RDFLiteral(value.uri, datatype=XSD['anyURI'])
+            return RDFLiteral(value.uri, datatype=XSD["anyURI"])
         elif type(value) in LITERAL_XSDTYPE_MAP:
             return RDFLiteral(value, datatype=LITERAL_XSDTYPE_MAP[type(value)])
         else:
             return RDFLiteral(value)
 
     def decode_rdf_representation(self, literal, graph):
         if isinstance(literal, RDFLiteral):
             value = literal.value if literal.value is not None else literal
-            datatype = literal.datatype if hasattr(literal, 'datatype') else None
-            langtag = literal.language if hasattr(literal, 'language') else None
-            if datatype and 'XMLLiteral' in datatype:
+            datatype = literal.datatype if hasattr(literal, "datatype") else None
+            langtag = literal.language if hasattr(literal, "language") else None
+            if datatype and "XMLLiteral" in datatype:
                 value = literal
-            if datatype and 'base64Binary' in datatype:
+            if datatype and "base64Binary" in datatype:
                 value = base64.standard_b64encode(value)
-            if datatype == XSD['QName']:
+            if datatype == XSD["QName"]:
                 return pm.Literal(literal, datatype=XSD_QNAME)
-            if datatype == XSD['dateTime']:
+            if datatype == XSD["dateTime"]:
                 return dateutil.parser.parse(literal)
-            if datatype == XSD['gYear']:
-                return pm.Literal(dateutil.parser.parse(literal).year,
-                                  datatype=self.valid_identifier(datatype))
-            if datatype == XSD['gYearMonth']:
+            if datatype == XSD["gYear"]:
+                return pm.Literal(
+                    dateutil.parser.parse(literal).year,
+                    datatype=self.valid_identifier(datatype),
+                )
+            if datatype == XSD["gYearMonth"]:
                 parsed_info = dateutil.parser.parse(literal)
-                return pm.Literal('{0}-{1:02d}'.format(parsed_info.year, parsed_info.month),
-                                  datatype=self.valid_identifier(datatype))
+                return pm.Literal(
+                    f"{parsed_info.year}-{parsed_info.month:02d}",
+                    datatype=self.valid_identifier(datatype),
+                )
             else:
                 # The literal of standard Python types is not converted here
                 # It will be automatically converted when added to a record by
                 # _auto_literal_conversion()
                 return pm.Literal(value, self.valid_identifier(datatype), langtag)
         elif isinstance(literal, URIRef):
             rval = self.valid_identifier(literal)
             if rval is None:
                 prefix, iri, _ = graph.namespace_manager.compute_qname(literal)
                 ns = self.document.add_namespace(prefix, iri)
-                rval = pm.QualifiedName(ns, literal.replace(ns.uri, ''))
+                rval = pm.QualifiedName(ns, literal.replace(ns.uri, ""))
             return rval
         else:
             # simple type, just return it
             return literal
 
     def encode_document(self, document):
         container = self.encode_container(document)
@@ -207,44 +205,50 @@
             container.addN(bundle.quads())
         return container
 
     def encode_container(self, bundle, container=None, identifier=None):
         if container is None:
             container = ConjunctiveGraph(identifier=identifier)
             nm = container.namespace_manager
-            nm.bind('prov', PROV.uri)
+            nm.bind("prov", PROV.uri)
 
         for namespace in bundle.namespaces:
             container.bind(namespace.prefix, namespace.uri)
 
         id_generator = AnonymousIDGenerator()
-        real_or_anon_id = lambda record: record._identifier.uri if \
-            record._identifier else id_generator.get_anon_id(record)
+        real_or_anon_id = (
+            lambda record: record._identifier.uri
+            if record._identifier
+            else id_generator.get_anon_id(record)
+        )
 
         for record in bundle._records:
             rec_type = record.get_type()
-            if hasattr(record, 'identifier') and record.identifier:
-                identifier = URIRef(six.text_type(real_or_anon_id(record)))
+            if hasattr(record, "identifier") and record.identifier:
+                identifier = URIRef(str(real_or_anon_id(record)))
                 container.add((identifier, RDF.type, URIRef(rec_type.uri)))
             else:
                 identifier = None
             if record.attributes:
                 bnode = None
                 formal_objects = []
                 used_objects = []
-                all_attributes = list(record.formal_attributes) + list(record.attributes)
+                all_attributes = list(record.formal_attributes) + list(
+                    record.attributes
+                )
                 formal_qualifiers = False
-                for attrid, (attr, value) in enumerate(list(record.formal_attributes)):
-                    if (identifier is not None and value is not None) or \
-                            (identifier is None and value is not None and attrid > 1):
+                for attrid, (_, value) in enumerate(list(record.formal_attributes)):
+                    if (identifier is not None and value is not None) or (
+                        identifier is None and value is not None and attrid > 1
+                    ):
                         formal_qualifiers = True
                 has_qualifiers = len(record.extra_attributes) > 0 or formal_qualifiers
                 for idx, (attr, value) in enumerate(all_attributes):
                     if record.is_relation():
-                        if rec_type.namespace.prefix == 'prov':
+                        if rec_type.namespace.prefix == "prov":
                             pred = URIRef(PROV[PROV_N_MAP[rec_type]].uri)
                         else:
                             pred = URIRef(PROVONE[PROVONE_N_MAP[rec_type]].uri)
                         # create bnode relation
                         if bnode is None:
                             valid_formal_indices = set()
                             for idx, (key, val) in enumerate(record.formal_attributes):
@@ -254,311 +258,373 @@
                             used_objects = [record.formal_attributes[0][0]]
                             subj = None
                             if record.formal_attributes[0][1]:
                                 subj = URIRef(record.formal_attributes[0][1].uri)
                             if identifier is None and subj is not None:
                                 try:
                                     obj_val = record.formal_attributes[1][1]
-                                    obj_attr = URIRef(record.formal_attributes[1][0].uri)
-                                    # TODO: Why is obj_attr above not used anywhere?
+                                    URIRef(record.formal_attributes[1][0].uri)
                                 except IndexError:
                                     obj_val = None
-                                if obj_val and (rec_type not in
-                                                    {PROV_END,
-                                                     PROV_START,
-                                                     PROV_USAGE,
-                                                     PROV_GENERATION,
-                                                     PROV_DERIVATION,
-                                                     PROV_ASSOCIATION,
-                                                     PROV_INVALIDATION} or
-                                            (valid_formal_indices == {0, 1} and
-                                                 len(record.extra_attributes) == 0)):
+                                if obj_val and (
+                                    rec_type
+                                    not in {
+                                        PROV_END,
+                                        PROV_START,
+                                        PROV_USAGE,
+                                        PROV_GENERATION,
+                                        PROV_DERIVATION,
+                                        PROV_ASSOCIATION,
+                                        PROV_INVALIDATION,
+                                    }
+                                    or (
+                                        valid_formal_indices == {0, 1}
+                                        and len(record.extra_attributes) == 0
+                                    )
+                                ):
                                     used_objects.append(record.formal_attributes[1][0])
                                     obj_val = self.encode_rdf_representation(obj_val)
                                     if rec_type == PROV_ALTERNATE:
                                         subj, obj_val = obj_val, subj
                                     container.add((subj, pred, obj_val))
                                     if rec_type == PROV_MENTION:
                                         if record.formal_attributes[2][1]:
-                                            used_objects.append(record.formal_attributes[2][0])
-                                            obj_val = self.encode_rdf_representation(record.formal_attributes[2][1])
-                                            container.add((subj, URIRef(PROV['asInBundle'].uri), obj_val))
+                                            used_objects.append(
+                                                record.formal_attributes[2][0]
+                                            )
+                                            obj_val = self.encode_rdf_representation(
+                                                record.formal_attributes[2][1]
+                                            )
+                                            container.add(
+                                                (
+                                                    subj,
+                                                    URIRef(PROV["asInBundle"].uri),
+                                                    obj_val,
+                                                )
+                                            )
                                         has_qualifiers = False
                             if rec_type in [PROV_ALTERNATE]:
                                 continue
                             if subj and (has_qualifiers or identifier):
                                 qualifier = rec_type._localpart
                                 rec_uri = rec_type.uri
                                 for attr_name, val in record.extra_attributes:
-                                    if attr_name == PROV['type']:
-                                        if PROV['Revision'] == val or \
-                                              PROV['Quotation'] == val or \
-                                                PROV['PrimarySource'] == val:
+                                    if attr_name == PROV["type"]:
+                                        if val in (
+                                            PROV["Revision"],
+                                            PROV["Quotation"],
+                                            PROV["PrimarySource"],
+                                        ):
                                             qualifier = val._localpart
                                             rec_uri = val.uri
                                             if identifier is not None:
-                                                container.remove((identifier,
-                                                                  RDF.type,
-                                                                  URIRef(rec_type.uri)))
-                                QRole = URIRef(PROV['qualified' + qualifier].uri)
+                                                container.remove(
+                                                    (
+                                                        identifier,
+                                                        RDF.type,
+                                                        URIRef(rec_type.uri),
+                                                    )
+                                                )
+                                QRole = URIRef(PROV["qualified" + qualifier].uri)
                                 if identifier is not None:
                                     container.add((subj, QRole, identifier))
                                 else:
                                     bnode = identifier = BNode()
                                     container.add((subj, QRole, identifier))
                                     container.add(
                                         (identifier, RDF.type, URIRef(rec_uri))
                                     )  # reset identifier to BNode
                         if value is not None and attr not in used_objects:
                             if attr in formal_objects:
                                 pred = attr2rdf(attr)
-                            elif attr == PROV['role']:
-                                pred = URIRef(PROV['hadRole'].uri)
-                            elif attr == PROV['plan']:
-                                pred = URIRef(PROV['hadPlan'].uri)
-                            elif attr == PROV['type']:
+                            elif attr == PROV["role"]:
+                                pred = URIRef(PROV["hadRole"].uri)
+                            elif attr == PROV["plan"]:
+                                pred = URIRef(PROV["hadPlan"].uri)
+                            elif attr == PROV["type"]:
                                 pred = RDF.type
-                            elif attr == PROV['label']:
+                            elif attr == PROV["label"]:
                                 pred = RDFS.label
                             elif isinstance(attr, pm.QualifiedName):
                                 pred = URIRef(attr.uri)
                             else:
                                 pred = self.encode_rdf_representation(attr)
-                            if PROV['plan'].uri in pred:
-                                pred = URIRef(PROV['hadPlan'].uri)
-                            if PROV['informant'].uri in pred:
-                                pred = URIRef(PROV['activity'].uri)
-                            if PROV['responsible'].uri in pred:
-                                pred = URIRef(PROV['agent'].uri)
-                            if rec_type == PROV_DELEGATION and \
-                                            PROV['activity'].uri in pred:
-                                pred = URIRef(PROV['hadActivity'].uri)
-                            if (rec_type in [PROV_END, PROV_START] and
-                                            PROV['trigger'].uri in pred) or\
-                                (rec_type in [PROV_USAGE] and
-                                         PROV['used'].uri in pred):
-                                pred = URIRef(PROV['entity'].uri)
-                            if rec_type in [PROV_GENERATION, PROV_END,
-                                            PROV_START, PROV_USAGE,
-                                            PROV_INVALIDATION]:
-                                if PROV['time'].uri in pred:
-                                    pred = URIRef(PROV['atTime'].uri)
-                                if PROV['ender'].uri in pred:
-                                    pred = URIRef(PROV['hadActivity'].uri)
-                                if PROV['starter'].uri in pred:
-                                    pred = URIRef(PROV['hadActivity'].uri)
-                                if PROV['location'].uri in pred:
-                                    pred = URIRef(PROV['atLocation'].uri)
+                            if PROV["plan"].uri in pred:
+                                pred = URIRef(PROV["hadPlan"].uri)
+                            if PROV["informant"].uri in pred:
+                                pred = URIRef(PROV["activity"].uri)
+                            if PROV["responsible"].uri in pred:
+                                pred = URIRef(PROV["agent"].uri)
+                            if (
+                                rec_type == PROV_DELEGATION
+                                and PROV["activity"].uri in pred
+                            ):
+                                pred = URIRef(PROV["hadActivity"].uri)
+                            if (
+                                rec_type in [PROV_END, PROV_START]
+                                and PROV["trigger"].uri in pred
+                            ) or (
+                                rec_type in [PROV_USAGE] and PROV["used"].uri in pred
+                            ):
+                                pred = URIRef(PROV["entity"].uri)
+                            if rec_type in [
+                                PROV_GENERATION,
+                                PROV_END,
+                                PROV_START,
+                                PROV_USAGE,
+                                PROV_INVALIDATION,
+                            ]:
+                                if PROV["time"].uri in pred:
+                                    pred = URIRef(PROV["atTime"].uri)
+                                if PROV["ender"].uri in pred:
+                                    pred = URIRef(PROV["hadActivity"].uri)
+                                if PROV["starter"].uri in pred:
+                                    pred = URIRef(PROV["hadActivity"].uri)
+                                if PROV["location"].uri in pred:
+                                    pred = URIRef(PROV["atLocation"].uri)
                             if rec_type in [PROV_ACTIVITY]:
                                 if PROV_ATTR_STARTTIME in pred:
-                                    pred = URIRef(PROV['startedAtTime'].uri)
+                                    pred = URIRef(PROV["startedAtTime"].uri)
                                 if PROV_ATTR_ENDTIME in pred:
-                                    pred = URIRef(PROV['endedAtTime'].uri)
+                                    pred = URIRef(PROV["endedAtTime"].uri)
                             if rec_type == PROV_DERIVATION:
-                                if PROV['activity'].uri in pred:
-                                    pred = URIRef(PROV['hadActivity'].uri)
-                                if PROV['generation'].uri in pred:
-                                    pred = URIRef(PROV['hadGeneration'].uri)
-                                if PROV['usage'].uri in pred:
-                                    pred = URIRef(PROV['hadUsage'].uri)
-                                if PROV['usedEntity'].uri in pred:
-                                    pred = URIRef(PROV['entity'].uri)
-                            container.add((identifier, pred,
-                                           self.encode_rdf_representation(value)))
+                                if PROV["activity"].uri in pred:
+                                    pred = URIRef(PROV["hadActivity"].uri)
+                                if PROV["generation"].uri in pred:
+                                    pred = URIRef(PROV["hadGeneration"].uri)
+                                if PROV["usage"].uri in pred:
+                                    pred = URIRef(PROV["hadUsage"].uri)
+                                if PROV["usedEntity"].uri in pred:
+                                    pred = URIRef(PROV["entity"].uri)
+                            container.add(
+                                (
+                                    identifier,
+                                    pred,
+                                    self.encode_rdf_representation(value),
+                                )
+                            )
                         continue
                     if value is None:
                         continue
                     if isinstance(value, pm.ProvRecord):
-                        obj = URIRef(six.text_type(real_or_anon_id(value)))
+                        obj = URIRef(str(real_or_anon_id(value)))
                     else:
                         #  Assuming this is a datetime value
                         obj = self.encode_rdf_representation(value)
-                    if attr == PROV['location']:
-                        pred = URIRef(PROV['atLocation'].uri)
+                    if attr == PROV["location"]:
+                        pred = URIRef(PROV["atLocation"].uri)
                         if False and isinstance(value, (URIRef, pm.QualifiedName)):
                             if isinstance(value, pm.QualifiedName):
                                 value = URIRef(value.uri)
                             container.add((identifier, pred, value))
                         else:
-                            container.add((identifier, pred,
-                                           self.encode_rdf_representation(obj)))
+                            container.add(
+                                (identifier, pred, self.encode_rdf_representation(obj))
+                            )
                         continue
-                    if attr == PROV['type']:
+                    if attr == PROV["type"]:
                         pred = RDF.type
-                    elif attr == PROV['label']:
+                    elif attr == PROV["label"]:
                         pred = RDFS.label
                     elif attr == PROV_ATTR_STARTTIME:
-                        pred = URIRef(PROV['startedAtTime'].uri)
+                        pred = URIRef(PROV["startedAtTime"].uri)
                     elif attr == PROV_ATTR_ENDTIME:
-                        pred = URIRef(PROV['endedAtTime'].uri)
+                        pred = URIRef(PROV["endedAtTime"].uri)
                     else:
                         pred = self.encode_rdf_representation(attr)
                     container.add((identifier, pred, obj))
         return container
 
     def decode_document(self, content, document):
         for prefix, url in content.namespaces():
-            document.add_namespace(prefix, six.text_type(url))
-        if hasattr(content, 'contexts'):
+            document.add_namespace(prefix, str(url))
+        if hasattr(content, "contexts"):
             for graph in content.contexts():
                 if isinstance(graph.identifier, BNode):
                     self.decode_container(graph, document)
                 else:
-                    bundle_id = six.text_type(graph.identifier)
+                    bundle_id = str(graph.identifier)
                     bundle = document.bundle(bundle_id)
                     self.decode_container(graph, bundle)
         else:
             self.decode_container(content, document)
 
     def decode_container(self, graph, bundle):
         ids = {}
         PROV_CLS_MAP = {}
         formal_attributes = {}
         unique_sets = {}
-        for key, val in PROV_BASE_CLS.items():
-            PROV_CLS_MAP[key.uri] = PROV_BASE_CLS[key]
-        relation_mapper = {URIRef(PROV['alternateOf'].uri): 'alternate',
-                           URIRef(PROV['actedOnBehalfOf'].uri): 'delegation',
-                           URIRef(PROV['specializationOf'].uri): 'specialization',
-                           URIRef(PROV['mentionOf'].uri): 'mention',
-                           URIRef(PROV['wasAssociatedWith'].uri): 'association',
-                           URIRef(PROV['wasDerivedFrom'].uri): 'derivation',
-                           URIRef(PROV['wasAttributedTo'].uri): 'attribution',
-                           URIRef(PROV['wasInformedBy'].uri): 'communication',
-                           URIRef(PROV['wasGeneratedBy'].uri): 'generation',
-                           URIRef(PROV['wasInfluencedBy'].uri): 'influence',
-                           URIRef(PROV['wasInvalidatedBy'].uri): 'invalidation',
-                           URIRef(PROV['wasEndedBy'].uri): 'end',
-                           URIRef(PROV['wasStartedBy'].uri): 'start',
-                           URIRef(PROV['hadMember'].uri): 'membership',
-                           URIRef(PROV['used'].uri): 'usage',
-                           }
-        predicate_mapper = {RDFS.label: pm.PROV['label'],
-                            URIRef(PROV['atLocation'].uri): PROV_LOCATION,
-                            URIRef(PROV['startedAtTime'].uri): PROV_ATTR_STARTTIME,
-                            URIRef(PROV['endedAtTime'].uri): PROV_ATTR_ENDTIME,
-                            URIRef(PROV['atTime'].uri): PROV_ATTR_TIME,
-                            URIRef(PROV['hadRole'].uri): PROV_ROLE,
-                            URIRef(PROV['hadPlan'].uri): pm.PROV_ATTR_PLAN,
-                            URIRef(PROV['hadUsage'].uri): pm.PROV_ATTR_USAGE,
-                            URIRef(PROV['hadGeneration'].uri): pm.PROV_ATTR_GENERATION,
-                            URIRef(PROV['hadActivity'].uri): pm.PROV_ATTR_ACTIVITY,
-                            }
+        for key, value in PROV_BASE_CLS.items():
+            PROV_CLS_MAP[key.uri] = value
+        relation_mapper = {
+            URIRef(PROV["alternateOf"].uri): "alternate",
+            URIRef(PROV["actedOnBehalfOf"].uri): "delegation",
+            URIRef(PROV["specializationOf"].uri): "specialization",
+            URIRef(PROV["mentionOf"].uri): "mention",
+            URIRef(PROV["wasAssociatedWith"].uri): "association",
+            URIRef(PROV["wasDerivedFrom"].uri): "derivation",
+            URIRef(PROV["wasAttributedTo"].uri): "attribution",
+            URIRef(PROV["wasInformedBy"].uri): "communication",
+            URIRef(PROV["wasGeneratedBy"].uri): "generation",
+            URIRef(PROV["wasInfluencedBy"].uri): "influence",
+            URIRef(PROV["wasInvalidatedBy"].uri): "invalidation",
+            URIRef(PROV["wasEndedBy"].uri): "end",
+            URIRef(PROV["wasStartedBy"].uri): "start",
+            URIRef(PROV["hadMember"].uri): "membership",
+            URIRef(PROV["used"].uri): "usage",
+        }
+        predicate_mapper = {
+            RDFS.label: pm.PROV["label"],
+            URIRef(PROV["atLocation"].uri): PROV_LOCATION,
+            URIRef(PROV["startedAtTime"].uri): PROV_ATTR_STARTTIME,
+            URIRef(PROV["endedAtTime"].uri): PROV_ATTR_ENDTIME,
+            URIRef(PROV["atTime"].uri): PROV_ATTR_TIME,
+            URIRef(PROV["hadRole"].uri): PROV_ROLE,
+            URIRef(PROV["hadPlan"].uri): pm.PROV_ATTR_PLAN,
+            URIRef(PROV["hadUsage"].uri): pm.PROV_ATTR_USAGE,
+            URIRef(PROV["hadGeneration"].uri): pm.PROV_ATTR_GENERATION,
+            URIRef(PROV["hadActivity"].uri): pm.PROV_ATTR_ACTIVITY,
+        }
         other_attributes = {}
         for stmt in graph.triples((None, RDF.type, None)):
-            id = six.text_type(stmt[0])
-            obj = six.text_type(stmt[2])
+            id_ = str(stmt[0])
+            obj = str(stmt[2])
             if obj in PROV_CLS_MAP:
-                if not isinstance(stmt[0], BNode) and self.valid_identifier(id) is None:
-                    prefix, iri, _ = graph.namespace_manager.compute_qname(id)
+                if (
+                    not isinstance(stmt[0], BNode)
+                    and self.valid_identifier(id_) is None
+                ):
+                    prefix, iri, _ = graph.namespace_manager.compute_qname(id_)
                     self.document.add_namespace(prefix, iri)
                 try:
                     prov_obj = PROV_CLS_MAP[obj]
                 except AttributeError:
                     prov_obj = None
                 add_attr = True
-                isderivation = pm.PROV['Revision'].uri in stmt[2] or \
-                               pm.PROV['Quotation'].uri in stmt[2] or \
-                               pm.PROV['PrimarySource'].uri in stmt[2]
-                if id not in ids and prov_obj and (prov_obj.uri == obj or
-                                                    isderivation or
-                                                       isinstance(stmt[0], BNode)):
-                    ids[id] = prov_obj
+                isderivation = (
+                    pm.PROV["Revision"].uri in stmt[2]
+                    or pm.PROV["Quotation"].uri in stmt[2]
+                    or pm.PROV["PrimarySource"].uri in stmt[2]
+                )
+                if (
+                    id_ not in ids
+                    and prov_obj
+                    and (
+                        prov_obj.uri == obj
+                        or isderivation
+                        or isinstance(stmt[0], BNode)
+                    )
+                ):
+                    ids[id_] = prov_obj
                     klass = pm.PROV_REC_CLS[prov_obj]
-                    formal_attributes[id] = OrderedDict([(key, None) for key in klass.FORMAL_ATTRIBUTES])
-                    unique_sets[id] = OrderedDict([(key, []) for key in klass.FORMAL_ATTRIBUTES])
-                    add_attr = False or ((isinstance(stmt[0], BNode) or isderivation) and prov_obj.uri != obj)
+                    formal_attributes[id_] = OrderedDict(
+                        [(key, None) for key in klass.FORMAL_ATTRIBUTES]
+                    )
+                    unique_sets[id_] = OrderedDict(
+                        [(key, []) for key in klass.FORMAL_ATTRIBUTES]
+                    )
+                    add_attr = False or (
+                        (isinstance(stmt[0], BNode) or isderivation)
+                        and prov_obj.uri != obj
+                    )
                 if add_attr:
-                    if id not in other_attributes:
-                        other_attributes[id] = []
+                    if id_ not in other_attributes:
+                        other_attributes[id_] = []
                     obj_formatted = self.decode_rdf_representation(stmt[2], graph)
-                    other_attributes[id].append((pm.PROV['type'], obj_formatted))
+                    other_attributes[id_].append((pm.PROV["type"], obj_formatted))
             else:
-                if id not in other_attributes:
-                    other_attributes[id] = []
+                if id_ not in other_attributes:
+                    other_attributes[id_] = []
                 obj = self.decode_rdf_representation(stmt[2], graph)
-                other_attributes[id].append((pm.PROV['type'], obj))
-        for id, pred, obj in graph:
-            id = six.text_type(id)
-            if id not in other_attributes:
-                other_attributes[id] = []
+                other_attributes[id_].append((pm.PROV["type"], obj))
+        for id_, pred, obj in graph:
+            id_ = str(id_)
+            if id_ not in other_attributes:
+                other_attributes[id_] = []
             if pred == RDF.type:
                 continue
             if pred in relation_mapper:
-                if 'alternateOf' in pred:
-                    getattr(bundle, relation_mapper[pred])(obj, id)
-                elif 'mentionOf' in pred:
+                if "alternateOf" in pred:
+                    getattr(bundle, relation_mapper[pred])(obj, id_)
+                elif "mentionOf" in pred:
                     mentionBundle = None
-                    for stmt in graph.triples((URIRef(id), URIRef(pm.PROV['asInBundle'].uri), None)):
+                    for stmt in graph.triples(
+                        (URIRef(id_), URIRef(pm.PROV["asInBundle"].uri), None)
+                    ):
                         mentionBundle = stmt[2]
-                    getattr(bundle, relation_mapper[pred])(id, six.text_type(obj), mentionBundle)
-                elif 'actedOnBehalfOf' in pred or 'wasAssociatedWith' in pred:
-                    qualifier = 'qualified' + relation_mapper[pred].upper()[0] + relation_mapper[pred][1:]
+                    getattr(bundle, relation_mapper[pred])(id_, str(obj), mentionBundle)
+                elif "actedOnBehalfOf" in pred or "wasAssociatedWith" in pred:
+                    qualifier = (
+                        "qualified"
+                        + relation_mapper[pred].upper()[0]
+                        + relation_mapper[pred][1:]
+                    )
                     qualifier_bnode = None
-                    for stmt in graph.triples((URIRef(id), URIRef(pm.PROV[qualifier].uri), None)):
+                    for stmt in graph.triples(
+                        (URIRef(id_), URIRef(pm.PROV[qualifier].uri), None)
+                    ):
                         qualifier_bnode = stmt[2]
                     if qualifier_bnode is None:
-                        getattr(bundle, relation_mapper[pred])(id, six.text_type(obj))
+                        getattr(bundle, relation_mapper[pred])(id_, str(obj))
                     else:
-                        fakeys = list(formal_attributes[six.text_type(qualifier_bnode)].keys())
-                        formal_attributes[six.text_type(qualifier_bnode)][fakeys[0]] = id
-                        formal_attributes[six.text_type(qualifier_bnode)][fakeys[1]] = six.text_type(obj)
+                        fakeys = list(formal_attributes[str(qualifier_bnode)].keys())
+                        formal_attributes[str(qualifier_bnode)][fakeys[0]] = id_
+                        formal_attributes[str(qualifier_bnode)][fakeys[1]] = str(obj)
                 else:
-                    getattr(bundle, relation_mapper[pred])(id, six.text_type(obj))
-            elif id in ids:
+                    getattr(bundle, relation_mapper[pred])(id_, str(obj))
+            elif id_ in ids:
                 obj1 = self.decode_rdf_representation(obj, graph)
                 if obj is not None and obj1 is None:
-                    raise ValueError(('Error transforming', obj))
-                pred_new = pred
-                if pred in predicate_mapper:
-                    pred_new = predicate_mapper[pred]
-                if ids[id] == PROV_COMMUNICATION and 'activity' in six.text_type(pred_new):
+                    raise ValueError(("Error transforming", obj))
+                pred_new = predicate_mapper.get(pred, pred)
+                if ids[id_] == PROV_COMMUNICATION and "activity" in str(pred_new):
                     pred_new = PROV_ATTR_INFORMANT
-                if ids[id] == PROV_DELEGATION and 'agent' in six.text_type(pred_new):
+                if ids[id_] == PROV_DELEGATION and "agent" in str(pred_new):
                     pred_new = PROV_ATTR_RESPONSIBLE
-                if ids[id] in [PROV_END, PROV_START] and 'entity' in six.text_type(pred_new):
+                if ids[id_] in [PROV_END, PROV_START] and "entity" in str(pred_new):
                     pred_new = PROV_ATTR_TRIGGER
-                if ids[id] in [PROV_END] and 'activity' in six.text_type(pred_new):
+                if ids[id_] in [PROV_END] and "activity" in str(pred_new):
                     pred_new = PROV_ATTR_ENDER
-                if ids[id] in [PROV_START] and 'activity' in six.text_type(pred_new):
+                if ids[id_] in [PROV_START] and "activity" in str(pred_new):
                     pred_new = PROV_ATTR_STARTER
-                if ids[id] == PROV_DERIVATION and 'entity' in six.text_type(pred_new):
+                if ids[id_] == PROV_DERIVATION and "entity" in str(pred_new):
                     pred_new = PROV_ATTR_USED_ENTITY
-                if six.text_type(pred_new) in [val.uri for val in formal_attributes[id]]:
+                if str(pred_new) in [val.uri for val in formal_attributes[id_]]:
                     qname_key = self.valid_identifier(pred_new)
-                    formal_attributes[id][qname_key] = obj1
-                    unique_sets[id][qname_key].append(obj1)
-                    if len(unique_sets[id][qname_key]) > 1:
-                        formal_attributes[id][qname_key] = None
+                    formal_attributes[id_][qname_key] = obj1
+                    unique_sets[id_][qname_key].append(obj1)
+                    if len(unique_sets[id_][qname_key]) > 1:
+                        formal_attributes[id_][qname_key] = None
                 else:
-                    if 'qualified' not in six.text_type(pred_new) and \
-                                    'asInBundle' not in six.text_type(pred_new):
-                        other_attributes[id].append((six.text_type(pred_new), obj1))
-            local_key = six.text_type(obj)
+                    if "qualified" not in str(pred_new) and "asInBundle" not in str(
+                        pred_new
+                    ):
+                        other_attributes[id_].append((str(pred_new), obj1))
+            local_key = str(obj)
             if local_key in ids:
-                if 'qualified' in pred:
-                    formal_attributes[local_key][list(formal_attributes[local_key].keys())[0]] = id
-        for id in ids:
-            attrs = None
-            if id in other_attributes:
-                attrs = other_attributes[id]
+                if "qualified" in pred:
+                    formal_attributes[local_key][
+                        next(iter(formal_attributes[local_key]))
+                    ] = id_
+        for id_, idvalue in ids.items():
+            attrs = other_attributes.get(id_)
             items_to_walk = []
-            for qname, values in unique_sets[id].items():
+            for qname, values in unique_sets[id_].items():
                 if values and len(values) > 1:
                     items_to_walk.append((qname, values))
             if items_to_walk:
                 for subset in list(walk(items_to_walk)):
                     for key, value in subset.items():
-                        formal_attributes[id][key] = value
-                    bundle.new_record(ids[id], id, formal_attributes[id], attrs)
+                        formal_attributes[id_][key] = value
+                    bundle.new_record(idvalue, id_, formal_attributes[id_], attrs)
             else:
-                bundle.new_record(ids[id], id, formal_attributes[id], attrs)
-            ids[id] = None
+                bundle.new_record(idvalue, id_, formal_attributes[id_], attrs)
+            ids[id_] = None
             if attrs is not None:
-                other_attributes[id] = []
+                other_attributes[id_] = []
         for key, val in other_attributes.items():
             if val:
                 ids[key].add_attributes(val)
 
 
 def walk(children, level=0, path=None, usename=True):
     """Generate all the full paths in a tree, as a dict.
@@ -590,19 +656,16 @@
             path[level] = child
         # Recurse into the next level
         for child_paths in walk(tail, level + 1, path, usename):
             yield child_paths
 
 
 def literal_rdf_representation(literal):
-    value = six.text_type(literal.value) if literal.value else literal
+    value = str(literal.value) if literal.value else literal
     if literal.langtag:
         #  a language tag can only go with prov:InternationalizedString
         return RDFLiteral(value, lang=str(literal.langtag))
     else:
         datatype = literal.datatype
-        if 'base64Binary' in datatype.uri:
-            if six.PY2:
-                value = base64.standard_b64encode(value)
-            else:
-                value = literal.value.encode()
+        if "base64Binary" in datatype.uri:
+            value = literal.value.encode()
         return RDFLiteral(value, datatype=datatype.uri)
```

### Comparing `pynidm-3.9.7/nidm/experiment/Acquisition.py` & `pynidm-4.0.0/src/nidm/experiment/Acquisition.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,81 +1,89 @@
-import rdflib as rdf
-import os, sys
-
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-from ..core import Constants
-from ..experiment import Core
-from ..experiment.Core import getUUID
 import prov.model as pm
+from .Core import Core, getUUID
+from ..core import Constants
 
-class Acquisition(pm.ProvActivity,Core):
+
+class Acquisition(pm.ProvActivity, Core):
     """Class for NIDM-Experiment Acquisition-Level Objects.
 
     Default constructor uses empty graph with namespaces added from NIDM/Scripts/Constants.py.
     Additional alternate constructors for user-supplied graphs and default namespaces (i.e. from Constants.py)
     and user-supplied graph and namespaces
 
     @author: David Keator <dbkeator@uci.edu>
     @copyright: University of California, Irvine 2017
 
     """
-    #constructor
+
+    # constructor
     def __init__(self, session, attributes=None, uuid=None, add_default_type=True):
         """
-        Default contructor, creates a session activity and links to project object
+        Default constructor, creates a session activity and links to project object
 
         :param session: a session object
         :param uuid: optional uuid...used mostly for reading in existing NIDM document
         :param attributes: optional dictionary of attributes to add qname:value
 
         """
         if uuid is None:
             self._uuid = getUUID()
 
-            #execute default parent class constructor
-            super(Acquisition,self).__init__(session.graph, pm.QualifiedName(pm.Namespace("niiri",Constants.NIIRI),self.get_uuid()),attributes)
+            # execute default parent class constructor
+            super().__init__(
+                session.graph,
+                pm.QualifiedName(
+                    pm.Namespace("niiri", Constants.NIIRI), self.get_uuid()
+                ),
+                attributes,
+            )
         else:
             self._uuid = uuid
-            super(Acquisition,self).__init__(session.graph, pm.QualifiedName(pm.Namespace("niiri",Constants.NIIRI),self.get_uuid()),attributes)
+            super().__init__(
+                session.graph,
+                pm.QualifiedName(
+                    pm.Namespace("niiri", Constants.NIIRI), self.get_uuid()
+                ),
+                attributes,
+            )
 
         session.graph._add_record(self)
 
         if add_default_type:
             self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ACQUISITION_ACTIVITY})
-        #self.add_attributes({pm.QualifiedName(pm.Namespace("dct",Constants.DCT),'isPartOf'):self})
+        # self.add_attributes({pm.QualifiedName(pm.Namespace("dct",Constants.DCT),'isPartOf'):self})
 
-        #list to store acquisition objects associated with this activity
-        self._acquisition_objects=[]
-        #if constructor is called with a session object then add this acquisition to the session
+        # list to store acquisition objects associated with this activity
+        self._acquisition_objects = []
+        # if constructor is called with a session object then add this acquisition to the session
 
-        #carry graph object around
+        # carry graph object around
         self.graph = session.graph
 
-        #add acquisition to session
+        # add acquisition to session
         session.add_acquisition(self)
 
-    def add_acquisition_object(self,acquisition_object):
+    def add_acquisition_object(self, acquisition_object):
         """
         Adds acquisition objects to acquisition activity, creating links and adding reference to acquisitions list
 
         :param acquisition: object of type "AcquisitionObject" from nidm API
 
         """
-        #add acquisition object to self._acquisitions list
+        # add acquisition object to self._acquisitions list
         self._acquisition_objects.extend([acquisition_object])
-        #create links in graph
-        self.graph.wasGeneratedBy(acquisition_object,self)
+        # create links in graph
+        self.graph.wasGeneratedBy(acquisition_object, self)
+
     def get_acquisition_objects(self):
         return self._acquisition_objects
-    def acquisition_object_exists(self,uuid):
-        '''
+
+    def acquisition_object_exists(self, uuid):
+        """
         Checks whether uuid is a registered acquisition object
         :param uuid: full uuid of acquisition
         :return: True if exists, False otherwise
-        '''
-        if uuid in self._acquisition_objects:
-            return True
-        else:
-            return False
+        """
+        return bool(uuid in self._acquisition_objects)
 
     def __str__(self):
         return "NIDM-Experiment Acquisition Class"
```

### Comparing `pynidm-3.9.7/nidm/experiment/AcquisitionObject.py` & `pynidm-4.0.0/src/nidm/experiment/PETObject.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,50 +1,42 @@
-import os, sys
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-import rdflib as rdf
-from ..core import Constants
-from ..experiment import Core
-from ..experiment.Core import getUUID
 import prov.model as pm
+from .AcquisitionObject import AcquisitionObject
+from ..core import Constants
 
-class AcquisitionObject(pm.ProvEntity,Core):
-    """Class for NIDM-Experimenent AcquisitionObject-Level Objects.
+
+class PETObject(AcquisitionObject):
+    """Class for NIDM-Experimenent MRAcquisitionObject-Level Objects.
 
     Default constructor uses empty graph with namespaces added from NIDM/Scripts/Constants.py.
     Additional alternate constructors for user-supplied graphs and default namespaces (i.e. from Constants.py)
     and user-supplied graph and namespaces
 
     @author: David Keator <dbkeator@uci.edu>
     @copyright: University of California, Irvine 2017
 
     """
-    #constructor
-    def __init__(self, acquisition,attributes=None, uuid=None):
+
+    # constructor
+    def __init__(self, acquisition, attributes=None, uuid=None, add_default_type=True):
         """
-        Default contructor, creates an acquisition object and links to acquisition activity object
+        Default constructor, creates an acquisition object and links to acquisition activity object
 
-        :param acquisition: a Aquisition activity object
+        :param acquisition: a Acquisition activity object
         :param attributes: optional attributes to add to entity
         :param uuid: optional uuid...used mostly for reading in existing NIDM document
         :return: none
 
         """
+        # execute default parent class constructor
+        super().__init__(acquisition, attributes, uuid)
 
-        if uuid is None:
-            self._uuid = getUUID()
-            #execute default parent class constructor
-            super(AcquisitionObject,self).__init__(acquisition.graph, pm.QualifiedName(pm.Namespace("niiri",Constants.NIIRI),self.get_uuid()),attributes)
-        else:
-            self._uuid = uuid
-            super(AcquisitionObject,self).__init__(acquisition.graph, pm.QualifiedName(pm.Namespace("niiri",Constants.NIIRI),self.get_uuid()),attributes)
+        if add_default_type:
+            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ACQUISITION_ENTITY})
+            self.add_attributes(
+                {Constants.NIDM_ACQUISITION_MODALITY: Constants.NIDM_PET}
+            )
 
-        acquisition.graph._add_record(self)
-
-        #carry graph object around
+        # carry graph object around
         self.graph = acquisition.graph
-        #create link to acquisition activity
-        acquisition.add_acquisition_object(self)
 
     def __str__(self):
-        return "NIDM-Experiment AcquisitionObject Class"
-
-
+        return "NIDM-Experiment PET Object Class"
```

### Comparing `pynidm-3.9.7/nidm/experiment/AssessmentAcquisition.py` & `pynidm-4.0.0/src/nidm/experiment/DemographicsObject.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,42 +1,45 @@
-import os, sys
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-import rdflib as rdf
-from ..experiment import Acquisition
-from ..core import Constants
-from ..experiment.Core import getUUID
 import prov.model as pm
+from .AcquisitionObject import AcquisitionObject
+from ..core import Constants
 
-class AssessmentAcquisition(Acquisition):
-    """
-        Default contructor, creates a session activity and links to project object
 
-        :param session: a session object
+class DemographicsObject(AcquisitionObject):
+    """Class for NIDM-Experimenent MRAcquisitionObject-Level Objects.
+
+    Default constructor uses empty graph with namespaces added from NIDM/Scripts/Constants.py.
+    Additional alternate constructors for user-supplied graphs and default namespaces (i.e. from Constants.py)
+    and user-supplied graph and namespaces
+
+    @author: David Keator <dbkeator@uci.edu>
+    @copyright: University of California, Irvine 2017
 
     """
 
-    #constructor
-    def __init__(self, session,attributes=None, uuid=None, add_default_type=True):
+    # constructor
+    def __init__(self, acquisition, attributes=None, uuid=None, add_default_type=True):
         """
-        Default contructor, creates an acquisition object and links to acquisition activity object
+        Default constructor, creates an acquisition object and links to acquisition activity object
 
-        :param session: a session object
+        :param acquisition: a Acquisition activity object
         :param attributes: optional attributes to add to entity
         :param uuid: optional uuid...used mostly for reading in existing NIDM document
         :return: none
 
         """
-        #execute default parent class constructor
-          #execute default parent class constructor
-        super(AssessmentAcquisition,self).__init__(session,attributes,uuid)
-        #acquisition.graph._add_record(self)
+        # execute default parent class constructor
+        super().__init__(acquisition, attributes, uuid)
 
         if add_default_type:
-            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ACQUISITION_ACTIVITY})
-            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ASSESSMENT_ACQUISITION})
-
-        #carry graph object around
-        self.graph = session.graph
+            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ASSESSMENT_ENTITY})
+            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ACQUISITION_ENTITY})
+            self.add_attributes(
+                {
+                    Constants.NIDM_ASSESSMENT_USAGE_TYPE: Constants.NIDM_DEMOGRAPHICS_ENTITY
+                }
+            )
 
+        # carry graph object around
+        self.graph = acquisition.graph
 
     def __str__(self):
-        return "NIDM-Experiment Assessment Acquisition Class"
+        return "NIDM-Experiment Demographics Object Class"
```

### Comparing `pynidm-3.9.7/nidm/experiment/AssessmentObject.py` & `pynidm-4.0.0/src/nidm/experiment/DataElement.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,46 +1,52 @@
-import os, sys
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-import rdflib as rdf
-from ..core import Constants
-from ..experiment import AcquisitionObject
 import prov.model as pm
+from .Core import Core, getUUID
+from ..core import Constants
+
 
-class AssessmentObject(AcquisitionObject):
-    """Class for NIDM-Experimenent generic AssessmentAcquisitionObject-Level Objects.
+class DataElement(pm.ProvEntity, Core):
+    """Class for NIDM-Experiment DataElement Objects.
 
     Default constructor uses empty graph with namespaces added from NIDM/Scripts/Constants.py.
     Additional alternate constructors for user-supplied graphs and default namespaces (i.e. from Constants.py)
     and user-supplied graph and namespaces
 
     @author: David Keator <dbkeator@uci.edu>
-    @copyright: University of California, Irvine 2017
+    @copyright: University of California, Irvine 2019
 
     """
-    #constructor
-    def __init__(self, acquisition,assessment_type=None,attributes=None, uuid=None, add_default_type=True):
+
+    # constructor
+    def __init__(self, project, attributes=None, uuid=None, add_default_type=True):
         """
-        Default contructor, creates an acquisition object and links to acquisition activity object
+        Default constructor, creates an acquisition object and links to acquisition activity object
 
-        :param acquisition: a Aquisition activity object
-        :param assessment_type: optional qualified name of assessment type (e.g. pm.QualifiedName(pm.Namespace("nidm",Constants.NIDM),"PositiveAndNegativeSyndromeScale"))
+        :param project: NIDM project to add data element entity to.\
         :param attributes: optional attributes to add to entity
         :param uuid: optional uuid...used mostly for reading in existing NIDM document
         :return: none
 
         """
-        #execute default parent class constructor
-          #execute default parent class constructor
-        super(AssessmentObject,self).__init__(acquisition,attributes, uuid)
 
-        if add_default_type:
-            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ASSESSMENT_ENTITY})
-            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ACQUISITION_ENTITY})
+        if uuid is None:
+            # execute default parent class constructor
+            super().__init__(
+                project.graph,
+                pm.QualifiedName(pm.Namespace("niiri", Constants.NIIRI), getUUID()),
+                attributes,
+            )
+        else:
+            super().__init__(project.graph, pm.Identifier(uuid), attributes)
 
-        if assessment_type is not None:
-            self.add_attributes({pm.PROV_TYPE: assessment_type})
-        #carry graph object around
-        self.graph = acquisition.graph
+        project.graph._add_record(self)
 
+        if add_default_type:
+            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_DATAELEMENT})
+        project.add_dataelements(self)
+        self.graph = project.graph
+
+        # list to store acquisition objects associated with this activity
+        self._derivative_objects = []
+        # if constructor is called with a session object then add this acquisition to the session
 
     def __str__(self):
-        return "NIDM-Experiment Generic Assessment Object Class"
+        return "NIDM-Experiment DataElement Class"
```

### Comparing `pynidm-3.9.7/nidm/experiment/CDE.py` & `pynidm-4.0.0/src/nidm/experiment/CDE.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,74 +1,69 @@
-import tempfile
-from urllib.request import urlretrieve
-from nidm.core import Constants
 import hashlib
-from os import path, environ
+from os import environ, path
 import pickle
+import tempfile
 from rdflib import Graph
+from nidm.core import Constants
 import nidm.experiment.Query
-
-
+from nidm.util import urlretrieve
 
 
 def download_cde_files():
     cde_dir = tempfile.gettempdir()
 
     for url in Constants.CDE_FILE_LOCATIONS:
-        urlretrieve( url, "{}/{}".format(cde_dir, url.split('/')[-1] ) )
+        urlretrieve(url, f"{cde_dir}/{url.split('/')[-1]}")
 
     return cde_dir
 
 
 def getCDEs(file_list=None):
-
     if getCDEs.cache:
         return getCDEs.cache
 
     hasher = hashlib.md5()
-    hasher.update(str(file_list).encode('utf-8'))
+    hasher.update(str(file_list).encode("utf-8"))
     h = hasher.hexdigest()
 
-    cache_file_name = tempfile.gettempdir() + "/cde_graph.{}.pickle".format(h)
+    cache_file_name = tempfile.gettempdir() + f"/cde_graph.{h}.pickle"
 
     if path.isfile(cache_file_name):
-        rdf_graph = pickle.load(open(cache_file_name, "rb"))
+        with open(cache_file_name, "rb") as fp:
+            rdf_graph = pickle.load(fp)
         getCDEs.cache = rdf_graph
         return rdf_graph
 
     rdf_graph = Graph()
 
     if not file_list:
-
-        cde_dir = ''
+        cde_dir = ""
         if "CDE_DIR" in environ:
-            cde_dir = environ['CDE_DIR']
+            cde_dir = environ["CDE_DIR"]
 
-        if (not cde_dir) and (path.isfile( '/opt/project/nidm/core/cde_dir/ants_cde.ttl' )):
-            cde_dir = '/opt/project/nidm/core/cde_dir'
+        if (not cde_dir) and (
+            path.isfile("/opt/project/nidm/core/cde_dir/ants_cde.ttl")
+        ):
+            cde_dir = "/opt/project/nidm/core/cde_dir"
 
-        if (not cde_dir):
+        if not cde_dir:
             cde_dir = download_cde_files()
 
-        file_list = [ ]
-        for f in ['ants_cde.ttl', 'fs_cde.ttl', 'fsl_cde.ttl']:
-            fname = '{}/{}'.format(cde_dir, f)
-            if path.isfile( fname ):
-                file_list.append( fname )
-
-
+        file_list = []
+        for f in ["ants_cde.ttl", "fs_cde.ttl", "fsl_cde.ttl"]:
+            fname = f"{cde_dir}/{f}"
+            if path.isfile(fname):
+                file_list.append(fname)
 
     for fname in file_list:
         if path.isfile(fname):
             cde_graph = nidm.experiment.Query.OpenGraph(fname)
             rdf_graph = rdf_graph + cde_graph
 
-
-
-
-    cache_file = open(cache_file_name , 'wb')
-    pickle.dump(rdf_graph, cache_file)
-    cache_file.close()
+    with open(cache_file_name, "wb") as cache_file:
+        pickle.dump(rdf_graph, cache_file)
 
     getCDEs.cache = rdf_graph
     return rdf_graph
-getCDEs.cache = None
+
+
+getCDEs.cache = None
```

### Comparing `pynidm-3.9.7/nidm/experiment/Core.py` & `pynidm-4.0.0/src/nidm/experiment/Core.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,104 +1,95 @@
-import os,sys
-import uuid
-
-from rdflib import Namespace
-from rdflib.namespace import XSD
-import types 
-import graphviz
-from rdflib import Graph, RDF, URIRef, util, plugin
-from rdflib.serializer import Serializer
-
-
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-from ..core import Constants
-import prov.model as pm
-from prov.dot import prov_to_dot
-from io import StringIO
 from collections import OrderedDict
+from io import StringIO
 import json
+import random
 import re
 import string
-import random
-
+import uuid
+from prov.dot import prov_to_dot
+import prov.model as pm
 from pydot import Edge
+from rdflib import RDF, Graph, URIRef
+from ..core import Constants
+
 
 def getUUID():
     uid = str(uuid.uuid1())
     # added to address some weird bug in rdflib where if the uuid starts with a number, everything up until the first
     # alapha character becomes a prefix...
-    if not (re.match("^[a-fA-F]+.*", uid)):
+    if not re.match("^[a-fA-F]+.*", uid):
         # if first digit is not a character than replace it with a randomly selected hex character (a-f).
         uid_temp = uid
-        randint = random.randint(0,5)
+        randint = random.randint(0, 5)
         uid = string.ascii_lowercase[randint] + uid_temp[1:]
 
     return uid
 
 
-class Core(object):
+class Core:
     """Base-class for NIDM-Experimenent
 
     Typically this class is not instantiated directly.  Instantiate one of the child classes such as
     Project, Session, Acquisition, etec.
 
     @author: David Keator <dbkeator@uci.edu>
     @copyright: University of California, Irvine 2017
 
     """
-    language = 'en'
+
+    language = "en"
+
     def __init__(self):
         """
         Default constructor, loads empty graph and namespaces from NIDM/Scripts/Constants.py
         """
-        #a new instance of NIDMDocument PROV document with namespaces already bound
+        # a new instance of NIDMDocument PROV document with namespaces already bound
         self.graph = Constants.NIDMDocument()
-        #make a local copy of the namespaces
+        # make a local copy of the namespaces
         self.namespaces = Constants.namespaces
         # storage for uuid
         self._uuid = None
 
-    #class constructor with user-supplied PROV document/graph, namespaces from Constants.py
+    # class constructor with user-supplied PROV document/graph, namespaces from Constants.py
     @classmethod
-    def withGraph(self,graph):
+    def withGraph(cls, graph):
         """
         Alternate constructor, loads user-supplied graph and default namespaces from NIDM/Scripts/Constants.py
 
         Keyword arguments:
             graph -- an rdflib.Graph object
         """
-        self.graph = graph
-        self.namespaces = {}
-        #bind namespaces to self.graph
-        for name, namespace in self.namespaces.items():
-            self.graph.add_namespace(name, namespace)
+        cls.graph = graph
+        cls.namespaces = {}
+        # bind namespaces to cls.graph
+        for name, namespace in cls.namespaces.items():
+            cls.graph.add_namespace(name, namespace)
 
-    #class constructor with user-supplied graph and namespaces
+    # class constructor with user-supplied graph and namespaces
     @classmethod
-    def withGraphAndNamespaces(self,graph,namespaces):
+    def withGraphAndNamespaces(cls, graph, namespaces):
         """
         Alternate constructor, loads user-supplied graph and binds user-supplied namespaces
 
         :param graph: an rdflib.Graph object
         :param namespaces: python dictionary {namespace_identifier, URL}
         :return: none
         """
 
-
-        self.graph = graph
-        self.namespaces = namespaces
-        #bind namespaces to self.graph
-        for name, namespace in self.namespaces.items():
-            self.graph.add_namespace(name, namespace)
+        cls.graph = graph
+        cls.namespaces = namespaces
+        # bind namespaces to cls.graph
+        for name, namespace in cls.namespaces.items():
+            cls.graph.add_namespace(name, namespace)
 
     def get_uuid(self):
-        '''
+        """
         returns UUID of self
         :return:
-        '''
+        """
         return self._uuid
 
     def getGraph(self):
         """
         Returns rdflib.Graph object
         """
         return self.graph
@@ -112,463 +103,508 @@
     def addNamespace(self, prefix, uri):
         """
         Adds namespace to self.graph
         :param prefix: namespace prefix
         :param uri: namespace URI
         :return: none
         """
-        self.graph.add_namespace(prefix,uri)
+        self.graph.add_namespace(prefix, uri)
 
     def checkNamespacePrefix(self, prefix):
         """
         Checks if namespace prefix already exists in self.graph
         :param prefix: namespace identifier
         :return: True if prefix exists, False if not
         """
-        #check if prefix already exists
-        if prefix in self.graph._namespaces.keys():
-            #prefix already exists
-            return True
-        else:
-            return False
+        # check if prefix already exists
+        return bool(prefix in self.graph._namespaces)
 
     def safe_string(self, string):
-        return string.strip().replace(" ","_").replace("-", "_").replace(",", "_").replace("(", "_").replace(")","_")\
-            .replace("'","_").replace("/", "_").replace("#","num")
-
+        return (
+            string.strip()
+            .replace(" ", "_")
+            .replace("-", "_")
+            .replace(",", "_")
+            .replace("(", "_")
+            .replace(")", "_")
+            .replace("'", "_")
+            .replace("/", "_")
+            .replace("#", "num")
+        )
 
-
-    def getDataType(self,var):
+    def getDataType(self, var):
         if type(var) is int:
             return pm.XSD_INTEGER
         elif type(var) is float:
             return pm.XSD_FLOAT
-        elif (type(var) is str):
+        elif type(var) is str:
             return pm.XSD_STRING
-        elif (type(var) is list):
+        elif type(var) is list:
             return list
         else:
             print("datatype not found...")
             return None
-    def add_person(self,uuid=None,attributes=None,add_default_type=True):
+
+    def add_person(self, uuid=None, attributes=None, add_default_type=True):
         """
         Simply adds prov:agent to graph and returns object
         :param role:
         :param attributes:
         :return:
         """
 
-        if (uuid != None):
-            #add Person agent with existing uuid
-            person = self.graph.agent(Constants.namespaces["niiri"][uuid],other_attributes=attributes)
+        if uuid is not None:
+            # add Person agent with existing uuid
+            person = self.graph.agent(
+                Constants.namespaces["niiri"][uuid], other_attributes=attributes
+            )
         else:
-            #add Person agent
-            person = self.graph.agent(Constants.namespaces["niiri"][getUUID()],other_attributes=attributes)
+            # add Person agent
+            person = self.graph.agent(
+                Constants.namespaces["niiri"][getUUID()], other_attributes=attributes
+            )
 
         if add_default_type:
-            #add minimal attributes to person
-            person.add_attributes({pm.PROV_TYPE: pm.PROV['Person']})
+            # add minimal attributes to person
+            person.add_attributes({pm.PROV_TYPE: pm.PROV["Person"]})
 
-        #connect self to person serving as role
-        #if(isinstance(self,pm.ProvActivity)):
+        # connect self to person serving as role
+        # if(isinstance(self,pm.ProvActivity)):
         #    self.wasAssociatedWith(person)
-        #elif(isinstance(self,pm.ProvEntity)):
+        # elif(isinstance(self,pm.ProvEntity)):
         #    self.wasAttributedTo(person)
 
         return person
 
-    def add_qualified_association(self,person,role,plan=None, attributes=None):
+    def add_qualified_association(
+        self, person, role, plan=None, attributes=None  # noqa: U100
+    ):
         """
         Adds a qualified association to self object
         :param person: prov:agent to associated
         :param role: prov:hadRole to associate
         :param plan: optional prov:hadPlan to associate
         :param attributes: optional attributes to add to qualified association
         :return: association
         """
 
-        #connect self to person serving as role
-        #WIP this doesn't work for subclasses as they don't have the pm.ProvActivity type
-        #Might be able to use the following and look into the tuples but for now skip this check
-        #import inspect
-        #class_tree = inspect.getclasstree([self.__class__])
-
-        #if(isinstance(self, pm.ProvActivity)):
-
-        #associate person with activity for qualified association
-        assoc = self.graph.association(agent=person, activity=self, other_attributes={pm.PROV_ROLE:role})
+        # connect self to person serving as role
+        # WIP this doesn't work for subclasses as they don't have the pm.ProvActivity type
+        # Might be able to use the following and look into the tuples but for now skip this check
+        # import inspect
+        # class_tree = inspect.getclasstree([self.__class__])
+
+        # if(isinstance(self, pm.ProvActivity)):
+
+        # associate person with activity for qualified association
+        assoc = self.graph.association(
+            agent=person, activity=self, other_attributes={pm.PROV_ROLE: role}
+        )
 
-        #add wasAssociatedWith association
-        #self.wasAssociatedWith(person)
+        # add wasAssociatedWith association
+        # self.wasAssociatedWith(person)
 
         return assoc
 
-    def addLiteralAttribute(self, namespace_prefix, term, object, namespace_uri=None):
+    def addLiteralAttribute(
+        self, namespace_prefix, term, object, namespace_uri=None  # noqa: A002
+    ):
         """
         Adds generic literal and inserts into the graph
         :param namespace_prefix: namespace prefix
         :param pred_term: predidate term to associate with tuple
         :param object: literal to add as object of tuple
         :param namespace_uri: If namespace_prefix isn't one already used then use this optional argument to define
         :return: none
         """
-        #figure out datatype of literal
+        # figure out datatype of literal
         datatype = self.getDataType(object)
-        #check if namespace prefix already exists in graph
+        # check if namespace prefix already exists in graph
         if not self.checkNamespacePrefix(namespace_prefix):
-            #if so, use URI
-            #namespace_uri = self.namespaces[namespace_prefix]
-        #else: #add namespace_uri + prefix to graph
-            if (namespace_uri == None):
-                raise TypeError("Namespace_uri argument must be defined for new namespaces")
+            # if so, use URI
+            # namespace_uri = self.namespaces[namespace_prefix]
+            # else: #add namespace_uri + prefix to graph
+            if namespace_uri is None:
+                raise TypeError(
+                    "Namespace_uri argument must be defined for new namespaces"
+                )
             else:
-                self.addNamespace(namespace_prefix,namespace_uri)
+                self.addNamespace(namespace_prefix, namespace_uri)
 
-        #figure out if predicate namespace is defined, if not, return predicate namespace error
+        # figure out if predicate namespace is defined, if not, return predicate namespace error
         try:
-            if (datatype != None):
-                self.add_attributes({str(namespace_prefix + ':' + term): pm.Literal(object, datatype=datatype)})
+            if datatype is not None:
+                self.add_attributes(
+                    {
+                        str(namespace_prefix + ":" + term): pm.Literal(
+                            object, datatype=datatype
+                        )
+                    }
+                )
             else:
-                self.add_attributes({str(namespace_prefix + ':' + term): pm.Literal(object)})
+                self.add_attributes(
+                    {str(namespace_prefix + ":" + term): pm.Literal(object)}
+                )
         except KeyError as e:
-            print("\nPredicate namespace identifier \" %s \" not found! \n" % (str(e).split("'")[1]))
-            print("Use addNamespace method to add namespace before adding literal attribute \n")
+            print(
+                '\nPredicate namespace identifier "',
+                str(e).split("'")[1],
+                '" not found! \n',
+            )
+            print(
+                "Use addNamespace method to add namespace before adding literal attribute \n"
+            )
             print("No attribute has been added \n")
-    def addAttributesWithNamespaces(self,id,attributes):
+
+    def addAttributesWithNamespaces(self, id, attributes):  # noqa: A002
         """
         Adds generic attributes in bulk to object [id] and inserts into the graph
 
         :param id: subject identifier/URI
         :param attributes: List of dictionaries with keys prefix, uri, term, value} \
         example: [ {uri:"http://ncitt.ncit.nih.gov/", prefix:"ncit", term:"age", value:15},
                    {uri:"http://ncitt.ncit.nih.gov/", prefix:"ncit", term:"gender", value:"M"}]
         :return: TypeError if namespace prefix already exists in graph but URI is different
         """
-        #iterate through list of attributes
-        for tuple in attributes:
-            #check if namespace prefix already exists in graph
-            if self.checkNamespacePrefix(tuple['prefix']):
-                #checking if existing prefix maps to same namespaceURI, if so use it, if not then raise error
-                if (self.namespaces[tuple['prefix']] != tuple['uri']):
-                    raise TypeError("Namespace prefix: " + tuple['prefix'] + "already exists in document")
-
-            else: #add tuple to graph
-                self.addNamespace(tuple['prefix'], tuple['uri'])
-
-            #figure out datatype of literal
-            datatype = self.getDataType(tuple['value'])
-            if (datatype != None):
-                id.add_attributes({self.namespaces[tuple['prefix']][tuple['term']]:pm.Literal(tuple['value'],datatype=datatype)})
+        # iterate through list of attributes
+        for tple in attributes:
+            # check if namespace prefix already exists in graph
+            if self.checkNamespacePrefix(tple["prefix"]):
+                # checking if existing prefix maps to same namespaceURI, if so use it, if not then raise error
+                if self.namespaces[tple["prefix"]] != tple["uri"]:
+                    raise TypeError(
+                        "Namespace prefix: "
+                        + tple["prefix"]
+                        + "already exists in document"
+                    )
+
+            else:  # add tuple to graph
+                self.addNamespace(tple["prefix"], tple["uri"])
+
+            # figure out datatype of literal
+            datatype = self.getDataType(tple["value"])
+            if datatype is not None:
+                id.add_attributes(
+                    {
+                        self.namespaces[tple["prefix"]][tple["term"]]: pm.Literal(
+                            tple["value"], datatype=datatype
+                        )
+                    }
+                )
             else:
-                id.add_attributes({self.namespaces[tuple['prefix']][tuple['term']]:pm.Literal(tuple['value'])})
+                id.add_attributes(
+                    {
+                        self.namespaces[tple["prefix"]][tple["term"]]: pm.Literal(
+                            tple["value"]
+                        )
+                    }
+                )
 
-    def addAttributes(self,id,attributes):
+    def addAttributes(self, id, attributes):  # noqa: A002
         """
         Adds generic attributes in bulk to object [id] and inserts into the graph
 
         :param id: subject identifier/URI
         :param attributes: Dictionary with keys as prefix:term and value of attribute} \
         example: {"ncit:age":15,"ncit:gender":"M", Constants.NIDM_FAMILY_NAME:"Keator"}
         :return: TypeError if namespace prefix does not exist in graph
         """
-        #iterate through attributes
+        # iterate through attributes
         for key in attributes.keys():
-            #is the key already mapped to a URL (i.e. using one of the constants from Constants.py) or is it in prefix:term form?
-            #if not validators.url(key):
-                #check if namespace prefix already exists in graph or #if we're using a Constants reference
-            if (not self.checkNamespacePrefix(key.split(':')[0])):
-                raise TypeError("Namespace prefix " + key + " not in graph, use addAttributesWithNamespaces or manually add!")
-            #figure out datatype of literal
+            # is the key already mapped to a URL (i.e. using one of the constants from Constants.py) or is it in prefix:term form?
+            # if not validators.url(key):
+            # check if namespace prefix already exists in graph or #if we're using a Constants reference
+            if not self.checkNamespacePrefix(key.split(":")[0]):
+                raise TypeError(
+                    "Namespace prefix "
+                    + key
+                    + " not in graph, use addAttributesWithNamespaces or manually add!"
+                )
+            # figure out datatype of literal
             datatype = self.getDataType(attributes[key])
-            #if (not validators.url(key)):
-                #we must be using the prefix:term form instead of a constant directly
+            # if (not validators.url(key)):
+            # we must be using the prefix:term form instead of a constant directly
 
             #    if (datatype != None):
             #        id.add_attributes({self.namespaces[key.split(':')[0]][key.split(':')[1]]:Literal(attributes[key],datatype=datatype)})
             #    else:
             #        id.add_attributes({self.namespaces[key.split(':')[0]][key.split(':')[1]]:Literal(attributes[key])})
-            #else:
-                #we're using the Constants form
-            if (datatype != None):
-                id.add_attributes({key:pm.Literal(attributes[key],datatype=datatype)})
+            # else:
+            # we're using the Constants form
+            if datatype is not None:
+                id.add_attributes({key: pm.Literal(attributes[key], datatype=datatype)})
             else:
-                id.add_attributes({key:pm.Literal(attributes[key])})
+                id.add_attributes({key: pm.Literal(attributes[key])})
 
-    def get_metadata_dict(self,NIDM_TYPE):
+    def get_metadata_dict(self, NIDM_TYPE):
         """
         This function converts metadata to a dictionary using uris as keys
         :param NIDM_TYPE: a prov qualified name type (e.g. Constants.NIDM_PROJECT, Constants.NIDM_SESSION, etc.)
         :return: dictionary object containing metadata
 
         """
-        #create empty project_metadata json object
+        # create empty project_metadata json object
         metadata = {}
 
-        #use RDFLib here for temporary graph making query easier
+        # use RDFLib here for temporary graph making query easier
         rdf_graph = Graph()
 
-        rdf_graph_parse = rdf_graph.parse(source=StringIO(self.serializeTurtle()),format='turtle')
-
-        #get subject uri for object
-
-
-        uri=None
-        for s in rdf_graph_parse.subjects(predicate=RDF.type,object=URIRef(NIDM_TYPE.uri)):
-            uri=s
+        rdf_graph_parse = rdf_graph.parse(
+            source=StringIO(self.serializeTurtle()), format="turtle"
+        )
+
+        # get subject uri for object
+
+        uri = None
+        for s in rdf_graph_parse.subjects(
+            predicate=RDF.type, object=URIRef(NIDM_TYPE.uri)
+        ):
+            uri = s
 
         if uri is None:
-            print("Error finding %s in NIDM-Exp Graph" %NIDM_TYPE)
+            print(f"Error finding {NIDM_TYPE} in NIDM-Exp Graph")
             return metadata
 
-        #Cycle through metadata and add to json
+        # Cycle through metadata and add to json
         for predicate, objects in rdf_graph.predicate_objects(subject=uri):
             metadata[str(predicate)] = str(objects)
 
         return metadata
 
-    def     serializeTurtle(self):
+    def serializeTurtle(self):
         """
         Serializes graph to Turtle format
         :return: text of serialized graph in Turtle format
         """
-        return self.graph.serialize(None, format='rdf', rdf_format='ttl')
+        return self.graph.serialize(None, format="rdf", rdf_format="ttl")
 
     def serializeTrig(self, identifier=None):
-
         """
         Serializes graph to Turtle format
         :param identifier: Optional identifier to use for graph serialization
         :return: text of serialized graph in Turtle format
         """
         if identifier is not None:
             rdf_graph = Graph(identifier=identifier)
-            rdf_graph.parse(source=StringIO(self.serializeTurtle()),format='turtle')
+            rdf_graph.parse(source=StringIO(self.serializeTurtle()), format="turtle")
         else:
             rdf_graph = Graph()
-            rdf_graph.parse(source=StringIO(self.serializeTurtle()),format='turtle')
-
-        #return rdf_graph.serialize(format='trig').decode('ASCII')
-        return rdf_graph.serialize(format='trig')
+            rdf_graph.parse(source=StringIO(self.serializeTurtle()), format="turtle")
 
+        # return rdf_graph.serialize(format='trig').decode('ASCII')
+        return rdf_graph.serialize(format="trig")
 
     def serializeJSONLD(self):
         """
         Serializes graph to JSON-LD format
         :return: text of serialized graph in JSON-LD format
         """
-        #workaround to get JSONLD from RDFLib...
+        # workaround to get JSONLD from RDFLib...
         rdf_graph = Graph()
-        #rdf_graph_parse = rdf_graph.parse(source=StringIO(self.serializeTurtle()),format='turtle')
-        rdf_graph_parse = rdf_graph.parse(source=StringIO(self.graph.serialize(None, format='rdf', rdf_format='ttl')),format='turtle')
-
-
+        # rdf_graph_parse = rdf_graph.parse(source=StringIO(self.serializeTurtle()),format='turtle')
+        rdf_graph_parse = rdf_graph.parse(
+            source=StringIO(self.graph.serialize(None, format="rdf", rdf_format="ttl")),
+            format="turtle",
+        )
 
         # WIP: currently this creates a default JSON-LD context from Constants.py and not in the correct way from the
         # NIDM-E OWL files that that will be the next iteration
         context1 = self.createDefaultJSONLDcontext()
         # This part adds to the context any prefixes in an existing NIDM-E file that might have been added by a user
         # and isn't covered by the default namespaces / constants in Constants.py
         context2 = self.prefix_to_context()
         context = dict(context1, **context2)
 
         # WIP: LOOK AT https://github.com/satra/nidm-jsonld
-        #return rdf_graph_parse.serialize(format='json-ld', context=context, indent=4).decode('ASCII')
-        #g=rdf_graph_parse.serialize(format='json-ld', indent=4).decode('ASCII')
-        g = rdf_graph_parse.serialize(format='json-ld', indent=4)
-
+        # return rdf_graph_parse.serialize(format='json-ld', context=context, indent=4).decode('ASCII')
+        # g=rdf_graph_parse.serialize(format='json-ld', indent=4).decode('ASCII')
+        g = rdf_graph_parse.serialize(format="json-ld", indent=4)
 
         import pyld as ld
 
-        return json.dumps(ld.jsonld.compact(json.loads(g), context),indent=4)
+        return json.dumps(ld.jsonld.compact(json.loads(g), context), indent=4)
 
     def createDefaultJSONLDcontext(self):
-        '''
+        """
         This function returns a context dictionary for NIDM-E JSON serializations
         :return: context dictionary
-        '''
+        """
 
-        from nidm.experiment.Utils import load_nidm_owl_files
         from nidm.core.Constants import namespaces
+        from nidm.experiment.Utils import load_nidm_owl_files
 
-        #load current OWL files
-        term_graph=load_nidm_owl_files()
-
-        context={}
+        # load current OWL files
+        load_nidm_owl_files()
 
+        context = {}
 
-        context['@version'] = 1.1
-        context['records'] = {}
-        context['records']['@container'] = "@type"
-        context['records']['@id'] = "@graph"
+        context["@version"] = 1.1
+        context["records"] = {}
+        context["records"]["@container"] = "@type"
+        context["records"]["@id"] = "@graph"
 
-        #load Constants.namespaces
+        # load Constants.namespaces
         context.update(Constants.namespaces)
 
-        context.update ({
-            "xsd": {"@type": "@id","@id":"http://www.w3.org/2001/XMLSchema#"},
-            "prov": {"@type": "@id","@id":"http://www.w3.org/ns/prov#"},
-            "agent": { "@type": "@id", "@id": "prov:agent" },
-            "entity": { "@type": "@id", "@id": "prov:entity" },
-            "activity": { "@type": "@id", "@id": "prov:activity" },
-            "hadPlan": { "@type": "@id", "@id": "prov:hadPlan" },
-            "hadRole": { "@type": "@id", "@id": "prov:hadRole" },
-            "wasAttributedTo": { "@type": "@id", "@id": "prov:wasAttributedTo" },
-            "association": { "@type": "@id", "@id": "prov:qualifiedAssociation" },
-            "usage": { "@type": "@id", "@id": "prov:qualifiedUsage" },
-            "generation": { "@type": "@id", "@id": "prov:qualifiedGeneration" },
-            "startedAtTime": { "@type": "xsd:dateTime", "@id": "prov:startedAtTime" },
-            "endedAtTime": { "@type": "xsd:dateTime", "@id": "prov:endedAtTime" },
-        })
-
-
-        #add namespaces from Constants.namespaces
-        for key,value in namespaces.items():
-            #context['@context'][key] = value
+        context.update(
+            {
+                "xsd": {"@type": "@id", "@id": "http://www.w3.org/2001/XMLSchema#"},
+                "prov": {"@type": "@id", "@id": "http://www.w3.org/ns/prov#"},
+                "agent": {"@type": "@id", "@id": "prov:agent"},
+                "entity": {"@type": "@id", "@id": "prov:entity"},
+                "activity": {"@type": "@id", "@id": "prov:activity"},
+                "hadPlan": {"@type": "@id", "@id": "prov:hadPlan"},
+                "hadRole": {"@type": "@id", "@id": "prov:hadRole"},
+                "wasAttributedTo": {"@type": "@id", "@id": "prov:wasAttributedTo"},
+                "association": {"@type": "@id", "@id": "prov:qualifiedAssociation"},
+                "usage": {"@type": "@id", "@id": "prov:qualifiedUsage"},
+                "generation": {"@type": "@id", "@id": "prov:qualifiedGeneration"},
+                "startedAtTime": {"@type": "xsd:dateTime", "@id": "prov:startedAtTime"},
+                "endedAtTime": {"@type": "xsd:dateTime", "@id": "prov:endedAtTime"},
+            }
+        )
+
+        # add namespaces from Constants.namespaces
+        for key, value in namespaces.items():
+            # context['@context'][key] = value
             context[key] = value
 
-        #add terms from Constants.nidm_experiment_terms
+        # add terms from Constants.nidm_experiment_terms
         for term in Constants.nidm_experiment_terms:
-            #context['@context'][term.localpart] = term.uri
+            # context['@context'][term.localpart] = term.uri
             context[term.localpart] = term.uri
 
+        # add prefix's from current document...this accounts for new terms
+        context.update(self.prefix_to_context())
 
-        #add prefix's from current document...this accounts for new terms
-        context.update ( self.prefix_to_context() )
-
-        #WIP
-        #cycle through OWL graph and add terms
+        # WIP
+        # cycle through OWL graph and add terms
         # For anything that has a label
 
-        #for s, o in sorted(term_graph.subject_objects(Constants.RDFS['label'])):
+        # for s, o in sorted(term_graph.subject_objects(Constants.RDFS['label'])):
         #    json_key = str(o)
         #    if '_' in json_key:
         #        json_key = str(o).split('_')[1]
         #    context['@context'][json_key] = OrderedDict()
 
         #    if s in term_graph.ranges:
         #        context['@context'][json_key]['@id'] = str(s)
         #        context['@context'][json_key]['@type'] = next(iter(term_graph.ranges[s]))
         #    else:
         #        context['@context'][json_key] = str(s)
 
         return context
 
-    def save_DotGraph(self,filename,format=None):
+    def save_DotGraph(self, filename, format=None):  # noqa: A002
         dot = prov_to_dot(self.graph)
 
         ISPARTOF = {
-            'label': 'isPartOf',
-            'fontsize': '10.0',
-            'color': 'darkgreen',
-            'fontcolor' : 'darkgreen'
+            "label": "isPartOf",
+            "fontsize": "10.0",
+            "color": "darkgreen",
+            "fontcolor": "darkgreen",
         }
         style = ISPARTOF
 
-
-
-
-
         # query self.graph for Project uuids
-        #use RDFLib here for temporary graph making query easier
+        # use RDFLib here for temporary graph making query easier
         rdf_graph = Graph()
-        rdf_graph = rdf_graph.parse(source=StringIO(self.graph.serialize(None, format='rdf', rdf_format='ttl')),format='turtle')
+        rdf_graph = rdf_graph.parse(
+            source=StringIO(self.graph.serialize(None, format="rdf", rdf_format="ttl")),
+            format="turtle",
+        )
 
-
-        #SPARQL query to get project UUIDs
-        query = '''
+        # SPARQL query to get project UUIDs
+        query = """
         PREFIX nidm:<http://purl.org/nidash/nidm#>
         PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
 
         SELECT distinct ?uuid
         Where {
             {
                 ?uuid rdf:type nidm:Project
             }
 
         }
-        '''
+        """
         qres = rdf_graph.query(query)
         for row in qres:
-            print("project uuid = %s" %row)
+            print(f"project uuid = {row}")
             # parse uuid from project URI
-            #project_uuid = str(row[0]).rsplit('/', 1)[-1]
+            # project_uuid = str(row[0]).rsplit('/', 1)[-1]
             project_uuid = str(row[0])
             # for each Project uuid search dot structure for Project uuid
             project_node = None
-            for key,value in dot.obj_dict['nodes'].items():
+            for key, value in dot.obj_dict["nodes"].items():
                 # get node number in DOT graph for Project
-                if 'URL' in dot.obj_dict['nodes'][key][0]['attributes']:
-                    if project_uuid in str(dot.obj_dict['nodes'][key][0]['attributes']['URL']):
-                        project_node = key
-                        break
+                if project_uuid in str(value[0]["attributes"].get("URL", "")):
+                    project_node = key
+                    break
 
         # for each Session in Project class self.sessions list, find node numbers in DOT graph
 
         for session in self.sessions:
             print(session)
-            for key,value in dot.obj_dict['nodes'].items():
+            for key, value in dot.obj_dict["nodes"].items():
                 # get node number in DOT graph for Project
-                if 'URL' in dot.obj_dict['nodes'][key][0]['attributes']:
-                    if session.identifier.uri in str(dot.obj_dict['nodes'][key][0]['attributes']['URL']):
-                        session_node= key
-                        #print("session node = %s" %key)
-
-                        # add to DOT structure edge between project_node and session_node
-                        dot.add_edge(Edge(session_node, project_node, **style))
-
-
-
-
-                        # for each Acquisition in Session class ._acquisitions list, find node numbers in DOT graph
-                        for acquisition in session.get_acquisitions():
-                            # search through the nodes again to figure out node number for acquisition
-                            for key,value in dot.obj_dict['nodes'].items():
-                                # get node number in DOT graph for Project
-                                if 'URL' in dot.obj_dict['nodes'][key][0]['attributes']:
-                                    if acquisition.identifier.uri in str(dot.obj_dict['nodes'][key][0]['attributes']['URL']):
-                                        acquisition_node = key
-                                        #print("acquisition node = %s" %key)
-
-                                        dot.add_edge(Edge(acquisition_node, session_node, **style))
-
-
-        #add some logic to find nodes with dct:hasPart relation and add those edges to graph...prov_to_dot ignores these
-        if not (format == "None"):
-            dot.write(filename,format=format)
+                if session.identifier.uri in str(value[0]["attributes"].get("URL", "")):
+                    session_node = key
+                    # print(f"session node = {key}")
+
+                    # add to DOT structure edge between project_node and session_node
+                    dot.add_edge(Edge(session_node, project_node, **style))
+
+                    # for each Acquisition in Session class ._acquisitions list, find node numbers in DOT graph
+                    for acquisition in session.get_acquisitions():
+                        # search through the nodes again to figure out node number for acquisition
+                        for key, value in dot.obj_dict["nodes"].items():
+                            # get node number in DOT graph for Project
+                            if acquisition.identifier.uri in str(
+                                value[0]["attributes"].get("URL", "")
+                            ):
+                                acquisition_node = key
+                                # print(f"acquisition node = {key}")
+
+                                dot.add_edge(
+                                    Edge(acquisition_node, session_node, **style)
+                                )
+
+        # add some logic to find nodes with dct:hasPart relation and add those edges to graph...prov_to_dot ignores these
+        if format != "None":
+            dot.write(filename, format=format)
         else:
-            dot.write(filename,format="pdf")
+            dot.write(filename, format="pdf")
 
     def prefix_to_context(self):
-        '''
+        """
         This function returns a context dictionary for JSONLD export from current NIDM-Exp document....
         :return: Context dictionary for JSONLD
-        '''
+        """
 
-        #This sets up basic contexts from namespaces in documents
-        context=OrderedDict()
-        for key,value in self.graph._namespaces.items():
-            #context[key] = {}
-            #context[key]['@type']='@id'
-            #context[key]['@id']= value.uri
+        # This sets up basic contexts from namespaces in documents
+        context = OrderedDict()
+        for key, value in self.graph._namespaces.items():
+            # context[key] = {}
+            # context[key]['@type']='@id'
+            # context[key]['@id']= value.uri
 
-            #context[key]['@type']='@id'
+            # context[key]['@type']='@id'
             if type(value.uri) == str:
-                context[key]= value.uri
+                context[key] = value.uri
             # added for some weird namespaces where key is URIRef and value is Namespace
             # seems to only apply to PROV and NIDM qualified names.
             # has something to do with read_nidm function in Utils and add_metadata_for_subject
             # when it comes across a NIDM or PROV term.
             elif type(key) == URIRef:
                 continue
             else:
-                context[key]= str(value.uri)
-
+                context[key] = str(value.uri)
 
-        #This adds suffix part of namespaces as IDs to make things read easier in JSONLD
-        #for namespace in self.graph.namespaces:
+        # This adds suffix part of namespaces as IDs to make things read easier in JSONLD
+        # for namespace in self.graph.namespaces:
         #    context[namespace.qname()]='@id'
         #    context[namespace.qname()]=namespace.qname().localpart
 
         return context
 
     def __str__(self):
         return "NIDM-Experiment Base Class"
```

### Comparing `pynidm-3.9.7/nidm/experiment/DataElement.py` & `pynidm-4.0.0/src/nidm/experiment/DerivativeObject.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,51 +1,48 @@
-import os, sys
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-import rdflib as rdf
-from ..core import Constants
-from ..experiment import Core
-from ..experiment.Core import getUUID
 import prov.model as pm
+from .Core import Core, getUUID
+from ..core import Constants
+
 
-class DataElement(pm.ProvEntity,Core):
-    """Class for NIDM-Experiment DataElement Objects.
+class DerivativeObject(pm.ProvEntity, Core):
+    """Class for NIDM-Experimenent DerivativeObject-Level Objects.
 
     Default constructor uses empty graph with namespaces added from NIDM/Scripts/Constants.py.
     Additional alternate constructors for user-supplied graphs and default namespaces (i.e. from Constants.py)
     and user-supplied graph and namespaces
 
     @author: David Keator <dbkeator@uci.edu>
     @copyright: University of California, Irvine 2019
 
     """
-    #constructor
-    def __init__(self, project, attributes=None, uuid=None, add_default_type=True):
+
+    # constructor
+    def __init__(self, derivative, attributes=None, uuid=None):
         """
-        Default contructor, creates an acquisition object and links to acquisition activity object
+        Default constructor, creates an derivative object and links to derivative activity object
 
-        :param project: NIDM project to add data element entity to.\
+        :param derivative: a Derivative activity object
         :param attributes: optional attributes to add to entity
         :param uuid: optional uuid...used mostly for reading in existing NIDM document
         :return: none
 
         """
 
         if uuid is None:
-            #execute default parent class constructor
-            super(DataElement,self).__init__(project.graph, pm.QualifiedName(pm.Namespace("niiri",Constants.NIIRI),getUUID()),attributes)
+            # execute default parent class constructor
+            super().__init__(
+                derivative.graph,
+                pm.QualifiedName(pm.Namespace("niiri", Constants.NIIRI), getUUID()),
+                attributes,
+            )
         else:
-            super(DataElement,self).__init__(project.graph,pm.Identifier(uuid),attributes)
-
-        project.graph._add_record(self)
+            super().__init__(derivative.graph, pm.Identifier(uuid), attributes)
 
-        if add_default_type:
-            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_DATAELEMENT})
-        project.add_dataelements(self)
-        self.graph = project.graph
-
-        #list to store acquisition objects associated with this activity
-        self._derivative_objects=[]
-        #if constructor is called with a session object then add this acquisition to the session
+        derivative.graph._add_record(self)
 
+        # carry graph object around
+        self.graph = derivative.graph
+        # create link to acquisition activity
+        derivative.add_derivative_object(self)
 
     def __str__(self):
-        return "NIDM-Experiment DataElement Class"
+        return "NIDM-Experiment DerivativeObject Class"
```

### Comparing `pynidm-3.9.7/nidm/experiment/DemographicsObject.py` & `pynidm-4.0.0/src/nidm/experiment/MRObject.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,45 +1,42 @@
-import os, sys
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-import rdflib as rdf
-from ..core import Constants
-from ..experiment import AcquisitionObject
 import prov.model as pm
+from .AcquisitionObject import AcquisitionObject
+from ..core import Constants
+
 
-class DemographicsObject(AcquisitionObject):
+class MRObject(AcquisitionObject):
     """Class for NIDM-Experimenent MRAcquisitionObject-Level Objects.
 
     Default constructor uses empty graph with namespaces added from NIDM/Scripts/Constants.py.
     Additional alternate constructors for user-supplied graphs and default namespaces (i.e. from Constants.py)
     and user-supplied graph and namespaces
 
     @author: David Keator <dbkeator@uci.edu>
     @copyright: University of California, Irvine 2017
 
     """
-    #constructor
-    def __init__(self, acquisition,attributes=None, uuid=None, add_default_type=True):
+
+    # constructor
+    def __init__(self, acquisition, attributes=None, uuid=None, add_default_type=True):
         """
-        Default contructor, creates an acquisition object and links to acquisition activity object
+        Default constructor, creates an acquisition object and links to acquisition activity object
 
-        :param acquisition: a Aquisition activity object
+        :param acquisition: a Acquisition activity object
         :param attributes: optional attributes to add to entity
         :param uuid: optional uuid...used mostly for reading in existing NIDM document
         :return: none
 
         """
-        #execute default parent class constructor
-          #execute default parent class constructor
-        super(DemographicsObject,self).__init__(acquisition,attributes, uuid)
-
+        # execute default parent class constructor
+        super().__init__(acquisition, attributes, uuid)
 
         if add_default_type:
-            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ASSESSMENT_ENTITY})
             self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ACQUISITION_ENTITY})
-            self.add_attributes({Constants.NIDM_ASSESSMENT_USAGE_TYPE: Constants.NIDM_DEMOGRAPHICS_ENTITY})
+            self.add_attributes(
+                {Constants.NIDM_ACQUISITION_MODALITY: Constants.NIDM_MRI}
+            )
 
-        #carry graph object around
+        # carry graph object around
         self.graph = acquisition.graph
 
-
     def __str__(self):
-        return "NIDM-Experiment Demographics Object Class"
+        return "NIDM-Experiment MRI Object Class"
```

### Comparing `pynidm-3.9.7/nidm/experiment/Derivative.py` & `pynidm-4.0.0/src/nidm/experiment/Derivative.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,77 +1,78 @@
-import rdflib as rdf
-import os, sys
-
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-from ..core import Constants
-from ..experiment import Core
-from ..experiment.Core import getUUID
 import prov.model as pm
+from .Core import Core, getUUID
+from ..core import Constants
 
-class Derivative(pm.ProvActivity,Core):
+
+class Derivative(pm.ProvActivity, Core):
     """
     Class for NIDM-Experimenent Derivative Objects.
 
     Default constructor uses empty graph with namespaces added from NIDM/Scripts/Constants.py.
     Additional alternate constructors for user-supplied graphs and default namespaces (i.e. from Constants.py)
     and user-supplied graph and namespaces
 
     @author: David Keator <dbkeator@uci.edu>
     @copyright: University of California, Irvine 2017
 
     """
-    #constructor
+
+    # constructor
     def __init__(self, project, attributes=None, uuid=None):
         """
-        Default contructor, creates a derivative activity
+        Default constructor, creates a derivative activity
 
         :param uuid: optional uuid...used mostly for reading in existing NIDM document
         :param attributes: optional dictionary of attributes to add qname:value
 
         """
         if uuid is None:
             self._uuid = getUUID()
 
-            #execute default parent class constructor
-            super(Derivative,self).__init__(project.graph, pm.QualifiedName(pm.Namespace("niiri",Constants.NIIRI),self.get_uuid()),attributes)
+            # execute default parent class constructor
+            super().__init__(
+                project.graph,
+                pm.QualifiedName(
+                    pm.Namespace("niiri", Constants.NIIRI), self.get_uuid()
+                ),
+                attributes,
+            )
         else:
             self._uuid = uuid
-            super(Derivative,self).__init__(project.graph, pm.Identifier(uuid),attributes)
+            super().__init__(project.graph, pm.Identifier(uuid), attributes)
 
         project.graph._add_record(self)
 
-        #list to store acquisition objects associated with this activity
-        self._derivative_objects=[]
-        #if constructor is called with a session object then add this acquisition to the session
+        # list to store acquisition objects associated with this activity
+        self._derivative_objects = []
+        # if constructor is called with a session object then add this acquisition to the session
 
-        #carry graph object around
+        # carry graph object around
         self.graph = project.graph
 
         project.add_derivatives(self)
 
-
-    def add_derivative_object(self,derivative_object):
+    def add_derivative_object(self, derivative_object):
         """
         Adds derivative objects to derivative activity, creating links and adding reference to derivatives list
 
         :param derivative_object: object of type "DerivativeObject" from nidm API
 
         """
-        #add derivative object to self._derivatives list
+        # add derivative object to self._derivatives list
         self._derivative_objects.extend([derivative_object])
-        #create links in graph
-        self.graph.wasGeneratedBy(derivative_object,self)
+        # create links in graph
+        self.graph.wasGeneratedBy(derivative_object, self)
+
     def get_derivative_objects(self):
         return self._derivative_objects
-    def derivative_object_exists(self,uuid):
-        '''
+
+    def derivative_object_exists(self, uuid):
+        """
         Checks whether uuid is a registered derivative object
         :param uuid: full uuid of derivative object
         :return: True if exists, False otherwise
-        '''
-        if uuid in self._derivative_objects:
-            return True
-        else:
-            return False
+        """
+        return bool(uuid in self._derivative_objects)
 
     def __str__(self):
         return "NIDM-Experiment Derivative Activity Class"
```

### Comparing `pynidm-3.9.7/nidm/experiment/MRAcquisition.py` & `pynidm-4.0.0/src/nidm/experiment/AssessmentObject.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,40 +1,50 @@
-import os, sys
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-import rdflib as rdf
-from ..experiment import Acquisition
-from ..core import Constants
 import prov.model as pm
+from .AcquisitionObject import AcquisitionObject
+from ..core import Constants
 
-class MRAcquisition(Acquisition):
-    """
-        Default contructor, creates a session activity and links to project object
 
-        :param session: a session object
+class AssessmentObject(AcquisitionObject):
+    """Class for NIDM-Experimenent generic AssessmentAcquisitionObject-Level Objects.
+
+    Default constructor uses empty graph with namespaces added from NIDM/Scripts/Constants.py.
+    Additional alternate constructors for user-supplied graphs and default namespaces (i.e. from Constants.py)
+    and user-supplied graph and namespaces
+
+    @author: David Keator <dbkeator@uci.edu>
+    @copyright: University of California, Irvine 2017
 
     """
 
-    #constructor
-    def __init__(self, session,attributes=None, uuid=None, add_default_type=True):
+    # constructor
+    def __init__(
+        self,
+        acquisition,
+        assessment_type=None,
+        attributes=None,
+        uuid=None,
+        add_default_type=True,
+    ):
         """
-        Default contructor, creates an acquisition object and links to acquisition activity object
+        Default constructor, creates an acquisition object and links to acquisition activity object
 
-        :param session: a session object
+        :param acquisition: a Acquisition activity object
+        :param assessment_type: optional qualified name of assessment type (e.g. pm.QualifiedName(pm.Namespace("nidm",Constants.NIDM),"PositiveAndNegativeSyndromeScale"))
         :param attributes: optional attributes to add to entity
         :param uuid: optional uuid...used mostly for reading in existing NIDM document
         :return: none
 
         """
-        #execute default parent class constructor
-          #execute default parent class constructor
-        super(MRAcquisition,self).__init__(session,attributes,uuid)
-        #acquisition.graph._add_record(self)
+        # execute default parent class constructor
+        super().__init__(acquisition, attributes, uuid)
 
         if add_default_type:
-            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ACQUISITION_ACTIVITY})
-
-        #carry graph object around
-        self.graph = session.graph
+            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ASSESSMENT_ENTITY})
+            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ACQUISITION_ENTITY})
 
+        if assessment_type is not None:
+            self.add_attributes({pm.PROV_TYPE: assessment_type})
+        # carry graph object around
+        self.graph = acquisition.graph
 
     def __str__(self):
-        return "NIDM-Experiment MRI Acquisition Class"
+        return "NIDM-Experiment Generic Assessment Object Class"
```

### Comparing `pynidm-3.9.7/nidm/experiment/Navigate.py` & `pynidm-4.0.0/src/nidm/experiment/Navigate.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,317 +1,440 @@
-from nidm.core import Constants
-from nidm.experiment.Query import OpenGraph, URITail, trimWellKnownURIPrefix, getDataTypeInfo, ACQUISITION_MODALITY, \
-    IMAGE_CONTRAST_TYPE, IMAGE_USAGE_TYPE, TASK, expandUUID, matchPrefix
-from rdflib import Graph, RDF, URIRef, util, term, Literal
-import functools
 import collections
+import functools
+from rdflib import URIRef
+from nidm.core import Constants
 import nidm.experiment.CDE
+from nidm.experiment.Query import (
+    ACQUISITION_MODALITY,
+    IMAGE_CONTRAST_TYPE,
+    IMAGE_USAGE_TYPE,
+    TASK,
+    OpenGraph,
+    URITail,
+    expandUUID,
+    getDataTypeInfo,
+    matchPrefix,
+    trimWellKnownURIPrefix,
+)
 from nidm.experiment.Utils import validate_uuid
 
+isa = URIRef("http://www.w3.org/1999/02/22-rdf-syntax-ns#type")
+isPartOf = Constants.DCT["isPartOf"]
+ValueType = collections.namedtuple(
+    "ValueType",
+    [
+        "value",
+        "label",
+        "datumType",
+        "hasUnit",
+        "isAbout",
+        "measureOf",
+        "hasLaterality",
+        "dataElement",
+        "description",
+        "subject",
+        "project",
+        "sourceVariable",
+    ],
+)
+ActivityData = collections.namedtuple("ActivityData", ["category", "uuid", "data"])
+QUERY_CACHE_SIZE = 0
+BIG_CACHE_SIZE = 0
+
+
+def makeValueType(
+    value=None,
+    label=None,
+    datumType=None,
+    hasUnit=None,
+    isAbout=None,
+    measureOf=None,
+    hasLaterality=None,
+    dataElement=None,
+    description=None,
+    subject=None,
+    project=None,
+    source_variable=None,
+):
+    return ValueType(
+        str(value),
+        str(label),
+        str(datumType),
+        str(hasUnit),
+        str(isAbout),
+        str(measureOf),
+        str(hasLaterality),
+        str(dataElement),
+        str(description),
+        str(subject),
+        str(project),
+        str(source_variable),
+    )
 
-isa = URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')
-isPartOf = Constants.DCT['isPartOf']
-ValueType = collections.namedtuple('ValueType',
-                                   ['value', 'label', 'datumType', 'hasUnit', 'isAbout', 'measureOf', 'hasLaterality', 'dataElement', 'description', 'subject', 'project', 'sourceVariable'])
-ActivityData = collections.namedtuple('ActivityData', ['category', 'uuid', 'data'])
-QUERY_CACHE_SIZE=0
-BIG_CACHE_SIZE=0
-
-def makeValueType(value=None, label=None, datumType=None, hasUnit=None, isAbout=None, measureOf=None, hasLaterality=None, dataElement=None, description=None, subject=None, project=None, source_variable=None):
-    return ValueType(str(value), str(label), str(datumType), str(hasUnit), str(isAbout), str(measureOf), str(hasLaterality), str(dataElement), str(description), str(subject), str(project), str(source_variable))
 
 def makeValueTypeFromDataTypeInfo(value, data_type_info_tuple):
-
     if not data_type_info_tuple:
         data_type_info_tuple = {}
 
-    for key in ['label', 'datumType', 'hasUnit', 'isAbout', 'measureOf', 'hasLaterality', 'dataElement', 'description', 'subject', 'project', 'source_variable']:
-        if not key in data_type_info_tuple:
+    for key in [
+        "label",
+        "datumType",
+        "hasUnit",
+        "isAbout",
+        "measureOf",
+        "hasLaterality",
+        "dataElement",
+        "description",
+        "subject",
+        "project",
+        "source_variable",
+    ]:
+        if key not in data_type_info_tuple:
             data_type_info_tuple[key] = None
 
+    return ValueType(
+        str(value),
+        str(data_type_info_tuple["label"]),
+        str(data_type_info_tuple["datumType"]),
+        str(data_type_info_tuple["hasUnit"]),
+        str(data_type_info_tuple["isAbout"]),
+        str(data_type_info_tuple["measureOf"]),
+        str(data_type_info_tuple["hasLaterality"]),
+        str(data_type_info_tuple["dataElement"]),
+        str(data_type_info_tuple["description"]),
+        str(data_type_info_tuple["subject"]),
+        str(data_type_info_tuple["project"]),
+        str(data_type_info_tuple["source_variable"]),
+    )
 
-    return ValueType(str(value), str(data_type_info_tuple['label']), str(data_type_info_tuple['datumType']),
-                     str(data_type_info_tuple['hasUnit']), str(data_type_info_tuple['isAbout']), str(data_type_info_tuple['measureOf']),
-                     str(data_type_info_tuple['hasLaterality']), str(data_type_info_tuple['dataElement']),
-                     str(data_type_info_tuple['description']), str(data_type_info_tuple['subject']), str(data_type_info_tuple['project']), str(data_type_info_tuple['source_variable']))
 
-def expandID(id, namespace):
-    '''
+def expandID(id, namespace):  # noqa: A002
+    """
     If the ID isn't a full URI already, make it one in the given namespace
 
     :param id:
     :param namespace:
     :return: full URI
-    '''
-    if id.find('http') < 0:
+    """
+    if id.find("http") < 0:
         return namespace[id]
     # it has a http, but isn't a URIRef so convert it
     if type(id) == str:
         return URIRef(id)
 
     return id
 
 
 @functools.lru_cache(maxsize=BIG_CACHE_SIZE)
 def simplifyURIWithPrefix(nidm_file_tuples, uri):
-    '''
+    """
     Takes a URI and finds if there is a simple prefix for it in the graph
     :param rdf_graph:
     :param uri:
     :return: simple prefix or the original uri string
-    '''
+    """
 
     @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
     def getNamespaceLookup(nidm_file_tuples):
         names = {}
         for f in nidm_file_tuples:
             rdf_graph = OpenGraph(f)
-            for (prefix, uri) in rdf_graph.namespace_manager.namespaces():
-                if not str(uri) in names:
+            for prefix, uri in rdf_graph.namespace_manager.namespaces():
+                if str(uri) not in names:
                     names[str(uri)] = prefix
         return names
 
     names = getNamespaceLookup(tuple(nidm_file_tuples))
     # strip off the bit of URI after the last /
-    trimed_uri = str(uri).split('/')[0:-1]
-    trimed_uri = '/'.join(trimed_uri) + '/'
+    trimed_uri = str(uri).split("/")[0:-1]
+    trimed_uri = "/".join(trimed_uri) + "/"
     if trimed_uri in names:
         return names[trimed_uri]
     else:
         return uri
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def getProjects(nidm_file_tuples):
     projects = []
 
     for file in nidm_file_tuples:
         rdf_graph = OpenGraph(file)
-        #find all the sessions
-        for (project, p, o) in rdf_graph.triples((None, isa, Constants.NIDM['Project'])):
+        # find all the sessions
+        for project, _, _ in rdf_graph.triples((None, isa, Constants.NIDM["Project"])):
             projects.append(project)
 
     return projects
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def getSessions(nidm_file_tuples, project_id):
     project_uri = expandID(project_id, Constants.NIIRI)
     sessions = []
 
     for file in nidm_file_tuples:
         rdf_graph = OpenGraph(file)
-        #find all the sessions
-        for (session, p, o) in rdf_graph.triples((None, isa, Constants.NIDM['Session'])):
-            #check if it is part of our project
+        # find all the sessions
+        for session, _, _ in rdf_graph.triples((None, isa, Constants.NIDM["Session"])):
+            # check if it is part of our project
             if (session, isPartOf, project_uri) in rdf_graph:
                 sessions.append(session)
 
     return sessions
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def getAcquisitions(nidm_file_tuples, session_id):
     session_uri = expandID(session_id, Constants.NIIRI)
     acquisitions = []
 
     for file in nidm_file_tuples:
         rdf_graph = OpenGraph(file)
-        #find all the sessions
-        for (acq, p, o) in rdf_graph.triples((None, isPartOf, session_uri)):
-            #check if it is a acquisition
-            if (acq, isa, Constants.NIDM['Acquisition']) in rdf_graph:
+        # find all the sessions
+        for acq, _, _ in rdf_graph.triples((None, isPartOf, session_uri)):
+            # check if it is a acquisition
+            if (acq, isa, Constants.NIDM["Acquisition"]) in rdf_graph:
                 acquisitions.append(acq)
 
     return acquisitions
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def getSubject(nidm_file_tuples, acquisition_id):
     acquisition_uri = expandID(acquisition_id, Constants.NIIRI)
-    subjects = []
 
     for file in nidm_file_tuples:
         rdf_graph = OpenGraph(file)
-        #find all the sessions
-        for (acq, p, blank) in rdf_graph.triples((acquisition_uri, Constants.PROV['qualifiedAssociation'], None)):
-            for (s2, p2, sub) in rdf_graph.triples((blank, Constants.PROV['agent'], None)):
-                if (blank, Constants.PROV['hadRole'], Constants.SIO['Subject']) in rdf_graph:
+        # find all the sessions
+        for _, _, blank in rdf_graph.triples(
+            (acquisition_uri, Constants.PROV["qualifiedAssociation"], None)
+        ):
+            for _, _, sub in rdf_graph.triples((blank, Constants.PROV["agent"], None)):
+                if (
+                    blank,
+                    Constants.PROV["hadRole"],
+                    Constants.SIO["Subject"],
+                ) in rdf_graph:
                     return sub
     return None
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def getSubjects(nidm_file_tuples, project_id):
     subjects = set([])
     project_uri = expandID(project_id, Constants.NIIRI)
 
     sessions = getSessions(nidm_file_tuples, project_uri)
     for s in sessions:
         acquisitions = getAcquisitions(nidm_file_tuples, s)
         for acq in acquisitions:
             sub = getSubject(nidm_file_tuples, acq)
             subjects.add(sub)
     return subjects
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def getSubjectUUIDsfromID(nidm_file_tuples, sub_id):
     uuids = []
     for file in nidm_file_tuples:
         rdf_graph = OpenGraph(file)
 
-        result = rdf_graph.triples((None, Constants.NDAR['src_subject_id'], None))
-        for (s,p,o) in result:
+        result = rdf_graph.triples((None, Constants.NDAR["src_subject_id"], None))
+        for s, _, o in result:
             if str(o) == str(sub_id):
-                uuids.append( URITail(s) )
+                uuids.append(URITail(s))
 
     return uuids
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def getSubjectIDfromUUID(nidm_file_tuples, subject_uuid):
     for file in nidm_file_tuples:
         rdf_graph = OpenGraph(file)
-        id_generator = rdf_graph.objects(subject=subject_uuid, predicate=Constants.NDAR['src_subject_id'])
-        for id in id_generator:
-            return id
+        id_generator = rdf_graph.objects(
+            subject=subject_uuid, predicate=Constants.NDAR["src_subject_id"]
+        )
+        for id_ in id_generator:
+            return id_
     return None
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
-def normalizeSingleSubjectToUUID(nidm_file_tuples, id):
+def normalizeSingleSubjectToUUID(nidm_file_tuples, id):  # noqa: A002
     if len(getSubjectUUIDsfromID(nidm_file_tuples, id)) > 0:
         return getSubjectUUIDsfromID(nidm_file_tuples, id)[0]
     return id
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def getActivities(nidm_file_tuples, subject_id):
     activities = set([])
 
     # if we were passed in a sub_id rather than a UUID, lookup the associated UUID. (we might get multiple!)
     if validate_uuid(URITail(subject_id)):
         sub_uris = [subject_id]
     else:
         sub_uris = getSubjectUUIDsfromID(nidm_file_tuples, subject_id)
 
     for file in nidm_file_tuples:
         rdf_graph = OpenGraph(file)
         for subject_uri in sub_uris:
             subject_uri = expandID(subject_uri, Constants.NIIRI)
-            for blank_node in rdf_graph.subjects(predicate=Constants.PROV['agent'], object=subject_uri):
-                for activity in rdf_graph.subjects(predicate=Constants.PROV['qualifiedAssociation'], object=blank_node):
-                    if (activity, isa, Constants.PROV['Activity']) in rdf_graph:
+            for blank_node in rdf_graph.subjects(
+                predicate=Constants.PROV["agent"], object=subject_uri
+            ):
+                for activity in rdf_graph.subjects(
+                    predicate=Constants.PROV["qualifiedAssociation"], object=blank_node
+                ):
+                    if (activity, isa, Constants.PROV["Activity"]) in rdf_graph:
                         activities.add(activity)
     return activities
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def isAStatCollection(nidm_file_tuples, uri):
     for file in nidm_file_tuples:
         rdf_graph = OpenGraph(file)
-        if ((uri, isa, Constants.NIDM['FSStatsCollection']) in rdf_graph ) or \
-            ((uri, isa, Constants.NIDM['FSLStatsCollection']) in rdf_graph) or \
-            ((uri, isa, Constants.NIDM['ANTSStatsCollection']) in rdf_graph) :
+        if (
+            ((uri, isa, Constants.NIDM["FSStatsCollection"]) in rdf_graph)
+            or ((uri, isa, Constants.NIDM["FSLStatsCollection"]) in rdf_graph)
+            or ((uri, isa, Constants.NIDM["ANTSStatsCollection"]) in rdf_graph)
+        ):
             return True
     return False
 
+
 # def getDataElementInfo(nidm_file_list, id):
 #
 #     uuid = expandID(id, Constants.NIIRI)
 #
 #     for file in nidm_file_list:
 #         rdf_graph = OpenGraph(file)
 #         if (uuid, isa, Constants.NIDM['DataElement']) in rdf_graph:
 #             label = list(rdf_graph.objects(subject=uuid, predicate=Constants.RDFS['label'])) [0]
 #             description = list(rdf_graph.objects(subject=uuid, predicate=Constants.DCT['description'])) [0]
 #             isAbout = list(rdf_graph.objects(subject=uuid, predicate=Constants.NIDM['isAbout'])) [0]
 #             return makeValueType(label=label, description=description, isAbout=isAbout)
 #
 #     return False
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def getActivityData(nidm_file_tuples, acquisition_id):
     acquisition_uri = expandID(acquisition_id, Constants.NIIRI)
     result = []
     category = None
 
     for file in nidm_file_tuples:
         rdf_graph = OpenGraph(file)
         # find everything generated by the acquisition
-        for (data_object, p1, o1) in rdf_graph.triples((None, Constants.PROV['wasGeneratedBy'], acquisition_uri)):
+        for data_object, _, _ in rdf_graph.triples(
+            (None, Constants.PROV["wasGeneratedBy"], acquisition_uri)
+        ):
             # make sure this is an acquisition object
-            if (data_object, isa, Constants.NIDM['AcquisitionObject']) in rdf_graph:
-                category = 'instrument'
+            if (data_object, isa, Constants.NIDM["AcquisitionObject"]) in rdf_graph:
+                category = "instrument"
                 # iterate over all the items in the acquisition object
-                for (s, p, o) in rdf_graph.triples((data_object, None, None)):
-
+                for _, p, o in rdf_graph.triples((data_object, None, None)):
                     dti = getDataTypeInfo(rdf_graph, p)
-                    if (dti):
+                    if dti:
                         # there is a DataElement describing this predicate
-                        value_type = makeValueTypeFromDataTypeInfo(value=trimWellKnownURIPrefix(o), data_type_info_tuple=dti)
-                        result.append( value_type )
+                        value_type = makeValueTypeFromDataTypeInfo(
+                            value=trimWellKnownURIPrefix(o), data_type_info_tuple=dti
+                        )
+                        result.append(value_type)
                     else:
-                        #Don't know exactly what this is so just set a label and be done.
-                        if (data_object, isa, Constants.ONLI['assessment-instrument']) in rdf_graph:
-                            result.append(makeValueType(value=trimWellKnownURIPrefix(o), label=simplifyURIWithPrefix(nidm_file_tuples, str(p))))
-                            #result[ simplifyURIWithPrefix(nidm_file_list, str(p)) ] = trimWellKnownURIPrefix(o)
+                        # Don't know exactly what this is so just set a label and be done.
+                        if (
+                            data_object,
+                            isa,
+                            Constants.ONLI["assessment-instrument"],
+                        ) in rdf_graph:
+                            result.append(
+                                makeValueType(
+                                    value=trimWellKnownURIPrefix(o),
+                                    label=simplifyURIWithPrefix(
+                                        nidm_file_tuples, str(p)
+                                    ),
+                                )
+                            )
+                            # result[ simplifyURIWithPrefix(nidm_file_list, str(p)) ] = trimWellKnownURIPrefix(o)
                         else:
-                            result.append(makeValueType(value=trimWellKnownURIPrefix(o), label=URITail(str(p))))
+                            result.append(
+                                makeValueType(
+                                    value=trimWellKnownURIPrefix(o),
+                                    label=URITail(str(p)),
+                                )
+                            )
                             # result[ URITail(str(p))] = trimWellKnownURIPrefix(o)
 
             # or maybe it's a stats collection
-            elif isAStatCollection (nidm_file_tuples, data_object):
-                category = 'derivative'
-                for (s, p, o) in rdf_graph.triples((data_object, None, None)):
-                        cde = getDataTypeInfo(rdf_graph,p )
-                        result.append(
-                            makeValueTypeFromDataTypeInfo(value=str(o), data_type_info_tuple=cde)
+            elif isAStatCollection(nidm_file_tuples, data_object):
+                category = "derivative"
+                for _, p, o in rdf_graph.triples((data_object, None, None)):
+                    cde = getDataTypeInfo(rdf_graph, p)
+                    result.append(
+                        makeValueTypeFromDataTypeInfo(
+                            value=str(o), data_type_info_tuple=cde
                         )
-                        # result[ URITail(str(p)) ] = str(o)
+                    )
+                    # result[ URITail(str(p)) ] = str(o)
+
+    return ActivityData(
+        category=category, uuid=trimWellKnownURIPrefix(acquisition_uri), data=result
+    )
 
-    return ActivityData(category=category, uuid=trimWellKnownURIPrefix(acquisition_uri),  data=result)
 
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def GetProjectAttributes(nidm_files_tuple, project_id):
     result = {
         ACQUISITION_MODALITY: set([]),
         IMAGE_CONTRAST_TYPE: set([]),
-        IMAGE_USAGE_TYPE : set([]),
-        TASK : set([])
+        IMAGE_USAGE_TYPE: set([]),
+        TASK: set([]),
     }
 
     project_uuid = expandUUID(project_id)
 
     for file in nidm_files_tuple:
         rdf_graph = OpenGraph(file)
-        #find all the projects
-        for (project,pred,o) in rdf_graph.triples((None, None, Constants.NIDM['Project'])):
-            #check if it is our project
+        # find all the projects
+        for project, _, _ in rdf_graph.triples((None, None, Constants.NIDM["Project"])):
+            # check if it is our project
             if str(project) == str(project_uuid):
                 # get all the basic data from the project
-                for (proj, predicate, object) in rdf_graph.triples((project, None, None)):
-                    result[ matchPrefix(str(predicate)) ] = str(object)
+                for _, predicate, obj in rdf_graph.triples((project, None, None)):
+                    result[matchPrefix(str(predicate))] = str(obj)
 
     # now drill into the acquisition objects to get some specific
     # elements: AcquisitionModality, ImageContrastType, ImageUsageType, Task
     sessions = getSessions(nidm_files_tuple, project_id)
     for s in sessions:
         acquistions = getAcquisitions(nidm_files_tuple, s)
         for a in acquistions:
             acq_obj = getActivityData(nidm_files_tuple, a)
             for de in acq_obj.data:
-                if de.label == 'hadAcquisitionModality':
+                if de.label == "hadAcquisitionModality":
                     result[ACQUISITION_MODALITY].add(de.value)
-                if de.label == 'hadImageContrastType':
+                if de.label == "hadImageContrastType":
                     result[IMAGE_CONTRAST_TYPE].add(de.value)
-                if de.label == 'hadImageUsageType':
+                if de.label == "hadImageUsageType":
                     result[IMAGE_USAGE_TYPE].add(de.value)
-                if de.label == 'Task':
+                if de.label == "Task":
                     result[TASK].add(de.value)
 
     # de-set-ify items so they will play nice with JSON later
     result[ACQUISITION_MODALITY] = list(result[ACQUISITION_MODALITY])
     result[IMAGE_CONTRAST_TYPE] = list(result[IMAGE_CONTRAST_TYPE])
     result[IMAGE_USAGE_TYPE] = list(result[IMAGE_USAGE_TYPE])
     result[TASK] = list(result[TASK])
 
     return result
 
+
 @functools.lru_cache(maxsize=BIG_CACHE_SIZE)
 def GetAllPredicates(nidm_files_tuple):
     pred_set = set()
     for file in nidm_files_tuple:
         rdf_graph = OpenGraph(file)
         predicates = rdf_graph.predicates()
         for p in predicates:
@@ -322,102 +445,121 @@
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def GetDataelements(nidm_files_tuple):
     result = {"data_elements": {"uuid": [], "label": [], "data_type_info": []}}
     found_uris = set()
 
     for file in nidm_files_tuple:
         rdf_graph = OpenGraph(file)
-        #find all the datatypes
-        for de_uri in rdf_graph.subjects(predicate=isa, object=Constants.NIDM['DataElement']):
+        # find all the datatypes
+        for de_uri in rdf_graph.subjects(
+            predicate=isa, object=Constants.NIDM["DataElement"]
+        ):
             if de_uri not in found_uris:  # don't add duplicates
                 dti = getDataTypeInfo(rdf_graph, de_uri)
-                result['data_elements']['uuid'].append(str(dti['dataElementURI']))
-                result['data_elements']['label'].append(str(dti['label']))
-                result['data_elements']['data_type_info'].append( dti )
+                result["data_elements"]["uuid"].append(str(dti["dataElementURI"]))
+                result["data_elements"]["label"].append(str(dti["label"]))
+                result["data_elements"]["data_type_info"].append(dti)
                 found_uris.add(de_uri)
         # find all the datatypes
-        for de_uri in rdf_graph.subjects(predicate=isa, object=Constants.NIDM['PersonalDataElement']):
+        for de_uri in rdf_graph.subjects(
+            predicate=isa, object=Constants.NIDM["PersonalDataElement"]
+        ):
             if de_uri not in found_uris:  # don't add duplicates
                 dti = getDataTypeInfo(rdf_graph, de_uri)
-                result['data_elements']['uuid'].append(str(dti['dataElementURI']))
-                result['data_elements']['label'].append(str(dti['label']))
-                result['data_elements']['data_type_info'].append(dti)
+                result["data_elements"]["uuid"].append(str(dti["dataElementURI"]))
+                result["data_elements"]["label"].append(str(dti["label"]))
+                result["data_elements"]["data_type_info"].append(dti)
                 found_uris.add(de_uri)
 
     # now look for any of the CDEs
     all_predicates = GetAllPredicates(nidm_files_tuple)
     cde_graph = nidm.experiment.CDE.getCDEs()
-    cde_types = cde_graph.subjects(predicate=Constants.RDFS['subClassOf'], object=Constants.NIDM['DataElement'])
-    cde_type_set = set() # i.e. fs:DataElement
-    known_cde_types = set() # i.e. fs_003579
+    cde_types = cde_graph.subjects(
+        predicate=Constants.RDFS["subClassOf"], object=Constants.NIDM["DataElement"]
+    )
+    cde_type_set = set()  # i.e. fs:DataElement
+    known_cde_types = set()  # i.e. fs_003579
     for t in cde_types:
         cde_type_set.add(t)
         for s in cde_graph.subjects(predicate=isa, object=t):
             known_cde_types.add(s)
 
-
     for predicate in all_predicates:
         if predicate in known_cde_types:
             dti = getDataTypeInfo(cde_graph, predicate)
-            result['data_elements']['uuid'].append(str(dti['dataElementURI']))
-            result['data_elements']['label'].append(str(dti['label']))
-            result['data_elements']['data_type_info'].append(dti)
+            result["data_elements"]["uuid"].append(str(dti["dataElementURI"]))
+            result["data_elements"]["label"].append(str(dti["label"]))
+            result["data_elements"]["data_type_info"].append(dti)
 
     return result
 
 
 def GetDataelementDetails(nidm_files_tuple, dataelement):
     result = {}
 
     for file in nidm_files_tuple:
         rdf_graph = OpenGraph(file)
-        for de_uri in rdf_graph.subjects(predicate=isa, object=Constants.NIDM['DataElement']):
+        for de_uri in rdf_graph.subjects(
+            predicate=isa, object=Constants.NIDM["DataElement"]
+        ):
             dti = getDataTypeInfo(rdf_graph, de_uri)
 
             # check if this is the correct one
-            if not (dataelement in [ str(dti['label']), str(dti['dataElement']), str(dti['dataElementURI']) ] ):
+            if dataelement not in [
+                str(dti["label"]),
+                str(dti["dataElement"]),
+                str(dti["dataElementURI"]),
+            ]:
                 continue
 
-            for key in dti.keys():
-                result[key] = dti[key]
-            result['inProjects'] = set()
+            result.update(dti)
+            result["inProjects"] = set()
 
             # figure out what project the dataelement was used in
             uri = dti["dataElementURI"]
 
             a_list = rdf_graph.subjects(predicate=uri)
-            for a in a_list: # a is an assessment / AcquisitionObject
-                b_list = rdf_graph.objects(subject=a, predicate=Constants.PROV['wasGeneratedBy'])
-                for b in b_list: # b is an Acquisition / Activity
-                    c_list = rdf_graph.objects(subject=b, predicate=Constants.DCT['isPartOf'])
-                    for c in c_list: # c is a session
-                        d_list = rdf_graph.objects(subject=c, predicate=Constants.DCT['isPartOf'])
-                        for d in d_list: # d is most likely a project
-                            if d in rdf_graph.subjects(predicate=isa, object=Constants.NIDM['Project']):
-                                result['inProjects'].add("{} ({})".format(str(d), file))
-
-            return result # found it, we are done
+            for a in a_list:  # a is an assessment / AcquisitionObject
+                b_list = rdf_graph.objects(
+                    subject=a, predicate=Constants.PROV["wasGeneratedBy"]
+                )
+                for b in b_list:  # b is an Acquisition / Activity
+                    c_list = rdf_graph.objects(
+                        subject=b, predicate=Constants.DCT["isPartOf"]
+                    )
+                    for c in c_list:  # c is a session
+                        d_list = rdf_graph.objects(
+                            subject=c, predicate=Constants.DCT["isPartOf"]
+                        )
+                        for d in d_list:  # d is most likely a project
+                            if d in rdf_graph.subjects(
+                                predicate=isa, object=Constants.NIDM["Project"]
+                            ):
+                                result["inProjects"].add(f"{d} ({file})")
 
+            return result  # found it, we are done
 
-    if result == {}:  # didn't find it yet, check the CDEs
+    if not result:  # didn't find it yet, check the CDEs
         cde_graph = nidm.experiment.CDE.getCDEs()
         for de_uri in cde_graph.subjects(predicate=isa):
             dti = getDataTypeInfo(cde_graph, de_uri)
 
             # check if this is the correct one
-            if not (dataelement in [str(dti['label']), str(dti['dataElement']), str(dti['dataElementURI'])]):
+            if dataelement not in [
+                str(dti["label"]),
+                str(dti["dataElement"]),
+                str(dti["dataElementURI"]),
+            ]:
                 continue
 
-            for key in dti.keys():
-                result[key] = dti[key]
-            result['inProjects'] = set()
-            result['inProjects'].add("Common Data Element")
+            result.update(dti)
+            result["inProjects"] = set()
+            result["inProjects"].add("Common Data Element")
 
             for file in nidm_files_tuple:
                 rdf_graph = OpenGraph(file)
-                if result['dataElementURI'] in rdf_graph.predicates():
-                    result['inProjects'].add(file)
-
+                if result["dataElementURI"] in rdf_graph.predicates():
+                    result["inProjects"].add(file)
 
-            return result # found it, we are done
+            return result  # found it, we are done
 
-    return result
+    return result
```

### Comparing `pynidm-3.9.7/nidm/experiment/PETAcquisition.py` & `pynidm-4.0.0/src/nidm/experiment/AssessmentAcquisition.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,40 +1,37 @@
-import os, sys
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-import rdflib as rdf
-from ..experiment import Acquisition
-from ..core import Constants
 import prov.model as pm
+from .Acquisition import Acquisition
+from ..core import Constants
+
 
-class PETAcquisition(Acquisition):
+class AssessmentAcquisition(Acquisition):
     """
-        Default contructor, creates a session activity and links to project object
+    Default constructor, creates a session activity and links to project object
 
-        :param session: a session object
+    :param session: a session object
 
     """
 
-    #constructor
-    def __init__(self, session,attributes=None, uuid=None, add_default_type=True):
+    # constructor
+    def __init__(self, session, attributes=None, uuid=None, add_default_type=True):
         """
-        Default contructor, creates an acquisition object and links to acquisition activity object
+        Default constructor, creates an acquisition object and links to acquisition activity object
 
         :param session: a session object
         :param attributes: optional attributes to add to entity
         :param uuid: optional uuid...used mostly for reading in existing NIDM document
         :return: none
 
         """
-        #execute default parent class constructor
-          #execute default parent class constructor
-        super(PETAcquisition,self).__init__(session,attributes,uuid)
-        #acquisition.graph._add_record(self)
+        # execute default parent class constructor
+        super().__init__(session, attributes, uuid)
+        # acquisition.graph._add_record(self)
 
         if add_default_type:
             self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ACQUISITION_ACTIVITY})
+            self.add_attributes({pm.PROV_TYPE: Constants.NIDM_ASSESSMENT_ACQUISITION})
 
-        #carry graph object around
+        # carry graph object around
         self.graph = session.graph
 
-
     def __str__(self):
-        return "NIDM-Experiment PET Acquisition Class"
+        return "NIDM-Experiment Assessment Acquisition Class"
```

### Comparing `pynidm-3.9.7/nidm/experiment/Project.py` & `pynidm-4.0.0/src/nidm/experiment/Project.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,104 +1,96 @@
-import rdflib as rdf
-import os, sys
 import prov.model as pm
-import json
-from rdflib import Graph, RDF, URIRef, util, term
-from rdflib.namespace import split_uri
-import validators
-
-
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
+from .Core import Core, getUUID
 from ..core import Constants
 
-#import NIDMExperimentCore
-from ..experiment.Core import Core
-from ..experiment.Core import getUUID
 
-class Project(pm.ProvActivity,Core):
+class Project(pm.ProvActivity, Core):
     """Class for NIDM-Experiment Project-Level Objects.
 
     Default constructor uses empty graph with namespaces added from NIDM/Scripts/Constants.py.
     Additional alternate constructors for user-supplied graphs and default namespaces (i.e. from Constants.py)
     and user-supplied graph and namespaces
 
     @author: David Keator <dbkeator@uci.edu>
     @copyright: University of California, Irvine 2017
 
     """
-    #constructor, adds project
-    def __init__(self,attributes=None, empty_graph=False, uuid=None,add_default_type=True):
+
+    # constructor, adds project
+    def __init__(
+        self, attributes=None, empty_graph=False, uuid=None, add_default_type=True
+    ):
         """
-        Default contructor, creates document and adds Project activity to graph with optional attributes
+        Default constructor, creates document and adds Project activity to graph with optional attributes
 
         :param attributes: optional dictionary of attributes to add
         :empty_graph: if set to True, creates empty graph with no namespaces besides Prov defaults
         :uuid: if uuid is not None then use supplied uuid for project instead of generating one (for reading nidm docs)
 
         """
 
-        if (empty_graph):
+        if empty_graph:
             self.graph = Constants.NIDMDocument(namespaces=None)
         else:
             self.graph = Constants.NIDMDocument(namespaces=Constants.namespaces)
 
         if uuid is None:
             self._uuid = getUUID()
 
-            #execute default parent class constructor
-            super(Project,self).__init__(self.graph, pm.QualifiedName(pm.Namespace("niiri",Constants.NIIRI),self.get_uuid()),attributes)
+            # execute default parent class constructor
+            super().__init__(
+                self.graph,
+                pm.QualifiedName(
+                    pm.Namespace("niiri", Constants.NIIRI), self.get_uuid()
+                ),
+                attributes,
+            )
         else:
             self._uuid = uuid
-            #execute default parent class constructor
-            super(Project,self).__init__(self.graph, pm.QualifiedName(pm.Namespace("niiri",Constants.NIIRI),self.get_uuid()),attributes)
+            # execute default parent class constructor
+            super().__init__(
+                self.graph,
+                pm.QualifiedName(
+                    pm.Namespace("niiri", Constants.NIIRI), self.get_uuid()
+                ),
+                attributes,
+            )
 
-        #add record to graph
+        # add record to graph
         self.graph._add_record(self)
-        #create empty sessions list
-        self._sessions=[]
-        #create empty derivatives list
-        self._derivatives=[]
+        # create empty sessions list
+        self._sessions = []
+        # create empty derivatives list
+        self._derivatives = []
         # create empty data elements list
-        self._dataelements=[]
+        self._dataelements = []
 
         if add_default_type:
             self.add_attributes({pm.PROV_TYPE: Constants.NIDM_PROJECT})
 
-
-    @property
-    def sessions(self):
-        return self._sessions
-
-    # added for derivatives and data elements
-    @property
-    def derivatives(self):
-        return self._derivatives
-
-    @property
-    def dataelements(self):
-        return self._dataelements
-
-
-    def add_sessions(self,session):
+    def add_sessions(self, session):
         """
         Adds session to project, creating links and adding reference to sessions list
 
         :param session: object of type "Session" from nidm API
         :return true if session object added to project, false if session object is already in project
 
         """
         if session in self._sessions:
             return False
         else:
-            #add session to self.sessions list
+            # add session to self.sessions list
             self._sessions.extend([session])
-            #create links in graph
-            #session.add_attributes({str("dct:isPartOf"):self})
-            session.add_attributes({pm.QualifiedName(pm.Namespace("dct",Constants.DCT),'isPartOf'):self})
+            # create links in graph
+            # session.add_attributes({str("dct:isPartOf"):self})
+            session.add_attributes(
+                {pm.QualifiedName(pm.Namespace("dct", Constants.DCT), "isPartOf"): self}
+            )
             return True
+
     def get_sessions(self):
         return self._sessions
 
     def get_derivatives(self):
         return self._derivatives
 
     def get_dataelements(self):
@@ -113,15 +105,17 @@
         if derivative in self._derivatives:
             return False
         else:
             # add session to self.sessions list
             self._derivatives.extend([derivative])
             # create links in graph
             # session.add_attributes({str("dct:isPartOf"):self})
-            derivative.add_attributes({pm.QualifiedName(pm.Namespace("dct", Constants.DCT), 'isPartOf'): self})
+            derivative.add_attributes(
+                {pm.QualifiedName(pm.Namespace("dct", Constants.DCT), "isPartOf"): self}
+            )
             return True
 
     def add_dataelements(self, dataelement):
         """
         Adds data elements to project, creating links and adding reference to data elements list
         :param dataelement: object of type "DataElement" from nidm API
         :return true if derivative object added to project, false if derivative object is already in project
@@ -129,19 +123,16 @@
         if dataelement in self._dataelements:
             return False
         else:
             # add session to self.sessions list
             self._dataelements.extend([dataelement])
             # create links in graph
             # session.add_attributes({str("dct:isPartOf"):self})
-            #dataelement.add_attributes({pm.QualifiedName(pm.Namespace("dct", Constants.DCT), 'isPartOf'): self})
+            # dataelement.add_attributes({pm.QualifiedName(pm.Namespace("dct", Constants.DCT), 'isPartOf'): self})
             return True
 
     def __str__(self):
         return "NIDM-Experiment Project Class"
 
-
-
-
-    sessions = property(get_sessions,add_sessions)
-    derivatives = property(get_derivatives,add_derivatives)
-    dataelements = property(get_dataelements,add_dataelements)
+    sessions = property(get_sessions, add_sessions)
+    derivatives = property(get_derivatives, add_derivatives)
+    dataelements = property(get_dataelements, add_dataelements)
```

### Comparing `pynidm-3.9.7/nidm/experiment/Query.py` & `pynidm-4.0.0/src/nidm/experiment/Query.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,927 +1,1020 @@
-#**************************************************************************************
-#**************************************************************************************
-#  nidm_query.py
-#  License: GPL
-#**************************************************************************************
-#**************************************************************************************
-# Date: 8-1-18                 Coded by: David Keator (dbkeator@gmail.com)
-# Filename: nidm_query.py
-#
-# Program description:  This program provides query functionalty for NIDM-Experiment files
-#
-#
-#**************************************************************************************
-# Development environment: Python - PyCharm IDE
-#
-#**************************************************************************************
-# System requirements:  Python 3.X
-# Libraries: os, sys, rdflib, pandas, argparse, logging
-#**************************************************************************************
-# Start date: 8-1-18
-# Update history:
-# DATE            MODIFICATION				Who
-#
-#
-#**************************************************************************************
-# Programmer comments:
-#
-#
-#**************************************************************************************
-#**************************************************************************************
-import os
-import sys
-from urllib.request import urlretrieve
+"""This program provides query functionality for NIDM-Experiment files"""
 
-import rdflib
-from rdflib import Graph, URIRef, util
-import pandas as pd
-import logging
-from nidm.core import Constants
-import nidm.experiment.CDE
-import re
-import tempfile
-from os import path, environ
 import functools
 import hashlib
+import json
+import logging
+import os
+from os import environ, path
 import pickle
+import re
+import tempfile
+import pandas as pd
+import rdflib
+from rdflib import Graph, URIRef, util
 import requests
-import json
-
-
-from joblib import Memory
-memory = Memory(tempfile.gettempdir(), verbose=0 )
+from nidm.core import Constants
+import nidm.experiment.CDE
+from nidm.util import urlretrieve
 
+QUERY_CACHE_SIZE = 64
+BIG_CACHE_SIZE = 256
+LARGEST_CACHE_SIZE = 4096
+ACQUISITION_MODALITY = "AcquisitionModality"
+IMAGE_CONTRAST_TYPE = "ImageContrastType"
+IMAGE_USAGE_TYPE = "ImageUsageType"
+TASK = "Task"
 
-QUERY_CACHE_SIZE=64
-BIG_CACHE_SIZE=256
-LARGEST_CACHE_SIZE=4096
-ACQUISITION_MODALITY = 'AcquisitionModality'
-IMAGE_CONTRAST_TYPE = 'ImageContrastType'
-IMAGE_USAGE_TYPE = 'ImageUsageType'
-TASK = 'Task'
 
-def sparql_query_nidm(nidm_file_list,query, output_file=None, return_graph=False):
-    '''
+def sparql_query_nidm(nidm_file_list, query, output_file=None, return_graph=False):
+    """
 
     :param nidm_file_list: List of NIDM.ttl files to execute query on
     :param query:  SPARQL query string
     :param output_file:  Optional output file to write results
     :param return_graph: WIP - not working right now but for some queries we prefer to return a graph instead of a dataframe
     :return: dataframe | graph depending on return_graph parameter
-    '''
-
-
+    """
 
-    if 'BLAZEGRAPH_URL' in environ.keys():
+    if "BLAZEGRAPH_URL" in environ:
         try:
             # first make sure all files are loaded into blazegraph
             for nidm_file in nidm_file_list:
                 OpenGraph(nidm_file)
-            logging.debug("Sending sparql to blazegraph: %s", query )
-            r2 = requests.post(url=environ['BLAZEGRAPH_URL'], params={'query': query}, headers={'Accept': 'application/sparql-results+json'})
-            content = json.loads( r2.content )
+            logging.debug("Sending sparql to blazegraph: %s", query)
+            r2 = requests.post(
+                url=environ["BLAZEGRAPH_URL"],
+                params={"query": query},
+                headers={"Accept": "application/sparql-results+json"},
+            )
+            content = json.loads(r2.content)
             columns = {}
-            for key in content["head"]['vars']:
-                columns[key] = [x[key]['value'] for x in content['results']['bindings']]
+            for key in content["head"]["vars"]:
+                columns[key] = [x[key]["value"] for x in content["results"]["bindings"]]
             df = pd.DataFrame(data=columns)
-            if (output_file is not None):
+            if output_file is not None:
                 df.to_csv(output_file)
             return df
 
         except Exception as e:
-            print("Exception while communicating with blazegraph at {}: {}".format(environ['BLAZEGRAPH_URL'],e))
-
+            print(
+                f"Exception while communicating with blazegraph at {environ['BLAZEGRAPH_URL']}: {e}"
+            )
 
-    #query result list
+    # query result list
     results = []
 
+    logging.info("Query: %s", query)
 
-    logging.info("Query: %s" , query)
-
-    first_file=True
-    #cycle through NIDM files, adding query result to list
+    first_file = True
+    # cycle through NIDM files, adding query result to list
     for nidm_file in nidm_file_list:
-
         # project=read_nidm(nidm_file)
-        #read RDF file into temporary graph
+        # read RDF file into temporary graph
         # rdf_graph = Graph()
         # rdf_graph_parse = rdf_graph.parse(nidm_file,format=util.guess_format(nidm_file))
         rdf_graph_parse = OpenGraph(nidm_file)
 
-
         if not return_graph:
-            #execute query
+            # execute query
             qres = rdf_graph_parse.query(query)
 
-            #if this is the first file then grab the SPARQL bound variable names from query result for column headings of query result
+            # if this is the first file then grab the SPARQL bound variable names from query result for column headings of query result
             if first_file:
-                #format query result as dataframe and return
-                #for dicts in qres._get_bindings():
+                # format query result as dataframe and return
+                # for dicts in qres._get_bindings():
                 columns = [str(var) for var in qres.vars]
-                first_file=False
+                first_file = False
                 #    break
 
-            #append result as row to result list
+            # append result as row to result list
             for row in qres:
                 results.append(list(row))
         else:
-            #execute query
+            # execute query
             qres = rdf_graph_parse.query(query)
 
             if first_file:
-                #create graph
-                #WIP: qres_graph = Graph().parse(data=qres.serialize(format='turtle'))
-                qres_graph = qres.serialize(format='turtle')
-                first_file=False
+                # create graph
+                # WIP: qres_graph = Graph().parse(data=qres.serialize(format='turtle'))
+                qres_graph = qres.serialize(format="turtle")
+                first_file = False
             else:
-                #WIP qres_graph = qres_graph + Graph().parse(data=qres.serialize(format='turtle'))
-                qres_graph = qres_graph + qres.serialize(format='turtle')
-
-
+                # WIP qres_graph = qres_graph + Graph().parse(data=qres.serialize(format='turtle'))
+                qres_graph = qres_graph + qres.serialize(format="turtle")
 
     if not return_graph:
-        #convert results list to Pandas DataFrame and return
-        df = pd.DataFrame(results,columns=columns)
+        # convert results list to Pandas DataFrame and return
+        df = pd.DataFrame(results, columns=columns)
 
-        #if output file parameter specified
-        if (output_file is not None):
+        # if output file parameter specified
+        if output_file is not None:
             df.to_csv(output_file)
         return df
     else:
         return qres_graph
 
 
-def GetProjectsUUID(nidm_file_list,output_file=None):
-    '''
+def GetProjectsUUID(nidm_file_list, output_file=None):
+    """
 
     :param nidm_file_list: List of one or more NIDM files to query across for list of Projects
     :return: list of Project UUIDs
-    '''
+    """
 
-    #SPARQL query to get project UUIDs
-    query = '''
+    # SPARQL query to get project UUIDs
+    query = """
         PREFIX nidm:<http://purl.org/nidash/nidm#>
         PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
 
         SELECT distinct ?uuid
         Where {
             {
                 ?uuid rdf:type nidm:Project
             }
 
         }
-    '''
+    """
     df = sparql_query_nidm(nidm_file_list, query, output_file=output_file)
 
-    return df['uuid'] if type(df['uuid']) == list else df['uuid'].tolist()
+    return df["uuid"] if type(df["uuid"]) == list else df["uuid"].tolist()
 
-def GetProjectLocation(nidm_file_list, project_uuid, output_file=None):
-    '''
+
+def GetProjectLocation(nidm_file_list, project_uuid, output_file=None):  # noqa: U100
+    """
     This query will return the prov:Location value for project_uuid
 
     :param nidm_file_list: List of one or more NIDM files to query across for list of Projects
     :param output_file: Optional output file
     :return: list of Project prov:Locations
-    '''
+    """
 
     # SPARQL query to get project UUIDs
-    query = '''
+    query = """
             PREFIX nidm:<http://purl.org/nidash/nidm#>
             PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
             prefix prov: <http://www.w3.org/ns/prov#>
 
             SELECT distinct ?location
             Where {
                 {
                     ?uuid rdf:type nidm:Project ;
                         prov:Location ?location .
                 }
 
             }
-        '''
+        """
     df = sparql_query_nidm(nidm_file_list, query, output_file=output_file)
 
-    return df['location'].tolist()
+    return df["location"].tolist()
 
-def testprojectmeta(nidm_file_list):
-
-    import json
 
-    query = '''
+def testprojectmeta(nidm_file_list):
+    query = """
          prefix nidm: <http://purl.org/nidash/nidm#>
          prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
 
          select distinct ?uuid ?p ?o
 
          where {
- 	        ?uuid rdf:type nidm:Project ;
-	   	    ?p  ?o .
+                ?uuid rdf:type nidm:Project ;
+                    ?p  ?o .
          }
 
 
-    '''
+    """
 
-    df =sparql_query_nidm(nidm_file_list,query, output_file=None)
+    df = sparql_query_nidm(nidm_file_list, query, output_file=None)
 
     output_json = {}
-    for index,row in df.iterrows():
-        if row['uuid'] not in output_json:
-            output_json[row['uuid']] = {}
+    for _, row in df.iterrows():
+        if row["uuid"] not in output_json:
+            output_json[row["uuid"]] = {}
 
-        output_json[row['uuid']][row['p']] = row['o']
+        output_json[row["uuid"]][row["p"]] = row["o"]
 
     return json.dumps(output_json)
 
-def GetProjectSessionsMetadata(nidm_file_list, project_uuid):
 
-    import json
-
-    query = '''
+def GetProjectSessionsMetadata(nidm_file_list, project_uuid):
+    query = f"""
 
         prefix nidm: <http://purl.org/nidash/nidm#>
         prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
         prefix dct: <http://purl.org/dc/terms/>
 
         select distinct ?session_uuid ?p ?o
 
-        where {
- 	        ?session_uuid  dct:isPartOf  <%s> ;
- 	            ?p ?o .
-        }
+        where {{
+                ?session_uuid  dct:isPartOf  <{project_uuid}> ;
+                    ?p ?o .
+        }}
 
-    ''' % project_uuid
+    """
 
-    df =sparql_query_nidm(nidm_file_list,query, output_file=None)
+    df = sparql_query_nidm(nidm_file_list, query, output_file=None)
 
-    #outermost dictionary
+    # outermost dictionary
     output_json = {}
-    for index,row in df.iterrows():
+    for _, row in df.iterrows():
         if project_uuid not in output_json:
-            #creates dictionary for project UUID
+            # creates dictionary for project UUID
             output_json[project_uuid] = {}
-        if row['session_uuid'] not in output_json[project_uuid]:
-            #creates a dictionary under project_uuid dictionary for session
-            output_json[project_uuid][row['session_uuid']] = {}
+        if row["session_uuid"] not in output_json[project_uuid]:
+            # creates a dictionary under project_uuid dictionary for session
+            output_json[project_uuid][row["session_uuid"]] = {}
 
-        output_json[project_uuid][row['session_uuid']][row['p']] = row['o']
+        output_json[project_uuid][row["session_uuid"]][row["p"]] = row["o"]
 
     return json.dumps(output_json)
 
+
 def GetDataElementProperties(nidm_file_list):
     """
     This function will return a dictionary of data element properties for data_element_uuid
     :param nidm_file_list:
     :param data_element_uuid:
     :return:
     """
 
-    query='''
+    query = """
 
         select distinct ?uuid ?DataElements ?property ?value
             where {
 
                 ?uuid a/rdfs:subClassOf* nidm:DataElement ;
                     ?property ?value .
 
-            }'''
+            }"""
 
-    df = sparql_query_nidm(nidm_file_list.split(','), query, output_file=None)
+    df = sparql_query_nidm(nidm_file_list.split(","), query, output_file=None)
     return df
 
+
 def GetProjectInstruments(nidm_file_list, project_id):
     """
     Returns a list of unique instrument types.  For NIDM files this is rdf:type onli:assessment-instrument
     or related classes (e.g. nidm:NorthAmericanAdultReadingTest, nidm:PositiveAndNegativeSyndromeScale)
     :param nidm_file_list: List of one or more NIDM files to query across for list of Projects
     :param project_id: identifier of project you'd like to search for unique instruments
     :return: Dataframe of instruments and project titles
     """
-    query = '''
+    query = f"""
         PREFIX prov: <http://www.w3.org/ns/prov#>
         PREFIX sio: <http://semanticscience.org/ontology/sio.owl#>
         PREFIX dct: <http://purl.org/dc/terms/>
         prefix onli: <http://neurolog.unice.fr/ontoneurolog/v3.0/instrument.owl#>
         prefix dctypes: <http://purl.org/dc/dcmitype/>
 
         SELECT  DISTINCT ?project_title ?assessment_type
-        WHERE {
+        WHERE {{
             ?entity rdf:type  onli:assessment-instrument ;
                 rdf:type ?assessment_type .
             ?entity prov:wasGeneratedBy/dct:isPartOf/dct:isPartOf ?project .
 
             ?project dctypes:title ?project_title .
 
 
 
-            FILTER( (!regex(str(?assessment_type), "http://www.w3.org/ns/prov#Entity")) &&  (!regex(str(?assessment_type), "http://purl.org/nidash/nidm#AcquisitionObject")) &&  (regex(str(?project), "%s")) )
-            }
-            ''' % project_id
-    logging.info('Query: %s', query)
+            FILTER( (!regex(str(?assessment_type), "http://www.w3.org/ns/prov#Entity")) &&  (!regex(str(?assessment_type), "http://purl.org/nidash/nidm#AcquisitionObject")) &&  (regex(str(?project), "{project_id}")) )
+            }}
+            """
+    logging.info("Query: %s", query)
     df = sparql_query_nidm(nidm_file_list, query, output_file=None)
     results = df.to_dict()
     logging.info(results)
 
-
     return df
 
+
 def GetInstrumentVariables(nidm_file_list, project_id):
-    '''
+    """
     This function will return a comprehensive list of variables as part of any project instrument
     :param nidm_file_list: List of one or more NIDM files to query across for list of Projects
     :param project_id: identifier of project you'd like to search for unique instruments
     :return: Dataframe of instruments, project titles, and variables
-    '''
-    query = '''
+    """
+    query = f"""
         PREFIX prov: <http://www.w3.org/ns/prov#>
         PREFIX sio: <http://semanticscience.org/ontology/sio.owl#>
         PREFIX dct: <http://purl.org/dc/terms/>
         prefix onli: <http://neurolog.unice.fr/ontoneurolog/v3.0/instrument.owl#>
         prefix dctypes: <http://purl.org/dc/dcmitype/>
 
         SELECT  DISTINCT ?project_title ?assessment_type ?variables
-        WHERE {
+        WHERE {{
             ?entity rdf:type  onli:assessment-instrument ;
                 rdf:type ?assessment_type ;
                 ?variables ?value .
             ?entity prov:wasGeneratedBy/dct:isPartOf/dct:isPartOf ?project .
 
             ?project dctypes:title ?project_title .
 
 
 
-            FILTER( (!regex(str(?assessment_type), "http://www.w3.org/ns/prov#Entity")) &&  (!regex(str(?assessment_type), "http://purl.org/nidash/nidm#AcquisitionObject")) &&  (regex(str(?project), "%s")) )
-            }
-            ''' % project_id
-    logging.info('Query: %s', query)
+            FILTER( (!regex(str(?assessment_type), "http://www.w3.org/ns/prov#Entity")) &&  (!regex(str(?assessment_type), "http://purl.org/nidash/nidm#AcquisitionObject")) &&  (regex(str(?project), "{project_id}")) )
+            }}
+            """
+    logging.info("Query: %s", query)
     df = sparql_query_nidm(nidm_file_list, query, output_file=None)
     results = df.to_dict()
     logging.info(results)
 
-
     return df
 
-def GetParticipantIDs(nidm_file_list,output_file=None):
-    '''
+
+def GetParticipantIDs(nidm_file_list, output_file=None):
+    """
     This query will return a list of all prov:agent entity UUIDs that prov:hadRole sio:Subject or Constants.NIDM_PARTICIPANT
     :param nidm_file_list: List of one or more NIDM files to query across for list of Projects
     :return: list of Constants.NIDM_PARTICIPANT UUIDs and Constants.NIDM_SUBJECTID
-    '''
+    """
 
-    query = '''
+    query = f"""
 
         PREFIX prov:<http://www.w3.org/ns/prov#>
         PREFIX sio: <http://semanticscience.org/ontology/sio.owl#>
         PREFIX ndar: <https://ndar.nih.gov/api/datadictionary/v2/dataelement/>
         PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
 
         SELECT DISTINCT ?uuid ?ID
-        WHERE {
+        WHERE {{
 
             ?activity rdf:type prov:Activity ;
-		        prov:qualifiedAssociation _:blanknode .
+                        prov:qualifiedAssociation _:blanknode .
 
-	        _:blanknode prov:hadRole %s ;
+                _:blanknode prov:hadRole {Constants.NIDM_PARTICIPANT} ;
                  prov:agent ?uuid  .
 
-	        ?uuid %s ?ID .
+                ?uuid {Constants.NIDM_SUBJECTID} ?ID .
 
-        }
-    ''' %(Constants.NIDM_PARTICIPANT,Constants.NIDM_SUBJECTID)
+        }}
+    """
 
-    df = sparql_query_nidm(nidm_file_list,query, output_file=output_file)
+    df = sparql_query_nidm(nidm_file_list, query, output_file=output_file)
 
     return df
 
-def GetParticipantIDFromAcquisition(nidm_file_list,acquisition, output_file=None):
-    '''
+
+def GetParticipantIDFromAcquisition(nidm_file_list, acquisition, output_file=None):
+    """
     This function will return the participant ID of the participant with a qualified association of
     prov:hadRole sio:Subject.
 
     :param nidm_file_list: list of nidm files
     :param acquisition: nidm acquisition UUID to search for qualified association
     :param output_file: optional output filename
     :return: a dataframe subject ID and prov:Agent UUID of participant with qualified association
-    '''
+    """
 
-    query = '''
+    query = f"""
 
             PREFIX prov:<http://www.w3.org/ns/prov#>
             PREFIX sio: <http://semanticscience.org/ontology/sio.owl#>
             PREFIX ndar: <https://ndar.nih.gov/api/datadictionary/v2/dataelement/>
             PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
             PREFIX prov:<http://www.w3.org/ns/prov#>
 
             SELECT DISTINCT ?uuid ?ID
-            WHERE {
+            WHERE {{
 
-                <%s> rdf:type prov:Activity ;
-    		        prov:qualifiedAssociation _:blanknode .
+                <{acquisition}> rdf:type prov:Activity ;
+                        prov:qualifiedAssociation _:blanknode .
 
-    	        _:blanknode prov:hadRole %s ;
+                _:blanknode prov:hadRole {Constants.NIDM_PARTICIPANT} ;
                      prov:agent ?uuid  .
 
-    	        ?uuid %s ?ID .
+                ?uuid {Constants.NIDM_SUBJECTID} ?ID .
 
-            }
-        ''' % (acquisition, Constants.NIDM_PARTICIPANT, Constants.NIDM_SUBJECTID)
+            }}
+        """
 
     df = sparql_query_nidm(nidm_file_list, query, output_file=output_file)
 
     return df
 
 
-def GetParticipantDetails(nidm_file_list,project_id, participant_id, output_file=None):
-    '''
+def GetParticipantDetails(nidm_file_list, project_id, participant_id, output_file=None):
+    """
     This query will return a list of all prov:agent entity UUIDs that prov:hadRole Constants.NIDM_PARTICIPANT
     :param nidm_file_list: List of one or more NIDM files to query across for list of Projects
     :return: list of Constants.NIDM_PARTICIPANT UUIDs and Constants.NIDM_SUBJECTID
-    '''
+    """
 
-    query = '''
+    query = f"""
 
         PREFIX prov:<http://www.w3.org/ns/prov#>
         PREFIX sio: <http://semanticscience.org/ontology/sio.owl#>
         PREFIX ndar: <https://ndar.nih.gov/api/datadictionary/v2/dataelement/>
         PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
         PREFIX nidm: <http://purl.org/nidash/nidm#>
         PREFIX dct: <http://purl.org/dc/terms/>
 
 
         SELECT DISTINCT ?uuid ?id ?activity
-        WHERE {
+        WHERE {{
 
             ?activity rdf:type prov:Activity ;
-		        prov:qualifiedAssociation _:blanknode .
+                        prov:qualifiedAssociation _:blanknode .
 
-	        _:blanknode prov:hadRole %s ;
+                _:blanknode prov:hadRole {Constants.NIDM_PARTICIPANT} ;
                  prov:agent ?uuid  .
 
-	        ?uuid %s ?id .
+                ?uuid {Constants.NIDM_SUBJECTID} ?id .
 
             ?proj a nidm:Project .
             ?sess dct:isPartOf ?proj .
             ?activity dct:isPartOf ?sess .
 
-            FILTER(regex(str(?uuid), "%s")).
+            FILTER(regex(str(?uuid), "{participant_id}")).
 
-        }
-    ''' %(Constants.NIDM_PARTICIPANT,Constants.NIDM_SUBJECTID, participant_id)
+        }}
+    """
 
-    df = sparql_query_nidm(nidm_file_list,query, output_file=output_file)
+    df = sparql_query_nidm(nidm_file_list, query, output_file=output_file)
     data = df.values
 
     uuid = ""
-    id = ""
+    id_ = ""
     if len(data) > 0:
         uuid = data[0][0]
-        id = data[0][1]
+        id_ = data[0][1]
 
-    result = { 'uuid' : str(uuid).replace(Constants.NIIRI, ""),
-               'id' : str(id),
-               'activity': [] }
+    result = {
+        "uuid": str(uuid).replace(Constants.NIIRI, ""),
+        "id": str(id_),
+        "activity": [],
+    }
 
     for row in data:
         act = (str(row[2])).replace(str(Constants.NIIRI), "")
-        (result['activity']).append( act )
-
-    result["instruments"] = GetParticipantInstrumentData(nidm_file_list, project_id, participant_id)
+        (result["activity"]).append(act)
 
-    result["derivatives"] = GetDerivativesDataForSubject(nidm_file_list, None, participant_id)
+    result["instruments"] = GetParticipantInstrumentData(
+        nidm_file_list, project_id, participant_id
+    )
+
+    result["derivatives"] = GetDerivativesDataForSubject(
+        nidm_file_list, None, participant_id
+    )
 
     return result
 
+
 def GetMergedGraph(nidm_file_list):
     rdf_graph = Graph()
     for f in nidm_file_list:
         rdf_graph.parse(f, format=util.guess_format(f))
     return rdf_graph
 
+
 def GetNameForDataElement(graph, uri):
     label = isAbout = source_variable = None
 
-
-    for data_element, predicate, value in graph.triples( (uri, None, None) ):
-        if predicate == Constants.NIDM['source_variable']:
+    for _, predicate, value in graph.triples((uri, None, None)):
+        if predicate == Constants.NIDM["source_variable"]:
             source_variable = str(value)
-        if predicate == Constants.NIDM['isAbout']:
+        if predicate == Constants.NIDM["isAbout"]:
             isAbout = str(value)
-        if predicate == Constants.RDFS['label']:
+        if predicate == Constants.RDFS["label"]:
             label = str(value)
 
     return source_variable or label or isAbout or URITail(uri)
 
 
-def GetParticipantInstrumentData(nidm_file_list ,project_id, participant_id):
-    return GetParticipantInstrumentDataCached(tuple(nidm_file_list) ,project_id, participant_id)
+def GetParticipantInstrumentData(nidm_file_list, project_id, participant_id):
+    return GetParticipantInstrumentDataCached(
+        tuple(nidm_file_list), project_id, participant_id
+    )
+
 
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
-def GetParticipantInstrumentDataCached(nidm_file_list: tuple ,project_id, participant_id):
-    '''
+def GetParticipantInstrumentDataCached(
+    nidm_file_list: tuple, project_id, participant_id  # noqa: U100
+):
+    """
     This query will return a list of all instrument data for prov:agent entity UUIDs that has
     prov:hadRole sio:Subject or Constants.NIDM_PARTICIPANT
     :param nidm_file_list: List of one or more NIDM files to query across for list of Projects
     :return: list of Constants.NIDM_PARTICIPANT UUIDs and Constants.NIDM_SUBJECTID
-    '''
+    """
 
-    if participant_id.find('http') != 0:
+    if participant_id.find("http") != 0:
         participant_id = Constants.NIIRI[participant_id]
 
     result = {}
     names = []
     for f in nidm_file_list:
         rdf_graph = OpenGraph(f)
         for n in rdf_graph.namespace_manager.namespaces():
-            if not n in names:
+            if n not in names:
                 names.append(n)
 
-    isa = URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')
+    isa = URIRef("http://www.w3.org/1999/02/22-rdf-syntax-ns#type")
     for f in nidm_file_list:
         rdf_graph = OpenGraph(f)
         # find all the instrument based assessments
-        for acquisition in rdf_graph.subjects(isa, Constants.NIDM['Acquisition']):
+        for acquisition in rdf_graph.subjects(isa, Constants.NIDM["Acquisition"]):
             # verify that the assessment is linked to a subject through a blank node
-            for blanknode in rdf_graph.objects(subject=acquisition,predicate=Constants.PROV['qualifiedAssociation']):
+            for blanknode in rdf_graph.objects(
+                subject=acquisition, predicate=Constants.PROV["qualifiedAssociation"]
+            ):
                 # check to see if this assessment is about our participant
-                if ((blanknode, Constants.PROV['agent'], participant_id) in rdf_graph)  :
+                if (blanknode, Constants.PROV["agent"], participant_id) in rdf_graph:
                     # now we know that the assessment is one we want, find the actual assessment data
-                    for instrument in rdf_graph.subjects(predicate=Constants.PROV['wasGeneratedBy'], object=acquisition):
-                        #load up all the assement data into the result
-                        instrument_key = str(instrument).split('/')[-1]
+                    for instrument in rdf_graph.subjects(
+                        predicate=Constants.PROV["wasGeneratedBy"], object=acquisition
+                    ):
+                        # load up all the assement data into the result
+                        instrument_key = str(instrument).split("/")[-1]
                         result[instrument_key] = {}
-                        for s,data_element,o in rdf_graph.triples((instrument, None, None)):
+                        for _, data_element, o in rdf_graph.triples(
+                            (instrument, None, None)
+                        ):
                             # convert the random looking URIs to the prefix used in the ttl file, if any
                             matches = [n[0] for n in names if n[1] == data_element]
                             if len(matches) > 0:
                                 idx = str(matches[0])
                             else:
                                 # idx = str(data_element)
                                 idx = GetNameForDataElement(rdf_graph, data_element)
-                            result[instrument_key][ idx ] = str(str(o))
-
+                            result[instrument_key][idx] = str(str(o))
 
     return result
 
-def GetParticipantUUIDsForProject(nidm_file_list: tuple, project_id, filter=None, output_file=None):
-    return GetParticipantUUIDsForProjectCached(tuple(nidm_file_list), project_id, filter, output_file)
+
+def GetParticipantUUIDsForProject(
+    nidm_file_list: tuple, project_id, filter=None, output_file=None  # noqa: A002
+):
+    return GetParticipantUUIDsForProjectCached(
+        tuple(nidm_file_list), project_id, filter, output_file
+    )
+
 
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
-def GetParticipantUUIDsForProjectCached(nidm_file_list:tuple, project_id, filter=None, output_file=None):
-    '''
+def GetParticipantUUIDsForProjectCached(
+    nidm_file_list: tuple,
+    project_id,
+    filter=None,  # noqa: A002
+    output_file=None,  # noqa: U100
+):
+    """
     This query will return a list of all prov:agent entity UUIDs within a single project
     that prov:hadRole sio:Subject or Constants.NIDM_PARTICIPANT
     :param filter:
     :param nidm_file_list: List of one or more NIDM files to query across for list of Projects
     :return: list of Constants.NIDM_PARTICIPANT UUIDs and Constants.NIDM_SUBJECTID
-    '''
+    """
 
     # if this isn't already a URI, make it one.
     # calls from the REST api don't include the URI
     project = project_id
-    if project_id.find('http') < 0:
+    if project_id.find("http") < 0:
         project = Constants.NIIRI[project_id]
 
     ### added by DBK changed to dictionary to support subject ids along with uuids
-    #participants = []
+    # participants = []
     participants = {}
     participants["uuid"] = []
     participants["subject id"] = []
 
-
     for file in nidm_file_list:
         rdf_graph = OpenGraph(file)
-        #find all the sessions
-        for (session, p, o) in rdf_graph.triples((None, None, Constants.NIDM['Session'])): #rdf_graph.subjects(object=isa, predicate=Constants.NIDM['Session']):
-            #check if it is part of our project
-            if (session, Constants.DCT['isPartOf'], project) in rdf_graph:
-                #find all the activities/acquisitions/etc that are part of this session
-                for activity in rdf_graph.subjects(predicate=Constants.DCT['isPartOf'], object=session):
+        # find all the sessions
+        for session, _, _ in rdf_graph.triples(
+            (None, None, Constants.NIDM["Session"])
+        ):  # rdf_graph.subjects(object=isa, predicate=Constants.NIDM['Session']):
+            # check if it is part of our project
+            if (session, Constants.DCT["isPartOf"], project) in rdf_graph:
+                # find all the activities/acquisitions/etc that are part of this session
+                for activity in rdf_graph.subjects(
+                    predicate=Constants.DCT["isPartOf"], object=session
+                ):
                     # look to see if the activity is linked to a subject via blank node
-                    for blank in rdf_graph.objects(subject=activity, predicate=Constants.PROV['qualifiedAssociation']):
-                        if (blank, Constants.PROV['hadRole'], Constants.SIO['Subject']):
-                            for participant in rdf_graph.objects(subject=blank, predicate=Constants.PROV['agent']):
-                                uuid = (str(participant)).split('/')[-1]  # strip off the http://whatever/whatever/
-                                if (not uuid in participants) and \
-                                        ( (not filter) or CheckSubjectMatchesFilter( tuple([file]) , project, participant, filter) ):
+                    for blank in rdf_graph.objects(
+                        subject=activity,
+                        predicate=Constants.PROV["qualifiedAssociation"],
+                    ):
+                        if (
+                            blank,
+                            Constants.PROV["hadRole"],
+                            Constants.SIO["Subject"],
+                        ) in rdf_graph:
+                            for participant in rdf_graph.objects(
+                                subject=blank, predicate=Constants.PROV["agent"]
+                            ):
+                                uuid = (str(participant)).split("/")[
+                                    -1
+                                ]  # strip off the http://whatever/whatever/
+                                if (uuid not in participants) and (
+                                    (not filter)
+                                    or CheckSubjectMatchesFilter(
+                                        tuple([file]), project, participant, filter
+                                    )
+                                ):
                                     ### added by DBK for subject IDs as well ###
-                                    for id in rdf_graph.objects(subject=participant,predicate=URIRef(Constants.NIDM_SUBJECTID.uri)):
-                                        subid = (str(id)).split('/')[-1]  # strip off the http://whatever/whatever/
+                                    for id_ in rdf_graph.objects(
+                                        subject=participant,
+                                        predicate=URIRef(Constants.NIDM_SUBJECTID.uri),
+                                    ):
+                                        subid = (str(id_)).split("/")[
+                                            -1
+                                        ]  # strip off the http://whatever/whatever/
 
                                         ### added by DBK for subject IDs as well ###
-                                        #participants.append(uuid)
-                                        if ( not uuid in participants['uuid'] ):
+                                        # participants.append(uuid)
+                                        if uuid not in participants["uuid"]:
                                             try:
-                                                participants['uuid'].append(uuid)
-                                                participants['subject id'].append(subid)
+                                                participants["uuid"].append(uuid)
+                                                participants["subject id"].append(subid)
                                             # just in case there's no subject id in the file...
-                                            except:
-                                                #participants.append(uuid)
-                                                participants['uuid'].append(uuid)
-                                                participants['subject id'].append('')
+                                            except Exception:
+                                                # participants.append(uuid)
+                                                participants["uuid"].append(uuid)
+                                                participants["subject id"].append("")
 
     return participants
 
 
 # if this isn't already a URI, make it one.
 # calls from the REST api don't include the URI
 def expandUUID(partial_uuid):
-    '''
+    """
     Expands a uuid (which is the local part of a qname) to the proper full URI
     :param partial_uuid: UUID without the initial URI
     :return: full URI of UUID
-    '''
+    """
     uuid = partial_uuid
-    if partial_uuid.find('http') < 0:
+    if partial_uuid.find("http") < 0:
         uuid = Constants.NIIRI[partial_uuid]
     return uuid
 
 
 def getProjectAcquisitionObjects(nidm_file_list, project_id):
     acq_objects = []
-    isa = URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')
+    isa = URIRef("http://www.w3.org/1999/02/22-rdf-syntax-ns#type")
     project_uuid = expandUUID(project_id)
 
     for file in nidm_file_list:
         rdf_graph = OpenGraph(file)
-        #find all the projects
-        for (project,pred,o) in rdf_graph.triples((None, None, Constants.NIDM['Project'])):
-            #check if it is our project
+        # find all the projects
+        for project, _, _ in rdf_graph.triples((None, None, Constants.NIDM["Project"])):
+            # check if it is our project
             if str(project) == project_uuid:
-                for (session,p2,o2) in rdf_graph.triples((None,isa, Constants.NIDM['Session'])):
-                    for (acquisition,p3,o3) in rdf_graph.triples((None, Constants.DCT['isPartOf'], session)):
-                        for (acq_obj, p4, o4) in rdf_graph.triples((None, Constants.PROV['wasGeneratedBy'], acquisition)):
-                            if (acq_obj, isa, Constants.NIDM['AcquisitionObject']):
+                for session, _, _ in rdf_graph.triples(
+                    (None, isa, Constants.NIDM["Session"])
+                ):
+                    for acquisition, _, _ in rdf_graph.triples(
+                        (None, Constants.DCT["isPartOf"], session)
+                    ):
+                        for acq_obj, _, _ in rdf_graph.triples(
+                            (None, Constants.PROV["wasGeneratedBy"], acquisition)
+                        ):
+                            if (
+                                acq_obj,
+                                isa,
+                                Constants.NIDM["AcquisitionObject"],
+                            ) in rdf_graph:
                                 acq_objects.append(acq_obj)
     return acq_objects
 
+
 @functools.lru_cache(maxsize=LARGEST_CACHE_SIZE)
 def GetDatatypeSynonyms(nidm_file_list, project_id, datatype):
-    '''
+    """
     Try to match a datatype string with any of the known info about a data element
     Returns all the possible synonyms for that datatype
     For example, if AGE_AT_SCAN is a data element prefix, return the label, datumType, measureOf URI, prefix, etc.
 
     :param nidm_file_list:
     :param project_id:
     :param datatype:
     :return:
-    '''
+    """
     if datatype.startswith("instruments."):
         datatype = datatype[12:]
     if datatype.startswith("derivatives."):
         datatype = datatype[12:]
     project_data_elements = GetProjectDataElements(nidm_file_list, project_id)
     all_synonyms = set([datatype])
-    for dti in project_data_elements['data_type_info']:
-        #modified by DBK 7/25/2022
+    for dti in project_data_elements["data_type_info"]:
+        # modified by DBK 7/25/2022
         # if str(datatype) in [ str(x) for x in [dti['source_variable'], dti['label'], dti['datumType'], dti['measureOf'], URITail(dti['measureOf']), str(dti['isAbout']), URITail(dti['isAbout']), dti['dataElement'], dti['dataElementURI'], dti['prefix']] ]:
-        if (any(str(datatype) in str(x) for x in
-            [dti['source_variable'], dti['label'], dti['datumType'], dti['measureOf'], URITail(dti['measureOf']),
-             str(dti['isAbout']), URITail(dti['isAbout']), dti['dataElement'], dti['dataElementURI'], dti['prefix']])):
-            all_synonyms = all_synonyms.union(set([str(dti['source_variable']), str(dti['label']), str(dti['datumType']), str(dti['measureOf']), URITail(dti['measureOf']), str(dti['isAbout']), str(dti['dataElement']), str(dti['dataElementURI'])] ))
+        if any(
+            str(datatype) in str(x)
+            for x in [
+                dti["source_variable"],
+                dti["label"],
+                dti["datumType"],
+                dti["measureOf"],
+                URITail(dti["measureOf"]),
+                str(dti["isAbout"]),
+                URITail(dti["isAbout"]),
+                dti["dataElement"],
+                dti["dataElementURI"],
+                dti["prefix"],
+            ]
+        ):
+            all_synonyms = all_synonyms.union(
+                set(
+                    [
+                        str(dti["source_variable"]),
+                        str(dti["label"]),
+                        str(dti["datumType"]),
+                        str(dti["measureOf"]),
+                        URITail(dti["measureOf"]),
+                        str(dti["isAbout"]),
+                        str(dti["dataElement"]),
+                        str(dti["dataElementURI"]),
+                    ]
+                )
+            )
             all_synonyms.remove("")  # remove the empty string in case that is in there
     return all_synonyms
 
+
 def GetProjectDataElements(nidm_file_list, project_id):
     ### added by DBK...changing to dictionary to support labels along with uuids
-    #result = []
+    # result = []
     result = {}
     result["uuid"] = []
-    result['label']= []
-    result['data_type_info'] = []
-    isa = URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')
+    result["label"] = []
+    result["data_type_info"] = []
+    isa = URIRef("http://www.w3.org/1999/02/22-rdf-syntax-ns#type")
 
     # if this isn't already a URI, make it one.
     # calls from the REST api don't include the URI
     project = project_id
-    if project_id.find('http') < 0:
+    if project_id.find("http") < 0:
         project = Constants.NIIRI[project_id]
 
     for file in nidm_file_list:
         rdf_graph = OpenGraph(file)
-        #find all the sessions
-        for (session, cde_tuple, o) in rdf_graph.triples((None, None, Constants.NIDM['Session'])): #rdf_graph.subjects(object=isa, predicate=Constants.NIDM['Session']):
-            #check if it is part of our project
-            if (session, Constants.DCT['isPartOf'], project) in rdf_graph:
+        # find all the sessions
+        for session, cde_tuple, _ in rdf_graph.triples(
+            (None, None, Constants.NIDM["Session"])
+        ):  # rdf_graph.subjects(object=isa, predicate=Constants.NIDM['Session']):
+            # check if it is part of our project
+            if (session, Constants.DCT["isPartOf"], project) in rdf_graph:
                 # we know we have the right file, so just grab all the data elements from here
-                for de in rdf_graph.subjects(isa, Constants.NIDM['DataElement']):
+                for de in rdf_graph.subjects(isa, Constants.NIDM["DataElement"]):
                     ### added by DBK to return label as well as UUID
-                    #result.append(rdf_graph.namespace_manager.compute_qname(str(de))[2])
-                    for label in rdf_graph.objects(subject=de, predicate=Constants.RDFS['label']):
-                        #result.append(rdf_graph.namespace_manager.compute_qname(str(de))[2] + "=" + label)
-                        result["uuid"].append(rdf_graph.namespace_manager.compute_qname(str(de))[2])
+                    # result.append(rdf_graph.namespace_manager.compute_qname(str(de))[2])
+                    for label in rdf_graph.objects(
+                        subject=de, predicate=Constants.RDFS["label"]
+                    ):
+                        # result.append(rdf_graph.namespace_manager.compute_qname(str(de))[2] + "=" + label)
+                        result["uuid"].append(
+                            rdf_graph.namespace_manager.compute_qname(str(de))[2]
+                        )
                         result["label"].append(label)
                         result["data_type_info"].append(getDataTypeInfo(rdf_graph, de))
                 ### added by DBK...we should also look for data elements that are sub-classes of Constants.NIDM['DataElement']
                 ### to include any freesurfer, fsl, or ants data elements
-                for subclass in rdf_graph.subjects(predicate=Constants.RDFS["subClassOf"],object=Constants.NIDM['DataElement']):
+                for subclass in rdf_graph.subjects(
+                    predicate=Constants.RDFS["subClassOf"],
+                    object=Constants.NIDM["DataElement"],
+                ):
                     for de in rdf_graph.subjects(isa, subclass):
                         # and let's return the labels as well to make things more readable.
-                        for label in rdf_graph.objects(subject=de, predicate=Constants.RDFS['label']):
-                            #result.append(rdf_graph.namespace_manager.compute_qname(str(de))[2] + "=" + label)
-                            result["uuid"].append(rdf_graph.namespace_manager.compute_qname(str(de))[2])
+                        for label in rdf_graph.objects(
+                            subject=de, predicate=Constants.RDFS["label"]
+                        ):
+                            # result.append(rdf_graph.namespace_manager.compute_qname(str(de))[2] + "=" + label)
+                            result["uuid"].append(
+                                rdf_graph.namespace_manager.compute_qname(str(de))[2]
+                            )
                             result["label"].append(label)
-                            result["data_type_info"].append(getDataTypeInfo(rdf_graph, de))
+                            result["data_type_info"].append(
+                                getDataTypeInfo(rdf_graph, de)
+                            )
 
                 # Since common data elements won't have entries in the main graph, try to find them also
                 cde_set = set()
-                for stat_collection in rdf_graph.subjects(isa, Constants.NIDM['FSStatsCollection']):
+                for stat_collection in rdf_graph.subjects(
+                    isa, Constants.NIDM["FSStatsCollection"]
+                ):
                     for predicate in rdf_graph.predicates(subject=stat_collection):
                         dti = getDataTypeInfo(None, predicate)
                         if dti:
-                            cde_tuple = (predicate,  dti["label"])
-                            cde_set.add( cde_tuple )
+                            cde_tuple = (predicate, dti["label"])
+                            cde_set.add(cde_tuple)
 
                 for cde in cde_set:
                     result["uuid"].append(cde[0])
                     result["label"].append(cde[1])
                     result["data_type_info"].append(getDataTypeInfo(rdf_graph, cde[0]))
 
                 return result
     return result
 
 
 # in case someone passes in a filter subject with a full http or https URI, strip it back to just the bit after the namespace
 def splitSubject(subject):
     if subject.find("http") > -1:
-        matches = re.match(r'.*(https?://[^/]+[^\. ]+)', subject)
+        matches = re.match(r".*(https?://[^/]+[^\. ]+)", subject)
         URI = matches.group(1)
         subject = str(subject).replace(URI, URITail(URI))
 
     return subject.split(".")
 
+
 def URITail(URI):
-    '''
+    """
     Returns the last bit of a URI.
     Useful for pulling out datatype from long namespaces , e.g. http://purl.org/nidash/fsl#fsl_000032
     :param URI: string
     :return: string
-    '''
-    tail = URI.split('/')[-1]
-    tail = tail.split('#')[-1]
-    return  tail
+    """
+    tail = URI.split("/")[-1]
+    tail = tail.split("#")[-1]
+    return tail
+
 
 def trimWellKnownURIPrefix(uri):
-    trimed = uri
-    for p in ['http://purl.org/nidash/nidm#', 'http://www.w3.org/ns/prov#', 'http://iri.nidash.org/']:
-        trimed = str(trimed).replace(p, '')
-    return trimed
+    trimmed = uri
+    for p in [
+        "http://purl.org/nidash/nidm#",
+        "http://www.w3.org/ns/prov#",
+        "http://iri.nidash.org/",
+    ]:
+        trimmed = str(trimmed).replace(p, "")
+    return trimmed
+
 
-def CheckSubjectMatchesFilter(nidm_file_list, project_uuid, subject_uuid, filter):
-    '''
+def CheckSubjectMatchesFilter(
+    nidm_file_list, project_uuid, subject_uuid, filter  # noqa: A002
+):
+    """
     filter should look something like:
        instruments.AGE gt 12 and instruments.SITE_ID eq CMU
 
     :param nidm_file_list:
     :param project_uuid:
     :param subject_uuid:
     :param filter:
     :return:
-    '''
-
+    """
 
-    if filter == None:
+    if filter is None:
         return True
 
     # filter can have multiple and clauses, break them up and test each one
-    tests = filter.split('and')
-
-
+    tests = filter.split("and")
 
     for test in tests:
         found_match = False
-        split_array = test.split(' ')
+        split_array = test.split(" ")
         # TODO: I need to fix this here.  When there is a space inside the value the splitter gets more than 3 values
         # ex: 'projects.subjects.instruments.WISC_IV_VOCAB_SCALED eq \'not a match\''
         # in this case we must have spaces in identifier: 'projects.subjects.instruments.age at scan eq 21
         # not guaranteed to always be an 'eq' separator.
         # TODO: Make more robust!
-        #if len(split_array) > 3:
+        # if len(split_array) > 3:
         #    split_array = test.split('eq')
         #    compound_sub = split_array[0]
         #    op = 'eq'
         #    value = ' '.join(split_array[1:])
-        #else:
+        # else:
         compound_sub = split_array[0]
         op = split_array[1]
-        value = ' '.join(split_array[2:])
+        value = " ".join(split_array[2:])
 
-        #if the value is a string, it will have quotes around it.  Strip them out now
-        for quote in ["'", "\"", "`"]:
+        # if the value is a string, it will have quotes around it.  Strip them out now
+        for quote in ["'", '"', "`"]:
             if value[0] == quote and value[-1] == quote:
                 value = value[1:-1]
 
         sub_pieces = splitSubject(compound_sub)
 
         # figure out what we are filtering on
         term = None
         if len(sub_pieces) == 1:
             # no instruments or derivatives prefix was entered, so test in both
             term = sub_pieces[0]
 
-        if (len(sub_pieces) == 2 and sub_pieces[0] == 'instruments') or len(sub_pieces) == 1:
+        if (len(sub_pieces) == 2 and sub_pieces[0] == "instruments") or len(
+            sub_pieces
+        ) == 1:
             if len(sub_pieces) == 2:
-                term = sub_pieces[1] # 'AGE_AT_SCAN' for example
+                term = sub_pieces[1]  # 'AGE_AT_SCAN' for example
             synonyms = GetDatatypeSynonyms(tuple(nidm_file_list), project_uuid, term)
-            instrument_details = GetParticipantInstrumentData(nidm_file_list, project_uuid, subject_uuid)
-            for instrument_uuid in instrument_details:
-                for instrument_term in instrument_details[instrument_uuid]:
+            instrument_details = GetParticipantInstrumentData(
+                nidm_file_list, project_uuid, subject_uuid
+            )
+            for terms in instrument_details.values():
+                for instrument_term, v in terms.items():
                     if instrument_term in synonyms:
-                        found_match = filterCompare(instrument_details[instrument_uuid][instrument_term], op, value)
+                        found_match = filterCompare(v, op, value)
                     if found_match:
                         break
 
-        if (len(sub_pieces) == 2 and sub_pieces[0] == 'derivatives') or len(sub_pieces) == 1:
+        if (len(sub_pieces) == 2 and sub_pieces[0] == "derivatives") or len(
+            sub_pieces
+        ) == 1:
             if len(sub_pieces) == 2:
-                term = sub_pieces[1] # 'ilx:0102597' for example
-            derivatives_details = GetDerivativesDataForSubject(nidm_file_list, project_uuid, subject_uuid)
-            for key in derivatives_details:
-                derivatives = derivatives_details[key]['values']
-                for vkey in derivatives:  # values will be in the form { http://example.com/a/b/c#fs_00001 : { datumType: '', label: '', value: '', units:'' }, ... }
+                term = sub_pieces[1]  # 'ilx:0102597' for example
+            derivatives_details = GetDerivativesDataForSubject(
+                nidm_file_list, project_uuid, subject_uuid
+            )
+            for details in derivatives_details.values():
+                derivatives = details["values"]
+                for (
+                    vkey
+                ) in (
+                    derivatives
+                ):  # values will be in the form { http://example.com/a/b/c#fs_00001 : { datumType: '', label: '', value: '', units:'' }, ... }
                     short_key = URITail(vkey)
                     if short_key == term:
-                        found_match = filterCompare(derivatives[vkey]['value'], op, value)
+                        found_match = filterCompare(
+                            derivatives[vkey]["value"], op, value
+                        )
                     if found_match:
                         break
 
         # check after each test if we got false because the tests are joined with 'and'
         if not found_match:
             return False
 
     return True
 
+
 def filterCompare(left, op, right):
     try:
-        if op == 'eq':
-            return (left == right)
-        elif op == 'lt':
-            return (float(left) < float(right))
-        elif op == 'gt':
-            return (float(left) > float(right))
-    except:
+        if op == "eq":
+            return left == right
+        elif op == "lt":
+            return float(left) < float(right)
+        elif op == "gt":
+            return float(left) > float(right)
+    except Exception:
         pass
 
     return None
 
+
 def GetProjectsMetadata(nidm_file_list):
-    '''
+    """
      :param nidm_file_list: List of one or more NIDM files to query for project meta data
     :return: dataframe with two columns: "project_uuid" and "project_dentifier"
-    '''
+    """
 
-    query = '''
+    query = """
         PREFIX sio: <http://semanticscience.org/ontology/sio.owl#>
         PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
         PREFIX nidm:<http://purl.org/nidash/nidm#>
          SELECT DISTINCT ?property ?o ?s WHERE {{ ?s a nidm:Project . ?s ?property ?o }}
-    '''
+    """
     df = sparql_query_nidm(nidm_file_list, query, output_file=None)
 
     projects = {}
     arr = df.values
 
     for row in arr:
         field = str(row[0])
         value = str(row[1])
         project = str(row[2])
         if project not in projects:
             projects[str(project)] = {}
         # if field in field_whitelist:
         projects[str(project)][field] = value
 
-    return {'projects': compressForJSONResponse(projects)}
+    return {"projects": compressForJSONResponse(projects)}
 
 
 # def GetProjectsComputedMetadata(nidm_file_list):
 #     '''
 #      :param nidm_file_list: List of one or more NIDM files to query across for list of Projects
 #     :return: dataframe with two columns: "project_uuid" and "project_dentifier"
 #     '''
 #
 #     meta_data = GetProjectsMetadata(nidm_file_list)
 #     ExtractProjectSummary(meta_data, nidm_file_list)
 #
 #     return compressForJSONResponse(meta_data)
 
-def GetDataElements(nidm_file_list):
 
-    query='''
+def GetDataElements(nidm_file_list):
+    query = """
         select distinct ?uuid ?DataElements
             where {
 
                 ?uuid a ?DataElements
 
                 filter( regex(str(?DataElements), "DataElement" ))
 
-            }'''
+            }"""
 
-    df = sparql_query_nidm(nidm_file_list.split(','), query, output_file=None)
+    df = sparql_query_nidm(nidm_file_list.split(","), query, output_file=None)
     return df
+
+
 def GetBrainVolumeDataElements(nidm_file_list):
-    query='''
+    query = """
         prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
         prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>
         prefix prov: <http://www.w3.org/ns/prov#>
         prefix ndar: <https://ndar.nih.gov/api/datadictionary/v2/dataelement/>
         prefix fsl: <http://purl.org/nidash/fsl#>
         prefix nidm: <http://purl.org/nidash/nidm#>
         prefix onli: <http://neurolog.unice.fr/ontoneurolog/v3.0/instrument.owl#>
@@ -929,49 +1022,50 @@
         prefix dx: <http://ncitt.ncit.nih.gov/Diagnosis>
         prefix ants: <http://stnava.github.io/ANTs/>
         prefix dct: <http://purl.org/dc/terms/>
         prefix dctypes: <http://purl.org/dc/dcmitype/>
 
         SELECT DISTINCT ?element_id ?tool ?softwareLabel ?federatedLabel ?laterality
         where {
- 	        ?tool_act a prov:Activity ;
-		            prov:qualifiedAssociation [prov:agent [nidm:NIDM_0000164 ?tool]] .
-			?tool_entity prov:wasGeneratedBy ?tool_act ;
-				?element_id ?volume .
-
-			{?element_id a fsl:DataElement ;
-				    rdfs:label ?softwareLabel;
-				    nidm:measureOf <http://uri.interlex.org/base/ilx_0112559> ;
-				    nidm:datumType <http://uri.interlex.org/base/ilx_0738276> ;
-			}
-			UNION
-			{?element_id a freesurfer:DataElement ;
-				    rdfs:label ?softwareLabel;
-				    nidm:measureOf <http://uri.interlex.org/base/ilx_0112559> ;
-				    nidm:datumType <http://uri.interlex.org/base/ilx_0738276> ;
-			}
-			UNION
-			{?element_id a ants:DataElement ;
-				    rdfs:label ?softwareLabel;
-				    nidm:measureOf <http://uri.interlex.org/base/ilx_0112559> ;
-				    nidm:datumType <http://uri.interlex.org/base/ilx_0738276> ;
-			}
-			OPTIONAL {?element_id nidm:isAbout ?federatedLabel }.
-			OPTIONAL {?element_id nidm:hasLaterality ?laterality }.
-		}'''
+                ?tool_act a prov:Activity ;
+                            prov:qualifiedAssociation [prov:agent [nidm:NIDM_0000164 ?tool]] .
+                        ?tool_entity prov:wasGeneratedBy ?tool_act ;
+                                ?element_id ?volume .
+
+                        {?element_id a fsl:DataElement ;
+                                    rdfs:label ?softwareLabel;
+                                    nidm:measureOf <http://uri.interlex.org/base/ilx_0112559> ;
+                                    nidm:datumType <http://uri.interlex.org/base/ilx_0738276> ;
+                        }
+                        UNION
+                        {?element_id a freesurfer:DataElement ;
+                                    rdfs:label ?softwareLabel;
+                                    nidm:measureOf <http://uri.interlex.org/base/ilx_0112559> ;
+                                    nidm:datumType <http://uri.interlex.org/base/ilx_0738276> ;
+                        }
+                        UNION
+                        {?element_id a ants:DataElement ;
+                                    rdfs:label ?softwareLabel;
+                                    nidm:measureOf <http://uri.interlex.org/base/ilx_0112559> ;
+                                    nidm:datumType <http://uri.interlex.org/base/ilx_0738276> ;
+                        }
+                        OPTIONAL {?element_id nidm:isAbout ?federatedLabel }.
+                        OPTIONAL {?element_id nidm:hasLaterality ?laterality }.
+                }"""
 
-    df = sparql_query_nidm(nidm_file_list.split(','), query, output_file=None)
+    df = sparql_query_nidm(nidm_file_list.split(","), query, output_file=None)
     # now let's strip off the
-    for index, row in df.iterrows():
-        tmp = row['element_id']
-        row['element_id'] = re.search(r'(.*)/(.*)',tmp).group(2)
+    for _, row in df.iterrows():
+        tmp = row["element_id"]
+        row["element_id"] = re.search(r"(.*)/(.*)", tmp).group(2)
     return df
 
+
 def GetBrainVolumes(nidm_file_list):
-    query='''
+    query = """
         # This query simply returns the brain volume data without dependencies on other demographics/assessment measures.
 
         prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
         prefix prov: <http://www.w3.org/ns/prov#>
         prefix ndar: <https://ndar.nih.gov/api/datadictionary/v2/dataelement/>
         prefix fsl: <http://purl.org/nidash/fsl#>
         prefix nidm: <http://purl.org/nidash/nidm#>
@@ -981,378 +1075,415 @@
         prefix ants: <http://stnava.github.io/ANTs/>
         prefix dct: <http://purl.org/dc/terms/>
         prefix dctypes: <http://purl.org/dc/dcmitype/>
         prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>
 
         select distinct ?ID ?tool ?softwareLabel ?federatedLabel ?laterality ?volume
         where {
- 	        ?tool_act a prov:Activity ;
-		            prov:qualifiedAssociation [prov:agent [nidm:NIDM_0000164 ?tool]] .
-			?tool_act prov:qualifiedAssociation [prov:agent [ndar:src_subject_id ?ID]] .
-			?tool_entity prov:wasGeneratedBy ?tool_act ;
-				?measure ?volume .
-
-				?tool_entity prov:wasGeneratedBy ?tool_act ;
-					?measure ?volume .
-
-					?measure a/rdfs:subClassOf* nidm:DataElement ;
-						 rdfs:label ?softwareLabel;
-						 nidm:measureOf <http://uri.interlex.org/base/ilx_0112559> ;
-						 nidm:datumType <http://uri.interlex.org/base/ilx_0738276> .
-					OPTIONAL {?measure nidm:isAbout ?federatedLabel }.
-					OPTIONAL {?measure nidm:hasLaterality ?laterality }.
+                ?tool_act a prov:Activity ;
+                            prov:qualifiedAssociation [prov:agent [nidm:NIDM_0000164 ?tool]] .
+                        ?tool_act prov:qualifiedAssociation [prov:agent [ndar:src_subject_id ?ID]] .
+                        ?tool_entity prov:wasGeneratedBy ?tool_act ;
+                                ?measure ?volume .
+
+                                ?tool_entity prov:wasGeneratedBy ?tool_act ;
+                                        ?measure ?volume .
+
+                                        ?measure a/rdfs:subClassOf* nidm:DataElement ;
+                                                 rdfs:label ?softwareLabel;
+                                                 nidm:measureOf <http://uri.interlex.org/base/ilx_0112559> ;
+                                                 nidm:datumType <http://uri.interlex.org/base/ilx_0738276> .
+                                        OPTIONAL {?measure nidm:isAbout ?federatedLabel }.
+                                        OPTIONAL {?measure nidm:hasLaterality ?laterality }.
 
             }
-            '''
+            """
 
-    df = sparql_query_nidm(nidm_file_list.split(','), query, output_file=None)
+    df = sparql_query_nidm(nidm_file_list.split(","), query, output_file=None)
     return df
 
 
-
 def expandNIDMAbbreviation(shortKey) -> str:
-    '''
-    Takes a shorthand identifier such as dct:description and returns the 
+    """
+    Takes a shorthand identifier such as dct:description and returns the
     full URI http://purl.org/dc/terms/description
 
     :param shortKey:
     :type shortKey: str
     :return:
-    '''
+    """
     newkey = skey = str(shortKey)
     match = re.search(r"^([^:]+):([^:]+)$", skey)
     if match:
         newkey = Constants.namespaces[match.group(1)] + match.group(2)
     return newkey
 
+
 def compressForJSONResponse(data) -> dict:
-    '''
+    """
     Takes a Dictionary and shortens any key by replacing a full URI with
     the NIDM prefix
 
-    :param data: Data to seach for long URIs that can be replaced with prefixes
+    :param data: Data to search for long URIs that can be replaced with prefixes
     :return: Dictionary
-    '''
+    """
     new_dict = {}
 
-    if isinstance(data,dict):
+    if isinstance(data, dict):
         for key, value in data.items():
             new_dict[matchPrefix(key)] = compressForJSONResponse(value)
     else:
         return data
 
     return new_dict
 
+
 def matchPrefix(possible_URI, short=False) -> str:
-    '''
+    """
     If the possible_URI is found in Constants.namespaces it will
     be replaced with the prefix
 
     :param possible_URI: URI string to look at
     :type possible_URI: str
     :return: Returns a
-    '''
+    """
     for k, n in Constants.namespaces.items():
         if possible_URI.startswith(n):
             if short:
                 return k
             else:
-                return "{}:{}".format(k, possible_URI.replace(n, ""))
+                return f"{k}:{possible_URI.replace(n, '')}"
 
     # also check the prov prefix
     if possible_URI.startswith("http://www.w3.org/ns/prov#"):
-        return "{}:{}".format("prov", possible_URI.replace("http://www.w3.org/ns/prov#", ""))
+        return f"prov:{possible_URI.replace('http://www.w3.org/ns/prov#', '')}"
 
     return possible_URI
 
+
 # check if this activity is linked by a blank node to one of the sw agents
-def activityIsSWAgent(rdf_graph, activity, sw_agents):
-    '''
+def activityIsSWAgent(rdf_graph, activity, sw_agents):  # noqa: U100
+    """
     Returns True if the given activity is associated with a software agent from the sw_agents array
     :param rdf_graph: Graph
     :param activity: activity URI
     :param sw_agents: array of software agent URIs
     :return: Boolean
-    '''
+    """
     if activity in sw_agents:
         return True
 
     return False
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
-def getDerivativesNodesForSubject (rdf_graph, subject):
-    '''
+def getDerivativesNodesForSubject(rdf_graph, subject):
+    """
     Finds all the URIs that were generated by software agents and linked to the subject
 
     :param rdf_graph:
     :param subject:
     :return: Array of StatsCollections URIs
-    '''
-
-    qualified_association = URIRef('http://www.w3.org/ns/prov#qualifiedAssociation')
-    was_associated_with = URIRef('http://www.w3.org/ns/prov#wasAssociatedWith')
+    """
 
     sw_agents = getSoftwareAgents(rdf_graph)
     derivatives_uris = []
 
-    for blank, p, o in rdf_graph.triples( (None, Constants.PROV['agent'], subject)): # get the blank nodes associated with the subject
+    for blank, _, _ in rdf_graph.triples(
+        (None, Constants.PROV["agent"], subject)
+    ):  # get the blank nodes associated with the subject
         # verify this blank node points to the subject somewhere it has the  role subject
-        if (blank, Constants.PROV['hadRole'], Constants.SIO['Subject']) in rdf_graph:
+        if (blank, Constants.PROV["hadRole"], Constants.SIO["Subject"]) in rdf_graph:
             # get the activity that's the parent of the blank node
-            for activity in rdf_graph.subjects(predicate=Constants.PROV['qualifiedAssociation'], object=blank):
+            for activity in rdf_graph.subjects(
+                predicate=Constants.PROV["qualifiedAssociation"], object=blank
+            ):
                 # try to find if this activity has a qualified association with a software agent (through a blank node)
-                for software_blank in rdf_graph.objects(subject=activity, predicate=Constants.PROV['qualifiedAssociation']):
-                    for software_agent in rdf_graph.objects(subject=software_blank, predicate=Constants.PROV['agent']):
+                for software_blank in rdf_graph.objects(
+                    subject=activity, predicate=Constants.PROV["qualifiedAssociation"]
+                ):
+                    for software_agent in rdf_graph.objects(
+                        subject=software_blank, predicate=Constants.PROV["agent"]
+                    ):
                         if activityIsSWAgent(rdf_graph, software_agent, sw_agents):
-                            # now we know our activity generated a stats colleciton, so go find it (the stats_colleciton will be generated by the activity)
-                            for stats_collection in rdf_graph.subjects(predicate=Constants.PROV['wasGeneratedBy'], object=activity):
+                            # now we know our activity generated a stats collection, so go find it (the stats_colleciton will be generated by the activity)
+                            for stats_collection in rdf_graph.subjects(
+                                predicate=Constants.PROV["wasGeneratedBy"],
+                                object=activity,
+                            ):
                                 derivatives_uris.append(stats_collection)
 
     return derivatives_uris
 
+
 @functools.lru_cache(maxsize=LARGEST_CACHE_SIZE)
 def getDataTypeInfo(source_graph, datatype):
-    '''
+    """
     Scans all the triples with subject of datatype (isa DataElement in the graph) and looks for entries
     with specific predicates necessary to define it's type
 
     :param rdf_graph:
     :param dt: URI of the DataElement
     :return: { 'label': label, 'hasUnit': hasUnit, 'typeURI': typeURI}
-    '''
-    isa = URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')
-
+    """
+    isa = URIRef("http://www.w3.org/1999/02/22-rdf-syntax-ns#type")
 
     expanded_datatype = datatype
-    if expanded_datatype.find('http') < 0:
+    if expanded_datatype.find("http") < 0:
         expanded_datatype = Constants.NIIRI[expanded_datatype]
 
-
     # check to see if the datatype is in the main graph. If not, look in the CDE graph
-    if source_graph and  (expanded_datatype, isa, Constants.NIDM['DataElement']) in source_graph:
+    if (
+        source_graph
+        and (expanded_datatype, isa, Constants.NIDM["DataElement"]) in source_graph
+    ):
         rdf_graph = source_graph
     # check if datatype is a personal data element
-    elif source_graph and  (expanded_datatype, isa, Constants.NIDM['PersonalDataElement']) in source_graph:
+    elif (
+        source_graph
+        and (expanded_datatype, isa, Constants.NIDM["PersonalDataElement"])
+        in source_graph
+    ):
         rdf_graph = source_graph
     else:
         rdf_graph = nidm.experiment.CDE.getCDEs()
 
-    typeURI = ''
-    hasUnit = ''
-    label = ''
-    description = ''
-    measureOf = ''
-    isAbout = ''
-    structure = ''
-    prefix = ''
-    source_variable = ''
-
-    found = False
+    typeURI = ""
+    hasUnit = ""
+    label = ""
+    description = ""
+    measureOf = ""
+    isAbout = ""
+    prefix = ""
+    source_variable = ""
 
+    found = None
 
     # have to scan all tripples because the label can be in any namespace
     for s, p, o in rdf_graph.triples((expanded_datatype, None, None)):
-        found = True
-        if (re.search(r'label$', str(p)) != None):
+        found = s
+        if re.search(r"label$", str(p)) is not None:
             label = o
-        if (re.search(r'source_variable$', str(p)) != None):
+        if re.search(r"source_variable$", str(p)) is not None:
             source_variable = o
-        elif (re.search(r'sourceVariable$', str(p)) != None):
+        elif re.search(r"sourceVariable$", str(p)) is not None:
             source_variable = o
-        if (re.search(r'description$', str(p)) != None):
+        if re.search(r"description$", str(p)) is not None:
             description = o
-        if (re.search(r'hasUnit$', str(p), flags=re.IGNORECASE) != None):
+        if re.search(r"hasUnit$", str(p), flags=re.IGNORECASE) is not None:
             hasUnit = o
-        if (re.search(r'datumType$', str(p)) != None):
-            typeURI = str(o).split('/')[-1]
-        if (re.search(r'measureOf$', str(p)) != None):
+        if re.search(r"datumType$", str(p)) is not None:
+            typeURI = str(o).split("/")[-1]
+        if re.search(r"measureOf$", str(p)) is not None:
             measureOf = o
-        if (re.search(r'isAbout$', str(p), flags=re.IGNORECASE) != None):
+        if re.search(r"isAbout$", str(p), flags=re.IGNORECASE) is not None:
             isAbout = o
 
-    possible_prefix = [x for x in rdf_graph.namespaces() if expanded_datatype.startswith(x[1])]
-    if (len(possible_prefix) > 0):
+    possible_prefix = [
+        x for x in rdf_graph.namespaces() if expanded_datatype.startswith(x[1])
+    ]
+    if len(possible_prefix) > 0:
         prefix = possible_prefix[0][0]
 
-
-    if not found:
+    if found is None:
         return False
     else:
-        return {'label': label, 'hasUnit': hasUnit, 'datumType': typeURI, 'measureOf': measureOf, 'isAbout': isAbout,
-                'dataElement': str(URITail(s)), 'dataElementURI': s, 'description': description, 'prefix': prefix,
-                'source_variable': source_variable}
-
-def getStatsCollectionForNode (rdf_graph, derivatives_node):
-
-    isa = URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')
-    data = {'URI': derivatives_node, 'values': {}}
-
-    for s, datatype, value in rdf_graph.triples((derivatives_node, None, None)):
-        if datatype == isa and str(value).find('http://purl.org/nidash/nidm#') == 0:
-            data['StatCollectionType'] = str(value)[28:]
+        return {
+            "label": label,
+            "hasUnit": hasUnit,
+            "datumType": typeURI,
+            "measureOf": measureOf,
+            "isAbout": isAbout,
+            "dataElement": str(URITail(found)),
+            "dataElementURI": found,
+            "description": description,
+            "prefix": prefix,
+            "source_variable": source_variable,
+        }
+
+
+def getStatsCollectionForNode(rdf_graph, derivatives_node):
+    isa = URIRef("http://www.w3.org/1999/02/22-rdf-syntax-ns#type")
+    data = {"URI": derivatives_node, "values": {}}
+
+    for _, datatype, value in rdf_graph.triples((derivatives_node, None, None)):
+        if datatype == isa and str(value).find("http://purl.org/nidash/nidm#") == 0:
+            data["StatCollectionType"] = str(value)[28:]
         else:
-            dti = getDataTypeInfo(rdf_graph, datatype )
-            if dti:  # if we can't find a datatype then this is non-data info so don't record it
-                data['values'][str(datatype)] = {'datumType': str(dti['datumType']), 'label': str(dti['label']), 'value': str(value), 'units': str(dti['hasUnit']), 'isAbout': str(dti['isAbout'])}
+            dti = getDataTypeInfo(rdf_graph, datatype)
+            if (
+                dti
+            ):  # if we can't find a datatype then this is non-data info so don't record it
+                data["values"][str(datatype)] = {
+                    "datumType": str(dti["datumType"]),
+                    "label": str(dti["label"]),
+                    "value": str(value),
+                    "units": str(dti["hasUnit"]),
+                    "isAbout": str(dti["isAbout"]),
+                }
 
     return data
 
+
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
 def OpenGraph(file):
-    '''
+    """
     Returns a parsed RDFLib Graph object for the given file
     The file will be hashed and if a pickled copy is found in the TMP dir, that will be used
     Otherwise the graph will be computed and then saved in the TMP dir as a pickle file
     We also use functools.lru_cache to cache results in memory during a run
 
     :param file: filename
     :return: Graph
-    '''
+    """
 
     # if someone passed me a RDF graph rather than a file, just send it back
     if isinstance(file, rdflib.graph.Graph):
         return file
 
-
     # If we have a Blazegraph instance, load the data then do the rest
-    if 'BLAZEGRAPH_URL' in environ.keys():
+    if "BLAZEGRAPH_URL" in environ:
         try:
-            f = open(file)
-            data = f.read()
-            logging.debug("Sending {} to blazegraph".format(file))
-            r = requests.post(url=environ['BLAZEGRAPH_URL'], data=data, headers={'Content-type': 'application/x-turtle'})
+            with open(file, encoding="utf-8") as f:
+                data = f.read()
+            logging.debug("Sending %s to blazegraph", file)
+            requests.post(
+                url=environ["BLAZEGRAPH_URL"],
+                data=data,
+                headers={"Content-type": "application/x-turtle"},
+            )
         except Exception as e:
-            logging.error("Exception {} loading {} into Blazegraph.".format(e, file))
-
+            logging.error("Exception %s loading %s into Blazegraph.", e, file)
 
     BLOCKSIZE = 65536
     hasher = hashlib.md5()
-    with open(file, 'rb') as afile:
+    with open(file, "rb") as afile:
         buf = afile.read(BLOCKSIZE)
         while len(buf) > 0:
             hasher.update(buf)
             buf = afile.read(BLOCKSIZE)
-    hash = hasher.hexdigest()
+    digest = hasher.hexdigest()
 
-    pickle_file = '{}/rdf_graph.{}.pickle'.format( tempfile.gettempdir(), hash)
+    pickle_file = f"{tempfile.gettempdir()}/rdf_graph.{digest}.pickle"
     if path.isfile(pickle_file):
-        return pickle.load(open(pickle_file, "rb"))
+        with open(pickle_file, "rb") as fp:
+            return pickle.load(fp)
 
     rdf_graph = Graph()
     rdf_graph.parse(file, format=util.guess_format(file))
-    pickle.dump(rdf_graph, open(pickle_file, 'wb'))
-
-    # new graph, so to be safe clear out all cached entries
-    memory.clear(warn=False)
+    with open(pickle_file, "wb") as fp:
+        pickle.dump(rdf_graph, fp)
 
     return rdf_graph
 
+
 def GetDerivativesDataForSubject(files, project, subject):
-    return GetDerivativesDataForSubjectCache (tuple(files), project, subject)
+    return GetDerivativesDataForSubjectCache(tuple(files), project, subject)
+
 
 @functools.lru_cache(maxsize=QUERY_CACHE_SIZE)
-def GetDerivativesDataForSubjectCache(files, project, subject):
-    '''
+def GetDerivativesDataForSubjectCache(files, project, subject):  # noqa: U100
+    """
     Searches for the subject in the supplied RDF .ttl files and returns
     an array of all the data generated by software agents about that subject
 
     :param project:
     :param files: Array of RDF .ttl files
     :param subject: The URI (or just the bit after the NIIRI prefix) of a subject
     :return: Array of stat collections for the subject
-    '''
+    """
 
     # if this isn't already a URI, make it one.
     # calls from the REST api don't include the URI
-    if subject.find('http') < 0:
+    if subject.find("http") < 0:
         subject = Constants.NIIRI[subject]
 
     data = {}
 
     for nidm_file in files:
         rdf_graph = OpenGraph(nidm_file)
         for node in getDerivativesNodesForSubject(rdf_graph, subject):
             collection = getStatsCollectionForNode(rdf_graph, node)
-            key = str(collection['URI']).split('/')[-1]
+            key = str(collection["URI"]).split("/")[-1]
             data[key] = collection
 
     return data
 
+
 def getSoftwareAgents(rdf_graph):
-    '''
+    """
     Scans the supplied graph and returns any software agenyt URIs found there
 
     :param rdf_graph: a parsed RDF Graph
     :return: array of agent URIs
-    '''
+    """
 
-    isa = URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')
-    software_agent = URIRef('http://www.w3.org/ns/prov#SoftwareAgent')
+    isa = URIRef("http://www.w3.org/1999/02/22-rdf-syntax-ns#type")
+    software_agent = URIRef("http://www.w3.org/ns/prov#SoftwareAgent")
     agents = []
 
-    for s,o,p in rdf_graph.triples( (None, isa, software_agent) ):
+    for s, _, _ in rdf_graph.triples((None, isa, software_agent)):
         agents.append(s)
 
     return agents
 
+
 def download_cde_files():
-        cde_dir = tempfile.gettempdir()
+    cde_dir = tempfile.gettempdir()
 
-        for url in Constants.CDE_FILE_LOCATIONS:
-            urlretrieve(url, "{}/{}".format(cde_dir, url.split('/')[-1]))
+    for url in Constants.CDE_FILE_LOCATIONS:
+        urlretrieve(url, f"{cde_dir}/{url.split('/')[-1]}")
 
-        return cde_dir
+    return cde_dir
 
-def getCDEs(file_list=None):
 
+def getCDEs(file_list=None):
     if getCDEs.cache:
         return getCDEs.cache
 
     hasher = hashlib.md5()
-    hasher.update(str(file_list).encode('utf-8'))
+    hasher.update(str(file_list).encode("utf-8"))
     h = hasher.hexdigest()
 
-    cache_file_name = tempfile.gettempdir() + "/cde_graph.{}.pickle".format(h)
+    cache_file_name = tempfile.gettempdir() + f"/cde_graph.{h}.pickle"
 
     if path.isfile(cache_file_name):
-        rdf_graph = pickle.load(open(cache_file_name, "rb"))
+        with open(cache_file_name, "rb") as fp:
+            rdf_graph = pickle.load(fp)
         getCDEs.cache = rdf_graph
         return rdf_graph
 
     rdf_graph = Graph()
 
     if not file_list:
-
-        cde_dir = ''
+        cde_dir = ""
         if "CDE_DIR" in os.environ:
-            cde_dir = os.environ['CDE_DIR']
+            cde_dir = os.environ["CDE_DIR"]
 
-        if (not cde_dir) and (os.path.isfile( '/opt/project/nidm/core/cde_dir/ants_cde.ttl' )):
-            cde_dir = '/opt/project/nidm/core/cde_dir'
+        if (not cde_dir) and (
+            os.path.isfile("/opt/project/nidm/core/cde_dir/ants_cde.ttl")
+        ):
+            cde_dir = "/opt/project/nidm/core/cde_dir"
 
-        if (not cde_dir):
+        if not cde_dir:
             cde_dir = download_cde_files()
 
         # TODO: the list of file names should be it's own constant or derived from CDE_FILE_LOCATIONS
-        file_list = [ ]
-        for f in ['ants_cde.ttl', 'fs_cde.ttl', 'fsl_cde.ttl']:
-            fname = '{}/{}'.format(cde_dir, f)
-            if os.path.isfile( fname ):
-                file_list.append( fname )
-
-
+        file_list = []
+        for f in ["ants_cde.ttl", "fs_cde.ttl", "fsl_cde.ttl"]:
+            fname = f"{cde_dir}/{f}"
+            if os.path.isfile(fname):
+                file_list.append(fname)
 
     for fname in file_list:
         if os.path.isfile(fname):
             cde_graph = OpenGraph(fname)
             rdf_graph = rdf_graph + cde_graph
 
-
-
-
-    cache_file = open(cache_file_name , 'wb')
-    pickle.dump(rdf_graph, cache_file)
-    cache_file.close()
+    with open(cache_file_name, "wb") as cache_file:
+        pickle.dump(rdf_graph, cache_file)
 
     getCDEs.cache = rdf_graph
     return rdf_graph
-getCDEs.cache = None
+
+
+getCDEs.cache = None
```

### Comparing `pynidm-3.9.7/nidm/experiment/Session.py` & `pynidm-4.0.0/src/nidm/experiment/Session.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,71 +1,84 @@
-import rdflib as rdf
-import os, sys
-
-#sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
-from ..core import Constants
-from ..experiment import Core
-from ..experiment.Core import getUUID
 import prov.model as pm
+from .Core import Core, getUUID
+from ..core import Constants
 
 
-class Session(pm.ProvActivity,Core):
+class Session(pm.ProvActivity, Core):
     """Class for NIDM-Experimenent Session-Level Objects.
 
     Default constructor uses empty graph with namespaces added from NIDM/Scripts/Constants.py.
     Additional alternate constructors for user-supplied graphs and default namespaces (i.e. from Constants.py)
     and user-supplied graph and namespaces
 
     @author: David Keator <dbkeator@uci.edu>
     @copyright: University of California, Irvine 2017
 
     """
-    #constructor
-    def __init__(self, project,uuid=None,attributes=None,add_default_type=True):
+
+    # constructor
+    def __init__(self, project, uuid=None, attributes=None, add_default_type=True):
         """
-        Default contructor, creates a session activity and links to project object
+        Default constructor, creates a session activity and links to project object
 
         :param project: a project object
         :return: none
 
         """
         if uuid is None:
             self._uuid = getUUID()
-            #execute default parent class constructor
-            super(Session,self).__init__(project.graph, pm.QualifiedName(pm.Namespace("niiri",Constants.NIIRI),self.get_uuid()),attributes)
+            # execute default parent class constructor
+            super().__init__(
+                project.graph,
+                pm.QualifiedName(
+                    pm.Namespace("niiri", Constants.NIIRI), self.get_uuid()
+                ),
+                attributes,
+            )
         else:
             self._uuid = uuid
-            #execute default parent class constructor
-            super(Session,self).__init__(project.graph, pm.QualifiedName(pm.Namespace("niiri",Constants.NIIRI),self.get_uuid()),attributes)
+            # execute default parent class constructor
+            super().__init__(
+                project.graph,
+                pm.QualifiedName(
+                    pm.Namespace("niiri", Constants.NIIRI), self.get_uuid()
+                ),
+                attributes,
+            )
 
         project.graph._add_record(self)
 
         if add_default_type:
             self.add_attributes({pm.PROV_TYPE: Constants.NIDM_SESSION})
 
         self.graph = project.graph
         project.add_sessions(self)
 
-        #list of acquisitions associated with this session
-        self._acquisitions=[]
-    def add_acquisition(self,acquisition):
+        # list of acquisitions associated with this session
+        self._acquisitions = []
+
+    def add_acquisition(self, acquisition):
         self._acquisitions.extend([acquisition])
-        #create links in graph
-        acquisition.add_attributes({pm.QualifiedName(pm.Namespace("dct",Constants.DCT),'isPartOf'):self})
+        # create links in graph
+        acquisition.add_attributes(
+            {pm.QualifiedName(pm.Namespace("dct", Constants.DCT), "isPartOf"): self}
+        )
+
     def get_acquisitions(self):
         return self._acquisitions
-    def acquisition_exist(self,uuid):
-        '''
+
+    def acquisition_exist(self, uuid):
+        """
         Checks whether uuid is a registered acquisition
         :param uuid: full uuid of acquisition
         :return: True if exists, False otherwise
-        '''
-        #print("Query uuid: %s" %uuid)
+        """
+        # print(f"Query uuid: {uuid}")
         for acquisitions in self._acquisitions:
-            #print(acquisitions._identifier._localpart)
+            # print(acquisitions._identifier._localpart)
             if str(uuid) == acquisitions._identifier._localpart:
                 return True
 
         return False
+
     def __str__(self):
         return "NIDM-Experiment Session Class"
-
```

### Comparing `pynidm-3.9.7/nidm/experiment/Utils.py` & `pynidm-4.0.0/src/nidm/experiment/Utils.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,7406 +1,8310 @@
-00000000: 696d 706f 7274 206f 732c 7379 730a 0a0a  import os,sys...
-00000010: 6672 6f6d 2072 6466 6c69 6220 696d 706f  from rdflib impo
-00000020: 7274 204e 616d 6573 7061 6365 2c20 4c69  rt Namespace, Li
-00000030: 7465 7261 6c2c 5244 4653 0a66 726f 6d20  teral,RDFS.from 
-00000040: 7264 666c 6962 2e6e 616d 6573 7061 6365  rdflib.namespace
-00000050: 2069 6d70 6f72 7420 5853 440a 6672 6f6d   import XSD.from
-00000060: 2072 6466 6c69 622e 7265 736f 7572 6365   rdflib.resource
-00000070: 2069 6d70 6f72 7420 5265 736f 7572 6365   import Resource
-00000080: 0a66 726f 6d20 7264 666c 6962 2e75 7469  .from rdflib.uti
-00000090: 6c20 696d 706f 7274 2066 726f 6d5f 6e33  l import from_n3
-000000a0: 0a66 726f 6d20 7572 6c6c 6962 2e70 6172  .from urllib.par
-000000b0: 7365 2069 6d70 6f72 7420 7572 6c70 6172  se import urlpar
-000000c0: 7365 2c20 7572 6c73 706c 6974 0a66 726f  se, urlsplit.fro
-000000d0: 6d20 7264 666c 6962 2069 6d70 6f72 7420  m rdflib import 
-000000e0: 4772 6170 682c 2052 4446 2c20 5552 4952  Graph, RDF, URIR
-000000f0: 6566 2c20 7574 696c 0a66 726f 6d20 7264  ef, util.from rd
-00000100: 666c 6962 2e6e 616d 6573 7061 6365 2069  flib.namespace i
-00000110: 6d70 6f72 7420 7370 6c69 745f 7572 690a  mport split_uri.
-00000120: 696d 706f 7274 2076 616c 6964 6174 6f72  import validator
-00000130: 730a 696d 706f 7274 2070 726f 762e 6d6f  s.import prov.mo
-00000140: 6465 6c20 6173 2070 6d0a 6672 6f6d 2070  del as pm.from p
-00000150: 726f 762e 6d6f 6465 6c20 696d 706f 7274  rov.model import
-00000160: 2051 7561 6c69 6669 6564 4e61 6d65 2c20   QualifiedName, 
-00000170: 4964 656e 7469 6669 6572 0a66 726f 6d20  Identifier.from 
-00000180: 7072 6f76 2e6d 6f64 656c 2069 6d70 6f72  prov.model impor
-00000190: 7420 4e61 6d65 7370 6163 6520 6173 2070  t Namespace as p
-000001a0: 726f 764e 616d 6573 7061 6365 0a69 6d70  rovNamespace.imp
-000001b0: 6f72 7420 7265 7175 6573 7473 0a66 726f  ort requests.fro
-000001c0: 6d20 7261 7069 6466 757a 7a20 696d 706f  m rapidfuzz impo
-000001d0: 7274 2066 757a 7a0a 696d 706f 7274 206a  rt fuzz.import j
-000001e0: 736f 6e0a 6672 6f6d 2067 6974 6875 6220  son.from github 
-000001f0: 696d 706f 7274 2047 6974 6875 622c 2047  import Github, G
-00000200: 6974 6875 6245 7863 6570 7469 6f6e 0a69  ithubException.i
-00000210: 6d70 6f72 7420 6765 7470 6173 730a 6672  mport getpass.fr
-00000220: 6f6d 206e 756d 7079 2069 6d70 6f72 7420  om numpy import 
-00000230: 6261 7365 5f72 6570 720a 6672 6f6d 2062  base_repr.from b
-00000240: 696e 6173 6369 6920 696d 706f 7274 2063  inascii import c
-00000250: 7263 3332 0a69 6d70 6f72 7420 7061 6e64  rc32.import pand
-00000260: 6173 2061 7320 7064 0a66 726f 6d20 7575  as as pd.from uu
-00000270: 6964 2069 6d70 6f72 7420 5555 4944 0a66  id import UUID.f
-00000280: 726f 6d20 7572 6c6c 6962 2e72 6571 7565  rom urllib.reque
-00000290: 7374 2069 6d70 6f72 7420 7572 6c6f 7065  st import urlope
-000002a0: 6e0a 0a23 4e49 444d 2069 6d70 6f72 7473  n..#NIDM imports
-000002b0: 0a66 726f 6d20 2e2e 636f 7265 2069 6d70  .from ..core imp
-000002c0: 6f72 7420 436f 6e73 7461 6e74 730a 6672  ort Constants.fr
-000002d0: 6f6d 202e 2e63 6f72 652e 436f 6e73 7461  om ..core.Consta
-000002e0: 6e74 7320 696d 706f 7274 2044 440a 0a0a  nts import DD...
-000002f0: 6672 6f6d 202e 436f 7265 2069 6d70 6f72  from .Core impor
-00000300: 7420 6765 7455 5549 440a 6672 6f6d 202e  t getUUID.from .
-00000310: 5072 6f6a 6563 7420 696d 706f 7274 2050  Project import P
-00000320: 726f 6a65 6374 0a66 726f 6d20 2e53 6573  roject.from .Ses
-00000330: 7369 6f6e 2069 6d70 6f72 7420 5365 7373  sion import Sess
-00000340: 696f 6e0a 6672 6f6d 202e 4163 7175 6973  ion.from .Acquis
-00000350: 6974 696f 6e20 696d 706f 7274 2041 6371  ition import Acq
-00000360: 7569 7369 7469 6f6e 0a66 726f 6d20 2e4d  uisition.from .M
-00000370: 5241 6371 7569 7369 7469 6f6e 2069 6d70  RAcquisition imp
-00000380: 6f72 7420 4d52 4163 7175 6973 6974 696f  ort MRAcquisitio
-00000390: 6e0a 6672 6f6d 202e 5045 5441 6371 7569  n.from .PETAcqui
-000003a0: 7369 7469 6f6e 2069 6d70 6f72 7420 5045  sition import PE
-000003b0: 5441 6371 7569 7369 7469 6f6e 0a66 726f  TAcquisition.fro
-000003c0: 6d20 2e41 6371 7569 7369 7469 6f6e 4f62  m .AcquisitionOb
-000003d0: 6a65 6374 2069 6d70 6f72 7420 4163 7175  ject import Acqu
-000003e0: 6973 6974 696f 6e4f 626a 6563 740a 6672  isitionObject.fr
-000003f0: 6f6d 202e 4173 7365 7373 6d65 6e74 4163  om .AssessmentAc
-00000400: 7175 6973 6974 696f 6e20 696d 706f 7274  quisition import
-00000410: 2041 7373 6573 736d 656e 7441 6371 7569   AssessmentAcqui
-00000420: 7369 7469 6f6e 0a66 726f 6d20 2e41 7373  sition.from .Ass
-00000430: 6573 736d 656e 744f 626a 6563 7420 696d  essmentObject im
-00000440: 706f 7274 2041 7373 6573 736d 656e 744f  port AssessmentO
-00000450: 626a 6563 740a 6672 6f6d 202e 4465 7269  bject.from .Deri
-00000460: 7661 7469 7665 4f62 6a65 6374 2069 6d70  vativeObject imp
-00000470: 6f72 7420 4465 7269 7661 7469 7665 4f62  ort DerivativeOb
-00000480: 6a65 6374 0a66 726f 6d20 2e44 6572 6976  ject.from .Deriv
-00000490: 6174 6976 6520 696d 706f 7274 2044 6572  ative import Der
-000004a0: 6976 6174 6976 650a 6672 6f6d 202e 4461  ivative.from .Da
-000004b0: 7461 456c 656d 656e 7420 696d 706f 7274  taElement import
-000004c0: 2044 6174 6145 6c65 6d65 6e74 0a66 726f   DataElement.fro
-000004d0: 6d20 2e4d 524f 626a 6563 7420 696d 706f  m .MRObject impo
-000004e0: 7274 204d 524f 626a 6563 740a 6672 6f6d  rt MRObject.from
-000004f0: 202e 5045 544f 626a 6563 7420 696d 706f   .PETObject impo
-00000500: 7274 2050 4554 4f62 6a65 6374 0a66 726f  rt PETObject.fro
-00000510: 6d20 2e43 6f72 6520 696d 706f 7274 2043  m .Core import C
-00000520: 6f72 650a 696d 706f 7274 206c 6f67 6769  ore.import loggi
-00000530: 6e67 0a6c 6f67 6765 7220 3d20 6c6f 6767  ng.logger = logg
-00000540: 696e 672e 6765 744c 6f67 6765 7228 5f5f  ing.getLogger(__
-00000550: 6e61 6d65 5f5f 290a 0a69 6d70 6f72 7420  name__)..import 
-00000560: 7265 0a69 6d70 6f72 7420 7374 7269 6e67  re.import string
-00000570: 0a69 6d70 6f72 7420 7261 6e64 6f6d 0a0a  .import random..
-00000580: 2349 6e74 6572 6c65 7820 7374 7566 660a  #Interlex stuff.
-00000590: 696d 706f 7274 206f 6e74 7175 6572 7920  import ontquery 
-000005a0: 6173 206f 710a 0a23 2064 6174 616c 6164  as oq..# datalad
-000005b0: 202f 2067 6974 2d61 6e6e 6578 2073 6f75   / git-annex sou
-000005c0: 7263 6573 0a0a 6672 6f6d 2064 6174 616c  rces..from datal
-000005d0: 6164 2e73 7570 706f 7274 2e61 6e6e 6578  ad.support.annex
-000005e0: 7265 706f 2069 6d70 6f72 7420 416e 6e65  repo import Anne
-000005f0: 7852 6570 6f0a 0a23 2063 6f67 6e69 7469  xRepo..# cogniti
-00000600: 7665 2061 746c 6173 0a66 726f 6d20 636f  ve atlas.from co
-00000610: 676e 6974 6976 6561 746c 6173 2e61 7069  gnitiveatlas.api
-00000620: 2069 6d70 6f72 7420 6765 745f 636f 6e63   import get_conc
-00000630: 6570 742c 2067 6574 5f64 6973 6f72 6465  ept, get_disorde
-00000640: 720a 0a0a 0a23 2073 6574 2069 6620 7765  r....# set if we
-00000650: 2772 6520 7275 6e6e 696e 6720 696e 2070  're running in p
-00000660: 726f 6475 6374 696f 6e20 6f72 2074 6573  roduction or tes
-00000670: 7469 6e67 206d 6f64 650a 2349 4e54 4552  ting mode.#INTER
-00000680: 4c45 585f 4d4f 4445 203d 2027 7465 7374  LEX_MODE = 'test
-00000690: 270a 494e 5445 524c 4558 5f4d 4f44 4520  '.INTERLEX_MODE 
-000006a0: 3d20 2770 726f 6475 6374 696f 6e27 0a69  = 'production'.i
-000006b0: 6620 494e 5445 524c 4558 5f4d 4f44 4520  f INTERLEX_MODE 
-000006c0: 3d3d 2027 7465 7374 273a 0a20 2020 2049  == 'test':.    I
-000006d0: 4e54 4552 4c45 585f 5052 4546 4958 203d  NTERLEX_PREFIX =
-000006e0: 2027 746d 705f 270a 2020 2020 2349 4e54   'tmp_'.    #INT
-000006f0: 4552 4c45 585f 454e 4450 4f49 4e54 203d  ERLEX_ENDPOINT =
-00000700: 2022 6874 7470 733a 2f2f 6265 7461 2e73   "https://beta.s
-00000710: 6369 6372 756e 6368 2e6f 7267 2f61 7069  cicrunch.org/api
-00000720: 2f31 2f22 0a20 2020 2049 4e54 4552 4c45  /1/".    INTERLE
-00000730: 585f 454e 4450 4f49 4e54 203d 2022 6874  X_ENDPOINT = "ht
-00000740: 7470 733a 2f2f 7465 7374 332e 7363 6963  tps://test3.scic
-00000750: 7275 6e63 682e 6f72 672f 6170 692f 312f  runch.org/api/1/
-00000760: 220a 656c 6966 2049 4e54 4552 4c45 585f  ".elif INTERLEX_
-00000770: 4d4f 4445 203d 3d20 2770 726f 6475 6374  MODE == 'product
-00000780: 696f 6e27 3a0a 2020 2020 494e 5445 524c  ion':.    INTERL
-00000790: 4558 5f50 5245 4649 5820 3d20 2769 6c78  EX_PREFIX = 'ilx
-000007a0: 5f27 0a20 2020 2049 4e54 4552 4c45 585f  _'.    INTERLEX_
-000007b0: 454e 4450 4f49 4e54 203d 2022 6874 7470  ENDPOINT = "http
-000007c0: 733a 2f2f 7363 6963 7275 6e63 682e 6f72  s://scicrunch.or
-000007d0: 672f 6170 692f 312f 220a 656c 7365 3a0a  g/api/1/".else:.
-000007e0: 2020 2020 7072 696e 7428 2245 5252 4f52      print("ERROR
-000007f0: 3a20 496e 7465 726c 6578 206d 6f64 6520  : Interlex mode 
-00000800: 6361 6e20 6f6e 6c79 2062 6520 2774 6573  can only be 'tes
-00000810: 7427 206f 7220 2770 726f 6475 6374 696f  t' or 'productio
-00000820: 6e27 2229 0a20 2020 2065 7869 7428 3129  n'").    exit(1)
-00000830: 0a0a 0a0a 6465 6620 7361 6665 5f73 7472  ....def safe_str
-00000840: 696e 6728 7374 7269 6e67 293a 0a20 2020  ing(string):.   
-00000850: 2020 2020 2072 6574 7572 6e20 7374 7269       return stri
-00000860: 6e67 2e73 7472 6970 2829 2e72 6570 6c61  ng.strip().repla
-00000870: 6365 2822 2022 2c22 5f22 292e 7265 706c  ce(" ","_").repl
-00000880: 6163 6528 222d 222c 2022 5f22 292e 7265  ace("-", "_").re
-00000890: 706c 6163 6528 222c 222c 2022 5f22 292e  place(",", "_").
-000008a0: 7265 706c 6163 6528 2228 222c 2022 5f22  replace("(", "_"
-000008b0: 292e 7265 706c 6163 6528 2229 222c 225f  ).replace(")","_
-000008c0: 2229 5c0a 2020 2020 2020 2020 2020 2020  ")\.            
-000008d0: 2e72 6570 6c61 6365 2822 2722 2c22 5f22  .replace("'","_"
-000008e0: 292e 7265 706c 6163 6528 222f 222c 2022  ).replace("/", "
-000008f0: 5f22 292e 7265 706c 6163 6528 2223 222c  _").replace("#",
-00000900: 226e 756d 2229 0a0a 6465 6620 7265 6164  "num")..def read
-00000910: 5f6e 6964 6d28 6e69 646d 446f 6329 3a0a  _nidm(nidmDoc):.
-00000920: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
-00000930: 4c6f 6164 7320 6e69 646d 446f 6320 6669  Loads nidmDoc fi
-00000940: 6c65 2069 6e74 6f20 4e49 444d 2d45 7870  le into NIDM-Exp
-00000950: 6572 696d 656e 7420 7374 7275 6374 7572  eriment structur
-00000960: 6573 2061 6e64 2072 6574 7572 6e73 206f  es and returns o
-00000970: 626a 6563 7473 0a0a 2020 2020 2020 2020  bjects..        
-00000980: 3a6e 6964 6d44 6f63 3a20 6120 7661 6c69  :nidmDoc: a vali
-00000990: 6420 5244 4620 4e49 444d 2d65 7870 6572  d RDF NIDM-exper
-000009a0: 696d 656e 7420 646f 6375 6d65 6e74 2028  iment document (
-000009b0: 6465 7365 7269 616c 697a 6174 696f 6e20  deserialization 
-000009c0: 666f 726d 6174 7320 7375 7070 6f72 7465  formats supporte
-000009d0: 6420 6279 2052 4446 4c69 6229 0a0a 2020  d by RDFLib)..  
-000009e0: 2020 2020 2020 3a72 6574 7572 6e3a 204e        :return: N
-000009f0: 4944 4d20 5072 6f6a 6563 740a 0a20 2020  IDM Project..   
-00000a00: 2022 2222 0a0a 2020 2020 6672 6f6d 202e   """..    from .
-00000a10: 2e65 7870 6572 696d 656e 742e 5072 6f6a  .experiment.Proj
-00000a20: 6563 7420 696d 706f 7274 2050 726f 6a65  ect import Proje
-00000a30: 6374 0a20 2020 2066 726f 6d20 2e2e 6578  ct.    from ..ex
-00000a40: 7065 7269 6d65 6e74 2e53 6573 7369 6f6e  periment.Session
-00000a50: 2069 6d70 6f72 7420 5365 7373 696f 6e0a   import Session.
-00000a60: 0a0a 2020 2020 2320 7265 6164 2052 4446  ..    # read RDF
-00000a70: 2066 696c 6520 696e 746f 2074 656d 706f   file into tempo
-00000a80: 7261 7279 2067 7261 7068 0a20 2020 2072  rary graph.    r
-00000a90: 6466 5f67 7261 7068 203d 2047 7261 7068  df_graph = Graph
-00000aa0: 2829 0a20 2020 2072 6466 5f67 7261 7068  ().    rdf_graph
-00000ab0: 5f70 6172 7365 203d 2072 6466 5f67 7261  _parse = rdf_gra
-00000ac0: 7068 2e70 6172 7365 286e 6964 6d44 6f63  ph.parse(nidmDoc
-00000ad0: 2c66 6f72 6d61 743d 7574 696c 2e67 7565  ,format=util.gue
-00000ae0: 7373 5f66 6f72 6d61 7428 6e69 646d 446f  ss_format(nidmDo
-00000af0: 6329 290a 0a0a 2020 2020 2320 5175 6572  c))...    # Quer
-00000b00: 7920 6772 6170 6820 666f 7220 7072 6f6a  y graph for proj
-00000b10: 6563 7420 6d65 7461 6461 7461 2061 6e64  ect metadata and
-00000b20: 2063 7265 6174 6520 7072 6f6a 6563 7420   create project 
-00000b30: 6c65 7665 6c20 6f62 6a65 6374 730a 2020  level objects.  
-00000b40: 2020 2320 4765 7420 7375 626a 6563 7420    # Get subject 
-00000b50: 5552 4920 666f 7220 7072 6f6a 6563 740a  URI for project.
-00000b60: 2020 2020 7072 6f6a 5f69 643d 4e6f 6e65      proj_id=None
-00000b70: 0a20 2020 2066 6f72 2073 2069 6e20 7264  .    for s in rd
-00000b80: 665f 6772 6170 685f 7061 7273 652e 7375  f_graph_parse.su
-00000b90: 626a 6563 7473 2870 7265 6469 6361 7465  bjects(predicate
-00000ba0: 3d52 4446 2e74 7970 652c 6f62 6a65 6374  =RDF.type,object
-00000bb0: 3d55 5249 5265 6628 436f 6e73 7461 6e74  =URIRef(Constant
-00000bc0: 732e 4e49 444d 5f50 524f 4a45 4354 2e75  s.NIDM_PROJECT.u
-00000bd0: 7269 2929 3a0a 2020 2020 2020 2020 2370  ri)):.        #p
-00000be0: 7269 6e74 2873 290a 2020 2020 2020 2020  rint(s).        
-00000bf0: 7072 6f6a 5f69 643d 730a 0a20 2020 2069  proj_id=s..    i
-00000c00: 6620 7072 6f6a 5f69 6420 6973 204e 6f6e  f proj_id is Non
-00000c10: 653a 0a20 2020 2020 2020 2070 7269 6e74  e:.        print
-00000c20: 2822 4572 726f 7220 7265 6164 696e 6720  ("Error reading 
-00000c30: 4e49 444d 2d45 7870 2044 6f63 756d 656e  NIDM-Exp Documen
-00000c40: 7420 2573 2c20 4d75 7374 2068 6176 6520  t %s, Must have 
-00000c50: 5072 6f6a 6563 7420 4f62 6a65 6374 2220  Project Object" 
-00000c60: 2520 6e69 646d 446f 6329 0a20 2020 2020  % nidmDoc).     
-00000c70: 2020 2070 7269 6e74 2829 0a20 2020 2020     print().     
-00000c80: 2020 2063 7265 6174 655f 6f62 6a20 3d20     create_obj = 
-00000c90: 696e 7075 7428 2253 686f 756c 6420 7265  input("Should re
-00000ca0: 6164 5f6e 6964 6d20 6372 6561 7465 2061  ad_nidm create a
-00000cb0: 2050 726f 6a65 6374 206f 626a 6563 7420   Project object 
-00000cc0: 666f 7220 796f 7520 5b79 6573 5d3a 2022  for you [yes]: "
-00000cd0: 290a 2020 2020 2020 2020 6966 2028 6372  ).        if (cr
-00000ce0: 6561 7465 5f6f 626a 203d 3d20 2779 6573  eate_obj == 'yes
-00000cf0: 2720 6f72 2063 7265 6174 655f 6f62 6a20  ' or create_obj 
-00000d00: 3d3d 2027 2729 3a0a 2020 2020 2020 2020  == ''):.        
-00000d10: 2020 2020 7072 6f6a 6563 7420 3d20 5072      project = Pr
-00000d20: 6f6a 6563 7428 656d 7074 795f 6772 6170  oject(empty_grap
-00000d30: 683d 5472 7565 2c61 6464 5f64 6566 6175  h=True,add_defau
-00000d40: 6c74 5f74 7970 653d 5472 7565 290a 2020  lt_type=True).  
-00000d50: 2020 2020 2020 2020 2020 2320 6164 6420            # add 
-00000d60: 6e61 6d65 7370 6163 6573 2074 6f20 7072  namespaces to pr
-00000d70: 6f76 2067 7261 7068 0a20 2020 2020 2020  ov graph.       
-00000d80: 2020 2020 2066 6f72 206e 616d 652c 206e       for name, n
-00000d90: 616d 6573 7061 6365 2069 6e20 7264 665f  amespace in rdf_
-00000da0: 6772 6170 685f 7061 7273 652e 6e61 6d65  graph_parse.name
-00000db0: 7370 6163 6573 2829 3a0a 2020 2020 2020  spaces():.      
-00000dc0: 2020 2020 2020 2020 2020 2320 736b 6970            # skip
-00000dd0: 2074 6865 7365 2064 6566 6175 6c74 206e   these default n
-00000de0: 616d 6573 7061 6365 7320 696e 2070 726f  amespaces in pro
-00000df0: 7620 446f 6375 6d65 6e74 0a20 2020 2020  v Document.     
-00000e00: 2020 2020 2020 2020 2020 2069 6620 286e             if (n
-00000e10: 616d 6520 213d 2027 7072 6f76 2729 2061  ame != 'prov') a
-00000e20: 6e64 2028 6e61 6d65 2021 3d20 2778 7364  nd (name != 'xsd
-00000e30: 2729 2061 6e64 2028 6e61 6d65 2021 3d20  ') and (name != 
-00000e40: 276e 6964 6d27 2920 616e 6420 286e 616d  'nidm') and (nam
-00000e50: 6520 213d 2027 6e69 6972 6927 293a 0a20  e != 'niiri'):. 
-00000e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00000e70: 2020 2070 726f 6a65 6374 2e67 7261 7068     project.graph
-00000e80: 2e61 6464 5f6e 616d 6573 7061 6365 286e  .add_namespace(n
-00000e90: 616d 652c 206e 616d 6573 7061 6365 290a  ame, namespace).
-00000ea0: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00000eb0: 2020 2020 2020 2020 2020 2065 7869 7428             exit(
-00000ec0: 3129 0a20 2020 2065 6c73 653a 0a20 2020  1).    else:.   
-00000ed0: 2020 2020 2023 5370 6c69 7420 7375 626a       #Split subj
-00000ee0: 6563 7420 5552 4920 696e 746f 206e 616d  ect URI into nam
-00000ef0: 6573 7061 6365 2c20 7465 726d 0a20 2020  espace, term.   
-00000f00: 2020 2020 206e 6d2c 7072 6f6a 6563 745f       nm,project_
-00000f10: 7575 6964 203d 2073 706c 6974 5f75 7269  uuid = split_uri
-00000f20: 2870 726f 6a5f 6964 290a 0a20 2020 2020  (proj_id)..     
-00000f30: 2020 2023 6372 6561 7465 2065 6d70 7479     #create empty
-00000f40: 2070 726f 7620 6772 6170 680a 2020 2020   prov graph.    
-00000f50: 2020 2020 7072 6f6a 6563 7420 3d20 5072      project = Pr
-00000f60: 6f6a 6563 7428 656d 7074 795f 6772 6170  oject(empty_grap
-00000f70: 683d 5472 7565 2c75 7569 643d 7072 6f6a  h=True,uuid=proj
-00000f80: 6563 745f 7575 6964 2c61 6464 5f64 6566  ect_uuid,add_def
-00000f90: 6175 6c74 5f74 7970 653d 4661 6c73 6529  ault_type=False)
-00000fa0: 0a0a 2020 2020 2020 2020 2361 6464 206e  ..        #add n
-00000fb0: 616d 6573 7061 6365 7320 746f 2070 726f  amespaces to pro
-00000fc0: 7620 6772 6170 680a 2020 2020 2020 2020  v graph.        
-00000fd0: 666f 7220 6e61 6d65 2c20 6e61 6d65 7370  for name, namesp
-00000fe0: 6163 6520 696e 2072 6466 5f67 7261 7068  ace in rdf_graph
-00000ff0: 5f70 6172 7365 2e6e 616d 6573 7061 6365  _parse.namespace
-00001000: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
-00001010: 2023 736b 6970 2074 6865 7365 2064 6566   #skip these def
-00001020: 6175 6c74 206e 616d 6573 7061 6365 7320  ault namespaces 
-00001030: 696e 2070 726f 7620 446f 6375 6d65 6e74  in prov Document
-00001040: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00001050: 286e 616d 6520 213d 2027 7072 6f76 2729  (name != 'prov')
-00001060: 2061 6e64 2028 6e61 6d65 2021 3d20 2778   and (name != 'x
-00001070: 7364 2729 2061 6e64 2028 6e61 6d65 2021  sd') and (name !
-00001080: 3d20 276e 6964 6d27 2920 616e 6420 286e  = 'nidm') and (n
-00001090: 616d 6520 213d 2027 6e69 6972 6927 293a  ame != 'niiri'):
-000010a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000010b0: 2070 726f 6a65 6374 2e67 7261 7068 2e61   project.graph.a
-000010c0: 6464 5f6e 616d 6573 7061 6365 286e 616d  dd_namespace(nam
-000010d0: 652c 206e 616d 6573 7061 6365 290a 0a20  e, namespace).. 
-000010e0: 2020 2020 2020 2023 4379 636c 6520 7468         #Cycle th
-000010f0: 726f 7567 6820 5072 6f6a 6563 7420 6d65  rough Project me
-00001100: 7461 6461 7461 2061 6464 696e 6720 746f  tadata adding to
-00001110: 2070 726f 7620 6772 6170 680a 2020 2020   prov graph.    
-00001120: 2020 2020 6164 645f 6d65 7461 6461 7461      add_metadata
-00001130: 5f66 6f72 5f73 7562 6a65 6374 2028 7264  _for_subject (rd
-00001140: 665f 6772 6170 685f 7061 7273 652c 7072  f_graph_parse,pr
-00001150: 6f6a 5f69 642c 7072 6f6a 6563 742e 6772  oj_id,project.gr
-00001160: 6170 682e 6e61 6d65 7370 6163 6573 2c70  aph.namespaces,p
-00001170: 726f 6a65 6374 290a 0a0a 2020 2020 2351  roject)...    #Q
-00001180: 7565 7279 2067 7261 7068 2066 6f72 2073  uery graph for s
-00001190: 6573 7369 6f6e 732c 2069 6e73 7461 6e74  essions, instant
-000011a0: 6961 7465 2073 6573 7369 6f6e 206f 626a  iate session obj
-000011b0: 6563 7473 2c20 616e 6420 6164 6420 746f  ects, and add to
-000011c0: 2070 726f 6a65 6374 2e5f 7365 7373 696f   project._sessio
-000011d0: 6e20 6c69 7374 0a20 2020 2023 4765 7420  n list.    #Get 
-000011e0: 7375 626a 6563 7420 5552 4920 666f 7220  subject URI for 
-000011f0: 7365 7373 696f 6e73 0a20 2020 2066 6f72  sessions.    for
-00001200: 2073 2069 6e20 7264 665f 6772 6170 685f   s in rdf_graph_
-00001210: 7061 7273 652e 7375 626a 6563 7473 2870  parse.subjects(p
-00001220: 7265 6469 6361 7465 3d52 4446 2e74 7970  redicate=RDF.typ
-00001230: 652c 6f62 6a65 6374 3d55 5249 5265 6628  e,object=URIRef(
-00001240: 436f 6e73 7461 6e74 732e 4e49 444d 5f53  Constants.NIDM_S
-00001250: 4553 5349 4f4e 2e75 7269 2929 3a0a 2020  ESSION.uri)):.  
-00001260: 2020 2020 2020 2370 7269 6e74 2822 7365        #print("se
-00001270: 7373 696f 6e3a 2025 7322 2025 2073 290a  ssion: %s" % s).
-00001280: 0a20 2020 2020 2020 2023 5370 6c69 7420  .        #Split 
-00001290: 7375 626a 6563 7420 5552 4920 666f 7220  subject URI for 
-000012a0: 7365 7373 696f 6e20 696e 746f 206e 616d  session into nam
-000012b0: 6573 7061 6365 2c20 7575 6964 0a20 2020  espace, uuid.   
-000012c0: 2020 2020 206e 6d2c 7365 7373 696f 6e5f       nm,session_
-000012d0: 7575 6964 203d 2073 706c 6974 5f75 7269  uuid = split_uri
-000012e0: 2873 290a 0a20 2020 2020 2020 2023 7072  (s)..        #pr
-000012f0: 696e 7428 2273 6573 7369 6f6e 2075 7569  int("session uui
-00001300: 643d 2025 7322 2025 7365 7373 696f 6e5f  d= %s" %session_
-00001310: 7575 6964 290a 0a20 2020 2020 2020 2023  uuid)..        #
-00001320: 696e 7374 616e 7469 6174 6520 7365 7373  instantiate sess
-00001330: 696f 6e20 7769 7468 2074 6869 7320 7575  ion with this uu
-00001340: 6964 0a20 2020 2020 2020 2073 6573 7369  id.        sessi
-00001350: 6f6e 203d 2053 6573 7369 6f6e 2870 726f  on = Session(pro
-00001360: 6a65 6374 3d70 726f 6a65 6374 2c20 7575  ject=project, uu
-00001370: 6964 3d73 6573 7369 6f6e 5f75 7569 642c  id=session_uuid,
-00001380: 6164 645f 6465 6661 756c 745f 7479 7065  add_default_type
-00001390: 3d46 616c 7365 290a 0a20 2020 2020 2020  =False)..       
-000013a0: 2023 6164 6420 7365 7373 696f 6e20 746f   #add session to
-000013b0: 2070 726f 6a65 6374 0a20 2020 2020 2020   project.       
-000013c0: 2070 726f 6a65 6374 2e61 6464 5f73 6573   project.add_ses
-000013d0: 7369 6f6e 7328 7365 7373 696f 6e29 0a0a  sions(session)..
-000013e0: 2020 2020 2020 2020 236e 6f77 2067 6574          #now get
-000013f0: 2072 656d 6169 6e69 6e67 206d 6574 6164   remaining metad
-00001400: 6174 6120 696e 2073 6573 7369 6f6e 206f  ata in session o
-00001410: 626a 6563 7420 616e 6420 6164 6420 746f  bject and add to
-00001420: 2073 6573 7369 6f6e 0a20 2020 2020 2020   session.       
-00001430: 2023 4379 636c 6520 7468 726f 7567 6820   #Cycle through 
-00001440: 5365 7373 696f 6e20 6d65 7461 6461 7461  Session metadata
-00001450: 2061 6464 696e 6720 746f 2070 726f 7620   adding to prov 
-00001460: 6772 6170 680a 2020 2020 2020 2020 6164  graph.        ad
-00001470: 645f 6d65 7461 6461 7461 5f66 6f72 5f73  d_metadata_for_s
-00001480: 7562 6a65 6374 2028 7264 665f 6772 6170  ubject (rdf_grap
-00001490: 685f 7061 7273 652c 732c 7072 6f6a 6563  h_parse,s,projec
-000014a0: 742e 6772 6170 682e 6e61 6d65 7370 6163  t.graph.namespac
-000014b0: 6573 2c73 6573 7369 6f6e 290a 0a20 2020  es,session)..   
-000014c0: 2020 2020 2023 5175 6572 7920 6772 6170       #Query grap
-000014d0: 6820 666f 7220 6163 7175 6973 7469 6f6e  h for acquistion
-000014e0: 7320 6463 743a 6973 5061 7274 4f66 2074  s dct:isPartOf t
-000014f0: 6865 2073 6573 7369 6f6e 0a20 2020 2020  he session.     
-00001500: 2020 2066 6f72 2061 6371 2069 6e20 7264     for acq in rd
-00001510: 665f 6772 6170 685f 7061 7273 652e 7375  f_graph_parse.su
-00001520: 626a 6563 7473 2870 7265 6469 6361 7465  bjects(predicate
-00001530: 3d43 6f6e 7374 616e 7473 2e44 4354 5b27  =Constants.DCT['
-00001540: 6973 5061 7274 4f66 275d 2c6f 626a 6563  isPartOf'],objec
-00001550: 743d 7329 3a0a 2020 2020 2020 2020 2020  t=s):.          
-00001560: 2020 2353 706c 6974 2073 7562 6a65 6374    #Split subject
-00001570: 2055 5249 2066 6f72 2073 6573 7369 6f6e   URI for session
-00001580: 2069 6e74 6f20 6e61 6d65 7370 6163 652c   into namespace,
-00001590: 2075 7569 640a 2020 2020 2020 2020 2020   uuid.          
-000015a0: 2020 6e6d 2c61 6371 5f75 7569 6420 3d20    nm,acq_uuid = 
-000015b0: 7370 6c69 745f 7572 6928 6163 7129 0a20  split_uri(acq). 
-000015c0: 2020 2020 2020 2020 2020 2023 2070 7269             # pri
-000015d0: 6e74 2822 6163 7175 6973 6974 696f 6e20  nt("acquisition 
-000015e0: 7575 6964 3a20 2573 2220 2561 6371 5f75  uuid: %s" %acq_u
-000015f0: 7569 6429 0a0a 2020 2020 2020 2020 2020  uid)..          
-00001600: 2020 2371 7565 7279 2066 6f72 2077 6865    #query for whe
-00001610: 7468 6572 2074 6869 7320 6973 2061 6e20  ther this is an 
-00001620: 4173 7365 7373 6d65 6e74 4163 7175 6973  AssessmentAcquis
-00001630: 6974 696f 6e20 6f66 206f 7468 6572 2041  ition of other A
-00001640: 6371 7569 7369 7469 6f6e 2c20 6574 632e  cquisition, etc.
-00001650: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
-00001660: 2072 6466 5f74 7970 6520 696e 2020 7264   rdf_type in  rd
-00001670: 665f 6772 6170 685f 7061 7273 652e 6f62  f_graph_parse.ob
-00001680: 6a65 6374 7328 7375 626a 6563 743d 6163  jects(subject=ac
-00001690: 712c 2070 7265 6469 6361 7465 3d52 4446  q, predicate=RDF
-000016a0: 2e74 7970 6529 3a0a 2020 2020 2020 2020  .type):.        
-000016b0: 2020 2020 2020 2020 2369 6620 7468 6973          #if this
-000016c0: 2069 7320 616e 2061 6371 7569 7369 7469   is an acquisiti
-000016d0: 6f6e 2061 6374 6976 6974 792c 2077 6869  on activity, whi
-000016e0: 6368 206b 696e 643f 0a20 2020 2020 2020  ch kind?.       
-000016f0: 2020 2020 2020 2020 2069 6620 7374 7228           if str(
-00001700: 7264 665f 7479 7065 2920 3d3d 2043 6f6e  rdf_type) == Con
-00001710: 7374 616e 7473 2e4e 4944 4d5f 4143 5155  stants.NIDM_ACQU
-00001720: 4953 4954 494f 4e5f 4143 5449 5649 5459  ISITION_ACTIVITY
-00001730: 2e75 7269 3a0a 2020 2020 2020 2020 2020  .uri:.          
-00001740: 2020 2020 2020 2020 2020 2366 6972 7374            #first
-00001750: 2066 696e 6420 7468 6520 656e 7469 7479   find the entity
-00001760: 2067 656e 6572 6174 6564 2062 7920 7468   generated by th
-00001770: 6973 2061 6371 7569 7369 7469 6f6e 2061  is acquisition a
-00001780: 6374 6976 6974 790a 2020 2020 2020 2020  ctivity.        
-00001790: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-000017a0: 6163 715f 6f62 6a20 696e 2072 6466 5f67  acq_obj in rdf_g
-000017b0: 7261 7068 5f70 6172 7365 2e73 7562 6a65  raph_parse.subje
-000017c0: 6374 7328 7072 6564 6963 6174 653d 436f  cts(predicate=Co
-000017d0: 6e73 7461 6e74 732e 5052 4f56 5b22 7761  nstants.PROV["wa
-000017e0: 7347 656e 6572 6174 6564 4279 225d 2c6f  sGeneratedBy"],o
-000017f0: 626a 6563 743d 6163 7129 3a0a 2020 2020  bject=acq):.    
-00001800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001810: 2020 2020 2353 706c 6974 2073 7562 6a65      #Split subje
-00001820: 6374 2055 5249 2066 6f72 2061 6371 7569  ct URI for acqui
-00001830: 7369 7469 6f6e 206f 626a 6563 7420 2865  sition object (e
-00001840: 6e74 6974 7929 2069 6e74 6f20 6e61 6d65  ntity) into name
-00001850: 7370 6163 652c 2075 7569 640a 2020 2020  space, uuid.    
-00001860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001870: 2020 2020 6e6d 2c61 6371 5f6f 626a 5f75      nm,acq_obj_u
-00001880: 7569 6420 3d20 7370 6c69 745f 7572 6928  uid = split_uri(
-00001890: 6163 715f 6f62 6a29 0a20 2020 2020 2020  acq_obj).       
-000018a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000018b0: 2023 7072 696e 7428 2261 6371 7569 7369   #print("acquisi
-000018c0: 7469 6f6e 206f 626a 6563 7420 7575 6964  tion object uuid
-000018d0: 3a20 2573 2220 2561 6371 5f6f 626a 5f75  : %s" %acq_obj_u
-000018e0: 7569 6429 0a0a 2020 2020 2020 2020 2020  uid)..          
-000018f0: 2020 2020 2020 2020 2020 2020 2020 2371                #q
-00001900: 7565 7279 2066 6f72 2077 6865 7468 6572  uery for whether
-00001910: 2074 6869 7320 6973 2061 6e20 4d52 4920   this is an MRI 
-00001920: 6163 7175 6973 6974 696f 6e20 6279 2077  acquisition by w
-00001930: 6179 206f 6620 6c6f 6f6b 696e 6720 6174  ay of looking at
-00001940: 2074 6865 2067 656e 6572 6174 6564 2065   the generated e
-00001950: 6e74 6974 7920 616e 6420 6465 7465 726d  ntity and determ
-00001960: 696e 696e 670a 2020 2020 2020 2020 2020  ining.          
-00001970: 2020 2020 2020 2020 2020 2020 2020 2369                #i
-00001980: 6620 6974 2068 6173 2074 6865 2074 7570  f it has the tup
-00001990: 6c65 205b 7575 6964 2043 6f6e 7374 616e  le [uuid Constan
-000019a0: 7473 2e4e 4944 4d5f 4143 5155 4953 4954  ts.NIDM_ACQUISIT
-000019b0: 494f 4e5f 4d4f 4441 4c49 5459 2043 6f6e  ION_MODALITY Con
-000019c0: 7374 616e 7473 2e4e 4944 4d5f 4d52 495d  stants.NIDM_MRI]
-000019d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000019e0: 2020 2020 2020 2020 2069 6620 2861 6371           if (acq
-000019f0: 5f6f 626a 2c55 5249 5265 6628 436f 6e73  _obj,URIRef(Cons
-00001a00: 7461 6e74 732e 4e49 444d 5f41 4351 5549  tants.NIDM_ACQUI
-00001a10: 5349 5449 4f4e 5f4d 4f44 414c 4954 592e  SITION_MODALITY.
-00001a20: 5f75 7269 292c 5552 4952 6566 2843 6f6e  _uri),URIRef(Con
-00001a30: 7374 616e 7473 2e4e 4944 4d5f 4d52 492e  stants.NIDM_MRI.
-00001a40: 5f75 7269 2929 2069 6e20 7264 665f 6772  _uri)) in rdf_gr
-00001a50: 6170 683a 0a0a 2020 2020 2020 2020 2020  aph:..          
-00001a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001a70: 2020 2363 6865 636b 2077 6865 7468 6572    #check whether
-00001a80: 2074 6869 7320 6163 7175 6973 6974 696f   this acquisitio
-00001a90: 6e20 6163 7469 7669 7479 2068 6173 2061  n activity has a
-00001aa0: 6c72 6561 6479 2062 6565 6e20 696e 7374  lready been inst
-00001ab0: 616e 7469 6174 6564 2028 6d61 7962 6520  antiated (maybe 
-00001ac0: 6966 2074 6865 7265 2061 7265 206d 756c  if there are mul
-00001ad0: 7469 706c 6520 6163 7175 6973 6974 696f  tiple acquisitio
+00000000: 6672 6f6d 2062 696e 6173 6369 6920 696d  from binascii im
+00000010: 706f 7274 2063 7263 3332 0a69 6d70 6f72  port crc32.impor
+00000020: 7420 6765 7470 6173 730a 696d 706f 7274  t getpass.import
+00000030: 206a 736f 6e0a 696d 706f 7274 206c 6f67   json.import log
+00000040: 6769 6e67 0a69 6d70 6f72 7420 6f73 0a69  ging.import os.i
+00000050: 6d70 6f72 7420 7379 730a 6672 6f6d 2075  mport sys.from u
+00000060: 7569 6420 696d 706f 7274 2055 5549 440a  uid import UUID.
+00000070: 6672 6f6d 2063 6f67 6e69 7469 7665 6174  from cognitiveat
+00000080: 6c61 732e 6170 6920 696d 706f 7274 2067  las.api import g
+00000090: 6574 5f63 6f6e 6365 7074 2c20 6765 745f  et_concept, get_
+000000a0: 6469 736f 7264 6572 0a66 726f 6d20 6461  disorder.from da
+000000b0: 7461 6c61 642e 7375 7070 6f72 742e 616e  talad.support.an
+000000c0: 6e65 7872 6570 6f20 696d 706f 7274 2041  nexrepo import A
+000000d0: 6e6e 6578 5265 706f 0a66 726f 6d20 6769  nnexRepo.from gi
+000000e0: 7468 7562 2069 6d70 6f72 7420 4769 7468  thub import Gith
+000000f0: 7562 2c20 4769 7468 7562 4578 6365 7074  ub, GithubExcept
+00000100: 696f 6e0a 6672 6f6d 206e 756d 7079 2069  ion.from numpy i
+00000110: 6d70 6f72 7420 6261 7365 5f72 6570 720a  mport base_repr.
+00000120: 696d 706f 7274 206f 6e74 7175 6572 7920  import ontquery 
+00000130: 6173 206f 710a 696d 706f 7274 2070 616e  as oq.import pan
+00000140: 6461 7320 6173 2070 640a 696d 706f 7274  das as pd.import
+00000150: 2070 726f 762e 6d6f 6465 6c20 6173 2070   prov.model as p
+00000160: 6d0a 6672 6f6d 2070 726f 762e 6d6f 6465  m.from prov.mode
+00000170: 6c20 696d 706f 7274 2049 6465 6e74 6966  l import Identif
+00000180: 6965 720a 6672 6f6d 2070 726f 762e 6d6f  ier.from prov.mo
+00000190: 6465 6c20 696d 706f 7274 204e 616d 6573  del import Names
+000001a0: 7061 6365 2061 7320 7072 6f76 4e61 6d65  pace as provName
+000001b0: 7370 6163 650a 6672 6f6d 2070 726f 762e  space.from prov.
+000001c0: 6d6f 6465 6c20 696d 706f 7274 2051 7561  model import Qua
+000001d0: 6c69 6669 6564 4e61 6d65 0a66 726f 6d20  lifiedName.from 
+000001e0: 7261 7069 6466 757a 7a20 696d 706f 7274  rapidfuzz import
+000001f0: 2066 757a 7a0a 6672 6f6d 2072 6466 6c69   fuzz.from rdfli
+00000200: 6220 696d 706f 7274 2052 4446 2c20 5244  b import RDF, RD
+00000210: 4653 2c20 4772 6170 682c 204c 6974 6572  FS, Graph, Liter
+00000220: 616c 2c20 4e61 6d65 7370 6163 652c 2055  al, Namespace, U
+00000230: 5249 5265 662c 2075 7469 6c0a 6672 6f6d  RIRef, util.from
+00000240: 2072 6466 6c69 622e 6e61 6d65 7370 6163   rdflib.namespac
+00000250: 6520 696d 706f 7274 2058 5344 2c20 7370  e import XSD, sp
+00000260: 6c69 745f 7572 690a 6672 6f6d 2072 6466  lit_uri.from rdf
+00000270: 6c69 622e 7265 736f 7572 6365 2069 6d70  lib.resource imp
+00000280: 6f72 7420 5265 736f 7572 6365 0a66 726f  ort Resource.fro
+00000290: 6d20 7264 666c 6962 2e75 7469 6c20 696d  m rdflib.util im
+000002a0: 706f 7274 2066 726f 6d5f 6e33 0a69 6d70  port from_n3.imp
+000002b0: 6f72 7420 7265 7175 6573 7473 0a69 6d70  ort requests.imp
+000002c0: 6f72 7420 7661 6c69 6461 746f 7273 0a66  ort validators.f
+000002d0: 726f 6d20 2e41 6371 7569 7369 7469 6f6e  rom .Acquisition
+000002e0: 2069 6d70 6f72 7420 4163 7175 6973 6974   import Acquisit
+000002f0: 696f 6e0a 6672 6f6d 202e 4163 7175 6973  ion.from .Acquis
+00000300: 6974 696f 6e4f 626a 6563 7420 696d 706f  itionObject impo
+00000310: 7274 2041 6371 7569 7369 7469 6f6e 4f62  rt AcquisitionOb
+00000320: 6a65 6374 0a66 726f 6d20 2e41 7373 6573  ject.from .Asses
+00000330: 736d 656e 7441 6371 7569 7369 7469 6f6e  smentAcquisition
+00000340: 2069 6d70 6f72 7420 4173 7365 7373 6d65   import Assessme
+00000350: 6e74 4163 7175 6973 6974 696f 6e0a 6672  ntAcquisition.fr
+00000360: 6f6d 202e 4173 7365 7373 6d65 6e74 4f62  om .AssessmentOb
+00000370: 6a65 6374 2069 6d70 6f72 7420 4173 7365  ject import Asse
+00000380: 7373 6d65 6e74 4f62 6a65 6374 0a66 726f  ssmentObject.fro
+00000390: 6d20 2e43 6f72 6520 696d 706f 7274 2067  m .Core import g
+000003a0: 6574 5555 4944 0a66 726f 6d20 2e44 6174  etUUID.from .Dat
+000003b0: 6145 6c65 6d65 6e74 2069 6d70 6f72 7420  aElement import 
+000003c0: 4461 7461 456c 656d 656e 740a 6672 6f6d  DataElement.from
+000003d0: 202e 4465 7269 7661 7469 7665 2069 6d70   .Derivative imp
+000003e0: 6f72 7420 4465 7269 7661 7469 7665 0a66  ort Derivative.f
+000003f0: 726f 6d20 2e44 6572 6976 6174 6976 654f  rom .DerivativeO
+00000400: 626a 6563 7420 696d 706f 7274 2044 6572  bject import Der
+00000410: 6976 6174 6976 654f 626a 6563 740a 6672  ivativeObject.fr
+00000420: 6f6d 202e 4d52 4163 7175 6973 6974 696f  om .MRAcquisitio
+00000430: 6e20 696d 706f 7274 204d 5241 6371 7569  n import MRAcqui
+00000440: 7369 7469 6f6e 0a66 726f 6d20 2e4d 524f  sition.from .MRO
+00000450: 626a 6563 7420 696d 706f 7274 204d 524f  bject import MRO
+00000460: 626a 6563 740a 6672 6f6d 202e 5045 5441  bject.from .PETA
+00000470: 6371 7569 7369 7469 6f6e 2069 6d70 6f72  cquisition impor
+00000480: 7420 5045 5441 6371 7569 7369 7469 6f6e  t PETAcquisition
+00000490: 0a66 726f 6d20 2e50 4554 4f62 6a65 6374  .from .PETObject
+000004a0: 2069 6d70 6f72 7420 5045 544f 626a 6563   import PETObjec
+000004b0: 740a 6672 6f6d 202e 5072 6f6a 6563 7420  t.from .Project 
+000004c0: 696d 706f 7274 2050 726f 6a65 6374 0a66  import Project.f
+000004d0: 726f 6d20 2e53 6573 7369 6f6e 2069 6d70  rom .Session imp
+000004e0: 6f72 7420 5365 7373 696f 6e0a 6672 6f6d  ort Session.from
+000004f0: 202e 2e63 6f72 6520 696d 706f 7274 2043   ..core import C
+00000500: 6f6e 7374 616e 7473 0a66 726f 6d20 2e2e  onstants.from ..
+00000510: 636f 7265 2e43 6f6e 7374 616e 7473 2069  core.Constants i
+00000520: 6d70 6f72 7420 4444 0a0a 6c6f 6767 6572  mport DD..logger
+00000530: 203d 206c 6f67 6769 6e67 2e67 6574 4c6f   = logging.getLo
+00000540: 6767 6572 285f 5f6e 616d 655f 5f29 0a0a  gger(__name__)..
+00000550: 2320 6461 7461 6c61 6420 2f20 6769 742d  # datalad / git-
+00000560: 616e 6e65 7820 736f 7572 6365 730a 0a23  annex sources..#
+00000570: 2073 6574 2069 6620 7765 2772 6520 7275   set if we're ru
+00000580: 6e6e 696e 6720 696e 2070 726f 6475 6374  nning in product
+00000590: 696f 6e20 6f72 2074 6573 7469 6e67 206d  ion or testing m
+000005a0: 6f64 650a 2320 494e 5445 524c 4558 5f4d  ode.# INTERLEX_M
+000005b0: 4f44 4520 3d20 2774 6573 7427 0a49 4e54  ODE = 'test'.INT
+000005c0: 4552 4c45 585f 4d4f 4445 203d 2022 7072  ERLEX_MODE = "pr
+000005d0: 6f64 7563 7469 6f6e 220a 6966 2049 4e54  oduction".if INT
+000005e0: 4552 4c45 585f 4d4f 4445 203d 3d20 2274  ERLEX_MODE == "t
+000005f0: 6573 7422 3a0a 2020 2020 494e 5445 524c  est":.    INTERL
+00000600: 4558 5f50 5245 4649 5820 3d20 2274 6d70  EX_PREFIX = "tmp
+00000610: 5f22 0a20 2020 2023 2049 4e54 4552 4c45  _".    # INTERLE
+00000620: 585f 454e 4450 4f49 4e54 203d 2022 6874  X_ENDPOINT = "ht
+00000630: 7470 733a 2f2f 6265 7461 2e73 6369 6372  tps://beta.scicr
+00000640: 756e 6368 2e6f 7267 2f61 7069 2f31 2f22  unch.org/api/1/"
+00000650: 0a20 2020 2049 4e54 4552 4c45 585f 454e  .    INTERLEX_EN
+00000660: 4450 4f49 4e54 203d 2022 6874 7470 733a  DPOINT = "https:
+00000670: 2f2f 7465 7374 332e 7363 6963 7275 6e63  //test3.scicrunc
+00000680: 682e 6f72 672f 6170 692f 312f 220a 656c  h.org/api/1/".el
+00000690: 6966 2049 4e54 4552 4c45 585f 4d4f 4445  if INTERLEX_MODE
+000006a0: 203d 3d20 2270 726f 6475 6374 696f 6e22   == "production"
+000006b0: 3a0a 2020 2020 494e 5445 524c 4558 5f50  :.    INTERLEX_P
+000006c0: 5245 4649 5820 3d20 2269 6c78 5f22 0a20  REFIX = "ilx_". 
+000006d0: 2020 2049 4e54 4552 4c45 585f 454e 4450     INTERLEX_ENDP
+000006e0: 4f49 4e54 203d 2022 6874 7470 733a 2f2f  OINT = "https://
+000006f0: 7363 6963 7275 6e63 682e 6f72 672f 6170  scicrunch.org/ap
+00000700: 692f 312f 220a 656c 7365 3a0a 2020 2020  i/1/".else:.    
+00000710: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
+00000720: 6f72 2822 4552 524f 523a 2049 6e74 6572  or("ERROR: Inter
+00000730: 6c65 7820 6d6f 6465 2063 616e 206f 6e6c  lex mode can onl
+00000740: 7920 6265 2027 7465 7374 2720 6f72 2027  y be 'test' or '
+00000750: 7072 6f64 7563 7469 6f6e 2722 290a 0a0a  production'")...
+00000760: 6465 6620 7361 6665 5f73 7472 696e 6728  def safe_string(
+00000770: 7329 3a0a 2020 2020 7265 7475 726e 2028  s):.    return (
+00000780: 0a20 2020 2020 2020 2073 2e73 7472 6970  .        s.strip
+00000790: 2829 0a20 2020 2020 2020 202e 7265 706c  ().        .repl
+000007a0: 6163 6528 2220 222c 2022 5f22 290a 2020  ace(" ", "_").  
+000007b0: 2020 2020 2020 2e72 6570 6c61 6365 2822        .replace("
+000007c0: 2d22 2c20 225f 2229 0a20 2020 2020 2020  -", "_").       
+000007d0: 202e 7265 706c 6163 6528 222c 222c 2022   .replace(",", "
+000007e0: 5f22 290a 2020 2020 2020 2020 2e72 6570  _").        .rep
+000007f0: 6c61 6365 2822 2822 2c20 225f 2229 0a20  lace("(", "_"). 
+00000800: 2020 2020 2020 202e 7265 706c 6163 6528         .replace(
+00000810: 2229 222c 2022 5f22 290a 2020 2020 2020  ")", "_").      
+00000820: 2020 2e72 6570 6c61 6365 2822 2722 2c20    .replace("'", 
+00000830: 225f 2229 0a20 2020 2020 2020 202e 7265  "_").        .re
+00000840: 706c 6163 6528 222f 222c 2022 5f22 290a  place("/", "_").
+00000850: 2020 2020 2020 2020 2e72 6570 6c61 6365          .replace
+00000860: 2822 2322 2c20 226e 756d 2229 0a20 2020  ("#", "num").   
+00000870: 2029 0a0a 0a64 6566 2072 6561 645f 6e69   )...def read_ni
+00000880: 646d 286e 6964 6d44 6f63 293a 0a20 2020  dm(nidmDoc):.   
+00000890: 2022 2222 0a20 2020 204c 6f61 6473 206e   """.    Loads n
+000008a0: 6964 6d44 6f63 2066 696c 6520 696e 746f  idmDoc file into
+000008b0: 204e 4944 4d2d 4578 7065 7269 6d65 6e74   NIDM-Experiment
+000008c0: 2073 7472 7563 7475 7265 7320 616e 6420   structures and 
+000008d0: 7265 7475 726e 7320 6f62 6a65 6374 730a  returns objects.
+000008e0: 0a20 2020 203a 6e69 646d 446f 633a 2061  .    :nidmDoc: a
+000008f0: 2076 616c 6964 2052 4446 204e 4944 4d2d   valid RDF NIDM-
+00000900: 6578 7065 7269 6d65 6e74 2064 6f63 756d  experiment docum
+00000910: 656e 7420 2864 6573 6572 6961 6c69 7a61  ent (deserializa
+00000920: 7469 6f6e 2066 6f72 6d61 7473 2073 7570  tion formats sup
+00000930: 706f 7274 6564 2062 7920 5244 464c 6962  ported by RDFLib
+00000940: 290a 0a20 2020 203a 7265 7475 726e 3a20  )..    :return: 
+00000950: 4e49 444d 2050 726f 6a65 6374 0a0a 2020  NIDM Project..  
+00000960: 2020 2222 220a 0a20 2020 2023 2072 6561    """..    # rea
+00000970: 6420 5244 4620 6669 6c65 2069 6e74 6f20  d RDF file into 
+00000980: 7465 6d70 6f72 6172 7920 6772 6170 680a  temporary graph.
+00000990: 2020 2020 7264 665f 6772 6170 6820 3d20      rdf_graph = 
+000009a0: 4772 6170 6828 290a 2020 2020 7264 665f  Graph().    rdf_
+000009b0: 6772 6170 685f 7061 7273 6520 3d20 7264  graph_parse = rd
+000009c0: 665f 6772 6170 682e 7061 7273 6528 6e69  f_graph.parse(ni
+000009d0: 646d 446f 632c 2066 6f72 6d61 743d 7574  dmDoc, format=ut
+000009e0: 696c 2e67 7565 7373 5f66 6f72 6d61 7428  il.guess_format(
+000009f0: 6e69 646d 446f 6329 290a 0a20 2020 2023  nidmDoc))..    #
+00000a00: 2051 7565 7279 2067 7261 7068 2066 6f72   Query graph for
+00000a10: 2070 726f 6a65 6374 206d 6574 6164 6174   project metadat
+00000a20: 6120 616e 6420 6372 6561 7465 2070 726f  a and create pro
+00000a30: 6a65 6374 206c 6576 656c 206f 626a 6563  ject level objec
+00000a40: 7473 0a20 2020 2023 2047 6574 2073 7562  ts.    # Get sub
+00000a50: 6a65 6374 2055 5249 2066 6f72 2070 726f  ject URI for pro
+00000a60: 6a65 6374 0a20 2020 2070 726f 6a5f 6964  ject.    proj_id
+00000a70: 203d 204e 6f6e 650a 2020 2020 666f 7220   = None.    for 
+00000a80: 7320 696e 2072 6466 5f67 7261 7068 5f70  s in rdf_graph_p
+00000a90: 6172 7365 2e73 7562 6a65 6374 7328 0a20  arse.subjects(. 
+00000aa0: 2020 2020 2020 2070 7265 6469 6361 7465         predicate
+00000ab0: 3d52 4446 2e74 7970 652c 206f 626a 6563  =RDF.type, objec
+00000ac0: 743d 5552 4952 6566 2843 6f6e 7374 616e  t=URIRef(Constan
+00000ad0: 7473 2e4e 4944 4d5f 5052 4f4a 4543 542e  ts.NIDM_PROJECT.
+00000ae0: 7572 6929 0a20 2020 2029 3a0a 2020 2020  uri).    ):.    
+00000af0: 2020 2020 2320 7072 696e 7428 7329 0a20      # print(s). 
+00000b00: 2020 2020 2020 2070 726f 6a5f 6964 203d         proj_id =
+00000b10: 2073 0a0a 2020 2020 6966 2070 726f 6a5f   s..    if proj_
+00000b20: 6964 2069 7320 4e6f 6e65 3a0a 2020 2020  id is None:.    
+00000b30: 2020 2020 7072 696e 7428 6622 4572 726f      print(f"Erro
+00000b40: 7220 7265 6164 696e 6720 4e49 444d 2d45  r reading NIDM-E
+00000b50: 7870 2044 6f63 756d 656e 7420 7b6e 6964  xp Document {nid
+00000b60: 6d44 6f63 7d2c 204d 7573 7420 6861 7665  mDoc}, Must have
+00000b70: 2050 726f 6a65 6374 204f 626a 6563 7422   Project Object"
+00000b80: 290a 2020 2020 2020 2020 7072 696e 7428  ).        print(
+00000b90: 290a 2020 2020 2020 2020 6372 6561 7465  ).        create
+00000ba0: 5f6f 626a 203d 2069 6e70 7574 2822 5368  _obj = input("Sh
+00000bb0: 6f75 6c64 2072 6561 645f 6e69 646d 2063  ould read_nidm c
+00000bc0: 7265 6174 6520 6120 5072 6f6a 6563 7420  reate a Project 
+00000bd0: 6f62 6a65 6374 2066 6f72 2079 6f75 205b  object for you [
+00000be0: 7965 735d 3a20 2229 0a20 2020 2020 2020  yes]: ").       
+00000bf0: 2069 6620 6372 6561 7465 5f6f 626a 2069   if create_obj i
+00000c00: 6e20 2822 7965 7322 2c20 2222 293a 0a20  n ("yes", ""):. 
+00000c10: 2020 2020 2020 2020 2020 2070 726f 6a65             proje
+00000c20: 6374 203d 2050 726f 6a65 6374 2865 6d70  ct = Project(emp
+00000c30: 7479 5f67 7261 7068 3d54 7275 652c 2061  ty_graph=True, a
+00000c40: 6464 5f64 6566 6175 6c74 5f74 7970 653d  dd_default_type=
+00000c50: 5472 7565 290a 2020 2020 2020 2020 2020  True).          
+00000c60: 2020 2320 6164 6420 6e61 6d65 7370 6163    # add namespac
+00000c70: 6573 2074 6f20 7072 6f76 2067 7261 7068  es to prov graph
+00000c80: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+00000c90: 206e 616d 652c 206e 616d 6573 7061 6365   name, namespace
+00000ca0: 2069 6e20 7264 665f 6772 6170 685f 7061   in rdf_graph_pa
+00000cb0: 7273 652e 6e61 6d65 7370 6163 6573 2829  rse.namespaces()
+00000cc0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00000cd0: 2020 2320 736b 6970 2074 6865 7365 2064    # skip these d
+00000ce0: 6566 6175 6c74 206e 616d 6573 7061 6365  efault namespace
+00000cf0: 7320 696e 2070 726f 7620 446f 6375 6d65  s in prov Docume
+00000d00: 6e74 0a20 2020 2020 2020 2020 2020 2020  nt.             
+00000d10: 2020 2069 6620 6e61 6d65 206e 6f74 2069     if name not i
+00000d20: 6e20 2822 7072 6f76 222c 2022 7873 6422  n ("prov", "xsd"
+00000d30: 2c20 226e 6964 6d22 2c20 226e 6969 7269  , "nidm", "niiri
+00000d40: 2229 3a0a 2020 2020 2020 2020 2020 2020  "):.            
+00000d50: 2020 2020 2020 2020 7072 6f6a 6563 742e          project.
+00000d60: 6772 6170 682e 6164 645f 6e61 6d65 7370  graph.add_namesp
+00000d70: 6163 6528 6e61 6d65 2c20 6e61 6d65 7370  ace(name, namesp
+00000d80: 6163 6529 0a0a 2020 2020 2020 2020 656c  ace)..        el
+00000d90: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+00000da0: 7379 732e 6578 6974 2831 290a 2020 2020  sys.exit(1).    
+00000db0: 656c 7365 3a0a 2020 2020 2020 2020 2320  else:.        # 
+00000dc0: 5370 6c69 7420 7375 626a 6563 7420 5552  Split subject UR
+00000dd0: 4920 696e 746f 206e 616d 6573 7061 6365  I into namespace
+00000de0: 2c20 7465 726d 0a20 2020 2020 2020 205f  , term.        _
+00000df0: 2c20 7072 6f6a 6563 745f 7575 6964 203d  , project_uuid =
+00000e00: 2073 706c 6974 5f75 7269 2870 726f 6a5f   split_uri(proj_
+00000e10: 6964 290a 0a20 2020 2020 2020 2023 2063  id)..        # c
+00000e20: 7265 6174 6520 656d 7074 7920 7072 6f76  reate empty prov
+00000e30: 2067 7261 7068 0a20 2020 2020 2020 2070   graph.        p
+00000e40: 726f 6a65 6374 203d 2050 726f 6a65 6374  roject = Project
+00000e50: 2865 6d70 7479 5f67 7261 7068 3d54 7275  (empty_graph=Tru
+00000e60: 652c 2075 7569 643d 7072 6f6a 6563 745f  e, uuid=project_
+00000e70: 7575 6964 2c20 6164 645f 6465 6661 756c  uuid, add_defaul
+00000e80: 745f 7479 7065 3d46 616c 7365 290a 0a20  t_type=False).. 
+00000e90: 2020 2020 2020 2023 2061 6464 206e 616d         # add nam
+00000ea0: 6573 7061 6365 7320 746f 2070 726f 7620  espaces to prov 
+00000eb0: 6772 6170 680a 2020 2020 2020 2020 666f  graph.        fo
+00000ec0: 7220 6e61 6d65 2c20 6e61 6d65 7370 6163  r name, namespac
+00000ed0: 6520 696e 2072 6466 5f67 7261 7068 5f70  e in rdf_graph_p
+00000ee0: 6172 7365 2e6e 616d 6573 7061 6365 7328  arse.namespaces(
+00000ef0: 293a 0a20 2020 2020 2020 2020 2020 2023  ):.            #
+00000f00: 2073 6b69 7020 7468 6573 6520 6465 6661   skip these defa
+00000f10: 756c 7420 6e61 6d65 7370 6163 6573 2069  ult namespaces i
+00000f20: 6e20 7072 6f76 2044 6f63 756d 656e 740a  n prov Document.
+00000f30: 2020 2020 2020 2020 2020 2020 6966 206e              if n
+00000f40: 616d 6520 6e6f 7420 696e 2028 2270 726f  ame not in ("pro
+00000f50: 7622 2c20 2278 7364 222c 2022 6e69 646d  v", "xsd", "nidm
+00000f60: 222c 2022 6e69 6972 6922 293a 0a20 2020  ", "niiri"):.   
+00000f70: 2020 2020 2020 2020 2020 2020 2070 726f               pro
+00000f80: 6a65 6374 2e67 7261 7068 2e61 6464 5f6e  ject.graph.add_n
+00000f90: 616d 6573 7061 6365 286e 616d 652c 206e  amespace(name, n
+00000fa0: 616d 6573 7061 6365 290a 0a20 2020 2020  amespace)..     
+00000fb0: 2020 2023 2043 7963 6c65 2074 6872 6f75     # Cycle throu
+00000fc0: 6768 2050 726f 6a65 6374 206d 6574 6164  gh Project metad
+00000fd0: 6174 6120 6164 6469 6e67 2074 6f20 7072  ata adding to pr
+00000fe0: 6f76 2067 7261 7068 0a20 2020 2020 2020  ov graph.       
+00000ff0: 2061 6464 5f6d 6574 6164 6174 615f 666f   add_metadata_fo
+00001000: 725f 7375 626a 6563 7428 0a20 2020 2020  r_subject(.     
+00001010: 2020 2020 2020 2072 6466 5f67 7261 7068         rdf_graph
+00001020: 5f70 6172 7365 2c20 7072 6f6a 5f69 642c  _parse, proj_id,
+00001030: 2070 726f 6a65 6374 2e67 7261 7068 2e6e   project.graph.n
+00001040: 616d 6573 7061 6365 732c 2070 726f 6a65  amespaces, proje
+00001050: 6374 0a20 2020 2020 2020 2029 0a0a 2020  ct.        )..  
+00001060: 2020 2320 5175 6572 7920 6772 6170 6820    # Query graph 
+00001070: 666f 7220 7365 7373 696f 6e73 2c20 696e  for sessions, in
+00001080: 7374 616e 7469 6174 6520 7365 7373 696f  stantiate sessio
+00001090: 6e20 6f62 6a65 6374 732c 2061 6e64 2061  n objects, and a
+000010a0: 6464 2074 6f20 7072 6f6a 6563 742e 5f73  dd to project._s
+000010b0: 6573 7369 6f6e 206c 6973 740a 2020 2020  ession list.    
+000010c0: 2320 4765 7420 7375 626a 6563 7420 5552  # Get subject UR
+000010d0: 4920 666f 7220 7365 7373 696f 6e73 0a20  I for sessions. 
+000010e0: 2020 2066 6f72 2073 2069 6e20 7264 665f     for s in rdf_
+000010f0: 6772 6170 685f 7061 7273 652e 7375 626a  graph_parse.subj
+00001100: 6563 7473 280a 2020 2020 2020 2020 7072  ects(.        pr
+00001110: 6564 6963 6174 653d 5244 462e 7479 7065  edicate=RDF.type
+00001120: 2c20 6f62 6a65 6374 3d55 5249 5265 6628  , object=URIRef(
+00001130: 436f 6e73 7461 6e74 732e 4e49 444d 5f53  Constants.NIDM_S
+00001140: 4553 5349 4f4e 2e75 7269 290a 2020 2020  ESSION.uri).    
+00001150: 293a 0a20 2020 2020 2020 2023 2070 7269  ):.        # pri
+00001160: 6e74 2866 2273 6573 7369 6f6e 3a20 7b73  nt(f"session: {s
+00001170: 7d22 290a 0a20 2020 2020 2020 2023 2053  }")..        # S
+00001180: 706c 6974 2073 7562 6a65 6374 2055 5249  plit subject URI
+00001190: 2066 6f72 2073 6573 7369 6f6e 2069 6e74   for session int
+000011a0: 6f20 6e61 6d65 7370 6163 652c 2075 7569  o namespace, uui
+000011b0: 640a 2020 2020 2020 2020 5f2c 2073 6573  d.        _, ses
+000011c0: 7369 6f6e 5f75 7569 6420 3d20 7370 6c69  sion_uuid = spli
+000011d0: 745f 7572 6928 7329 0a0a 2020 2020 2020  t_uri(s)..      
+000011e0: 2020 2320 7072 696e 7428 6622 7365 7373    # print(f"sess
+000011f0: 696f 6e20 7575 6964 3d20 7b73 6573 7369  ion uuid= {sessi
+00001200: 6f6e 5f75 7569 647d 2229 0a0a 2020 2020  on_uuid}")..    
+00001210: 2020 2020 2320 696e 7374 616e 7469 6174      # instantiat
+00001220: 6520 7365 7373 696f 6e20 7769 7468 2074  e session with t
+00001230: 6869 7320 7575 6964 0a20 2020 2020 2020  his uuid.       
+00001240: 2073 6573 7369 6f6e 203d 2053 6573 7369   session = Sessi
+00001250: 6f6e 2870 726f 6a65 6374 3d70 726f 6a65  on(project=proje
+00001260: 6374 2c20 7575 6964 3d73 6573 7369 6f6e  ct, uuid=session
+00001270: 5f75 7569 642c 2061 6464 5f64 6566 6175  _uuid, add_defau
+00001280: 6c74 5f74 7970 653d 4661 6c73 6529 0a0a  lt_type=False)..
+00001290: 2020 2020 2020 2020 2320 6164 6420 7365          # add se
+000012a0: 7373 696f 6e20 746f 2070 726f 6a65 6374  ssion to project
+000012b0: 0a20 2020 2020 2020 2070 726f 6a65 6374  .        project
+000012c0: 2e61 6464 5f73 6573 7369 6f6e 7328 7365  .add_sessions(se
+000012d0: 7373 696f 6e29 0a0a 2020 2020 2020 2020  ssion)..        
+000012e0: 2320 6e6f 7720 6765 7420 7265 6d61 696e  # now get remain
+000012f0: 696e 6720 6d65 7461 6461 7461 2069 6e20  ing metadata in 
+00001300: 7365 7373 696f 6e20 6f62 6a65 6374 2061  session object a
+00001310: 6e64 2061 6464 2074 6f20 7365 7373 696f  nd add to sessio
+00001320: 6e0a 2020 2020 2020 2020 2320 4379 636c  n.        # Cycl
+00001330: 6520 7468 726f 7567 6820 5365 7373 696f  e through Sessio
+00001340: 6e20 6d65 7461 6461 7461 2061 6464 696e  n metadata addin
+00001350: 6720 746f 2070 726f 7620 6772 6170 680a  g to prov graph.
+00001360: 2020 2020 2020 2020 6164 645f 6d65 7461          add_meta
+00001370: 6461 7461 5f66 6f72 5f73 7562 6a65 6374  data_for_subject
+00001380: 2872 6466 5f67 7261 7068 5f70 6172 7365  (rdf_graph_parse
+00001390: 2c20 732c 2070 726f 6a65 6374 2e67 7261  , s, project.gra
+000013a0: 7068 2e6e 616d 6573 7061 6365 732c 2073  ph.namespaces, s
+000013b0: 6573 7369 6f6e 290a 0a20 2020 2020 2020  ession)..       
+000013c0: 2023 2051 7565 7279 2067 7261 7068 2066   # Query graph f
+000013d0: 6f72 2061 6371 7569 7374 696f 6e73 2064  or acquistions d
+000013e0: 6374 3a69 7350 6172 744f 6620 7468 6520  ct:isPartOf the 
+000013f0: 7365 7373 696f 6e0a 2020 2020 2020 2020  session.        
+00001400: 666f 7220 6163 7120 696e 2072 6466 5f67  for acq in rdf_g
+00001410: 7261 7068 5f70 6172 7365 2e73 7562 6a65  raph_parse.subje
+00001420: 6374 7328 0a20 2020 2020 2020 2020 2020  cts(.           
+00001430: 2070 7265 6469 6361 7465 3d43 6f6e 7374   predicate=Const
+00001440: 616e 7473 2e44 4354 5b22 6973 5061 7274  ants.DCT["isPart
+00001450: 4f66 225d 2c20 6f62 6a65 6374 3d73 0a20  Of"], object=s. 
+00001460: 2020 2020 2020 2029 3a0a 2020 2020 2020         ):.      
+00001470: 2020 2020 2020 2320 5370 6c69 7420 7375        # Split su
+00001480: 626a 6563 7420 5552 4920 666f 7220 7365  bject URI for se
+00001490: 7373 696f 6e20 696e 746f 206e 616d 6573  ssion into names
+000014a0: 7061 6365 2c20 7575 6964 0a20 2020 2020  pace, uuid.     
+000014b0: 2020 2020 2020 205f 2c20 6163 715f 7575         _, acq_uu
+000014c0: 6964 203d 2073 706c 6974 5f75 7269 2861  id = split_uri(a
+000014d0: 6371 290a 2020 2020 2020 2020 2020 2020  cq).            
+000014e0: 2320 7072 696e 7428 2261 6371 7569 7369  # print("acquisi
+000014f0: 7469 6f6e 2075 7569 643a 222c 2061 6371  tion uuid:", acq
+00001500: 5f75 7569 6429 0a0a 2020 2020 2020 2020  _uuid)..        
+00001510: 2020 2020 2320 7175 6572 7920 666f 7220      # query for 
+00001520: 7768 6574 6865 7220 7468 6973 2069 7320  whether this is 
+00001530: 616e 2041 7373 6573 736d 656e 7441 6371  an AssessmentAcq
+00001540: 7569 7369 7469 6f6e 206f 6620 6f74 6865  uisition of othe
+00001550: 7220 4163 7175 6973 6974 696f 6e2c 2065  r Acquisition, e
+00001560: 7463 2e0a 2020 2020 2020 2020 2020 2020  tc..            
+00001570: 666f 7220 7264 665f 7479 7065 2069 6e20  for rdf_type in 
+00001580: 7264 665f 6772 6170 685f 7061 7273 652e  rdf_graph_parse.
+00001590: 6f62 6a65 6374 7328 7375 626a 6563 743d  objects(subject=
+000015a0: 6163 712c 2070 7265 6469 6361 7465 3d52  acq, predicate=R
+000015b0: 4446 2e74 7970 6529 3a0a 2020 2020 2020  DF.type):.      
+000015c0: 2020 2020 2020 2020 2020 2320 6966 2074            # if t
+000015d0: 6869 7320 6973 2061 6e20 6163 7175 6973  his is an acquis
+000015e0: 6974 696f 6e20 6163 7469 7669 7479 2c20  ition activity, 
+000015f0: 7768 6963 6820 6b69 6e64 3f0a 2020 2020  which kind?.    
+00001600: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00001610: 7472 2872 6466 5f74 7970 6529 203d 3d20  tr(rdf_type) == 
+00001620: 436f 6e73 7461 6e74 732e 4e49 444d 5f41  Constants.NIDM_A
+00001630: 4351 5549 5349 5449 4f4e 5f41 4354 4956  CQUISITION_ACTIV
+00001640: 4954 592e 7572 693a 0a20 2020 2020 2020  ITY.uri:.       
+00001650: 2020 2020 2020 2020 2020 2020 2023 2066               # f
+00001660: 6972 7374 2066 696e 6420 7468 6520 656e  irst find the en
+00001670: 7469 7479 2067 656e 6572 6174 6564 2062  tity generated b
+00001680: 7920 7468 6973 2061 6371 7569 7369 7469  y this acquisiti
+00001690: 6f6e 2061 6374 6976 6974 790a 2020 2020  on activity.    
+000016a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000016b0: 666f 7220 6163 715f 6f62 6a20 696e 2072  for acq_obj in r
+000016c0: 6466 5f67 7261 7068 5f70 6172 7365 2e73  df_graph_parse.s
+000016d0: 7562 6a65 6374 7328 0a20 2020 2020 2020  ubjects(.       
+000016e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000016f0: 2070 7265 6469 6361 7465 3d43 6f6e 7374   predicate=Const
+00001700: 616e 7473 2e50 524f 565b 2277 6173 4765  ants.PROV["wasGe
+00001710: 6e65 7261 7465 6442 7922 5d2c 206f 626a  neratedBy"], obj
+00001720: 6563 743d 6163 710a 2020 2020 2020 2020  ect=acq.        
+00001730: 2020 2020 2020 2020 2020 2020 293a 0a20              ):. 
+00001740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001750: 2020 2020 2020 2023 2053 706c 6974 2073         # Split s
+00001760: 7562 6a65 6374 2055 5249 2066 6f72 2061  ubject URI for a
+00001770: 6371 7569 7369 7469 6f6e 206f 626a 6563  cquisition objec
+00001780: 7420 2865 6e74 6974 7929 2069 6e74 6f20  t (entity) into 
+00001790: 6e61 6d65 7370 6163 652c 2075 7569 640a  namespace, uuid.
+000017a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000017b0: 2020 2020 2020 2020 5f2c 2061 6371 5f6f          _, acq_o
+000017c0: 626a 5f75 7569 6420 3d20 7370 6c69 745f  bj_uuid = split_
+000017d0: 7572 6928 6163 715f 6f62 6a29 0a20 2020  uri(acq_obj).   
+000017e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000017f0: 2020 2020 2023 2070 7269 6e74 2822 6163       # print("ac
+00001800: 7175 6973 6974 696f 6e20 6f62 6a65 6374  quisition object
+00001810: 2075 7569 643a 222c 2061 6371 5f6f 626a   uuid:", acq_obj
+00001820: 5f75 7569 6429 0a0a 2020 2020 2020 2020  _uuid)..        
+00001830: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001840: 2320 7175 6572 7920 666f 7220 7768 6574  # query for whet
+00001850: 6865 7220 7468 6973 2069 7320 616e 204d  her this is an M
+00001860: 5249 2061 6371 7569 7369 7469 6f6e 2062  RI acquisition b
+00001870: 7920 7761 7920 6f66 206c 6f6f 6b69 6e67  y way of looking
+00001880: 2061 7420 7468 6520 6765 6e65 7261 7465   at the generate
+00001890: 6420 656e 7469 7479 2061 6e64 2064 6574  d entity and det
+000018a0: 6572 6d69 6e69 6e67 0a20 2020 2020 2020  ermining.       
+000018b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000018c0: 2023 2069 6620 6974 2068 6173 2074 6865   # if it has the
+000018d0: 2074 7570 6c65 205b 7575 6964 2043 6f6e   tuple [uuid Con
+000018e0: 7374 616e 7473 2e4e 4944 4d5f 4143 5155  stants.NIDM_ACQU
+000018f0: 4953 4954 494f 4e5f 4d4f 4441 4c49 5459  ISITION_MODALITY
+00001900: 2043 6f6e 7374 616e 7473 2e4e 4944 4d5f   Constants.NIDM_
+00001910: 4d52 495d 0a20 2020 2020 2020 2020 2020  MRI].           
+00001920: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00001930: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00001940: 2020 2020 2020 2020 2020 2020 2020 6163                ac
+00001950: 715f 6f62 6a2c 0a20 2020 2020 2020 2020  q_obj,.         
+00001960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001970: 2020 2055 5249 5265 6628 436f 6e73 7461     URIRef(Consta
+00001980: 6e74 732e 4e49 444d 5f41 4351 5549 5349  nts.NIDM_ACQUISI
+00001990: 5449 4f4e 5f4d 4f44 414c 4954 592e 5f75  TION_MODALITY._u
+000019a0: 7269 292c 0a20 2020 2020 2020 2020 2020  ri),.           
+000019b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000019c0: 2055 5249 5265 6628 436f 6e73 7461 6e74   URIRef(Constant
+000019d0: 732e 4e49 444d 5f4d 5249 2e5f 7572 6929  s.NIDM_MRI._uri)
+000019e0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000019f0: 2020 2020 2020 2020 2020 2920 696e 2072            ) in r
+00001a00: 6466 5f67 7261 7068 3a0a 2020 2020 2020  df_graph:.      
+00001a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001a20: 2020 2020 2020 2320 6368 6563 6b20 7768        # check wh
+00001a30: 6574 6865 7220 7468 6973 2061 6371 7569  ether this acqui
+00001a40: 7369 7469 6f6e 2061 6374 6976 6974 7920  sition activity 
+00001a50: 6861 7320 616c 7265 6164 7920 6265 656e  has already been
+00001a60: 2069 6e73 7461 6e74 6961 7465 6420 286d   instantiated (m
+00001a70: 6179 6265 2069 6620 7468 6572 6520 6172  aybe if there ar
+00001a80: 6520 6d75 6c74 6970 6c65 2061 6371 7569  e multiple acqui
+00001a90: 7369 7469 6f6e 0a20 2020 2020 2020 2020  sition.         
+00001aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001ab0: 2020 2023 2065 6e74 6974 6965 7320 7072     # entities pr
+00001ac0: 6f76 3a77 6173 4765 6e65 7261 7465 6442  ov:wasGeneratedB
+00001ad0: 7920 7468 6520 6163 7175 6973 6974 696f  y the acquisitio
 00001ae0: 6e0a 2020 2020 2020 2020 2020 2020 2020  n.              
-00001af0: 2020 2020 2020 2020 2020 2020 2020 2365                #e
-00001b00: 6e74 6974 6965 7320 7072 6f76 3a77 6173  ntities prov:was
-00001b10: 4765 6e65 7261 7465 6442 7920 7468 6520  GeneratedBy the 
-00001b20: 6163 7175 6973 6974 696f 6e0a 2020 2020  acquisition.    
+00001af0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00001b00: 206e 6f74 2073 6573 7369 6f6e 2e61 6371   not session.acq
+00001b10: 7569 7369 7469 6f6e 5f65 7869 7374 2861  uisition_exist(a
+00001b20: 6371 5f75 7569 6429 3a0a 2020 2020 2020  cq_uuid):.      
 00001b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001b40: 2020 2020 2020 2020 6966 206e 6f74 2073          if not s
-00001b50: 6573 7369 6f6e 2e61 6371 7569 7369 7469  ession.acquisiti
-00001b60: 6f6e 5f65 7869 7374 2861 6371 5f75 7569  on_exist(acq_uui
-00001b70: 6429 3a0a 2020 2020 2020 2020 2020 2020  d):.            
-00001b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001b90: 2020 2020 6163 7175 6973 6974 696f 6e3d      acquisition=
-00001ba0: 4d52 4163 7175 6973 6974 696f 6e28 7365  MRAcquisition(se
-00001bb0: 7373 696f 6e3d 7365 7373 696f 6e2c 7575  ssion=session,uu
-00001bc0: 6964 3d61 6371 5f75 7569 642c 6164 645f  id=acq_uuid,add_
-00001bd0: 6465 6661 756c 745f 7479 7065 3d46 616c  default_type=Fal
-00001be0: 7365 290a 2020 2020 2020 2020 2020 2020  se).            
-00001bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001c00: 2020 2020 7365 7373 696f 6e2e 6164 645f      session.add_
-00001c10: 6163 7175 6973 6974 696f 6e28 6163 7175  acquisition(acqu
-00001c20: 6973 6974 696f 6e29 0a20 2020 2020 2020  isition).       
+00001b40: 2020 2020 2020 2020 2020 6163 7175 6973            acquis
+00001b50: 6974 696f 6e20 3d20 4d52 4163 7175 6973  ition = MRAcquis
+00001b60: 6974 696f 6e28 0a20 2020 2020 2020 2020  ition(.         
+00001b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001b80: 2020 2020 2020 2020 2020 2073 6573 7369             sessi
+00001b90: 6f6e 3d73 6573 7369 6f6e 2c0a 2020 2020  on=session,.    
+00001ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001bc0: 7575 6964 3d61 6371 5f75 7569 642c 0a20  uuid=acq_uuid,. 
+00001bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001bf0: 2020 2061 6464 5f64 6566 6175 6c74 5f74     add_default_t
+00001c00: 7970 653d 4661 6c73 652c 0a20 2020 2020  ype=False,.     
+00001c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001c20: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
 00001c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001c40: 2020 2020 2020 2020 2023 4379 636c 6520           #Cycle 
-00001c50: 7468 726f 7567 6820 7265 6d61 696e 696e  through remainin
-00001c60: 6720 6d65 7461 6461 7461 2066 6f72 2061  g metadata for a
-00001c70: 6371 7569 7369 7469 6f6e 2061 6374 6976  cquisition activ
-00001c80: 6974 7920 616e 6420 6164 6420 6174 7472  ity and add attr
-00001c90: 6962 7574 6573 0a20 2020 2020 2020 2020  ibutes.         
-00001ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001cb0: 2020 2020 2020 2061 6464 5f6d 6574 6164         add_metad
-00001cc0: 6174 615f 666f 725f 7375 626a 6563 7420  ata_for_subject 
-00001cd0: 2872 6466 5f67 7261 7068 5f70 6172 7365  (rdf_graph_parse
-00001ce0: 2c61 6371 2c70 726f 6a65 6374 2e67 7261  ,acq,project.gra
-00001cf0: 7068 2e6e 616d 6573 7061 6365 732c 6163  ph.namespaces,ac
-00001d00: 7175 6973 6974 696f 6e29 0a0a 0a20 2020  quisition)...   
-00001d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001d20: 2020 2020 2020 2020 2023 616e 6420 6164           #and ad
-00001d30: 6420 6163 7175 6973 6974 696f 6e20 6f62  d acquisition ob
-00001d40: 6a65 6374 0a20 2020 2020 2020 2020 2020  ject.           
+00001c40: 2020 2020 2020 2020 2020 2020 2073 6573               ses
+00001c50: 7369 6f6e 2e61 6464 5f61 6371 7569 7369  sion.add_acquisi
+00001c60: 7469 6f6e 2861 6371 7569 7369 7469 6f6e  tion(acquisition
+00001c70: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00001c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001c90: 2020 2320 4379 636c 6520 7468 726f 7567    # Cycle throug
+00001ca0: 6820 7265 6d61 696e 696e 6720 6d65 7461  h remaining meta
+00001cb0: 6461 7461 2066 6f72 2061 6371 7569 7369  data for acquisi
+00001cc0: 7469 6f6e 2061 6374 6976 6974 7920 616e  tion activity an
+00001cd0: 6420 6164 6420 6174 7472 6962 7574 6573  d add attributes
+00001ce0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001d00: 2061 6464 5f6d 6574 6164 6174 615f 666f   add_metadata_fo
+00001d10: 725f 7375 626a 6563 7428 0a20 2020 2020  r_subject(.     
+00001d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001d30: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+00001d40: 6466 5f67 7261 7068 5f70 6172 7365 2c0a  df_graph_parse,.
 00001d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001d60: 2061 6371 7569 7369 7469 6f6e 5f6f 626a   acquisition_obj
-00001d70: 3d4d 524f 626a 6563 7428 6163 7175 6973  =MRObject(acquis
-00001d80: 6974 696f 6e3d 6163 7175 6973 6974 696f  ition=acquisitio
-00001d90: 6e2c 7575 6964 3d61 6371 5f6f 626a 5f75  n,uuid=acq_obj_u
-00001da0: 7569 642c 6164 645f 6465 6661 756c 745f  uid,add_default_
-00001db0: 7479 7065 3d46 616c 7365 290a 2020 2020  type=False).    
+00001d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001d70: 2020 2020 6163 712c 0a20 2020 2020 2020      acq,.       
+00001d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001d90: 2020 2020 2020 2020 2020 2020 2070 726f               pro
+00001da0: 6a65 6374 2e67 7261 7068 2e6e 616d 6573  ject.graph.names
+00001db0: 7061 6365 732c 0a20 2020 2020 2020 2020  paces,.         
 00001dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001dd0: 2020 2020 2020 2020 6163 7175 6973 6974          acquisit
-00001de0: 696f 6e2e 6164 645f 6163 7175 6973 6974  ion.add_acquisit
-00001df0: 696f 6e5f 6f62 6a65 6374 2861 6371 7569  ion_object(acqui
-00001e00: 7369 7469 6f6e 5f6f 626a 290a 2020 2020  sition_obj).    
+00001dd0: 2020 2020 2020 2020 2020 2061 6371 7569             acqui
+00001de0: 7369 7469 6f6e 2c0a 2020 2020 2020 2020  sition,.        
+00001df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001e00: 2020 2020 2020 2020 290a 0a20 2020 2020          )..     
 00001e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001e20: 2020 2020 2020 2020 2343 7963 6c65 2074          #Cycle t
-00001e30: 6872 6f75 6768 2072 656d 6169 6e69 6e67  hrough remaining
-00001e40: 206d 6574 6164 6174 6120 666f 7220 6163   metadata for ac
-00001e50: 7175 6973 6974 696f 6e20 656e 7469 7479  quisition entity
-00001e60: 2061 6e64 2061 6464 2061 7474 7269 6275   and add attribu
-00001e70: 7465 730a 2020 2020 2020 2020 2020 2020  tes.            
+00001e20: 2020 2020 2020 2023 2061 6e64 2061 6464         # and add
+00001e30: 2061 6371 7569 7369 7469 6f6e 206f 626a   acquisition obj
+00001e40: 6563 740a 2020 2020 2020 2020 2020 2020  ect.            
+00001e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001e60: 6163 7175 6973 6974 696f 6e5f 6f62 6a20  acquisition_obj 
+00001e70: 3d20 4d52 4f62 6a65 6374 280a 2020 2020  = MRObject(.    
 00001e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001e90: 6164 645f 6d65 7461 6461 7461 5f66 6f72  add_metadata_for
-00001ea0: 5f73 7562 6a65 6374 2872 6466 5f67 7261  _subject(rdf_gra
-00001eb0: 7068 5f70 6172 7365 2c61 6371 5f6f 626a  ph_parse,acq_obj
-00001ec0: 2c70 726f 6a65 6374 2e67 7261 7068 2e6e  ,project.graph.n
-00001ed0: 616d 6573 7061 6365 732c 6163 7175 6973  amespaces,acquis
-00001ee0: 6974 696f 6e5f 6f62 6a29 0a0a 2020 2020  ition_obj)..    
+00001e90: 2020 2020 2020 2020 2020 2020 6163 7175              acqu
+00001ea0: 6973 6974 696f 6e3d 6163 7175 6973 6974  isition=acquisit
+00001eb0: 696f 6e2c 0a20 2020 2020 2020 2020 2020  ion,.           
+00001ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001ed0: 2020 2020 2075 7569 643d 6163 715f 6f62       uuid=acq_ob
+00001ee0: 6a5f 7575 6964 2c0a 2020 2020 2020 2020  j_uuid,.        
 00001ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001f00: 2020 2020 2020 2020 234d 5249 2061 6371          #MRI acq
-00001f10: 7569 7369 7469 6f6e 7320 6d61 7920 6861  uisitions may ha
-00001f20: 7665 2061 6e20 6173 736f 6369 6174 6564  ve an associated
-00001f30: 2073 7469 6d75 6c75 7320 6669 6c65 2073   stimulus file s
-00001f40: 6f20 6c65 7427 7320 7365 6520 6966 2074  o let's see if t
-00001f50: 6865 7265 2069 7320 616e 2065 6e74 6974  here is an entit
-00001f60: 790a 2020 2020 2020 2020 2020 2020 2020  y.              
-00001f70: 2020 2020 2020 2020 2020 2020 2020 2370                #p
-00001f80: 726f 763a 7761 7341 7474 7269 6275 7465  rov:wasAttribute
-00001f90: 6454 6f20 7468 6973 2061 6371 7569 7369  dTo this acquisi
-00001fa0: 7469 6f6e 5f6f 626a 0a20 2020 2020 2020  tion_obj.       
-00001fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001fc0: 2020 2020 2066 6f72 2061 7373 6f63 5f61       for assoc_a
-00001fd0: 6371 2069 6e20 7264 665f 6772 6170 685f  cq in rdf_graph_
-00001fe0: 7061 7273 652e 7375 626a 6563 7473 2870  parse.subjects(p
-00001ff0: 7265 6469 6361 7465 3d43 6f6e 7374 616e  redicate=Constan
-00002000: 7473 2e50 524f 565b 2277 6173 4174 7472  ts.PROV["wasAttr
-00002010: 6962 7574 6564 546f 225d 2c6f 626a 6563  ibutedTo"],objec
-00002020: 743d 6163 715f 6f62 6a29 3a0a 2020 2020  t=acq_obj):.    
+00001f00: 2020 2020 2020 2020 6164 645f 6465 6661          add_defa
+00001f10: 756c 745f 7479 7065 3d46 616c 7365 2c0a  ult_type=False,.
+00001f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001f30: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00001f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001f50: 2020 2020 2020 2020 2020 6163 7175 6973            acquis
+00001f60: 6974 696f 6e2e 6164 645f 6163 7175 6973  ition.add_acquis
+00001f70: 6974 696f 6e5f 6f62 6a65 6374 2861 6371  ition_object(acq
+00001f80: 7569 7369 7469 6f6e 5f6f 626a 290a 2020  uisition_obj).  
+00001f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001fa0: 2020 2020 2020 2020 2020 2320 4379 636c            # Cycl
+00001fb0: 6520 7468 726f 7567 6820 7265 6d61 696e  e through remain
+00001fc0: 696e 6720 6d65 7461 6461 7461 2066 6f72  ing metadata for
+00001fd0: 2061 6371 7569 7369 7469 6f6e 2065 6e74   acquisition ent
+00001fe0: 6974 7920 616e 6420 6164 6420 6174 7472  ity and add attr
+00001ff0: 6962 7574 6573 0a20 2020 2020 2020 2020  ibutes.         
+00002000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002010: 2020 2061 6464 5f6d 6574 6164 6174 615f     add_metadata_
+00002020: 666f 725f 7375 626a 6563 7428 0a20 2020  for_subject(.   
 00002030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002040: 2020 2020 2020 2020 2020 2020 2367 6574              #get
-00002050: 2072 6466 3a74 7970 6520 6f66 2074 6869   rdf:type of thi
-00002060: 7320 656e 7469 7479 2061 6e64 2063 6865  s entity and che
-00002070: 636b 2069 6620 6974 2773 2061 206e 6964  ck if it's a nid
-00002080: 6d3a 5374 696d 756c 7573 5265 7370 6f6e  m:StimulusRespon
-00002090: 7365 4669 6c65 206f 7220 6e6f 740a 2020  seFile or not.  
-000020a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000020b0: 2020 2020 2020 2020 2020 2020 2020 2369                #i
-000020c0: 6620 7264 665f 6772 6170 685f 7061 7273  f rdf_graph_pars
-000020d0: 652e 7472 6970 6c65 7328 2861 7373 6f63  e.triples((assoc
-000020e0: 5f61 6371 2c20 5244 462e 7479 7065 2c20  _acq, RDF.type, 
-000020f0: 5552 4952 6566 2822 6874 7470 3a2f 2f70  URIRef("http://p
-00002100: 7572 6c2e 6f72 672f 6e69 6461 7368 2f6e  url.org/nidash/n
-00002110: 6964 6d23 5374 696d 756c 7573 5265 7370  idm#StimulusResp
-00002120: 6f6e 7365 4669 6c65 2229 2929 3a0a 2020  onseFile"))):.  
-00002130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002140: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00002150: 2028 6173 736f 635f 6163 712c 5244 462e   (assoc_acq,RDF.
-00002160: 7479 7065 2c55 5249 5265 6628 436f 6e73  type,URIRef(Cons
-00002170: 7461 6e74 732e 4e49 444d 5f4d 5249 5f42  tants.NIDM_MRI_B
-00002180: 4f4c 445f 4556 454e 5453 2e5f 7572 6929  OLD_EVENTS._uri)
-00002190: 2920 696e 2072 6466 5f67 7261 7068 3a0a  ) in rdf_graph:.
-000021a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000021b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000021c0: 2020 2020 2353 706c 6974 2073 7562 6a65      #Split subje
-000021d0: 6374 2055 5249 2066 6f72 2061 7373 6f63  ct URI for assoc
-000021e0: 6961 7465 6420 6163 7175 6973 6974 696f  iated acquisitio
-000021f0: 6e20 656e 7469 7479 2066 6f72 206e 6964  n entity for nid
-00002200: 6d3a 5374 696d 756c 7573 5265 7370 6f6e  m:StimulusRespon
-00002210: 7365 4669 6c65 2069 6e74 6f20 6e61 6d65  seFile into name
-00002220: 7370 6163 652c 2075 7569 640a 2020 2020  space, uuid.    
-00002230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002250: 6e6d 2c61 7373 6f63 5f61 6371 5f75 7569  nm,assoc_acq_uui
-00002260: 6420 3d20 7370 6c69 745f 7572 6928 6173  d = split_uri(as
-00002270: 736f 635f 6163 7129 0a20 2020 2020 2020  soc_acq).       
-00002280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002290: 2020 2020 2020 2020 2020 2020 2023 7072               #pr
-000022a0: 696e 7428 2261 7373 6f63 6961 7465 6420  int("associated 
-000022b0: 6163 7175 6973 6974 696f 6e20 6f62 6a65  acquisition obje
-000022c0: 6374 2028 7374 696d 756c 7573 2066 696c  ct (stimulus fil
-000022d0: 6529 2075 7569 643a 2025 7322 2025 2061  e) uuid: %s" % a
-000022e0: 7373 6f63 5f61 6371 5f75 7569 6429 0a20  ssoc_acq_uuid). 
-000022f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002310: 2020 2023 6966 2073 6f20 7468 656e 2061     #if so then a
-00002320: 6464 2074 6869 7320 656e 7469 7479 2061  dd this entity a
-00002330: 6e64 2061 7373 6f63 6961 7465 2069 7420  nd associate it 
-00002340: 7769 7468 2061 6371 7569 7369 7469 6f6e  with acquisition
-00002350: 2061 6374 6976 6974 7920 616e 6420 4d52   activity and MR
-00002360: 4920 656e 7469 7479 0a20 2020 2020 2020  I entity.       
-00002370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002380: 2020 2020 2020 2020 2020 2020 2065 7665               eve
-00002390: 6e74 735f 6f62 6a20 3d20 4163 7175 6973  nts_obj = Acquis
-000023a0: 6974 696f 6e4f 626a 6563 7428 6163 7175  itionObject(acqu
-000023b0: 6973 6974 696f 6e3d 6163 7175 6973 6974  isition=acquisit
-000023c0: 696f 6e2c 7575 6964 3d61 7373 6f63 5f61  ion,uuid=assoc_a
-000023d0: 6371 5f75 7569 6429 0a20 2020 2020 2020  cq_uuid).       
+00002040: 2020 2020 2020 2020 2020 2020 2072 6466               rdf
+00002050: 5f67 7261 7068 5f70 6172 7365 2c0a 2020  _graph_parse,.  
+00002060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002070: 2020 2020 2020 2020 2020 2020 2020 6163                ac
+00002080: 715f 6f62 6a2c 0a20 2020 2020 2020 2020  q_obj,.         
+00002090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000020a0: 2020 2020 2020 2070 726f 6a65 6374 2e67         project.g
+000020b0: 7261 7068 2e6e 616d 6573 7061 6365 732c  raph.namespaces,
+000020c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000020d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000020e0: 2061 6371 7569 7369 7469 6f6e 5f6f 626a   acquisition_obj
+000020f0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00002100: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+00002110: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002120: 2020 2020 2020 2020 2020 2020 2023 204d               # M
+00002130: 5249 2061 6371 7569 7369 7469 6f6e 7320  RI acquisitions 
+00002140: 6d61 7920 6861 7665 2061 6e20 6173 736f  may have an asso
+00002150: 6369 6174 6564 2073 7469 6d75 6c75 7320  ciated stimulus 
+00002160: 6669 6c65 2073 6f20 6c65 7427 7320 7365  file so let's se
+00002170: 6520 6966 2074 6865 7265 2069 7320 616e  e if there is an
+00002180: 2065 6e74 6974 790a 2020 2020 2020 2020   entity.        
+00002190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000021a0: 2020 2020 2320 7072 6f76 3a77 6173 4174      # prov:wasAt
+000021b0: 7472 6962 7574 6564 546f 2074 6869 7320  tributedTo this 
+000021c0: 6163 7175 6973 6974 696f 6e5f 6f62 6a0a  acquisition_obj.
+000021d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000021e0: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+000021f0: 6173 736f 635f 6163 7120 696e 2072 6466  assoc_acq in rdf
+00002200: 5f67 7261 7068 5f70 6172 7365 2e73 7562  _graph_parse.sub
+00002210: 6a65 6374 7328 0a20 2020 2020 2020 2020  jects(.         
+00002220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002230: 2020 2020 2020 2070 7265 6469 6361 7465         predicate
+00002240: 3d43 6f6e 7374 616e 7473 2e50 524f 565b  =Constants.PROV[
+00002250: 2277 6173 4174 7472 6962 7574 6564 546f  "wasAttributedTo
+00002260: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+00002270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002280: 2020 2020 6f62 6a65 6374 3d61 6371 5f6f      object=acq_o
+00002290: 626a 2c0a 2020 2020 2020 2020 2020 2020  bj,.            
+000022a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000022b0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+000022c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000022d0: 2020 2023 2067 6574 2072 6466 3a74 7970     # get rdf:typ
+000022e0: 6520 6f66 2074 6869 7320 656e 7469 7479  e of this entity
+000022f0: 2061 6e64 2063 6865 636b 2069 6620 6974   and check if it
+00002300: 2773 2061 206e 6964 6d3a 5374 696d 756c  's a nidm:Stimul
+00002310: 7573 5265 7370 6f6e 7365 4669 6c65 206f  usResponseFile o
+00002320: 7220 6e6f 740a 2020 2020 2020 2020 2020  r not.          
+00002330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002340: 2020 2020 2020 2320 6966 2072 6466 5f67        # if rdf_g
+00002350: 7261 7068 5f70 6172 7365 2e74 7269 706c  raph_parse.tripl
+00002360: 6573 2828 6173 736f 635f 6163 712c 2052  es((assoc_acq, R
+00002370: 4446 2e74 7970 652c 2055 5249 5265 6628  DF.type, URIRef(
+00002380: 2268 7474 703a 2f2f 7075 726c 2e6f 7267  "http://purl.org
+00002390: 2f6e 6964 6173 682f 6e69 646d 2353 7469  /nidash/nidm#Sti
+000023a0: 6d75 6c75 7352 6573 706f 6e73 6546 696c  mulusResponseFil
+000023b0: 6522 2929 293a 0a20 2020 2020 2020 2020  e"))):.         
+000023c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000023d0: 2020 2020 2020 2069 6620 280a 2020 2020         if (.    
 000023e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000023f0: 2020 2020 2020 2020 2020 2020 2023 6c69               #li
-00002400: 6e6b 2069 7420 746f 2061 7070 726f 7072  nk it to appropr
-00002410: 6961 7465 204d 5220 6163 7175 6973 6974  iate MR acquisit
-00002420: 696f 6e20 656e 7469 7479 0a20 2020 2020  ion entity.     
-00002430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002440: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00002450: 7665 6e74 735f 6f62 6a2e 7761 7341 7474  vents_obj.wasAtt
-00002460: 7269 6275 7465 6454 6f28 6163 7175 6973  ributedTo(acquis
-00002470: 6974 696f 6e5f 6f62 6a29 0a20 2020 2020  ition_obj).     
-00002480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002490: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-000024a0: 6379 636c 6520 7468 726f 7567 6820 7265  cycle through re
-000024b0: 7374 206f 6620 6d65 7461 6461 7461 0a20  st of metadata. 
+000023f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002400: 6173 736f 635f 6163 712c 0a20 2020 2020  assoc_acq,.     
+00002410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002420: 2020 2020 2020 2020 2020 2020 2020 2052                 R
+00002430: 4446 2e74 7970 652c 0a20 2020 2020 2020  DF.type,.       
+00002440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002450: 2020 2020 2020 2020 2020 2020 2055 5249               URI
+00002460: 5265 6628 436f 6e73 7461 6e74 732e 4e49  Ref(Constants.NI
+00002470: 444d 5f4d 5249 5f42 4f4c 445f 4556 454e  DM_MRI_BOLD_EVEN
+00002480: 5453 2e5f 7572 6929 2c0a 2020 2020 2020  TS._uri),.      
+00002490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000024a0: 2020 2020 2020 2020 2020 2920 696e 2072            ) in r
+000024b0: 6466 5f67 7261 7068 3a0a 2020 2020 2020  df_graph:.      
 000024c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000024d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000024e0: 2020 2061 6464 5f6d 6574 6164 6174 615f     add_metadata_
-000024f0: 666f 725f 7375 626a 6563 7428 7264 665f  for_subject(rdf_
-00002500: 6772 6170 685f 7061 7273 652c 6173 736f  graph_parse,asso
-00002510: 635f 6163 712c 7072 6f6a 6563 742e 6772  c_acq,project.gr
-00002520: 6170 682e 6e61 6d65 7370 6163 6573 2c65  aph.namespaces,e
-00002530: 7665 6e74 735f 6f62 6a29 0a0a 0a0a 2020  vents_obj)....  
-00002540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002550: 2020 2020 2020 656c 6966 2028 6163 715f        elif (acq_
-00002560: 6f62 6a2c 2052 4446 2e74 7970 652c 2055  obj, RDF.type, U
-00002570: 5249 5265 6628 436f 6e73 7461 6e74 732e  RIRef(Constants.
-00002580: 4e49 444d 5f4d 5249 5f42 4f4c 445f 4556  NIDM_MRI_BOLD_EV
-00002590: 454e 5453 2e5f 7572 6929 2920 696e 2072  ENTS._uri)) in r
-000025a0: 6466 5f67 7261 7068 3a0a 2020 2020 2020  df_graph:.      
-000025b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000025c0: 2020 2020 2020 2349 6620 7468 6973 2069        #If this i
-000025d0: 7320 6120 7374 696d 756c 7573 2072 6573  s a stimulus res
-000025e0: 706f 6e73 6520 6669 6c65 0a20 2020 2020  ponse file.     
-000025f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002600: 2020 2020 2020 2023 656c 6966 2073 7472         #elif str
-00002610: 2861 6371 5f6d 6f64 616c 6974 7929 203d  (acq_modality) =
-00002620: 3d20 436f 6e73 7461 6e74 732e 4e49 444d  = Constants.NIDM
-00002630: 5f4d 5249 5f42 4f4c 445f 4556 454e 5453  _MRI_BOLD_EVENTS
-00002640: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00002650: 2020 2020 2020 2020 2020 2020 2020 6163                ac
-00002660: 7175 6973 6974 696f 6e3d 4163 7175 6973  quisition=Acquis
-00002670: 6974 696f 6e28 7365 7373 696f 6e3d 7365  ition(session=se
-00002680: 7373 696f 6e2c 7575 6964 3d61 6371 5f75  ssion,uuid=acq_u
-00002690: 7569 6429 0a20 2020 2020 2020 2020 2020  uid).           
-000026a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000026b0: 2069 6620 6e6f 7420 7365 7373 696f 6e2e   if not session.
-000026c0: 6163 7175 6973 6974 696f 6e5f 6578 6973  acquisition_exis
-000026d0: 7428 6163 715f 7575 6964 293a 0a20 2020  t(acq_uuid):.   
-000026e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000026f0: 2020 2020 2020 2020 2020 2020 2073 6573               ses
-00002700: 7369 6f6e 2e61 6464 5f61 6371 7569 7369  sion.add_acquisi
-00002710: 7469 6f6e 2861 6371 7569 7369 7469 6f6e  tion(acquisition
-00002720: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00002730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002740: 2020 2343 7963 6c65 2074 6872 6f75 6768    #Cycle through
-00002750: 2072 656d 6169 6e69 6e67 206d 6574 6164   remaining metad
-00002760: 6174 6120 666f 7220 6163 7175 6973 6974  ata for acquisit
-00002770: 696f 6e20 6163 7469 7669 7479 2061 6e64  ion activity and
-00002780: 2061 6464 2061 7474 7269 6275 7465 730a   add attributes.
-00002790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000024d0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+000024e0: 5370 6c69 7420 7375 626a 6563 7420 5552  Split subject UR
+000024f0: 4920 666f 7220 6173 736f 6369 6174 6564  I for associated
+00002500: 2061 6371 7569 7369 7469 6f6e 2065 6e74   acquisition ent
+00002510: 6974 7920 666f 7220 6e69 646d 3a53 7469  ity for nidm:Sti
+00002520: 6d75 6c75 7352 6573 706f 6e73 6546 696c  mulusResponseFil
+00002530: 6520 696e 746f 206e 616d 6573 7061 6365  e into namespace
+00002540: 2c20 7575 6964 0a20 2020 2020 2020 2020  , uuid.         
+00002550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002560: 2020 2020 2020 2020 2020 205f 2c20 6173             _, as
+00002570: 736f 635f 6163 715f 7575 6964 203d 2073  soc_acq_uuid = s
+00002580: 706c 6974 5f75 7269 2861 7373 6f63 5f61  plit_uri(assoc_a
+00002590: 6371 290a 2020 2020 2020 2020 2020 2020  cq).            
+000025a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000025b0: 2020 2020 2020 2020 2320 7072 696e 7428          # print(
+000025c0: 2261 7373 6f63 6961 7465 6420 6163 7175  "associated acqu
+000025d0: 6973 6974 696f 6e20 6f62 6a65 6374 2028  isition object (
+000025e0: 7374 696d 756c 7573 2066 696c 6529 2075  stimulus file) u
+000025f0: 7569 643a 222c 2061 7373 6f63 5f61 6371  uid:", assoc_acq
+00002600: 5f75 7569 6429 0a20 2020 2020 2020 2020  _uuid).         
+00002610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002620: 2020 2020 2020 2020 2020 2023 2069 6620             # if 
+00002630: 736f 2074 6865 6e20 6164 6420 7468 6973  so then add this
+00002640: 2065 6e74 6974 7920 616e 6420 6173 736f   entity and asso
+00002650: 6369 6174 6520 6974 2077 6974 6820 6163  ciate it with ac
+00002660: 7175 6973 6974 696f 6e20 6163 7469 7669  quisition activi
+00002670: 7479 2061 6e64 204d 5249 2065 6e74 6974  ty and MRI entit
+00002680: 790a 2020 2020 2020 2020 2020 2020 2020  y.              
+00002690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000026a0: 2020 2020 2020 6576 656e 7473 5f6f 626a        events_obj
+000026b0: 203d 2041 6371 7569 7369 7469 6f6e 4f62   = AcquisitionOb
+000026c0: 6a65 6374 280a 2020 2020 2020 2020 2020  ject(.          
+000026d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000026e0: 2020 2020 2020 2020 2020 2020 2020 6163                ac
+000026f0: 7175 6973 6974 696f 6e3d 6163 7175 6973  quisition=acquis
+00002700: 6974 696f 6e2c 2075 7569 643d 6173 736f  ition, uuid=asso
+00002710: 635f 6163 715f 7575 6964 0a20 2020 2020  c_acq_uuid.     
+00002720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002730: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00002740: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002750: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002760: 2020 2020 2023 206c 696e 6b20 6974 2074       # link it t
+00002770: 6f20 6170 7072 6f70 7269 6174 6520 4d52  o appropriate MR
+00002780: 2061 6371 7569 7369 7469 6f6e 2065 6e74   acquisition ent
+00002790: 6974 790a 2020 2020 2020 2020 2020 2020  ity.            
 000027a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000027b0: 6164 645f 6d65 7461 6461 7461 5f66 6f72  add_metadata_for
-000027c0: 5f73 7562 6a65 6374 2028 7264 665f 6772  _subject (rdf_gr
-000027d0: 6170 685f 7061 7273 652c 6163 712c 7072  aph_parse,acq,pr
-000027e0: 6f6a 6563 742e 6772 6170 682e 6e61 6d65  oject.graph.name
-000027f0: 7370 6163 6573 2c61 6371 7569 7369 7469  spaces,acquisiti
-00002800: 6f6e 290a 0a20 2020 2020 2020 2020 2020  on)..           
-00002810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002820: 2023 616e 6420 6164 6420 6163 7175 6973   #and add acquis
-00002830: 6974 696f 6e20 6f62 6a65 6374 0a20 2020  ition object.   
-00002840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002850: 2020 2020 2020 2020 2061 6371 7569 7369           acquisi
-00002860: 7469 6f6e 5f6f 626a 3d41 6371 7569 7369  tion_obj=Acquisi
-00002870: 7469 6f6e 4f62 6a65 6374 2861 6371 7569  tionObject(acqui
-00002880: 7369 7469 6f6e 3d61 6371 7569 7369 7469  sition=acquisiti
-00002890: 6f6e 2c75 7569 643d 6163 715f 6f62 6a5f  on,uuid=acq_obj_
-000028a0: 7575 6964 290a 2020 2020 2020 2020 2020  uuid).          
+000027b0: 2020 2020 2020 2020 6576 656e 7473 5f6f          events_o
+000027c0: 626a 2e77 6173 4174 7472 6962 7574 6564  bj.wasAttributed
+000027d0: 546f 2861 6371 7569 7369 7469 6f6e 5f6f  To(acquisition_o
+000027e0: 626a 290a 2020 2020 2020 2020 2020 2020  bj).            
+000027f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002800: 2020 2020 2020 2020 2320 6379 636c 6520          # cycle 
+00002810: 7468 726f 7567 6820 7265 7374 206f 6620  through rest of 
+00002820: 6d65 7461 6461 7461 0a20 2020 2020 2020  metadata.       
+00002830: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002840: 2020 2020 2020 2020 2020 2020 2061 6464               add
+00002850: 5f6d 6574 6164 6174 615f 666f 725f 7375  _metadata_for_su
+00002860: 626a 6563 7428 0a20 2020 2020 2020 2020  bject(.         
+00002870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002880: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+00002890: 6466 5f67 7261 7068 5f70 6172 7365 2c0a  df_graph_parse,.
+000028a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000028b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000028c0: 2020 6163 7175 6973 6974 696f 6e2e 6164    acquisition.ad
-000028d0: 645f 6163 7175 6973 6974 696f 6e5f 6f62  d_acquisition_ob
-000028e0: 6a65 6374 2861 6371 7569 7369 7469 6f6e  ject(acquisition
-000028f0: 5f6f 626a 290a 2020 2020 2020 2020 2020  _obj).          
-00002900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002910: 2020 2343 7963 6c65 2074 6872 6f75 6768    #Cycle through
-00002920: 2072 656d 6169 6e69 6e67 206d 6574 6164   remaining metad
-00002930: 6174 6120 666f 7220 6163 7175 6973 6974  ata for acquisit
-00002940: 696f 6e20 656e 7469 7479 2061 6e64 2061  ion entity and a
-00002950: 6464 2061 7474 7269 6275 7465 730a 2020  dd attributes.  
-00002960: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002970: 2020 2020 2020 2020 2020 6164 645f 6d65            add_me
-00002980: 7461 6461 7461 5f66 6f72 5f73 7562 6a65  tadata_for_subje
-00002990: 6374 2872 6466 5f67 7261 7068 5f70 6172  ct(rdf_graph_par
-000029a0: 7365 2c61 6371 5f6f 626a 2c70 726f 6a65  se,acq_obj,proje
-000029b0: 6374 2e67 7261 7068 2e6e 616d 6573 7061  ct.graph.namespa
-000029c0: 6365 732c 6163 7175 6973 6974 696f 6e5f  ces,acquisition_
-000029d0: 6f62 6a29 0a0a 2020 2020 2020 2020 2020  obj)..          
-000029e0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-000029f0: 6368 6563 6b20 6966 2074 6869 7320 6973  check if this is
-00002a00: 2061 2050 4554 2061 6371 7569 7369 7469   a PET acquisiti
-00002a10: 6f6e 206f 626a 6563 740a 2020 2020 2020  on object.      
-00002a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a30: 2020 656c 6966 2028 6163 715f 6f62 6a2c    elif (acq_obj,
-00002a40: 2052 4446 2e74 7970 652c 5552 4952 6566   RDF.type,URIRef
-00002a50: 2843 6f6e 7374 616e 7473 2e4e 4944 4d5f  (Constants.NIDM_
-00002a60: 5045 542e 5f75 7269 2929 2069 6e20 7264  PET._uri)) in rd
-00002a70: 665f 6772 6170 683a 0a20 2020 2020 2020  f_graph:.       
-00002a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a90: 2020 2020 2061 6371 7569 7369 7469 6f6e       acquisition
-00002aa0: 203d 2050 4554 4163 7175 6973 6974 696f   = PETAcquisitio
-00002ab0: 6e28 7365 7373 696f 6e3d 7365 7373 696f  n(session=sessio
-00002ac0: 6e2c 2075 7569 643d 6163 715f 7575 6964  n, uuid=acq_uuid
-00002ad0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00002ae0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00002af0: 206e 6f74 2073 6573 7369 6f6e 2e61 6371   not session.acq
-00002b00: 7569 7369 7469 6f6e 5f65 7869 7374 2861  uisition_exist(a
-00002b10: 6371 5f75 7569 6429 3a0a 2020 2020 2020  cq_uuid):.      
-00002b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002b30: 2020 2020 2020 2020 2020 7365 7373 696f            sessio
-00002b40: 6e2e 6164 645f 6163 7175 6973 6974 696f  n.add_acquisitio
-00002b50: 6e28 6163 7175 6973 6974 696f 6e29 0a20  n(acquisition). 
-00002b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002b70: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-00002b80: 2043 7963 6c65 2074 6872 6f75 6768 2072   Cycle through r
-00002b90: 656d 6169 6e69 6e67 206d 6574 6164 6174  emaining metadat
-00002ba0: 6120 666f 7220 6163 7175 6973 6974 696f  a for acquisitio
-00002bb0: 6e20 6163 7469 7669 7479 2061 6e64 2061  n activity and a
-00002bc0: 6464 2061 7474 7269 6275 7465 730a 2020  dd attributes.  
+000028c0: 2020 2020 2020 2020 6173 736f 635f 6163          assoc_ac
+000028d0: 712c 0a20 2020 2020 2020 2020 2020 2020  q,.             
+000028e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000028f0: 2020 2020 2020 2020 2020 2070 726f 6a65             proje
+00002900: 6374 2e67 7261 7068 2e6e 616d 6573 7061  ct.graph.namespa
+00002910: 6365 732c 0a20 2020 2020 2020 2020 2020  ces,.           
+00002920: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002930: 2020 2020 2020 2020 2020 2020 2065 7665               eve
+00002940: 6e74 735f 6f62 6a2c 0a20 2020 2020 2020  nts_obj,.       
+00002950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002960: 2020 2020 2020 2020 2020 2020 2029 0a0a               )..
+00002970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002980: 2020 2020 2020 2020 656c 6966 2028 0a20          elif (. 
+00002990: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000029a0: 2020 2020 2020 2020 2020 2061 6371 5f6f             acq_o
+000029b0: 626a 2c0a 2020 2020 2020 2020 2020 2020  bj,.            
+000029c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000029d0: 5244 462e 7479 7065 2c0a 2020 2020 2020  RDF.type,.      
+000029e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000029f0: 2020 2020 2020 5552 4952 6566 2843 6f6e        URIRef(Con
+00002a00: 7374 616e 7473 2e4e 4944 4d5f 4d52 495f  stants.NIDM_MRI_
+00002a10: 424f 4c44 5f45 5645 4e54 532e 5f75 7269  BOLD_EVENTS._uri
+00002a20: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
+00002a30: 2020 2020 2020 2020 2020 2029 2069 6e20             ) in 
+00002a40: 7264 665f 6772 6170 683a 0a20 2020 2020  rdf_graph:.     
+00002a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002a60: 2020 2020 2020 2023 2049 6620 7468 6973         # If this
+00002a70: 2069 7320 6120 7374 696d 756c 7573 2072   is a stimulus r
+00002a80: 6573 706f 6e73 6520 6669 6c65 0a20 2020  esponse file.   
+00002a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002aa0: 2020 2020 2020 2020 2023 2065 6c69 6620           # elif 
+00002ab0: 7374 7228 6163 715f 6d6f 6461 6c69 7479  str(acq_modality
+00002ac0: 2920 3d3d 2043 6f6e 7374 616e 7473 2e4e  ) == Constants.N
+00002ad0: 4944 4d5f 4d52 495f 424f 4c44 5f45 5645  IDM_MRI_BOLD_EVE
+00002ae0: 4e54 533a 0a20 2020 2020 2020 2020 2020  NTS:.           
+00002af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b00: 2061 6371 7569 7369 7469 6f6e 203d 2041   acquisition = A
+00002b10: 6371 7569 7369 7469 6f6e 2873 6573 7369  cquisition(sessi
+00002b20: 6f6e 3d73 6573 7369 6f6e 2c20 7575 6964  on=session, uuid
+00002b30: 3d61 6371 5f75 7569 6429 0a20 2020 2020  =acq_uuid).     
+00002b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b50: 2020 2020 2020 2069 6620 6e6f 7420 7365         if not se
+00002b60: 7373 696f 6e2e 6163 7175 6973 6974 696f  ssion.acquisitio
+00002b70: 6e5f 6578 6973 7428 6163 715f 7575 6964  n_exist(acq_uuid
+00002b80: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+00002b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002ba0: 2020 2073 6573 7369 6f6e 2e61 6464 5f61     session.add_a
+00002bb0: 6371 7569 7369 7469 6f6e 2861 6371 7569  cquisition(acqui
+00002bc0: 7369 7469 6f6e 290a 2020 2020 2020 2020  sition).        
 00002bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002be0: 2020 2020 2020 2020 2020 2020 2020 6164                ad
-00002bf0: 645f 6d65 7461 6461 7461 5f66 6f72 5f73  d_metadata_for_s
-00002c00: 7562 6a65 6374 2872 6466 5f67 7261 7068  ubject(rdf_graph
-00002c10: 5f70 6172 7365 2c20 6163 712c 2070 726f  _parse, acq, pro
-00002c20: 6a65 6374 2e67 7261 7068 2e6e 616d 6573  ject.graph.names
-00002c30: 7061 6365 732c 2061 6371 7569 7369 7469  paces, acquisiti
-00002c40: 6f6e 290a 0a20 2020 2020 2020 2020 2020  on)..           
-00002c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002c60: 2023 2061 6e64 2061 6464 2061 6371 7569   # and add acqui
-00002c70: 7369 7469 6f6e 206f 626a 6563 740a 2020  sition object.  
+00002be0: 2020 2020 2020 2020 2320 4379 636c 6520          # Cycle 
+00002bf0: 7468 726f 7567 6820 7265 6d61 696e 696e  through remainin
+00002c00: 6720 6d65 7461 6461 7461 2066 6f72 2061  g metadata for a
+00002c10: 6371 7569 7369 7469 6f6e 2061 6374 6976  cquisition activ
+00002c20: 6974 7920 616e 6420 6164 6420 6174 7472  ity and add attr
+00002c30: 6962 7574 6573 0a20 2020 2020 2020 2020  ibutes.         
+00002c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002c50: 2020 2020 2020 2061 6464 5f6d 6574 6164         add_metad
+00002c60: 6174 615f 666f 725f 7375 626a 6563 7428  ata_for_subject(
+00002c70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
 00002c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002c90: 2020 2020 2020 2020 2020 6163 7175 6973            acquis
-00002ca0: 6974 696f 6e5f 6f62 6a20 3d20 5045 544f  ition_obj = PETO
-00002cb0: 626a 6563 7428 6163 7175 6973 6974 696f  bject(acquisitio
-00002cc0: 6e3d 6163 7175 6973 6974 696f 6e2c 2075  n=acquisition, u
-00002cd0: 7569 643d 6163 715f 6f62 6a5f 7575 6964  uid=acq_obj_uuid
-00002ce0: 2c61 6464 5f64 6566 6175 6c74 5f74 7970  ,add_default_typ
-00002cf0: 653d 4661 6c73 6529 0a20 2020 2020 2020  e=False).       
-00002d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002d10: 2020 2020 2061 6371 7569 7369 7469 6f6e       acquisition
-00002d20: 2e61 6464 5f61 6371 7569 7369 7469 6f6e  .add_acquisition
-00002d30: 5f6f 626a 6563 7428 6163 7175 6973 6974  _object(acquisit
-00002d40: 696f 6e5f 6f62 6a29 0a20 2020 2020 2020  ion_obj).       
-00002d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002d60: 2020 2020 2023 2043 7963 6c65 2074 6872       # Cycle thr
-00002d70: 6f75 6768 2072 656d 6169 6e69 6e67 206d  ough remaining m
-00002d80: 6574 6164 6174 6120 666f 7220 6163 7175  etadata for acqu
-00002d90: 6973 6974 696f 6e20 656e 7469 7479 2061  isition entity a
-00002da0: 6e64 2061 6464 2061 7474 7269 6275 7465  nd add attribute
-00002db0: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
-00002dc0: 2020 2020 2020 2020 2020 2020 2020 6164                ad
-00002dd0: 645f 6d65 7461 6461 7461 5f66 6f72 5f73  d_metadata_for_s
-00002de0: 7562 6a65 6374 2872 6466 5f67 7261 7068  ubject(rdf_graph
-00002df0: 5f70 6172 7365 2c20 6163 715f 6f62 6a2c  _parse, acq_obj,
-00002e00: 2070 726f 6a65 6374 2e67 7261 7068 2e6e   project.graph.n
-00002e10: 616d 6573 7061 6365 732c 0a20 2020 2020  amespaces,.     
-00002e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002c90: 2020 2020 2072 6466 5f67 7261 7068 5f70       rdf_graph_p
+00002ca0: 6172 7365 2c0a 2020 2020 2020 2020 2020  arse,.          
+00002cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002cc0: 2020 2020 2020 2020 2020 6163 712c 0a20            acq,. 
+00002cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002cf0: 2020 2070 726f 6a65 6374 2e67 7261 7068     project.graph
+00002d00: 2e6e 616d 6573 7061 6365 732c 0a20 2020  .namespaces,.   
+00002d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002d30: 2061 6371 7569 7369 7469 6f6e 2c0a 2020   acquisition,.  
+00002d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002d50: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+00002d60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002d70: 2020 2020 2020 2020 2020 2020 2023 2061               # a
+00002d80: 6e64 2061 6464 2061 6371 7569 7369 7469  nd add acquisiti
+00002d90: 6f6e 206f 626a 6563 740a 2020 2020 2020  on object.      
+00002da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002db0: 2020 2020 2020 6163 7175 6973 6974 696f        acquisitio
+00002dc0: 6e5f 6f62 6a20 3d20 4163 7175 6973 6974  n_obj = Acquisit
+00002dd0: 696f 6e4f 626a 6563 7428 0a20 2020 2020  ionObject(.     
+00002de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002df0: 2020 2020 2020 2020 2020 2061 6371 7569             acqui
+00002e00: 7369 7469 6f6e 3d61 6371 7569 7369 7469  sition=acquisiti
+00002e10: 6f6e 2c20 7575 6964 3d61 6371 5f6f 626a  on, uuid=acq_obj
+00002e20: 5f75 7569 640a 2020 2020 2020 2020 2020  _uuid.          
 00002e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002e50: 6163 7175 6973 6974 696f 6e5f 6f62 6a29  acquisition_obj)
-00002e60: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00002e70: 2020 2020 2020 2020 2020 2371 7565 7279            #query
-00002e80: 2077 6865 7468 6572 2074 6869 7320 6973   whether this is
-00002e90: 2061 6e20 6173 7365 7373 6d65 6e74 2061   an assessment a
-00002ea0: 6371 7569 7369 7469 6f6e 2062 7920 7761  cquisition by wa
-00002eb0: 7920 6f66 206c 6f6f 6b69 6e67 2061 7420  y of looking at 
-00002ec0: 7468 6520 6765 6e65 7261 7465 6420 656e  the generated en
-00002ed0: 7469 7479 2061 6e64 2064 6574 6572 6d69  tity and determi
-00002ee0: 6e69 6e67 0a20 2020 2020 2020 2020 2020  ning.           
-00002ef0: 2020 2020 2020 2020 2020 2020 2023 6966               #if
-00002f00: 2069 7420 6861 7320 7468 6520 7264 663a   it has the rdf:
-00002f10: 7479 7065 2043 6f6e 7374 616e 7473 2e4e  type Constants.N
-00002f20: 4944 4d5f 4153 5345 5353 4d45 4e54 5f45  IDM_ASSESSMENT_E
-00002f30: 4e54 4954 590a 2020 2020 2020 2020 2020  NTITY.          
-00002f40: 2020 2020 2020 2020 2020 2020 2020 2366                #f
-00002f50: 6f72 2061 6371 5f6d 6f64 616c 6974 7920  or acq_modality 
-00002f60: 696e 2072 6466 5f67 7261 7068 5f70 6172  in rdf_graph_par
-00002f70: 7365 2e6f 626a 6563 7473 2873 7562 6a65  se.objects(subje
-00002f80: 6374 3d61 6371 5f6f 626a 2c70 7265 6469  ct=acq_obj,predi
-00002f90: 6361 7465 3d52 4446 2e74 7970 6529 3a0a  cate=RDF.type):.
-00002fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002fb0: 2020 2020 2020 2020 656c 6966 2028 6163          elif (ac
-00002fc0: 715f 6f62 6a2c 2052 4446 2e74 7970 652c  q_obj, RDF.type,
-00002fd0: 2055 5249 5265 6628 436f 6e73 7461 6e74   URIRef(Constant
-00002fe0: 732e 4e49 444d 5f41 5353 4553 534d 454e  s.NIDM_ASSESSMEN
-00002ff0: 545f 454e 5449 5459 2e5f 7572 6929 2920  T_ENTITY._uri)) 
-00003000: 696e 2072 6466 5f67 7261 7068 3a0a 0a20  in rdf_graph:.. 
-00003010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003020: 2020 2020 2020 2020 2020 2023 6966 2073             #if s
-00003030: 7472 2861 6371 5f6d 6f64 616c 6974 7929  tr(acq_modality)
-00003040: 203d 3d20 436f 6e73 7461 6e74 732e 4e49   == Constants.NI
-00003050: 444d 5f41 5353 4553 534d 454e 545f 454e  DM_ASSESSMENT_EN
-00003060: 5449 5459 2e5f 7572 693a 0a20 2020 2020  TITY._uri:.     
-00003070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003080: 2020 2020 2020 2061 6371 7569 7369 7469         acquisiti
-00003090: 6f6e 3d41 7373 6573 736d 656e 7441 6371  on=AssessmentAcq
-000030a0: 7569 7369 7469 6f6e 2873 6573 7369 6f6e  uisition(session
-000030b0: 3d73 6573 7369 6f6e 2c75 7569 643d 6163  =session,uuid=ac
-000030c0: 715f 7575 6964 2c61 6464 5f64 6566 6175  q_uuid,add_defau
-000030d0: 6c74 5f74 7970 653d 4661 6c73 6529 0a20  lt_type=False). 
-000030e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000030f0: 2020 2020 2020 2020 2020 2023 4379 636c             #Cycl
-00003100: 6520 7468 726f 7567 6820 7265 6d61 696e  e through remain
-00003110: 696e 6720 6d65 7461 6461 7461 2066 6f72  ing metadata for
-00003120: 2061 6371 7569 7369 7469 6f6e 2061 6374   acquisition act
-00003130: 6976 6974 7920 616e 6420 6164 6420 6174  ivity and add at
-00003140: 7472 6962 7574 6573 0a20 2020 2020 2020  tributes.       
-00003150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003160: 2020 2020 2061 6464 5f6d 6574 6164 6174       add_metadat
-00003170: 615f 666f 725f 7375 626a 6563 7420 2872  a_for_subject (r
-00003180: 6466 5f67 7261 7068 5f70 6172 7365 2c61  df_graph_parse,a
-00003190: 6371 2c70 726f 6a65 6374 2e67 7261 7068  cq,project.graph
-000031a0: 2e6e 616d 6573 7061 6365 732c 6163 7175  .namespaces,acqu
-000031b0: 6973 6974 696f 6e29 0a0a 2020 2020 2020  isition)..      
-000031c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000031d0: 2020 2020 2020 2361 6e64 2061 6464 2061        #and add a
-000031e0: 6371 7569 7369 7469 6f6e 206f 626a 6563  cquisition objec
-000031f0: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
-00003200: 2020 2020 2020 2020 2020 2020 2020 6163                ac
-00003210: 7175 6973 6974 696f 6e5f 6f62 6a3d 4173  quisition_obj=As
-00003220: 7365 7373 6d65 6e74 4f62 6a65 6374 2861  sessmentObject(a
-00003230: 6371 7569 7369 7469 6f6e 3d61 6371 7569  cquisition=acqui
-00003240: 7369 7469 6f6e 2c75 7569 643d 6163 715f  sition,uuid=acq_
-00003250: 6f62 6a5f 7575 6964 2c61 6464 5f64 6566  obj_uuid,add_def
-00003260: 6175 6c74 5f74 7970 653d 4661 6c73 6529  ault_type=False)
-00003270: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003280: 2020 2020 2020 2020 2020 2020 2061 6371               acq
-00003290: 7569 7369 7469 6f6e 2e61 6464 5f61 6371  uisition.add_acq
-000032a0: 7569 7369 7469 6f6e 5f6f 626a 6563 7428  uisition_object(
-000032b0: 6163 7175 6973 6974 696f 6e5f 6f62 6a29  acquisition_obj)
-000032c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000032d0: 2020 2020 2020 2020 2020 2020 2023 4379               #Cy
-000032e0: 636c 6520 7468 726f 7567 6820 7265 6d61  cle through rema
-000032f0: 696e 696e 6720 6d65 7461 6461 7461 2066  ining metadata f
-00003300: 6f72 2061 6371 7569 7369 7469 6f6e 2065  or acquisition e
-00003310: 6e74 6974 7920 616e 6420 6164 6420 6174  ntity and add at
-00003320: 7472 6962 7574 6573 0a20 2020 2020 2020  tributes.       
-00003330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003340: 2020 2020 2061 6464 5f6d 6574 6164 6174       add_metadat
-00003350: 615f 666f 725f 7375 626a 6563 7428 7264  a_for_subject(rd
-00003360: 665f 6772 6170 685f 7061 7273 652c 6163  f_graph_parse,ac
-00003370: 715f 6f62 6a2c 7072 6f6a 6563 742e 6772  q_obj,project.gr
-00003380: 6170 682e 6e61 6d65 7370 6163 6573 2c61  aph.namespaces,a
-00003390: 6371 7569 7369 7469 6f6e 5f6f 626a 290a  cquisition_obj).
-000033a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000033b0: 2020 2020 2020 2020 2320 6966 2074 6869          # if thi
-000033c0: 7320 6973 2061 2044 5749 2073 6361 6e20  s is a DWI scan 
-000033d0: 7468 656e 2077 6520 636f 756c 6420 6861  then we could ha
-000033e0: 7665 2062 2d76 616c 7565 2061 6e64 2062  ve b-value and b
-000033f0: 2d76 6563 746f 7220 6669 6c65 7320 6173  -vector files as
-00003400: 736f 6369 6174 6564 0a20 2020 2020 2020  sociated.       
-00003410: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003420: 2065 6c69 6620 2828 6163 715f 6f62 6a2c   elif ((acq_obj,
-00003430: 2052 4446 2e74 7970 652c 2055 5249 5265   RDF.type, URIRe
-00003440: 6628 436f 6e73 7461 6e74 732e 4e49 444d  f(Constants.NIDM
-00003450: 5f4d 5249 5f44 5749 5f42 5641 4c2e 5f75  _MRI_DWI_BVAL._u
-00003460: 7269 2929 2069 6e20 7264 665f 6772 6170  ri)) in rdf_grap
-00003470: 6829 206f 7220 5c0a 2020 2020 2020 2020  h) or \.        
-00003480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003490: 2020 2020 2828 6163 715f 6f62 6a2c 2052      ((acq_obj, R
-000034a0: 4446 2e74 7970 652c 2055 5249 5265 6628  DF.type, URIRef(
-000034b0: 436f 6e73 7461 6e74 732e 4e49 444d 5f4d  Constants.NIDM_M
-000034c0: 5249 5f44 5749 5f42 5645 432e 5f75 7269  RI_DWI_BVEC._uri
-000034d0: 2929 2069 6e20 7264 665f 6772 6170 6829  )) in rdf_graph)
-000034e0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000034f0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-00003500: 4966 2074 6869 7320 6973 2061 2062 2d76  If this is a b-v
-00003510: 616c 7565 7320 6669 6c65 760a 2020 2020  alues filev.    
-00003520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003530: 2020 2020 2020 2020 6163 7175 6973 6974          acquisit
-00003540: 696f 6e20 3d20 4163 7175 6973 6974 696f  ion = Acquisitio
-00003550: 6e28 7365 7373 696f 6e3d 7365 7373 696f  n(session=sessio
-00003560: 6e2c 2075 7569 643d 6163 715f 7575 6964  n, uuid=acq_uuid
-00003570: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00003580: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00003590: 206e 6f74 2073 6573 7369 6f6e 2e61 6371   not session.acq
-000035a0: 7569 7369 7469 6f6e 5f65 7869 7374 2861  uisition_exist(a
-000035b0: 6371 5f75 7569 6429 3a0a 2020 2020 2020  cq_uuid):.      
-000035c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000035d0: 2020 2020 2020 2020 2020 7365 7373 696f            sessio
-000035e0: 6e2e 6164 645f 6163 7175 6973 6974 696f  n.add_acquisitio
-000035f0: 6e28 6163 7175 6973 6974 696f 6e29 0a20  n(acquisition). 
+00002e40: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+00002e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002e60: 6163 7175 6973 6974 696f 6e2e 6164 645f  acquisition.add_
+00002e70: 6163 7175 6973 6974 696f 6e5f 6f62 6a65  acquisition_obje
+00002e80: 6374 2861 6371 7569 7369 7469 6f6e 5f6f  ct(acquisition_o
+00002e90: 626a 290a 2020 2020 2020 2020 2020 2020  bj).            
+00002ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002eb0: 2320 4379 636c 6520 7468 726f 7567 6820  # Cycle through 
+00002ec0: 7265 6d61 696e 696e 6720 6d65 7461 6461  remaining metada
+00002ed0: 7461 2066 6f72 2061 6371 7569 7369 7469  ta for acquisiti
+00002ee0: 6f6e 2065 6e74 6974 7920 616e 6420 6164  on entity and ad
+00002ef0: 6420 6174 7472 6962 7574 6573 0a20 2020  d attributes.   
+00002f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002f10: 2020 2020 2020 2020 2061 6464 5f6d 6574           add_met
+00002f20: 6164 6174 615f 666f 725f 7375 626a 6563  adata_for_subjec
+00002f30: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
+00002f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002f50: 2020 2072 6466 5f67 7261 7068 5f70 6172     rdf_graph_par
+00002f60: 7365 2c0a 2020 2020 2020 2020 2020 2020  se,.            
+00002f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002f80: 2020 2020 6163 715f 6f62 6a2c 0a20 2020      acq_obj,.   
+00002f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002fa0: 2020 2020 2020 2020 2020 2020 2070 726f               pro
+00002fb0: 6a65 6374 2e67 7261 7068 2e6e 616d 6573  ject.graph.names
+00002fc0: 7061 6365 732c 0a20 2020 2020 2020 2020  paces,.         
+00002fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002fe0: 2020 2020 2020 2061 6371 7569 7369 7469         acquisiti
+00002ff0: 6f6e 5f6f 626a 2c0a 2020 2020 2020 2020  on_obj,.        
+00003000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003010: 2020 2020 290a 0a20 2020 2020 2020 2020      )..         
+00003020: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+00003030: 2063 6865 636b 2069 6620 7468 6973 2069   check if this i
+00003040: 7320 6120 5045 5420 6163 7175 6973 6974  s a PET acquisit
+00003050: 696f 6e20 6f62 6a65 6374 0a20 2020 2020  ion object.     
+00003060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003070: 2020 2065 6c69 6620 280a 2020 2020 2020     elif (.      
+00003080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003090: 2020 2020 2020 6163 715f 6f62 6a2c 0a20        acq_obj,. 
+000030a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000030b0: 2020 2020 2020 2020 2020 2052 4446 2e74             RDF.t
+000030c0: 7970 652c 0a20 2020 2020 2020 2020 2020  ype,.           
+000030d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000030e0: 2055 5249 5265 6628 436f 6e73 7461 6e74   URIRef(Constant
+000030f0: 732e 4e49 444d 5f50 4554 2e5f 7572 6929  s.NIDM_PET._uri)
+00003100: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00003110: 2020 2020 2020 2020 2020 2920 696e 2072            ) in r
+00003120: 6466 5f67 7261 7068 3a0a 2020 2020 2020  df_graph:.      
+00003130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003140: 2020 2020 2020 6163 7175 6973 6974 696f        acquisitio
+00003150: 6e20 3d20 5045 5441 6371 7569 7369 7469  n = PETAcquisiti
+00003160: 6f6e 2873 6573 7369 6f6e 3d73 6573 7369  on(session=sessi
+00003170: 6f6e 2c20 7575 6964 3d61 6371 5f75 7569  on, uuid=acq_uui
+00003180: 6429 0a20 2020 2020 2020 2020 2020 2020  d).             
+00003190: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+000031a0: 6620 6e6f 7420 7365 7373 696f 6e2e 6163  f not session.ac
+000031b0: 7175 6973 6974 696f 6e5f 6578 6973 7428  quisition_exist(
+000031c0: 6163 715f 7575 6964 293a 0a20 2020 2020  acq_uuid):.     
+000031d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000031e0: 2020 2020 2020 2020 2020 2073 6573 7369             sessi
+000031f0: 6f6e 2e61 6464 5f61 6371 7569 7369 7469  on.add_acquisiti
+00003200: 6f6e 2861 6371 7569 7369 7469 6f6e 290a  on(acquisition).
+00003210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003230: 2320 4379 636c 6520 7468 726f 7567 6820  # Cycle through 
+00003240: 7265 6d61 696e 696e 6720 6d65 7461 6461  remaining metada
+00003250: 7461 2066 6f72 2061 6371 7569 7369 7469  ta for acquisiti
+00003260: 6f6e 2061 6374 6976 6974 7920 616e 6420  on activity and 
+00003270: 6164 6420 6174 7472 6962 7574 6573 0a20  add attributes. 
+00003280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003290: 2020 2020 2020 2020 2020 2020 2020 2061                 a
+000032a0: 6464 5f6d 6574 6164 6174 615f 666f 725f  dd_metadata_for_
+000032b0: 7375 626a 6563 7428 0a20 2020 2020 2020  subject(.       
+000032c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000032d0: 2020 2020 2020 2020 2020 2020 2072 6466               rdf
+000032e0: 5f67 7261 7068 5f70 6172 7365 2c0a 2020  _graph_parse,.  
+000032f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003310: 2020 6163 712c 0a20 2020 2020 2020 2020    acq,.         
+00003320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003330: 2020 2020 2020 2020 2020 2070 726f 6a65             proje
+00003340: 6374 2e67 7261 7068 2e6e 616d 6573 7061  ct.graph.namespa
+00003350: 6365 732c 0a20 2020 2020 2020 2020 2020  ces,.           
+00003360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003370: 2020 2020 2020 2020 2061 6371 7569 7369           acquisi
+00003380: 7469 6f6e 2c0a 2020 2020 2020 2020 2020  tion,.          
+00003390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000033a0: 2020 2020 2020 290a 0a20 2020 2020 2020        )..       
+000033b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000033c0: 2020 2020 2023 2061 6e64 2061 6464 2061       # and add a
+000033d0: 6371 7569 7369 7469 6f6e 206f 626a 6563  cquisition objec
+000033e0: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
+000033f0: 2020 2020 2020 2020 2020 2020 2020 6163                ac
+00003400: 7175 6973 6974 696f 6e5f 6f62 6a20 3d20  quisition_obj = 
+00003410: 5045 544f 626a 6563 7428 0a20 2020 2020  PETObject(.     
+00003420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003430: 2020 2020 2020 2020 2020 2061 6371 7569             acqui
+00003440: 7369 7469 6f6e 3d61 6371 7569 7369 7469  sition=acquisiti
+00003450: 6f6e 2c0a 2020 2020 2020 2020 2020 2020  on,.            
+00003460: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003470: 2020 2020 7575 6964 3d61 6371 5f6f 626a      uuid=acq_obj
+00003480: 5f75 7569 642c 0a20 2020 2020 2020 2020  _uuid,.         
+00003490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000034a0: 2020 2020 2020 2061 6464 5f64 6566 6175         add_defau
+000034b0: 6c74 5f74 7970 653d 4661 6c73 652c 0a20  lt_type=False,. 
+000034c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000034d0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+000034e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000034f0: 2020 2020 2020 2020 2061 6371 7569 7369           acquisi
+00003500: 7469 6f6e 2e61 6464 5f61 6371 7569 7369  tion.add_acquisi
+00003510: 7469 6f6e 5f6f 626a 6563 7428 6163 7175  tion_object(acqu
+00003520: 6973 6974 696f 6e5f 6f62 6a29 0a20 2020  isition_obj).   
+00003530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003540: 2020 2020 2020 2020 2023 2043 7963 6c65           # Cycle
+00003550: 2074 6872 6f75 6768 2072 656d 6169 6e69   through remaini
+00003560: 6e67 206d 6574 6164 6174 6120 666f 7220  ng metadata for 
+00003570: 6163 7175 6973 6974 696f 6e20 656e 7469  acquisition enti
+00003580: 7479 2061 6e64 2061 6464 2061 7474 7269  ty and add attri
+00003590: 6275 7465 730a 2020 2020 2020 2020 2020  butes.          
+000035a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000035b0: 2020 6164 645f 6d65 7461 6461 7461 5f66    add_metadata_f
+000035c0: 6f72 5f73 7562 6a65 6374 280a 2020 2020  or_subject(.    
+000035d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000035e0: 2020 2020 2020 2020 2020 2020 7264 665f              rdf_
+000035f0: 6772 6170 685f 7061 7273 652c 0a20 2020  graph_parse,.   
 00003600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003610: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-00003620: 2043 7963 6c65 2074 6872 6f75 6768 2072   Cycle through r
-00003630: 656d 6169 6e69 6e67 206d 6574 6164 6174  emaining metadat
-00003640: 6120 666f 7220 6163 7175 6973 6974 696f  a for acquisitio
-00003650: 6e20 6163 7469 7669 7479 2061 6e64 2061  n activity and a
-00003660: 6464 2061 7474 7269 6275 7465 730a 2020  dd attributes.  
+00003610: 2020 2020 2020 2020 2020 2020 2061 6371               acq
+00003620: 5f6f 626a 2c0a 2020 2020 2020 2020 2020  _obj,.          
+00003630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003640: 2020 2020 2020 7072 6f6a 6563 742e 6772        project.gr
+00003650: 6170 682e 6e61 6d65 7370 6163 6573 2c0a  aph.namespaces,.
+00003660: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00003670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003680: 2020 2020 2020 2020 2020 2020 2020 6164                ad
-00003690: 645f 6d65 7461 6461 7461 5f66 6f72 5f73  d_metadata_for_s
-000036a0: 7562 6a65 6374 2872 6466 5f67 7261 7068  ubject(rdf_graph
-000036b0: 5f70 6172 7365 2c20 6163 712c 2070 726f  _parse, acq, pro
-000036c0: 6a65 6374 2e67 7261 7068 2e6e 616d 6573  ject.graph.names
-000036d0: 7061 6365 732c 2061 6371 7569 7369 7469  paces, acquisiti
-000036e0: 6f6e 290a 0a20 2020 2020 2020 2020 2020  on)..           
-000036f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003700: 2023 2061 6e64 2061 6464 2061 6371 7569   # and add acqui
-00003710: 7369 7469 6f6e 206f 626a 6563 740a 2020  sition object.  
-00003720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003730: 2020 2020 2020 2020 2020 6163 7175 6973            acquis
-00003740: 6974 696f 6e5f 6f62 6a20 3d20 4163 7175  ition_obj = Acqu
-00003750: 6973 6974 696f 6e4f 626a 6563 7428 6163  isitionObject(ac
-00003760: 7175 6973 6974 696f 6e3d 6163 7175 6973  quisition=acquis
-00003770: 6974 696f 6e2c 2075 7569 643d 6163 715f  ition, uuid=acq_
-00003780: 6f62 6a5f 7575 6964 290a 2020 2020 2020  obj_uuid).      
-00003790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000037a0: 2020 2020 2020 6163 7175 6973 6974 696f        acquisitio
-000037b0: 6e2e 6164 645f 6163 7175 6973 6974 696f  n.add_acquisitio
-000037c0: 6e5f 6f62 6a65 6374 2861 6371 7569 7369  n_object(acquisi
-000037d0: 7469 6f6e 5f6f 626a 290a 2020 2020 2020  tion_obj).      
-000037e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000037f0: 2020 2020 2020 2320 4379 636c 6520 7468        # Cycle th
-00003800: 726f 7567 6820 7265 6d61 696e 696e 6720  rough remaining 
-00003810: 6d65 7461 6461 7461 2066 6f72 2061 6371  metadata for acq
-00003820: 7569 7369 7469 6f6e 2065 6e74 6974 7920  uisition entity 
-00003830: 616e 6420 6164 6420 6174 7472 6962 7574  and add attribut
-00003840: 6573 0a20 2020 2020 2020 2020 2020 2020  es.             
-00003850: 2020 2020 2020 2020 2020 2020 2020 2061                 a
-00003860: 6464 5f6d 6574 6164 6174 615f 666f 725f  dd_metadata_for_
-00003870: 7375 626a 6563 7428 7264 665f 6772 6170  subject(rdf_grap
-00003880: 685f 7061 7273 652c 2061 6371 5f6f 626a  h_parse, acq_obj
-00003890: 2c20 7072 6f6a 6563 742e 6772 6170 682e  , project.graph.
-000038a0: 6e61 6d65 7370 6163 6573 2c0a 2020 2020  namespaces,.    
-000038b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000038c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003680: 6163 7175 6973 6974 696f 6e5f 6f62 6a2c  acquisition_obj,
+00003690: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000036a0: 2020 2020 2020 2020 2020 2020 2029 0a0a               )..
+000036b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000036c0: 2020 2020 2020 2020 2320 7175 6572 7920          # query 
+000036d0: 7768 6574 6865 7220 7468 6973 2069 7320  whether this is 
+000036e0: 616e 2061 7373 6573 736d 656e 7420 6163  an assessment ac
+000036f0: 7175 6973 6974 696f 6e20 6279 2077 6179  quisition by way
+00003700: 206f 6620 6c6f 6f6b 696e 6720 6174 2074   of looking at t
+00003710: 6865 2067 656e 6572 6174 6564 2065 6e74  he generated ent
+00003720: 6974 7920 616e 6420 6465 7465 726d 696e  ity and determin
+00003730: 696e 670a 2020 2020 2020 2020 2020 2020  ing.            
+00003740: 2020 2020 2020 2020 2020 2020 2320 6966              # if
+00003750: 2069 7420 6861 7320 7468 6520 7264 663a   it has the rdf:
+00003760: 7479 7065 2043 6f6e 7374 616e 7473 2e4e  type Constants.N
+00003770: 4944 4d5f 4153 5345 5353 4d45 4e54 5f45  IDM_ASSESSMENT_E
+00003780: 4e54 4954 590a 2020 2020 2020 2020 2020  NTITY.          
+00003790: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+000037a0: 666f 7220 6163 715f 6d6f 6461 6c69 7479  for acq_modality
+000037b0: 2069 6e20 7264 665f 6772 6170 685f 7061   in rdf_graph_pa
+000037c0: 7273 652e 6f62 6a65 6374 7328 7375 626a  rse.objects(subj
+000037d0: 6563 743d 6163 715f 6f62 6a2c 7072 6564  ect=acq_obj,pred
+000037e0: 6963 6174 653d 5244 462e 7479 7065 293a  icate=RDF.type):
+000037f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00003800: 2020 2020 2020 2020 2065 6c69 6620 280a           elif (.
+00003810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003820: 2020 2020 2020 2020 2020 2020 6163 715f              acq_
+00003830: 6f62 6a2c 0a20 2020 2020 2020 2020 2020  obj,.           
+00003840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003850: 2052 4446 2e74 7970 652c 0a20 2020 2020   RDF.type,.     
+00003860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003870: 2020 2020 2020 2055 5249 5265 6628 436f         URIRef(Co
+00003880: 6e73 7461 6e74 732e 4e49 444d 5f41 5353  nstants.NIDM_ASS
+00003890: 4553 534d 454e 545f 454e 5449 5459 2e5f  ESSMENT_ENTITY._
+000038a0: 7572 6929 2c0a 2020 2020 2020 2020 2020  uri),.          
+000038b0: 2020 2020 2020 2020 2020 2020 2020 2920                ) 
+000038c0: 696e 2072 6466 5f67 7261 7068 3a0a 2020  in rdf_graph:.  
 000038d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000038e0: 2061 6371 7569 7369 7469 6f6e 5f6f 626a   acquisition_obj
-000038f0: 290a 0a0a 0a20 2020 2020 2020 2020 2020  )....           
-00003900: 2020 2020 2023 5468 6973 2073 6b69 7073       #This skips
-00003910: 2072 6466 5f74 7970 6520 5052 4f56 5b27   rdf_type PROV['
-00003920: 4163 7469 7669 7479 275d 0a20 2020 2020  Activity'].     
-00003930: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-00003940: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003950: 2020 2020 2063 6f6e 7469 6e75 650a 0a20       continue.. 
-00003960: 2020 2023 2051 7565 7279 2067 7261 7068     # Query graph
-00003970: 2066 6f72 206e 6964 6d3a 4461 7461 456c   for nidm:DataEl
-00003980: 656d 656e 7473 2061 6e64 2069 6e73 7461  ements and insta
-00003990: 6e74 6961 7465 2061 206e 6964 6d3a 4461  ntiate a nidm:Da
-000039a0: 7461 456c 656d 656e 7420 636c 6173 7320  taElement class 
-000039b0: 616e 6420 6164 6420 7468 656d 2074 6f20  and add them to 
-000039c0: 7468 6520 7072 6f6a 6563 740a 2020 2020  the project.    
-000039d0: 7175 6572 7920 3d20 2727 270a 2020 2020  query = '''.    
-000039e0: 2020 2020 2020 2020 2020 2020 7072 6566              pref
-000039f0: 6978 206e 6964 6d3a 203c 6874 7470 3a2f  ix nidm: <http:/
-00003a00: 2f70 7572 6c2e 6f72 672f 6e69 6461 7368  /purl.org/nidash
-00003a10: 2f6e 6964 6d23 3e0a 2020 2020 2020 2020  /nidm#>.        
-00003a20: 2020 2020 2020 2020 7072 6566 6978 2072          prefix r
-00003a30: 6466 733a 203c 6874 7470 3a2f 2f77 7777  dfs: <http://www
-00003a40: 2e77 332e 6f72 672f 3230 3030 2f30 312f  .w3.org/2000/01/
-00003a50: 7264 662d 7363 6865 6d61 233e 200a 2020  rdf-schema#> .  
-00003a60: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00003a70: 6c65 6374 2064 6973 7469 6e63 7420 3f75  lect distinct ?u
-00003a80: 7569 640a 2020 2020 2020 2020 2020 2020  uid.            
-00003a90: 2020 2020 7768 6572 6520 7b0a 2020 2020      where {.    
-00003aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003ab0: 3f75 7569 6420 612f 7264 6673 3a73 7562  ?uuid a/rdfs:sub
-00003ac0: 436c 6173 734f 662a 206e 6964 6d3a 4461  ClassOf* nidm:Da
-00003ad0: 7461 456c 656d 656e 7420 2e0a 0a20 2020  taElement ...   
-00003ae0: 2020 2020 2020 2020 2020 2020 207d 0a20               }. 
-00003af0: 2020 2020 2020 2020 2020 2020 2020 2027                 '
-00003b00: 2727 0a0a 2020 2020 2320 6164 6420 616c  ''..    # add al
-00003b10: 6c20 6e69 646d 3a44 6174 6145 6c65 6d65  l nidm:DataEleme
-00003b20: 6e74 7320 696e 2067 7261 7068 0a20 2020  nts in graph.   
-00003b30: 2071 7265 7320 3d20 7264 665f 6772 6170   qres = rdf_grap
-00003b40: 685f 7061 7273 652e 7175 6572 7928 7175  h_parse.query(qu
-00003b50: 6572 7929 0a20 2020 2066 6f72 2072 6f77  ery).    for row
-00003b60: 2069 6e20 7172 6573 3a0a 2020 2020 2020   in qres:.      
-00003b70: 2020 7072 696e 7428 726f 7729 0a20 2020    print(row).   
-00003b80: 2020 2020 2023 2069 6e73 7461 6e74 6961       # instantia
-00003b90: 7465 2061 2064 6174 6120 656c 656d 656e  te a data elemen
-00003ba0: 7420 636c 6173 7320 6173 7369 676e 696e  t class assignin
-00003bb0: 6720 6974 2074 6865 2065 7869 7374 696e  g it the existin
-00003bc0: 6720 7575 6964 0a20 2020 2020 2020 2064  g uuid.        d
-00003bd0: 6520 3d20 4461 7461 456c 656d 656e 7428  e = DataElement(
-00003be0: 7072 6f6a 6563 743d 7072 6f6a 6563 742c  project=project,
-00003bf0: 2075 7569 643d 726f 775b 2775 7569 6427   uuid=row['uuid'
-00003c00: 5d2c 2061 6464 5f64 6566 6175 6c74 5f74  ], add_default_t
-00003c10: 7970 653d 4661 6c73 6529 0a20 2020 2020  ype=False).     
-00003c20: 2020 2023 2067 6574 2074 6865 2072 6573     # get the res
-00003c30: 7420 6f66 2074 6865 2061 7474 7269 6275  t of the attribu
-00003c40: 7465 7320 666f 7220 7468 6973 2064 6174  tes for this dat
-00003c50: 6120 656c 656d 656e 7420 616e 6420 7374  a element and st
-00003c60: 6f72 650a 2020 2020 2020 2020 6164 645f  ore.        add_
-00003c70: 6d65 7461 6461 7461 5f66 6f72 5f73 7562  metadata_for_sub
-00003c80: 6a65 6374 2872 6466 5f67 7261 7068 5f70  ject(rdf_graph_p
-00003c90: 6172 7365 2c20 726f 775b 2775 7569 6427  arse, row['uuid'
-00003ca0: 5d2c 2070 726f 6a65 6374 2e67 7261 7068  ], project.graph
-00003cb0: 2e6e 616d 6573 7061 6365 732c 2064 6529  .namespaces, de)
-00003cc0: 0a0a 2020 2020 2020 2020 2320 6e6f 7720  ..        # now 
-00003cd0: 7765 206e 6565 6420 746f 2063 6865 636b  we need to check
-00003ce0: 2069 6620 7468 6572 6520 6172 6520 6c61   if there are la
-00003cf0: 6265 6c73 2066 6f72 2064 6174 6120 656c  bels for data el
-00003d00: 656d 656e 7420 6973 4162 6f75 7420 656e  ement isAbout en
-00003d10: 7472 6965 732c 2069 6620 736f 2061 6464  tries, if so add
-00003d20: 2074 6865 6d2e 0a20 2020 2020 2020 2071   them..        q
-00003d30: 7565 7279 3220 3d20 2727 270a 0a20 2020  uery2 = '''..   
-00003d40: 2020 2020 2020 2020 2020 2020 2070 7265               pre
-00003d50: 6669 7820 6e69 646d 3a20 3c68 7474 703a  fix nidm: <http:
-00003d60: 2f2f 7075 726c 2e6f 7267 2f6e 6964 6173  //purl.org/nidas
-00003d70: 682f 6e69 646d 233e 0a20 2020 2020 2020  h/nidm#>.       
-00003d80: 2020 2020 2020 2020 2070 7265 6669 7820           prefix 
-00003d90: 7264 6673 3a20 3c68 7474 703a 2f2f 7777  rdfs: <http://ww
-00003da0: 772e 7733 2e6f 7267 2f32 3030 302f 3031  w.w3.org/2000/01
-00003db0: 2f72 6466 2d73 6368 656d 6123 3e0a 2020  /rdf-schema#>.  
-00003dc0: 2020 2020 2020 2020 2020 2020 2020 7072                pr
-00003dd0: 6566 6978 2072 6466 3a20 3c68 7474 703a  efix rdf: <http:
-00003de0: 2f2f 7777 772e 7733 2e6f 7267 2f31 3939  //www.w3.org/199
-00003df0: 392f 3032 2f32 322d 7264 662d 7379 6e74  9/02/22-rdf-synt
-00003e00: 6178 2d6e 7323 3e0a 2020 2020 2020 2020  ax-ns#>.        
-00003e10: 2020 2020 2020 2020 7072 6566 6978 2070          prefix p
-00003e20: 726f 763a 203c 6874 7470 3a2f 2f77 7777  rov: <http://www
-00003e30: 2e77 332e 6f72 672f 6e73 2f70 726f 7623  .w3.org/ns/prov#
-00003e40: 3e0a 0a20 2020 2020 2020 2020 2020 2020  >..             
-00003e50: 2020 2073 656c 6563 7420 6469 7374 696e     select distin
-00003e60: 6374 203f 6964 203f 6c61 6265 6c0a 2020  ct ?id ?label.  
-00003e70: 2020 2020 2020 2020 2020 2020 2020 7768                wh
-00003e80: 6572 6520 7b0a 2020 2020 2020 2020 2020  ere {.          
-00003e90: 2020 2020 2020 2020 2020 3c25 733e 206e            <%s> n
-00003ea0: 6964 6d3a 6973 4162 6f75 7420 3f69 6420  idm:isAbout ?id 
-00003eb0: 2e0a 0a20 2020 2020 2020 2020 2020 2020  ...             
-00003ec0: 2020 2020 2020 203f 6964 2072 6466 3a74         ?id rdf:t
-00003ed0: 7970 6520 7072 6f76 3a45 6e74 6974 7920  ype prov:Entity 
-00003ee0: 3b0a 2020 2020 2020 2020 2020 2020 2020  ;.              
-00003ef0: 2020 2020 2020 2020 2020 7264 6673 3a6c            rdfs:l
-00003f00: 6162 656c 203f 6c61 6265 6c20 2e20 200a  abel ?label .  .
-00003f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003f20: 7d0a 0a20 2020 2020 2020 2020 2020 2027  }..            '
-00003f30: 2727 2025 2072 6f77 5b27 7575 6964 275d  '' % row['uuid']
-00003f40: 0a20 2020 2020 2020 2023 2070 7269 6e74  .        # print
-00003f50: 2871 7565 7279 3229 0a20 2020 2020 2020  (query2).       
-00003f60: 2071 7265 7332 203d 2072 6466 5f67 7261   qres2 = rdf_gra
-00003f70: 7068 5f70 6172 7365 2e71 7565 7279 2871  ph_parse.query(q
-00003f80: 7565 7279 3229 0a0a 2020 2020 2020 2020  uery2)..        
-00003f90: 2320 6164 6420 7468 6973 2074 7570 6c65  # add this tuple
-00003fa0: 2074 6f20 6772 6170 680a 2020 2020 2020   to graph.      
-00003fb0: 2020 666f 7220 726f 7732 2069 6e20 7172    for row2 in qr
-00003fc0: 6573 323a 0a20 2020 2020 2020 2020 2020  es2:.           
-00003fd0: 2070 726f 6a65 6374 2e67 7261 7068 2e65   project.graph.e
-00003fe0: 6e74 6974 7928 726f 7732 5b30 5d2c 207b  ntity(row2[0], {
-00003ff0: 2772 6466 733a 6c61 6265 6c27 3a20 726f  'rdfs:label': ro
-00004000: 7732 5b31 5d7d 290a 0a20 2020 2023 2063  w2[1]})..    # c
-00004010: 6865 636b 2066 6f72 2044 6572 6976 6174  heck for Derivat
-00004020: 6976 6573 2e0a 2020 2020 2320 5749 503a  ives..    # WIP:
-00004030: 2043 7572 7265 6e74 6c79 2046 534c 2c20   Currently FSL, 
-00004040: 4672 6565 7375 7266 6572 2c20 616e 6420  Freesurfer, and 
-00004050: 414e 5453 2074 6f6f 6c73 2061 6464 2074  ANTS tools add t
-00004060: 6865 7365 2064 6572 6976 6174 6976 6573  hese derivatives
-00004070: 2061 7320 6e69 646d 3a46 5353 7461 7473   as nidm:FSStats
-00004080: 436f 6c6c 6563 7469 6f6e 2c0a 2020 2020  Collection,.    
-00004090: 2320 6e69 646d 3a46 534c 5374 6174 7343  # nidm:FSLStatsC
-000040a0: 6f6c 6c65 6374 696f 6e2c 206f 7220 6e69  ollection, or ni
-000040b0: 646d 3a41 4e54 5353 7461 7473 436f 6c6c  dm:ANTSStatsColl
-000040c0: 6563 7469 6f6e 2077 6869 6368 2061 7265  ection which are
-000040d0: 2073 7562 636c 6173 7365 7320 6f66 206e   subclasses of n
-000040e0: 6964 6d3a 4465 7269 7661 7469 7665 730a  idm:Derivatives.
-000040f0: 2020 2020 2320 7468 6973 2073 686f 756c      # this shoul
-00004100: 6420 7072 6f62 6162 6c79 2062 6520 6578  d probably be ex
-00004110: 706c 6963 6974 6c79 2069 6e64 6963 6174  plicitly indicat
-00004120: 6564 2069 6e20 7468 6520 6772 6170 6873  ed in the graphs
-00004130: 2062 7574 2063 7572 7265 6e74 6c79 2069   but currently i
-00004140: 736e 2774 0a0a 2020 2020 2320 5175 6572  sn't..    # Quer
-00004150: 7920 6772 6170 6820 666f 7220 616e 7920  y graph for any 
-00004160: 6f66 2074 6865 2061 626f 7665 2044 6572  of the above Der
-00004170: 6976 6174 6965 730a 2020 2020 7175 6572  ivaties.    quer
-00004180: 7920 3d20 2727 270a 2020 2020 2020 2020  y = '''.        
-00004190: 2020 2020 7072 6566 6978 206e 6964 6d3a      prefix nidm:
-000041a0: 203c 6874 7470 3a2f 2f70 7572 6c2e 6f72   <http://purl.or
-000041b0: 672f 6e69 6461 7368 2f6e 6964 6d23 3e20  g/nidash/nidm#> 
-000041c0: 0a20 2020 2020 2020 2020 2020 2070 7265  .            pre
-000041d0: 6669 7820 7072 6f76 3a20 3c68 7474 703a  fix prov: <http:
-000041e0: 2f2f 7777 772e 7733 2e6f 7267 2f6e 732f  //www.w3.org/ns/
-000041f0: 7072 6f76 233e 200a 2020 2020 2020 2020  prov#> .        
-00004200: 2020 2020 7365 6c65 6374 2064 6973 7469      select disti
-00004210: 6e63 7420 3f75 7569 6420 3f70 6172 656e  nct ?uuid ?paren
-00004220: 745f 6163 740a 2020 2020 2020 2020 2020  t_act.          
-00004230: 2020 7768 6572 6520 7b0a 2020 2020 2020    where {.      
-00004240: 2020 2020 2020 2020 2020 7b3f 7575 6964            {?uuid
-00004250: 2061 206e 6964 6d3a 4465 7269 7661 7469   a nidm:Derivati
-00004260: 7665 203b 0a20 2020 2020 2020 2020 2020  ve ;.           
-00004270: 2009 2020 2020 7072 6f76 3a77 6173 4765   .    prov:wasGe
-00004280: 6e65 7261 7465 6442 7920 3f70 6172 656e  neratedBy ?paren
-00004290: 745f 6163 7420 2e7d 0a20 2020 2020 0909  t_act .}.     ..
-000042a0: 2020 2020 554e 494f 4e0a 2020 2020 2009      UNION.     .
-000042b0: 0920 2020 207b 3f75 7569 6420 6120 6e69  .    {?uuid a ni
-000042c0: 646d 3a46 5353 7461 7473 436f 6c6c 6563  dm:FSStatsCollec
-000042d0: 7469 6f6e 203b 0a20 2020 2020 2020 2020  tion ;.         
-000042e0: 2020 2009 2020 2020 7072 6f76 3a77 6173     .    prov:was
-000042f0: 4765 6e65 7261 7465 6442 7920 3f70 6172  GeneratedBy ?par
-00004300: 656e 745f 6163 7420 2e7d 0a20 2020 2020  ent_act .}.     
-00004310: 0909 2020 2020 554e 494f 4e0a 2020 2020  ..    UNION.    
-00004320: 2009 0920 2020 207b 3f75 7569 6420 6120   ..    {?uuid a 
-00004330: 6e69 646d 3a46 534c 5374 6174 7343 6f6c  nidm:FSLStatsCol
-00004340: 6c65 6374 696f 6e20 3b0a 2020 2020 2020  lection ;.      
-00004350: 2020 2020 2020 0920 2020 2070 726f 763a        .    prov:
-00004360: 7761 7347 656e 6572 6174 6564 4279 203f  wasGeneratedBy ?
-00004370: 7061 7265 6e74 5f61 6374 202e 7d0a 2020  parent_act .}.  
-00004380: 2020 2009 0920 2020 2055 4e49 4f4e 0a20     ..    UNION. 
-00004390: 2020 2020 0909 2020 2020 7b3f 7575 6964      ..    {?uuid
-000043a0: 2061 206e 6964 6d3a 414e 5453 5374 6174   a nidm:ANTSStat
-000043b0: 7343 6f6c 6c65 6374 696f 6e20 3b0a 2020  sCollection ;.  
-000043c0: 2020 2020 2020 2020 2020 0920 2020 2070            .    p
-000043d0: 726f 763a 7761 7347 656e 6572 6174 6564  rov:wasGenerated
-000043e0: 4279 203f 7061 7265 6e74 5f61 6374 202e  By ?parent_act .
-000043f0: 7d0a 2020 2020 2020 2020 2020 2020 7d0a  }.            }.
-00004400: 2020 2020 0a20 2020 2020 2020 2027 2727      .        '''
-00004410: 0a20 2020 2071 7265 7320 3d20 7264 665f  .    qres = rdf_
-00004420: 6772 6170 685f 7061 7273 652e 7175 6572  graph_parse.quer
-00004430: 7928 7175 6572 7929 0a20 2020 2066 6f72  y(query).    for
-00004440: 2072 6f77 2069 6e20 7172 6573 3a0a 2020   row in qres:.  
-00004450: 2020 2020 2020 2320 7075 7420 7468 6973        # put this
-00004460: 2068 6572 6520 736f 2074 6865 2066 6f6c   here so the fol
-00004470: 6c6f 7769 6e67 206d 616b 6573 206d 6f72  lowing makes mor
-00004480: 6520 7365 6e73 650a 2020 2020 2020 2020  e sense.        
-00004490: 6465 7269 766f 626a 5f75 7569 6420 3d20  derivobj_uuid = 
-000044a0: 726f 775b 2775 7569 6427 5d0a 2020 2020  row['uuid'].    
-000044b0: 2020 2020 2320 6966 2074 6865 2070 6172      # if the par
-000044c0: 656e 7420 6163 7469 7669 7479 206f 6620  ent activity of 
-000044d0: 7468 6520 6465 7269 7661 7469 7665 206f  the derivative o
-000044e0: 626a 6563 7420 2865 6e74 6974 7929 2064  bject (entity) d
-000044f0: 6f65 736e 2774 2065 7869 7374 2069 6e20  oesn't exist in 
-00004500: 7468 6520 6772 6170 6820 7468 656e 2063  the graph then c
-00004510: 7265 6174 6520 6974 0a20 2020 2020 2020  reate it.       
-00004520: 2069 6620 726f 775b 2770 6172 656e 745f   if row['parent_
-00004530: 6163 7427 5d20 6e6f 7420 696e 2070 726f  act'] not in pro
-00004540: 6a65 6374 2e64 6572 6976 6174 6976 6573  ject.derivatives
-00004550: 3a0a 2020 2020 2020 2020 2020 2020 6465  :.            de
-00004560: 7269 765f 6163 7420 3d20 4465 7269 7661  riv_act = Deriva
-00004570: 7469 7665 2870 726f 6a65 6374 3d70 726f  tive(project=pro
-00004580: 6a65 6374 2c20 7575 6964 3d72 6f77 5b27  ject, uuid=row['
-00004590: 7061 7265 6e74 5f61 6374 275d 290a 2020  parent_act']).  
-000045a0: 2020 2020 2020 2020 2020 2320 6164 6420            # add 
-000045b0: 6164 6469 7469 6f6e 616c 2074 7269 7065  additional tripe
-000045c0: 730a 2020 2020 2020 2020 2020 2020 6164  s.            ad
-000045d0: 645f 6d65 7461 6461 7461 5f66 6f72 5f73  d_metadata_for_s
-000045e0: 7562 6a65 6374 2872 6466 5f67 7261 7068  ubject(rdf_graph
-000045f0: 5f70 6172 7365 2c20 726f 775b 2770 6172  _parse, row['par
-00004600: 656e 745f 6163 7427 5d2c 2070 726f 6a65  ent_act'], proje
-00004610: 6374 2e67 7261 7068 2e6e 616d 6573 7061  ct.graph.namespa
-00004620: 6365 732c 2064 6572 6976 5f61 6374 290a  ces, deriv_act).
-00004630: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00004640: 2020 2020 2020 2020 2020 666f 7220 6420            for d 
-00004650: 696e 2070 726f 6a65 6374 2e67 6574 5f64  in project.get_d
-00004660: 6572 6976 6174 6976 6573 3a0a 2020 2020  erivatives:.    
-00004670: 2020 2020 2020 2020 2020 2020 6966 2072              if r
-00004680: 6f77 5b27 7061 7265 6e74 5f61 6374 275d  ow['parent_act']
-00004690: 203d 3d20 642e 6765 745f 7575 6964 2829   == d.get_uuid()
-000046a0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000046b0: 2020 2020 2020 6465 7269 765f 6163 7420        deriv_act 
-000046c0: 3d20 640a 0a20 2020 2020 2020 2023 6368  = d..        #ch
-000046d0: 6563 6b20 6966 2064 6572 6976 6174 6976  eck if derivativ
-000046e0: 6520 6f62 6a65 6374 2061 6c72 6561 6479  e object already
-000046f0: 2063 7265 6174 6564 2061 6e64 2069 6620   created and if 
-00004700: 6e6f 7420 6372 6561 7465 2069 740a 2020  not create it.  
-00004710: 2020 2020 2020 2369 6620 6465 7269 766f        #if derivo
-00004720: 626a 5f75 7569 6420 6e6f 7420 696e 2064  bj_uuid not in d
-00004730: 6572 6976 5f61 6374 2e67 6574 5f64 6572  eriv_act.get_der
-00004740: 6976 6174 6976 655f 6f62 6a65 6374 7328  ivative_objects(
-00004750: 293a 0a20 2020 2020 2020 2023 206e 6f77  ):.        # now
-00004760: 2069 6e73 7461 6e74 6961 7465 2074 6865   instantiate the
-00004770: 2064 6572 6976 6174 6976 6520 6f62 6a65   derivative obje
-00004780: 6374 2061 6e64 2061 6464 2061 6c6c 2074  ct and add all t
-00004790: 7269 706c 6573 0a20 2020 2020 2020 2064  riples.        d
-000047a0: 6572 6976 6f62 6a20 3d20 4465 7269 7661  erivobj = Deriva
-000047b0: 7469 7665 4f62 6a65 6374 2864 6572 6976  tiveObject(deriv
-000047c0: 6174 6976 653d 6465 7269 765f 6163 742c  ative=deriv_act,
-000047d0: 7575 6964 3d64 6572 6976 6f62 6a5f 7575  uuid=derivobj_uu
-000047e0: 6964 290a 2020 2020 2020 2020 6164 645f  id).        add_
-000047f0: 6d65 7461 6461 7461 5f66 6f72 5f73 7562  metadata_for_sub
-00004800: 6a65 6374 2872 6466 5f67 7261 7068 5f70  ject(rdf_graph_p
-00004810: 6172 7365 2c20 726f 775b 2775 7569 6427  arse, row['uuid'
-00004820: 5d2c 2070 726f 6a65 6374 2e67 7261 7068  ], project.graph
-00004830: 2e6e 616d 6573 7061 6365 732c 2064 6572  .namespaces, der
-00004840: 6976 6f62 6a29 0a0a 0a0a 2020 2020 7265  ivobj)....    re
-00004850: 7475 726e 2870 726f 6a65 6374 290a 0a0a  turn(project)...
-00004860: 6465 6620 6765 745f 5244 466c 6974 6572  def get_RDFliter
-00004870: 616c 5f74 7970 6528 7264 665f 6c69 7465  al_type(rdf_lite
-00004880: 7261 6c29 3a0a 2020 2020 6966 2028 7264  ral):.    if (rd
-00004890: 665f 6c69 7465 7261 6c2e 6461 7461 7479  f_literal.dataty
-000048a0: 7065 203d 3d20 5853 445b 2269 6e74 6567  pe == XSD["integ
-000048b0: 6572 225d 293a 0a20 2020 2020 2020 2023  er"]):.        #
-000048c0: 7265 7475 726e 2028 696e 7428 7264 665f  return (int(rdf_
-000048d0: 6c69 7465 7261 6c29 290a 2020 2020 2020  literal)).      
-000048e0: 2020 7265 7475 726e 2870 6d2e 4c69 7465    return(pm.Lite
-000048f0: 7261 6c28 7264 665f 6c69 7465 7261 6c2c  ral(rdf_literal,
-00004900: 6461 7461 7479 7065 3d70 6d2e 5853 445b  datatype=pm.XSD[
-00004910: 2269 6e74 6567 6572 225d 2929 0a20 2020  "integer"])).   
-00004920: 2065 6c69 6620 2828 7264 665f 6c69 7465   elif ((rdf_lite
-00004930: 7261 6c2e 6461 7461 7479 7065 203d 3d20  ral.datatype == 
-00004940: 5853 445b 2266 6c6f 6174 225d 2920 6f72  XSD["float"]) or
-00004950: 2028 7264 665f 6c69 7465 7261 6c2e 6461   (rdf_literal.da
-00004960: 7461 7479 7065 203d 3d20 5853 445b 2264  tatype == XSD["d
-00004970: 6f75 626c 6522 5d29 293a 0a20 2020 2020  ouble"])):.     
-00004980: 2020 2023 7265 7475 726e 2866 6c6f 6174     #return(float
-00004990: 2872 6466 5f6c 6974 6572 616c 2929 0a20  (rdf_literal)). 
-000049a0: 2020 2020 2020 2072 6574 7572 6e28 706d         return(pm
-000049b0: 2e4c 6974 6572 616c 2872 6466 5f6c 6974  .Literal(rdf_lit
-000049c0: 6572 616c 2c64 6174 6174 7970 653d 706d  eral,datatype=pm
-000049d0: 2e58 5344 5b22 666c 6f61 7422 5d29 290a  .XSD["float"])).
-000049e0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-000049f0: 2020 2372 6574 7572 6e20 2873 7472 2872    #return (str(r
-00004a00: 6466 5f6c 6974 6572 616c 2929 0a20 2020  df_literal)).   
-00004a10: 2020 2020 2072 6574 7572 6e28 706d 2e4c       return(pm.L
-00004a20: 6974 6572 616c 2872 6466 5f6c 6974 6572  iteral(rdf_liter
-00004a30: 616c 2c64 6174 6174 7970 653d 706d 2e58  al,datatype=pm.X
-00004a40: 5344 5b22 7374 7269 6e67 225d 2929 0a0a  SD["string"]))..
-00004a50: 6465 6620 6669 6e64 5f69 6e5f 6e61 6d65  def find_in_name
-00004a60: 7370 6163 6573 2873 6561 7263 685f 7572  spaces(search_ur
-00004a70: 692c 206e 616d 6573 7061 6365 7329 3a0a  i, namespaces):.
-00004a80: 2020 2020 2727 270a 2020 2020 4c6f 6f6b      '''.    Look
-00004a90: 7320 7468 726f 7567 6820 6e61 6d65 7370  s through namesp
-00004aa0: 6163 6573 2066 6f72 2073 6561 7263 685f  aces for search_
-00004ab0: 7572 690a 2020 2020 3a72 6574 7572 6e3a  uri.    :return:
-00004ac0: 2055 5249 2069 6620 666f 756e 6420 656c   URI if found el
-00004ad0: 7365 2046 616c 7365 0a20 2020 2027 2727  se False.    '''
-00004ae0: 0a0a 2020 2020 666f 7220 7572 6973 2069  ..    for uris i
-00004af0: 6e20 6e61 6d65 7370 6163 6573 3a0a 2020  n namespaces:.  
-00004b00: 2020 2020 2020 6966 2075 7269 732e 7572        if uris.ur
-00004b10: 6920 3d3d 2073 6561 7263 685f 7572 693a  i == search_uri:
-00004b20: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00004b30: 7572 6e20 7572 6973 0a20 2020 200a 2020  urn uris.    .  
-00004b40: 2020 7265 7475 726e 2046 616c 7365 0a0a    return False..
-00004b50: 6465 6620 6164 645f 6d65 7461 6461 7461  def add_metadata
-00004b60: 5f66 6f72 5f73 7562 6a65 6374 2028 7264  _for_subject (rd
-00004b70: 665f 6772 6170 682c 7375 626a 6563 745f  f_graph,subject_
-00004b80: 7572 692c 6e61 6d65 7370 6163 6573 2c6e  uri,namespaces,n
-00004b90: 6964 6d5f 6f62 6a29 3a0a 2020 2020 2222  idm_obj):.    ""
-00004ba0: 220a 2020 2020 4379 636c 6573 2074 6872  ".    Cycles thr
-00004bb0: 6f75 6768 2074 7269 706c 6573 2066 6f72  ough triples for
-00004bc0: 2061 2070 6172 7469 6375 6c61 7220 7375   a particular su
-00004bd0: 626a 6563 7420 616e 6420 6164 6473 2074  bject and adds t
-00004be0: 6865 6d20 746f 2074 6865 206e 6964 6d5f  hem to the nidm_
-00004bf0: 6f62 6a0a 0a20 2020 203a 7061 7261 6d20  obj..    :param 
-00004c00: 7264 665f 6772 6170 683a 2052 4446 2067  rdf_graph: RDF g
-00004c10: 7261 7068 206f 626a 6563 740a 2020 2020  raph object.    
-00004c20: 3a70 6172 616d 2073 7562 6a65 6374 5f75  :param subject_u
-00004c30: 7269 3a20 5552 4920 6f66 2073 7562 6a65  ri: URI of subje
-00004c40: 6374 2074 6f20 7175 6572 7920 666f 7220  ct to query for 
-00004c50: 6164 6469 7469 6f6e 616c 206d 6574 6164  additional metad
-00004c60: 6174 610a 2020 2020 3a70 6172 616d 206e  ata.    :param n
-00004c70: 616d 6573 7061 6365 733a 204e 616d 6573  amespaces: Names
-00004c80: 7061 6365 7320 696e 2069 6e70 7574 2067  paces in input g
-00004c90: 7261 7068 0a20 2020 203a 7061 7261 6d20  raph.    :param 
-00004ca0: 6e69 646d 5f6f 626a 3a20 4e49 444d 206f  nidm_obj: NIDM o
-00004cb0: 626a 6563 7420 746f 2061 6464 206d 6574  bject to add met
-00004cc0: 6164 6174 610a 2020 2020 3a72 6574 7572  adata.    :retur
-00004cd0: 6e3a 204e 6f6e 650a 0a20 2020 2022 2222  n: None..    """
-00004ce0: 0a20 2020 2023 4379 636c 6520 7468 726f  .    #Cycle thro
-00004cf0: 7567 6820 7265 6d61 696e 696e 6720 6d65  ugh remaining me
-00004d00: 7461 6461 7461 2061 6e64 2061 6464 2061  tadata and add a
-00004d10: 7474 7269 6275 7465 730a 2020 2020 666f  ttributes.    fo
-00004d20: 7220 7072 6564 6963 6174 652c 206f 626a  r predicate, obj
-00004d30: 6563 7473 2069 6e20 7264 665f 6772 6170  ects in rdf_grap
-00004d40: 682e 7072 6564 6963 6174 655f 6f62 6a65  h.predicate_obje
-00004d50: 6374 7328 7375 626a 6563 743d 7375 626a  cts(subject=subj
-00004d60: 6563 745f 7572 6929 3a0a 2020 2020 2020  ect_uri):.      
-00004d70: 2020 2320 6966 2074 6869 7320 6973 6e27    # if this isn'
-00004d80: 7420 6120 7175 616c 6966 6965 6420 6173  t a qualified as
-00004d90: 736f 6369 6174 696f 6e2c 2061 6464 2074  sociation, add t
-00004da0: 7269 706c 6573 0a20 2020 2020 2020 2069  riples.        i
-00004db0: 6620 7072 6564 6963 6174 6520 213d 2055  f predicate != U
-00004dc0: 5249 5265 6628 436f 6e73 7461 6e74 732e  RIRef(Constants.
-00004dd0: 5052 4f56 5b27 7175 616c 6966 6965 6441  PROV['qualifiedA
-00004de0: 7373 6f63 6961 7469 6f6e 275d 293a 0a20  ssociation']):. 
-00004df0: 2020 2020 2020 2020 2020 2023 206d 616b             # mak
-00004e00: 6520 7072 6564 6963 6174 6520 6120 7175  e predicate a qu
-00004e10: 616c 6966 6965 6420 6e61 6d65 0a20 2020  alified name.   
-00004e20: 2020 2020 2020 2020 206f 626a 5f6e 6d2c           obj_nm,
-00004e30: 206f 626a 5f74 6572 6d20 3d20 7370 6c69   obj_term = spli
-00004e40: 745f 7572 6928 7072 6564 6963 6174 6529  t_uri(predicate)
-00004e50: 0a20 2020 2020 2020 2020 2020 2066 6f75  .            fou
-00004e60: 6e64 5f75 7269 203d 2066 696e 645f 696e  nd_uri = find_in
-00004e70: 5f6e 616d 6573 7061 6365 7328 7365 6172  _namespaces(sear
-00004e80: 6368 5f75 7269 3d55 5249 5265 6628 6f62  ch_uri=URIRef(ob
-00004e90: 6a5f 6e6d 292c 206e 616d 6573 7061 6365  j_nm), namespace
-00004ea0: 733d 6e61 6d65 7370 6163 6573 290a 2020  s=namespaces).  
-00004eb0: 2020 2020 2020 2020 2020 2320 6966 206f            # if o
-00004ec0: 626a 5f6e 6d20 6973 206e 6f74 2069 6e20  bj_nm is not in 
-00004ed0: 6e61 6d65 7370 6163 6573 2074 6865 6e20  namespaces then 
-00004ee0: 6974 206d 7573 7420 6a75 7374 2062 6520  it must just be 
-00004ef0: 7061 7274 206f 6620 736f 6d65 2055 5249  part of some URI
-00004f00: 2069 6e20 7468 6520 7472 6970 6c65 0a20   in the triple. 
-00004f10: 2020 2020 2020 2020 2020 2023 2073 6f20             # so 
-00004f20: 6a75 7374 2061 6464 2069 7420 6173 2061  just add it as a
-00004f30: 2070 726f 762e 4964 656e 7469 6669 6572   prov.Identifier
-00004f40: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00004f50: 286e 6f74 2066 6f75 6e64 5f75 7269 2920  (not found_uri) 
-00004f60: 616e 6420 286f 626a 5f6e 6d20 213d 2043  and (obj_nm != C
-00004f70: 6f6e 7374 616e 7473 2e50 524f 5629 2061  onstants.PROV) a
-00004f80: 6e64 2028 6f62 6a5f 6e6d 2021 3d20 436f  nd (obj_nm != Co
-00004f90: 6e73 7461 6e74 732e 5853 4429 3a0a 2020  nstants.XSD):.  
-00004fa0: 2020 2020 2020 2020 2020 2020 2020 7072                pr
-00004fb0: 6564 6963 6174 6520 3d20 706d 2e51 7561  edicate = pm.Qua
-00004fc0: 6c69 6669 6564 4e61 6d65 286e 616d 6573  lifiedName(names
-00004fd0: 7061 6365 3d4e 616d 6573 7061 6365 2873  pace=Namespace(s
-00004fe0: 7472 2870 7265 6469 6361 7465 2929 2c20  tr(predicate)), 
-00004ff0: 6c6f 6361 6c70 6172 743d 2222 290a 2020  localpart="").  
-00005000: 2020 2020 2020 2020 2020 2320 656c 7365            # else
-00005010: 2061 6464 2061 7320 6578 706c 6963 6974   add as explicit
-00005020: 2070 726f 762e 5175 616c 6966 6965 644e   prov.QualifiedN
-00005030: 616d 6520 6265 6361 7573 6520 6974 2773  ame because it's
-00005040: 2065 6173 6965 7220 746f 2072 6561 640a   easier to read.
-00005050: 2020 2020 2020 2020 2020 2020 2365 6c73              #els
-00005060: 653a 0a20 2020 2020 2020 2020 2020 2023  e:.            #
-00005070: 2020 2020 7072 6564 6963 6174 6520 3d20      predicate = 
-00005080: 4964 656e 7469 6669 6572 2870 7265 6469  Identifier(predi
-00005090: 6361 7465 290a 2020 2020 2020 2020 2020  cate).          
-000050a0: 2020 6966 2028 7661 6c69 6461 746f 7273    if (validators
-000050b0: 2e75 726c 286f 626a 6563 7473 2929 2061  .url(objects)) a
-000050c0: 6e64 2028 7072 6564 6963 6174 6520 213d  nd (predicate !=
-000050d0: 2043 6f6e 7374 616e 7473 2e50 524f 565b   Constants.PROV[
-000050e0: 274c 6f63 6174 696f 6e27 5d29 3a0a 2020  'Location']):.  
-000050f0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-00005100: 7472 7920 746f 2073 706c 6974 2074 6865  try to split the
-00005110: 2055 5249 2074 6f20 6e61 6d65 7370 6163   URI to namespac
-00005120: 6520 616e 6420 6c6f 6361 6c20 7061 7274  e and local part
-00005130: 732c 2069 6620 6661 696c 7320 6a75 7374  s, if fails just
-00005140: 2075 7365 2074 6865 2065 6e74 6972 6520   use the entire 
-00005150: 5552 492e 0a20 2020 2020 2020 2020 2020  URI..           
-00005160: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
-00005170: 2020 2020 2020 2020 2020 2020 2020 2363                #c
-00005180: 7265 6174 6520 7175 616c 6966 6965 6420  reate qualified 
-00005190: 6e61 6d65 7320 666f 7220 6f62 6a65 6374  names for object
-000051a0: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
-000051b0: 2020 2020 2020 6f62 6a5f 6e6d 2c6f 626a        obj_nm,obj
-000051c0: 5f74 6572 6d20 3d20 7370 6c69 745f 7572  _term = split_ur
-000051d0: 6928 6f62 6a65 6374 7329 0a0a 2020 2020  i(objects)..    
-000051e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000051f0: 2320 6164 6465 6420 6265 6361 7573 6520  # added because 
-00005200: 5079 4e49 444d 2061 6765 6e74 2c20 6163  PyNIDM agent, ac
-00005210: 7469 7669 7479 2c20 616e 6420 656e 7469  tivity, and enti
-00005220: 7479 2063 6c61 7373 6573 2061 6c72 6561  ty classes alrea
-00005230: 6479 2061 6464 2074 6865 2074 7970 650a  dy add the type.
-00005240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005250: 2020 2020 6966 2028 286f 626a 6563 7473      if ((objects
-00005260: 203d 3d20 436f 6e73 7461 6e74 732e 5052   == Constants.PR
-00005270: 4f56 5b27 4163 7469 7669 7479 275d 2920  OV['Activity']) 
-00005280: 6f72 2028 6f62 6a65 6374 7320 3d3d 2043  or (objects == C
-00005290: 6f6e 7374 616e 7473 2e50 524f 565b 2741  onstants.PROV['A
-000052a0: 6765 6e74 275d 2920 6f72 0a20 2020 2020  gent']) or.     
-000052b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000052c0: 2020 2028 6f62 6a65 6374 7320 3d3d 2043     (objects == C
-000052d0: 6f6e 7374 616e 7473 2e50 524f 565b 2745  onstants.PROV['E
-000052e0: 6e74 6974 7927 5d29 293a 0a20 2020 2020  ntity'])):.     
-000052f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005300: 2020 2063 6f6e 7469 6e75 650a 2020 2020     continue.    
-00005310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005320: 2320 7370 6563 6961 6c20 6361 7365 2069  # special case i
-00005330: 6620 6f62 6a5f 6e6d 2069 7320 7072 6f76  f obj_nm is prov
-00005340: 2c20 7873 642c 206f 7220 6e69 646d 206e  , xsd, or nidm n
-00005350: 616d 6573 7061 6365 732e 2020 5468 6573  amespaces.  Thes
-00005360: 6520 6172 6520 6164 6465 640a 2020 2020  e are added.    
-00005370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005380: 2320 6175 746f 6d61 7469 6361 6c6c 7920  # automatically 
-00005390: 6279 2070 726f 7644 6f63 756d 656e 7420  by provDocument 
-000053a0: 736f 2074 6865 7920 6172 656e 2774 2061  so they aren't a
-000053b0: 6363 6573 7369 626c 6520 7669 6120 7468  ccessible via th
-000053c0: 6520 6e61 6d65 7370 6163 6573 206c 6973  e namespaces lis
-000053d0: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
-000053e0: 2020 2020 2020 2320 736f 2077 6520 6368        # so we ch
-000053f0: 6563 6b20 6578 706c 6963 6974 6c79 2068  eck explicitly h
-00005400: 6572 650a 2020 2020 2020 2020 2020 2020  ere.            
-00005410: 2020 2020 2020 2020 6966 2028 286f 626a          if ((obj
-00005420: 5f6e 6d20 3d3d 2073 7472 2843 6f6e 7374  _nm == str(Const
-00005430: 616e 7473 2e50 524f 5629 2929 3a0a 2020  ants.PROV))):.  
-00005440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005450: 2020 2020 2020 6e69 646d 5f6f 626a 2e61        nidm_obj.a
-00005460: 6464 5f61 7474 7269 6275 7465 7328 7b70  dd_attributes({p
-00005470: 7265 6469 6361 7465 3a20 5175 616c 6966  redicate: Qualif
-00005480: 6965 644e 616d 6528 436f 6e73 7461 6e74  iedName(Constant
-00005490: 732e 5052 4f56 5b6f 626a 5f74 6572 6d5d  s.PROV[obj_term]
-000054a0: 297d 290a 2020 2020 2020 2020 2020 2020  )}).            
-000054b0: 2020 2020 2020 2020 656c 6966 2028 286f          elif ((o
-000054c0: 626a 5f6e 6d20 3d3d 2073 7472 2843 6f6e  bj_nm == str(Con
-000054d0: 7374 616e 7473 2e4e 4944 4d29 2929 3a0a  stants.NIDM))):.
-000054e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000054f0: 2020 2020 2020 2020 6e69 646d 5f6f 626a          nidm_obj
-00005500: 2e61 6464 5f61 7474 7269 6275 7465 7328  .add_attributes(
-00005510: 7b70 7265 6469 6361 7465 3a20 5175 616c  {predicate: Qual
-00005520: 6966 6965 644e 616d 6528 436f 6e73 7461  ifiedName(Consta
-00005530: 6e74 732e 4e49 444d 5b6f 626a 5f74 6572  nts.NIDM[obj_ter
-00005540: 6d5d 297d 290a 2020 2020 2020 2020 2020  m])}).          
-00005550: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-00005560: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005570: 2020 2020 2020 2020 666f 756e 645f 7572          found_ur
-00005580: 6920 3d20 6669 6e64 5f69 6e5f 6e61 6d65  i = find_in_name
-00005590: 7370 6163 6573 2873 6561 7263 685f 7572  spaces(search_ur
-000055a0: 693d 5552 4952 6566 286f 626a 5f6e 6d29  i=URIRef(obj_nm)
-000055b0: 2c6e 616d 6573 7061 6365 733d 6e61 6d65  ,namespaces=name
-000055c0: 7370 6163 6573 290a 2020 2020 2020 2020  spaces).        
-000055d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000055e0: 2320 6966 206f 626a 5f6e 6d20 6973 206e  # if obj_nm is n
-000055f0: 6f74 2069 6e20 6e61 6d65 7370 6163 6573  ot in namespaces
-00005600: 2074 6865 6e20 6974 206d 7573 7420 6a75   then it must ju
-00005610: 7374 2062 6520 7061 7274 206f 6620 736f  st be part of so
-00005620: 6d65 2055 5249 2069 6e20 7468 6520 7472  me URI in the tr
-00005630: 6970 6c65 0a20 2020 2020 2020 2020 2020  iple.           
-00005640: 2020 2020 2020 2020 2020 2020 2023 2073               # s
-00005650: 6f20 6a75 7374 2061 6464 2069 7420 6173  o just add it as
-00005660: 2061 2070 726f 762e 4964 656e 7469 6669   a prov.Identifi
-00005670: 6572 0a20 2020 2020 2020 2020 2020 2020  er.             
-00005680: 2020 2020 2020 2020 2020 2069 6620 6e6f             if no
-00005690: 7420 666f 756e 645f 7572 693a 0a20 2020  t found_uri:.   
-000056a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000056b0: 2020 2020 2020 2020 206e 6964 6d5f 6f62           nidm_ob
-000056c0: 6a2e 6164 645f 6174 7472 6962 7574 6573  j.add_attributes
-000056d0: 287b 7072 6564 6963 6174 653a 2049 6465  ({predicate: Ide
-000056e0: 6e74 6966 6965 7228 6f62 6a65 6374 7329  ntifier(objects)
-000056f0: 7d29 0a20 2020 2020 2020 2020 2020 2020  }).             
-00005700: 2020 2020 2020 2020 2020 2023 2065 6c73             # els
-00005710: 6520 6164 6420 6173 2065 7870 6c69 6369  e add as explici
-00005720: 7420 7072 6f76 2e51 7561 6c69 6669 6564  t prov.Qualified
-00005730: 4e61 6d65 2062 6563 6175 7365 2069 7427  Name because it'
-00005740: 7320 6561 7369 6572 2074 6f20 7265 6164  s easier to read
-00005750: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005760: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-00005770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005780: 2020 2020 2020 2020 2020 206e 6964 6d5f             nidm_
-00005790: 6f62 6a2e 6164 645f 6174 7472 6962 7574  obj.add_attribut
-000057a0: 6573 287b 7072 6564 6963 6174 653a 2070  es({predicate: p
-000057b0: 6d2e 5175 616c 6966 6965 644e 616d 6528  m.QualifiedName(
-000057c0: 666f 756e 645f 7572 692c 206f 626a 5f74  found_uri, obj_t
-000057d0: 6572 6d29 7d29 0a20 2020 2020 2020 2020  erm)}).         
-000057e0: 2020 2020 2020 2065 7863 6570 743a 0a20         except:. 
-000057f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005800: 2020 206e 6964 6d5f 6f62 6a2e 6164 645f     nidm_obj.add_
-00005810: 6174 7472 6962 7574 6573 287b 7072 6564  attributes({pred
-00005820: 6963 6174 653a 2070 6d2e 5175 616c 6966  icate: pm.Qualif
-00005830: 6965 644e 616d 6528 6e61 6d65 7370 6163  iedName(namespac
-00005840: 653d 4e61 6d65 7370 6163 6528 7374 7228  e=Namespace(str(
-00005850: 6f62 6a65 6374 7329 292c 6c6f 6361 6c70  objects)),localp
-00005860: 6172 743d 2222 297d 290a 2020 2020 2020  art="")}).      
-00005870: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00005880: 2020 2020 2020 2020 2020 2020 2320 6368              # ch
-00005890: 6563 6b20 6966 2074 6869 7320 6973 2061  eck if this is a
-000058a0: 2071 6e61 6d65 2061 6e64 2069 6620 736f   qname and if so
-000058b0: 2065 7870 616e 6420 6974 0a20 2020 2020   expand it.     
-000058c0: 2020 2020 2020 2020 2020 2023 2061 6464             # add
-000058d0: 6564 2074 6f20 6861 6e64 6c65 2077 6865  ed to handle whe
-000058e0: 6e20 6120 7661 6c75 6520 6973 2061 2071  n a value is a q
-000058f0: 6e61 6d65 2e20 2074 6869 7320 7368 6f75  name.  this shou
-00005900: 6c64 2065 7870 616e 6420 6974 2e2e 2e2e  ld expand it....
-00005910: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005920: 2069 6620 2822 3a22 2069 6e20 6f62 6a65   if (":" in obje
-00005930: 6374 7329 2061 6e64 2069 7369 6e73 7461  cts) and isinsta
-00005940: 6e63 6528 6f62 6a65 6374 732c 5552 4952  nce(objects,URIR
-00005950: 6566 293a 0a20 2020 2020 2020 2020 2020  ef):.           
-00005960: 2020 2020 2020 2020 206f 626a 6563 7473           objects
-00005970: 203d 2066 726f 6d5f 6e33 286f 626a 6563   = from_n3(objec
-00005980: 7473 290a 2020 2020 2020 2020 2020 2020  ts).            
-00005990: 2020 2020 2320 6368 6563 6b20 6966 206f      # check if o
-000059a0: 626a 6563 7473 2069 7320 6120 7572 6c20  bjects is a url 
-000059b0: 616e 6420 6966 2073 6f20 7374 6f72 6520  and if so store 
-000059c0: 6974 2061 7320 6120 5552 4952 6566 2065  it as a URIRef e
-000059d0: 6c73 6520 6120 4c69 7465 7261 6c0a 2020  lse a Literal.  
-000059e0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-000059f0: 2028 7661 6c69 6461 746f 7273 2e75 726c   (validators.url
-00005a00: 286f 626a 6563 7473 2929 3a0a 2020 2020  (objects)):.    
-00005a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005a20: 6f62 6a5f 6e6d 2c20 6f62 6a5f 7465 726d  obj_nm, obj_term
-00005a30: 203d 2073 706c 6974 5f75 7269 286f 626a   = split_uri(obj
-00005a40: 6563 7473 290a 2020 2020 2020 2020 2020  ects).          
-00005a50: 2020 2020 2020 2020 2020 6e69 646d 5f6f            nidm_o
-00005a60: 626a 2e61 6464 5f61 7474 7269 6275 7465  bj.add_attribute
-00005a70: 7328 7b70 7265 6469 6361 7465 203a 2049  s({predicate : I
-00005a80: 6465 6e74 6966 6965 7228 6f62 6a65 6374  dentifier(object
-00005a90: 7329 7d29 0a20 2020 2020 2020 2020 2020  s)}).           
-00005aa0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00005ab0: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-00005ac0: 6964 6d5f 6f62 6a2e 6164 645f 6174 7472  idm_obj.add_attr
-00005ad0: 6962 7574 6573 287b 7072 6564 6963 6174  ibutes({predicat
-00005ae0: 6520 3a20 6765 745f 5244 466c 6974 6572  e : get_RDFliter
-00005af0: 616c 5f74 7970 6528 6f62 6a65 6374 7329  al_type(objects)
-00005b00: 7d29 0a0a 2020 2020 2320 6e6f 7720 6669  })..    # now fi
-00005b10: 6e64 2071 7561 6c69 6669 6564 2061 7373  nd qualified ass
-00005b20: 6f63 6961 7469 6f6e 730a 2020 2020 666f  ociations.    fo
-00005b30: 7220 626e 6f64 6520 696e 2072 6466 5f67  r bnode in rdf_g
-00005b40: 7261 7068 2e6f 626a 6563 7473 2873 7562  raph.objects(sub
-00005b50: 6a65 6374 3d73 7562 6a65 6374 5f75 7269  ject=subject_uri
-00005b60: 2c20 7072 6564 6963 6174 653d 436f 6e73  , predicate=Cons
-00005b70: 7461 6e74 732e 5052 4f56 5b27 7175 616c  tants.PROV['qual
-00005b80: 6966 6965 6441 7373 6f63 6961 7469 6f6e  ifiedAssociation
-00005b90: 275d 293a 0a20 2020 2020 2020 2023 2063  ']):.        # c
-00005ba0: 7265 6174 6520 7465 6d70 6f72 6172 7920  reate temporary 
-00005bb0: 7265 736f 7572 6365 2066 6f72 2074 6869  resource for thi
-00005bc0: 7320 626e 6f64 650a 2020 2020 2020 2020  s bnode.        
-00005bd0: 7220 3d20 5265 736f 7572 6365 2872 6466  r = Resource(rdf
-00005be0: 5f67 7261 7068 2c20 626e 6f64 6529 0a20  _graph, bnode). 
-00005bf0: 2020 2020 2020 2023 2067 6574 2074 6865         # get the
-00005c00: 206f 626a 6563 7420 666f 7220 7468 6973   object for this
-00005c10: 2062 6e6f 6465 2077 6974 6820 7072 6564   bnode with pred
-00005c20: 6963 6174 6520 436f 6e73 7461 6e74 732e  icate Constants.
-00005c30: 5052 4f56 5b27 6861 6452 6f6c 6527 5d0a  PROV['hadRole'].
-00005c40: 2020 2020 2020 2020 666f 7220 725f 6f62          for r_ob
-00005c50: 6a20 696e 2072 2e6f 626a 6563 7473 2870  j in r.objects(p
-00005c60: 7265 6469 6361 7465 3d43 6f6e 7374 616e  redicate=Constan
-00005c70: 7473 2e50 524f 565b 2768 6164 526f 6c65  ts.PROV['hadRole
-00005c80: 275d 293a 0a20 2020 2020 2020 2020 2020  ']):.           
-00005c90: 2023 2069 6620 7468 6973 2069 7320 6120   # if this is a 
-00005ca0: 7175 616c 6966 6965 6420 6173 736f 6369  qualified associ
-00005cb0: 6174 696f 6e20 7769 7468 2061 2070 6172  ation with a par
-00005cc0: 7469 6369 7061 6e74 2074 6865 6e20 6372  ticipant then cr
-00005cd0: 6561 7465 2074 6865 2070 726f 763a 5065  eate the prov:Pe
-00005ce0: 7273 6f6e 2061 6765 6e74 0a20 2020 2020  rson agent.     
-00005cf0: 2020 2020 2020 2069 6620 725f 6f62 6a2e         if r_obj.
-00005d00: 6964 656e 7469 6669 6572 203d 3d20 5552  identifier == UR
-00005d10: 4952 6566 2843 6f6e 7374 616e 7473 2e4e  IRef(Constants.N
-00005d20: 4944 4d5f 5041 5254 4943 4950 414e 542e  IDM_PARTICIPANT.
-00005d30: 7572 6929 3a0a 2020 2020 2020 2020 2020  uri):.          
-00005d40: 2020 2020 2020 2320 6765 7420 6964 656e        # get iden
-00005d50: 7469 6669 6572 2066 6f72 2070 726f 763a  tifier for prov:
-00005d60: 6167 656e 7420 7061 7274 206f 6620 7468  agent part of th
-00005d70: 6520 626c 616e 6b20 6e6f 6465 0a20 2020  e blank node.   
-00005d80: 2020 2020 2020 2020 2020 2020 2066 6f72               for
-00005d90: 2061 6765 6e74 5f6f 626a 2069 6e20 722e   agent_obj in r.
-00005da0: 6f62 6a65 6374 7328 7072 6564 6963 6174  objects(predicat
-00005db0: 653d 436f 6e73 7461 6e74 732e 5052 4f56  e=Constants.PROV
-00005dc0: 5b27 6167 656e 7427 5d29 3a0a 2020 2020  ['agent']):.    
+000038e0: 2020 2020 2020 2020 2020 2320 6966 2073            # if s
+000038f0: 7472 2861 6371 5f6d 6f64 616c 6974 7929  tr(acq_modality)
+00003900: 203d 3d20 436f 6e73 7461 6e74 732e 4e49   == Constants.NI
+00003910: 444d 5f41 5353 4553 534d 454e 545f 454e  DM_ASSESSMENT_EN
+00003920: 5449 5459 2e5f 7572 693a 0a20 2020 2020  TITY._uri:.     
+00003930: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003940: 2020 2020 2020 2061 6371 7569 7369 7469         acquisiti
+00003950: 6f6e 203d 2041 7373 6573 736d 656e 7441  on = AssessmentA
+00003960: 6371 7569 7369 7469 6f6e 280a 2020 2020  cquisition(.    
+00003970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003980: 2020 2020 2020 2020 2020 2020 7365 7373              sess
+00003990: 696f 6e3d 7365 7373 696f 6e2c 2075 7569  ion=session, uui
+000039a0: 643d 6163 715f 7575 6964 2c20 6164 645f  d=acq_uuid, add_
+000039b0: 6465 6661 756c 745f 7479 7065 3d46 616c  default_type=Fal
+000039c0: 7365 0a20 2020 2020 2020 2020 2020 2020  se.             
+000039d0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+000039e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000039f0: 2020 2020 2020 2020 2020 2020 2023 2043               # C
+00003a00: 7963 6c65 2074 6872 6f75 6768 2072 656d  ycle through rem
+00003a10: 6169 6e69 6e67 206d 6574 6164 6174 6120  aining metadata 
+00003a20: 666f 7220 6163 7175 6973 6974 696f 6e20  for acquisition 
+00003a30: 6163 7469 7669 7479 2061 6e64 2061 6464  activity and add
+00003a40: 2061 7474 7269 6275 7465 730a 2020 2020   attributes.    
+00003a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003a60: 2020 2020 2020 2020 6164 645f 6d65 7461          add_meta
+00003a70: 6461 7461 5f66 6f72 5f73 7562 6a65 6374  data_for_subject
+00003a80: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00003a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003aa0: 2020 7264 665f 6772 6170 685f 7061 7273    rdf_graph_pars
+00003ab0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
+00003ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003ad0: 2020 2061 6371 2c0a 2020 2020 2020 2020     acq,.        
+00003ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003af0: 2020 2020 2020 2020 7072 6f6a 6563 742e          project.
+00003b00: 6772 6170 682e 6e61 6d65 7370 6163 6573  graph.namespaces
+00003b10: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00003b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003b30: 2020 6163 7175 6973 6974 696f 6e2c 0a20    acquisition,. 
+00003b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003b50: 2020 2020 2020 2020 2020 2029 0a0a 2020             )..  
+00003b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003b70: 2020 2020 2020 2020 2020 2320 616e 6420            # and 
+00003b80: 6164 6420 6163 7175 6973 6974 696f 6e20  add acquisition 
+00003b90: 6f62 6a65 6374 0a20 2020 2020 2020 2020  object.         
+00003ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003bb0: 2020 2061 6371 7569 7369 7469 6f6e 5f6f     acquisition_o
+00003bc0: 626a 203d 2041 7373 6573 736d 656e 744f  bj = AssessmentO
+00003bd0: 626a 6563 7428 0a20 2020 2020 2020 2020  bject(.         
+00003be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003bf0: 2020 2020 2020 2061 6371 7569 7369 7469         acquisiti
+00003c00: 6f6e 3d61 6371 7569 7369 7469 6f6e 2c0a  on=acquisition,.
+00003c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003c30: 7575 6964 3d61 6371 5f6f 626a 5f75 7569  uuid=acq_obj_uui
+00003c40: 642c 0a20 2020 2020 2020 2020 2020 2020  d,.             
+00003c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003c60: 2020 2061 6464 5f64 6566 6175 6c74 5f74     add_default_t
+00003c70: 7970 653d 4661 6c73 652c 0a20 2020 2020  ype=False,.     
+00003c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003c90: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00003ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003cb0: 2020 2020 2061 6371 7569 7369 7469 6f6e       acquisition
+00003cc0: 2e61 6464 5f61 6371 7569 7369 7469 6f6e  .add_acquisition
+00003cd0: 5f6f 626a 6563 7428 6163 7175 6973 6974  _object(acquisit
+00003ce0: 696f 6e5f 6f62 6a29 0a20 2020 2020 2020  ion_obj).       
+00003cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003d00: 2020 2020 2023 2043 7963 6c65 2074 6872       # Cycle thr
+00003d10: 6f75 6768 2072 656d 6169 6e69 6e67 206d  ough remaining m
+00003d20: 6574 6164 6174 6120 666f 7220 6163 7175  etadata for acqu
+00003d30: 6973 6974 696f 6e20 656e 7469 7479 2061  isition entity a
+00003d40: 6e64 2061 6464 2061 7474 7269 6275 7465  nd add attribute
+00003d50: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
+00003d60: 2020 2020 2020 2020 2020 2020 2020 6164                ad
+00003d70: 645f 6d65 7461 6461 7461 5f66 6f72 5f73  d_metadata_for_s
+00003d80: 7562 6a65 6374 280a 2020 2020 2020 2020  ubject(.        
+00003d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003da0: 2020 2020 2020 2020 7264 665f 6772 6170          rdf_grap
+00003db0: 685f 7061 7273 652c 0a20 2020 2020 2020  h_parse,.       
+00003dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003dd0: 2020 2020 2020 2020 2061 6371 5f6f 626a           acq_obj
+00003de0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00003df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003e00: 2020 7072 6f6a 6563 742e 6772 6170 682e    project.graph.
+00003e10: 6e61 6d65 7370 6163 6573 2c0a 2020 2020  namespaces,.    
+00003e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003e30: 2020 2020 2020 2020 2020 2020 6163 7175              acqu
+00003e40: 6973 6974 696f 6e5f 6f62 6a2c 0a20 2020  isition_obj,.   
+00003e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003e60: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+00003e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003e80: 2020 2023 2069 6620 7468 6973 2069 7320     # if this is 
+00003e90: 6120 4457 4920 7363 616e 2074 6865 6e20  a DWI scan then 
+00003ea0: 7765 2063 6f75 6c64 2068 6176 6520 622d  we could have b-
+00003eb0: 7661 6c75 6520 616e 6420 622d 7665 6374  value and b-vect
+00003ec0: 6f72 2066 696c 6573 2061 7373 6f63 6961  or files associa
+00003ed0: 7465 640a 2020 2020 2020 2020 2020 2020  ted.            
+00003ee0: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+00003ef0: 2028 0a20 2020 2020 2020 2020 2020 2020   (.             
+00003f00: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+00003f10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00003f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f30: 2061 6371 5f6f 626a 2c0a 2020 2020 2020   acq_obj,.      
+00003f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f50: 2020 2020 2020 2020 2020 5244 462e 7479            RDF.ty
+00003f60: 7065 2c0a 2020 2020 2020 2020 2020 2020  pe,.            
+00003f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f80: 2020 2020 5552 4952 6566 2843 6f6e 7374      URIRef(Const
+00003f90: 616e 7473 2e4e 4944 4d5f 4d52 495f 4457  ants.NIDM_MRI_DW
+00003fa0: 495f 4256 414c 2e5f 7572 6929 2c0a 2020  I_BVAL._uri),.  
+00003fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003fc0: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+00003fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003fe0: 2020 2020 2020 2020 696e 2072 6466 5f67          in rdf_g
+00003ff0: 7261 7068 0a20 2020 2020 2020 2020 2020  raph.           
+00004000: 2020 2020 2020 2020 2020 2020 2029 206f               ) o
+00004010: 7220 280a 2020 2020 2020 2020 2020 2020  r (.            
+00004020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004030: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00004040: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004050: 2020 6163 715f 6f62 6a2c 0a20 2020 2020    acq_obj,.     
+00004060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004070: 2020 2020 2020 2020 2020 2052 4446 2e74             RDF.t
+00004080: 7970 652c 0a20 2020 2020 2020 2020 2020  ype,.           
+00004090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000040a0: 2020 2020 2055 5249 5265 6628 436f 6e73       URIRef(Cons
+000040b0: 7461 6e74 732e 4e49 444d 5f4d 5249 5f44  tants.NIDM_MRI_D
+000040c0: 5749 5f42 5645 432e 5f75 7269 292c 0a20  WI_BVEC._uri),. 
+000040d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000040e0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+000040f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004100: 2020 2020 2020 2020 2069 6e20 7264 665f           in rdf_
+00004110: 6772 6170 680a 2020 2020 2020 2020 2020  graph.          
+00004120: 2020 2020 2020 2020 2020 2020 2020 293a                ):
+00004130: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00004140: 2020 2020 2020 2020 2020 2020 2023 2049               # I
+00004150: 6620 7468 6973 2069 7320 6120 622d 7661  f this is a b-va
+00004160: 6c75 6573 2066 696c 6576 0a20 2020 2020  lues filev.     
+00004170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004180: 2020 2020 2020 2061 6371 7569 7369 7469         acquisiti
+00004190: 6f6e 203d 2041 6371 7569 7369 7469 6f6e  on = Acquisition
+000041a0: 2873 6573 7369 6f6e 3d73 6573 7369 6f6e  (session=session
+000041b0: 2c20 7575 6964 3d61 6371 5f75 7569 6429  , uuid=acq_uuid)
+000041c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000041d0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+000041e0: 6e6f 7420 7365 7373 696f 6e2e 6163 7175  not session.acqu
+000041f0: 6973 6974 696f 6e5f 6578 6973 7428 6163  isition_exist(ac
+00004200: 715f 7575 6964 293a 0a20 2020 2020 2020  q_uuid):.       
+00004210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004220: 2020 2020 2020 2020 2073 6573 7369 6f6e           session
+00004230: 2e61 6464 5f61 6371 7569 7369 7469 6f6e  .add_acquisition
+00004240: 2861 6371 7569 7369 7469 6f6e 290a 2020  (acquisition).  
+00004250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004260: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+00004270: 4379 636c 6520 7468 726f 7567 6820 7265  Cycle through re
+00004280: 6d61 696e 696e 6720 6d65 7461 6461 7461  maining metadata
+00004290: 2066 6f72 2061 6371 7569 7369 7469 6f6e   for acquisition
+000042a0: 2061 6374 6976 6974 7920 616e 6420 6164   activity and ad
+000042b0: 6420 6174 7472 6962 7574 6573 0a20 2020  d attributes.   
+000042c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000042d0: 2020 2020 2020 2020 2020 2020 2061 6464               add
+000042e0: 5f6d 6574 6164 6174 615f 666f 725f 7375  _metadata_for_su
+000042f0: 626a 6563 7428 0a20 2020 2020 2020 2020  bject(.         
+00004300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004310: 2020 2020 2020 2020 2020 2072 6466 5f67             rdf_g
+00004320: 7261 7068 5f70 6172 7365 2c0a 2020 2020  raph_parse,.    
+00004330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004340: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004350: 6163 712c 0a20 2020 2020 2020 2020 2020  acq,.           
+00004360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004370: 2020 2020 2020 2020 2070 726f 6a65 6374           project
+00004380: 2e67 7261 7068 2e6e 616d 6573 7061 6365  .graph.namespace
+00004390: 732c 0a20 2020 2020 2020 2020 2020 2020  s,.             
+000043a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000043b0: 2020 2020 2020 2061 6371 7569 7369 7469         acquisiti
+000043c0: 6f6e 2c0a 2020 2020 2020 2020 2020 2020  on,.            
+000043d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000043e0: 2020 2020 290a 0a20 2020 2020 2020 2020      )..         
+000043f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004400: 2020 2023 2061 6e64 2061 6464 2061 6371     # and add acq
+00004410: 7569 7369 7469 6f6e 206f 626a 6563 740a  uisition object.
+00004420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004430: 2020 2020 2020 2020 2020 2020 6163 7175              acqu
+00004440: 6973 6974 696f 6e5f 6f62 6a20 3d20 4163  isition_obj = Ac
+00004450: 7175 6973 6974 696f 6e4f 626a 6563 7428  quisitionObject(
+00004460: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00004470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004480: 2061 6371 7569 7369 7469 6f6e 3d61 6371   acquisition=acq
+00004490: 7569 7369 7469 6f6e 2c20 7575 6964 3d61  uisition, uuid=a
+000044a0: 6371 5f6f 626a 5f75 7569 640a 2020 2020  cq_obj_uuid.    
+000044b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000044c0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+000044d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000044e0: 2020 2020 2020 6163 7175 6973 6974 696f        acquisitio
+000044f0: 6e2e 6164 645f 6163 7175 6973 6974 696f  n.add_acquisitio
+00004500: 6e5f 6f62 6a65 6374 2861 6371 7569 7369  n_object(acquisi
+00004510: 7469 6f6e 5f6f 626a 290a 2020 2020 2020  tion_obj).      
+00004520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004530: 2020 2020 2020 2320 4379 636c 6520 7468        # Cycle th
+00004540: 726f 7567 6820 7265 6d61 696e 696e 6720  rough remaining 
+00004550: 6d65 7461 6461 7461 2066 6f72 2061 6371  metadata for acq
+00004560: 7569 7369 7469 6f6e 2065 6e74 6974 7920  uisition entity 
+00004570: 616e 6420 6164 6420 6174 7472 6962 7574  and add attribut
+00004580: 6573 0a20 2020 2020 2020 2020 2020 2020  es.             
+00004590: 2020 2020 2020 2020 2020 2020 2020 2061                 a
+000045a0: 6464 5f6d 6574 6164 6174 615f 666f 725f  dd_metadata_for_
+000045b0: 7375 626a 6563 7428 0a20 2020 2020 2020  subject(.       
+000045c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000045d0: 2020 2020 2020 2020 2072 6466 5f67 7261           rdf_gra
+000045e0: 7068 5f70 6172 7365 2c0a 2020 2020 2020  ph_parse,.      
+000045f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004600: 2020 2020 2020 2020 2020 6163 715f 6f62            acq_ob
+00004610: 6a2c 0a20 2020 2020 2020 2020 2020 2020  j,.             
+00004620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004630: 2020 2070 726f 6a65 6374 2e67 7261 7068     project.graph
+00004640: 2e6e 616d 6573 7061 6365 732c 0a20 2020  .namespaces,.   
+00004650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004660: 2020 2020 2020 2020 2020 2020 2061 6371               acq
+00004670: 7569 7369 7469 6f6e 5f6f 626a 2c0a 2020  uisition_obj,.  
+00004680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004690: 2020 2020 2020 2020 2020 290a 0a20 2020            )..   
+000046a0: 2020 2020 2020 2020 2020 2020 2023 2054               # T
+000046b0: 6869 7320 736b 6970 7320 7264 665f 7479  his skips rdf_ty
+000046c0: 7065 2050 524f 565b 2741 6374 6976 6974  pe PROV['Activit
+000046d0: 7927 5d0a 2020 2020 2020 2020 2020 2020  y'].            
+000046e0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+000046f0: 2020 2020 2020 2020 2020 2020 2020 636f                co
+00004700: 6e74 696e 7565 0a0a 2020 2020 2320 5175  ntinue..    # Qu
+00004710: 6572 7920 6772 6170 6820 666f 7220 6e69  ery graph for ni
+00004720: 646d 3a44 6174 6145 6c65 6d65 6e74 7320  dm:DataElements 
+00004730: 616e 6420 696e 7374 616e 7469 6174 6520  and instantiate 
+00004740: 6120 6e69 646d 3a44 6174 6145 6c65 6d65  a nidm:DataEleme
+00004750: 6e74 2063 6c61 7373 2061 6e64 2061 6464  nt class and add
+00004760: 2074 6865 6d20 746f 2074 6865 2070 726f   them to the pro
+00004770: 6a65 6374 0a20 2020 2071 7565 7279 203d  ject.    query =
+00004780: 2022 2222 0a20 2020 2020 2020 2020 2020   """.           
+00004790: 2020 2020 2070 7265 6669 7820 6e69 646d       prefix nidm
+000047a0: 3a20 3c68 7474 703a 2f2f 7075 726c 2e6f  : <http://purl.o
+000047b0: 7267 2f6e 6964 6173 682f 6e69 646d 233e  rg/nidash/nidm#>
+000047c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000047d0: 2070 7265 6669 7820 7264 6673 3a20 3c68   prefix rdfs: <h
+000047e0: 7474 703a 2f2f 7777 772e 7733 2e6f 7267  ttp://www.w3.org
+000047f0: 2f32 3030 302f 3031 2f72 6466 2d73 6368  /2000/01/rdf-sch
+00004800: 656d 6123 3e0a 2020 2020 2020 2020 2020  ema#>.          
+00004810: 2020 2020 2020 7365 6c65 6374 2064 6973        select dis
+00004820: 7469 6e63 7420 3f75 7569 640a 2020 2020  tinct ?uuid.    
+00004830: 2020 2020 2020 2020 2020 2020 7768 6572              wher
+00004840: 6520 7b0a 2020 2020 2020 2020 2020 2020  e {.            
+00004850: 2020 2020 2020 2020 3f75 7569 6420 612f          ?uuid a/
+00004860: 7264 6673 3a73 7562 436c 6173 734f 662a  rdfs:subClassOf*
+00004870: 206e 6964 6d3a 4461 7461 456c 656d 656e   nidm:DataElemen
+00004880: 7420 2e0a 0a20 2020 2020 2020 2020 2020  t ...           
+00004890: 2020 2020 207d 0a20 2020 2020 2020 2020       }.         
+000048a0: 2020 2020 2020 2022 2222 0a0a 2020 2020         """..    
+000048b0: 2320 6164 6420 616c 6c20 6e69 646d 3a44  # add all nidm:D
+000048c0: 6174 6145 6c65 6d65 6e74 7320 696e 2067  ataElements in g
+000048d0: 7261 7068 0a20 2020 2071 7265 7320 3d20  raph.    qres = 
+000048e0: 7264 665f 6772 6170 685f 7061 7273 652e  rdf_graph_parse.
+000048f0: 7175 6572 7928 7175 6572 7929 0a20 2020  query(query).   
+00004900: 2066 6f72 2072 6f77 2069 6e20 7172 6573   for row in qres
+00004910: 3a0a 2020 2020 2020 2020 7072 696e 7428  :.        print(
+00004920: 726f 7729 0a20 2020 2020 2020 2023 2069  row).        # i
+00004930: 6e73 7461 6e74 6961 7465 2061 2064 6174  nstantiate a dat
+00004940: 6120 656c 656d 656e 7420 636c 6173 7320  a element class 
+00004950: 6173 7369 676e 696e 6720 6974 2074 6865  assigning it the
+00004960: 2065 7869 7374 696e 6720 7575 6964 0a20   existing uuid. 
+00004970: 2020 2020 2020 2064 6520 3d20 4461 7461         de = Data
+00004980: 456c 656d 656e 7428 7072 6f6a 6563 743d  Element(project=
+00004990: 7072 6f6a 6563 742c 2075 7569 643d 726f  project, uuid=ro
+000049a0: 775b 2275 7569 6422 5d2c 2061 6464 5f64  w["uuid"], add_d
+000049b0: 6566 6175 6c74 5f74 7970 653d 4661 6c73  efault_type=Fals
+000049c0: 6529 0a20 2020 2020 2020 2023 2067 6574  e).        # get
+000049d0: 2074 6865 2072 6573 7420 6f66 2074 6865   the rest of the
+000049e0: 2061 7474 7269 6275 7465 7320 666f 7220   attributes for 
+000049f0: 7468 6973 2064 6174 6120 656c 656d 656e  this data elemen
+00004a00: 7420 616e 6420 7374 6f72 650a 2020 2020  t and store.    
+00004a10: 2020 2020 6164 645f 6d65 7461 6461 7461      add_metadata
+00004a20: 5f66 6f72 5f73 7562 6a65 6374 280a 2020  _for_subject(.  
+00004a30: 2020 2020 2020 2020 2020 7264 665f 6772            rdf_gr
+00004a40: 6170 685f 7061 7273 652c 2072 6f77 5b22  aph_parse, row["
+00004a50: 7575 6964 225d 2c20 7072 6f6a 6563 742e  uuid"], project.
+00004a60: 6772 6170 682e 6e61 6d65 7370 6163 6573  graph.namespaces
+00004a70: 2c20 6465 0a20 2020 2020 2020 2029 0a0a  , de.        )..
+00004a80: 2020 2020 2020 2020 2320 6e6f 7720 7765          # now we
+00004a90: 206e 6565 6420 746f 2063 6865 636b 2069   need to check i
+00004aa0: 6620 7468 6572 6520 6172 6520 6c61 6265  f there are labe
+00004ab0: 6c73 2066 6f72 2064 6174 6120 656c 656d  ls for data elem
+00004ac0: 656e 7420 6973 4162 6f75 7420 656e 7472  ent isAbout entr
+00004ad0: 6965 732c 2069 6620 736f 2061 6464 2074  ies, if so add t
+00004ae0: 6865 6d2e 0a20 2020 2020 2020 2071 7565  hem..        que
+00004af0: 7279 3220 3d20 6622 2222 0a0a 2020 2020  ry2 = f"""..    
+00004b00: 2020 2020 2020 2020 2020 2020 7072 6566              pref
+00004b10: 6978 206e 6964 6d3a 203c 6874 7470 3a2f  ix nidm: <http:/
+00004b20: 2f70 7572 6c2e 6f72 672f 6e69 6461 7368  /purl.org/nidash
+00004b30: 2f6e 6964 6d23 3e0a 2020 2020 2020 2020  /nidm#>.        
+00004b40: 2020 2020 2020 2020 7072 6566 6978 2072          prefix r
+00004b50: 6466 733a 203c 6874 7470 3a2f 2f77 7777  dfs: <http://www
+00004b60: 2e77 332e 6f72 672f 3230 3030 2f30 312f  .w3.org/2000/01/
+00004b70: 7264 662d 7363 6865 6d61 233e 0a20 2020  rdf-schema#>.   
+00004b80: 2020 2020 2020 2020 2020 2020 2070 7265               pre
+00004b90: 6669 7820 7264 663a 203c 6874 7470 3a2f  fix rdf: <http:/
+00004ba0: 2f77 7777 2e77 332e 6f72 672f 3139 3939  /www.w3.org/1999
+00004bb0: 2f30 322f 3232 2d72 6466 2d73 796e 7461  /02/22-rdf-synta
+00004bc0: 782d 6e73 233e 0a20 2020 2020 2020 2020  x-ns#>.         
+00004bd0: 2020 2020 2020 2070 7265 6669 7820 7072         prefix pr
+00004be0: 6f76 3a20 3c68 7474 703a 2f2f 7777 772e  ov: <http://www.
+00004bf0: 7733 2e6f 7267 2f6e 732f 7072 6f76 233e  w3.org/ns/prov#>
+00004c00: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00004c10: 2020 7365 6c65 6374 2064 6973 7469 6e63    select distinc
+00004c20: 7420 3f69 6420 3f6c 6162 656c 0a20 2020  t ?id ?label.   
+00004c30: 2020 2020 2020 2020 2020 2020 2077 6865               whe
+00004c40: 7265 207b 7b0a 2020 2020 2020 2020 2020  re {{.          
+00004c50: 2020 2020 2020 2020 2020 3c7b 726f 775b            <{row[
+00004c60: 2275 7569 6422 5d7d 3e20 6e69 646d 3a69  "uuid"]}> nidm:i
+00004c70: 7341 626f 7574 203f 6964 202e 0a0a 2020  sAbout ?id ...  
+00004c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004c90: 2020 3f69 6420 7264 663a 7479 7065 2070    ?id rdf:type p
+00004ca0: 726f 763a 456e 7469 7479 203b 0a20 2020  rov:Entity ;.   
+00004cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004cc0: 2020 2020 2072 6466 733a 6c61 6265 6c20       rdfs:label 
+00004cd0: 3f6c 6162 656c 202e 0a20 2020 2020 2020  ?label ..       
+00004ce0: 2020 2020 2020 2020 207d 7d0a 0a20 2020           }}..   
+00004cf0: 2020 2020 2020 2020 2022 2222 0a20 2020           """.   
+00004d00: 2020 2020 2023 2070 7269 6e74 2871 7565       # print(que
+00004d10: 7279 3229 0a20 2020 2020 2020 2071 7265  ry2).        qre
+00004d20: 7332 203d 2072 6466 5f67 7261 7068 5f70  s2 = rdf_graph_p
+00004d30: 6172 7365 2e71 7565 7279 2871 7565 7279  arse.query(query
+00004d40: 3229 0a0a 2020 2020 2020 2020 2320 6164  2)..        # ad
+00004d50: 6420 7468 6973 2074 7570 6c65 2074 6f20  d this tuple to 
+00004d60: 6772 6170 680a 2020 2020 2020 2020 666f  graph.        fo
+00004d70: 7220 726f 7732 2069 6e20 7172 6573 323a  r row2 in qres2:
+00004d80: 0a20 2020 2020 2020 2020 2020 2070 726f  .            pro
+00004d90: 6a65 6374 2e67 7261 7068 2e65 6e74 6974  ject.graph.entit
+00004da0: 7928 726f 7732 5b30 5d2c 207b 2272 6466  y(row2[0], {"rdf
+00004db0: 733a 6c61 6265 6c22 3a20 726f 7732 5b31  s:label": row2[1
+00004dc0: 5d7d 290a 0a20 2020 2023 2063 6865 636b  ]})..    # check
+00004dd0: 2066 6f72 2044 6572 6976 6174 6976 6573   for Derivatives
+00004de0: 2e0a 2020 2020 2320 5749 503a 2043 7572  ..    # WIP: Cur
+00004df0: 7265 6e74 6c79 2046 534c 2c20 4672 6565  rently FSL, Free
+00004e00: 7375 7266 6572 2c20 616e 6420 414e 5453  surfer, and ANTS
+00004e10: 2074 6f6f 6c73 2061 6464 2074 6865 7365   tools add these
+00004e20: 2064 6572 6976 6174 6976 6573 2061 7320   derivatives as 
+00004e30: 6e69 646d 3a46 5353 7461 7473 436f 6c6c  nidm:FSStatsColl
+00004e40: 6563 7469 6f6e 2c0a 2020 2020 2320 6e69  ection,.    # ni
+00004e50: 646d 3a46 534c 5374 6174 7343 6f6c 6c65  dm:FSLStatsColle
+00004e60: 6374 696f 6e2c 206f 7220 6e69 646d 3a41  ction, or nidm:A
+00004e70: 4e54 5353 7461 7473 436f 6c6c 6563 7469  NTSStatsCollecti
+00004e80: 6f6e 2077 6869 6368 2061 7265 2073 7562  on which are sub
+00004e90: 636c 6173 7365 7320 6f66 206e 6964 6d3a  classes of nidm:
+00004ea0: 4465 7269 7661 7469 7665 730a 2020 2020  Derivatives.    
+00004eb0: 2320 7468 6973 2073 686f 756c 6420 7072  # this should pr
+00004ec0: 6f62 6162 6c79 2062 6520 6578 706c 6963  obably be explic
+00004ed0: 6974 6c79 2069 6e64 6963 6174 6564 2069  itly indicated i
+00004ee0: 6e20 7468 6520 6772 6170 6873 2062 7574  n the graphs but
+00004ef0: 2063 7572 7265 6e74 6c79 2069 736e 2774   currently isn't
+00004f00: 0a0a 2020 2020 2320 5175 6572 7920 6772  ..    # Query gr
+00004f10: 6170 6820 666f 7220 616e 7920 6f66 2074  aph for any of t
+00004f20: 6865 2061 626f 7665 2044 6572 6976 6174  he above Derivat
+00004f30: 6976 6573 0a20 2020 2071 7565 7279 203d  ives.    query =
+00004f40: 2022 2222 0a20 2020 2020 2020 2020 2020   """.           
+00004f50: 2070 7265 6669 7820 6e69 646d 3a20 3c68   prefix nidm: <h
+00004f60: 7474 703a 2f2f 7075 726c 2e6f 7267 2f6e  ttp://purl.org/n
+00004f70: 6964 6173 682f 6e69 646d 233e 0a20 2020  idash/nidm#>.   
+00004f80: 2020 2020 2020 2020 2070 7265 6669 7820           prefix 
+00004f90: 7072 6f76 3a20 3c68 7474 703a 2f2f 7777  prov: <http://ww
+00004fa0: 772e 7733 2e6f 7267 2f6e 732f 7072 6f76  w.w3.org/ns/prov
+00004fb0: 233e 0a20 2020 2020 2020 2020 2020 2073  #>.            s
+00004fc0: 656c 6563 7420 6469 7374 696e 6374 203f  elect distinct ?
+00004fd0: 7575 6964 203f 7061 7265 6e74 5f61 6374  uuid ?parent_act
+00004fe0: 0a20 2020 2020 2020 2020 2020 2077 6865  .            whe
+00004ff0: 7265 207b 0a20 2020 2020 2020 2020 2020  re {.           
+00005000: 2020 2020 207b 3f75 7569 6420 6120 6e69       {?uuid a ni
+00005010: 646d 3a44 6572 6976 6174 6976 6520 3b0a  dm:Derivative ;.
+00005020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005030: 2020 2020 7072 6f76 3a77 6173 4765 6e65      prov:wasGene
+00005040: 7261 7465 6442 7920 3f70 6172 656e 745f  ratedBy ?parent_
+00005050: 6163 7420 2e7d 0a20 2020 2020 2020 2020  act .}.         
+00005060: 2020 2020 2020 2020 2020 2055 4e49 4f4e             UNION
+00005070: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005080: 2020 2020 207b 3f75 7569 6420 6120 6e69       {?uuid a ni
+00005090: 646d 3a46 5353 7461 7473 436f 6c6c 6563  dm:FSStatsCollec
+000050a0: 7469 6f6e 203b 0a20 2020 2020 2020 2020  tion ;.         
+000050b0: 2020 2020 2020 2020 2020 2070 726f 763a             prov:
+000050c0: 7761 7347 656e 6572 6174 6564 4279 203f  wasGeneratedBy ?
+000050d0: 7061 7265 6e74 5f61 6374 202e 7d0a 2020  parent_act .}.  
+000050e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000050f0: 2020 554e 494f 4e0a 2020 2020 2020 2020    UNION.        
+00005100: 2020 2020 2020 2020 2020 2020 7b3f 7575              {?uu
+00005110: 6964 2061 206e 6964 6d3a 4653 4c53 7461  id a nidm:FSLSta
+00005120: 7473 436f 6c6c 6563 7469 6f6e 203b 0a20  tsCollection ;. 
+00005130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005140: 2020 2070 726f 763a 7761 7347 656e 6572     prov:wasGener
+00005150: 6174 6564 4279 203f 7061 7265 6e74 5f61  atedBy ?parent_a
+00005160: 6374 202e 7d0a 2020 2020 2020 2020 2020  ct .}.          
+00005170: 2020 2020 2020 2020 2020 554e 494f 4e0a            UNION.
+00005180: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005190: 2020 2020 7b3f 7575 6964 2061 206e 6964      {?uuid a nid
+000051a0: 6d3a 414e 5453 5374 6174 7343 6f6c 6c65  m:ANTSStatsColle
+000051b0: 6374 696f 6e20 3b0a 2020 2020 2020 2020  ction ;.        
+000051c0: 2020 2020 2020 2020 2020 2020 7072 6f76              prov
+000051d0: 3a77 6173 4765 6e65 7261 7465 6442 7920  :wasGeneratedBy 
+000051e0: 3f70 6172 656e 745f 6163 7420 2e7d 0a20  ?parent_act .}. 
+000051f0: 2020 2020 2020 2020 2020 207d 0a0a 2020             }..  
+00005200: 2020 2020 2020 2222 220a 2020 2020 7172        """.    qr
+00005210: 6573 203d 2072 6466 5f67 7261 7068 5f70  es = rdf_graph_p
+00005220: 6172 7365 2e71 7565 7279 2871 7565 7279  arse.query(query
+00005230: 290a 2020 2020 666f 7220 726f 7720 696e  ).    for row in
+00005240: 2071 7265 733a 0a20 2020 2020 2020 2023   qres:.        #
+00005250: 2070 7574 2074 6869 7320 6865 7265 2073   put this here s
+00005260: 6f20 7468 6520 666f 6c6c 6f77 696e 6720  o the following 
+00005270: 6d61 6b65 7320 6d6f 7265 2073 656e 7365  makes more sense
+00005280: 0a20 2020 2020 2020 2064 6572 6976 6f62  .        derivob
+00005290: 6a5f 7575 6964 203d 2072 6f77 5b22 7575  j_uuid = row["uu
+000052a0: 6964 225d 0a20 2020 2020 2020 2023 2069  id"].        # i
+000052b0: 6620 7468 6520 7061 7265 6e74 2061 6374  f the parent act
+000052c0: 6976 6974 7920 6f66 2074 6865 2064 6572  ivity of the der
+000052d0: 6976 6174 6976 6520 6f62 6a65 6374 2028  ivative object (
+000052e0: 656e 7469 7479 2920 646f 6573 6e27 7420  entity) doesn't 
+000052f0: 6578 6973 7420 696e 2074 6865 2067 7261  exist in the gra
+00005300: 7068 2074 6865 6e20 6372 6561 7465 2069  ph then create i
+00005310: 740a 2020 2020 2020 2020 6966 2072 6f77  t.        if row
+00005320: 5b22 7061 7265 6e74 5f61 6374 225d 206e  ["parent_act"] n
+00005330: 6f74 2069 6e20 7072 6f6a 6563 742e 6465  ot in project.de
+00005340: 7269 7661 7469 7665 733a 0a20 2020 2020  rivatives:.     
+00005350: 2020 2020 2020 2064 6572 6976 5f61 6374         deriv_act
+00005360: 203d 2044 6572 6976 6174 6976 6528 7072   = Derivative(pr
+00005370: 6f6a 6563 743d 7072 6f6a 6563 742c 2075  oject=project, u
+00005380: 7569 643d 726f 775b 2270 6172 656e 745f  uid=row["parent_
+00005390: 6163 7422 5d29 0a20 2020 2020 2020 2020  act"]).         
+000053a0: 2020 2023 2061 6464 2061 6464 6974 696f     # add additio
+000053b0: 6e61 6c20 7472 6970 6573 0a20 2020 2020  nal tripes.     
+000053c0: 2020 2020 2020 2061 6464 5f6d 6574 6164         add_metad
+000053d0: 6174 615f 666f 725f 7375 626a 6563 7428  ata_for_subject(
+000053e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000053f0: 2072 6466 5f67 7261 7068 5f70 6172 7365   rdf_graph_parse
+00005400: 2c20 726f 775b 2270 6172 656e 745f 6163  , row["parent_ac
+00005410: 7422 5d2c 2070 726f 6a65 6374 2e67 7261  t"], project.gra
+00005420: 7068 2e6e 616d 6573 7061 6365 732c 2064  ph.namespaces, d
+00005430: 6572 6976 5f61 6374 0a20 2020 2020 2020  eriv_act.       
+00005440: 2020 2020 2029 0a20 2020 2020 2020 2065       ).        e
+00005450: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00005460: 2066 6f72 2064 2069 6e20 7072 6f6a 6563   for d in projec
+00005470: 742e 6765 745f 6465 7269 7661 7469 7665  t.get_derivative
+00005480: 733a 0a20 2020 2020 2020 2020 2020 2020  s:.             
+00005490: 2020 2069 6620 726f 775b 2270 6172 656e     if row["paren
+000054a0: 745f 6163 7422 5d20 3d3d 2064 2e67 6574  t_act"] == d.get
+000054b0: 5f75 7569 6428 293a 0a20 2020 2020 2020  _uuid():.       
+000054c0: 2020 2020 2020 2020 2020 2020 2064 6572               der
+000054d0: 6976 5f61 6374 203d 2064 0a0a 2020 2020  iv_act = d..    
+000054e0: 2020 2020 2320 6368 6563 6b20 6966 2064      # check if d
+000054f0: 6572 6976 6174 6976 6520 6f62 6a65 6374  erivative object
+00005500: 2061 6c72 6561 6479 2063 7265 6174 6564   already created
+00005510: 2061 6e64 2069 6620 6e6f 7420 6372 6561   and if not crea
+00005520: 7465 2069 740a 2020 2020 2020 2020 2320  te it.        # 
+00005530: 6966 2064 6572 6976 6f62 6a5f 7575 6964  if derivobj_uuid
+00005540: 206e 6f74 2069 6e20 6465 7269 765f 6163   not in deriv_ac
+00005550: 742e 6765 745f 6465 7269 7661 7469 7665  t.get_derivative
+00005560: 5f6f 626a 6563 7473 2829 3a0a 2020 2020  _objects():.    
+00005570: 2020 2020 2320 6e6f 7720 696e 7374 616e      # now instan
+00005580: 7469 6174 6520 7468 6520 6465 7269 7661  tiate the deriva
+00005590: 7469 7665 206f 626a 6563 7420 616e 6420  tive object and 
+000055a0: 6164 6420 616c 6c20 7472 6970 6c65 730a  add all triples.
+000055b0: 2020 2020 2020 2020 6465 7269 766f 626a          derivobj
+000055c0: 203d 2044 6572 6976 6174 6976 654f 626a   = DerivativeObj
+000055d0: 6563 7428 6465 7269 7661 7469 7665 3d64  ect(derivative=d
+000055e0: 6572 6976 5f61 6374 2c20 7575 6964 3d64  eriv_act, uuid=d
+000055f0: 6572 6976 6f62 6a5f 7575 6964 290a 2020  erivobj_uuid).  
+00005600: 2020 2020 2020 6164 645f 6d65 7461 6461        add_metada
+00005610: 7461 5f66 6f72 5f73 7562 6a65 6374 280a  ta_for_subject(.
+00005620: 2020 2020 2020 2020 2020 2020 7264 665f              rdf_
+00005630: 6772 6170 685f 7061 7273 652c 2072 6f77  graph_parse, row
+00005640: 5b22 7575 6964 225d 2c20 7072 6f6a 6563  ["uuid"], projec
+00005650: 742e 6772 6170 682e 6e61 6d65 7370 6163  t.graph.namespac
+00005660: 6573 2c20 6465 7269 766f 626a 0a20 2020  es, derivobj.   
+00005670: 2020 2020 2029 0a0a 2020 2020 7265 7475       )..    retu
+00005680: 726e 2070 726f 6a65 6374 0a0a 0a64 6566  rn project...def
+00005690: 2067 6574 5f52 4446 6c69 7465 7261 6c5f   get_RDFliteral_
+000056a0: 7479 7065 2872 6466 5f6c 6974 6572 616c  type(rdf_literal
+000056b0: 293a 0a20 2020 2069 6620 7264 665f 6c69  ):.    if rdf_li
+000056c0: 7465 7261 6c2e 6461 7461 7479 7065 203d  teral.datatype =
+000056d0: 3d20 5853 445b 2269 6e74 6567 6572 225d  = XSD["integer"]
+000056e0: 3a0a 2020 2020 2020 2020 2320 7265 7475  :.        # retu
+000056f0: 726e 2028 696e 7428 7264 665f 6c69 7465  rn (int(rdf_lite
+00005700: 7261 6c29 290a 2020 2020 2020 2020 7265  ral)).        re
+00005710: 7475 726e 2070 6d2e 4c69 7465 7261 6c28  turn pm.Literal(
+00005720: 7264 665f 6c69 7465 7261 6c2c 2064 6174  rdf_literal, dat
+00005730: 6174 7970 653d 706d 2e58 5344 5b22 696e  atype=pm.XSD["in
+00005740: 7465 6765 7222 5d29 0a20 2020 2065 6c69  teger"]).    eli
+00005750: 6620 7264 665f 6c69 7465 7261 6c2e 6461  f rdf_literal.da
+00005760: 7461 7479 7065 2069 6e20 2858 5344 5b22  tatype in (XSD["
+00005770: 666c 6f61 7422 5d2c 2058 5344 5b22 646f  float"], XSD["do
+00005780: 7562 6c65 225d 293a 0a20 2020 2020 2020  uble"]):.       
+00005790: 2023 2072 6574 7572 6e28 666c 6f61 7428   # return(float(
+000057a0: 7264 665f 6c69 7465 7261 6c29 290a 2020  rdf_literal)).  
+000057b0: 2020 2020 2020 7265 7475 726e 2070 6d2e        return pm.
+000057c0: 4c69 7465 7261 6c28 7264 665f 6c69 7465  Literal(rdf_lite
+000057d0: 7261 6c2c 2064 6174 6174 7970 653d 706d  ral, datatype=pm
+000057e0: 2e58 5344 5b22 666c 6f61 7422 5d29 0a20  .XSD["float"]). 
+000057f0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00005800: 2023 2072 6574 7572 6e20 2873 7472 2872   # return (str(r
+00005810: 6466 5f6c 6974 6572 616c 2929 0a20 2020  df_literal)).   
+00005820: 2020 2020 2072 6574 7572 6e20 706d 2e4c       return pm.L
+00005830: 6974 6572 616c 2872 6466 5f6c 6974 6572  iteral(rdf_liter
+00005840: 616c 2c20 6461 7461 7479 7065 3d70 6d2e  al, datatype=pm.
+00005850: 5853 445b 2273 7472 696e 6722 5d29 0a0a  XSD["string"])..
+00005860: 0a64 6566 2066 696e 645f 696e 5f6e 616d  .def find_in_nam
+00005870: 6573 7061 6365 7328 7365 6172 6368 5f75  espaces(search_u
+00005880: 7269 2c20 6e61 6d65 7370 6163 6573 293a  ri, namespaces):
+00005890: 0a20 2020 2022 2222 0a20 2020 204c 6f6f  .    """.    Loo
+000058a0: 6b73 2074 6872 6f75 6768 206e 616d 6573  ks through names
+000058b0: 7061 6365 7320 666f 7220 7365 6172 6368  paces for search
+000058c0: 5f75 7269 0a20 2020 203a 7265 7475 726e  _uri.    :return
+000058d0: 3a20 5552 4920 6966 2066 6f75 6e64 2065  : URI if found e
+000058e0: 6c73 6520 4661 6c73 650a 2020 2020 2222  lse False.    ""
+000058f0: 220a 0a20 2020 2066 6f72 2075 7269 7320  "..    for uris 
+00005900: 696e 206e 616d 6573 7061 6365 733a 0a20  in namespaces:. 
+00005910: 2020 2020 2020 2069 6620 7572 6973 2e75         if uris.u
+00005920: 7269 203d 3d20 7365 6172 6368 5f75 7269  ri == search_uri
+00005930: 3a0a 2020 2020 2020 2020 2020 2020 7265  :.            re
+00005940: 7475 726e 2075 7269 730a 0a20 2020 2072  turn uris..    r
+00005950: 6574 7572 6e20 4661 6c73 650a 0a0a 6465  eturn False...de
+00005960: 6620 6164 645f 6d65 7461 6461 7461 5f66  f add_metadata_f
+00005970: 6f72 5f73 7562 6a65 6374 2872 6466 5f67  or_subject(rdf_g
+00005980: 7261 7068 2c20 7375 626a 6563 745f 7572  raph, subject_ur
+00005990: 692c 206e 616d 6573 7061 6365 732c 206e  i, namespaces, n
+000059a0: 6964 6d5f 6f62 6a29 3a0a 2020 2020 2222  idm_obj):.    ""
+000059b0: 220a 2020 2020 4379 636c 6573 2074 6872  ".    Cycles thr
+000059c0: 6f75 6768 2074 7269 706c 6573 2066 6f72  ough triples for
+000059d0: 2061 2070 6172 7469 6375 6c61 7220 7375   a particular su
+000059e0: 626a 6563 7420 616e 6420 6164 6473 2074  bject and adds t
+000059f0: 6865 6d20 746f 2074 6865 206e 6964 6d5f  hem to the nidm_
+00005a00: 6f62 6a0a 0a20 2020 203a 7061 7261 6d20  obj..    :param 
+00005a10: 7264 665f 6772 6170 683a 2052 4446 2067  rdf_graph: RDF g
+00005a20: 7261 7068 206f 626a 6563 740a 2020 2020  raph object.    
+00005a30: 3a70 6172 616d 2073 7562 6a65 6374 5f75  :param subject_u
+00005a40: 7269 3a20 5552 4920 6f66 2073 7562 6a65  ri: URI of subje
+00005a50: 6374 2074 6f20 7175 6572 7920 666f 7220  ct to query for 
+00005a60: 6164 6469 7469 6f6e 616c 206d 6574 6164  additional metad
+00005a70: 6174 610a 2020 2020 3a70 6172 616d 206e  ata.    :param n
+00005a80: 616d 6573 7061 6365 733a 204e 616d 6573  amespaces: Names
+00005a90: 7061 6365 7320 696e 2069 6e70 7574 2067  paces in input g
+00005aa0: 7261 7068 0a20 2020 203a 7061 7261 6d20  raph.    :param 
+00005ab0: 6e69 646d 5f6f 626a 3a20 4e49 444d 206f  nidm_obj: NIDM o
+00005ac0: 626a 6563 7420 746f 2061 6464 206d 6574  bject to add met
+00005ad0: 6164 6174 610a 2020 2020 3a72 6574 7572  adata.    :retur
+00005ae0: 6e3a 204e 6f6e 650a 0a20 2020 2022 2222  n: None..    """
+00005af0: 0a20 2020 2023 2043 7963 6c65 2074 6872  .    # Cycle thr
+00005b00: 6f75 6768 2072 656d 6169 6e69 6e67 206d  ough remaining m
+00005b10: 6574 6164 6174 6120 616e 6420 6164 6420  etadata and add 
+00005b20: 6174 7472 6962 7574 6573 0a20 2020 2066  attributes.    f
+00005b30: 6f72 2070 7265 6469 6361 7465 2c20 6f62  or predicate, ob
+00005b40: 6a65 6374 7320 696e 2072 6466 5f67 7261  jects in rdf_gra
+00005b50: 7068 2e70 7265 6469 6361 7465 5f6f 626a  ph.predicate_obj
+00005b60: 6563 7473 2873 7562 6a65 6374 3d73 7562  ects(subject=sub
+00005b70: 6a65 6374 5f75 7269 293a 0a20 2020 2020  ject_uri):.     
+00005b80: 2020 2023 2069 6620 7468 6973 2069 736e     # if this isn
+00005b90: 2774 2061 2071 7561 6c69 6669 6564 2061  't a qualified a
+00005ba0: 7373 6f63 6961 7469 6f6e 2c20 6164 6420  ssociation, add 
+00005bb0: 7472 6970 6c65 730a 2020 2020 2020 2020  triples.        
+00005bc0: 6966 2070 7265 6469 6361 7465 2021 3d20  if predicate != 
+00005bd0: 5552 4952 6566 2843 6f6e 7374 616e 7473  URIRef(Constants
+00005be0: 2e50 524f 565b 2271 7561 6c69 6669 6564  .PROV["qualified
+00005bf0: 4173 736f 6369 6174 696f 6e22 5d29 3a0a  Association"]):.
+00005c00: 2020 2020 2020 2020 2020 2020 2320 6d61              # ma
+00005c10: 6b65 2070 7265 6469 6361 7465 2061 2071  ke predicate a q
+00005c20: 7561 6c69 6669 6564 206e 616d 650a 2020  ualified name.  
+00005c30: 2020 2020 2020 2020 2020 6f62 6a5f 6e6d            obj_nm
+00005c40: 2c20 6f62 6a5f 7465 726d 203d 2073 706c  , obj_term = spl
+00005c50: 6974 5f75 7269 2870 7265 6469 6361 7465  it_uri(predicate
+00005c60: 290a 2020 2020 2020 2020 2020 2020 666f  ).            fo
+00005c70: 756e 645f 7572 6920 3d20 6669 6e64 5f69  und_uri = find_i
+00005c80: 6e5f 6e61 6d65 7370 6163 6573 280a 2020  n_namespaces(.  
+00005c90: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00005ca0: 6172 6368 5f75 7269 3d55 5249 5265 6628  arch_uri=URIRef(
+00005cb0: 6f62 6a5f 6e6d 292c 206e 616d 6573 7061  obj_nm), namespa
+00005cc0: 6365 733d 6e61 6d65 7370 6163 6573 0a20  ces=namespaces. 
+00005cd0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00005ce0: 2020 2020 2020 2020 2023 2069 6620 6f62           # if ob
+00005cf0: 6a5f 6e6d 2069 7320 6e6f 7420 696e 206e  j_nm is not in n
+00005d00: 616d 6573 7061 6365 7320 7468 656e 2069  amespaces then i
+00005d10: 7420 6d75 7374 206a 7573 7420 6265 2070  t must just be p
+00005d20: 6172 7420 6f66 2073 6f6d 6520 5552 4920  art of some URI 
+00005d30: 696e 2074 6865 2074 7269 706c 650a 2020  in the triple.  
+00005d40: 2020 2020 2020 2020 2020 2320 736f 206a            # so j
+00005d50: 7573 7420 6164 6420 6974 2061 7320 6120  ust add it as a 
+00005d60: 7072 6f76 2e49 6465 6e74 6966 6965 720a  prov.Identifier.
+00005d70: 2020 2020 2020 2020 2020 2020 6966 2028              if (
+00005d80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005d90: 2028 6e6f 7420 666f 756e 645f 7572 6929   (not found_uri)
+00005da0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005db0: 2061 6e64 2028 6f62 6a5f 6e6d 2021 3d20   and (obj_nm != 
+00005dc0: 436f 6e73 7461 6e74 732e 5052 4f56 290a  Constants.PROV).
 00005dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005de0: 2320 6368 6563 6b20 6966 2070 6572 736f  # check if perso
-00005df0: 6e20 6578 6973 7473 2061 6c72 6561 6479  n exists already
-00005e00: 2069 6e20 6772 6170 682c 2069 6620 6e6f   in graph, if no
-00005e10: 7420 6372 6561 7465 2069 740a 2020 2020  t create it.    
-00005e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005e30: 6966 2061 6765 6e74 5f6f 626a 2e69 6465  if agent_obj.ide
-00005e40: 6e74 6966 6965 7220 6e6f 7420 696e 206e  ntifier not in n
-00005e50: 6964 6d5f 6f62 6a2e 6772 6170 682e 6765  idm_obj.graph.ge
-00005e60: 745f 7265 636f 7264 7328 293a 0a20 2020  t_records():.   
-00005e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005e80: 2020 2020 2070 6572 736f 6e20 3d20 6e69       person = ni
-00005e90: 646d 5f6f 626a 2e61 6464 5f70 6572 736f  dm_obj.add_perso
-00005ea0: 6e28 7575 6964 3d61 6765 6e74 5f6f 626a  n(uuid=agent_obj
-00005eb0: 2e69 6465 6e74 6966 6965 722c 6164 645f  .identifier,add_
-00005ec0: 6465 6661 756c 745f 7479 7065 3d46 616c  default_type=Fal
-00005ed0: 7365 290a 2020 2020 2020 2020 2020 2020  se).            
-00005ee0: 2020 2020 2020 2020 2020 2020 2320 6164              # ad
-00005ef0: 6420 7265 7374 206f 6620 6d65 6174 6164  d rest of meatad
-00005f00: 6174 6120 6162 6f75 7420 7065 7273 6f6e  ata about person
-00005f10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005f20: 2020 2020 2020 2020 2061 6464 5f6d 6574           add_met
-00005f30: 6164 6174 615f 666f 725f 7375 626a 6563  adata_for_subjec
-00005f40: 7428 7264 665f 6772 6170 683d 7264 665f  t(rdf_graph=rdf_
-00005f50: 6772 6170 682c 2073 7562 6a65 6374 5f75  graph, subject_u
-00005f60: 7269 3d61 6765 6e74 5f6f 626a 2e69 6465  ri=agent_obj.ide
-00005f70: 6e74 6966 6965 722c 0a20 2020 2020 2020  ntifier,.       
-00005f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005fa0: 2020 2020 2020 2020 2020 6e61 6d65 7370            namesp
-00005fb0: 6163 6573 3d6e 616d 6573 7061 6365 732c  aces=namespaces,
-00005fc0: 206e 6964 6d5f 6f62 6a3d 7065 7273 6f6e   nidm_obj=person
-00005fd0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00005fe0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00005ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006000: 2020 2020 2320 7765 206e 6565 6420 7468      # we need th
-00006010: 6520 4e49 444d 206f 626a 6563 7420 6865  e NIDM object he
-00006020: 7265 2077 6974 6820 7575 6964 2061 6765  re with uuid age
-00006030: 6e74 5f6f 626a 2e69 6465 6e74 6966 6965  nt_obj.identifie
-00006040: 7220 616e 6420 7374 6f72 6520 6974 2069  r and store it i
-00006050: 6e20 7065 7273 6f6e 0a20 2020 2020 2020  n person.       
-00006060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006070: 2066 6f72 206f 626a 2069 6e20 6e69 646d   for obj in nidm
-00006080: 5f6f 626a 2e67 7261 7068 2e67 6574 5f72  _obj.graph.get_r
-00006090: 6563 6f72 6473 2829 3a0a 2020 2020 2020  ecords():.      
-000060a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000060b0: 2020 2020 2020 6966 2061 6765 6e74 5f6f        if agent_o
-000060c0: 626a 2e69 6465 6e74 6966 6965 7220 3d3d  bj.identifier ==
-000060d0: 206f 626a 2e69 6465 6e74 6966 6965 723a   obj.identifier:
-000060e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000060f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006100: 2070 6572 736f 6e20 3d20 6f62 6a0a 2020   person = obj.  
-00006110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006120: 2020 2320 6372 6561 7465 2071 7561 6c69    # create quali
-00006130: 6669 6564 206e 616d 6573 2066 6f72 206f  fied names for o
-00006140: 626a 6563 7473 0a20 2020 2020 2020 2020  bjects.         
-00006150: 2020 2020 2020 2020 2020 206f 626a 5f6e             obj_n
-00006160: 6d2c 206f 626a 5f74 6572 6d20 3d20 7370  m, obj_term = sp
-00006170: 6c69 745f 7572 6928 725f 6f62 6a2e 6964  lit_uri(r_obj.id
-00006180: 656e 7469 6669 6572 290a 2020 2020 2020  entifier).      
-00006190: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-000061a0: 756e 645f 7572 6920 3d20 6669 6e64 5f69  und_uri = find_i
-000061b0: 6e5f 6e61 6d65 7370 6163 6573 2873 6561  n_namespaces(sea
-000061c0: 7263 685f 7572 693d 5552 4952 6566 286f  rch_uri=URIRef(o
-000061d0: 626a 5f6e 6d29 2c6e 616d 6573 7061 6365  bj_nm),namespace
-000061e0: 733d 6e61 6d65 7370 6163 6573 290a 2020  s=namespaces).  
-000061f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006200: 2020 2320 6966 206f 626a 5f6e 6d20 6973    # if obj_nm is
-00006210: 206e 6f74 2069 6e20 6e61 6d65 7370 6163   not in namespac
-00006220: 6573 2074 6865 6e20 6974 206d 7573 7420  es then it must 
-00006230: 6a75 7374 2062 6520 7061 7274 206f 6620  just be part of 
-00006240: 736f 6d65 2055 5249 2069 6e20 7468 6520  some URI in the 
-00006250: 7472 6970 6c65 0a20 2020 2020 2020 2020  triple.         
-00006260: 2020 2020 2020 2020 2020 2023 2073 6f20             # so 
-00006270: 6a75 7374 2061 6464 2069 7420 6173 2061  just add it as a
-00006280: 2070 726f 762e 4964 656e 7469 6669 6572   prov.Identifier
+00005de0: 616e 6420 286f 626a 5f6e 6d20 213d 2043  and (obj_nm != C
+00005df0: 6f6e 7374 616e 7473 2e58 5344 290a 2020  onstants.XSD).  
+00005e00: 2020 2020 2020 2020 2020 293a 0a20 2020            ):.   
+00005e10: 2020 2020 2020 2020 2020 2020 2070 7265               pre
+00005e20: 6469 6361 7465 203d 2070 6d2e 5175 616c  dicate = pm.Qual
+00005e30: 6966 6965 644e 616d 6528 0a20 2020 2020  ifiedName(.     
+00005e40: 2020 2020 2020 2020 2020 2020 2020 206e                 n
+00005e50: 616d 6573 7061 6365 3d4e 616d 6573 7061  amespace=Namespa
+00005e60: 6365 2873 7472 2870 7265 6469 6361 7465  ce(str(predicate
+00005e70: 2929 2c20 6c6f 6361 6c70 6172 743d 2222  )), localpart=""
+00005e80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005e90: 2029 0a20 2020 2020 2020 2020 2020 2023   ).            #
+00005ea0: 2065 6c73 6520 6164 6420 6173 2065 7870   else add as exp
+00005eb0: 6c69 6369 7420 7072 6f76 2e51 7561 6c69  licit prov.Quali
+00005ec0: 6669 6564 4e61 6d65 2062 6563 6175 7365  fiedName because
+00005ed0: 2069 7427 7320 6561 7369 6572 2074 6f20   it's easier to 
+00005ee0: 7265 6164 0a20 2020 2020 2020 2020 2020  read.           
+00005ef0: 2023 2065 6c73 653a 0a20 2020 2020 2020   # else:.       
+00005f00: 2020 2020 2023 2020 2020 7072 6564 6963       #    predic
+00005f10: 6174 6520 3d20 4964 656e 7469 6669 6572  ate = Identifier
+00005f20: 2870 7265 6469 6361 7465 290a 2020 2020  (predicate).    
+00005f30: 2020 2020 2020 2020 6966 2028 7661 6c69          if (vali
+00005f40: 6461 746f 7273 2e75 726c 286f 626a 6563  dators.url(objec
+00005f50: 7473 2929 2061 6e64 2028 7072 6564 6963  ts)) and (predic
+00005f60: 6174 6520 213d 2043 6f6e 7374 616e 7473  ate != Constants
+00005f70: 2e50 524f 565b 224c 6f63 6174 696f 6e22  .PROV["Location"
+00005f80: 5d29 3a0a 2020 2020 2020 2020 2020 2020  ]):.            
+00005f90: 2020 2020 2320 7472 7920 746f 2073 706c      # try to spl
+00005fa0: 6974 2074 6865 2055 5249 2074 6f20 6e61  it the URI to na
+00005fb0: 6d65 7370 6163 6520 616e 6420 6c6f 6361  mespace and loca
+00005fc0: 6c20 7061 7274 732c 2069 6620 6661 696c  l parts, if fail
+00005fd0: 7320 6a75 7374 2075 7365 2074 6865 2065  s just use the e
+00005fe0: 6e74 6972 6520 5552 492e 0a20 2020 2020  ntire URI..     
+00005ff0: 2020 2020 2020 2020 2020 2074 7279 3a0a             try:.
+00006000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006010: 2020 2020 2320 6372 6561 7465 2071 7561      # create qua
+00006020: 6c69 6669 6564 206e 616d 6573 2066 6f72  lified names for
+00006030: 206f 626a 6563 7473 0a20 2020 2020 2020   objects.       
+00006040: 2020 2020 2020 2020 2020 2020 206f 626a               obj
+00006050: 5f6e 6d2c 206f 626a 5f74 6572 6d20 3d20  _nm, obj_term = 
+00006060: 7370 6c69 745f 7572 6928 6f62 6a65 6374  split_uri(object
+00006070: 7329 0a0a 2020 2020 2020 2020 2020 2020  s)..            
+00006080: 2020 2020 2020 2020 2320 6164 6465 6420          # added 
+00006090: 6265 6361 7573 6520 5079 4e49 444d 2061  because PyNIDM a
+000060a0: 6765 6e74 2c20 6163 7469 7669 7479 2c20  gent, activity, 
+000060b0: 616e 6420 656e 7469 7479 2063 6c61 7373  and entity class
+000060c0: 6573 2061 6c72 6561 6479 2061 6464 2074  es already add t
+000060d0: 6865 2074 7970 650a 2020 2020 2020 2020  he type.        
+000060e0: 2020 2020 2020 2020 2020 2020 6966 206f              if o
+000060f0: 626a 6563 7473 2069 6e20 280a 2020 2020  bjects in (.    
+00006100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006110: 2020 2020 436f 6e73 7461 6e74 732e 5052      Constants.PR
+00006120: 4f56 5b22 4163 7469 7669 7479 225d 2c0a  OV["Activity"],.
+00006130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006140: 2020 2020 2020 2020 436f 6e73 7461 6e74          Constant
+00006150: 732e 5052 4f56 5b22 4167 656e 7422 5d2c  s.PROV["Agent"],
+00006160: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00006170: 2020 2020 2020 2020 2043 6f6e 7374 616e           Constan
+00006180: 7473 2e50 524f 565b 2245 6e74 6974 7922  ts.PROV["Entity"
+00006190: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+000061a0: 2020 2020 2020 2029 3a0a 2020 2020 2020         ):.      
+000061b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000061c0: 2020 636f 6e74 696e 7565 0a20 2020 2020    continue.     
+000061d0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+000061e0: 2073 7065 6369 616c 2063 6173 6520 6966   special case if
+000061f0: 206f 626a 5f6e 6d20 6973 2070 726f 762c   obj_nm is prov,
+00006200: 2078 7364 2c20 6f72 206e 6964 6d20 6e61   xsd, or nidm na
+00006210: 6d65 7370 6163 6573 2e20 2054 6865 7365  mespaces.  These
+00006220: 2061 7265 2061 6464 6564 0a20 2020 2020   are added.     
+00006230: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+00006240: 2061 7574 6f6d 6174 6963 616c 6c79 2062   automatically b
+00006250: 7920 7072 6f76 446f 6375 6d65 6e74 2073  y provDocument s
+00006260: 6f20 7468 6579 2061 7265 6e27 7420 6163  o they aren't ac
+00006270: 6365 7373 6962 6c65 2076 6961 2074 6865  cessible via the
+00006280: 206e 616d 6573 7061 6365 7320 6c69 7374   namespaces list
 00006290: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000062a0: 2020 2020 2069 6620 6e6f 7420 666f 756e       if not foun
-000062b0: 645f 7572 693a 0a20 2020 2020 2020 2020  d_uri:.         
-000062c0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-000062d0: 6e69 646d 5f6f 626a 2e61 6464 5f71 7561  nidm_obj.add_qua
-000062e0: 6c69 6669 6564 5f61 7373 6f63 6961 7469  lified_associati
-000062f0: 6f6e 2870 6572 736f 6e3d 7065 7273 6f6e  on(person=person
-00006300: 2c20 726f 6c65 3d70 6d2e 4964 656e 7469  , role=pm.Identi
-00006310: 6669 6572 2872 5f6f 626a 2e69 6465 6e74  fier(r_obj.ident
-00006320: 6966 6965 7229 290a 2020 2020 2020 2020  ifier)).        
+000062a0: 2020 2020 2023 2073 6f20 7765 2063 6865       # so we che
+000062b0: 636b 2065 7870 6c69 6369 746c 7920 6865  ck explicitly he
+000062c0: 7265 0a20 2020 2020 2020 2020 2020 2020  re.             
+000062d0: 2020 2020 2020 2069 6620 6f62 6a5f 6e6d         if obj_nm
+000062e0: 203d 3d20 7374 7228 436f 6e73 7461 6e74   == str(Constant
+000062f0: 732e 5052 4f56 293a 0a20 2020 2020 2020  s.PROV):.       
+00006300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006310: 206e 6964 6d5f 6f62 6a2e 6164 645f 6174   nidm_obj.add_at
+00006320: 7472 6962 7574 6573 280a 2020 2020 2020  tributes(.      
 00006330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006340: 6e69 646d 5f6f 626a 2e61 6464 5f71 7561  nidm_obj.add_qua
-00006350: 6c69 6669 6564 5f61 7373 6f63 6961 7469  lified_associati
-00006360: 6f6e 2870 6572 736f 6e3d 7065 7273 6f6e  on(person=person
-00006370: 2c20 726f 6c65 3d70 6d2e 5175 616c 6966  , role=pm.Qualif
-00006380: 6965 644e 616d 6528 4e61 6d65 7370 6163  iedName(Namespac
-00006390: 6528 6f62 6a5f 6e6d 292c 6f62 6a5f 7465  e(obj_nm),obj_te
-000063a0: 726d 2929 0a20 2020 2020 2020 2020 2020  rm)).           
-000063b0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-000063c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000063d0: 2020 2020 2020 206e 6964 6d5f 6f62 6a2e         nidm_obj.
-000063e0: 6164 645f 7175 616c 6966 6965 645f 6173  add_qualified_as
-000063f0: 736f 6369 6174 696f 6e28 7065 7273 6f6e  sociation(person
-00006400: 3d70 6572 736f 6e2c 2072 6f6c 653d 706d  =person, role=pm
-00006410: 2e51 7561 6c69 6669 6564 4e61 6d65 2866  .QualifiedName(f
-00006420: 6f75 6e64 5f75 7269 2c20 6f62 6a5f 7465  ound_uri, obj_te
-00006430: 726d 2929 0a0a 2020 2020 2020 2020 2020  rm))..          
-00006440: 2020 2320 656c 7365 2069 7427 7320 616e    # else it's an
-00006450: 2061 7373 6f63 6961 7469 6f6e 2077 6974   association wit
-00006460: 6820 616e 6f74 6865 7220 6167 656e 7420  h another agent 
-00006470: 7768 6963 6820 6973 6e27 7420 6120 7061  which isn't a pa
-00006480: 7274 6963 6970 616e 740a 2020 2020 2020  rticipant.      
-00006490: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-000064a0: 2020 2020 2020 2020 2020 2020 2320 6765              # ge
-000064b0: 7420 6964 656e 7469 6669 6572 2066 6f72  t identifier for
-000064c0: 2074 6865 2070 726f 763a 6167 656e 7420   the prov:agent 
-000064d0: 7061 7274 206f 6620 7468 6520 626c 616e  part of the blan
-000064e0: 6b20 6e6f 6465 0a20 2020 2020 2020 2020  k node.         
-000064f0: 2020 2020 2020 2066 6f72 2061 6765 6e74         for agent
-00006500: 5f6f 626a 2069 6e20 722e 6f62 6a65 6374  _obj in r.object
-00006510: 7328 7072 6564 6963 6174 653d 436f 6e73  s(predicate=Cons
-00006520: 7461 6e74 732e 5052 4f56 5b27 6167 656e  tants.PROV['agen
-00006530: 7427 5d29 3a0a 2020 2020 2020 2020 2020  t']):.          
-00006540: 2020 2020 2020 2020 2020 2320 6368 6563            # chec
-00006550: 6b20 6966 2074 6865 2061 6765 6e74 2065  k if the agent e
-00006560: 7869 7374 7320 696e 2074 6865 2067 7261  xists in the gra
-00006570: 7068 2065 6c73 6520 6164 6420 6974 0a20  ph else add it. 
-00006580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006590: 2020 2069 6620 6167 656e 745f 6f62 6a2e     if agent_obj.
-000065a0: 6964 656e 7469 6669 6572 206e 6f74 2069  identifier not i
-000065b0: 6e20 6e69 646d 5f6f 626a 2e67 7261 7068  n nidm_obj.graph
-000065c0: 2e67 6574 5f72 6563 6f72 6473 2829 3a0a  .get_records():.
+00006340: 2020 2020 2020 7b70 7265 6469 6361 7465        {predicate
+00006350: 3a20 5175 616c 6966 6965 644e 616d 6528  : QualifiedName(
+00006360: 436f 6e73 7461 6e74 732e 5052 4f56 5b6f  Constants.PROV[o
+00006370: 626a 5f74 6572 6d5d 297d 0a20 2020 2020  bj_term])}.     
+00006380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006390: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+000063a0: 2020 2020 2020 2020 2065 6c69 6620 6f62           elif ob
+000063b0: 6a5f 6e6d 203d 3d20 7374 7228 436f 6e73  j_nm == str(Cons
+000063c0: 7461 6e74 732e 4e49 444d 293a 0a20 2020  tants.NIDM):.   
+000063d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000063e0: 2020 2020 206e 6964 6d5f 6f62 6a2e 6164       nidm_obj.ad
+000063f0: 645f 6174 7472 6962 7574 6573 280a 2020  d_attributes(.  
+00006400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006410: 2020 2020 2020 2020 2020 7b70 7265 6469            {predi
+00006420: 6361 7465 3a20 5175 616c 6966 6965 644e  cate: QualifiedN
+00006430: 616d 6528 436f 6e73 7461 6e74 732e 4e49  ame(Constants.NI
+00006440: 444d 5b6f 626a 5f74 6572 6d5d 297d 0a20  DM[obj_term])}. 
+00006450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006460: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00006470: 2020 2020 2020 2020 2020 2020 2065 6c73               els
+00006480: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00006490: 2020 2020 2020 2020 2020 2066 6f75 6e64             found
+000064a0: 5f75 7269 203d 2066 696e 645f 696e 5f6e  _uri = find_in_n
+000064b0: 616d 6573 7061 6365 7328 0a20 2020 2020  amespaces(.     
+000064c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000064d0: 2020 2020 2020 2073 6561 7263 685f 7572         search_ur
+000064e0: 693d 5552 4952 6566 286f 626a 5f6e 6d29  i=URIRef(obj_nm)
+000064f0: 2c20 6e61 6d65 7370 6163 6573 3d6e 616d  , namespaces=nam
+00006500: 6573 7061 6365 730a 2020 2020 2020 2020  espaces.        
+00006510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006520: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00006530: 2020 2020 2020 2020 2020 2320 6966 206f            # if o
+00006540: 626a 5f6e 6d20 6973 206e 6f74 2069 6e20  bj_nm is not in 
+00006550: 6e61 6d65 7370 6163 6573 2074 6865 6e20  namespaces then 
+00006560: 6974 206d 7573 7420 6a75 7374 2062 6520  it must just be 
+00006570: 7061 7274 206f 6620 736f 6d65 2055 5249  part of some URI
+00006580: 2069 6e20 7468 6520 7472 6970 6c65 0a20   in the triple. 
+00006590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000065a0: 2020 2020 2020 2023 2073 6f20 6a75 7374         # so just
+000065b0: 2061 6464 2069 7420 6173 2061 2070 726f   add it as a pro
+000065c0: 762e 4964 656e 7469 6669 6572 0a20 2020  v.Identifier.   
 000065d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000065e0: 2020 2020 2020 2020 6765 6e65 7269 635f          generic_
-000065f0: 6167 656e 7420 3d20 6e69 646d 5f6f 626a  agent = nidm_obj
-00006600: 2e67 7261 7068 2e61 6765 6e74 2869 6465  .graph.agent(ide
-00006610: 6e74 6966 6965 723d 6167 656e 745f 6f62  ntifier=agent_ob
-00006620: 6a2e 6964 656e 7469 6669 6572 290a 0a20  j.identifier).. 
-00006630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006640: 2020 2020 2020 2023 2061 6464 2072 6573         # add res
-00006650: 7420 6f66 206d 6561 7461 6461 7461 2061  t of meatadata a
-00006660: 626f 7574 2074 6865 2061 6765 6e74 0a20  bout the agent. 
-00006670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006680: 2020 2020 2020 2061 6464 5f6d 6574 6164         add_metad
-00006690: 6174 615f 666f 725f 7375 626a 6563 7428  ata_for_subject(
-000066a0: 7264 665f 6772 6170 683d 7264 665f 6772  rdf_graph=rdf_gr
-000066b0: 6170 682c 2073 7562 6a65 6374 5f75 7269  aph, subject_uri
-000066c0: 3d61 6765 6e74 5f6f 626a 2e69 6465 6e74  =agent_obj.ident
-000066d0: 6966 6965 722c 0a20 2020 2020 2020 2020  ifier,.         
-000066e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000066f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006700: 2020 2020 2020 2020 6e61 6d65 7370 6163          namespac
-00006710: 6573 3d6e 616d 6573 7061 6365 732c 206e  es=namespaces, n
-00006720: 6964 6d5f 6f62 6a3d 6765 6e65 7269 635f  idm_obj=generic_
-00006730: 6167 656e 7429 0a20 2020 2020 2020 2020  agent).         
-00006740: 2020 2020 2020 2020 2020 2023 2074 7279             # try
-00006750: 2061 6e64 2073 706c 6974 2075 7269 2069   and split uri i
-00006760: 6e74 6f20 6e61 6d65 7370 6163 6520 616e  nto namespace an
-00006770: 6420 6c6f 6361 6c20 7061 7274 732c 2069  d local parts, i
-00006780: 6620 6661 696c 7320 6a75 7374 2075 7365  f fails just use
-00006790: 2065 6e74 6972 6520 5552 490a 2020 2020   entire URI.    
-000067a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000067b0: 7472 793a 0a20 2020 2020 2020 2020 2020  try:.           
-000067c0: 2020 2020 2020 2020 2020 2020 2023 2063               # c
-000067d0: 7265 6174 6520 7175 616c 6966 6965 6420  reate qualified 
-000067e0: 6e61 6d65 7320 666f 7220 6f62 6a65 6374  names for object
-000067f0: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
-00006800: 2020 2020 2020 2020 2020 6f62 6a5f 6e6d            obj_nm
-00006810: 2c20 6f62 6a5f 7465 726d 203d 2073 706c  , obj_term = spl
-00006820: 6974 5f75 7269 2872 5f6f 626a 2e69 6465  it_uri(r_obj.ide
-00006830: 6e74 6966 6965 7229 0a0a 2020 2020 2020  ntifier)..      
-00006840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006850: 2020 666f 756e 645f 7572 6920 3d20 6669    found_uri = fi
-00006860: 6e64 5f69 6e5f 6e61 6d65 7370 6163 6573  nd_in_namespaces
-00006870: 2873 6561 7263 685f 7572 693d 5552 4952  (search_uri=URIR
-00006880: 6566 286f 626a 5f6e 6d29 2c20 6e61 6d65  ef(obj_nm), name
-00006890: 7370 6163 6573 3d6e 616d 6573 7061 6365  spaces=namespace
-000068a0: 7329 0a20 2020 2020 2020 2020 2020 2020  s).             
-000068b0: 2020 2020 2020 2020 2020 2023 2069 6620             # if 
-000068c0: 6f62 6a5f 6e6d 2069 7320 6e6f 7420 696e  obj_nm is not in
-000068d0: 206e 616d 6573 7061 6365 7320 7468 656e   namespaces then
-000068e0: 2069 7420 6d75 7374 206a 7573 7420 6265   it must just be
-000068f0: 2070 6172 7420 6f66 2073 6f6d 6520 5552   part of some UR
-00006900: 4920 696e 2074 6865 2074 7269 706c 650a  I in the triple.
-00006910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006920: 2020 2020 2020 2020 2320 736f 206a 7573          # so jus
-00006930: 7420 6164 6420 6974 2061 7320 6120 7072  t add it as a pr
-00006940: 6f76 2e49 6465 6e74 6966 6965 720a 2020  ov.Identifier.  
-00006950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006960: 2020 2020 2020 6966 206e 6f74 2066 6f75        if not fou
-00006970: 6e64 5f75 7269 3a0a 0a20 2020 2020 2020  nd_uri:..       
-00006980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006990: 2020 2020 206e 6964 6d5f 6f62 6a2e 6164       nidm_obj.ad
-000069a0: 645f 7175 616c 6966 6965 645f 6173 736f  d_qualified_asso
-000069b0: 6369 6174 696f 6e28 7065 7273 6f6e 3d67  ciation(person=g
-000069c0: 656e 6572 6963 5f61 6765 6e74 2c0a 2020  eneric_agent,.  
-000069d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000069e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000069f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006a00: 2020 2020 2020 2020 2020 2020 2072 6f6c               rol
-00006a10: 653d 706d 2e51 7561 6c69 6669 6564 4e61  e=pm.QualifiedNa
-00006a20: 6d65 284e 616d 6573 7061 6365 286f 626a  me(Namespace(obj
-00006a30: 5f6e 6d29 2c6f 626a 5f74 6572 6d29 290a  _nm),obj_term)).
-00006a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006a50: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00006a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006a70: 2020 2020 2020 2020 2020 6e69 646d 5f6f            nidm_o
-00006a80: 626a 2e61 6464 5f71 7561 6c69 6669 6564  bj.add_qualified
-00006a90: 5f61 7373 6f63 6961 7469 6f6e 2870 6572  _association(per
-00006aa0: 736f 6e3d 6765 6e65 7269 635f 6167 656e  son=generic_agen
-00006ab0: 742c 0a20 2020 2020 2020 2020 2020 2020  t,.             
-00006ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006af0: 2020 726f 6c65 3d70 6d2e 5175 616c 6966    role=pm.Qualif
-00006b00: 6965 644e 616d 6528 666f 756e 645f 7572  iedName(found_ur
-00006b10: 692c 206f 626a 5f74 6572 6d29 290a 0a20  i, obj_term)).. 
-00006b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006b30: 2020 2065 7863 6570 743a 0a20 2020 2020     except:.     
-00006b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006b50: 2020 206e 6964 6d5f 6f62 6a2e 6164 645f     nidm_obj.add_
-00006b60: 7175 616c 6966 6965 645f 6173 736f 6369  qualified_associ
-00006b70: 6174 696f 6e28 7065 7273 6f6e 3d67 656e  ation(person=gen
-00006b80: 6572 6963 5f61 6765 6e74 2c20 726f 6c65  eric_agent, role
-00006b90: 3d70 6d2e 5175 616c 6966 6965 644e 616d  =pm.QualifiedNam
-00006ba0: 6528 4e61 6d65 7370 6163 6528 725f 6f62  e(Namespace(r_ob
-00006bb0: 6a2e 6964 656e 7469 6669 6572 292c 2222  j.identifier),""
-00006bc0: 2929 0a0a 0a64 6566 2051 7565 7279 5363  ))...def QuerySc
-00006bd0: 6943 7275 6e63 6845 6c61 7374 6963 5365  iCrunchElasticSe
-00006be0: 6172 6368 2871 7565 7279 5f73 7472 696e  arch(query_strin
-00006bf0: 672c 7479 7065 3d27 6364 6527 2c20 616e  g,type='cde', an
-00006c00: 7363 6573 746f 7273 3d54 7275 6529 3a0a  scestors=True):.
-00006c10: 2020 2020 2727 270a 2020 2020 5468 6973      '''.    This
-00006c20: 2066 756e 6374 696f 6e20 7769 6c6c 2070   function will p
-00006c30: 6572 666f 726d 2061 6e20 656c 6173 7469  erform an elasti
-00006c40: 6320 7365 6172 6368 2069 6e20 5363 6943  c search in SciC
-00006c50: 7275 6e63 6820 6f6e 2074 6865 205b 7175  runch on the [qu
-00006c60: 6572 795f 7374 7269 6e67 5d20 7573 696e  ery_string] usin
-00006c70: 6720 4150 4920 5b6b 6579 5d20 616e 6420  g API [key] and 
-00006c80: 7265 7475 726e 2074 6865 206a 736f 6e20  return the json 
-00006c90: 7061 636b 6167 652e 0a20 2020 203a 7061  package..    :pa
-00006ca0: 7261 6d20 6b65 793a 2041 5049 206b 6579  ram key: API key
-00006cb0: 2066 726f 6d20 7363 6920 6372 756e 6368   from sci crunch
-00006cc0: 0a20 2020 203a 7061 7261 6d20 7175 6572  .    :param quer
-00006cd0: 795f 7374 7269 6e67 3a20 6172 6269 7472  y_string: arbitr
-00006ce0: 6172 7920 7374 7269 6e67 2074 6f20 7365  ary string to se
-00006cf0: 6172 6368 2066 6f72 2074 6572 6d73 0a20  arch for terms. 
-00006d00: 2020 203a 7061 7261 6d20 7479 7065 3a20     :param type: 
-00006d10: 6465 6661 756c 7420 6973 2027 4344 4527  default is 'CDE'
-00006d20: 2e20 2041 6363 6570 7469 626c 6520 7661  .  Acceptible va
-00006d30: 6c75 6573 2061 7265 2027 6364 6527 206f  lues are 'cde' o
-00006d40: 7220 2770 6465 272e 0a20 2020 203a 7265  r 'pde'..    :re
-00006d50: 7475 726e 3a20 6a73 6f6e 2064 6f63 756d  turn: json docum
-00006d60: 656e 7420 6f66 2072 6573 756c 7473 2066  ent of results f
-00006d70: 6f72 6d20 656c 6173 7469 6320 7365 6172  orm elastic sear
-00006d80: 6368 0a20 2020 2027 2727 0a0a 2020 2020  ch.    '''..    
-00006d90: 234e 6f74 652c 206f 6e63 6520 4a65 6666  #Note, once Jeff
-00006da0: 2047 7265 7468 652c 2065 7420 616c 2e20   Grethe, et al. 
-00006db0: 6769 7665 2075 7320 7468 6520 7175 6572  give us the quer
-00006dc0: 7920 746f 2067 6574 2074 6865 2052 6570  y to get the Rep
-00006dd0: 726f 4e69 6d20 2274 6167 6765 6422 2061  roNim "tagged" a
-00006de0: 6e63 6573 746f 7273 2071 7565 7279 2077  ncestors query w
-00006df0: 6527 6420 646f 2074 6861 7420 7175 6572  e'd do that quer
-00006e00: 7920 6669 7273 7420 616e 6420 7265 706c  y first and repl
-00006e10: 6163 650a 2020 2020 2374 6865 2022 616e  ace.    #the "an
-00006e20: 6365 7374 6f72 732e 696c 7822 2070 6172  cestors.ilx" par
-00006e30: 616d 6574 6572 2069 6e20 7468 6520 7175  ameter in the qu
-00006e40: 6572 7920 6461 7461 2070 6163 6b61 6765  ery data package
-00006e50: 2062 656c 6f77 2077 6974 6820 6e65 7720   below with new 
-00006e60: 696e 7465 726c 6578 2049 4473 2e2e 2e0a  interlex IDs....
-00006e70: 2020 2020 2374 6869 7320 616c 6c6f 7773      #this allows
-00006e80: 2069 6e74 6572 6c65 7820 6465 7665 6c6f   interlex develo
-00006e90: 7065 7273 2074 6f20 6479 6e61 6d69 6361  pers to dynamica
-00006ea0: 6c6c 2063 6861 6e67 6520 7468 6520 616e  ll change the an
-00006eb0: 6365 7374 6f72 2074 6572 6d73 2074 6861  cestor terms tha
-00006ec0: 7420 6172 6520 7061 7274 206f 6620 7468  t are part of th
-00006ed0: 6520 5265 7072 6f4e 696d 2074 6572 6d20  e ReproNim term 
-00006ee0: 7472 6f76 6520 616e 6420 6861 7665 2074  trove and have t
-00006ef0: 6869 730a 2020 2020 2371 7565 7279 2075  his.    #query u
-00006f00: 7365 2074 6861 7420 6e65 7720 696e 666f  se that new info
-00006f10: 726d 6174 696f 6e2e 2e2e 2e0a 0a20 2020  rmation......   
-00006f20: 2074 7279 3a0a 2020 2020 2020 2020 6f73   try:.        os
-00006f30: 2e65 6e76 6972 6f6e 5b22 494e 5445 524c  .environ["INTERL
-00006f40: 4558 5f41 5049 5f4b 4559 225d 0a20 2020  EX_API_KEY"].   
-00006f50: 2065 7863 6570 7420 4b65 7945 7272 6f72   except KeyError
-00006f60: 3a0a 2020 2020 2020 2020 7072 696e 7428  :.        print(
-00006f70: 2250 6c65 6173 6520 7365 7420 7468 6520  "Please set the 
-00006f80: 656e 7669 726f 6e6d 656e 7420 7661 7269  environment vari
-00006f90: 6162 6c65 2049 4e54 4552 4c45 585f 4150  able INTERLEX_AP
-00006fa0: 495f 4b45 5922 290a 2020 2020 2020 2020  I_KEY").        
-00006fb0: 7379 732e 6578 6974 2831 290a 2020 2020  sys.exit(1).    
-00006fc0: 2341 6464 2063 6865 636b 2066 6f72 2069  #Add check for i
-00006fd0: 6e74 6572 6e65 7420 636f 6e6e 6e65 6374  nternet connnect
-00006fe0: 696f 6e2c 2069 6620 6e6f 7420 7468 656e  ion, if not then
-00006ff0: 2073 6b69 7020 7468 6973 2071 7565 7279   skip this query
-00007000: 2e2e 2e72 6574 7572 6e20 656d 7074 7920  ...return empty 
-00007010: 6469 6374 696f 6e61 7279 0a0a 0a20 2020  dictionary...   
-00007020: 2068 6561 6465 7273 203d 207b 0a20 2020   headers = {.   
-00007030: 2020 2020 2027 436f 6e74 656e 742d 5479       'Content-Ty
-00007040: 7065 273a 2027 6170 706c 6963 6174 696f  pe': 'applicatio
-00007050: 6e2f 6a73 6f6e 272c 0a20 2020 207d 0a0a  n/json',.    }..
-00007060: 2020 2020 7061 7261 6d73 203d 2028 0a20      params = (. 
-00007070: 2020 2020 2020 2028 276b 6579 272c 206f         ('key', o
-00007080: 732e 656e 7669 726f 6e5b 2249 4e54 4552  s.environ["INTER
-00007090: 4c45 585f 4150 495f 4b45 5922 5d29 2c0a  LEX_API_KEY"]),.
-000070a0: 2020 2020 290a 2020 2020 6966 2074 7970      ).    if typ
-000070b0: 6520 3d3d 2027 6364 6527 3a0a 2020 2020  e == 'cde':.    
-000070c0: 2020 2020 6966 2061 6e73 6365 7374 6f72      if anscestor
-000070d0: 733a 0a20 2020 2020 2020 2020 2020 2064  s:.            d
-000070e0: 6174 6120 3d20 275c 6e7b 5c6e 2020 2271  ata = '\n{\n  "q
-000070f0: 7565 7279 223a 207b 5c6e 2020 2020 2262  uery": {\n    "b
-00007100: 6f6f 6c22 3a20 7b5c 6e20 2020 2020 2020  ool": {\n       
-00007110: 226d 7573 7422 203a 205b 5c6e 2020 2020  "must" : [\n    
-00007120: 2020 207b 2020 2274 6572 6d22 203a 207b     {  "term" : {
-00007130: 2022 7479 7065 2220 3a20 2263 6465 2220   "type" : "cde" 
-00007140: 7d20 7d2c 5c6e 2020 2020 2020 207b 2022  } },\n       { "
-00007150: 7465 726d 7322 203a 207b 2022 616e 6365  terms" : { "ance
-00007160: 7374 6f72 732e 696c 7822 203a 205b 2269  stors.ilx" : ["i
-00007170: 6c78 5f30 3131 3530 3636 2220 2c20 2269  lx_0115066" , "i
-00007180: 6c78 5f30 3130 3332 3130 222c 2022 696c  lx_0103210", "il
-00007190: 785f 3031 3135 3037 3222 2c20 2269 6c78  x_0115072", "ilx
-000071a0: 5f30 3131 3530 3730 225d 207d 207d 2c5c  _0115070"] } },\
-000071b0: 6e20 2020 2020 2020 7b20 226d 756c 7469  n       { "multi
-000071c0: 5f6d 6174 6368 2220 3a20 7b5c 6e20 2020  _match" : {\n   
-000071d0: 2020 2020 2020 2271 7565 7279 223a 2020        "query":  
-000071e0: 2020 2225 7322 2c20 5c6e 2020 2020 2020    "%s", \n      
-000071f0: 2020 2022 6669 656c 6473 223a 205b 2022     "fields": [ "
-00007200: 6c61 6265 6c22 2c20 2264 6566 696e 6974  label", "definit
-00007210: 696f 6e22 205d 205c 6e20 2020 2020 2020  ion" ] \n       
-00007220: 7d20 7d5c 6e5d 5c6e 2020 2020 7d5c 6e20  } }\n]\n    }\n 
-00007230: 207d 5c6e 7d5c 6e27 2025 7175 6572 795f   }\n}\n' %query_
-00007240: 7374 7269 6e67 0a20 2020 2020 2020 2065  string.        e
-00007250: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00007260: 2064 6174 6120 3d20 275c 6e7b 5c6e 2020   data = '\n{\n  
-00007270: 2271 7565 7279 223a 207b 5c6e 2020 2020  "query": {\n    
-00007280: 2262 6f6f 6c22 3a20 7b5c 6e20 2020 2020  "bool": {\n     
-00007290: 2020 226d 7573 7422 203a 205b 5c6e 2020    "must" : [\n  
-000072a0: 2020 2020 207b 2020 2274 6572 6d22 203a       {  "term" :
-000072b0: 207b 2022 7479 7065 2220 3a20 2263 6465   { "type" : "cde
-000072c0: 2220 7d20 7d2c 5c6e 2020 2020 2020 2020  " } },\n        
-000072d0: 2020 2020 207b 2022 6d75 6c74 695f 6d61       { "multi_ma
-000072e0: 7463 6822 203a 207b 5c6e 2020 2020 2020  tch" : {\n      
-000072f0: 2020 2022 7175 6572 7922 3a20 2020 2022     "query":    "
-00007300: 2573 222c 205c 6e20 2020 2020 2020 2020  %s", \n         
-00007310: 2266 6965 6c64 7322 3a20 5b20 226c 6162  "fields": [ "lab
-00007320: 656c 222c 2022 6465 6669 6e69 7469 6f6e  el", "definition
-00007330: 2220 5d20 5c6e 2020 2020 2020 207d 207d  " ] \n       } }
-00007340: 5c6e 5d5c 6e20 2020 207d 5c6e 2020 7d5c  \n]\n    }\n  }\
-00007350: 6e7d 5c6e 2720 2571 7565 7279 5f73 7472  n}\n' %query_str
-00007360: 696e 670a 2020 2020 656c 6966 2074 7970  ing.    elif typ
-00007370: 6520 3d3d 2027 7064 6527 3a0a 2020 2020  e == 'pde':.    
-00007380: 2020 2020 6966 2061 6e73 6365 7374 6f72      if anscestor
-00007390: 733a 0a20 2020 2020 2020 2020 2020 2064  s:.            d
-000073a0: 6174 6120 3d20 275c 6e7b 5c6e 2020 2271  ata = '\n{\n  "q
-000073b0: 7565 7279 223a 207b 5c6e 2020 2020 2262  uery": {\n    "b
-000073c0: 6f6f 6c22 3a20 7b5c 6e20 2020 2020 2020  ool": {\n       
-000073d0: 226d 7573 7422 203a 205b 5c6e 2020 2020  "must" : [\n    
-000073e0: 2020 207b 2020 2274 6572 6d22 203a 207b     {  "term" : {
-000073f0: 2022 7479 7065 2220 3a20 2270 6465 2220   "type" : "pde" 
-00007400: 7d20 7d2c 5c6e 2020 2020 2020 207b 2022  } },\n       { "
-00007410: 7465 726d 7322 203a 207b 2022 616e 6365  terms" : { "ance
-00007420: 7374 6f72 732e 696c 7822 203a 205b 2269  stors.ilx" : ["i
-00007430: 6c78 5f30 3131 3530 3636 2220 2c20 2269  lx_0115066" , "i
-00007440: 6c78 5f30 3130 3332 3130 222c 2022 696c  lx_0103210", "il
-00007450: 785f 3031 3135 3037 3222 2c20 2269 6c78  x_0115072", "ilx
-00007460: 5f30 3131 3530 3730 225d 207d 207d 2c5c  _0115070"] } },\
-00007470: 6e20 2020 2020 2020 7b20 226d 756c 7469  n       { "multi
-00007480: 5f6d 6174 6368 2220 3a20 7b5c 6e20 2020  _match" : {\n   
-00007490: 2020 2020 2020 2271 7565 7279 223a 2020        "query":  
-000074a0: 2020 2225 7322 2c20 5c6e 2020 2020 2020    "%s", \n      
-000074b0: 2020 2022 6669 656c 6473 223a 205b 2022     "fields": [ "
-000074c0: 6c61 6265 6c22 2c20 2264 6566 696e 6974  label", "definit
-000074d0: 696f 6e22 205d 205c 6e20 2020 2020 2020  ion" ] \n       
-000074e0: 7d20 7d5c 6e5d 5c6e 2020 2020 7d5c 6e20  } }\n]\n    }\n 
-000074f0: 207d 5c6e 7d5c 6e27 2025 7175 6572 795f   }\n}\n' %query_
-00007500: 7374 7269 6e67 0a20 2020 2020 2020 2065  string.        e
-00007510: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00007520: 2064 6174 6120 3d20 275c 6e7b 5c6e 2020   data = '\n{\n  
-00007530: 2271 7565 7279 223a 207b 5c6e 2020 2020  "query": {\n    
-00007540: 2262 6f6f 6c22 3a20 7b5c 6e20 2020 2020  "bool": {\n     
-00007550: 2020 226d 7573 7422 203a 205b 5c6e 2020    "must" : [\n  
-00007560: 2020 2020 207b 2020 2274 6572 6d22 203a       {  "term" :
-00007570: 207b 2022 7479 7065 2220 3a20 2270 6465   { "type" : "pde
-00007580: 2220 7d20 7d2c 5c6e 2020 2020 2020 2020  " } },\n        
-00007590: 2020 2020 2020 7b20 226d 756c 7469 5f6d        { "multi_m
-000075a0: 6174 6368 2220 3a20 7b5c 6e20 2020 2020  atch" : {\n     
-000075b0: 2020 2020 2271 7565 7279 223a 2020 2020      "query":    
-000075c0: 2225 7322 2c20 5c6e 2020 2020 2020 2020  "%s", \n        
-000075d0: 2022 6669 656c 6473 223a 205b 2022 6c61   "fields": [ "la
-000075e0: 6265 6c22 2c20 2264 6566 696e 6974 696f  bel", "definitio
-000075f0: 6e22 205d 205c 6e20 2020 2020 2020 7d20  n" ] \n       } 
-00007600: 7d5c 6e5d 5c6e 2020 2020 7d5c 6e20 207d  }\n]\n    }\n  }
-00007610: 5c6e 7d5c 6e27 2025 7175 6572 795f 7374  \n}\n' %query_st
-00007620: 7269 6e67 0a20 2020 2065 6c69 6620 7479  ring.    elif ty
-00007630: 7065 203d 3d20 2766 6465 273a 0a20 2020  pe == 'fde':.   
-00007640: 2020 2020 2069 6620 616e 7363 6573 746f       if anscesto
-00007650: 7273 3a0a 2020 2020 2020 2020 2020 2020  rs:.            
-00007660: 6461 7461 203d 2027 5c6e 7b5c 6e20 2022  data = '\n{\n  "
-00007670: 7175 6572 7922 3a20 7b5c 6e20 2020 2022  query": {\n    "
-00007680: 626f 6f6c 223a 207b 5c6e 2020 2020 2020  bool": {\n      
-00007690: 2022 6d75 7374 2220 3a20 5b5c 6e20 2020   "must" : [\n   
-000076a0: 2020 2020 7b20 2022 7465 726d 2220 3a20      {  "term" : 
-000076b0: 7b20 2274 7970 6522 203a 2022 6664 6522  { "type" : "fde"
-000076c0: 207d 207d 2c5c 6e20 2020 2020 2020 7b20   } },\n       { 
-000076d0: 2274 6572 6d73 2220 3a20 7b20 2261 6e63  "terms" : { "anc
-000076e0: 6573 746f 7273 2e69 6c78 2220 3a20 5b22  estors.ilx" : ["
-000076f0: 696c 785f 3031 3135 3036 3622 202c 2022  ilx_0115066" , "
-00007700: 696c 785f 3031 3033 3231 3022 2c20 2269  ilx_0103210", "i
-00007710: 6c78 5f30 3131 3530 3732 222c 2022 696c  lx_0115072", "il
-00007720: 785f 3031 3135 3037 3022 5d20 7d20 7d2c  x_0115070"] } },
-00007730: 5c6e 2020 2020 2020 207b 2022 6d75 6c74  \n       { "mult
-00007740: 695f 6d61 7463 6822 203a 207b 5c6e 2020  i_match" : {\n  
-00007750: 2020 2020 2020 2022 7175 6572 7922 3a20         "query": 
-00007760: 2020 2022 2573 222c 205c 6e20 2020 2020     "%s", \n     
-00007770: 2020 2020 2266 6965 6c64 7322 3a20 5b20      "fields": [ 
-00007780: 226c 6162 656c 222c 2022 6465 6669 6e69  "label", "defini
-00007790: 7469 6f6e 2220 5d20 5c6e 2020 2020 2020  tion" ] \n      
-000077a0: 207d 207d 5c6e 5d5c 6e20 2020 207d 5c6e   } }\n]\n    }\n
-000077b0: 2020 7d5c 6e7d 5c6e 2720 2571 7565 7279    }\n}\n' %query
-000077c0: 5f73 7472 696e 670a 2020 2020 2020 2020  _string.        
-000077d0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-000077e0: 2020 6461 7461 203d 2027 5c6e 7b5c 6e20    data = '\n{\n 
-000077f0: 2022 7175 6572 7922 3a20 7b5c 6e20 2020   "query": {\n   
-00007800: 2022 626f 6f6c 223a 207b 5c6e 2020 2020   "bool": {\n    
-00007810: 2020 2022 6d75 7374 2220 3a20 5b5c 6e20     "must" : [\n 
-00007820: 2020 2020 2020 7b20 2022 7465 726d 2220        {  "term" 
-00007830: 3a20 7b20 2274 7970 6522 203a 2022 6664  : { "type" : "fd
-00007840: 6522 207d 207d 2c5c 6e20 2020 2020 2020  e" } },\n       
-00007850: 2020 2020 2020 207b 2022 6d75 6c74 695f         { "multi_
-00007860: 6d61 7463 6822 203a 207b 5c6e 2020 2020  match" : {\n    
-00007870: 2020 2020 2022 7175 6572 7922 3a20 2020       "query":   
-00007880: 2022 2573 222c 205c 6e20 2020 2020 2020   "%s", \n       
-00007890: 2020 2266 6965 6c64 7322 3a20 5b20 226c    "fields": [ "l
-000078a0: 6162 656c 222c 2022 6465 6669 6e69 7469  abel", "definiti
-000078b0: 6f6e 2220 5d20 5c6e 2020 2020 2020 207d  on" ] \n       }
-000078c0: 207d 5c6e 5d5c 6e20 2020 207d 5c6e 2020   }\n]\n    }\n  
-000078d0: 7d5c 6e7d 5c6e 2720 2571 7565 7279 5f73  }\n}\n' %query_s
-000078e0: 7472 696e 670a 0a20 2020 2065 6c69 6620  tring..    elif 
-000078f0: 7479 7065 203d 3d20 2774 6572 6d27 3a0a  type == 'term':.
-00007900: 2020 2020 2020 2020 6966 2061 6e73 6365          if ansce
-00007910: 7374 6f72 733a 0a20 2020 2020 2020 2020  stors:.         
-00007920: 2020 2064 6174 6120 3d20 275c 6e7b 5c6e     data = '\n{\n
-00007930: 2020 2271 7565 7279 223a 207b 5c6e 2020    "query": {\n  
-00007940: 2020 2262 6f6f 6c22 3a20 7b5c 6e20 2020    "bool": {\n   
-00007950: 2020 2020 226d 7573 7422 203a 205b 5c6e      "must" : [\n
-00007960: 2020 2020 2020 207b 2020 2274 6572 6d22         {  "term"
-00007970: 203a 207b 2022 7479 7065 2220 3a20 2274   : { "type" : "t
-00007980: 6572 6d22 207d 207d 2c5c 6e20 2020 2020  erm" } },\n     
-00007990: 2020 7b20 2274 6572 6d73 2220 3a20 7b20    { "terms" : { 
-000079a0: 2261 6e63 6573 746f 7273 2e69 6c78 2220  "ancestors.ilx" 
-000079b0: 3a20 5b22 696c 785f 3031 3135 3036 3622  : ["ilx_0115066"
-000079c0: 202c 2022 696c 785f 3031 3033 3231 3022   , "ilx_0103210"
-000079d0: 2c20 2269 6c78 5f30 3131 3530 3732 222c  , "ilx_0115072",
-000079e0: 2022 696c 785f 3031 3135 3037 3022 5d20   "ilx_0115070"] 
-000079f0: 7d20 7d2c 5c6e 2020 2020 2020 207b 2022  } },\n       { "
-00007a00: 6d75 6c74 695f 6d61 7463 6822 203a 207b  multi_match" : {
-00007a10: 5c6e 2020 2020 2020 2020 2022 7175 6572  \n         "quer
-00007a20: 7922 3a20 2020 2022 2573 222c 205c 6e20  y":    "%s", \n 
-00007a30: 2020 2020 2020 2020 2266 6965 6c64 7322          "fields"
-00007a40: 3a20 5b20 226c 6162 656c 222c 2022 6465  : [ "label", "de
-00007a50: 6669 6e69 7469 6f6e 2220 5d20 5c6e 2020  finition" ] \n  
-00007a60: 2020 2020 207d 207d 5c6e 5d5c 6e20 2020       } }\n]\n   
-00007a70: 207d 5c6e 2020 7d5c 6e7d 5c6e 2720 2520   }\n  }\n}\n' % 
-00007a80: 7175 6572 795f 7374 7269 6e67 0a20 2020  query_string.   
-00007a90: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00007aa0: 2020 2020 2020 2064 6174 6120 3d20 275c         data = '\
-00007ab0: 6e7b 5c6e 2020 2271 7565 7279 223a 207b  n{\n  "query": {
-00007ac0: 5c6e 2020 2020 2262 6f6f 6c22 3a20 7b5c  \n    "bool": {\
-00007ad0: 6e20 2020 2020 2020 226d 7573 7422 203a  n       "must" :
-00007ae0: 205b 5c6e 2020 2020 2020 207b 2020 2274   [\n       {  "t
-00007af0: 6572 6d22 203a 207b 2022 7479 7065 2220  erm" : { "type" 
-00007b00: 3a20 2274 6572 6d22 207d 207d 2c5c 6e20  : "term" } },\n 
-00007b10: 2020 2020 2020 2020 2020 2020 207b 2022               { "
-00007b20: 6d75 6c74 695f 6d61 7463 6822 203a 207b  multi_match" : {
-00007b30: 5c6e 2020 2020 2020 2020 2022 7175 6572  \n         "quer
-00007b40: 7922 3a20 2020 2022 2573 222c 205c 6e20  y":    "%s", \n 
-00007b50: 2020 2020 2020 2020 2266 6965 6c64 7322          "fields"
-00007b60: 3a20 5b20 226c 6162 656c 222c 2022 6465  : [ "label", "de
-00007b70: 6669 6e69 7469 6f6e 2220 5d20 5c6e 2020  finition" ] \n  
-00007b80: 2020 2020 207d 207d 5c6e 5d5c 6e20 2020       } }\n]\n   
-00007b90: 207d 5c6e 2020 7d5c 6e7d 5c6e 2720 2520   }\n  }\n}\n' % 
-00007ba0: 7175 6572 795f 7374 7269 6e67 0a0a 2020  query_string..  
-00007bb0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00007bc0: 7072 696e 7428 2245 5252 4f52 3a20 5661  print("ERROR: Va
-00007bd0: 6c69 6420 7479 7065 7320 666f 7220 5363  lid types for Sc
-00007be0: 6943 7275 6e63 6820 7175 6572 7920 6172  iCrunch query ar
-00007bf0: 6520 2763 6465 272c 2770 6465 272c 206f  e 'cde','pde', o
-00007c00: 7220 2766 6465 272e 2020 596f 7520 7365  r 'fde'.  You se
-00007c10: 7420 7479 7065 3a20 2573 2022 2025 7479  t type: %s " %ty
-00007c20: 7065 290a 2020 2020 2020 2020 7072 696e  pe).        prin
-00007c30: 7428 2245 5252 4f52 3a20 696e 2066 756e  t("ERROR: in fun
-00007c40: 6374 696f 6e20 5574 696c 732e 7079 2f51  ction Utils.py/Q
-00007c50: 7565 7279 5363 6943 7275 6e63 6845 6c61  uerySciCrunchEla
-00007c60: 7374 6963 5365 6172 6368 2229 0a20 2020  sticSearch").   
-00007c70: 2020 2020 2065 7869 7428 3129 0a0a 2020       exit(1)..  
-00007c80: 2020 7265 7370 6f6e 7365 203d 2072 6571    response = req
-00007c90: 7565 7374 732e 706f 7374 2827 6874 7470  uests.post('http
-00007ca0: 733a 2f2f 7363 6963 7275 6e63 682e 6f72  s://scicrunch.or
-00007cb0: 672f 6170 692f 312f 656c 6173 7469 632d  g/api/1/elastic-
-00007cc0: 696c 782f 696e 7465 726c 6578 2f74 6572  ilx/interlex/ter
-00007cd0: 6d2f 5f73 6561 7263 6823 272c 2068 6561  m/_search#', hea
-00007ce0: 6465 7273 3d68 6561 6465 7273 2c20 7061  ders=headers, pa
-00007cf0: 7261 6d73 3d70 6172 616d 732c 2064 6174  rams=params, dat
-00007d00: 613d 6461 7461 290a 0a20 2020 2072 6574  a=data)..    ret
-00007d10: 7572 6e20 6a73 6f6e 2e6c 6f61 6473 2872  urn json.loads(r
-00007d20: 6573 706f 6e73 652e 7465 7874 290a 0a64  esponse.text)..d
-00007d30: 6566 2047 6574 4e49 444d 5465 726d 7346  ef GetNIDMTermsF
-00007d40: 726f 6d53 6369 4372 756e 6368 2871 7565  romSciCrunch(que
-00007d50: 7279 5f73 7472 696e 672c 7479 7065 3d27  ry_string,type='
-00007d60: 6364 6527 2c20 616e 6365 7374 6f72 3d54  cde', ancestor=T
-00007d70: 7275 6529 3a0a 2020 2020 2727 270a 2020  rue):.    '''.  
-00007d80: 2020 4865 6c70 6572 2066 756e 6374 696f    Helper functio
-00007d90: 6e20 7768 6963 6820 6973 7375 6573 2065  n which issues e
-00007da0: 6c61 7374 6963 2073 6561 7263 6820 7175  lastic search qu
-00007db0: 6572 7920 6f66 2053 6369 4372 756e 6368  ery of SciCrunch
-00007dc0: 2075 7369 6e67 2051 7565 7279 5363 6943   using QuerySciC
-00007dd0: 7275 6e63 6845 6c61 7374 6963 5365 6172  runchElasticSear
-00007de0: 6368 2066 756e 6374 696f 6e20 616e 6420  ch function and 
-00007df0: 7265 7475 726e 7320 7465 726d 7320 6c69  returns terms li
-00007e00: 7374 0a20 2020 2077 6974 6820 6c61 6265  st.    with labe
-00007e10: 6c2c 2064 6566 696e 6974 696f 6e2c 2061  l, definition, a
-00007e20: 6e64 2070 7265 6665 7272 6564 2055 524c  nd preferred URL
-00007e30: 7320 696e 2064 6963 7469 6f6e 6172 790a  s in dictionary.
-00007e40: 2020 2020 3a70 6172 616d 206b 6579 3a20      :param key: 
-00007e50: 4150 4920 6b65 7920 6672 6f6d 2073 6369  API key from sci
-00007e60: 2063 7275 6e63 680a 2020 2020 3a70 6172   crunch.    :par
-00007e70: 616d 2071 7565 7279 5f73 7472 696e 673a  am query_string:
-00007e80: 2061 7262 6974 7261 7279 2073 7472 696e   arbitrary strin
-00007e90: 6720 746f 2073 6561 7263 6820 666f 7220  g to search for 
-00007ea0: 7465 726d 730a 2020 2020 3a70 6172 616d  terms.    :param
-00007eb0: 2074 7970 653a 2073 686f 756c 6420 6265   type: should be
-00007ec0: 2027 6364 6527 206f 7220 2770 6465 2720   'cde' or 'pde' 
-00007ed0: 666f 7220 7468 6520 6d6f 6d65 6e74 0a20  for the moment. 
-00007ee0: 2020 203a 7061 7261 6d20 616e 6365 7374     :param ancest
-00007ef0: 6f72 3a20 426f 6f6c 6561 6e20 666c 6167  or: Boolean flag
-00007f00: 2074 6f20 7465 6c6c 2049 6e74 6572 6c65   to tell Interle
-00007f10: 7820 656c 6173 7469 6320 7365 6172 6368  x elastic search
-00007f20: 2074 6f20 7573 6520 616e 6365 7374 6f72   to use ancestor
-00007f30: 7320 2869 2e65 2e20 7461 6767 6564 2074  s (i.e. tagged t
-00007f40: 6572 6d73 2920 6f72 206e 6f74 0a20 2020  erms) or not.   
-00007f50: 203a 7265 7475 726e 3a20 6469 6374 696f   :return: dictio
-00007f60: 6e61 7279 2077 6974 6820 6b65 7973 2027  nary with keys '
-00007f70: 696c 7827 2c27 6c61 6265 6c27 2c27 6465  ilx','label','de
-00007f80: 6669 6e69 7469 6f6e 272c 2770 7265 6665  finition','prefe
-00007f90: 7272 6564 5f75 726c 270a 2020 2020 2727  rred_url'.    ''
-00007fa0: 270a 0a20 2020 206a 736f 6e5f 6461 7461  '..    json_data
-00007fb0: 203d 2051 7565 7279 5363 6943 7275 6e63   = QuerySciCrunc
-00007fc0: 6845 6c61 7374 6963 5365 6172 6368 2871  hElasticSearch(q
-00007fd0: 7565 7279 5f73 7472 696e 672c 7479 7065  uery_string,type
-00007fe0: 2c61 6e63 6573 746f 7229 0a20 2020 2072  ,ancestor).    r
-00007ff0: 6573 756c 7473 3d7b 7d0a 2020 2020 2363  esults={}.    #c
-00008000: 6865 636b 2069 6620 7175 6572 7920 7761  heck if query wa
-00008010: 7320 7375 6363 6573 7366 756c 0a20 2020  s successful.   
-00008020: 2069 6620 6a73 6f6e 5f64 6174 615b 2774   if json_data['t
-00008030: 696d 6564 5f6f 7574 275d 2021 3d20 5472  imed_out'] != Tr
-00008040: 7565 3a0a 2020 2020 2020 2020 2365 7861  ue:.        #exa
-00008050: 6d70 6c65 2070 7269 6e74 696e 6720 7465  mple printing te
-00008060: 726d 206c 6162 656c 2c20 6465 6669 6e69  rm label, defini
-00008070: 7469 6f6e 2c20 616e 6420 7072 6566 6572  tion, and prefer
-00008080: 7265 6420 5552 4c0a 2020 2020 2020 2020  red URL.        
-00008090: 666f 7220 7465 726d 2069 6e20 6a73 6f6e  for term in json
-000080a0: 5f64 6174 615b 2768 6974 7327 5d5b 2768  _data['hits']['h
-000080b0: 6974 7327 5d3a 0a20 2020 2020 2020 2020  its']:.         
-000080c0: 2020 2023 6669 6e64 2070 7265 6665 7272     #find preferr
-000080d0: 6564 2055 524c 0a20 2020 2020 2020 2020  ed URL.         
-000080e0: 2020 2072 6573 756c 7473 5b74 6572 6d5b     results[term[
-000080f0: 275f 736f 7572 6365 275d 5b27 696c 7827  '_source']['ilx'
-00008100: 5d5d 203d 207b 7d0a 2020 2020 2020 2020  ]] = {}.        
-00008110: 2020 2020 666f 7220 6974 656d 7320 696e      for items in
-00008120: 2074 6572 6d5b 275f 736f 7572 6365 275d   term['_source']
-00008130: 5b27 6578 6973 7469 6e67 5f69 6473 275d  ['existing_ids']
-00008140: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00008150: 2020 6966 2069 7465 6d73 5b27 7072 6566    if items['pref
-00008160: 6572 7265 6427 5d3d 3d27 3127 3a0a 2020  erred']=='1':.  
-00008170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008180: 2020 7265 7375 6c74 735b 7465 726d 5b27    results[term['
-00008190: 5f73 6f75 7263 6527 5d5b 2769 6c78 275d  _source']['ilx']
-000081a0: 5d5b 2770 7265 6665 7272 6564 5f75 726c  ]['preferred_url
-000081b0: 275d 3d69 7465 6d73 5b27 6972 6927 5d0a  ']=items['iri'].
-000081c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000081d0: 7265 7375 6c74 735b 7465 726d 5b27 5f73  results[term['_s
-000081e0: 6f75 7263 6527 5d5b 2769 6c78 275d 5d5b  ource']['ilx']][
-000081f0: 276c 6162 656c 275d 203d 2074 6572 6d5b  'label'] = term[
-00008200: 275f 736f 7572 6365 275d 5b27 6c61 6265  '_source']['labe
-00008210: 6c27 5d0a 2020 2020 2020 2020 2020 2020  l'].            
-00008220: 2020 2020 7265 7375 6c74 735b 7465 726d      results[term
-00008230: 5b27 5f73 6f75 7263 6527 5d5b 2769 6c78  ['_source']['ilx
-00008240: 275d 5d5b 2764 6566 696e 6974 696f 6e27  ']]['definition'
-00008250: 5d20 3d20 7465 726d 5b27 5f73 6f75 7263  ] = term['_sourc
-00008260: 6527 5d5b 2764 6566 696e 6974 696f 6e27  e']['definition'
-00008270: 5d0a 0a20 2020 2072 6574 7572 6e20 7265  ]..    return re
-00008280: 7375 6c74 730a 0a64 6566 2049 6e69 7469  sults..def Initi
-00008290: 616c 697a 6549 6e74 6572 6c65 7852 656d  alizeInterlexRem
-000082a0: 6f74 6528 293a 0a20 2020 2027 2727 0a20  ote():.    '''. 
-000082b0: 2020 2054 6869 7320 6675 6e63 7469 6f6e     This function
-000082c0: 2069 6e69 7469 616c 697a 6573 2061 2063   initializes a c
-000082d0: 6f6e 6e65 6374 696f 6e20 746f 2049 6e74  onnection to Int
-000082e0: 6572 6c65 7820 666f 7220 7573 6520 696e  erlex for use in
-000082f0: 2061 6464 696e 6720 7065 7273 6f6e 616c   adding personal
-00008300: 2064 6174 6120 656c 656d 656e 7473 2e20   data elements. 
-00008310: 546f 2075 7365 2049 6e74 6572 4c65 780a  To use InterLex.
-00008320: 2020 2020 6974 2072 6571 7569 7265 7320      it requires 
-00008330: 796f 7520 746f 2073 6574 2061 6e20 656e  you to set an en
-00008340: 7669 726f 6e6d 656e 7420 7661 7269 6162  vironment variab
-00008350: 6c65 2049 4e54 4552 4c45 585f 4150 495f  le INTERLEX_API_
-00008360: 4b45 5920 7769 7468 2079 6f75 7220 6170  KEY with your ap
-00008370: 6920 6b65 790a 2020 2020 3a72 6574 7572  i key.    :retur
-00008380: 6e3a 2069 6e74 6572 6c65 7820 6f62 6a65  n: interlex obje
-00008390: 6374 0a20 2020 2027 2727 0a20 2020 2023  ct.    '''.    #
-000083a0: 656e 6470 6f69 6e74 203d 2022 6874 7470  endpoint = "http
-000083b0: 733a 2f2f 7363 6963 7275 6e63 682e 6f72  s://scicrunch.or
-000083c0: 672f 6170 692f 312f 220a 2020 2020 2320  g/api/1/".    # 
-000083d0: 6265 7461 2065 6e64 706f 696e 7420 666f  beta endpoint fo
-000083e0: 7220 7465 7374 696e 670a 2020 2020 2320  r testing.    # 
-000083f0: 656e 6470 6f69 6e74 203d 2022 6874 7470  endpoint = "http
-00008400: 733a 2f2f 6265 7461 2e73 6369 6372 756e  s://beta.scicrun
-00008410: 6368 2e6f 7267 2f61 7069 2f31 2f22 0a0a  ch.org/api/1/"..
-00008420: 2020 2020 496e 7465 724c 6578 5265 6d6f      InterLexRemo
-00008430: 7465 203d 206f 712e 706c 7567 696e 2e67  te = oq.plugin.g
-00008440: 6574 2827 496e 7465 724c 6578 2729 0a20  et('InterLex'). 
-00008450: 2020 2023 2063 6861 6e67 6564 2070 6572     # changed per
-00008460: 2074 6762 7567 7320 6368 616e 6765 7320   tgbugs changes 
-00008470: 746f 2049 6e74 6572 4c65 7852 656d 6f74  to InterLexRemot
-00008480: 6520 6e6f 206c 6f6e 6765 7220 7461 6b69  e no longer taki
-00008490: 6e67 2061 7069 5f6b 6579 2061 7320 6120  ng api_key as a 
-000084a0: 7061 7261 6d65 7465 720a 2020 2020 2320  parameter.    # 
-000084b0: 7365 7420 494e 5445 524c 4558 5f41 5049  set INTERLEX_API
-000084c0: 5f4b 4559 2065 6e76 6972 6f6e 6d65 6e74  _KEY environment
-000084d0: 2076 6172 6961 626c 6520 696e 7374 6561   variable instea
-000084e0: 642e 2e2e 696c 785f 636c 6920 3d20 496e  d...ilx_cli = In
-000084f0: 7465 724c 6578 5265 6d6f 7465 2861 7069  terLexRemote(api
-00008500: 5f6b 6579 3d6b 6579 2c20 6170 6945 6e64  _key=key, apiEnd
-00008510: 706f 696e 743d 656e 6470 6f69 6e74 290a  point=endpoint).
-00008520: 2020 2020 696c 785f 636c 6920 3d20 496e      ilx_cli = In
-00008530: 7465 724c 6578 5265 6d6f 7465 2861 7069  terLexRemote(api
-00008540: 456e 6470 6f69 6e74 3d49 4e54 4552 4c45  Endpoint=INTERLE
-00008550: 585f 454e 4450 4f49 4e54 290a 2020 2020  X_ENDPOINT).    
-00008560: 7472 793a 0a20 2020 2020 2020 2069 6c78  try:.        ilx
-00008570: 5f63 6c69 2e73 6574 7570 2869 6e73 7472  _cli.setup(instr
-00008580: 756d 656e 7465 643d 6f71 2e4f 6e74 5465  umented=oq.OntTe
-00008590: 726d 290a 2020 2020 6578 6365 7074 2045  rm).    except E
-000085a0: 7863 6570 7469 6f6e 2061 7320 653a 0a20  xception as e:. 
-000085b0: 2020 2020 2020 2070 7269 6e74 2822 6572         print("er
-000085c0: 726f 7220 696e 6974 6961 6c69 7a69 6e67  ror initializing
-000085d0: 2049 6e74 6572 4c65 7820 636f 6e6e 6563   InterLex connec
-000085e0: 7469 6f6e 2e2e 2e22 290a 2020 2020 2020  tion...").      
-000085f0: 2020 7072 696e 7428 2279 6f75 2077 696c    print("you wil
-00008600: 6c20 6e6f 7420 6265 2061 626c 6520 746f  l not be able to
-00008610: 2061 6464 206e 6577 2070 6572 736f 6e61   add new persona
-00008620: 6c20 6461 7461 2065 6c65 6d65 6e74 732e  l data elements.
-00008630: 2229 0a20 2020 2020 2020 2070 7269 6e74  ").        print
-00008640: 2822 4469 6420 796f 7520 7075 7420 796f  ("Did you put yo
-00008650: 7572 2073 6369 6372 756e 6368 2041 5049  ur scicrunch API
-00008660: 206b 6579 2069 6e20 616e 2065 6e76 6972   key in an envir
-00008670: 6f6e 6d65 6e74 2076 6172 6961 626c 6520  onment variable 
-00008680: 494e 5445 524c 4558 5f41 5049 5f4b 4559  INTERLEX_API_KEY
-00008690: 3f22 290a 0a20 2020 2072 6574 7572 6e20  ?")..    return 
-000086a0: 696c 785f 636c 690a 0a64 6566 2041 6464  ilx_cli..def Add
-000086b0: 5044 4554 6f49 6e74 6572 6c65 7828 696c  PDEToInterlex(il
-000086c0: 785f 6f62 6a2c 6c61 6265 6c2c 6465 6669  x_obj,label,defi
-000086d0: 6e69 7469 6f6e 2c75 6e69 7473 2c20 6d69  nition,units, mi
-000086e0: 6e2c 206d 6178 2c20 6461 7461 7479 7065  n, max, datatype
-000086f0: 2c20 6973 6162 6f75 743d 4e6f 6e65 2c20  , isabout=None, 
-00008700: 6361 7465 676f 7279 6d61 7070 696e 6773  categorymappings
-00008710: 3d4e 6f6e 6529 3a0a 2020 2020 2727 270a  =None):.    '''.
-00008720: 2020 2020 5468 6973 2066 756e 6374 696f      This functio
-00008730: 6e20 7769 6c6c 2061 6464 2074 6865 2050  n will add the P
-00008740: 4445 2028 7065 7273 6f6e 616c 2064 6174  DE (personal dat
-00008750: 6120 656c 656d 656e 7473 2920 746f 2049  a elements) to I
-00008760: 6e74 6572 6c65 7820 7573 696e 6720 7468  nterlex using th
-00008770: 6520 496e 7465 726c 6578 206f 6e74 7175  e Interlex ontqu
-00008780: 6572 7920 4150 492e 2020 0a20 2020 200a  ery API.  .    .
-00008790: 2020 2020 3a70 6172 616d 2069 6e74 6572      :param inter
-000087a0: 6c65 785f 6f62 6a3a 204f 626a 6563 7420  lex_obj: Object 
-000087b0: 6372 6561 7465 6420 7573 696e 6720 6f6e  created using on
-000087c0: 7471 7565 7279 2e70 6c75 6769 6e2e 6765  tquery.plugin.ge
-000087d0: 7428 2920 6675 6e63 7469 6f6e 2028 7365  t() function (se
-000087e0: 653a 2068 7474 7073 3a2f 2f67 6974 6875  e: https://githu
-000087f0: 622e 636f 6d2f 7467 6275 6773 2f6f 6e74  b.com/tgbugs/ont
-00008800: 7175 6572 7929 200a 2020 2020 3a70 6172  query) .    :par
-00008810: 616d 206c 6162 656c 3a20 4c61 6265 6c20  am label: Label 
-00008820: 666f 7220 7465 726d 2065 6e74 6974 7920  for term entity 
-00008830: 6265 696e 6720 6372 6561 7465 640a 2020  being created.  
-00008840: 2020 3a70 6172 616d 2064 6566 696e 6974    :param definit
-00008850: 696f 6e3a 2044 6566 696e 6974 696f 6e20  ion: Definition 
-00008860: 666f 7220 7465 726d 2065 6e74 6974 7920  for term entity 
-00008870: 6265 696e 6720 6372 6561 7465 640a 2020  being created.  
-00008880: 2020 3a70 6172 616d 2063 6f6d 6d65 6e74    :param comment
-00008890: 3a20 436f 6d6d 656e 7473 2074 6f20 6865  : Comments to he
-000088a0: 6c70 2075 6e64 6572 7374 616e 6420 7468  lp understand th
-000088b0: 6520 6f62 6a65 6374 0a20 2020 203a 7265  e object.    :re
-000088c0: 7475 726e 3a20 7265 7370 6f6e 7365 2066  turn: response f
-000088d0: 726f 6d20 496e 7465 726c 6578 200a 2020  rom Interlex .  
-000088e0: 2020 2727 270a 0a20 2020 2023 2049 6e74    '''..    # Int
-000088f0: 6572 6c65 7820 7572 6973 2066 6f72 2070  erlex uris for p
-00008900: 7265 6469 6361 7465 732c 2074 6d70 5f20  redicates, tmp_ 
-00008910: 7072 6566 6978 2064 6f72 2062 6574 6120  prefix dor beta 
-00008920: 656e 6470 6f69 6e67 2c20 696c 785f 2066  endpoing, ilx_ f
-00008930: 6f72 2070 726f 6475 6374 696f 6e0a 2020  or production.  
-00008940: 2020 7072 6566 6978 3d49 4e54 4552 4c45    prefix=INTERLE
-00008950: 585f 5052 4546 4958 0a20 2020 2023 2066  X_PREFIX.    # f
-00008960: 6f72 2062 6574 6120 7465 7374 696e 670a  or beta testing.
-00008970: 2020 2020 2320 7072 6566 6978 203d 2027      # prefix = '
-00008980: 746d 7027 0a20 2020 2075 7269 5f64 6174  tmp'.    uri_dat
-00008990: 6174 7970 6520 3d20 2768 7474 703a 2f2f  atype = 'http://
-000089a0: 7572 692e 696e 7465 726c 6578 2e6f 7267  uri.interlex.org
-000089b0: 2f62 6173 652f 2720 2b20 7072 6566 6978  /base/' + prefix
-000089c0: 202b 2027 5f30 3338 3231 3331 270a 2020   + '_0382131'.  
-000089d0: 2020 7572 695f 756e 6974 7320 3d20 2768    uri_units = 'h
-000089e0: 7474 703a 2f2f 7572 692e 696e 7465 726c  ttp://uri.interl
-000089f0: 6578 2e6f 7267 2f62 6173 652f 2720 2b20  ex.org/base/' + 
-00008a00: 7072 6566 6978 202b 2027 5f30 3338 3231  prefix + '_03821
-00008a10: 3330 270a 2020 2020 7572 695f 6d69 6e20  30'.    uri_min 
-00008a20: 3d20 2768 7474 703a 2f2f 7572 692e 696e  = 'http://uri.in
-00008a30: 7465 726c 6578 2e6f 7267 2f62 6173 652f  terlex.org/base/
-00008a40: 2720 2b20 7072 6566 6978 202b 2027 5f30  ' + prefix + '_0
-00008a50: 3338 3231 3333 270a 2020 2020 7572 695f  382133'.    uri_
-00008a60: 6d61 7820 3d20 2768 7474 703a 2f2f 7572  max = 'http://ur
-00008a70: 692e 696e 7465 726c 6578 2e6f 7267 2f62  i.interlex.org/b
-00008a80: 6173 652f 2720 2b20 7072 6566 6978 202b  ase/' + prefix +
-00008a90: 2027 5f30 3338 3231 3332 270a 2020 2020   '_0382132'.    
-00008aa0: 7572 695f 6361 7465 676f 7279 203d 2027  uri_category = '
-00008ab0: 6874 7470 3a2f 2f75 7269 2e69 6e74 6572  http://uri.inter
-00008ac0: 6c65 782e 6f72 672f 6261 7365 2f27 202b  lex.org/base/' +
-00008ad0: 2070 7265 6669 7820 2b20 275f 3033 3832   prefix + '_0382
-00008ae0: 3132 3927 0a20 2020 2075 7269 5f69 7361  129'.    uri_isa
-00008af0: 626f 7574 203d 2027 6874 7470 3a2f 2f75  bout = 'http://u
-00008b00: 7269 2e69 6e74 6572 6c65 782e 6f72 672f  ri.interlex.org/
-00008b10: 6261 7365 2f27 202b 2070 7265 6669 7820  base/' + prefix 
-00008b20: 2b20 275f 3033 3831 3338 3527 0a0a 0a20  + '_0381385'... 
-00008b30: 2020 2023 2072 6574 7572 6e20 696c 785f     # return ilx_
-00008b40: 6f62 6a2e 6164 645f 7064 6528 6c61 6265  obj.add_pde(labe
-00008b50: 6c3d 6c61 6265 6c2c 2064 6566 696e 6974  l=label, definit
-00008b60: 696f 6e3d 6465 6669 6e69 7469 6f6e 2c20  ion=definition, 
-00008b70: 636f 6d6d 656e 743d 636f 6d6d 656e 742c  comment=comment,
-00008b80: 2074 7970 653d 2770 6465 2729 0a20 2020   type='pde').   
-00008b90: 2069 6620 6361 7465 676f 7279 6d61 7070   if categorymapp
-00008ba0: 696e 6773 2069 7320 6e6f 7420 4e6f 6e65  ings is not None
-00008bb0: 3a0a 2020 2020 2020 2020 6966 2069 7361  :.        if isa
-00008bc0: 626f 7574 2069 7320 6e6f 7420 4e6f 6e65  bout is not None
-00008bd0: 3a0a 2020 2020 2020 2020 2020 2020 746d  :.            tm
-00008be0: 7020 3d20 696c 785f 6f62 6a2e 6164 645f  p = ilx_obj.add_
-00008bf0: 7064 6528 6c61 6265 6c3d 6c61 6265 6c2c  pde(label=label,
-00008c00: 2064 6566 696e 6974 696f 6e3d 6465 6669   definition=defi
-00008c10: 6e69 7469 6f6e 2c20 7072 6564 6963 6174  nition, predicat
-00008c20: 6573 203d 207b 0a20 2020 2020 2020 2020  es = {.         
-00008c30: 2020 2020 2020 2075 7269 5f64 6174 6174         uri_datat
-00008c40: 7970 6520 3a20 6461 7461 7479 7065 2c0a  ype : datatype,.
-00008c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008c60: 7572 695f 756e 6974 7320 3a20 756e 6974  uri_units : unit
-00008c70: 732c 0a20 2020 2020 2020 2020 2020 2020  s,.             
-00008c80: 2020 2075 7269 5f6d 696e 203a 206d 696e     uri_min : min
-00008c90: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00008ca0: 2020 7572 695f 6d61 7820 3a20 6d61 782c    uri_max : max,
-00008cb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00008cc0: 2075 7269 5f69 7361 626f 7574 203a 2069   uri_isabout : i
-00008cd0: 7361 626f 7574 2c0a 2020 2020 2020 2020  sabout,.        
-00008ce0: 2020 2020 2020 2020 7572 695f 6361 7465          uri_cate
-00008cf0: 676f 7279 203a 2063 6174 6567 6f72 796d  gory : categorym
-00008d00: 6170 7069 6e67 730a 2020 2020 2020 2020  appings.        
-00008d10: 2020 2020 7d29 0a20 2020 2020 2020 2065      }).        e
-00008d20: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00008d30: 2074 6d70 203d 2069 6c78 5f6f 626a 2e61   tmp = ilx_obj.a
-00008d40: 6464 5f70 6465 286c 6162 656c 3d6c 6162  dd_pde(label=lab
-00008d50: 656c 2c20 6465 6669 6e69 7469 6f6e 3d64  el, definition=d
-00008d60: 6566 696e 6974 696f 6e2c 2070 7265 6469  efinition, predi
-00008d70: 6361 7465 7320 3d20 7b0a 2020 2020 2020  cates = {.      
-00008d80: 2020 2020 2020 2020 2020 7572 695f 6461            uri_da
-00008d90: 7461 7479 7065 203a 2064 6174 6174 7970  tatype : datatyp
-00008da0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-00008db0: 2020 2075 7269 5f75 6e69 7473 203a 2075     uri_units : u
-00008dc0: 6e69 7473 2c0a 2020 2020 2020 2020 2020  nits,.          
-00008dd0: 2020 2020 2020 7572 695f 6d69 6e20 3a20        uri_min : 
-00008de0: 6d69 6e2c 0a20 2020 2020 2020 2020 2020  min,.           
-00008df0: 2020 2020 2075 7269 5f6d 6178 203a 206d       uri_max : m
-00008e00: 6178 2c0a 2020 2020 2020 2020 2020 2020  ax,.            
-00008e10: 2020 2020 7572 695f 6361 7465 676f 7279      uri_category
-00008e20: 203a 2063 6174 6567 6f72 796d 6170 7069   : categorymappi
-00008e30: 6e67 730a 2020 2020 2020 2020 2020 2020  ngs.            
-00008e40: 7d29 0a20 2020 2065 6c73 653a 0a20 2020  }).    else:.   
-00008e50: 2020 2020 2069 6620 6973 6162 6f75 7420       if isabout 
-00008e60: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-00008e70: 2020 2020 2020 2020 2074 6d70 203d 2069           tmp = i
-00008e80: 6c78 5f6f 626a 2e61 6464 5f70 6465 286c  lx_obj.add_pde(l
-00008e90: 6162 656c 3d6c 6162 656c 2c20 6465 6669  abel=label, defi
-00008ea0: 6e69 7469 6f6e 3d64 6566 696e 6974 696f  nition=definitio
-00008eb0: 6e2c 2070 7265 6469 6361 7465 7320 3d20  n, predicates = 
-00008ec0: 7b0a 0a20 2020 2020 2020 2020 2020 2020  {..             
-00008ed0: 2020 2075 7269 5f64 6174 6174 7970 6520     uri_datatype 
-00008ee0: 3a20 6461 7461 7479 7065 2c0a 2020 2020  : datatype,.    
-00008ef0: 2020 2020 2020 2020 2020 2020 7572 695f              uri_
-00008f00: 756e 6974 7320 3a20 756e 6974 732c 0a20  units : units,. 
-00008f10: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00008f20: 7269 5f6d 696e 203a 206d 696e 2c0a 2020  ri_min : min,.  
-00008f30: 2020 2020 2020 2020 2020 2020 2020 7572                ur
-00008f40: 695f 6d61 7820 3a20 6d61 782c 0a20 2020  i_max : max,.   
-00008f50: 2020 2020 2020 2020 2020 2020 2075 7269               uri
-00008f60: 5f69 7361 626f 7574 203a 2069 7361 626f  _isabout : isabo
-00008f70: 7574 0a20 2020 2020 2020 2020 2020 207d  ut.            }
-00008f80: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-00008f90: 2020 2020 2020 2020 2020 2020 746d 7020              tmp 
-00008fa0: 3d20 696c 785f 6f62 6a2e 6164 645f 7064  = ilx_obj.add_pd
-00008fb0: 6528 6c61 6265 6c3d 6c61 6265 6c2c 2064  e(label=label, d
-00008fc0: 6566 696e 6974 696f 6e3d 6465 6669 6e69  efinition=defini
-00008fd0: 7469 6f6e 2c20 7072 6564 6963 6174 6573  tion, predicates
-00008fe0: 203d 207b 0a0a 2020 2020 2020 2020 2020   = {..          
-00008ff0: 2020 2020 2020 7572 695f 6461 7461 7479        uri_dataty
-00009000: 7065 203a 2064 6174 6174 7970 652c 0a20  pe : datatype,. 
-00009010: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00009020: 7269 5f75 6e69 7473 203a 2075 6e69 7473  ri_units : units
-00009030: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00009040: 2020 7572 695f 6d69 6e20 3a20 6d69 6e2c    uri_min : min,
-00009050: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00009060: 2075 7269 5f6d 6178 203a 206d 6178 0a20   uri_max : max. 
-00009070: 2020 2020 2020 2020 2020 207d 290a 0a20             }).. 
-00009080: 2020 2072 6574 7572 6e20 746d 700a 0a64     return tmp..d
-00009090: 6566 2041 6464 436f 6e63 6570 7454 6f49  ef AddConceptToI
-000090a0: 6e74 6572 6c65 7828 696c 785f 6f62 6a2c  nterlex(ilx_obj,
-000090b0: 206c 6162 656c 2c20 6465 6669 6e69 7469   label, definiti
-000090c0: 6f6e 293a 0a20 2020 2027 2727 0a20 2020  on):.    '''.   
-000090d0: 2020 2020 2054 6869 7320 6675 6e63 7469       This functi
-000090e0: 6f6e 2077 696c 6c20 6164 6420 6120 636f  on will add a co
-000090f0: 6e63 6570 7420 746f 2049 6e74 6572 6c65  ncept to Interle
-00009100: 7820 7573 696e 6720 7468 6520 496e 7465  x using the Inte
-00009110: 726c 6578 206f 6e74 7175 6572 7920 4150  rlex ontquery AP
-00009120: 492e 0a0a 2020 2020 2020 2020 3a70 6172  I...        :par
-00009130: 616d 2069 6c78 5f6f 626a 3a20 4f62 6a65  am ilx_obj: Obje
-00009140: 6374 2063 7265 6174 6564 2075 7369 6e67  ct created using
-00009150: 206f 6e74 7175 6572 792e 706c 7567 696e   ontquery.plugin
-00009160: 2e67 6574 2829 2066 756e 6374 696f 6e20  .get() function 
-00009170: 2873 6565 3a20 6874 7470 733a 2f2f 6769  (see: https://gi
-00009180: 7468 7562 2e63 6f6d 2f74 6762 7567 732f  thub.com/tgbugs/
-00009190: 6f6e 7471 7565 7279 290a 2020 2020 2020  ontquery).      
-000091a0: 2020 3a70 6172 616d 206c 6162 656c 3a20    :param label: 
-000091b0: 4c61 6265 6c20 666f 7220 7465 726d 2065  Label for term e
-000091c0: 6e74 6974 7920 6265 696e 6720 6372 6561  ntity being crea
-000091d0: 7465 640a 2020 2020 2020 2020 3a70 6172  ted.        :par
-000091e0: 616d 2064 6566 696e 6974 696f 6e3a 2044  am definition: D
-000091f0: 6566 696e 6974 696f 6e20 666f 7220 7465  efinition for te
-00009200: 726d 2065 6e74 6974 7920 6265 696e 6720  rm entity being 
-00009210: 6372 6561 7465 640a 2020 2020 2020 2020  created.        
-00009220: 3a70 6172 616d 2063 6f6d 6d65 6e74 3a20  :param comment: 
-00009230: 436f 6d6d 656e 7473 2074 6f20 6865 6c70  Comments to help
-00009240: 2075 6e64 6572 7374 616e 6420 7468 6520   understand the 
-00009250: 6f62 6a65 6374 0a20 2020 2020 2020 203a  object.        :
-00009260: 7265 7475 726e 3a20 7265 7370 6f6e 7365  return: response
-00009270: 2066 726f 6d20 496e 7465 726c 6578 0a20   from Interlex. 
-00009280: 2020 2020 2020 2027 2727 0a0a 2020 2020         '''..    
-00009290: 2320 496e 7465 726c 6578 2075 7269 7320  # Interlex uris 
-000092a0: 666f 7220 7072 6564 6963 6174 6573 2c20  for predicates, 
-000092b0: 746d 705f 2070 7265 6669 7820 646f 7220  tmp_ prefix dor 
-000092c0: 6265 7461 2065 6e64 706f 696e 672c 2069  beta endpoing, i
-000092d0: 6c78 5f20 666f 7220 7072 6f64 7563 7469  lx_ for producti
-000092e0: 6f6e 0a20 2020 2023 7072 6566 6978 203d  on.    #prefix =
-000092f0: 2027 696c 7827 0a20 2020 2023 2066 6f72   'ilx'.    # for
-00009300: 2062 6574 6120 7465 7374 696e 670a 2020   beta testing.  
-00009310: 2020 7072 6566 6978 203d 2049 4e54 4552    prefix = INTER
-00009320: 4c45 585f 5052 4546 4958 0a20 2020 2074  LEX_PREFIX.    t
-00009330: 6d70 203d 2069 6c78 5f6f 626a 2e61 6464  mp = ilx_obj.add
-00009340: 5f70 6465 286c 6162 656c 3d6c 6162 656c  _pde(label=label
-00009350: 2c20 6465 6669 6e69 7469 6f6e 3d64 6566  , definition=def
-00009360: 696e 6974 696f 6e29 0a20 2020 2072 6574  inition).    ret
-00009370: 7572 6e20 746d 700a 6465 6620 6c6f 6164  urn tmp.def load
-00009380: 5f6e 6964 6d5f 7465 726d 735f 636f 6e63  _nidm_terms_conc
-00009390: 6570 7473 2829 3a0a 2020 2020 2727 270a  epts():.    '''.
-000093a0: 2020 2020 5468 6973 2066 756e 6374 696f      This functio
-000093b0: 6e20 7769 6c6c 2070 756c 6c20 4e49 444d  n will pull NIDM
-000093c0: 2d54 6572 6d73 2075 7365 6420 636f 6e63  -Terms used conc
-000093d0: 6570 7473 2066 726f 6d20 7468 6520 4e49  epts from the NI
-000093e0: 444d 2d54 6572 6d73 2072 6570 6f2e 2054  DM-Terms repo. T
-000093f0: 6865 7365 2061 7265 2063 6f6e 6365 7074  hese are concept
-00009400: 7320 7573 6564 2069 6e20 616e 6e6f 7461  s used in annota
-00009410: 7469 6e67 0a20 2020 206f 7468 6572 2064  ting.    other d
-00009420: 6174 6173 6574 7320 616e 6420 7368 6f75  atasets and shou
-00009430: 6c64 2062 6520 7573 6564 2070 7269 6f72  ld be used prior
-00009440: 2074 6f20 6272 6f61 6465 6e69 6e67 2074   to broadening t
-00009450: 6865 2073 6561 7263 6820 746f 2049 6e74  he search to Int
-00009460: 6572 4c65 7820 616e 6420 436f 6741 746c  erLex and CogAtl
-00009470: 6173 2063 6f6e 6365 7074 732e 2042 7920  as concepts. By 
-00009480: 7573 696e 6720 7468 6573 650a 2020 2020  using these.    
-00009490: 6669 7273 742c 206f 6e65 7320 7468 6174  first, ones that
-000094a0: 2068 6176 6520 616c 7265 6164 7920 6265   have already be
-000094b0: 656e 2075 7365 6420 746f 2061 6e6e 6f74  en used to annot
-000094c0: 6174 6520 6461 7461 7365 7473 2c20 7765  ate datasets, we
-000094d0: 206d 6178 696d 697a 6520 6f75 7220 6162   maximize our ab
-000094e0: 696c 6974 7920 746f 2066 696e 6420 636f  ility to find co
-000094f0: 6e63 6570 742d 6261 7365 6420 7175 6572  ncept-based quer
-00009500: 790a 2020 2020 6d61 7463 6865 7320 6163  y.    matches ac
-00009510: 726f 7373 2064 6174 6173 6574 730a 2020  ross datasets.  
-00009520: 2020 3a72 6574 7572 6e3a 0a20 2020 2027    :return:.    '
-00009530: 2727 0a0a 2020 2020 636f 6e63 6570 745f  ''..    concept_
-00009540: 7572 6c20 3d20 2268 7474 7073 3a2f 2f72  url = "https://r
-00009550: 6177 2e67 6974 6875 6275 7365 7263 6f6e  aw.githubusercon
-00009560: 7465 6e74 2e63 6f6d 2f4e 4944 4d2d 5465  tent.com/NIDM-Te
-00009570: 726d 732f 7465 726d 732f 6d61 7374 6572  rms/terms/master
-00009580: 2f74 6572 6d73 2f4e 4944 4d5f 436f 6e63  /terms/NIDM_Conc
-00009590: 6570 7473 2e6a 736f 6e6c 6422 0a0a 0a20  epts.jsonld"... 
-000095a0: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
-000095b0: 7265 7370 6f6e 7365 203d 2075 726c 6f70  response = urlop
-000095c0: 656e 2863 6f6e 6365 7074 5f75 726c 290a  en(concept_url).
-000095d0: 2020 2020 2020 2020 636f 6e63 6570 745f          concept_
-000095e0: 6772 6170 6820 3d20 6a73 6f6e 2e6c 6f61  graph = json.loa
-000095f0: 6473 2872 6573 706f 6e73 652e 7265 6164  ds(response.read
-00009600: 2829 2e64 6563 6f64 6528 2275 7466 2d38  ().decode("utf-8
-00009610: 2229 290a 2020 2020 6578 6365 7074 2045  ")).    except E
-00009620: 7863 6570 7469 6f6e 3a0a 2020 2020 2020  xception:.      
-00009630: 2020 6c6f 6767 696e 672e 696e 666f 2822    logging.info("
-00009640: 4572 726f 7220 6f70 656e 696e 6720 2573  Error opening %s
-00009650: 2075 7365 6420 636f 6e63 6570 7473 2066   used concepts f
-00009660: 696c 652e 2e63 6f6e 7469 6e75 696e 6722  ile..continuing"
-00009670: 2025 2063 6f6e 6365 7074 5f75 726c 290a   % concept_url).
-00009680: 2020 2020 2020 2020 7265 7475 726e 204e          return N
-00009690: 6f6e 650a 0a20 2020 2072 6574 7572 6e20  one..    return 
-000096a0: 636f 6e63 6570 745f 6772 6170 680a 0a0a  concept_graph...
-000096b0: 6465 6620 6c6f 6164 5f6e 6964 6d5f 6f77  def load_nidm_ow
-000096c0: 6c5f 6669 6c65 7328 293a 0a20 2020 2027  l_files():.    '
-000096d0: 2727 0a20 2020 2054 6869 7320 6675 6e63  ''.    This func
-000096e0: 7469 6f6e 206c 6f61 6473 2074 6865 204e  tion loads the N
-000096f0: 4944 4d2d 6578 7065 7269 6d65 6e74 2072  IDM-experiment r
-00009700: 656c 6174 6564 204f 574c 2066 696c 6573  elated OWL files
-00009710: 2061 6e64 2069 6d70 6f72 7473 2c20 6372   and imports, cr
-00009720: 6561 7465 7320 6120 756e 696f 6e20 6772  eates a union gr
-00009730: 6170 6820 616e 6420 7265 7475 726e 7320  aph and returns 
-00009740: 6974 2e0a 2020 2020 3a72 6574 7572 6e3a  it..    :return:
-00009750: 2067 7261 7068 206f 6620 616c 6c20 4f57   graph of all OW
-00009760: 4c20 6669 6c65 7320 616e 6420 696d 706f  L files and impo
-00009770: 7274 7320 6672 6f6d 2050 794e 4944 4d20  rts from PyNIDM 
-00009780: 6578 7065 7269 6d65 6e74 0a20 2020 2027  experiment.    '
-00009790: 2727 0a20 2020 2023 6c6f 6164 206e 6964  ''.    #load nid
-000097a0: 6d2d 6578 7065 7269 6d65 6e74 2e6f 776c  m-experiment.owl
-000097b0: 2066 696c 6520 616e 6420 616c 6c20 696d   file and all im
-000097c0: 706f 7274 7320 6469 7265 6374 6c79 0a20  ports directly. 
-000097d0: 2020 2023 6372 6561 7465 2065 6d70 7479     #create empty
-000097e0: 2067 7261 7068 0a20 2020 2075 6e69 6f6e   graph.    union
-000097f0: 5f67 7261 7068 203d 2047 7261 7068 2829  _graph = Graph()
-00009800: 0a0a 0a20 2020 2023 2320 434f 4d4d 454e  ...    ## COMMEN
-00009810: 5445 4420 4f55 5420 4259 2044 424b 2028  TED OUT BY DBK (
-00009820: 352f 3133 2f32 3129 2e20 4348 414e 4749  5/13/21). CHANGI
-00009830: 4e47 2054 4f20 4745 5420 4f57 4c20 4649  NG TO GET OWL FI
-00009840: 4c45 5320 4449 5245 4354 4f52 5920 4652  LES DIRECTORY FR
-00009850: 4f4d 204e 4944 4d2d 5350 4543 5320 5245  OM NIDM-SPECS RE
-00009860: 504f 0a20 2020 2023 0a20 2020 2023 6368  PO.    #.    #ch
-00009870: 6563 6b20 6966 2074 6865 7265 2069 7320  eck if there is 
-00009880: 616e 2069 6e74 6572 6e65 7420 636f 6e6e  an internet conn
-00009890: 6563 7469 6f6e 2c20 6966 2073 6f20 6c6f  ection, if so lo
-000098a0: 6164 2064 6972 6563 746c 7920 6672 6f6d  ad directly from
-000098b0: 2068 7474 7073 3a2f 2f67 6974 6875 622e   https://github.
-000098c0: 636f 6d2f 696e 6366 2d6e 6964 6173 682f  com/incf-nidash/
-000098d0: 6e69 646d 2d73 7065 6373 2f74 7265 652f  nidm-specs/tree/
-000098e0: 6d61 7374 6572 2f6e 6964 6d2f 6e69 646d  master/nidm/nidm
-000098f0: 2d65 7870 6572 696d 656e 742f 7465 726d  -experiment/term
-00009900: 7320 616e 640a 2020 2020 2362 6173 6570  s and.    #basep
-00009910: 6174 683d 6f73 2e70 6174 682e 6469 726e  ath=os.path.dirn
-00009920: 616d 6528 6f73 2e70 6174 682e 6469 726e  ame(os.path.dirn
-00009930: 616d 6528 5f5f 6669 6c65 5f5f 2929 0a20  ame(__file__)). 
-00009940: 2020 2023 7465 726d 735f 7061 7468 203d     #terms_path =
-00009950: 206f 732e 7061 7468 2e6a 6f69 6e28 6261   os.path.join(ba
-00009960: 7365 7061 7468 2c22 7465 726d 7322 290a  sepath,"terms").
-00009970: 2020 2020 2369 6d70 6f72 7473 5f70 6174      #imports_pat
-00009980: 683d 6f73 2e70 6174 682e 6a6f 696e 2862  h=os.path.join(b
-00009990: 6173 6570 6174 682c 2274 6572 6d73 222c  asepath,"terms",
-000099a0: 2269 6d70 6f72 7473 2229 0a20 2020 2023  "imports").    #
-000099b0: 0a20 2020 2023 696d 706f 7274 733d 5b0a  .    #imports=[.
-000099c0: 2020 2020 2320 2020 2020 2020 2022 6372      #        "cr
-000099d0: 7970 746f 5f69 6d70 6f72 742e 7474 6c22  ypto_import.ttl"
-000099e0: 2c0a 2020 2020 2320 2020 2020 2020 2022  ,.    #        "
-000099f0: 6463 5f69 6d70 6f72 742e 7474 6c22 2c0a  dc_import.ttl",.
-00009a00: 2020 2020 2320 2020 2020 2020 2022 6961      #        "ia
-00009a10: 6f5f 696d 706f 7274 2e74 746c 222c 0a20  o_import.ttl",. 
-00009a20: 2020 2023 2020 2020 2020 2020 226e 666f     #        "nfo
-00009a30: 5f69 6d70 6f72 742e 7474 6c22 2c0a 2020  _import.ttl",.  
-00009a40: 2020 2320 2020 2020 2020 2022 6e6c 785f    #        "nlx_
-00009a50: 696d 706f 7274 2e74 746c 222c 0a20 2020  import.ttl",.   
-00009a60: 2023 2020 2020 2020 2020 226f 6269 5f69   #        "obi_i
-00009a70: 6d70 6f72 742e 7474 6c22 2c0a 2020 2020  mport.ttl",.    
-00009a80: 2320 2020 2020 2020 2022 6f6e 746f 6e65  #        "ontone
-00009a90: 7572 6f6c 6f67 5f69 6e73 7472 756d 656e  urolog_instrumen
-00009aa0: 7473 5f69 6d70 6f72 742e 7474 6c22 2c0a  ts_import.ttl",.
-00009ab0: 2020 2020 2320 2020 2020 2020 2022 7061      #        "pa
-00009ac0: 746f 5f69 6d70 6f72 742e 7474 6c22 2c0a  to_import.ttl",.
-00009ad0: 2020 2020 2320 2020 2020 2020 2022 7072      #        "pr
-00009ae0: 765f 696d 706f 7274 2e74 746c 222c 0a20  v_import.ttl",. 
-00009af0: 2020 2023 2020 2020 2020 2020 2271 6962     #        "qib
-00009b00: 6f5f 696d 706f 7274 2e74 746c 222c 0a20  o_import.ttl",. 
-00009b10: 2020 2023 2020 2020 2020 2020 2273 696f     #        "sio
-00009b20: 5f69 6d70 6f72 742e 7474 6c22 2c0a 2020  _import.ttl",.  
-00009b30: 2020 2320 2020 2020 2020 2022 7374 6174    #        "stat
-00009b40: 6f5f 696d 706f 7274 2e74 746c 220a 2020  o_import.ttl".  
-00009b50: 2020 235d 0a0a 2020 2020 2323 6c6f 6164    #]..    ##load
-00009b60: 2065 6163 6820 696d 706f 7274 0a20 2020   each import.   
-00009b70: 2023 666f 7220 7265 736f 7572 6365 2069   #for resource i
-00009b80: 6e20 696d 706f 7274 733a 0a20 2020 2023  n imports:.    #
-00009b90: 2020 2020 7465 6d70 5f67 7261 7068 203d      temp_graph =
-00009ba0: 2047 7261 7068 2829 0a20 2020 2023 2020   Graph().    #  
-00009bb0: 2020 7472 793a 0a20 2020 2023 0a20 2020    try:.    #.   
-00009bc0: 2023 2020 2020 2020 2020 7465 6d70 5f67   #        temp_g
-00009bd0: 7261 7068 2e70 6172 7365 286f 732e 7061  raph.parse(os.pa
-00009be0: 7468 2e6a 6f69 6e28 696d 706f 7274 735f  th.join(imports_
-00009bf0: 7061 7468 2c72 6573 6f75 7263 6529 2c66  path,resource),f
-00009c00: 6f72 6d61 743d 2274 7572 746c 6522 290a  ormat="turtle").
-00009c10: 2020 2020 2320 2020 2020 2020 2075 6e69      #        uni
-00009c20: 6f6e 5f67 7261 7068 3d75 6e69 6f6e 5f67  on_graph=union_g
-00009c30: 7261 7068 2b74 656d 705f 6772 6170 680a  raph+temp_graph.
-00009c40: 2020 2020 230a 2020 2020 2320 2020 2065      #.    #    e
-00009c50: 7863 6570 7420 4578 6365 7074 696f 6e3a  xcept Exception:
-00009c60: 0a20 2020 2023 2020 2020 2020 2020 6c6f  .    #        lo
-00009c70: 6767 696e 672e 696e 666f 2822 4572 726f  gging.info("Erro
-00009c80: 7220 6f70 656e 696e 6720 2573 2069 6d70  r opening %s imp
-00009c90: 6f72 7420 6669 6c65 2e2e 636f 6e74 696e  ort file..contin
-00009ca0: 7569 6e67 2220 256f 732e 7061 7468 2e6a  uing" %os.path.j
-00009cb0: 6f69 6e28 696d 706f 7274 735f 7061 7468  oin(imports_path
-00009cc0: 2c72 6573 6f75 7263 6529 290a 2020 2020  ,resource)).    
-00009cd0: 2320 2020 2020 2020 2063 6f6e 7469 6e75  #        continu
-00009ce0: 650a 0a20 2020 206f 776c 733d 5b0a 2020  e..    owls=[.  
-00009cf0: 2020 2020 2020 2020 2020 2268 7474 7073            "https
-00009d00: 3a2f 2f72 6177 2e67 6974 6875 6275 7365  ://raw.githubuse
-00009d10: 7263 6f6e 7465 6e74 2e63 6f6d 2f69 6e63  rcontent.com/inc
-00009d20: 662d 6e69 6461 7368 2f6e 6964 6d2d 7370  f-nidash/nidm-sp
-00009d30: 6563 732f 6d61 7374 6572 2f6e 6964 6d2f  ecs/master/nidm/
-00009d40: 6e69 646d 2d65 7870 6572 696d 656e 742f  nidm-experiment/
-00009d50: 696d 706f 7274 732f 6372 7970 746f 5f69  imports/crypto_i
-00009d60: 6d70 6f72 742e 7474 6c22 2c0a 2020 2020  mport.ttl",.    
-00009d70: 2020 2020 2020 2020 2268 7474 7073 3a2f          "https:/
-00009d80: 2f72 6177 2e67 6974 6875 6275 7365 7263  /raw.githubuserc
-00009d90: 6f6e 7465 6e74 2e63 6f6d 2f69 6e63 662d  ontent.com/incf-
-00009da0: 6e69 6461 7368 2f6e 6964 6d2d 7370 6563  nidash/nidm-spec
-00009db0: 732f 6d61 7374 6572 2f6e 6964 6d2f 6e69  s/master/nidm/ni
-00009dc0: 646d 2d65 7870 6572 696d 656e 742f 696d  dm-experiment/im
-00009dd0: 706f 7274 732f 6463 5f69 6d70 6f72 742e  ports/dc_import.
-00009de0: 7474 6c22 2c0a 2020 2020 2020 2020 2020  ttl",.          
-00009df0: 2020 2268 7474 7073 3a2f 2f72 6177 2e67    "https://raw.g
-00009e00: 6974 6875 6275 7365 7263 6f6e 7465 6e74  ithubusercontent
-00009e10: 2e63 6f6d 2f69 6e63 662d 6e69 6461 7368  .com/incf-nidash
-00009e20: 2f6e 6964 6d2d 7370 6563 732f 6d61 7374  /nidm-specs/mast
-00009e30: 6572 2f6e 6964 6d2f 6e69 646d 2d65 7870  er/nidm/nidm-exp
-00009e40: 6572 696d 656e 742f 696d 706f 7274 732f  eriment/imports/
-00009e50: 6469 636f 6d5f 696d 706f 7274 2e74 746c  dicom_import.ttl
-00009e60: 222c 0a20 2020 2020 2020 2020 2020 2022  ",.            "
-00009e70: 6874 7470 733a 2f2f 7261 772e 6769 7468  https://raw.gith
-00009e80: 7562 7573 6572 636f 6e74 656e 742e 636f  ubusercontent.co
-00009e90: 6d2f 696e 6366 2d6e 6964 6173 682f 6e69  m/incf-nidash/ni
-00009ea0: 646d 2d73 7065 6373 2f6d 6173 7465 722f  dm-specs/master/
-00009eb0: 6e69 646d 2f6e 6964 6d2d 6578 7065 7269  nidm/nidm-experi
-00009ec0: 6d65 6e74 2f69 6d70 6f72 7473 2f69 616f  ment/imports/iao
-00009ed0: 5f69 6d70 6f72 742e 7474 6c22 2c0a 2020  _import.ttl",.  
-00009ee0: 2020 2020 2020 2020 2020 2268 7474 7073            "https
-00009ef0: 3a2f 2f72 6177 2e67 6974 6875 6275 7365  ://raw.githubuse
-00009f00: 7263 6f6e 7465 6e74 2e63 6f6d 2f69 6e63  rcontent.com/inc
-00009f10: 662d 6e69 6461 7368 2f6e 6964 6d2d 7370  f-nidash/nidm-sp
-00009f20: 6563 732f 6d61 7374 6572 2f6e 6964 6d2f  ecs/master/nidm/
-00009f30: 6e69 646d 2d65 7870 6572 696d 656e 742f  nidm-experiment/
-00009f40: 696d 706f 7274 732f 6e66 6f5f 696d 706f  imports/nfo_impo
-00009f50: 7274 2e74 746c 222c 0a20 2020 2020 2020  rt.ttl",.       
-00009f60: 2020 2020 2022 6874 7470 733a 2f2f 7261       "https://ra
-00009f70: 772e 6769 7468 7562 7573 6572 636f 6e74  w.githubusercont
-00009f80: 656e 742e 636f 6d2f 696e 6366 2d6e 6964  ent.com/incf-nid
-00009f90: 6173 682f 6e69 646d 2d73 7065 6373 2f6d  ash/nidm-specs/m
-00009fa0: 6173 7465 722f 6e69 646d 2f6e 6964 6d2d  aster/nidm/nidm-
-00009fb0: 6578 7065 7269 6d65 6e74 2f69 6d70 6f72  experiment/impor
-00009fc0: 7473 2f6f 6269 5f69 6d70 6f72 742e 7474  ts/obi_import.tt
-00009fd0: 6c22 2c0a 2020 2020 2020 2020 2020 2020  l",.            
-00009fe0: 2268 7474 7073 3a2f 2f72 6177 2e67 6974  "https://raw.git
-00009ff0: 6875 6275 7365 7263 6f6e 7465 6e74 2e63  hubusercontent.c
-0000a000: 6f6d 2f69 6e63 662d 6e69 6461 7368 2f6e  om/incf-nidash/n
-0000a010: 6964 6d2d 7370 6563 732f 6d61 7374 6572  idm-specs/master
-0000a020: 2f6e 6964 6d2f 6e69 646d 2d65 7870 6572  /nidm/nidm-exper
-0000a030: 696d 656e 742f 696d 706f 7274 732f 6f6e  iment/imports/on
-0000a040: 746f 6e65 7572 6f6c 6f67 5f69 6e73 7472  toneurolog_instr
-0000a050: 756d 656e 7473 5f69 6d70 6f72 742e 7474  uments_import.tt
-0000a060: 6c22 2c0a 2020 2020 2020 2020 2020 2020  l",.            
-0000a070: 2268 7474 7073 3a2f 2f72 6177 2e67 6974  "https://raw.git
-0000a080: 6875 6275 7365 7263 6f6e 7465 6e74 2e63  hubusercontent.c
-0000a090: 6f6d 2f69 6e63 662d 6e69 6461 7368 2f6e  om/incf-nidash/n
-0000a0a0: 6964 6d2d 7370 6563 732f 6d61 7374 6572  idm-specs/master
-0000a0b0: 2f6e 6964 6d2f 6e69 646d 2d65 7870 6572  /nidm/nidm-exper
-0000a0c0: 696d 656e 742f 696d 706f 7274 732f 7061  iment/imports/pa
-0000a0d0: 746f 5f69 6d70 6f72 742e 7474 6c22 2c0a  to_import.ttl",.
-0000a0e0: 2020 2020 2020 2020 2020 2020 2268 7474              "htt
-0000a0f0: 7073 3a2f 2f72 6177 2e67 6974 6875 6275  ps://raw.githubu
-0000a100: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f69  sercontent.com/i
-0000a110: 6e63 662d 6e69 6461 7368 2f6e 6964 6d2d  ncf-nidash/nidm-
-0000a120: 7370 6563 732f 6d61 7374 6572 2f6e 6964  specs/master/nid
-0000a130: 6d2f 6e69 646d 2d65 7870 6572 696d 656e  m/nidm-experimen
-0000a140: 742f 696d 706f 7274 732f 7061 746f 5f69  t/imports/pato_i
-0000a150: 6d70 6f72 742e 7474 6c22 2c0a 2020 2020  mport.ttl",.    
-0000a160: 2020 2020 2020 2020 2268 7474 7073 3a2f          "https:/
-0000a170: 2f72 6177 2e67 6974 6875 6275 7365 7263  /raw.githubuserc
-0000a180: 6f6e 7465 6e74 2e63 6f6d 2f69 6e63 662d  ontent.com/incf-
-0000a190: 6e69 6461 7368 2f6e 6964 6d2d 7370 6563  nidash/nidm-spec
-0000a1a0: 732f 6d61 7374 6572 2f6e 6964 6d2f 6e69  s/master/nidm/ni
-0000a1b0: 646d 2d65 7870 6572 696d 656e 742f 696d  dm-experiment/im
-0000a1c0: 706f 7274 732f 7072 765f 696d 706f 7274  ports/prv_import
-0000a1d0: 2e74 746c 222c 0a20 2020 2020 2020 2020  .ttl",.         
-0000a1e0: 2020 2022 6874 7470 733a 2f2f 7261 772e     "https://raw.
-0000a1f0: 6769 7468 7562 7573 6572 636f 6e74 656e  githubuserconten
-0000a200: 742e 636f 6d2f 696e 6366 2d6e 6964 6173  t.com/incf-nidas
-0000a210: 682f 6e69 646d 2d73 7065 6373 2f6d 6173  h/nidm-specs/mas
-0000a220: 7465 722f 6e69 646d 2f6e 6964 6d2d 6578  ter/nidm/nidm-ex
-0000a230: 7065 7269 6d65 6e74 2f69 6d70 6f72 7473  periment/imports
-0000a240: 2f73 696f 5f69 6d70 6f72 742e 7474 6c22  /sio_import.ttl"
-0000a250: 2c0a 2020 2020 2020 2020 2020 2020 2268  ,.            "h
-0000a260: 7474 7073 3a2f 2f72 6177 2e67 6974 6875  ttps://raw.githu
-0000a270: 6275 7365 7263 6f6e 7465 6e74 2e63 6f6d  busercontent.com
-0000a280: 2f69 6e63 662d 6e69 6461 7368 2f6e 6964  /incf-nidash/nid
-0000a290: 6d2d 7370 6563 732f 6d61 7374 6572 2f6e  m-specs/master/n
-0000a2a0: 6964 6d2f 6e69 646d 2d65 7870 6572 696d  idm/nidm-experim
-0000a2b0: 656e 742f 7465 726d 732f 6e69 646d 2d65  ent/terms/nidm-e
-0000a2c0: 7870 6572 696d 656e 742e 6f77 6c22 2c0a  xperiment.owl",.
-0000a2d0: 2020 2020 2020 2020 2020 2020 2268 7474              "htt
-0000a2e0: 7073 3a2f 2f72 6177 2e67 6974 6875 6275  ps://raw.githubu
-0000a2f0: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f69  sercontent.com/i
-0000a300: 6e63 662d 6e69 6461 7368 2f6e 6964 6d2d  ncf-nidash/nidm-
-0000a310: 7370 6563 732f 6d61 7374 6572 2f6e 6964  specs/master/nid
-0000a320: 6d2f 6e69 646d 2d72 6573 756c 7473 2f74  m/nidm-results/t
-0000a330: 6572 6d73 2f6e 6964 6d2d 7265 7375 6c74  erms/nidm-result
-0000a340: 732e 6f77 6c22 0a20 2020 205d 0a0a 2020  s.owl".    ]..  
-0000a350: 2020 236c 6f61 6420 6561 6368 206f 776c    #load each owl
-0000a360: 2066 696c 650a 2020 2020 666f 7220 7265   file.    for re
-0000a370: 736f 7572 6365 2069 6e20 6f77 6c73 3a0a  source in owls:.
-0000a380: 2020 2020 2020 2020 7465 6d70 5f67 7261          temp_gra
-0000a390: 7068 203d 2047 7261 7068 2829 0a20 2020  ph = Graph().   
-0000a3a0: 2020 2020 2074 7279 3a0a 2020 2020 2020       try:.      
-0000a3b0: 2020 2020 2020 7465 6d70 5f67 7261 7068        temp_graph
-0000a3c0: 2e70 6172 7365 286c 6f63 6174 696f 6e3d  .parse(location=
-0000a3d0: 7265 736f 7572 6365 2c20 666f 726d 6174  resource, format
-0000a3e0: 3d22 7475 7274 6c65 2229 0a20 2020 2020  ="turtle").     
-0000a3f0: 2020 2020 2020 2075 6e69 6f6e 5f67 7261         union_gra
-0000a400: 7068 3d75 6e69 6f6e 5f67 7261 7068 2b74  ph=union_graph+t
-0000a410: 656d 705f 6772 6170 680a 2020 2020 2020  emp_graph.      
-0000a420: 2020 6578 6365 7074 2045 7863 6570 7469    except Excepti
-0000a430: 6f6e 3a0a 2020 2020 2020 2020 2020 2020  on:.            
-0000a440: 6c6f 6767 696e 672e 696e 666f 2822 4572  logging.info("Er
-0000a450: 726f 7220 6f70 656e 696e 6720 2573 206f  ror opening %s o
-0000a460: 776c 2066 696c 652e 2e63 6f6e 7469 6e75  wl file..continu
-0000a470: 696e 6722 2025 7265 736f 7572 6365 290a  ing" %resource).
-0000a480: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-0000a490: 696e 7565 0a0a 0a20 2020 2072 6574 7572  inue...    retur
-0000a4a0: 6e20 756e 696f 6e5f 6772 6170 680a 0a0a  n union_graph...
-0000a4b0: 0a64 6566 2066 757a 7a79 5f6d 6174 6368  .def fuzzy_match
-0000a4c0: 5f74 6572 6d73 5f66 726f 6d5f 6772 6170  _terms_from_grap
-0000a4d0: 6828 6772 6170 682c 7175 6572 795f 7374  h(graph,query_st
-0000a4e0: 7269 6e67 293a 0a20 2020 2027 2727 0a20  ring):.    '''. 
-0000a4f0: 2020 2054 6869 7320 6675 6e63 7469 6f6e     This function
-0000a500: 2070 6572 666f 726d 7320 6120 6675 7a7a   performs a fuzz
-0000a510: 7920 6d61 7463 6820 6f66 2074 6865 2063  y match of the c
-0000a520: 6f6e 7374 616e 7473 2069 6e20 436f 6e73  onstants in Cons
-0000a530: 7461 6e74 732e 7079 206c 6973 7420 6e69  tants.py list ni
-0000a540: 646d 5f65 7870 6572 696d 656e 745f 7465  dm_experiment_te
-0000a550: 726d 7320 666f 7220 7465 726d 2063 6f6e  rms for term con
-0000a560: 7374 616e 7473 206d 6174 6368 696e 6720  stants matching 
-0000a570: 7468 6520 7175 6572 792e 2e2e 2e69 0a20  the query....i. 
-0000a580: 2020 2069 6465 616c 6c79 2074 6869 7320     ideally this 
-0000a590: 7368 6f75 6c64 2072 6561 6c6c 7920 6265  should really be
-0000a5a0: 2073 6561 7263 6869 6e67 2074 6865 204f   searching the O
-0000a5b0: 574c 2066 696c 6520 7768 656e 2069 7427  WL file when it'
-0000a5c0: 7320 7265 6164 790a 2020 2020 3a70 6172  s ready.    :par
-0000a5d0: 616d 2071 7565 7279 5f73 7472 696e 673a  am query_string:
-0000a5e0: 2073 7472 696e 6720 746f 2071 7565 7279   string to query
-0000a5f0: 0a20 2020 203a 7265 7475 726e 3a20 6469  .    :return: di
-0000a600: 6374 696f 6e61 7279 2077 686f 7365 206b  ctionary whose k
-0000a610: 6579 2069 7320 7468 6520 4e49 444d 2063  ey is the NIDM c
-0000a620: 6f6e 7374 616e 7420 616e 6420 7661 6c75  onstant and valu
-0000a630: 6520 6973 2074 6865 206d 6174 6368 2073  e is the match s
-0000a640: 636f 7265 2074 6f20 7468 6520 7175 6572  core to the quer
-0000a650: 790a 2020 2020 2727 270a 0a0a 2020 2020  y.    '''...    
-0000a660: 6d61 7463 685f 7363 6f72 6573 3d7b 7d0a  match_scores={}.
-0000a670: 0a20 2020 2023 7365 6172 6368 2066 6f72  .    #search for
-0000a680: 206c 6162 656c 7320 7264 6673 3a6c 6162   labels rdfs:lab
-0000a690: 656c 2061 6e64 206f 626f 3a49 414f 5f30  el and obo:IAO_0
-0000a6a0: 3030 3031 3135 2028 6465 7363 7269 7074  000115 (descript
-0000a6b0: 696f 6e29 2066 6f72 2065 6163 6820 7264  ion) for each rd
-0000a6c0: 663a 7479 7065 206f 776c 3a43 6c61 7373  f:type owl:Class
-0000a6d0: 0a20 2020 2066 6f72 2074 6572 6d20 696e  .    for term in
-0000a6e0: 2067 7261 7068 2e73 7562 6a65 6374 7328   graph.subjects(
-0000a6f0: 7072 6564 6963 6174 653d 5244 462e 7479  predicate=RDF.ty
-0000a700: 7065 2c20 6f62 6a65 6374 3d43 6f6e 7374  pe, object=Const
-0000a710: 616e 7473 2e4f 574c 5b22 436c 6173 7322  ants.OWL["Class"
-0000a720: 5d29 3a0a 2020 2020 2020 2020 666f 7220  ]):.        for 
-0000a730: 6c61 6265 6c20 696e 2067 7261 7068 2e6f  label in graph.o
-0000a740: 626a 6563 7473 2873 7562 6a65 6374 3d74  bjects(subject=t
-0000a750: 6572 6d2c 2070 7265 6469 6361 7465 3d43  erm, predicate=C
-0000a760: 6f6e 7374 616e 7473 2e52 4446 535b 276c  onstants.RDFS['l
-0000a770: 6162 656c 275d 293a 0a20 2020 2020 2020  abel']):.       
-0000a780: 2020 2020 206d 6174 6368 5f73 636f 7265       match_score
-0000a790: 735b 7465 726d 5d20 3d20 7b7d 0a20 2020  s[term] = {}.   
-0000a7a0: 2020 2020 2020 2020 206d 6174 6368 5f73           match_s
-0000a7b0: 636f 7265 735b 7465 726d 5d5b 2773 636f  cores[term]['sco
-0000a7c0: 7265 275d 203d 2066 757a 7a2e 746f 6b65  re'] = fuzz.toke
-0000a7d0: 6e5f 736f 7274 5f72 6174 696f 2871 7565  n_sort_ratio(que
-0000a7e0: 7279 5f73 7472 696e 672c 6c61 6265 6c29  ry_string,label)
-0000a7f0: 0a20 2020 2020 2020 2020 2020 206d 6174  .            mat
-0000a800: 6368 5f73 636f 7265 735b 7465 726d 5d5b  ch_scores[term][
-0000a810: 276c 6162 656c 275d 203d 206c 6162 656c  'label'] = label
-0000a820: 0a20 2020 2020 2020 2020 2020 206d 6174  .            mat
-0000a830: 6368 5f73 636f 7265 735b 7465 726d 5d5b  ch_scores[term][
-0000a840: 2775 726c 275d 203d 2074 6572 6d0a 2020  'url'] = term.  
-0000a850: 2020 2020 2020 2020 2020 6d61 7463 685f            match_
-0000a860: 7363 6f72 6573 5b74 6572 6d5d 5b27 6465  scores[term]['de
-0000a870: 6669 6e69 7469 6f6e 275d 3d4e 6f6e 650a  finition']=None.
-0000a880: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-0000a890: 6465 7363 7269 7074 696f 6e20 696e 2067  description in g
-0000a8a0: 7261 7068 2e6f 626a 6563 7473 2873 7562  raph.objects(sub
-0000a8b0: 6a65 6374 3d74 6572 6d2c 7072 6564 6963  ject=term,predic
-0000a8c0: 6174 653d 436f 6e73 7461 6e74 732e 4f42  ate=Constants.OB
-0000a8d0: 4f5b 2249 414f 5f30 3030 3031 3135 225d  O["IAO_0000115"]
-0000a8e0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-0000a8f0: 2020 206d 6174 6368 5f73 636f 7265 735b     match_scores[
-0000a900: 7465 726d 5d5b 2764 6566 696e 6974 696f  term]['definitio
-0000a910: 6e27 5d20 3d64 6573 6372 6970 7469 6f6e  n'] =description
-0000a920: 0a0a 2020 2020 2366 6f72 2074 6572 6d20  ..    #for term 
-0000a930: 696e 206f 776c 5f67 7261 7068 2e63 6c61  in owl_graph.cla
-0000a940: 7373 6573 2829 3a0a 2020 2020 2320 2020  sses():.    #   
-0000a950: 2070 7269 6e74 2874 6572 6d2e 6765 745f   print(term.get_
-0000a960: 7072 6f70 6572 7469 6573 2829 290a 2020  properties()).  
-0000a970: 2020 7265 7475 726e 206d 6174 6368 5f73    return match_s
-0000a980: 636f 7265 730a 0a64 6566 2066 757a 7a79  cores..def fuzzy
-0000a990: 5f6d 6174 6368 5f63 6f6e 6365 7074 735f  _match_concepts_
-0000a9a0: 6672 6f6d 5f6e 6964 6d74 6572 6d73 5f6a  from_nidmterms_j
-0000a9b0: 736f 6e6c 6428 6a73 6f6e 5f73 7472 7563  sonld(json_struc
-0000a9c0: 742c 7175 6572 795f 7374 7269 6e67 293a  t,query_string):
-0000a9d0: 0a20 2020 206d 6174 6368 5f73 636f 7265  .    match_score
-0000a9e0: 7320 3d20 7b7d 0a0a 2020 2020 2320 7365  s = {}..    # se
-0000a9f0: 6172 6368 2066 6f72 206c 6162 656c 7320  arch for labels 
-0000aa00: 7264 6673 3a6c 6162 656c 2061 6e64 206f  rdfs:label and o
-0000aa10: 626f 3a49 414f 5f30 3030 3031 3135 2028  bo:IAO_0000115 (
-0000aa20: 6465 7363 7269 7074 696f 6e29 2066 6f72  description) for
-0000aa30: 2065 6163 6820 7264 663a 7479 7065 206f   each rdf:type o
-0000aa40: 776c 3a43 6c61 7373 0a20 2020 2066 6f72  wl:Class.    for
-0000aa50: 2065 6e74 7279 2069 6e20 6a73 6f6e 5f73   entry in json_s
-0000aa60: 7472 7563 745b 2774 6572 6d73 275d 3a0a  truct['terms']:.
-0000aa70: 2020 2020 2020 2020 6d61 7463 685f 7363          match_sc
-0000aa80: 6f72 6573 5b65 6e74 7279 5b27 6c61 6265  ores[entry['labe
-0000aa90: 6c27 5d5d 203d 207b 7d0a 2020 2020 2020  l']] = {}.      
-0000aaa0: 2020 6d61 7463 685f 7363 6f72 6573 5b65    match_scores[e
-0000aab0: 6e74 7279 5b27 6c61 6265 6c27 5d5d 5b27  ntry['label']]['
-0000aac0: 7363 6f72 6527 5d20 3d20 6675 7a7a 2e74  score'] = fuzz.t
-0000aad0: 6f6b 656e 5f73 6f72 745f 7261 7469 6f28  oken_sort_ratio(
-0000aae0: 7175 6572 795f 7374 7269 6e67 2c20 656e  query_string, en
-0000aaf0: 7472 795b 276c 6162 656c 275d 290a 2020  try['label']).  
-0000ab00: 2020 2020 2020 6d61 7463 685f 7363 6f72        match_scor
-0000ab10: 6573 5b65 6e74 7279 5b27 6c61 6265 6c27  es[entry['label'
-0000ab20: 5d5d 5b27 6c61 6265 6c27 5d20 3d20 656e  ]]['label'] = en
-0000ab30: 7472 795b 276c 6162 656c 275d 0a20 2020  try['label'].   
-0000ab40: 2020 2020 2069 6620 2273 6368 656d 613a       if "schema:
-0000ab50: 7572 6c22 2069 6e20 656e 7472 792e 6b65  url" in entry.ke
-0000ab60: 7973 2829 3a0a 2020 2020 2020 2020 2020  ys():.          
-0000ab70: 2020 6d61 7463 685f 7363 6f72 6573 5b65    match_scores[e
-0000ab80: 6e74 7279 5b27 6c61 6265 6c27 5d5d 5b27  ntry['label']]['
-0000ab90: 7572 6c27 5d20 3d20 656e 7472 795b 2273  url'] = entry["s
-0000aba0: 6368 656d 613a 7572 6c22 5d0a 2020 2020  chema:url"].    
-0000abb0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-0000abc0: 2020 2020 2020 6d61 7463 685f 7363 6f72        match_scor
-0000abd0: 6573 5b65 6e74 7279 5b27 6c61 6265 6c27  es[entry['label'
-0000abe0: 5d5d 5b27 7572 6c27 5d20 3d20 2222 0a20  ]]['url'] = "". 
-0000abf0: 2020 2020 2020 2069 6620 2764 6573 6372         if 'descr
-0000ac00: 6970 7469 6f6e 2720 696e 2065 6e74 7279  iption' in entry
-0000ac10: 2e6b 6579 7328 293a 0a20 2020 2020 2020  .keys():.       
-0000ac20: 2020 2020 206d 6174 6368 5f73 636f 7265       match_score
-0000ac30: 735b 656e 7472 795b 276c 6162 656c 275d  s[entry['label']
-0000ac40: 5d5b 2764 6566 696e 6974 696f 6e27 5d20  ]['definition'] 
-0000ac50: 3d20 656e 7472 795b 2764 6573 6372 6970  = entry['descrip
-0000ac60: 7469 6f6e 275d 0a20 2020 2020 2020 2065  tion'].        e
-0000ac70: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-0000ac80: 206d 6174 6368 5f73 636f 7265 735b 656e   match_scores[en
-0000ac90: 7472 795b 276c 6162 656c 275d 5d5b 2764  try['label']]['d
-0000aca0: 6566 696e 6974 696f 6e27 5d20 3d20 2222  efinition'] = ""
-0000acb0: 0a0a 2020 2020 2320 666f 7220 7465 726d  ..    # for term
-0000acc0: 2069 6e20 6f77 6c5f 6772 6170 682e 636c   in owl_graph.cl
-0000acd0: 6173 7365 7328 293a 0a20 2020 2023 2020  asses():.    #  
-0000ace0: 2020 7072 696e 7428 7465 726d 2e67 6574    print(term.get
-0000acf0: 5f70 726f 7065 7274 6965 7328 2929 0a20  _properties()). 
-0000ad00: 2020 2072 6574 7572 6e20 6d61 7463 685f     return match_
-0000ad10: 7363 6f72 6573 0a0a 6465 6620 6675 7a7a  scores..def fuzz
-0000ad20: 795f 6d61 7463 685f 7465 726d 735f 6672  y_match_terms_fr
-0000ad30: 6f6d 5f63 6f67 6174 6c61 735f 6a73 6f6e  om_cogatlas_json
-0000ad40: 286a 736f 6e5f 7374 7275 6374 2c71 7565  (json_struct,que
-0000ad50: 7279 5f73 7472 696e 6729 3a0a 0a20 2020  ry_string):..   
-0000ad60: 206d 6174 6368 5f73 636f 7265 733d 7b7d   match_scores={}
-0000ad70: 0a0a 2020 2020 2373 6561 7263 6820 666f  ..    #search fo
-0000ad80: 7220 6c61 6265 6c73 2072 6466 733a 6c61  r labels rdfs:la
-0000ad90: 6265 6c20 616e 6420 6f62 6f3a 4941 4f5f  bel and obo:IAO_
-0000ada0: 3030 3030 3131 3520 2864 6573 6372 6970  0000115 (descrip
-0000adb0: 7469 6f6e 2920 666f 7220 6561 6368 2072  tion) for each r
-0000adc0: 6466 3a74 7970 6520 6f77 6c3a 436c 6173  df:type owl:Clas
-0000add0: 730a 2020 2020 666f 7220 656e 7472 7920  s.    for entry 
-0000ade0: 696e 206a 736f 6e5f 7374 7275 6374 3a0a  in json_struct:.
-0000adf0: 0a20 2020 2020 2020 206d 6174 6368 5f73  .        match_s
-0000ae00: 636f 7265 735b 656e 7472 795b 276e 616d  cores[entry['nam
-0000ae10: 6527 5d5d 203d 207b 7d0a 2020 2020 2020  e']] = {}.      
-0000ae20: 2020 6d61 7463 685f 7363 6f72 6573 5b65    match_scores[e
-0000ae30: 6e74 7279 5b27 6e61 6d65 275d 5d5b 2773  ntry['name']]['s
-0000ae40: 636f 7265 275d 203d 2066 757a 7a2e 746f  core'] = fuzz.to
-0000ae50: 6b65 6e5f 736f 7274 5f72 6174 696f 2871  ken_sort_ratio(q
-0000ae60: 7565 7279 5f73 7472 696e 672c 656e 7472  uery_string,entr
-0000ae70: 795b 276e 616d 6527 5d29 0a20 2020 2020  y['name']).     
-0000ae80: 2020 206d 6174 6368 5f73 636f 7265 735b     match_scores[
-0000ae90: 656e 7472 795b 276e 616d 6527 5d5d 5b27  entry['name']]['
-0000aea0: 6c61 6265 6c27 5d20 3d20 656e 7472 795b  label'] = entry[
-0000aeb0: 276e 616d 6527 5d0a 2020 2020 2020 2020  'name'].        
-0000aec0: 6d61 7463 685f 7363 6f72 6573 5b65 6e74  match_scores[ent
-0000aed0: 7279 5b27 6e61 6d65 275d 5d5b 2775 726c  ry['name']]['url
-0000aee0: 275d 203d 2022 6874 7470 733a 2f2f 7777  '] = "https://ww
-0000aef0: 772e 636f 676e 6974 6976 6561 746c 6173  w.cognitiveatlas
-0000af00: 2e6f 7267 2f63 6f6e 6365 7074 2f69 642f  .org/concept/id/
-0000af10: 2220 2b20 656e 7472 795b 2769 6427 5d0a  " + entry['id'].
-0000af20: 2020 2020 2020 2020 6d61 7463 685f 7363          match_sc
-0000af30: 6f72 6573 5b65 6e74 7279 5b27 6e61 6d65  ores[entry['name
-0000af40: 275d 5d5b 2764 6566 696e 6974 696f 6e27  ']]['definition'
-0000af50: 5d3d 656e 7472 795b 2764 6566 696e 6974  ]=entry['definit
-0000af60: 696f 6e5f 7465 7874 275d 0a0a 2020 2020  ion_text']..    
-0000af70: 2366 6f72 2074 6572 6d20 696e 206f 776c  #for term in owl
-0000af80: 5f67 7261 7068 2e63 6c61 7373 6573 2829  _graph.classes()
-0000af90: 3a0a 2020 2020 2320 2020 2070 7269 6e74  :.    #    print
-0000afa0: 2874 6572 6d2e 6765 745f 7072 6f70 6572  (term.get_proper
-0000afb0: 7469 6573 2829 290a 2020 2020 7265 7475  ties()).    retu
-0000afc0: 726e 206d 6174 6368 5f73 636f 7265 730a  rn match_scores.
-0000afd0: 0a64 6566 2061 7574 6865 6e74 6963 6174  .def authenticat
-0000afe0: 655f 6769 7468 7562 2861 7574 6865 643d  e_github(authed=
-0000aff0: 4e6f 6e65 2c63 7265 6465 6e74 6961 6c73  None,credentials
-0000b000: 3d4e 6f6e 6529 3a0a 2020 2020 2727 270a  =None):.    '''.
-0000b010: 2020 2020 5468 6973 2066 756e 6374 696f      This functio
-0000b020: 6e20 7769 6c6c 2068 616e 676c 6520 4769  n will hangle Gi
-0000b030: 7448 7562 2061 7574 6865 6e74 6963 6174  tHub authenticat
-0000b040: 696f 6e20 7769 7468 206f 7220 7769 7468  ion with or with
-0000b050: 6f75 7420 6120 746f 6b65 6e2e 2020 4966  out a token.  If
-0000b060: 2074 6865 2070 6172 616d 6574 6572 2061   the parameter a
-0000b070: 7574 6865 6420 6973 2064 6566 696e 6564  uthed is defined
-0000b080: 2074 6865 0a20 2020 2066 756e 6374 696f   the.    functio
-0000b090: 6e20 7769 6c6c 2063 6865 636b 2077 6865  n will check whe
-0000b0a0: 7468 6572 2069 7427 7320 616e 2061 6374  ther it's an act
-0000b0b0: 6976 652f 7661 6c69 6465 2061 7574 6865  ive/valide authe
-0000b0c0: 6e74 6963 6174 696f 6e20 6f62 6a65 6374  ntication object
-0000b0d0: 2e20 2049 6620 6e6f 742c 2061 6e64 2075  .  If not, and u
-0000b0e0: 7365 726e 616d 652f 746f 6b65 6e20 6973  sername/token is
-0000b0f0: 2073 7570 706c 6965 6420 7468 656e 0a20   supplied then. 
-0000b100: 2020 2061 6e20 6175 7468 656e 7469 6361     an authentica
-0000b110: 7469 6f6e 206f 626a 6563 7420 7769 6c6c  tion object will
-0000b120: 2062 6520 6372 6561 7465 642e 2020 4966   be created.  If
-0000b130: 2075 7365 726e 616d 6520 2b20 746f 6b65   username + toke
-0000b140: 6e20 6973 206e 6f74 2073 7570 706c 6965  n is not supplie
-0000b150: 6420 7468 656e 2074 6865 2075 7365 7220  d then the user 
-0000b160: 7769 6c6c 2062 6520 7072 6f6d 7074 6564  will be prompted
-0000b170: 2074 6f20 696e 7075 740a 2020 2020 7468   to input.    th
-0000b180: 6520 696e 666f 726d 6174 696f 6e2e 0a20  e information.. 
-0000b190: 2020 203a 7061 7261 6d20 6175 7468 6564     :param authed
-0000b1a0: 3a20 4f70 7469 6f6e 616c 2061 7574 6865  : Optional authe
-0000b1b0: 6e74 6963 6169 6f6e 206f 626a 6563 7420  nticaion object 
-0000b1c0: 6672 6f6d 2050 7947 6974 6875 620a 2020  from PyGithub.  
-0000b1d0: 2020 3a70 6172 616d 2063 7265 6465 6e74    :param credent
-0000b1e0: 6961 6c73 3a20 4f70 7469 6f6e 616c 2047  ials: Optional G
-0000b1f0: 6974 4875 6220 6372 6564 656e 7469 616c  itHub credential
-0000b200: 206c 6973 7420 7573 6572 6e61 6d65 2c70   list username,p
-0000b210: 6173 7377 6f72 6420 6f72 2075 7365 726e  assword or usern
-0000b220: 616d 652c 746f 6b65 6e0a 2020 2020 3a72  ame,token.    :r
-0000b230: 6574 7572 6e3a 2047 6974 4875 6220 6175  eturn: GitHub au
-0000b240: 7468 656e 7469 6361 7469 6f6e 206f 626a  thentication obj
-0000b250: 6563 7420 6f72 204e 6f6e 6520 6966 2075  ect or None if u
-0000b260: 6e73 7563 6365 7373 6675 6c0a 0a20 2020  nsuccessful..   
-0000b270: 2027 2727 0a0a 2020 2020 7072 696e 7428   '''..    print(
-0000b280: 2247 6974 4875 6220 6175 7468 656e 7469  "GitHub authenti
-0000b290: 6361 7469 6f6e 2e2e 2e22 290a 2020 2020  cation...").    
-0000b2a0: 696e 6478 3d31 0a20 2020 206d 6178 7472  indx=1.    maxtr
-0000b2b0: 793d 350a 2020 2020 7768 696c 6520 696e  y=5.    while in
-0000b2c0: 6478 203c 206d 6178 7472 793a 0a20 2020  dx < maxtry:.   
-0000b2d0: 2020 2020 2069 6620 286c 656e 2863 7265       if (len(cre
-0000b2e0: 6465 6e74 6961 6c73 293e 3d20 3229 3a0a  dentials)>= 2):.
-0000b2f0: 2020 2020 2020 2020 2020 2020 2361 7574              #aut
-0000b300: 6865 6e74 6963 6174 6520 7769 7468 2074  henticate with t
-0000b310: 6f6b 656e 0a20 2020 2020 2020 2020 2020  oken.           
-0000b320: 2067 3d47 6974 6875 6228 6372 6564 656e   g=Github(creden
-0000b330: 7469 616c 735b 305d 2c63 7265 6465 6e74  tials[0],credent
-0000b340: 6961 6c73 5b31 5d29 0a20 2020 2020 2020  ials[1]).       
-0000b350: 2065 6c69 6620 286c 656e 2863 7265 6465   elif (len(crede
-0000b360: 6e74 6961 6c73 293d 3d31 293a 0a20 2020  ntials)==1):.   
-0000b370: 2020 2020 2020 2020 2070 7720 3d20 6765           pw = ge
-0000b380: 7470 6173 732e 6765 7470 6173 7328 2250  tpass.getpass("P
-0000b390: 6c65 6173 6520 656e 7465 7220 796f 7572  lease enter your
-0000b3a0: 2047 6974 4875 6220 7061 7373 776f 7264   GitHub password
-0000b3b0: 3a20 2229 0a20 2020 2020 2020 2020 2020  : ").           
-0000b3c0: 2067 3d47 6974 6875 6228 6372 6564 656e   g=Github(creden
-0000b3d0: 7469 616c 735b 305d 2c70 7729 0a20 2020  tials[0],pw).   
-0000b3e0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-0000b3f0: 2020 2020 2020 2075 7365 726e 616d 6520         username 
-0000b400: 3d20 696e 7075 7428 2250 6c65 6173 6520  = input("Please 
-0000b410: 656e 7465 7220 796f 7572 2047 6974 4875  enter your GitHu
-0000b420: 6220 7573 6572 206e 616d 653a 2022 290a  b user name: ").
-0000b430: 2020 2020 2020 2020 2020 2020 7077 203d              pw =
-0000b440: 2067 6574 7061 7373 2e67 6574 7061 7373   getpass.getpass
-0000b450: 2822 506c 6561 7365 2065 6e74 6572 2079  ("Please enter y
-0000b460: 6f75 7220 4769 7448 7562 2070 6173 7377  our GitHub passw
-0000b470: 6f72 643a 2022 290a 2020 2020 2020 2020  ord: ").        
-0000b480: 2020 2020 2374 7279 2074 6f20 6c6f 6767      #try to logg
-0000b490: 696e 6720 696e 746f 2047 6974 4875 620a  ing into GitHub.
-0000b4a0: 2020 2020 2020 2020 2020 2020 673d 4769              g=Gi
-0000b4b0: 7468 7562 2875 7365 726e 616d 652c 7077  thub(username,pw
-0000b4c0: 290a 0a20 2020 2020 2020 2061 7574 6865  )..        authe
-0000b4d0: 643d 672e 6765 745f 7573 6572 2829 0a20  d=g.get_user(). 
-0000b4e0: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-0000b4f0: 2020 2020 2020 2020 2363 6865 636b 2077          #check w
-0000b500: 6527 7265 206c 6f67 6765 6420 696e 2062  e're logged in b
-0000b510: 7920 6368 6563 6b69 6e67 2074 6861 7420  y checking that 
-0000b520: 7765 2063 616e 2061 6363 6573 7320 7468  we can access th
-0000b530: 6520 7075 626c 6963 2072 6570 6f73 206c  e public repos l
-0000b540: 6973 740a 2020 2020 2020 2020 2020 2020  ist.            
-0000b550: 7265 706f 3d61 7574 6865 642e 7075 626c  repo=authed.publ
-0000b560: 6963 5f72 6570 6f73 0a20 2020 2020 2020  ic_repos.       
-0000b570: 2020 2020 206c 6f67 6769 6e67 2e69 6e66       logging.inf
-0000b580: 6f28 2247 6974 6875 6220 6175 7468 656e  o("Github authen
-0000b590: 7469 6361 7469 6f6e 2073 7563 6365 7373  tication success
-0000b5a0: 6675 6c22 290a 2020 2020 2020 2020 2020  ful").          
-0000b5b0: 2020 6e65 775f 7465 726d 3d46 616c 7365    new_term=False
-0000b5c0: 0a20 2020 2020 2020 2020 2020 2062 7265  .            bre
-0000b5d0: 616b 0a20 2020 2020 2020 2065 7863 6570  ak.        excep
-0000b5e0: 7420 4769 7468 7562 4578 6365 7074 696f  t GithubExceptio
-0000b5f0: 6e20 6173 2065 3a0a 2020 2020 2020 2020  n as e:.        
-0000b600: 2020 2020 6c6f 6767 696e 672e 696e 666f      logging.info
-0000b610: 2822 6572 726f 7220 6c6f 6767 696e 6720  ("error logging 
-0000b620: 696e 746f 2079 6f75 7220 6769 7468 7562  into your github
-0000b630: 2061 6363 6f75 6e74 2c20 706c 6561 7365   account, please
-0000b640: 2074 7279 2061 6761 696e 2e2e 2e22 290a   try again...").
-0000b650: 2020 2020 2020 2020 2020 2020 696e 6478              indx
-0000b660: 3d69 6e64 782b 310a 0a20 2020 2069 6620  =indx+1..    if 
-0000b670: 2869 6e64 7820 3d3d 206d 6178 7472 7929  (indx == maxtry)
-0000b680: 3a0a 2020 2020 2020 2020 6c6f 6767 696e  :.        loggin
-0000b690: 672e 6372 6974 6963 616c 2822 4769 7448  g.critical("GitH
-0000b6a0: 7562 2061 7574 6865 6e74 6963 6174 696f  ub authenticatio
-0000b6b0: 6e20 6661 696c 6564 2e20 2043 6865 636b  n failed.  Check
-0000b6c0: 2079 6f75 7220 7573 6572 6e61 6d65 202f   your username /
-0000b6d0: 2070 6173 7377 6f72 6420 2f20 746f 6b65   password / toke
-0000b6e0: 6e20 616e 6420 7472 7920 6167 6169 6e22  n and try again"
-0000b6f0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-0000b700: 204e 6f6e 650a 2020 2020 656c 7365 3a0a   None.    else:.
-0000b710: 2020 2020 2020 2020 7265 7475 726e 2061          return a
-0000b720: 7574 6865 642c 670a 0a64 6566 2067 6574  uthed,g..def get
-0000b730: 5375 626a 4944 436f 6c75 6d6e 2863 6f6c  SubjIDColumn(col
-0000b740: 756d 6e5f 746f 5f74 6572 6d73 2c64 6629  umn_to_terms,df)
-0000b750: 3a0a 2020 2020 2727 270a 2020 2020 5468  :.    '''.    Th
-0000b760: 6973 2066 756e 6374 696f 6e20 7265 7475  is function retu
-0000b770: 726e 7320 636f 6c75 6d6e 206e 756d 6265  rns column numbe
-0000b780: 7220 6672 6f6d 2043 5356 2066 696c 6520  r from CSV file 
-0000b790: 7468 6174 206d 6174 6368 6573 2073 7562  that matches sub
-0000b7a0: 6a69 642e 2020 4966 2069 7420 6361 6e27  jid.  If it can'
-0000b7b0: 7420 6175 746f 6d61 7469 6361 6c6c 790a  t automatically.
-0000b7c0: 2020 2020 6465 7465 6374 2069 7420 6261      detect it ba
-0000b7d0: 7365 6420 6f6e 2074 6865 2043 6f6e 7374  sed on the Const
-0000b7e0: 616e 7473 2e4e 4944 4d5f 5355 424a 4543  ants.NIDM_SUBJEC
-0000b7f0: 5449 4420 7465 726d 2028 692e 652e 2069  TID term (i.e. i
-0000b800: 6620 7468 6520 7573 6572 2073 656c 6563  f the user selec
-0000b810: 7465 6420 6120 6469 6666 6572 656e 7420  ted a different 
-0000b820: 7465 726d 0a20 2020 2074 6f20 616e 6e6f  term.    to anno
-0000b830: 7461 7465 2073 7562 6a65 6374 2049 4420  tate subject ID 
-0000b840: 7468 656e 2069 7420 6173 6b73 2074 6865  then it asks the
-0000b850: 2075 7365 722e 0a20 2020 203a 7061 7261   user..    :para
-0000b860: 6d20 636f 6c75 6d6e 5f74 6f5f 7465 726d  m column_to_term
-0000b870: 733a 206a 736f 6e20 7661 7269 6162 6c65  s: json variable
-0000b880: 2d3e 7465 726d 206d 6170 7069 6e67 2064  ->term mapping d
-0000b890: 6963 7469 6f6e 6172 7920 6d61 6465 2062  ictionary made b
-0000b8a0: 7920 6e69 646d 2e65 7870 6572 696d 656e  y nidm.experimen
-0000b8b0: 742e 5574 696c 732e 6d61 705f 7661 7269  t.Utils.map_vari
-0000b8c0: 6162 6c65 735f 746f 5f74 6572 6d73 0a20  ables_to_terms. 
-0000b8d0: 2020 203a 7061 7261 6d20 6466 3a20 6461     :param df: da
-0000b8e0: 7461 6672 616d 6520 6f66 2043 5356 2066  taframe of CSV f
-0000b8f0: 696c 6520 7769 7468 2074 6162 756c 6172  ile with tabular
-0000b900: 2064 6174 6120 746f 2063 6f6e 7665 7274   data to convert
-0000b910: 2074 6f20 5244 462e 0a20 2020 203a 7265   to RDF..    :re
-0000b920: 7475 726e 3a20 7375 626a 6563 7420 4944  turn: subject ID
-0000b930: 2063 6f6c 756d 6e20 6e75 6d62 6572 2069   column number i
-0000b940: 6e20 4353 5620 6461 7461 6672 616d 650a  n CSV dataframe.
-0000b950: 2020 2020 2727 270a 0a20 2020 2023 6c6f      '''..    #lo
-0000b960: 6f6b 2061 7420 636f 6c75 6d6e 5f74 6f5f  ok at column_to_
-0000b970: 7465 726d 7320 6469 6374 696f 6e61 7279  terms dictionary
-0000b980: 2066 6f72 204e 4944 4d20 5552 4c20 666f   for NIDM URL fo
-0000b990: 7220 7375 626a 6563 7420 6964 2020 2843  r subject id  (C
-0000b9a0: 6f6e 7374 616e 7473 2e4e 4944 4d5f 5355  onstants.NIDM_SU
-0000b9b0: 424a 4543 5449 4429 0a20 2020 2069 645f  BJECTID).    id_
-0000b9c0: 6669 656c 643d 4e6f 6e65 0a20 2020 2066  field=None.    f
-0000b9d0: 6f72 206b 6579 2c20 7661 6c75 6520 696e  or key, value in
-0000b9e0: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
-0000b9f0: 2e69 7465 6d73 2829 3a0a 2020 2020 2020  .items():.      
-0000ba00: 2020 6966 2043 6f6e 7374 616e 7473 2e4e    if Constants.N
-0000ba10: 4944 4d5f 5355 424a 4543 5449 442e 5f73  IDM_SUBJECTID._s
-0000ba20: 7472 203d 3d20 636f 6c75 6d6e 5f74 6f5f  tr == column_to_
-0000ba30: 7465 726d 735b 6b65 795d 5b27 6c61 6265  terms[key]['labe
-0000ba40: 6c27 5d3a 0a20 2020 2020 2020 2020 2020  l']:.           
-0000ba50: 2069 645f 6669 656c 643d 6b65 790a 0a20   id_field=key.. 
-0000ba60: 2020 2023 6966 2077 6520 636f 756c 646e     #if we couldn
-0000ba70: 2774 2066 696e 6420 6120 7375 626a 6563  't find a subjec
-0000ba80: 7420 4944 2066 6965 6c64 2069 6e20 636f  t ID field in co
-0000ba90: 6c75 6d6e 5f74 6f5f 7465 726d 732c 2061  lumn_to_terms, a
-0000baa0: 736b 2075 7365 720a 2020 2020 6966 2069  sk user.    if i
-0000bab0: 645f 6669 656c 6420 6973 204e 6f6e 653a  d_field is None:
-0000bac0: 0a20 2020 2020 2020 206f 7074 696f 6e3d  .        option=
-0000bad0: 310a 2020 2020 2020 2020 666f 7220 636f  1.        for co
-0000bae0: 6c75 6d6e 2069 6e20 6466 2e63 6f6c 756d  lumn in df.colum
-0000baf0: 6e73 3a0a 2020 2020 2020 2020 2020 2020  ns:.            
-0000bb00: 7072 696e 7428 2225 643a 2025 7322 2025  print("%d: %s" %
-0000bb10: 286f 7074 696f 6e2c 636f 6c75 6d6e 2929  (option,column))
-0000bb20: 0a20 2020 2020 2020 2020 2020 206f 7074  .            opt
-0000bb30: 696f 6e3d 6f70 7469 6f6e 2b31 0a20 2020  ion=option+1.   
-0000bb40: 2020 2020 2073 656c 6563 7469 6f6e 3d69       selection=i
-0000bb50: 6e70 7574 2822 506c 6561 7365 2073 656c  nput("Please sel
-0000bb60: 6563 7420 7468 6520 7375 626a 6563 7420  ect the subject 
-0000bb70: 4944 2066 6965 6c64 2066 726f 6d20 7468  ID field from th
-0000bb80: 6520 6c69 7374 2061 626f 7665 3a20 2229  e list above: ")
-0000bb90: 0a20 2020 2020 2020 2069 645f 6669 656c  .        id_fiel
-0000bba0: 643d 6466 2e63 6f6c 756d 6e73 5b69 6e74  d=df.columns[int
-0000bbb0: 2873 656c 6563 7469 6f6e 292d 315d 0a20  (selection)-1]. 
-0000bbc0: 2020 2072 6574 7572 6e20 6964 5f66 6965     return id_fie
-0000bbd0: 6c64 0a0a 6465 6620 7265 6463 6170 5f64  ld..def redcap_d
-0000bbe0: 6174 6164 6963 7469 6f6e 6172 795f 746f  atadictionary_to
-0000bbf0: 5f6a 736f 6e28 7265 6463 6170 5f64 645f  _json(redcap_dd_
-0000bc00: 6669 6c65 2c61 7373 6573 736d 656e 745f  file,assessment_
-0000bc10: 6e61 6d65 293a 0a20 2020 2027 2727 0a20  name):.    '''. 
-0000bc20: 2020 2054 6869 7320 6675 6e63 7469 6f6e     This function
-0000bc30: 2077 696c 6c20 636f 6e76 6572 7420 6120   will convert a 
-0000bc40: 7265 6463 6170 2064 6174 6120 6469 6374  redcap data dict
-0000bc50: 696f 6e61 7279 2074 6f20 6f75 7220 6a73  ionary to our js
-0000bc60: 6f6e 2064 6174 6120 656c 656d 656e 7473  on data elements
-0000bc70: 2073 7472 7563 7475 7265 0a20 2020 203a   structure.    :
-0000bc80: 7061 7261 6d20 7265 6463 6170 5f64 643a  param redcap_dd:
-0000bc90: 2052 6564 4361 7020 6461 7461 2064 6963   RedCap data dic
-0000bca0: 7469 6f6e 6172 790a 2020 2020 3a72 6574  tionary.    :ret
-0000bcb0: 7572 6e3a 206a 736f 6e20 6461 7461 2065  urn: json data e
-0000bcc0: 6c65 6d65 6e74 2064 6566 696e 7469 6f6e  lement defintion
-0000bcd0: 730a 2020 2020 2727 270a 0a20 2020 2023  s.    '''..    #
-0000bce0: 206c 6f61 6420 7265 6463 6170 2064 6174   load redcap dat
-0000bcf0: 6120 6469 6374 696f 6e61 7279 0a20 2020  a dictionary.   
-0000bd00: 2072 6564 6361 705f 6464 203d 2070 642e   redcap_dd = pd.
-0000bd10: 7265 6164 5f63 7376 2872 6564 6361 705f  read_csv(redcap_
-0000bd20: 6464 5f66 696c 6529 0a0a 2020 2020 6a73  dd_file)..    js
-0000bd30: 6f6e 5f6d 6170 3d7b 7d0a 0a20 2020 2023  on_map={}..    #
-0000bd40: 2063 7963 6c65 2074 6872 6f75 6768 2072   cycle through r
-0000bd50: 6f77 7320 616e 6420 7374 6f72 6520 7661  ows and store va
-0000bd60: 7269 6162 6c65 2064 6174 6120 656c 656d  riable data elem
-0000bd70: 656e 7473 0a20 2020 2066 6f72 2069 6e64  ents.    for ind
-0000bd80: 6578 2c72 6f77 2069 6e20 7265 6463 6170  ex,row in redcap
-0000bd90: 5f64 642e 6974 6572 726f 7773 2829 3a0a  _dd.iterrows():.
-0000bda0: 2020 2020 2020 2020 6375 7272 656e 745f          current_
-0000bdb0: 7475 706c 6520 3d20 7374 7228 4444 2873  tuple = str(DD(s
-0000bdc0: 6f75 7263 653d 6173 7365 7373 6d65 6e74  ource=assessment
-0000bdd0: 5f6e 616d 652c 2076 6172 6961 626c 653d  _name, variable=
-0000bde0: 726f 775b 2756 6172 6961 626c 6520 2f20  row['Variable / 
-0000bdf0: 4669 656c 6420 4e61 6d65 275d 2929 0a20  Field Name'])). 
-0000be00: 2020 2020 2020 206a 736f 6e5f 6d61 705b         json_map[
-0000be10: 6375 7272 656e 745f 7475 706c 655d 203d  current_tuple] =
-0000be20: 207b 7d0a 2020 2020 2020 2020 6a73 6f6e   {}.        json
-0000be30: 5f6d 6170 5b63 7572 7265 6e74 5f74 7570  _map[current_tup
-0000be40: 6c65 5d5b 276c 6162 656c 275d 203d 2072  le]['label'] = r
-0000be50: 6f77 5b27 5661 7269 6162 6c65 202f 2046  ow['Variable / F
-0000be60: 6965 6c64 204e 616d 6527 5d0a 2020 2020  ield Name'].    
-0000be70: 2020 2020 6a73 6f6e 5f6d 6170 5b63 7572      json_map[cur
-0000be80: 7265 6e74 5f74 7570 6c65 5d5b 2773 6f75  rent_tuple]['sou
-0000be90: 7263 655f 7661 7269 6162 6c65 275d 203d  rce_variable'] =
-0000bea0: 2072 6f77 5b27 5661 7269 6162 6c65 202f   row['Variable /
-0000beb0: 2046 6965 6c64 204e 616d 6527 5d0a 2020   Field Name'].  
-0000bec0: 2020 2020 2020 6a73 6f6e 5f6d 6170 5b63        json_map[c
-0000bed0: 7572 7265 6e74 5f74 7570 6c65 5d5b 2764  urrent_tuple]['d
-0000bee0: 6573 6372 6970 7469 6f6e 275d 203d 2072  escription'] = r
-0000bef0: 6f77 5b27 4669 656c 6420 4c61 6265 6c27  ow['Field Label'
-0000bf00: 5d0a 2020 2020 2020 2020 6966 206e 6f74  ].        if not
-0000bf10: 2070 642e 6973 6e75 6c6c 2872 6f77 5b27   pd.isnull(row['
-0000bf20: 4368 6f69 6365 7320 4f52 2043 616c 6375  Choices OR Calcu
-0000bf30: 6c61 7469 6f6e 7327 5d29 3a0a 2020 2020  lations']):.    
-0000bf40: 2020 2020 2020 2020 6966 2072 6f77 5b27          if row['
-0000bf50: 4669 656c 6420 5479 7065 275d 203d 3d20  Field Type'] == 
-0000bf60: 2763 616c 6327 3a0a 2020 2020 2020 2020  'calc':.        
-0000bf70: 2020 2020 2020 2020 2320 7468 6973 2069          # this i
-0000bf80: 7320 6120 6361 6c63 756c 6174 6564 2066  s a calculated f
-0000bf90: 6965 6c64 2073 6f20 6974 2074 7970 6963  ield so it typic
-0000bfa0: 616c 6c79 2068 6173 2061 2073 756d 285b  ally has a sum([
-0000bfb0: 7661 7231 5d2c 5b76 6172 325d 2c2e 2e2c  var1],[var2],..,
-0000bfc0: 6574 6329 2073 6f20 7765 276c 6c20 6a75  etc) so we'll ju
-0000bfd0: 7374 2073 746f 7265 0a20 2020 2020 2020  st store.       
-0000bfe0: 2020 2020 2020 2020 2023 2069 7420 6861           # it ha
-0000bff0: 7320 6173 2061 2073 696e 676c 6520 6c65  s as a single le
-0000c000: 7665 6c0a 2020 2020 2020 2020 2020 2020  vel.            
-0000c010: 2020 2020 6a73 6f6e 5f6d 6170 5b63 7572      json_map[cur
-0000c020: 7265 6e74 5f74 7570 6c65 5d5b 276c 6576  rent_tuple]['lev
-0000c030: 656c 7327 5d20 3d20 5b5d 0a20 2020 2020  els'] = [].     
-0000c040: 2020 2020 2020 2020 2020 206a 736f 6e5f             json_
-0000c050: 6d61 705b 6375 7272 656e 745f 7475 706c  map[current_tupl
-0000c060: 655d 5b27 6c65 7665 6c73 275d 2e61 7070  e]['levels'].app
-0000c070: 656e 6428 7374 7228 726f 775b 2743 686f  end(str(row['Cho
-0000c080: 6963 6573 204f 5220 4361 6c63 756c 6174  ices OR Calculat
-0000c090: 696f 6e73 275d 2929 0a20 2020 2020 2020  ions'])).       
-0000c0a0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-0000c0b0: 2020 2020 2020 2020 2020 2073 706c 6974             split
-0000c0c0: 5f63 686f 6963 6573 203d 2072 6f77 5b27  _choices = row['
-0000c0d0: 4368 6f69 6365 7320 4f52 2043 616c 6375  Choices OR Calcu
-0000c0e0: 6c61 7469 6f6e 7327 5d2e 7370 6c69 7428  lations'].split(
-0000c0f0: 227c 2229 0a20 2020 2020 2020 2020 2020  "|").           
-0000c100: 2020 2020 2069 6620 6c65 6e28 7370 6c69       if len(spli
-0000c110: 745f 6368 6f69 6365 7329 203d 3d20 313a  t_choices) == 1:
-0000c120: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000c130: 2020 2020 206a 736f 6e5f 6d61 705b 6375       json_map[cu
-0000c140: 7272 656e 745f 7475 706c 655d 5b27 6c65  rrent_tuple]['le
-0000c150: 7665 6c73 275d 203d 205b 5d0a 2020 2020  vels'] = [].    
-0000c160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c170: 6a73 6f6e 5f6d 6170 5b63 7572 7265 6e74  json_map[current
-0000c180: 5f74 7570 6c65 5d5b 2776 616c 7565 5479  _tuple]['valueTy
-0000c190: 7065 275d 203d 2055 5249 5265 6628 436f  pe'] = URIRef(Co
-0000c1a0: 6e73 7461 6e74 732e 5853 445b 2263 6f6d  nstants.XSD["com
-0000c1b0: 706c 6578 5479 7065 225d 290a 2020 2020  plexType"]).    
-0000c1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c1d0: 7370 6c69 745f 6368 6f69 6365 7320 3d20  split_choices = 
-0000c1e0: 726f 775b 2743 686f 6963 6573 204f 5220  row['Choices OR 
-0000c1f0: 4361 6c63 756c 6174 696f 6e73 275d 2e73  Calculations'].s
-0000c200: 706c 6974 2822 2c22 290a 2020 2020 2020  plit(",").      
-0000c210: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-0000c220: 7220 6368 6f69 6365 7320 696e 2073 706c  r choices in spl
-0000c230: 6974 5f63 686f 6963 6573 3a0a 2020 2020  it_choices:.    
-0000c240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c250: 2020 2020 6a73 6f6e 5f6d 6170 5b63 7572      json_map[cur
-0000c260: 7265 6e74 5f74 7570 6c65 5d5b 276c 6576  rent_tuple]['lev
-0000c270: 656c 7327 5d2e 6170 7065 6e64 2863 686f  els'].append(cho
-0000c280: 6963 6573 2e73 7472 6970 2829 290a 0a20  ices.strip()).. 
-0000c290: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0000c2a0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-0000c2b0: 2020 2020 2020 2020 206a 736f 6e5f 6d61           json_ma
-0000c2c0: 705b 6375 7272 656e 745f 7475 706c 655d  p[current_tuple]
-0000c2d0: 5b27 6c65 7665 6c73 275d 203d 207b 7d0a  ['levels'] = {}.
-0000c2e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c2f0: 2020 2020 6a73 6f6e 5f6d 6170 5b63 7572      json_map[cur
-0000c300: 7265 6e74 5f74 7570 6c65 5d5b 2776 616c  rent_tuple]['val
-0000c310: 7565 5479 7065 275d 203d 2055 5249 5265  ueType'] = URIRe
-0000c320: 6628 436f 6e73 7461 6e74 732e 5853 445b  f(Constants.XSD[
-0000c330: 2263 6f6d 706c 6578 5479 7065 225d 290a  "complexType"]).
-0000c340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c350: 2020 2020 666f 7220 6368 6f69 6365 7320      for choices 
-0000c360: 696e 2073 706c 6974 5f63 686f 6963 6573  in split_choices
-0000c370: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000c380: 2020 2020 2020 2020 2020 6b65 795f 7661            key_va
-0000c390: 6c75 653d 6368 6f69 6365 732e 7370 6c69  lue=choices.spli
-0000c3a0: 7428 222c 2229 0a20 2020 2020 2020 2020  t(",").         
-0000c3b0: 2020 2020 2020 2020 2020 2020 2020 206a                 j
-0000c3c0: 736f 6e5f 6d61 705b 6375 7272 656e 745f  son_map[current_
-0000c3d0: 7475 706c 655d 5b27 6c65 7665 6c73 275d  tuple]['levels']
-0000c3e0: 5b73 7472 286b 6579 5f76 616c 7565 5b30  [str(key_value[0
-0000c3f0: 5d29 2e73 7472 6970 2829 5d20 3d20 7374  ]).strip()] = st
-0000c400: 7228 6b65 795f 7661 6c75 655b 315d 292e  r(key_value[1]).
-0000c410: 7374 7269 7028 290a 2020 2020 2020 2020  strip().        
-0000c420: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-0000c430: 2020 6a73 6f6e 5f6d 6170 5b63 7572 7265    json_map[curre
-0000c440: 6e74 5f74 7570 6c65 5d5b 2776 616c 7565  nt_tuple]['value
-0000c450: 5479 7065 275d 203d 2055 5249 5265 6628  Type'] = URIRef(
-0000c460: 436f 6e73 7461 6e74 732e 5853 445b 2273  Constants.XSD["s
-0000c470: 7472 696e 6722 5d29 0a0a 2020 2020 7265  tring"])..    re
-0000c480: 7475 726e 206a 736f 6e5f 6d61 700a 0a64  turn json_map..d
-0000c490: 6566 2064 6574 6563 745f 6a73 6f6e 5f66  ef detect_json_f
-0000c4a0: 6f72 6d61 7428 6a73 6f6e 5f6d 6170 293a  ormat(json_map):
-0000c4b0: 0a20 2020 2027 2727 0a20 2020 2054 6869  .    '''.    Thi
-0000c4c0: 7320 6675 6e63 7469 6f6e 2077 696c 6c20  s function will 
-0000c4d0: 7461 6b65 2061 206a 736f 6e20 2273 6964  take a json "sid
-0000c4e0: 6563 6172 2220 6669 6c65 206f 7220 6a73  ecar" file or js
-0000c4f0: 6f6e 2061 6e6e 6f74 6174 696f 6e20 6461  on annotation da
-0000c500: 7461 2064 6963 7469 6f6e 6172 7920 7374  ta dictionary st
-0000c510: 7275 6374 7572 650a 2020 2020 616e 6420  ructure.    and 
-0000c520: 6465 7465 726d 696e 6520 6966 2069 7427  determine if it'
-0000c530: 2773 2063 6f6e 7369 7374 656e 7420 7769  's consistent wi
-0000c540: 7468 2074 6865 2052 6570 726f 5363 6865  th the ReproSche
-0000c550: 6d61 2073 7472 7563 7475 7265 2028 636f  ma structure (co
-0000c560: 6d70 6f75 6e64 206b 6579 7320 726f 6f74  mpound keys root
-0000c570: 2d6c 6576 656c 206b 6579 730a 2020 2020  -level keys.    
-0000c580: 4444 2873 6f75 7263 653d 5858 582c 7661  DD(source=XXX,va
-0000c590: 7269 6162 6c65 3d59 5959 2920 616e 6420  riable=YYY) and 
-0000c5a0: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
-0000c5b0: 2720 7375 626b 6579 7329 2c20 7468 6520  ' subkeys), the 
-0000c5c0: 6f6c 6465 7220 7079 6e69 646d 2066 6f72  older pynidm for
-0000c5d0: 6d61 7420 2863 6f6d 706f 756e 640a 2020  mat (compound.  
-0000c5e0: 2020 6b65 7973 2061 7320 5265 7072 6f53    keys as ReproS
-0000c5f0: 6368 656d 612c 206e 6f20 7265 706f 6e73  chema, no repons
-0000c600: 654f 7074 696f 6e73 2073 7562 6b65 7973  eOptions subkeys
-0000c610: 292c 206f 7220 7468 6520 4249 4453 2073  ), or the BIDS s
-0000c620: 6964 6563 6172 2066 696c 6520 7374 7275  idecar file stru
-0000c630: 6374 7572 650a 2020 2020 2866 6c61 7420  cture.    (flat 
-0000c640: 7374 7275 6374 7572 652c 2076 6172 6961  structure, varia
-0000c650: 626c 6520 6e61 6d65 7320 6173 206b 6579  ble names as key
-0000c660: 732c 206e 6f20 7265 7370 6f6e 7365 206f  s, no response o
-0000c670: 7074 696f 6e73 292e 2020 4974 2077 696c  ptions).  It wil
-0000c680: 6c20 7265 7475 726e 2061 2073 7472 696e  l return a strin
-0000c690: 6720 6173 736f 6369 6174 6564 0a20 2020  g associated.   
-0000c6a0: 2077 6974 6820 7468 6520 7374 7275 6374   with the struct
-0000c6b0: 7572 653a 2042 4944 5320 7c20 4f4c 445f  ure: BIDS | OLD_
-0000c6c0: 5059 4e49 444d 207c 2052 4550 524f 5343  PYNIDM | REPROSC
-0000c6d0: 4845 4d41 0a0a 2020 2020 3a70 6172 616d  HEMA..    :param
-0000c6e0: 206a 736f 6e5f 6d61 703a 206a 736f 6e20   json_map: json 
-0000c6f0: 616e 6e6f 7461 7469 6f6e 2066 696c 6520  annotation file 
-0000c700: 6469 6374 696f 6e61 7279 2028 6669 6c65  dictionary (file
-0000c710: 2061 6c72 6561 6479 206c 6f61 6465 6420   already loaded 
-0000c720: 7769 7468 206a 736f 6e2e 6c6f 6164 290a  with json.load).
-0000c730: 0a20 2020 2027 2727 0a0a 2020 2020 666f  .    '''..    fo
-0000c740: 7220 6b65 792c 7661 6c75 6520 696e 206a  r key,value in j
-0000c750: 736f 6e5f 6d61 702e 6b65 7973 2829 3a0a  son_map.keys():.
-0000c760: 2020 2020 2020 2020 6966 2022 4444 2822          if "DD("
-0000c770: 2069 6e20 6b65 793a 0a20 2020 2020 2020   in key:.       
-0000c780: 2020 2020 2069 6620 2272 6573 706f 6e73       if "respons
-0000c790: 654f 7074 696f 6e73 2220 696e 2076 616c  eOptions" in val
-0000c7a0: 7565 2e6b 6579 7328 293a 0a20 2020 2020  ue.keys():.     
-0000c7b0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-0000c7c0: 6e20 2252 4550 524f 5343 4845 4d41 220a  n "REPROSCHEMA".
-0000c7d0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-0000c7e0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000c7f0: 2020 7265 7475 726e 2022 4f4c 445f 5059    return "OLD_PY
-0000c800: 4e49 444d 220a 2020 2020 2020 2020 656c  NIDM".        el
-0000c810: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-0000c820: 7265 7475 726e 2022 4249 4453 220a 0a64  return "BIDS"..d
-0000c830: 6566 206d 6174 6368 5f70 6172 7469 6369  ef match_partici
-0000c840: 7061 6e74 5f69 645f 6669 656c 6428 736f  pant_id_field(so
-0000c850: 7572 6365 5f76 6172 6961 626c 6529 3a0a  urce_variable):.
-0000c860: 2020 2020 2727 270a 2020 2020 5468 6973      '''.    This
-0000c870: 2066 756e 6374 696f 6e20 7769 6c6c 2074   function will t
-0000c880: 6573 7420 7768 6574 6865 7220 7468 6520  est whether the 
-0000c890: 736f 7572 6365 5f76 6172 6961 626c 6520  source_variable 
-0000c8a0: 6973 2061 2070 6172 7469 6369 7061 6e74  is a participant
-0000c8b0: 2049 4420 6669 656c 6420 6f72 206e 6f74   ID field or not
-0000c8c0: 2062 7920 7374 7269 6e67 206d 6174 6368   by string match
-0000c8d0: 696e 672e 0a20 2020 203a 7061 7261 6d20  ing..    :param 
-0000c8e0: 736f 7572 6365 5f76 6172 6961 626c 653a  source_variable:
-0000c8f0: 2073 6f75 7263 6520 7661 7269 6162 6c65   source variable
-0000c900: 2073 7472 696e 6720 746f 2074 6573 740a   string to test.
-0000c910: 2020 2020 2727 270a 0a20 2020 2069 6620      '''..    if 
-0000c920: 2828 2822 7061 7274 6963 6970 616e 745f  ((("participant_
-0000c930: 6964 2220 696e 2073 6f75 7263 655f 7661  id" in source_va
-0000c940: 7269 6162 6c65 2e6c 6f77 6572 2829 2920  riable.lower()) 
-0000c950: 6f72 0a20 2020 2020 2020 2020 2028 2273  or.          ("s
-0000c960: 7562 6a65 6374 5f69 6422 2069 6e20 736f  ubject_id" in so
-0000c970: 7572 6365 5f76 6172 6961 626c 652e 6c6f  urce_variable.lo
-0000c980: 7765 7228 2929 206f 720a 2020 2020 2020  wer()) or.      
-0000c990: 2020 2020 2828 2270 6172 7469 6369 7061      (("participa
-0000c9a0: 6e74 2220 696e 2073 6f75 7263 655f 7661  nt" in source_va
-0000c9b0: 7269 6162 6c65 2e6c 6f77 6572 2829 2920  riable.lower()) 
-0000c9c0: 616e 6420 2822 6964 2220 696e 2073 6f75  and ("id" in sou
-0000c9d0: 7263 655f 7661 7269 6162 6c65 2e6c 6f77  rce_variable.low
-0000c9e0: 6572 2829 2929 206f 720a 2020 2020 2020  er())) or.      
-0000c9f0: 2020 2020 2828 2273 7562 6a65 6374 2220      (("subject" 
-0000ca00: 696e 2073 6f75 7263 655f 7661 7269 6162  in source_variab
-0000ca10: 6c65 2e6c 6f77 6572 2829 2920 616e 6420  le.lower()) and 
-0000ca20: 2822 6964 2220 696e 2073 6f75 7263 655f  ("id" in source_
-0000ca30: 7661 7269 6162 6c65 2e6c 6f77 6572 2829  variable.lower()
-0000ca40: 2929 206f 720a 2020 2020 2020 2020 2020  )) or.          
-0000ca50: 2828 2273 7562 2220 696e 2073 6f75 7263  (("sub" in sourc
-0000ca60: 655f 7661 7269 6162 6c65 2e6c 6f77 6572  e_variable.lower
-0000ca70: 2829 2920 616e 6420 2822 6964 2220 696e  ()) and ("id" in
-0000ca80: 2073 6f75 7263 655f 7661 7269 6162 6c65   source_variable
-0000ca90: 2e6c 6f77 6572 2829 2929 2929 3a0a 0a20  .lower())))):.. 
-0000caa0: 2020 2020 2020 2072 6574 7572 6e20 5472         return Tr
-0000cab0: 7565 0a20 2020 2065 6c73 653a 0a20 2020  ue.    else:.   
-0000cac0: 2020 2020 2072 6574 7572 6e20 4661 6c73       return Fals
-0000cad0: 650a 0a64 6566 206d 6170 5f76 6172 6961  e..def map_varia
-0000cae0: 626c 6573 5f74 6f5f 7465 726d 7328 6466  bles_to_terms(df
-0000caf0: 2c64 6972 6563 746f 7279 2c20 6173 7365  ,directory, asse
-0000cb00: 7373 6d65 6e74 5f6e 616d 652c 206f 7574  ssment_name, out
-0000cb10: 7075 745f 6669 6c65 3d4e 6f6e 652c 6a73  put_file=None,js
-0000cb20: 6f6e 5f73 6f75 7263 653d 4e6f 6e65 2c62  on_source=None,b
-0000cb30: 6964 733d 4661 6c73 652c 6f77 6c5f 6669  ids=False,owl_fi
-0000cb40: 6c65 3d27 6e69 646d 272c 0a20 2020 2020  le='nidm',.     
-0000cb50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cb60: 2020 2020 2020 6173 736f 6369 6174 655f        associate_
-0000cb70: 636f 6e63 6570 7473 3d54 7275 652c 2064  concepts=True, d
-0000cb80: 6174 6173 6574 5f69 6465 6e74 6966 6965  ataset_identifie
-0000cb90: 723d 4e6f 6e65 293a 0a20 2020 2027 2727  r=None):.    '''
-0000cba0: 0a0a 2020 2020 3a70 6172 616d 2064 663a  ..    :param df:
-0000cbb0: 2064 6174 6120 6672 616d 6520 7769 7468   data frame with
-0000cbc0: 2066 6972 7374 2072 6f77 2063 6f6e 7461   first row conta
-0000cbd0: 696e 696e 6720 7661 7269 6162 6c65 206e  ining variable n
-0000cbe0: 616d 6573 0a20 2020 203a 7061 7261 6d20  ames.    :param 
-0000cbf0: 6173 7365 7373 6d65 6e74 5f6e 616d 653a  assessment_name:
-0000cc00: 204e 616d 6520 666f 7220 7468 6520 6173   Name for the as
-0000cc10: 7365 7373 6d65 6e74 2074 6f20 7573 6520  sessment to use 
-0000cc20: 696e 2073 746f 7269 6e67 204a 534f 4e20  in storing JSON 
-0000cc30: 6d61 7070 696e 6720 6469 6374 696f 6e61  mapping dictiona
-0000cc40: 7279 206b 6579 730a 2020 2020 3a70 6172  ry keys.    :par
-0000cc50: 616d 206a 736f 6e5f 736f 7572 6365 3a20  am json_source: 
-0000cc60: 6f70 7469 6f6e 616c 206a 736f 6e20 646f  optional json do
-0000cc70: 6375 6d65 6e74 2065 6974 6865 7220 696e  cument either in
-0000cc80: 2066 696c 6520 6f72 2073 7472 7563 7475   file or structu
-0000cc90: 7265 0a20 2020 2020 2020 2020 2020 2077  re.            w
-0000cca0: 6974 6820 7661 7269 6162 6c65 206e 616d  ith variable nam
-0000ccb0: 6573 2061 7320 6b65 7973 2061 6e64 206d  es as keys and m
-0000ccc0: 696e 696d 616c 2066 6965 6c64 7320 2264  inimal fields "d
-0000ccd0: 6566 696e 6974 696f 6e22 2c22 6c61 6265  efinition","labe
-0000cce0: 6c22 2c22 7572 6c22 0a20 2020 203a 7061  l","url".    :pa
-0000ccf0: 7261 6d20 6f75 7470 7574 5f66 696c 653a  ram output_file:
-0000cd00: 206f 7574 7075 7420 6669 6c65 6e61 6d65   output filename
-0000cd10: 2074 6f20 7361 7665 2076 6172 6961 626c   to save variabl
-0000cd20: 652d 3e20 7465 726d 206d 6170 7069 6e67  e-> term mapping
-0000cd30: 730a 2020 2020 3a70 6172 616d 2064 6972  s.    :param dir
-0000cd40: 6563 746f 7279 3a20 6966 206f 7574 7075  ectory: if outpu
-0000cd50: 745f 6669 6c65 2070 6172 616d 6574 6572  t_file parameter
-0000cd60: 2069 7320 7365 7420 746f 204e 6f6e 6520   is set to None 
-0000cd70: 7468 656e 2075 7365 2074 6869 7320 6469  then use this di
-0000cd80: 7265 6374 6f72 7920 746f 2073 746f 7265  rectory to store
-0000cd90: 2064 6566 6175 6c74 204a 534f 4e20 6d61   default JSON ma
-0000cda0: 7070 696e 6720 6669 6c65 0a20 2020 2069  pping file.    i
-0000cdb0: 6620 646f 696e 6720 7661 7269 6162 6c65  f doing variable
-0000cdc0: 2d3e 7465 726d 206d 6170 7069 6e67 730a  ->term mappings.
-0000cdd0: 2020 2020 3a72 6574 7572 6e3a 7265 7475      :return:retu
-0000cde0: 726e 2064 6963 7469 6f6e 6172 7920 6d61  rn dictionary ma
-0000cdf0: 7070 696e 6720 7661 7269 6162 6c65 206e  pping variable n
-0000ce00: 616d 6573 2028 692e 652e 2063 6f6c 756d  ames (i.e. colum
-0000ce10: 6e73 2920 746f 2074 6572 6d73 0a20 2020  ns) to terms.   
-0000ce20: 2027 2727 0a0a 0a20 2020 2023 2064 6963   '''...    # dic
-0000ce30: 7469 6f6e 6172 7920 6d61 7070 696e 6720  tionary mapping 
-0000ce40: 636f 6c75 6d6e 206e 616d 6520 746f 2070  column name to p
-0000ce50: 7265 6665 7272 6564 2074 6572 6d0a 2020  referred term.  
-0000ce60: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
-0000ce70: 7320 3d20 7b7d 0a0a 2020 2020 2320 6368  s = {}..    # ch
-0000ce80: 6563 6b20 6966 2075 7365 7220 7375 7070  eck if user supp
-0000ce90: 6c69 6564 2061 204a 534f 4e20 6669 6c65  lied a JSON file
-0000cea0: 206f 7220 6120 6a73 6f6e 2064 6963 7469   or a json dicti
-0000ceb0: 6f6e 6172 790a 2020 2020 6966 206a 736f  onary.    if jso
-0000cec0: 6e5f 736f 7572 6365 2069 7320 6e6f 7420  n_source is not 
-0000ced0: 4e6f 6e65 3a0a 2020 2020 2020 2020 7472  None:.        tr
-0000cee0: 793a 0a20 2020 2020 2020 2020 2020 2023  y:.            #
-0000cef0: 2063 6865 636b 2069 6620 6a73 6f6e 5f73   check if json_s
-0000cf00: 6f75 7263 6520 6973 2061 2066 696c 650a  ource is a file.
-0000cf10: 2020 2020 2020 2020 2020 2020 6966 206f              if o
-0000cf20: 732e 7061 7468 2e69 7366 696c 6528 6a73  s.path.isfile(js
-0000cf30: 6f6e 5f73 6f75 7263 6529 3a0a 2020 2020  on_source):.    
-0000cf40: 2020 2020 2020 2020 2020 2020 2320 6c6f              # lo
-0000cf50: 6164 2066 696c 650a 2020 2020 2020 2020  ad file.        
-0000cf60: 2020 2020 2020 2020 7769 7468 206f 7065          with ope
-0000cf70: 6e28 6a73 6f6e 5f73 6f75 7263 652c 2772  n(json_source,'r
-0000cf80: 2729 2061 7320 663a 0a20 2020 2020 2020  ') as f:.       
-0000cf90: 2020 2020 2020 2020 2020 2020 206a 736f               jso
-0000cfa0: 6e5f 6d61 7020 3d20 6a73 6f6e 2e6c 6f61  n_map = json.loa
-0000cfb0: 6428 6629 0a20 2020 2020 2020 2020 2020  d(f).           
-0000cfc0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-0000cfd0: 2020 2020 2020 2070 7269 6e74 2822 4552         print("ER
-0000cfe0: 524f 523a 2043 616e 2774 206f 7065 6e20  ROR: Can't open 
-0000cff0: 6a73 6f6e 206d 6170 7069 6e67 2066 696c  json mapping fil
-0000d000: 653a 2025 7322 2025 286a 736f 6e5f 736f  e: %s" %(json_so
-0000d010: 7572 6365 2929 0a20 2020 2020 2020 2020  urce)).         
-0000d020: 2020 2020 2020 2065 7869 7428 290a 2020         exit().  
-0000d030: 2020 2020 2020 6578 6365 7074 3a0a 2020        except:.  
-0000d040: 2020 2020 2020 2020 2020 2320 6966 206e            # if n
-0000d050: 6f74 2074 6865 6e20 6974 2773 2061 206a  ot then it's a j
-0000d060: 736f 6e20 7374 7275 6374 7572 6520 616c  son structure al
-0000d070: 7265 6164 790a 2020 2020 2020 2020 2020  ready.          
-0000d080: 2020 6a73 6f6e 5f6d 6170 203d 206a 736f    json_map = jso
-0000d090: 6e5f 736f 7572 6365 0a20 2020 2020 2020  n_source.       
-0000d0a0: 2020 2020 2023 2061 6464 6564 2063 6865       # added che
-0000d0b0: 636b 2074 6f20 6d61 6b65 2073 7572 6520  ck to make sure 
-0000d0c0: 6a73 6f6e 5f6d 6170 2069 7320 7661 6c69  json_map is vali
-0000d0d0: 6420 6469 6374 696f 6e61 7279 0a20 2020  d dictionary.   
-0000d0e0: 2020 2020 2020 2020 2069 6620 6e6f 7420           if not 
-0000d0f0: 6973 696e 7374 616e 6365 286a 736f 6e5f  isinstance(json_
-0000d100: 6d61 702c 6469 6374 293a 0a20 2020 2020  map,dict):.     
-0000d110: 2020 2020 2020 2020 2020 2070 7269 6e74             print
-0000d120: 2822 4552 524f 523a 2049 6e76 616c 6964  ("ERROR: Invalid
-0000d130: 204a 534f 4e20 6669 6c65 2073 7570 706c   JSON file suppl
-0000d140: 6965 642e 2020 506c 6561 7365 2063 6865  ied.  Please che
-0000d150: 636b 2079 6f75 7220 4a53 4f4e 2066 696c  ck your JSON fil
-0000d160: 6520 7769 7468 2061 2076 616c 6964 6174  e with a validat
-0000d170: 6f72 2066 6972 7374 2122 290a 2020 2020  or first!").    
-0000d180: 2020 2020 2020 2020 2020 2020 7072 696e              prin
-0000d190: 7428 2265 7869 7469 6e67 2122 290a 2020  t("exiting!").  
-0000d1a0: 2020 2020 2020 2020 2020 2020 2020 6578                ex
-0000d1b0: 6974 2829 0a0a 0a20 2020 2023 2069 6620  it()...    # if 
-0000d1c0: 6e6f 204a 534f 4e20 6d61 7070 696e 6720  no JSON mapping 
-0000d1d0: 6669 6c65 2077 6173 2073 7065 6369 6669  file was specifi
-0000d1e0: 6564 2074 6865 6e20 6372 6561 7465 2061  ed then create a
-0000d1f0: 2064 6566 6175 6c74 206f 6e65 2066 6f72   default one for
-0000d200: 2076 6172 6961 626c 652d 7465 726d 206d   variable-term m
-0000d210: 6170 7069 6e67 730a 2020 2020 2320 6372  appings.    # cr
-0000d220: 6561 7465 2061 206a 736f 6e5f 6669 6c65  eate a json_file
-0000d230: 2066 696c 656e 616d 6520 6672 6f6d 2074   filename from t
-0000d240: 6865 206f 7574 7075 7420 6669 6c65 2066  he output file f
-0000d250: 696c 656e 616d 650a 2020 2020 6966 206f  ilename.    if o
-0000d260: 7574 7075 745f 6669 6c65 2069 7320 4e6f  utput_file is No
-0000d270: 6e65 3a0a 2020 2020 2020 2020 6f75 7470  ne:.        outp
-0000d280: 7574 5f66 696c 6520 3d20 6f73 2e70 6174  ut_file = os.pat
-0000d290: 682e 6a6f 696e 2864 6972 6563 746f 7279  h.join(directory
-0000d2a0: 2c20 226e 6964 6d5f 616e 6e6f 7461 7469  , "nidm_annotati
-0000d2b0: 6f6e 732e 6a73 6f6e 2229 0a0a 2020 2020  ons.json")..    
-0000d2c0: 2320 696e 6974 6961 6c69 7a65 2049 6e74  # initialize Int
-0000d2d0: 6572 4c65 7820 636f 6e6e 6563 7469 6f6e  erLex connection
-0000d2e0: 0a20 2020 2074 7279 3a0a 2020 2020 2020  .    try:.      
-0000d2f0: 2020 696c 785f 6f62 6a20 3d20 496e 6974    ilx_obj = Init
-0000d300: 6961 6c69 7a65 496e 7465 726c 6578 5265  ializeInterlexRe
-0000d310: 6d6f 7465 2829 0a20 2020 2065 7863 6570  mote().    excep
-0000d320: 7420 4578 6365 7074 696f 6e20 6173 2065  t Exception as e
-0000d330: 3a0a 2020 2020 2020 2020 7072 696e 7428  :.        print(
-0000d340: 2245 5252 4f52 3a20 696e 6974 6961 6c69  "ERROR: initiali
-0000d350: 7a69 6e67 2049 6e74 6572 4c65 7820 636f  zing InterLex co
-0000d360: 6e6e 6563 7469 6f6e 2e2e 2e22 290a 2020  nnection...").  
-0000d370: 2020 2020 2020 7072 696e 7428 2259 6f75        print("You
-0000d380: 2077 696c 6c20 6e6f 7420 6265 2061 626c   will not be abl
-0000d390: 6520 746f 2061 6464 206f 7220 7175 6572  e to add or quer
-0000d3a0: 7920 666f 7220 636f 6e63 6570 7473 2e22  y for concepts."
-0000d3b0: 290a 2020 2020 2020 2020 696c 785f 6f62  ).        ilx_ob
-0000d3c0: 6a3d 4e6f 6e65 0a20 2020 2023 206c 6f61  j=None.    # loa
-0000d3d0: 6420 4e49 444d 204f 574c 2066 696c 6573  d NIDM OWL files
-0000d3e0: 2069 6620 7573 6572 2072 6571 7565 7374   if user request
-0000d3f0: 6564 2069 740a 2020 2020 6966 206f 776c  ed it.    if owl
-0000d400: 5f66 696c 653d 3d27 6e69 646d 273a 0a20  _file=='nidm':. 
-0000d410: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-0000d420: 2020 2020 2020 2020 6e69 646d 5f6f 776c          nidm_owl
-0000d430: 5f67 7261 7068 203d 206c 6f61 645f 6e69  _graph = load_ni
-0000d440: 646d 5f6f 776c 5f66 696c 6573 2829 0a20  dm_owl_files(). 
-0000d450: 2020 2020 2020 2065 7863 6570 7420 4578         except Ex
-0000d460: 6365 7074 696f 6e20 6173 2065 3a0a 2020  ception as e:.  
-0000d470: 2020 2020 2020 2020 2020 7072 696e 7428            print(
-0000d480: 290a 2020 2020 2020 2020 2020 2020 7072  ).            pr
-0000d490: 696e 7428 2245 5252 4f52 3a20 696e 6974  int("ERROR: init
-0000d4a0: 6961 6c69 7a69 6e67 2069 6e74 6572 6e65  ializing interne
-0000d4b0: 7420 636f 6e6e 6563 7469 6f6e 2074 6f20  t connection to 
-0000d4c0: 4e49 444d 204f 574c 2066 696c 6573 2e2e  NIDM OWL files..
-0000d4d0: 2e22 290a 2020 2020 2020 2020 2020 2020  .").            
-0000d4e0: 7072 696e 7428 2259 6f75 2077 696c 6c20  print("You will 
-0000d4f0: 6e6f 7420 6265 2061 626c 6520 746f 2073  not be able to s
-0000d500: 656c 6563 7420 7465 726d 7320 6672 6f6d  elect terms from
-0000d510: 204e 4944 4d20 4f57 4c20 6669 6c65 732e   NIDM OWL files.
-0000d520: 2229 0a20 2020 2020 2020 2020 2020 206e  ").            n
-0000d530: 6964 6d5f 6f77 6c5f 6772 6170 6820 3d20  idm_owl_graph = 
-0000d540: 4e6f 6e65 0a20 2020 2023 2065 6c73 6520  None.    # else 
-0000d550: 6c6f 6164 2075 7365 722d 7375 7070 6c69  load user-suppli
-0000d560: 6564 206f 776c 2066 696c 650a 2020 2020  ed owl file.    
-0000d570: 656c 6966 206f 776c 5f66 696c 6520 6973  elif owl_file is
-0000d580: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
-0000d590: 2020 206e 6964 6d5f 6f77 6c5f 6772 6170     nidm_owl_grap
-0000d5a0: 6820 3d20 4772 6170 6828 290a 2020 2020  h = Graph().    
-0000d5b0: 2020 2020 6e69 646d 5f6f 776c 5f67 7261      nidm_owl_gra
-0000d5c0: 7068 2e70 6172 7365 286c 6f63 6174 696f  ph.parse(locatio
-0000d5d0: 6e3d 6f77 6c5f 6669 6c65 290a 2020 2020  n=owl_file).    
-0000d5e0: 656c 7365 3a0a 2020 2020 2020 2020 6e69  else:.        ni
-0000d5f0: 646d 5f6f 776c 5f67 7261 7068 203d 204e  dm_owl_graph = N
-0000d600: 6f6e 650a 0a20 2020 2023 2069 7465 7261  one..    # itera
-0000d610: 7465 206f 7665 7220 636f 6c75 6d6e 730a  te over columns.
-0000d620: 2020 2020 666f 7220 636f 6c75 6d6e 2069      for column i
-0000d630: 6e20 6466 2e63 6f6c 756d 6e73 3a0a 0a20  n df.columns:.. 
-0000d640: 2020 2020 2020 2023 2073 6574 2075 7020         # set up 
-0000d650: 6120 6469 6374 696f 6e61 7279 2065 6e74  a dictionary ent
-0000d660: 7279 2066 6f72 2074 6869 7320 636f 6c75  ry for this colu
-0000d670: 6d6e 0a20 2020 2020 2020 2063 7572 7265  mn.        curre
-0000d680: 6e74 5f74 7570 6c65 203d 2073 7472 2844  nt_tuple = str(D
-0000d690: 4428 736f 7572 6365 3d61 7373 6573 736d  D(source=assessm
-0000d6a0: 656e 745f 6e61 6d65 2c20 7661 7269 6162  ent_name, variab
-0000d6b0: 6c65 3d63 6f6c 756d 6e29 290a 0a20 2020  le=column))..   
-0000d6c0: 2020 2020 2023 2069 6620 7765 206c 6f61       # if we loa
-0000d6d0: 6465 6420 6120 6a73 6f6e 2066 696c 6520  ded a json file 
-0000d6e0: 7769 7468 2065 7869 7374 696e 6720 6d61  with existing ma
-0000d6f0: 7070 696e 6773 0a20 2020 2020 2020 2074  ppings.        t
-0000d700: 7279 3a0a 2020 2020 2020 2020 2020 2020  ry:.            
-0000d710: 6a73 6f6e 5f6d 6170 0a20 2020 2020 2020  json_map.       
-0000d720: 2020 2020 2023 7472 793a 0a20 2020 2020       #try:.     
-0000d730: 2020 2020 2020 2020 2020 2023 2063 6865             # che
-0000d740: 636b 2066 6f72 2063 6f6c 756d 6e20 696e  ck for column in
-0000d750: 206a 736f 6e20 6669 6c65 0a20 2020 2020   json file.     
-0000d760: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
-0000d770: 2020 2020 2020 2020 2020 2020 6a73 6f6e              json
-0000d780: 5f6b 6579 203d 205b 6b65 7920 666f 7220  _key = [key for 
-0000d790: 6b65 7920 696e 206a 736f 6e5f 6d61 7020  key in json_map 
-0000d7a0: 6966 2063 6f6c 756d 6e2e 6c73 7472 6970  if column.lstrip
-0000d7b0: 2829 2e72 7374 7269 7028 2920 3d3d 0a20  ().rstrip() ==. 
-0000d7c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d7d0: 2020 2020 2020 206b 6579 2e73 706c 6974         key.split
-0000d7e0: 2822 7661 7269 6162 6c65 2229 5b31 5d2e  ("variable")[1].
-0000d7f0: 7370 6c69 7428 223d 2229 5b31 5d2e 7370  split("=")[1].sp
-0000d800: 6c69 7428 2229 2229 5b30 5d2e 6c73 7472  lit(")")[0].lstr
-0000d810: 6970 2822 2722 292e 7273 7472 6970 2822  ip("'").rstrip("
-0000d820: 2722 295d 0a20 2020 2020 2020 2020 2020  '")].           
-0000d830: 2065 7863 6570 7420 4578 6365 7074 696f   except Exceptio
-0000d840: 6e20 6173 2065 3a0a 2020 2020 2020 2020  n as e:.        
-0000d850: 2020 2020 2020 2020 6966 2022 6c69 7374          if "list
-0000d860: 2069 6e64 6578 206f 7574 206f 6620 7261   index out of ra
-0000d870: 6e67 6522 2069 6e20 7374 7228 6529 3a0a  nge" in str(e):.
-0000d880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d890: 2020 2020 6a73 6f6e 5f6b 6579 203d 205b      json_key = [
-0000d8a0: 6b65 7920 666f 7220 6b65 7920 696e 206a  key for key in j
-0000d8b0: 736f 6e5f 6d61 7020 6966 2063 6f6c 756d  son_map if colum
-0000d8c0: 6e2e 6c73 7472 6970 2829 2e72 7374 7269  n.lstrip().rstri
-0000d8d0: 7028 2920 3d3d 206b 6579 5d0a 0a0a 2020  p() == key]...  
-0000d8e0: 2020 2020 2020 2020 2020 6669 6e61 6c6c            finall
-0000d8f0: 793a 0a0a 2020 2020 2020 2020 2020 2020  y:..            
-0000d900: 2020 2020 6966 2028 6a73 6f6e 5f6d 6170      if (json_map
-0000d910: 2069 7320 6e6f 7420 4e6f 6e65 2920 616e   is not None) an
-0000d920: 6420 286c 656e 286a 736f 6e5f 6b65 7929  d (len(json_key)
-0000d930: 3e30 293a 0a20 2020 2020 2020 2020 2020  >0):.           
-0000d940: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
-0000d950: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-0000d960: 5f74 7570 6c65 5d20 3d20 7b7d 0a0a 2020  _tuple] = {}..  
-0000d970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d980: 2020 2320 6164 6465 6420 696e 2063 6173    # added in cas
-0000d990: 6520 666f 7220 736f 6d65 2072 6561 736f  e for some reaso
-0000d9a0: 6e20 7468 6572 6520 6973 6e27 7420 6120  n there isn't a 
-0000d9b0: 6c61 6265 6c20 6b65 792c 2074 7279 2073  label key, try s
-0000d9c0: 6f75 7263 655f 7661 7269 6162 6c65 2061  ource_variable a
-0000d9d0: 6e64 2069 6620 6974 2773 0a20 2020 2020  nd if it's.     
-0000d9e0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-0000d9f0: 2061 206b 6579 2074 6865 6e20 6164 6420   a key then add 
-0000da00: 7468 6973 2061 7320 7468 6520 6c61 6265  this as the labe
-0000da10: 6c20 6173 2077 656c 6c2e 0a20 2020 2020  l as well..     
-0000da20: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0000da30: 6620 276c 6162 656c 2720 6e6f 7420 696e  f 'label' not in
-0000da40: 206a 736f 6e5f 6d61 705b 6a73 6f6e 5f6b   json_map[json_k
-0000da50: 6579 5b30 5d5d 2e6b 6579 7328 293a 0a20  ey[0]].keys():. 
-0000da60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000da70: 2020 2020 2020 2069 6620 2827 736f 7572         if ('sour
-0000da80: 6365 5f76 6172 6961 626c 6527 2069 6e20  ce_variable' in 
-0000da90: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
-0000daa0: 795b 305d 5d2e 6b65 7973 2829 293a 0a20  y[0]].keys()):. 
-0000dab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dac0: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
-0000dad0: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
-0000dae0: 6e74 5f74 7570 6c65 5d5b 276c 6162 656c  nt_tuple]['label
-0000daf0: 275d 203d 206a 736f 6e5f 6d61 705b 6a73  '] = json_map[js
-0000db00: 6f6e 5f6b 6579 5b30 5d5d 5b27 736f 7572  on_key[0]]['sour
-0000db10: 6365 5f76 6172 6961 626c 6527 5d0a 2020  ce_variable'].  
-0000db20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000db30: 2020 2020 2020 656c 6966 2028 2773 6f75        elif ('sou
-0000db40: 7263 6556 6172 6961 626c 6527 2069 6e20  rceVariable' in 
-0000db50: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
-0000db60: 795b 305d 5d2e 6b65 7973 2829 293a 0a20  y[0]].keys()):. 
-0000db70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000db80: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
-0000db90: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
-0000dba0: 6e74 5f74 7570 6c65 5d5b 276c 6162 656c  nt_tuple]['label
-0000dbb0: 275d 203d 206a 736f 6e5f 6d61 705b 6a73  '] = json_map[js
-0000dbc0: 6f6e 5f6b 6579 5b30 5d5d 5b27 736f 7572  on_key[0]]['sour
-0000dbd0: 6365 5661 7269 6162 6c65 275d 0a20 2020  ceVariable'].   
-0000dbe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dbf0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-0000dc00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dc10: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
-0000dc20: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-0000dc30: 7570 6c65 5d5b 276c 6162 656c 275d 203d  uple]['label'] =
-0000dc40: 2022 220a 2020 2020 2020 2020 2020 2020   "".            
-0000dc50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dc60: 7072 696e 7428 224e 6f20 6c61 6265 6c20  print("No label 
-0000dc70: 6f72 2073 6f75 7263 655f 7661 7269 6162  or source_variab
-0000dc80: 6c65 206f 7220 736f 7572 6365 5661 7269  le or sourceVari
-0000dc90: 6162 6c65 206b 6579 7320 666f 756e 6420  able keys found 
-0000dca0: 696e 206a 736f 6e20 6d61 7070 696e 6720  in json mapping 
-0000dcb0: 6669 6c65 2066 6f72 2076 6172 6961 626c  file for variabl
-0000dcc0: 6520 220a 2020 2020 2020 2020 2020 2020  e ".            
-0000dcd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dce0: 2020 2020 2020 2225 732e 2043 6f6e 7369        "%s. Consi
-0000dcf0: 6465 7220 6164 6469 6e67 2074 6865 7365  der adding these
-0000dd00: 2074 6f20 7468 6520 6a73 6f6e 2066 696c   to the json fil
-0000dd10: 6520 6173 2074 6865 7920 6172 6520 696d  e as they are im
-0000dd20: 706f 7274 616e 7422 2025 6a73 6f6e 5f6b  portant" %json_k
-0000dd30: 6579 5b30 5d29 0a20 2020 2020 2020 2020  ey[0]).         
-0000dd40: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-0000dd50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000dd60: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
-0000dd70: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-0000dd80: 5f74 7570 6c65 5d5b 276c 6162 656c 275d  _tuple]['label']
-0000dd90: 203d 206a 736f 6e5f 6d61 705b 6a73 6f6e   = json_map[json
-0000dda0: 5f6b 6579 5b30 5d5d 5b27 6c61 6265 6c27  _key[0]]['label'
-0000ddb0: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
-0000ddc0: 2020 2020 2020 2320 6164 6465 6420 7468        # added th
-0000ddd0: 6973 2062 6974 2074 6f20 6163 636f 756e  is bit to accoun
-0000dde0: 7420 666f 7220 4249 4453 206a 736f 6e20  t for BIDS json 
-0000ddf0: 6669 6c65 7320 7573 696e 6720 2244 6573  files using "Des
-0000de00: 6372 6970 7469 6f6e 2220 7768 6572 6561  cription" wherea
-0000de10: 7320 7765 2075 7365 2022 6465 7363 7269  s we use "descri
-0000de20: 7074 696f 6e22 0a20 2020 2020 2020 2020  ption".         
-0000de30: 2020 2020 2020 2020 2020 2023 2065 7665             # eve
-0000de40: 7279 7768 6572 6520 656c 7365 0a20 2020  rywhere else.   
-0000de50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000de60: 2069 6620 2764 6573 6372 6970 7469 6f6e   if 'description
-0000de70: 2720 696e 206a 736f 6e5f 6d61 705b 6a73  ' in json_map[js
-0000de80: 6f6e 5f6b 6579 5b30 5d5d 2e6b 6579 7328  on_key[0]].keys(
-0000de90: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-0000dea0: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
-0000deb0: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
-0000dec0: 6e74 5f74 7570 6c65 5d5b 2764 6573 6372  nt_tuple]['descr
-0000ded0: 6970 7469 6f6e 275d 203d 206a 736f 6e5f  iption'] = json_
-0000dee0: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
-0000def0: 5b27 6465 7363 7269 7074 696f 6e27 5d0a  ['description'].
-0000df00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000df10: 2020 2020 656c 6966 2027 4465 7363 7269      elif 'Descri
-0000df20: 7074 696f 6e27 2069 6e20 6a73 6f6e 5f6d  ption' in json_m
-0000df30: 6170 5b6a 736f 6e5f 6b65 795b 305d 5d2e  ap[json_key[0]].
-0000df40: 6b65 7973 2829 3a0a 2020 2020 2020 2020  keys():.        
-0000df50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000df60: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
-0000df70: 6375 7272 656e 745f 7475 706c 655d 5b27  current_tuple]['
-0000df80: 6465 7363 7269 7074 696f 6e27 5d20 3d20  description'] = 
-0000df90: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
-0000dfa0: 795b 305d 5d5b 2744 6573 6372 6970 7469  y[0]]['Descripti
-0000dfb0: 6f6e 275d 0a20 2020 2020 2020 2020 2020  on'].           
-0000dfc0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-0000dfd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dfe0: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
-0000dff0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-0000e000: 7570 6c65 5d5b 2764 6573 6372 6970 7469  uple]['descripti
-0000e010: 6f6e 275d 203d 2022 220a 2020 2020 2020  on'] = "".      
-0000e020: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-0000e030: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
-0000e040: 6375 7272 656e 745f 7475 706c 655d 5b27  current_tuple]['
-0000e050: 7661 7269 6162 6c65 275d 203d 206a 736f  variable'] = jso
-0000e060: 6e5f 6d61 705b 6a73 6f6e 5f6b 6579 5b30  n_map[json_key[0
-0000e070: 5d5d 5b27 7661 7269 6162 6c65 275d 0a0a  ]]['variable']..
-0000e080: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e090: 2020 2020 7072 696e 7428 225c 6e2a 2a2a      print("\n***
-0000e0a0: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-0000e0b0: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-0000e0c0: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-0000e0d0: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-0000e0e0: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-0000e0f0: 2a2a 2229 0a20 2020 2020 2020 2020 2020  **").           
-0000e100: 2020 2020 2020 2020 2070 7269 6e74 2822           print("
-0000e110: 436f 6c75 6d6e 2025 7320 616c 7265 6164  Column %s alread
-0000e120: 7920 616e 6e6f 7461 7465 6420 696e 2075  y annotated in u
-0000e130: 7365 7220 7375 7070 6c69 6564 204a 534f  ser supplied JSO
-0000e140: 4e20 6d61 7070 696e 6720 6669 6c65 2220  N mapping file" 
-0000e150: 2563 6f6c 756d 6e29 0a20 2020 2020 2020  %column).       
-0000e160: 2020 2020 2020 2020 2020 2020 2070 7269               pri
-0000e170: 6e74 2822 6c61 6265 6c3a 2025 7322 2025  nt("label: %s" %
-0000e180: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
-0000e190: 6375 7272 656e 745f 7475 706c 655d 5b27  current_tuple]['
-0000e1a0: 6c61 6265 6c27 5d29 0a20 2020 2020 2020  label']).       
-0000e1b0: 2020 2020 2020 2020 2020 2020 2070 7269               pri
-0000e1c0: 6e74 2822 6465 7363 7269 7074 696f 6e3a  nt("description:
-0000e1d0: 2025 7322 2025 636f 6c75 6d6e 5f74 6f5f   %s" %column_to_
-0000e1e0: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
-0000e1f0: 706c 655d 5b27 6465 7363 7269 7074 696f  ple]['descriptio
-0000e200: 6e27 5d29 0a20 2020 2020 2020 2020 2020  n']).           
-0000e210: 2020 2020 2020 2020 2069 6620 2775 726c           if 'url
-0000e220: 2720 696e 206a 736f 6e5f 6d61 705b 6a73  ' in json_map[js
-0000e230: 6f6e 5f6b 6579 5b30 5d5d 3a0a 2020 2020  on_key[0]]:.    
-0000e240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e250: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
-0000e260: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
-0000e270: 655d 5b27 7572 6c27 5d20 3d20 6a73 6f6e  e]['url'] = json
-0000e280: 5f6d 6170 5b6a 736f 6e5f 6b65 795b 305d  _map[json_key[0]
-0000e290: 5d5b 2775 726c 275d 0a20 2020 2020 2020  ]['url'].       
-0000e2a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e2b0: 2070 7269 6e74 2822 7572 6c3a 2025 7322   print("url: %s"
-0000e2c0: 2025 636f 6c75 6d6e 5f74 6f5f 7465 726d   %column_to_term
-0000e2d0: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-0000e2e0: 5b27 7572 6c27 5d29 0a20 2020 2020 2020  ['url']).       
-0000e2f0: 2020 2020 2020 2020 2020 2020 2023 2070               # p
-0000e300: 7269 6e74 2822 5661 7269 6162 6c65 3a20  rint("Variable: 
-0000e310: 2573 2220 2563 6f6c 756d 6e5f 746f 5f74  %s" %column_to_t
-0000e320: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
-0000e330: 6c65 5d5b 2776 6172 6961 626c 6527 5d29  le]['variable'])
-0000e340: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e350: 2020 2020 2069 6620 2773 616d 6541 7327       if 'sameAs'
-0000e360: 2069 6e20 6a73 6f6e 5f6d 6170 5b6a 736f   in json_map[jso
-0000e370: 6e5f 6b65 795b 305d 5d3a 0a20 2020 2020  n_key[0]]:.     
+000065e0: 2020 2020 2069 6620 6e6f 7420 666f 756e       if not foun
+000065f0: 645f 7572 693a 0a20 2020 2020 2020 2020  d_uri:.         
+00006600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006610: 2020 206e 6964 6d5f 6f62 6a2e 6164 645f     nidm_obj.add_
+00006620: 6174 7472 6962 7574 6573 287b 7072 6564  attributes({pred
+00006630: 6963 6174 653a 2049 6465 6e74 6966 6965  icate: Identifie
+00006640: 7228 6f62 6a65 6374 7329 7d29 0a20 2020  r(objects)}).   
+00006650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006660: 2020 2020 2023 2065 6c73 6520 6164 6420       # else add 
+00006670: 6173 2065 7870 6c69 6369 7420 7072 6f76  as explicit prov
+00006680: 2e51 7561 6c69 6669 6564 4e61 6d65 2062  .QualifiedName b
+00006690: 6563 6175 7365 2069 7427 7320 6561 7369  ecause it's easi
+000066a0: 6572 2074 6f20 7265 6164 0a20 2020 2020  er to read.     
+000066b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000066c0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+000066d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000066e0: 2020 2020 206e 6964 6d5f 6f62 6a2e 6164       nidm_obj.ad
+000066f0: 645f 6174 7472 6962 7574 6573 280a 2020  d_attributes(.  
+00006700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006710: 2020 2020 2020 2020 2020 2020 2020 7b70                {p
+00006720: 7265 6469 6361 7465 3a20 706d 2e51 7561  redicate: pm.Qua
+00006730: 6c69 6669 6564 4e61 6d65 2866 6f75 6e64  lifiedName(found
+00006740: 5f75 7269 2c20 6f62 6a5f 7465 726d 297d  _uri, obj_term)}
+00006750: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00006760: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+00006770: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+00006780: 7863 6570 7420 4578 6365 7074 696f 6e3a  xcept Exception:
+00006790: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000067a0: 2020 2020 206e 6964 6d5f 6f62 6a2e 6164       nidm_obj.ad
+000067b0: 645f 6174 7472 6962 7574 6573 280a 2020  d_attributes(.  
+000067c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000067d0: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+000067e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000067f0: 2020 2020 7072 6564 6963 6174 653a 2070      predicate: p
+00006800: 6d2e 5175 616c 6966 6965 644e 616d 6528  m.QualifiedName(
+00006810: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00006820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006830: 206e 616d 6573 7061 6365 3d4e 616d 6573   namespace=Names
+00006840: 7061 6365 2873 7472 286f 626a 6563 7473  pace(str(objects
+00006850: 2929 2c20 6c6f 6361 6c70 6172 743d 2222  )), localpart=""
+00006860: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00006870: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+00006880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006890: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+000068a0: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+000068b0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+000068c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000068d0: 2023 2063 6865 636b 2069 6620 7468 6973   # check if this
+000068e0: 2069 7320 6120 716e 616d 6520 616e 6420   is a qname and 
+000068f0: 6966 2073 6f20 6578 7061 6e64 2069 740a  if so expand it.
+00006900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006910: 2320 6164 6465 6420 746f 2068 616e 646c  # added to handl
+00006920: 6520 7768 656e 2061 2076 616c 7565 2069  e when a value i
+00006930: 7320 6120 716e 616d 652e 2020 7468 6973  s a qname.  this
+00006940: 2073 686f 756c 6420 6578 7061 6e64 2069   should expand i
+00006950: 742e 2e2e 2e0a 2020 2020 2020 2020 2020  t.....          
+00006960: 2020 2020 2020 6966 2028 223a 2220 696e        if (":" in
+00006970: 206f 626a 6563 7473 2920 616e 6420 6973   objects) and is
+00006980: 696e 7374 616e 6365 286f 626a 6563 7473  instance(objects
+00006990: 2c20 5552 4952 6566 293a 0a20 2020 2020  , URIRef):.     
+000069a0: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+000069b0: 626a 6563 7473 203d 2066 726f 6d5f 6e33  bjects = from_n3
+000069c0: 286f 626a 6563 7473 290a 2020 2020 2020  (objects).      
+000069d0: 2020 2020 2020 2020 2020 2320 6368 6563            # chec
+000069e0: 6b20 6966 206f 626a 6563 7473 2069 7320  k if objects is 
+000069f0: 6120 7572 6c20 616e 6420 6966 2073 6f20  a url and if so 
+00006a00: 7374 6f72 6520 6974 2061 7320 6120 5552  store it as a UR
+00006a10: 4952 6566 2065 6c73 6520 6120 4c69 7465  IRef else a Lite
+00006a20: 7261 6c0a 2020 2020 2020 2020 2020 2020  ral.            
+00006a30: 2020 2020 6966 2076 616c 6964 6174 6f72      if validator
+00006a40: 732e 7572 6c28 6f62 6a65 6374 7329 3a0a  s.url(objects):.
+00006a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006a60: 2020 2020 6f62 6a5f 6e6d 2c20 6f62 6a5f      obj_nm, obj_
+00006a70: 7465 726d 203d 2073 706c 6974 5f75 7269  term = split_uri
+00006a80: 286f 626a 6563 7473 290a 2020 2020 2020  (objects).      
+00006a90: 2020 2020 2020 2020 2020 2020 2020 6e69                ni
+00006aa0: 646d 5f6f 626a 2e61 6464 5f61 7474 7269  dm_obj.add_attri
+00006ab0: 6275 7465 7328 7b70 7265 6469 6361 7465  butes({predicate
+00006ac0: 3a20 4964 656e 7469 6669 6572 286f 626a  : Identifier(obj
+00006ad0: 6563 7473 297d 290a 2020 2020 2020 2020  ects)}).        
+00006ae0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00006af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006b00: 2020 6e69 646d 5f6f 626a 2e61 6464 5f61    nidm_obj.add_a
+00006b10: 7474 7269 6275 7465 7328 7b70 7265 6469  ttributes({predi
+00006b20: 6361 7465 3a20 6765 745f 5244 466c 6974  cate: get_RDFlit
+00006b30: 6572 616c 5f74 7970 6528 6f62 6a65 6374  eral_type(object
+00006b40: 7329 7d29 0a0a 2020 2020 2320 6e6f 7720  s)})..    # now 
+00006b50: 6669 6e64 2071 7561 6c69 6669 6564 2061  find qualified a
+00006b60: 7373 6f63 6961 7469 6f6e 730a 2020 2020  ssociations.    
+00006b70: 666f 7220 626e 6f64 6520 696e 2072 6466  for bnode in rdf
+00006b80: 5f67 7261 7068 2e6f 626a 6563 7473 280a  _graph.objects(.
+00006b90: 2020 2020 2020 2020 7375 626a 6563 743d          subject=
+00006ba0: 7375 626a 6563 745f 7572 692c 2070 7265  subject_uri, pre
+00006bb0: 6469 6361 7465 3d43 6f6e 7374 616e 7473  dicate=Constants
+00006bc0: 2e50 524f 565b 2271 7561 6c69 6669 6564  .PROV["qualified
+00006bd0: 4173 736f 6369 6174 696f 6e22 5d0a 2020  Association"].  
+00006be0: 2020 293a 0a20 2020 2020 2020 2023 2063    ):.        # c
+00006bf0: 7265 6174 6520 7465 6d70 6f72 6172 7920  reate temporary 
+00006c00: 7265 736f 7572 6365 2066 6f72 2074 6869  resource for thi
+00006c10: 7320 626e 6f64 650a 2020 2020 2020 2020  s bnode.        
+00006c20: 7220 3d20 5265 736f 7572 6365 2872 6466  r = Resource(rdf
+00006c30: 5f67 7261 7068 2c20 626e 6f64 6529 0a20  _graph, bnode). 
+00006c40: 2020 2020 2020 2023 2067 6574 2074 6865         # get the
+00006c50: 206f 626a 6563 7420 666f 7220 7468 6973   object for this
+00006c60: 2062 6e6f 6465 2077 6974 6820 7072 6564   bnode with pred
+00006c70: 6963 6174 6520 436f 6e73 7461 6e74 732e  icate Constants.
+00006c80: 5052 4f56 5b27 6861 6452 6f6c 6527 5d0a  PROV['hadRole'].
+00006c90: 2020 2020 2020 2020 666f 7220 725f 6f62          for r_ob
+00006ca0: 6a20 696e 2072 2e6f 626a 6563 7473 2870  j in r.objects(p
+00006cb0: 7265 6469 6361 7465 3d43 6f6e 7374 616e  redicate=Constan
+00006cc0: 7473 2e50 524f 565b 2268 6164 526f 6c65  ts.PROV["hadRole
+00006cd0: 225d 293a 0a20 2020 2020 2020 2020 2020  "]):.           
+00006ce0: 2023 2069 6620 7468 6973 2069 7320 6120   # if this is a 
+00006cf0: 7175 616c 6966 6965 6420 6173 736f 6369  qualified associ
+00006d00: 6174 696f 6e20 7769 7468 2061 2070 6172  ation with a par
+00006d10: 7469 6369 7061 6e74 2074 6865 6e20 6372  ticipant then cr
+00006d20: 6561 7465 2074 6865 2070 726f 763a 5065  eate the prov:Pe
+00006d30: 7273 6f6e 2061 6765 6e74 0a20 2020 2020  rson agent.     
+00006d40: 2020 2020 2020 2069 6620 725f 6f62 6a2e         if r_obj.
+00006d50: 6964 656e 7469 6669 6572 203d 3d20 5552  identifier == UR
+00006d60: 4952 6566 2843 6f6e 7374 616e 7473 2e4e  IRef(Constants.N
+00006d70: 4944 4d5f 5041 5254 4943 4950 414e 542e  IDM_PARTICIPANT.
+00006d80: 7572 6929 3a0a 2020 2020 2020 2020 2020  uri):.          
+00006d90: 2020 2020 2020 2320 6765 7420 6964 656e        # get iden
+00006da0: 7469 6669 6572 2066 6f72 2070 726f 763a  tifier for prov:
+00006db0: 6167 656e 7420 7061 7274 206f 6620 7468  agent part of th
+00006dc0: 6520 626c 616e 6b20 6e6f 6465 0a20 2020  e blank node.   
+00006dd0: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+00006de0: 2061 6765 6e74 5f6f 626a 2069 6e20 722e   agent_obj in r.
+00006df0: 6f62 6a65 6374 7328 7072 6564 6963 6174  objects(predicat
+00006e00: 653d 436f 6e73 7461 6e74 732e 5052 4f56  e=Constants.PROV
+00006e10: 5b22 6167 656e 7422 5d29 3a0a 2020 2020  ["agent"]):.    
+00006e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006e30: 2320 6368 6563 6b20 6966 2070 6572 736f  # check if perso
+00006e40: 6e20 6578 6973 7473 2061 6c72 6561 6479  n exists already
+00006e50: 2069 6e20 6772 6170 682c 2069 6620 6e6f   in graph, if no
+00006e60: 7420 6372 6561 7465 2069 740a 2020 2020  t create it.    
+00006e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006e80: 6966 2061 6765 6e74 5f6f 626a 2e69 6465  if agent_obj.ide
+00006e90: 6e74 6966 6965 7220 6e6f 7420 696e 206e  ntifier not in n
+00006ea0: 6964 6d5f 6f62 6a2e 6772 6170 682e 6765  idm_obj.graph.ge
+00006eb0: 745f 7265 636f 7264 7328 293a 0a20 2020  t_records():.   
+00006ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006ed0: 2020 2020 2070 6572 736f 6e20 3d20 6e69       person = ni
+00006ee0: 646d 5f6f 626a 2e61 6464 5f70 6572 736f  dm_obj.add_perso
+00006ef0: 6e28 0a20 2020 2020 2020 2020 2020 2020  n(.             
+00006f00: 2020 2020 2020 2020 2020 2020 2020 2075                 u
+00006f10: 7569 643d 6167 656e 745f 6f62 6a2e 6964  uid=agent_obj.id
+00006f20: 656e 7469 6669 6572 2c20 6164 645f 6465  entifier, add_de
+00006f30: 6661 756c 745f 7479 7065 3d46 616c 7365  fault_type=False
+00006f40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00006f50: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+00006f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006f70: 2020 2023 2061 6464 2072 6573 7420 6f66     # add rest of
+00006f80: 206d 6574 6164 6174 6120 6162 6f75 7420   metadata about 
+00006f90: 7065 7273 6f6e 0a20 2020 2020 2020 2020  person.         
+00006fa0: 2020 2020 2020 2020 2020 2020 2020 2061                 a
+00006fb0: 6464 5f6d 6574 6164 6174 615f 666f 725f  dd_metadata_for_
+00006fc0: 7375 626a 6563 7428 0a20 2020 2020 2020  subject(.       
+00006fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006fe0: 2020 2020 2072 6466 5f67 7261 7068 3d72       rdf_graph=r
+00006ff0: 6466 5f67 7261 7068 2c0a 2020 2020 2020  df_graph,.      
+00007000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007010: 2020 2020 2020 7375 626a 6563 745f 7572        subject_ur
+00007020: 693d 6167 656e 745f 6f62 6a2e 6964 656e  i=agent_obj.iden
+00007030: 7469 6669 6572 2c0a 2020 2020 2020 2020  tifier,.        
+00007040: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007050: 2020 2020 6e61 6d65 7370 6163 6573 3d6e      namespaces=n
+00007060: 616d 6573 7061 6365 732c 0a20 2020 2020  amespaces,.     
+00007070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007080: 2020 2020 2020 206e 6964 6d5f 6f62 6a3d         nidm_obj=
+00007090: 7065 7273 6f6e 2c0a 2020 2020 2020 2020  person,.        
+000070a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000070b0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+000070c0: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+000070d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000070e0: 2020 2020 2320 7765 206e 6565 6420 7468      # we need th
+000070f0: 6520 4e49 444d 206f 626a 6563 7420 6865  e NIDM object he
+00007100: 7265 2077 6974 6820 7575 6964 2061 6765  re with uuid age
+00007110: 6e74 5f6f 626a 2e69 6465 6e74 6966 6965  nt_obj.identifie
+00007120: 7220 616e 6420 7374 6f72 6520 6974 2069  r and store it i
+00007130: 6e20 7065 7273 6f6e 0a20 2020 2020 2020  n person.       
+00007140: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007150: 2066 6f72 206f 626a 2069 6e20 6e69 646d   for obj in nidm
+00007160: 5f6f 626a 2e67 7261 7068 2e67 6574 5f72  _obj.graph.get_r
+00007170: 6563 6f72 6473 2829 3a0a 2020 2020 2020  ecords():.      
+00007180: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007190: 2020 2020 2020 6966 2061 6765 6e74 5f6f        if agent_o
+000071a0: 626a 2e69 6465 6e74 6966 6965 7220 3d3d  bj.identifier ==
+000071b0: 206f 626a 2e69 6465 6e74 6966 6965 723a   obj.identifier:
+000071c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000071d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000071e0: 2070 6572 736f 6e20 3d20 6f62 6a0a 2020   person = obj.  
+000071f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007200: 2020 2320 6372 6561 7465 2071 7561 6c69    # create quali
+00007210: 6669 6564 206e 616d 6573 2066 6f72 206f  fied names for o
+00007220: 626a 6563 7473 0a20 2020 2020 2020 2020  bjects.         
+00007230: 2020 2020 2020 2020 2020 206f 626a 5f6e             obj_n
+00007240: 6d2c 206f 626a 5f74 6572 6d20 3d20 7370  m, obj_term = sp
+00007250: 6c69 745f 7572 6928 725f 6f62 6a2e 6964  lit_uri(r_obj.id
+00007260: 656e 7469 6669 6572 290a 2020 2020 2020  entifier).      
+00007270: 2020 2020 2020 2020 2020 2020 2020 666f                fo
+00007280: 756e 645f 7572 6920 3d20 6669 6e64 5f69  und_uri = find_i
+00007290: 6e5f 6e61 6d65 7370 6163 6573 280a 2020  n_namespaces(.  
+000072a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000072b0: 2020 2020 2020 7365 6172 6368 5f75 7269        search_uri
+000072c0: 3d55 5249 5265 6628 6f62 6a5f 6e6d 292c  =URIRef(obj_nm),
+000072d0: 206e 616d 6573 7061 6365 733d 6e61 6d65   namespaces=name
+000072e0: 7370 6163 6573 0a20 2020 2020 2020 2020  spaces.         
+000072f0: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00007300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007310: 2023 2069 6620 6f62 6a5f 6e6d 2069 7320   # if obj_nm is 
+00007320: 6e6f 7420 696e 206e 616d 6573 7061 6365  not in namespace
+00007330: 7320 7468 656e 2069 7420 6d75 7374 206a  s then it must j
+00007340: 7573 7420 6265 2070 6172 7420 6f66 2073  ust be part of s
+00007350: 6f6d 6520 5552 4920 696e 2074 6865 2074  ome URI in the t
+00007360: 7269 706c 650a 2020 2020 2020 2020 2020  riple.          
+00007370: 2020 2020 2020 2020 2020 2320 736f 206a            # so j
+00007380: 7573 7420 6164 6420 6974 2061 7320 6120  ust add it as a 
+00007390: 7072 6f76 2e49 6465 6e74 6966 6965 720a  prov.Identifier.
+000073a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000073b0: 2020 2020 6966 206e 6f74 2066 6f75 6e64      if not found
+000073c0: 5f75 7269 3a0a 2020 2020 2020 2020 2020  _uri:.          
+000073d0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+000073e0: 6e69 646d 5f6f 626a 2e61 6464 5f71 7561  nidm_obj.add_qua
+000073f0: 6c69 6669 6564 5f61 7373 6f63 6961 7469  lified_associati
+00007400: 6f6e 2870 6572 736f 6e3d 7065 7273 6f6e  on(person=person
+00007410: 2c20 726f 6c65 3d70 6d2e 4964 656e 7469  , role=pm.Identi
+00007420: 6669 6572 2872 5f6f 626a 2e69 6465 6e74  fier(r_obj.ident
+00007430: 6966 6965 7229 290a 2020 2020 2020 2020  ifier)).        
+00007440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007450: 6e69 646d 5f6f 626a 2e61 6464 5f71 7561  nidm_obj.add_qua
+00007460: 6c69 6669 6564 5f61 7373 6f63 6961 7469  lified_associati
+00007470: 6f6e 280a 2020 2020 2020 2020 2020 2020  on(.            
+00007480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007490: 7065 7273 6f6e 3d70 6572 736f 6e2c 0a20  person=person,. 
+000074a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000074b0: 2020 2020 2020 2020 2020 2072 6f6c 653d             role=
+000074c0: 706d 2e51 7561 6c69 6669 6564 4e61 6d65  pm.QualifiedName
+000074d0: 284e 616d 6573 7061 6365 286f 626a 5f6e  (Namespace(obj_n
+000074e0: 6d29 2c20 6f62 6a5f 7465 726d 292c 0a20  m), obj_term),. 
+000074f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007500: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00007510: 2020 2020 2020 2020 2020 2020 2065 6c73               els
+00007520: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
+00007530: 2020 2020 2020 2020 2020 206e 6964 6d5f             nidm_
+00007540: 6f62 6a2e 6164 645f 7175 616c 6966 6965  obj.add_qualifie
+00007550: 645f 6173 736f 6369 6174 696f 6e28 0a20  d_association(. 
+00007560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007570: 2020 2020 2020 2020 2020 2070 6572 736f             perso
+00007580: 6e3d 7065 7273 6f6e 2c20 726f 6c65 3d70  n=person, role=p
+00007590: 6d2e 5175 616c 6966 6965 644e 616d 6528  m.QualifiedName(
+000075a0: 666f 756e 645f 7572 692c 206f 626a 5f74  found_uri, obj_t
+000075b0: 6572 6d29 0a20 2020 2020 2020 2020 2020  erm).           
+000075c0: 2020 2020 2020 2020 2020 2020 2029 0a0a               )..
+000075d0: 2020 2020 2020 2020 2020 2020 2320 656c              # el
+000075e0: 7365 2069 7427 7320 616e 2061 7373 6f63  se it's an assoc
+000075f0: 6961 7469 6f6e 2077 6974 6820 616e 6f74  iation with anot
+00007600: 6865 7220 6167 656e 7420 7768 6963 6820  her agent which 
+00007610: 6973 6e27 7420 6120 7061 7274 6963 6970  isn't a particip
+00007620: 616e 740a 2020 2020 2020 2020 2020 2020  ant.            
+00007630: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+00007640: 2020 2020 2020 2320 6765 7420 6964 656e        # get iden
+00007650: 7469 6669 6572 2066 6f72 2074 6865 2070  tifier for the p
+00007660: 726f 763a 6167 656e 7420 7061 7274 206f  rov:agent part o
+00007670: 6620 7468 6520 626c 616e 6b20 6e6f 6465  f the blank node
+00007680: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007690: 2066 6f72 2061 6765 6e74 5f6f 626a 2069   for agent_obj i
+000076a0: 6e20 722e 6f62 6a65 6374 7328 7072 6564  n r.objects(pred
+000076b0: 6963 6174 653d 436f 6e73 7461 6e74 732e  icate=Constants.
+000076c0: 5052 4f56 5b22 6167 656e 7422 5d29 3a0a  PROV["agent"]):.
+000076d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000076e0: 2020 2020 2320 6368 6563 6b20 6966 2074      # check if t
+000076f0: 6865 2061 6765 6e74 2065 7869 7374 7320  he agent exists 
+00007700: 696e 2074 6865 2067 7261 7068 2065 6c73  in the graph els
+00007710: 6520 6164 6420 6974 0a20 2020 2020 2020  e add it.       
+00007720: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00007730: 6167 656e 745f 6f62 6a2e 6964 656e 7469  agent_obj.identi
+00007740: 6669 6572 206e 6f74 2069 6e20 6e69 646d  fier not in nidm
+00007750: 5f6f 626a 2e67 7261 7068 2e67 6574 5f72  _obj.graph.get_r
+00007760: 6563 6f72 6473 2829 3a0a 2020 2020 2020  ecords():.      
+00007770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007780: 2020 6765 6e65 7269 635f 6167 656e 7420    generic_agent 
+00007790: 3d20 6e69 646d 5f6f 626a 2e67 7261 7068  = nidm_obj.graph
+000077a0: 2e61 6765 6e74 280a 2020 2020 2020 2020  .agent(.        
+000077b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000077c0: 2020 2020 6964 656e 7469 6669 6572 3d61      identifier=a
+000077d0: 6765 6e74 5f6f 626a 2e69 6465 6e74 6966  gent_obj.identif
+000077e0: 6965 720a 2020 2020 2020 2020 2020 2020  ier.            
+000077f0: 2020 2020 2020 2020 2020 2020 290a 0a20              ).. 
+00007800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007810: 2020 2020 2020 2023 2061 6464 2072 6573         # add res
+00007820: 7420 6f66 206d 6574 6164 6174 6120 6162  t of metadata ab
+00007830: 6f75 7420 7468 6520 6167 656e 740a 2020  out the agent.  
+00007840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007850: 2020 2020 2020 6164 645f 6d65 7461 6461        add_metada
+00007860: 7461 5f66 6f72 5f73 7562 6a65 6374 280a  ta_for_subject(.
+00007870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007880: 2020 2020 2020 2020 2020 2020 7264 665f              rdf_
+00007890: 6772 6170 683d 7264 665f 6772 6170 682c  graph=rdf_graph,
+000078a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000078b0: 2020 2020 2020 2020 2020 2020 2073 7562               sub
+000078c0: 6a65 6374 5f75 7269 3d61 6765 6e74 5f6f  ject_uri=agent_o
+000078d0: 626a 2e69 6465 6e74 6966 6965 722c 0a20  bj.identifier,. 
+000078e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000078f0: 2020 2020 2020 2020 2020 206e 616d 6573             names
+00007900: 7061 6365 733d 6e61 6d65 7370 6163 6573  paces=namespaces
+00007910: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00007920: 2020 2020 2020 2020 2020 2020 2020 6e69                ni
+00007930: 646d 5f6f 626a 3d67 656e 6572 6963 5f61  dm_obj=generic_a
+00007940: 6765 6e74 2c0a 2020 2020 2020 2020 2020  gent,.          
+00007950: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+00007960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007970: 2020 2020 2320 7472 7920 616e 6420 7370      # try and sp
+00007980: 6c69 7420 7572 6920 696e 746f 206e 616d  lit uri into nam
+00007990: 6573 7061 6365 2061 6e64 206c 6f63 616c  espace and local
+000079a0: 2070 6172 7473 2c20 6966 2066 6169 6c73   parts, if fails
+000079b0: 206a 7573 7420 7573 6520 656e 7469 7265   just use entire
+000079c0: 2055 5249 0a20 2020 2020 2020 2020 2020   URI.           
+000079d0: 2020 2020 2020 2020 2074 7279 3a0a 2020           try:.  
+000079e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000079f0: 2020 2020 2020 2320 6372 6561 7465 2071        # create q
+00007a00: 7561 6c69 6669 6564 206e 616d 6573 2066  ualified names f
+00007a10: 6f72 206f 626a 6563 7473 0a20 2020 2020  or objects.     
+00007a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007a30: 2020 206f 626a 5f6e 6d2c 206f 626a 5f74     obj_nm, obj_t
+00007a40: 6572 6d20 3d20 7370 6c69 745f 7572 6928  erm = split_uri(
+00007a50: 725f 6f62 6a2e 6964 656e 7469 6669 6572  r_obj.identifier
+00007a60: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
+00007a70: 2020 2020 2020 2020 2020 2066 6f75 6e64             found
+00007a80: 5f75 7269 203d 2066 696e 645f 696e 5f6e  _uri = find_in_n
+00007a90: 616d 6573 7061 6365 7328 0a20 2020 2020  amespaces(.     
+00007aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007ab0: 2020 2020 2020 2073 6561 7263 685f 7572         search_ur
+00007ac0: 693d 5552 4952 6566 286f 626a 5f6e 6d29  i=URIRef(obj_nm)
+00007ad0: 2c20 6e61 6d65 7370 6163 6573 3d6e 616d  , namespaces=nam
+00007ae0: 6573 7061 6365 730a 2020 2020 2020 2020  espaces.        
+00007af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007b00: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00007b10: 2020 2020 2020 2020 2020 2320 6966 206f            # if o
+00007b20: 626a 5f6e 6d20 6973 206e 6f74 2069 6e20  bj_nm is not in 
+00007b30: 6e61 6d65 7370 6163 6573 2074 6865 6e20  namespaces then 
+00007b40: 6974 206d 7573 7420 6a75 7374 2062 6520  it must just be 
+00007b50: 7061 7274 206f 6620 736f 6d65 2055 5249  part of some URI
+00007b60: 2069 6e20 7468 6520 7472 6970 6c65 0a20   in the triple. 
+00007b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007b80: 2020 2020 2020 2023 2073 6f20 6a75 7374         # so just
+00007b90: 2061 6464 2069 7420 6173 2061 2070 726f   add it as a pro
+00007ba0: 762e 4964 656e 7469 6669 6572 0a20 2020  v.Identifier.   
+00007bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007bc0: 2020 2020 2069 6620 6e6f 7420 666f 756e       if not foun
+00007bd0: 645f 7572 693a 0a20 2020 2020 2020 2020  d_uri:.         
+00007be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007bf0: 2020 206e 6964 6d5f 6f62 6a2e 6164 645f     nidm_obj.add_
+00007c00: 7175 616c 6966 6965 645f 6173 736f 6369  qualified_associ
+00007c10: 6174 696f 6e28 0a20 2020 2020 2020 2020  ation(.         
+00007c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007c30: 2020 2020 2020 2070 6572 736f 6e3d 6765         person=ge
+00007c40: 6e65 7269 635f 6167 656e 742c 0a20 2020  neric_agent,.   
+00007c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007c60: 2020 2020 2020 2020 2020 2020 2072 6f6c               rol
+00007c70: 653d 706d 2e51 7561 6c69 6669 6564 4e61  e=pm.QualifiedNa
+00007c80: 6d65 284e 616d 6573 7061 6365 286f 626a  me(Namespace(obj
+00007c90: 5f6e 6d29 2c20 6f62 6a5f 7465 726d 292c  _nm), obj_term),
+00007ca0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007cb0: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+00007cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007cd0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00007ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007cf0: 2020 2020 2020 2020 206e 6964 6d5f 6f62           nidm_ob
+00007d00: 6a2e 6164 645f 7175 616c 6966 6965 645f  j.add_qualified_
+00007d10: 6173 736f 6369 6174 696f 6e28 0a20 2020  association(.   
+00007d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007d30: 2020 2020 2020 2020 2020 2020 2070 6572               per
+00007d40: 736f 6e3d 6765 6e65 7269 635f 6167 656e  son=generic_agen
+00007d50: 742c 0a20 2020 2020 2020 2020 2020 2020  t,.             
+00007d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007d70: 2020 2072 6f6c 653d 706d 2e51 7561 6c69     role=pm.Quali
+00007d80: 6669 6564 4e61 6d65 2866 6f75 6e64 5f75  fiedName(found_u
+00007d90: 7269 2c20 6f62 6a5f 7465 726d 292c 0a20  ri, obj_term),. 
+00007da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007db0: 2020 2020 2020 2020 2020 2029 0a0a 2020             )..  
+00007dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007dd0: 2020 6578 6365 7074 2045 7863 6570 7469    except Excepti
+00007de0: 6f6e 3a0a 2020 2020 2020 2020 2020 2020  on:.            
+00007df0: 2020 2020 2020 2020 2020 2020 6e69 646d              nidm
+00007e00: 5f6f 626a 2e61 6464 5f71 7561 6c69 6669  _obj.add_qualifi
+00007e10: 6564 5f61 7373 6f63 6961 7469 6f6e 280a  ed_association(.
+00007e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007e30: 2020 2020 2020 2020 2020 2020 7065 7273              pers
+00007e40: 6f6e 3d67 656e 6572 6963 5f61 6765 6e74  on=generic_agent
+00007e50: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00007e60: 2020 2020 2020 2020 2020 2020 2020 726f                ro
+00007e70: 6c65 3d70 6d2e 5175 616c 6966 6965 644e  le=pm.QualifiedN
+00007e80: 616d 6528 4e61 6d65 7370 6163 6528 725f  ame(Namespace(r_
+00007e90: 6f62 6a2e 6964 656e 7469 6669 6572 292c  obj.identifier),
+00007ea0: 2022 2229 2c0a 2020 2020 2020 2020 2020   ""),.          
+00007eb0: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+00007ec0: 0a0a 6465 6620 5175 6572 7953 6369 4372  ..def QuerySciCr
+00007ed0: 756e 6368 456c 6173 7469 6353 6561 7263  unchElasticSearc
+00007ee0: 6828 0a20 2020 2071 7565 7279 5f73 7472  h(.    query_str
+00007ef0: 696e 672c 2074 7970 653d 2263 6465 222c  ing, type="cde",
+00007f00: 2061 6e73 6365 7374 6f72 733d 5472 7565   anscestors=True
+00007f10: 2020 2320 6e6f 7161 3a20 4130 3032 0a29    # noqa: A002.)
+00007f20: 3a0a 2020 2020 2222 220a 2020 2020 5468  :.    """.    Th
+00007f30: 6973 2066 756e 6374 696f 6e20 7769 6c6c  is function will
+00007f40: 2070 6572 666f 726d 2061 6e20 656c 6173   perform an elas
+00007f50: 7469 6320 7365 6172 6368 2069 6e20 5363  tic search in Sc
+00007f60: 6943 7275 6e63 6820 6f6e 2074 6865 205b  iCrunch on the [
+00007f70: 7175 6572 795f 7374 7269 6e67 5d20 7573  query_string] us
+00007f80: 696e 6720 4150 4920 5b6b 6579 5d20 616e  ing API [key] an
+00007f90: 6420 7265 7475 726e 2074 6865 206a 736f  d return the jso
+00007fa0: 6e20 7061 636b 6167 652e 0a20 2020 203a  n package..    :
+00007fb0: 7061 7261 6d20 6b65 793a 2041 5049 206b  param key: API k
+00007fc0: 6579 2066 726f 6d20 7363 6920 6372 756e  ey from sci crun
+00007fd0: 6368 0a20 2020 203a 7061 7261 6d20 7175  ch.    :param qu
+00007fe0: 6572 795f 7374 7269 6e67 3a20 6172 6269  ery_string: arbi
+00007ff0: 7472 6172 7920 7374 7269 6e67 2074 6f20  trary string to 
+00008000: 7365 6172 6368 2066 6f72 2074 6572 6d73  search for terms
+00008010: 0a20 2020 203a 7061 7261 6d20 7479 7065  .    :param type
+00008020: 3a20 6465 6661 756c 7420 6973 2027 4344  : default is 'CD
+00008030: 4527 2e20 2041 6363 6570 7461 626c 6520  E'.  Acceptable 
+00008040: 7661 6c75 6573 2061 7265 2027 6364 6527  values are 'cde'
+00008050: 206f 7220 2770 6465 272e 0a20 2020 203a   or 'pde'..    :
+00008060: 7265 7475 726e 3a20 6a73 6f6e 2064 6f63  return: json doc
+00008070: 756d 656e 7420 6f66 2072 6573 756c 7473  ument of results
+00008080: 2066 6f72 6d20 656c 6173 7469 6320 7365   form elastic se
+00008090: 6172 6368 0a20 2020 2022 2222 0a0a 2020  arch.    """..  
+000080a0: 2020 2320 4e6f 7465 2c20 6f6e 6365 204a    # Note, once J
+000080b0: 6566 6620 4772 6574 6865 2c20 6574 2061  eff Grethe, et a
+000080c0: 6c2e 2067 6976 6520 7573 2074 6865 2071  l. give us the q
+000080d0: 7565 7279 2074 6f20 6765 7420 7468 6520  uery to get the 
+000080e0: 5265 7072 6f4e 696d 2022 7461 6767 6564  ReproNim "tagged
+000080f0: 2220 616e 6365 7374 6f72 7320 7175 6572  " ancestors quer
+00008100: 7920 7765 2764 2064 6f20 7468 6174 2071  y we'd do that q
+00008110: 7565 7279 2066 6972 7374 2061 6e64 2072  uery first and r
+00008120: 6570 6c61 6365 0a20 2020 2023 2074 6865  eplace.    # the
+00008130: 2022 616e 6365 7374 6f72 732e 696c 7822   "ancestors.ilx"
+00008140: 2070 6172 616d 6574 6572 2069 6e20 7468   parameter in th
+00008150: 6520 7175 6572 7920 6461 7461 2070 6163  e query data pac
+00008160: 6b61 6765 2062 656c 6f77 2077 6974 6820  kage below with 
+00008170: 6e65 7720 696e 7465 726c 6578 2049 4473  new interlex IDs
+00008180: 2e2e 2e0a 2020 2020 2320 7468 6973 2061  ....    # this a
+00008190: 6c6c 6f77 7320 696e 7465 726c 6578 2064  llows interlex d
+000081a0: 6576 656c 6f70 6572 7320 746f 2064 796e  evelopers to dyn
+000081b0: 616d 6963 616c 6c20 6368 616e 6765 2074  amicall change t
+000081c0: 6865 2061 6e63 6573 746f 7220 7465 726d  he ancestor term
+000081d0: 7320 7468 6174 2061 7265 2070 6172 7420  s that are part 
+000081e0: 6f66 2074 6865 2052 6570 726f 4e69 6d20  of the ReproNim 
+000081f0: 7465 726d 2074 726f 7665 2061 6e64 2068  term trove and h
+00008200: 6176 6520 7468 6973 0a20 2020 2023 2071  ave this.    # q
+00008210: 7565 7279 2075 7365 2074 6861 7420 6e65  uery use that ne
+00008220: 7720 696e 666f 726d 6174 696f 6e2e 2e2e  w information...
+00008230: 2e0a 0a20 2020 2074 7279 3a0a 2020 2020  ...    try:.    
+00008240: 2020 2020 6f73 2e65 6e76 6972 6f6e 5b22      os.environ["
+00008250: 494e 5445 524c 4558 5f41 5049 5f4b 4559  INTERLEX_API_KEY
+00008260: 225d 0a20 2020 2065 7863 6570 7420 4b65  "].    except Ke
+00008270: 7945 7272 6f72 3a0a 2020 2020 2020 2020  yError:.        
+00008280: 7072 696e 7428 2250 6c65 6173 6520 7365  print("Please se
+00008290: 7420 7468 6520 656e 7669 726f 6e6d 656e  t the environmen
+000082a0: 7420 7661 7269 6162 6c65 2049 4e54 4552  t variable INTER
+000082b0: 4c45 585f 4150 495f 4b45 5922 290a 2020  LEX_API_KEY").  
+000082c0: 2020 2020 2020 7379 732e 6578 6974 2831        sys.exit(1
+000082d0: 290a 2020 2020 2320 4164 6420 6368 6563  ).    # Add chec
+000082e0: 6b20 666f 7220 696e 7465 726e 6574 2063  k for internet c
+000082f0: 6f6e 6e65 6374 696f 6e2c 2069 6620 6e6f  onnection, if no
+00008300: 7420 7468 656e 2073 6b69 7020 7468 6973  t then skip this
+00008310: 2071 7565 7279 2e2e 2e72 6574 7572 6e20   query...return 
+00008320: 656d 7074 7920 6469 6374 696f 6e61 7279  empty dictionary
+00008330: 0a0a 2020 2020 7061 7261 6d73 203d 2028  ..    params = (
+00008340: 2822 6b65 7922 2c20 6f73 2e65 6e76 6972  ("key", os.envir
+00008350: 6f6e 5b22 494e 5445 524c 4558 5f41 5049  on["INTERLEX_API
+00008360: 5f4b 4559 225d 292c 290a 2020 2020 6966  _KEY"]),).    if
+00008370: 2074 7970 6520 3d3d 2022 6364 6522 3a0a   type == "cde":.
+00008380: 2020 2020 2020 2020 6966 2061 6e73 6365          if ansce
+00008390: 7374 6f72 733a 0a20 2020 2020 2020 2020  stors:.         
+000083a0: 2020 2064 6174 6120 3d20 7b0a 2020 2020     data = {.    
+000083b0: 2020 2020 2020 2020 2020 2020 2271 7565              "que
+000083c0: 7279 223a 207b 0a20 2020 2020 2020 2020  ry": {.         
+000083d0: 2020 2020 2020 2020 2020 2022 626f 6f6c             "bool
+000083e0: 223a 207b 0a20 2020 2020 2020 2020 2020  ": {.           
+000083f0: 2020 2020 2020 2020 2020 2020 2022 6d75               "mu
+00008400: 7374 223a 205b 0a20 2020 2020 2020 2020  st": [.         
+00008410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008420: 2020 207b 2274 6572 6d22 3a20 7b22 7479     {"term": {"ty
+00008430: 7065 223a 2022 6364 6522 7d7d 2c0a 2020  pe": "cde"}},.  
+00008440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008450: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
+00008460: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008470: 2020 2020 2020 2020 2020 2020 2274 6572              "ter
+00008480: 6d73 223a 207b 0a20 2020 2020 2020 2020  ms": {.         
+00008490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000084a0: 2020 2020 2020 2020 2020 2022 616e 6365             "ance
+000084b0: 7374 6f72 732e 696c 7822 3a20 5b0a 2020  stors.ilx": [.  
+000084c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000084d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000084e0: 2020 2020 2020 2269 6c78 5f30 3131 3530        "ilx_01150
+000084f0: 3636 222c 0a20 2020 2020 2020 2020 2020  66",.           
+00008500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008510: 2020 2020 2020 2020 2020 2020 2022 696c               "il
+00008520: 785f 3031 3033 3231 3022 2c0a 2020 2020  x_0103210",.    
+00008530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008550: 2020 2020 2269 6c78 5f30 3131 3530 3732      "ilx_0115072
+00008560: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00008570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008580: 2020 2020 2020 2020 2020 2022 696c 785f             "ilx_
+00008590: 3031 3135 3037 3022 2c0a 2020 2020 2020  0115070",.      
+000085a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000085b0: 2020 2020 2020 2020 2020 2020 2020 5d0a                ].
+000085c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000085d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000085e0: 7d0a 2020 2020 2020 2020 2020 2020 2020  }.              
+000085f0: 2020 2020 2020 2020 2020 2020 2020 7d2c                },
+00008600: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00008610: 2020 2020 2020 2020 2020 2020 207b 0a20               {. 
+00008620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008630: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00008640: 6d75 6c74 695f 6d61 7463 6822 3a20 7b0a  multi_match": {.
+00008650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008670: 2020 2020 2271 7565 7279 223a 2071 7565      "query": que
+00008680: 7279 5f73 7472 696e 672c 0a20 2020 2020  ry_string,.     
+00008690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000086a0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000086b0: 6669 656c 6473 223a 205b 226c 6162 656c  fields": ["label
+000086c0: 222c 2022 6465 6669 6e69 7469 6f6e 225d  ", "definition"]
+000086d0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000086e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000086f0: 2020 7d0a 2020 2020 2020 2020 2020 2020    }.            
+00008700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008710: 7d2c 0a20 2020 2020 2020 2020 2020 2020  },.             
+00008720: 2020 2020 2020 2020 2020 205d 0a20 2020             ].   
+00008730: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008740: 207d 0a20 2020 2020 2020 2020 2020 2020   }.             
+00008750: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
+00008760: 207d 0a20 2020 2020 2020 2065 6c73 653a   }.        else:
+00008770: 0a20 2020 2020 2020 2020 2020 2064 6174  .            dat
+00008780: 6120 3d20 7b0a 2020 2020 2020 2020 2020  a = {.          
+00008790: 2020 2020 2020 2271 7565 7279 223a 207b        "query": {
+000087a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000087b0: 2020 2020 2022 626f 6f6c 223a 207b 0a20       "bool": {. 
+000087c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000087d0: 2020 2020 2020 2022 6d75 7374 223a 205b         "must": [
+000087e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000087f0: 2020 2020 2020 2020 2020 2020 207b 2274               {"t
+00008800: 6572 6d22 3a20 7b22 7479 7065 223a 2022  erm": {"type": "
+00008810: 6364 6522 7d7d 2c0a 2020 2020 2020 2020  cde"}},.        
+00008820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008830: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
+00008840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008850: 2020 2020 2020 226d 756c 7469 5f6d 6174        "multi_mat
+00008860: 6368 223a 207b 0a20 2020 2020 2020 2020  ch": {.         
+00008870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008880: 2020 2020 2020 2020 2020 2022 7175 6572             "quer
+00008890: 7922 3a20 7175 6572 795f 7374 7269 6e67  y": query_string
+000088a0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000088b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000088c0: 2020 2020 2020 2266 6965 6c64 7322 3a20        "fields": 
+000088d0: 5b22 6c61 6265 6c22 2c20 2264 6566 696e  ["label", "defin
+000088e0: 6974 696f 6e22 5d2c 0a20 2020 2020 2020  ition"],.       
+000088f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008900: 2020 2020 2020 2020 207d 0a20 2020 2020           }.     
+00008910: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008920: 2020 2020 2020 207d 2c0a 2020 2020 2020         },.      
+00008930: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008940: 2020 5d0a 2020 2020 2020 2020 2020 2020    ].            
+00008950: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
+00008960: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+00008970: 2020 2020 2020 2020 7d0a 2020 2020 656c          }.    el
+00008980: 6966 2074 7970 6520 3d3d 2022 7064 6522  if type == "pde"
+00008990: 3a0a 2020 2020 2020 2020 6966 2061 6e73  :.        if ans
+000089a0: 6365 7374 6f72 733a 0a20 2020 2020 2020  cestors:.       
+000089b0: 2020 2020 2064 6174 6120 3d20 7b0a 2020       data = {.  
+000089c0: 2020 2020 2020 2020 2020 2020 2020 2271                "q
+000089d0: 7565 7279 223a 207b 0a20 2020 2020 2020  uery": {.       
+000089e0: 2020 2020 2020 2020 2020 2020 2022 626f               "bo
+000089f0: 6f6c 223a 207b 0a20 2020 2020 2020 2020  ol": {.         
+00008a00: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00008a10: 6d75 7374 223a 205b 0a20 2020 2020 2020  must": [.       
+00008a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008a30: 2020 2020 207b 2274 6572 6d22 3a20 7b22       {"term": {"
+00008a40: 7479 7065 223a 2022 7064 6522 7d7d 2c0a  type": "pde"}},.
+00008a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008a60: 2020 2020 2020 2020 2020 2020 7b0a 2020              {.  
+00008a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008a80: 2020 2020 2020 2020 2020 2020 2020 2274                "t
+00008a90: 6572 6d73 223a 207b 0a20 2020 2020 2020  erms": {.       
+00008aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008ab0: 2020 2020 2020 2020 2020 2020 2022 616e               "an
+00008ac0: 6365 7374 6f72 732e 696c 7822 3a20 5b0a  cestors.ilx": [.
+00008ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008af0: 2020 2020 2020 2020 2269 6c78 5f30 3131          "ilx_011
+00008b00: 3530 3636 222c 0a20 2020 2020 2020 2020  5066",.         
+00008b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008b20: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00008b30: 696c 785f 3031 3033 3231 3022 2c0a 2020  ilx_0103210",.  
+00008b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008b60: 2020 2020 2020 2269 6c78 5f30 3131 3530        "ilx_01150
+00008b70: 3732 222c 0a20 2020 2020 2020 2020 2020  72",.           
+00008b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008b90: 2020 2020 2020 2020 2020 2020 2022 696c               "il
+00008ba0: 785f 3031 3135 3037 3022 2c0a 2020 2020  x_0115070",.    
+00008bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008bd0: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+00008be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008bf0: 2020 7d0a 2020 2020 2020 2020 2020 2020    }.            
+00008c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008c10: 7d2c 0a20 2020 2020 2020 2020 2020 2020  },.             
+00008c20: 2020 2020 2020 2020 2020 2020 2020 207b                 {
+00008c30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00008c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008c50: 2022 6d75 6c74 695f 6d61 7463 6822 3a20   "multi_match": 
+00008c60: 7b0a 2020 2020 2020 2020 2020 2020 2020  {.              
+00008c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008c80: 2020 2020 2020 2271 7565 7279 223a 2071        "query": q
+00008c90: 7565 7279 5f73 7472 696e 672c 0a20 2020  uery_string,.   
+00008ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008cc0: 2022 6669 656c 6473 223a 205b 226c 6162   "fields": ["lab
+00008cd0: 656c 222c 2022 6465 6669 6e69 7469 6f6e  el", "definition
+00008ce0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+00008cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008d00: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
+00008d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008d20: 2020 7d2c 0a20 2020 2020 2020 2020 2020    },.           
+00008d30: 2020 2020 2020 2020 2020 2020 205d 0a20               ]. 
+00008d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008d50: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
+00008d60: 2020 2020 207d 0a20 2020 2020 2020 2020       }.         
+00008d70: 2020 207d 0a20 2020 2020 2020 2065 6c73     }.        els
+00008d80: 653a 0a20 2020 2020 2020 2020 2020 2064  e:.            d
+00008d90: 6174 6120 3d20 7b0a 2020 2020 2020 2020  ata = {.        
+00008da0: 2020 2020 2020 2020 2271 7565 7279 223a          "query":
+00008db0: 207b 0a20 2020 2020 2020 2020 2020 2020   {.             
+00008dc0: 2020 2020 2020 2022 626f 6f6c 223a 207b         "bool": {
+00008dd0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00008de0: 2020 2020 2020 2020 2022 6d75 7374 223a           "must":
+00008df0: 205b 0a20 2020 2020 2020 2020 2020 2020   [.             
+00008e00: 2020 2020 2020 2020 2020 2020 2020 207b                 {
+00008e10: 2274 6572 6d22 3a20 7b22 7479 7065 223a  "term": {"type":
+00008e20: 2022 7064 6522 7d7d 2c0a 2020 2020 2020   "pde"}},.      
+00008e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008e40: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+00008e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008e60: 2020 2020 2020 2020 226d 756c 7469 5f6d          "multi_m
+00008e70: 6174 6368 223a 207b 0a20 2020 2020 2020  atch": {.       
+00008e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008e90: 2020 2020 2020 2020 2020 2020 2022 7175               "qu
+00008ea0: 6572 7922 3a20 7175 6572 795f 7374 7269  ery": query_stri
+00008eb0: 6e67 2c0a 2020 2020 2020 2020 2020 2020  ng,.            
+00008ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008ed0: 2020 2020 2020 2020 2266 6965 6c64 7322          "fields"
+00008ee0: 3a20 5b22 6c61 6265 6c22 2c20 2264 6566  : ["label", "def
+00008ef0: 696e 6974 696f 6e22 5d2c 0a20 2020 2020  inition"],.     
+00008f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008f10: 2020 2020 2020 2020 2020 207d 0a20 2020             }.   
+00008f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008f30: 2020 2020 2020 2020 207d 2c0a 2020 2020           },.    
+00008f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008f50: 2020 2020 5d0a 2020 2020 2020 2020 2020      ].          
+00008f60: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+00008f70: 2020 2020 2020 2020 2020 2020 7d0a 2020              }.  
+00008f80: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+00008f90: 656c 6966 2074 7970 6520 3d3d 2022 6664  elif type == "fd
+00008fa0: 6522 3a0a 2020 2020 2020 2020 6966 2061  e":.        if a
+00008fb0: 6e73 6365 7374 6f72 733a 0a20 2020 2020  nscestors:.     
+00008fc0: 2020 2020 2020 2064 6174 6120 3d20 7b0a         data = {.
+00008fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008fe0: 2271 7565 7279 223a 207b 0a20 2020 2020  "query": {.     
+00008ff0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00009000: 626f 6f6c 223a 207b 0a20 2020 2020 2020  bool": {.       
+00009010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009020: 2022 6d75 7374 223a 205b 0a20 2020 2020   "must": [.     
+00009030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009040: 2020 2020 2020 207b 2274 6572 6d22 3a20         {"term": 
+00009050: 7b22 7479 7065 223a 2022 6664 6522 7d7d  {"type": "fde"}}
+00009060: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00009070: 2020 2020 2020 2020 2020 2020 2020 7b0a                {.
+00009080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000090a0: 2274 6572 6d73 223a 207b 0a20 2020 2020  "terms": {.     
+000090b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000090c0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000090d0: 616e 6365 7374 6f72 732e 696c 7822 3a20  ancestors.ilx": 
+000090e0: 5b0a 2020 2020 2020 2020 2020 2020 2020  [.              
+000090f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009100: 2020 2020 2020 2020 2020 2269 6c78 5f30            "ilx_0
+00009110: 3131 3530 3636 222c 0a20 2020 2020 2020  115066",.       
+00009120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009140: 2022 696c 785f 3031 3033 3231 3022 2c0a   "ilx_0103210",.
+00009150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009170: 2020 2020 2020 2020 2269 6c78 5f30 3131          "ilx_011
+00009180: 3530 3732 222c 0a20 2020 2020 2020 2020  5072",.         
+00009190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000091a0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000091b0: 696c 785f 3031 3135 3037 3022 2c0a 2020  ilx_0115070",.  
+000091c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000091d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000091e0: 2020 5d0a 2020 2020 2020 2020 2020 2020    ].            
+000091f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009200: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
+00009210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009220: 2020 7d2c 0a20 2020 2020 2020 2020 2020    },.           
+00009230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009240: 207b 0a20 2020 2020 2020 2020 2020 2020   {.             
+00009250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009260: 2020 2022 6d75 6c74 695f 6d61 7463 6822     "multi_match"
+00009270: 3a20 7b0a 2020 2020 2020 2020 2020 2020  : {.            
+00009280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009290: 2020 2020 2020 2020 2271 7565 7279 223a          "query":
+000092a0: 2071 7565 7279 5f73 7472 696e 672c 0a20   query_string,. 
+000092b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000092c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000092d0: 2020 2022 6669 656c 6473 223a 205b 226c     "fields": ["l
+000092e0: 6162 656c 222c 2022 6465 6669 6e69 7469  abel", "definiti
+000092f0: 6f6e 225d 2c0a 2020 2020 2020 2020 2020  on"],.          
+00009300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009310: 2020 2020 2020 7d0a 2020 2020 2020 2020        }.        
+00009320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009330: 2020 2020 7d2c 0a20 2020 2020 2020 2020      },.         
+00009340: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
+00009350: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00009360: 2020 2020 207d 0a20 2020 2020 2020 2020       }.         
+00009370: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+00009380: 2020 2020 207d 0a20 2020 2020 2020 2065       }.        e
+00009390: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+000093a0: 2064 6174 6120 3d20 7b0a 2020 2020 2020   data = {.      
+000093b0: 2020 2020 2020 2020 2020 2271 7565 7279            "query
+000093c0: 223a 207b 0a20 2020 2020 2020 2020 2020  ": {.           
+000093d0: 2020 2020 2020 2020 2022 626f 6f6c 223a           "bool":
+000093e0: 207b 0a20 2020 2020 2020 2020 2020 2020   {.             
+000093f0: 2020 2020 2020 2020 2020 2022 6d75 7374             "must
+00009400: 223a 205b 0a20 2020 2020 2020 2020 2020  ": [.           
+00009410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009420: 207b 2274 6572 6d22 3a20 7b22 7479 7065   {"term": {"type
+00009430: 223a 2022 6664 6522 7d7d 2c0a 2020 2020  ": "fde"}},.    
+00009440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009450: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
+00009460: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009470: 2020 2020 2020 2020 2020 226d 756c 7469            "multi
+00009480: 5f6d 6174 6368 223a 207b 0a20 2020 2020  _match": {.     
+00009490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000094a0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000094b0: 7175 6572 7922 3a20 7175 6572 795f 7374  query": query_st
+000094c0: 7269 6e67 2c0a 2020 2020 2020 2020 2020  ring,.          
+000094d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000094e0: 2020 2020 2020 2020 2020 2266 6965 6c64            "field
+000094f0: 7322 3a20 5b22 6c61 6265 6c22 2c20 2264  s": ["label", "d
+00009500: 6566 696e 6974 696f 6e22 5d2c 0a20 2020  efinition"],.   
+00009510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009520: 2020 2020 2020 2020 2020 2020 207d 0a20               }. 
+00009530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009540: 2020 2020 2020 2020 2020 207d 2c0a 2020             },.  
+00009550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009560: 2020 2020 2020 5d0a 2020 2020 2020 2020        ].        
+00009570: 2020 2020 2020 2020 2020 2020 7d0a 2020              }.  
+00009580: 2020 2020 2020 2020 2020 2020 2020 7d0a                }.
+00009590: 2020 2020 2020 2020 2020 2020 7d0a 0a20              }.. 
+000095a0: 2020 2065 6c69 6620 7479 7065 203d 3d20     elif type == 
+000095b0: 2274 6572 6d22 3a0a 2020 2020 2020 2020  "term":.        
+000095c0: 6966 2061 6e73 6365 7374 6f72 733a 0a20  if anscestors:. 
+000095d0: 2020 2020 2020 2020 2020 2064 6174 6120             data 
+000095e0: 3d20 7b0a 2020 2020 2020 2020 2020 2020  = {.            
+000095f0: 2020 2020 2271 7565 7279 223a 207b 0a20      "query": {. 
+00009600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009610: 2020 2022 626f 6f6c 223a 207b 0a20 2020     "bool": {.   
+00009620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009630: 2020 2020 2022 6d75 7374 223a 205b 0a20       "must": [. 
+00009640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009650: 2020 2020 2020 2020 2020 207b 2274 6572             {"ter
+00009660: 6d22 3a20 7b22 7479 7065 223a 2022 7465  m": {"type": "te
+00009670: 726d 227d 7d2c 0a20 2020 2020 2020 2020  rm"}},.         
+00009680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009690: 2020 207b 0a20 2020 2020 2020 2020 2020     {.           
+000096a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000096b0: 2020 2020 2022 7465 726d 7322 3a20 7b0a       "terms": {.
+000096c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000096d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000096e0: 2020 2020 2261 6e63 6573 746f 7273 2e69      "ancestors.i
+000096f0: 6c78 223a 205b 0a20 2020 2020 2020 2020  lx": [.         
+00009700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009710: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00009720: 696c 785f 3031 3135 3036 3622 2c0a 2020  ilx_0115066",.  
+00009730: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009750: 2020 2020 2020 2269 6c78 5f30 3130 3332        "ilx_01032
+00009760: 3130 222c 0a20 2020 2020 2020 2020 2020  10",.           
+00009770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009780: 2020 2020 2020 2020 2020 2020 2022 696c               "il
+00009790: 785f 3031 3135 3037 3222 2c0a 2020 2020  x_0115072",.    
+000097a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000097b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000097c0: 2020 2020 2269 6c78 5f30 3131 3530 3730      "ilx_0115070
+000097d0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+000097e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000097f0: 2020 2020 2020 205d 0a20 2020 2020 2020         ].       
+00009800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009810: 2020 2020 2020 2020 207d 0a20 2020 2020           }.     
+00009820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009830: 2020 2020 2020 207d 2c0a 2020 2020 2020         },.      
+00009840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009850: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+00009860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009870: 2020 2020 2020 2020 226d 756c 7469 5f6d          "multi_m
+00009880: 6174 6368 223a 207b 0a20 2020 2020 2020  atch": {.       
+00009890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000098a0: 2020 2020 2020 2020 2020 2020 2022 7175               "qu
+000098b0: 6572 7922 3a20 7175 6572 795f 7374 7269  ery": query_stri
+000098c0: 6e67 2c0a 2020 2020 2020 2020 2020 2020  ng,.            
+000098d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000098e0: 2020 2020 2020 2020 2266 6965 6c64 7322          "fields"
+000098f0: 3a20 5b22 6c61 6265 6c22 2c20 2264 6566  : ["label", "def
+00009900: 696e 6974 696f 6e22 5d2c 0a20 2020 2020  inition"],.     
+00009910: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009920: 2020 2020 2020 2020 2020 207d 0a20 2020             }.   
+00009930: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009940: 2020 2020 2020 2020 207d 2c0a 2020 2020           },.    
+00009950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009960: 2020 2020 5d0a 2020 2020 2020 2020 2020      ].          
+00009970: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+00009980: 2020 2020 2020 2020 2020 2020 7d0a 2020              }.  
+00009990: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+000099a0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+000099b0: 2020 2020 2020 6461 7461 203d 207b 0a20        data = {. 
+000099c0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000099d0: 7175 6572 7922 3a20 7b0a 2020 2020 2020  query": {.      
+000099e0: 2020 2020 2020 2020 2020 2020 2020 2262                "b
+000099f0: 6f6f 6c22 3a20 7b0a 2020 2020 2020 2020  ool": {.        
+00009a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009a10: 226d 7573 7422 3a20 5b0a 2020 2020 2020  "must": [.      
+00009a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009a30: 2020 2020 2020 7b22 7465 726d 223a 207b        {"term": {
+00009a40: 2274 7970 6522 3a20 2274 6572 6d22 7d7d  "type": "term"}}
+00009a50: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00009a60: 2020 2020 2020 2020 2020 2020 2020 7b0a                {.
+00009a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009a90: 226d 756c 7469 5f6d 6174 6368 223a 207b  "multi_match": {
+00009aa0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00009ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009ac0: 2020 2020 2022 7175 6572 7922 3a20 7175       "query": qu
+00009ad0: 6572 795f 7374 7269 6e67 2c0a 2020 2020  ery_string,.    
+00009ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009b00: 2266 6965 6c64 7322 3a20 5b22 6c61 6265  "fields": ["labe
+00009b10: 6c22 2c20 2264 6566 696e 6974 696f 6e22  l", "definition"
+00009b20: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00009b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009b40: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
+00009b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009b60: 207d 2c0a 2020 2020 2020 2020 2020 2020   },.            
+00009b70: 2020 2020 2020 2020 2020 2020 5d0a 2020              ].  
+00009b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009b90: 2020 7d0a 2020 2020 2020 2020 2020 2020    }.            
+00009ba0: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
+00009bb0: 2020 7d0a 0a20 2020 2065 6c73 653a 0a20    }..    else:. 
+00009bc0: 2020 2020 2020 2070 7269 6e74 280a 2020         print(.  
+00009bd0: 2020 2020 2020 2020 2020 6622 4552 524f            f"ERRO
+00009be0: 523a 2056 616c 6964 2074 7970 6573 2066  R: Valid types f
+00009bf0: 6f72 2053 6369 4372 756e 6368 2071 7565  or SciCrunch que
+00009c00: 7279 2061 7265 2027 6364 6527 2c27 7064  ry are 'cde','pd
+00009c10: 6527 2c20 6f72 2027 6664 6527 2e20 2059  e', or 'fde'.  Y
+00009c20: 6f75 2073 6574 2074 7970 653a 207b 7479  ou set type: {ty
+00009c30: 7065 7d20 220a 2020 2020 2020 2020 290a  pe} ".        ).
+00009c40: 2020 2020 2020 2020 7072 696e 7428 2245          print("E
+00009c50: 5252 4f52 3a20 696e 2066 756e 6374 696f  RROR: in functio
+00009c60: 6e20 5574 696c 732e 7079 2f51 7565 7279  n Utils.py/Query
+00009c70: 5363 6943 7275 6e63 6845 6c61 7374 6963  SciCrunchElastic
+00009c80: 5365 6172 6368 2229 0a20 2020 2020 2020  Search").       
+00009c90: 2073 7973 2e65 7869 7428 3129 0a0a 2020   sys.exit(1)..  
+00009ca0: 2020 7265 7370 6f6e 7365 203d 2072 6571    response = req
+00009cb0: 7565 7374 732e 706f 7374 280a 2020 2020  uests.post(.    
+00009cc0: 2020 2020 2268 7474 7073 3a2f 2f73 6369      "https://sci
+00009cd0: 6372 756e 6368 2e6f 7267 2f61 7069 2f31  crunch.org/api/1
+00009ce0: 2f65 6c61 7374 6963 2d69 6c78 2f69 6e74  /elastic-ilx/int
+00009cf0: 6572 6c65 782f 7465 726d 2f5f 7365 6172  erlex/term/_sear
+00009d00: 6368 2322 2c0a 2020 2020 2020 2020 7061  ch#",.        pa
+00009d10: 7261 6d73 3d70 6172 616d 732c 0a20 2020  rams=params,.   
+00009d20: 2020 2020 206a 736f 6e3d 6461 7461 2c0a       json=data,.
+00009d30: 2020 2020 290a 0a20 2020 2072 6574 7572      )..    retur
+00009d40: 6e20 6a73 6f6e 2e6c 6f61 6473 2872 6573  n json.loads(res
+00009d50: 706f 6e73 652e 7465 7874 290a 0a0a 6465  ponse.text)...de
+00009d60: 6620 4765 744e 4944 4d54 6572 6d73 4672  f GetNIDMTermsFr
+00009d70: 6f6d 5363 6943 7275 6e63 6828 7175 6572  omSciCrunch(quer
+00009d80: 795f 7374 7269 6e67 2c20 7479 7065 3d22  y_string, type="
+00009d90: 6364 6522 2c20 616e 6365 7374 6f72 3d54  cde", ancestor=T
+00009da0: 7275 6529 3a20 2023 206e 6f71 613a 2041  rue):  # noqa: A
+00009db0: 3030 320a 2020 2020 2222 220a 2020 2020  002.    """.    
+00009dc0: 4865 6c70 6572 2066 756e 6374 696f 6e20  Helper function 
+00009dd0: 7768 6963 6820 6973 7375 6573 2065 6c61  which issues ela
+00009de0: 7374 6963 2073 6561 7263 6820 7175 6572  stic search quer
+00009df0: 7920 6f66 2053 6369 4372 756e 6368 2075  y of SciCrunch u
+00009e00: 7369 6e67 2051 7565 7279 5363 6943 7275  sing QuerySciCru
+00009e10: 6e63 6845 6c61 7374 6963 5365 6172 6368  nchElasticSearch
+00009e20: 2066 756e 6374 696f 6e20 616e 6420 7265   function and re
+00009e30: 7475 726e 7320 7465 726d 7320 6c69 7374  turns terms list
+00009e40: 0a20 2020 2077 6974 6820 6c61 6265 6c2c  .    with label,
+00009e50: 2064 6566 696e 6974 696f 6e2c 2061 6e64   definition, and
+00009e60: 2070 7265 6665 7272 6564 2055 524c 7320   preferred URLs 
+00009e70: 696e 2064 6963 7469 6f6e 6172 790a 2020  in dictionary.  
+00009e80: 2020 3a70 6172 616d 206b 6579 3a20 4150    :param key: AP
+00009e90: 4920 6b65 7920 6672 6f6d 2073 6369 2063  I key from sci c
+00009ea0: 7275 6e63 680a 2020 2020 3a70 6172 616d  runch.    :param
+00009eb0: 2071 7565 7279 5f73 7472 696e 673a 2061   query_string: a
+00009ec0: 7262 6974 7261 7279 2073 7472 696e 6720  rbitrary string 
+00009ed0: 746f 2073 6561 7263 6820 666f 7220 7465  to search for te
+00009ee0: 726d 730a 2020 2020 3a70 6172 616d 2074  rms.    :param t
+00009ef0: 7970 653a 2073 686f 756c 6420 6265 2027  ype: should be '
+00009f00: 6364 6527 206f 7220 2770 6465 2720 666f  cde' or 'pde' fo
+00009f10: 7220 7468 6520 6d6f 6d65 6e74 0a20 2020  r the moment.   
+00009f20: 203a 7061 7261 6d20 616e 6365 7374 6f72   :param ancestor
+00009f30: 3a20 426f 6f6c 6561 6e20 666c 6167 2074  : Boolean flag t
+00009f40: 6f20 7465 6c6c 2049 6e74 6572 6c65 7820  o tell Interlex 
+00009f50: 656c 6173 7469 6320 7365 6172 6368 2074  elastic search t
+00009f60: 6f20 7573 6520 616e 6365 7374 6f72 7320  o use ancestors 
+00009f70: 2869 2e65 2e20 7461 6767 6564 2074 6572  (i.e. tagged ter
+00009f80: 6d73 2920 6f72 206e 6f74 0a20 2020 203a  ms) or not.    :
+00009f90: 7265 7475 726e 3a20 6469 6374 696f 6e61  return: dictiona
+00009fa0: 7279 2077 6974 6820 6b65 7973 2027 696c  ry with keys 'il
+00009fb0: 7827 2c27 6c61 6265 6c27 2c27 6465 6669  x','label','defi
+00009fc0: 6e69 7469 6f6e 272c 2770 7265 6665 7272  nition','preferr
+00009fd0: 6564 5f75 726c 270a 2020 2020 2222 220a  ed_url'.    """.
+00009fe0: 0a20 2020 206a 736f 6e5f 6461 7461 203d  .    json_data =
+00009ff0: 2051 7565 7279 5363 6943 7275 6e63 6845   QuerySciCrunchE
+0000a000: 6c61 7374 6963 5365 6172 6368 2871 7565  lasticSearch(que
+0000a010: 7279 5f73 7472 696e 672c 2074 7970 652c  ry_string, type,
+0000a020: 2061 6e63 6573 746f 7229 0a20 2020 2072   ancestor).    r
+0000a030: 6573 756c 7473 203d 207b 7d0a 2020 2020  esults = {}.    
+0000a040: 2320 6368 6563 6b20 6966 2071 7565 7279  # check if query
+0000a050: 2077 6173 2073 7563 6365 7373 6675 6c0a   was successful.
+0000a060: 2020 2020 6966 206a 736f 6e5f 6461 7461      if json_data
+0000a070: 5b22 7469 6d65 645f 6f75 7422 5d20 6973  ["timed_out"] is
+0000a080: 206e 6f74 2054 7275 653a 0a20 2020 2020   not True:.     
+0000a090: 2020 2023 2065 7861 6d70 6c65 2070 7269     # example pri
+0000a0a0: 6e74 696e 6720 7465 726d 206c 6162 656c  nting term label
+0000a0b0: 2c20 6465 6669 6e69 7469 6f6e 2c20 616e  , definition, an
+0000a0c0: 6420 7072 6566 6572 7265 6420 5552 4c0a  d preferred URL.
+0000a0d0: 2020 2020 2020 2020 666f 7220 7465 726d          for term
+0000a0e0: 2069 6e20 6a73 6f6e 5f64 6174 615b 2268   in json_data["h
+0000a0f0: 6974 7322 5d5b 2268 6974 7322 5d3a 0a20  its"]["hits"]:. 
+0000a100: 2020 2020 2020 2020 2020 2023 2066 696e             # fin
+0000a110: 6420 7072 6566 6572 7265 6420 5552 4c0a  d preferred URL.
+0000a120: 2020 2020 2020 2020 2020 2020 7265 7375              resu
+0000a130: 6c74 735b 7465 726d 5b22 5f73 6f75 7263  lts[term["_sourc
+0000a140: 6522 5d5b 2269 6c78 225d 5d20 3d20 7b7d  e"]["ilx"]] = {}
+0000a150: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+0000a160: 2069 7465 6d73 2069 6e20 7465 726d 5b22   items in term["
+0000a170: 5f73 6f75 7263 6522 5d5b 2265 7869 7374  _source"]["exist
+0000a180: 696e 675f 6964 7322 5d3a 0a20 2020 2020  ing_ids"]:.     
+0000a190: 2020 2020 2020 2020 2020 2069 6620 6974             if it
+0000a1a0: 656d 735b 2270 7265 6665 7272 6564 225d  ems["preferred"]
+0000a1b0: 203d 3d20 2231 223a 0a20 2020 2020 2020   == "1":.       
+0000a1c0: 2020 2020 2020 2020 2020 2020 2072 6573               res
+0000a1d0: 756c 7473 5b74 6572 6d5b 225f 736f 7572  ults[term["_sour
+0000a1e0: 6365 225d 5b22 696c 7822 5d5d 5b22 7072  ce"]["ilx"]]["pr
+0000a1f0: 6566 6572 7265 645f 7572 6c22 5d20 3d20  eferred_url"] = 
+0000a200: 6974 656d 735b 2269 7269 225d 0a20 2020  items["iri"].   
+0000a210: 2020 2020 2020 2020 2020 2020 2072 6573               res
+0000a220: 756c 7473 5b74 6572 6d5b 225f 736f 7572  ults[term["_sour
+0000a230: 6365 225d 5b22 696c 7822 5d5d 5b22 6c61  ce"]["ilx"]]["la
+0000a240: 6265 6c22 5d20 3d20 7465 726d 5b22 5f73  bel"] = term["_s
+0000a250: 6f75 7263 6522 5d5b 226c 6162 656c 225d  ource"]["label"]
+0000a260: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000a270: 2072 6573 756c 7473 5b74 6572 6d5b 225f   results[term["_
+0000a280: 736f 7572 6365 225d 5b22 696c 7822 5d5d  source"]["ilx"]]
+0000a290: 5b22 6465 6669 6e69 7469 6f6e 225d 203d  ["definition"] =
+0000a2a0: 2074 6572 6d5b 225f 736f 7572 6365 225d   term["_source"]
+0000a2b0: 5b0a 2020 2020 2020 2020 2020 2020 2020  [.              
+0000a2c0: 2020 2020 2020 2264 6566 696e 6974 696f        "definitio
+0000a2d0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
+0000a2e0: 2020 205d 0a0a 2020 2020 7265 7475 726e     ]..    return
+0000a2f0: 2072 6573 756c 7473 0a0a 0a64 6566 2049   results...def I
+0000a300: 6e69 7469 616c 697a 6549 6e74 6572 6c65  nitializeInterle
+0000a310: 7852 656d 6f74 6528 293a 0a20 2020 2022  xRemote():.    "
+0000a320: 2222 0a20 2020 2054 6869 7320 6675 6e63  "".    This func
+0000a330: 7469 6f6e 2069 6e69 7469 616c 697a 6573  tion initializes
+0000a340: 2061 2063 6f6e 6e65 6374 696f 6e20 746f   a connection to
+0000a350: 2049 6e74 6572 6c65 7820 666f 7220 7573   Interlex for us
+0000a360: 6520 696e 2061 6464 696e 6720 7065 7273  e in adding pers
+0000a370: 6f6e 616c 2064 6174 6120 656c 656d 656e  onal data elemen
+0000a380: 7473 2e20 546f 2075 7365 2049 6e74 6572  ts. To use Inter
+0000a390: 4c65 780a 2020 2020 6974 2072 6571 7569  Lex.    it requi
+0000a3a0: 7265 7320 796f 7520 746f 2073 6574 2061  res you to set a
+0000a3b0: 6e20 656e 7669 726f 6e6d 656e 7420 7661  n environment va
+0000a3c0: 7269 6162 6c65 2049 4e54 4552 4c45 585f  riable INTERLEX_
+0000a3d0: 4150 495f 4b45 5920 7769 7468 2079 6f75  API_KEY with you
+0000a3e0: 7220 6170 6920 6b65 790a 2020 2020 3a72  r api key.    :r
+0000a3f0: 6574 7572 6e3a 2069 6e74 6572 6c65 7820  eturn: interlex 
+0000a400: 6f62 6a65 6374 0a20 2020 2022 2222 0a20  object.    """. 
+0000a410: 2020 2023 2065 6e64 706f 696e 7420 3d20     # endpoint = 
+0000a420: 2268 7474 7073 3a2f 2f73 6369 6372 756e  "https://scicrun
+0000a430: 6368 2e6f 7267 2f61 7069 2f31 2f22 0a20  ch.org/api/1/". 
+0000a440: 2020 2023 2062 6574 6120 656e 6470 6f69     # beta endpoi
+0000a450: 6e74 2066 6f72 2074 6573 7469 6e67 0a20  nt for testing. 
+0000a460: 2020 2023 2065 6e64 706f 696e 7420 3d20     # endpoint = 
+0000a470: 2268 7474 7073 3a2f 2f62 6574 612e 7363  "https://beta.sc
+0000a480: 6963 7275 6e63 682e 6f72 672f 6170 692f  icrunch.org/api/
+0000a490: 312f 220a 0a20 2020 2049 6e74 6572 4c65  1/"..    InterLe
+0000a4a0: 7852 656d 6f74 6520 3d20 6f71 2e70 6c75  xRemote = oq.plu
+0000a4b0: 6769 6e2e 6765 7428 2249 6e74 6572 4c65  gin.get("InterLe
+0000a4c0: 7822 290a 2020 2020 2320 6368 616e 6765  x").    # change
+0000a4d0: 6420 7065 7220 7467 6275 6773 2063 6861  d per tgbugs cha
+0000a4e0: 6e67 6573 2074 6f20 496e 7465 724c 6578  nges to InterLex
+0000a4f0: 5265 6d6f 7465 206e 6f20 6c6f 6e67 6572  Remote no longer
+0000a500: 2074 616b 696e 6720 6170 695f 6b65 7920   taking api_key 
+0000a510: 6173 2061 2070 6172 616d 6574 6572 0a20  as a parameter. 
+0000a520: 2020 2023 2073 6574 2049 4e54 4552 4c45     # set INTERLE
+0000a530: 585f 4150 495f 4b45 5920 656e 7669 726f  X_API_KEY enviro
+0000a540: 6e6d 656e 7420 7661 7269 6162 6c65 2069  nment variable i
+0000a550: 6e73 7465 6164 2e2e 2e69 6c78 5f63 6c69  nstead...ilx_cli
+0000a560: 203d 2049 6e74 6572 4c65 7852 656d 6f74   = InterLexRemot
+0000a570: 6528 6170 695f 6b65 793d 6b65 792c 2061  e(api_key=key, a
+0000a580: 7069 456e 6470 6f69 6e74 3d65 6e64 706f  piEndpoint=endpo
+0000a590: 696e 7429 0a20 2020 2069 6c78 5f63 6c69  int).    ilx_cli
+0000a5a0: 203d 2049 6e74 6572 4c65 7852 656d 6f74   = InterLexRemot
+0000a5b0: 6528 6170 6945 6e64 706f 696e 743d 494e  e(apiEndpoint=IN
+0000a5c0: 5445 524c 4558 5f45 4e44 504f 494e 5429  TERLEX_ENDPOINT)
+0000a5d0: 0a20 2020 2074 7279 3a0a 2020 2020 2020  .    try:.      
+0000a5e0: 2020 696c 785f 636c 692e 7365 7475 7028    ilx_cli.setup(
+0000a5f0: 696e 7374 7275 6d65 6e74 6564 3d6f 712e  instrumented=oq.
+0000a600: 4f6e 7454 6572 6d29 0a20 2020 2065 7863  OntTerm).    exc
+0000a610: 6570 7420 4578 6365 7074 696f 6e3a 0a20  ept Exception:. 
+0000a620: 2020 2020 2020 2070 7269 6e74 2822 6572         print("er
+0000a630: 726f 7220 696e 6974 6961 6c69 7a69 6e67  ror initializing
+0000a640: 2049 6e74 6572 4c65 7820 636f 6e6e 6563   InterLex connec
+0000a650: 7469 6f6e 2e2e 2e22 290a 2020 2020 2020  tion...").      
+0000a660: 2020 7072 696e 7428 2279 6f75 2077 696c    print("you wil
+0000a670: 6c20 6e6f 7420 6265 2061 626c 6520 746f  l not be able to
+0000a680: 2061 6464 206e 6577 2070 6572 736f 6e61   add new persona
+0000a690: 6c20 6461 7461 2065 6c65 6d65 6e74 732e  l data elements.
+0000a6a0: 2229 0a20 2020 2020 2020 2070 7269 6e74  ").        print
+0000a6b0: 280a 2020 2020 2020 2020 2020 2020 2244  (.            "D
+0000a6c0: 6964 2079 6f75 2070 7574 2079 6f75 7220  id you put your 
+0000a6d0: 7363 6963 7275 6e63 6820 4150 4920 6b65  scicrunch API ke
+0000a6e0: 7920 696e 2061 6e20 656e 7669 726f 6e6d  y in an environm
+0000a6f0: 656e 7420 7661 7269 6162 6c65 2049 4e54  ent variable INT
+0000a700: 4552 4c45 585f 4150 495f 4b45 593f 220a  ERLEX_API_KEY?".
+0000a710: 2020 2020 2020 2020 290a 0a20 2020 2072          )..    r
+0000a720: 6574 7572 6e20 696c 785f 636c 690a 0a0a  eturn ilx_cli...
+0000a730: 6465 6620 4164 6450 4445 546f 496e 7465  def AddPDEToInte
+0000a740: 726c 6578 280a 2020 2020 696c 785f 6f62  rlex(.    ilx_ob
+0000a750: 6a2c 0a20 2020 206c 6162 656c 2c0a 2020  j,.    label,.  
+0000a760: 2020 6465 6669 6e69 7469 6f6e 2c0a 2020    definition,.  
+0000a770: 2020 756e 6974 732c 0a20 2020 206d 696e    units,.    min
+0000a780: 2c20 2023 206e 6f71 613a 2041 3030 320a  ,  # noqa: A002.
+0000a790: 2020 2020 6d61 782c 2020 2320 6e6f 7161      max,  # noqa
+0000a7a0: 3a20 4130 3032 0a20 2020 2064 6174 6174  : A002.    datat
+0000a7b0: 7970 652c 0a20 2020 2069 7361 626f 7574  ype,.    isabout
+0000a7c0: 3d4e 6f6e 652c 0a20 2020 2063 6174 6567  =None,.    categ
+0000a7d0: 6f72 796d 6170 7069 6e67 733d 4e6f 6e65  orymappings=None
+0000a7e0: 2c0a 293a 0a20 2020 2022 2222 0a20 2020  ,.):.    """.   
+0000a7f0: 2054 6869 7320 6675 6e63 7469 6f6e 2077   This function w
+0000a800: 696c 6c20 6164 6420 7468 6520 5044 4520  ill add the PDE 
+0000a810: 2870 6572 736f 6e61 6c20 6461 7461 2065  (personal data e
+0000a820: 6c65 6d65 6e74 7329 2074 6f20 496e 7465  lements) to Inte
+0000a830: 726c 6578 2075 7369 6e67 2074 6865 2049  rlex using the I
+0000a840: 6e74 6572 6c65 7820 6f6e 7471 7565 7279  nterlex ontquery
+0000a850: 2041 5049 2e0a 0a20 2020 203a 7061 7261   API...    :para
+0000a860: 6d20 696e 7465 726c 6578 5f6f 626a 3a20  m interlex_obj: 
+0000a870: 4f62 6a65 6374 2063 7265 6174 6564 2075  Object created u
+0000a880: 7369 6e67 206f 6e74 7175 6572 792e 706c  sing ontquery.pl
+0000a890: 7567 696e 2e67 6574 2829 2066 756e 6374  ugin.get() funct
+0000a8a0: 696f 6e20 2873 6565 3a20 6874 7470 733a  ion (see: https:
+0000a8b0: 2f2f 6769 7468 7562 2e63 6f6d 2f74 6762  //github.com/tgb
+0000a8c0: 7567 732f 6f6e 7471 7565 7279 290a 2020  ugs/ontquery).  
+0000a8d0: 2020 3a70 6172 616d 206c 6162 656c 3a20    :param label: 
+0000a8e0: 4c61 6265 6c20 666f 7220 7465 726d 2065  Label for term e
+0000a8f0: 6e74 6974 7920 6265 696e 6720 6372 6561  ntity being crea
+0000a900: 7465 640a 2020 2020 3a70 6172 616d 2064  ted.    :param d
+0000a910: 6566 696e 6974 696f 6e3a 2044 6566 696e  efinition: Defin
+0000a920: 6974 696f 6e20 666f 7220 7465 726d 2065  ition for term e
+0000a930: 6e74 6974 7920 6265 696e 6720 6372 6561  ntity being crea
+0000a940: 7465 640a 2020 2020 3a70 6172 616d 2063  ted.    :param c
+0000a950: 6f6d 6d65 6e74 3a20 436f 6d6d 656e 7473  omment: Comments
+0000a960: 2074 6f20 6865 6c70 2075 6e64 6572 7374   to help underst
+0000a970: 616e 6420 7468 6520 6f62 6a65 6374 0a20  and the object. 
+0000a980: 2020 203a 7265 7475 726e 3a20 7265 7370     :return: resp
+0000a990: 6f6e 7365 2066 726f 6d20 496e 7465 726c  onse from Interl
+0000a9a0: 6578 0a20 2020 2022 2222 0a0a 2020 2020  ex.    """..    
+0000a9b0: 2320 496e 7465 726c 6578 2075 7269 7320  # Interlex uris 
+0000a9c0: 666f 7220 7072 6564 6963 6174 6573 2c20  for predicates, 
+0000a9d0: 746d 705f 2070 7265 6669 7820 646f 7220  tmp_ prefix dor 
+0000a9e0: 6265 7461 2065 6e64 706f 696e 672c 2069  beta endpoing, i
+0000a9f0: 6c78 5f20 666f 7220 7072 6f64 7563 7469  lx_ for producti
+0000aa00: 6f6e 0a20 2020 2070 7265 6669 7820 3d20  on.    prefix = 
+0000aa10: 494e 5445 524c 4558 5f50 5245 4649 580a  INTERLEX_PREFIX.
+0000aa20: 2020 2020 2320 666f 7220 6265 7461 2074      # for beta t
+0000aa30: 6573 7469 6e67 0a20 2020 2023 2070 7265  esting.    # pre
+0000aa40: 6669 7820 3d20 2774 6d70 270a 2020 2020  fix = 'tmp'.    
+0000aa50: 7572 695f 6461 7461 7479 7065 203d 2022  uri_datatype = "
+0000aa60: 6874 7470 3a2f 2f75 7269 2e69 6e74 6572  http://uri.inter
+0000aa70: 6c65 782e 6f72 672f 6261 7365 2f22 202b  lex.org/base/" +
+0000aa80: 2070 7265 6669 7820 2b20 225f 3033 3832   prefix + "_0382
+0000aa90: 3133 3122 0a20 2020 2075 7269 5f75 6e69  131".    uri_uni
+0000aaa0: 7473 203d 2022 6874 7470 3a2f 2f75 7269  ts = "http://uri
+0000aab0: 2e69 6e74 6572 6c65 782e 6f72 672f 6261  .interlex.org/ba
+0000aac0: 7365 2f22 202b 2070 7265 6669 7820 2b20  se/" + prefix + 
+0000aad0: 225f 3033 3832 3133 3022 0a20 2020 2075  "_0382130".    u
+0000aae0: 7269 5f6d 696e 203d 2022 6874 7470 3a2f  ri_min = "http:/
+0000aaf0: 2f75 7269 2e69 6e74 6572 6c65 782e 6f72  /uri.interlex.or
+0000ab00: 672f 6261 7365 2f22 202b 2070 7265 6669  g/base/" + prefi
+0000ab10: 7820 2b20 225f 3033 3832 3133 3322 0a20  x + "_0382133". 
+0000ab20: 2020 2075 7269 5f6d 6178 203d 2022 6874     uri_max = "ht
+0000ab30: 7470 3a2f 2f75 7269 2e69 6e74 6572 6c65  tp://uri.interle
+0000ab40: 782e 6f72 672f 6261 7365 2f22 202b 2070  x.org/base/" + p
+0000ab50: 7265 6669 7820 2b20 225f 3033 3832 3133  refix + "_038213
+0000ab60: 3222 0a20 2020 2075 7269 5f63 6174 6567  2".    uri_categ
+0000ab70: 6f72 7920 3d20 2268 7474 703a 2f2f 7572  ory = "http://ur
+0000ab80: 692e 696e 7465 726c 6578 2e6f 7267 2f62  i.interlex.org/b
+0000ab90: 6173 652f 2220 2b20 7072 6566 6978 202b  ase/" + prefix +
+0000aba0: 2022 5f30 3338 3231 3239 220a 2020 2020   "_0382129".    
+0000abb0: 7572 695f 6973 6162 6f75 7420 3d20 2268  uri_isabout = "h
+0000abc0: 7474 703a 2f2f 7572 692e 696e 7465 726c  ttp://uri.interl
+0000abd0: 6578 2e6f 7267 2f62 6173 652f 2220 2b20  ex.org/base/" + 
+0000abe0: 7072 6566 6978 202b 2022 5f30 3338 3133  prefix + "_03813
+0000abf0: 3835 220a 0a20 2020 2023 2072 6574 7572  85"..    # retur
+0000ac00: 6e20 696c 785f 6f62 6a2e 6164 645f 7064  n ilx_obj.add_pd
+0000ac10: 6528 6c61 6265 6c3d 6c61 6265 6c2c 2064  e(label=label, d
+0000ac20: 6566 696e 6974 696f 6e3d 6465 6669 6e69  efinition=defini
+0000ac30: 7469 6f6e 2c20 636f 6d6d 656e 743d 636f  tion, comment=co
+0000ac40: 6d6d 656e 742c 2074 7970 653d 2770 6465  mment, type='pde
+0000ac50: 2729 0a20 2020 2069 6620 6361 7465 676f  ').    if catego
+0000ac60: 7279 6d61 7070 696e 6773 2069 7320 6e6f  rymappings is no
+0000ac70: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
+0000ac80: 6966 2069 7361 626f 7574 2069 7320 6e6f  if isabout is no
+0000ac90: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
+0000aca0: 2020 2020 746d 7020 3d20 696c 785f 6f62      tmp = ilx_ob
+0000acb0: 6a2e 6164 645f 7064 6528 0a20 2020 2020  j.add_pde(.     
+0000acc0: 2020 2020 2020 2020 2020 206c 6162 656c             label
+0000acd0: 3d6c 6162 656c 2c0a 2020 2020 2020 2020  =label,.        
+0000ace0: 2020 2020 2020 2020 6465 6669 6e69 7469          definiti
+0000acf0: 6f6e 3d64 6566 696e 6974 696f 6e2c 0a20  on=definition,. 
+0000ad00: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0000ad10: 7265 6469 6361 7465 733d 7b0a 2020 2020  redicates={.    
+0000ad20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ad30: 7572 695f 6461 7461 7479 7065 3a20 6461  uri_datatype: da
+0000ad40: 7461 7479 7065 2c0a 2020 2020 2020 2020  tatype,.        
+0000ad50: 2020 2020 2020 2020 2020 2020 7572 695f              uri_
+0000ad60: 756e 6974 733a 2075 6e69 7473 2c0a 2020  units: units,.  
+0000ad70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ad80: 2020 7572 695f 6d69 6e3a 206d 696e 2c0a    uri_min: min,.
+0000ad90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ada0: 2020 2020 7572 695f 6d61 783a 206d 6178      uri_max: max
+0000adb0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000adc0: 2020 2020 2020 7572 695f 6973 6162 6f75        uri_isabou
+0000add0: 743a 2069 7361 626f 7574 2c0a 2020 2020  t: isabout,.    
+0000ade0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000adf0: 7572 695f 6361 7465 676f 7279 3a20 6361  uri_category: ca
+0000ae00: 7465 676f 7279 6d61 7070 696e 6773 2c0a  tegorymappings,.
+0000ae10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ae20: 7d2c 0a20 2020 2020 2020 2020 2020 2029  },.            )
+0000ae30: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+0000ae40: 2020 2020 2020 2020 2020 2074 6d70 203d             tmp =
+0000ae50: 2069 6c78 5f6f 626a 2e61 6464 5f70 6465   ilx_obj.add_pde
+0000ae60: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+0000ae70: 2020 6c61 6265 6c3d 6c61 6265 6c2c 0a20    label=label,. 
+0000ae80: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+0000ae90: 6566 696e 6974 696f 6e3d 6465 6669 6e69  efinition=defini
+0000aea0: 7469 6f6e 2c0a 2020 2020 2020 2020 2020  tion,.          
+0000aeb0: 2020 2020 2020 7072 6564 6963 6174 6573        predicates
+0000aec0: 3d7b 0a20 2020 2020 2020 2020 2020 2020  ={.             
+0000aed0: 2020 2020 2020 2075 7269 5f64 6174 6174         uri_datat
+0000aee0: 7970 653a 2064 6174 6174 7970 652c 0a20  ype: datatype,. 
+0000aef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000af00: 2020 2075 7269 5f75 6e69 7473 3a20 756e     uri_units: un
+0000af10: 6974 732c 0a20 2020 2020 2020 2020 2020  its,.           
+0000af20: 2020 2020 2020 2020 2075 7269 5f6d 696e           uri_min
+0000af30: 3a20 6d69 6e2c 0a20 2020 2020 2020 2020  : min,.         
+0000af40: 2020 2020 2020 2020 2020 2075 7269 5f6d             uri_m
+0000af50: 6178 3a20 6d61 782c 0a20 2020 2020 2020  ax: max,.       
+0000af60: 2020 2020 2020 2020 2020 2020 2075 7269               uri
+0000af70: 5f63 6174 6567 6f72 793a 2063 6174 6567  _category: categ
+0000af80: 6f72 796d 6170 7069 6e67 732c 0a20 2020  orymappings,.   
+0000af90: 2020 2020 2020 2020 2020 2020 207d 2c0a               },.
+0000afa0: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+0000afb0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0000afc0: 6966 2069 7361 626f 7574 2069 7320 6e6f  if isabout is no
+0000afd0: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
+0000afe0: 2020 2020 746d 7020 3d20 696c 785f 6f62      tmp = ilx_ob
+0000aff0: 6a2e 6164 645f 7064 6528 0a20 2020 2020  j.add_pde(.     
+0000b000: 2020 2020 2020 2020 2020 206c 6162 656c             label
+0000b010: 3d6c 6162 656c 2c0a 2020 2020 2020 2020  =label,.        
+0000b020: 2020 2020 2020 2020 6465 6669 6e69 7469          definiti
+0000b030: 6f6e 3d64 6566 696e 6974 696f 6e2c 0a20  on=definition,. 
+0000b040: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0000b050: 7265 6469 6361 7465 733d 7b0a 2020 2020  redicates={.    
+0000b060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b070: 7572 695f 6461 7461 7479 7065 3a20 6461  uri_datatype: da
+0000b080: 7461 7479 7065 2c0a 2020 2020 2020 2020  tatype,.        
+0000b090: 2020 2020 2020 2020 2020 2020 7572 695f              uri_
+0000b0a0: 756e 6974 733a 2075 6e69 7473 2c0a 2020  units: units,.  
+0000b0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b0c0: 2020 7572 695f 6d69 6e3a 206d 696e 2c0a    uri_min: min,.
+0000b0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b0e0: 2020 2020 7572 695f 6d61 783a 206d 6178      uri_max: max
+0000b0f0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000b100: 2020 2020 2020 7572 695f 6973 6162 6f75        uri_isabou
+0000b110: 743a 2069 7361 626f 7574 2c0a 2020 2020  t: isabout,.    
+0000b120: 2020 2020 2020 2020 2020 2020 7d2c 0a20              },. 
+0000b130: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+0000b140: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0000b150: 2020 2020 2020 2074 6d70 203d 2069 6c78         tmp = ilx
+0000b160: 5f6f 626a 2e61 6464 5f70 6465 280a 2020  _obj.add_pde(.  
+0000b170: 2020 2020 2020 2020 2020 2020 2020 6c61                la
+0000b180: 6265 6c3d 6c61 6265 6c2c 0a20 2020 2020  bel=label,.     
+0000b190: 2020 2020 2020 2020 2020 2064 6566 696e             defin
+0000b1a0: 6974 696f 6e3d 6465 6669 6e69 7469 6f6e  ition=definition
+0000b1b0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000b1c0: 2020 7072 6564 6963 6174 6573 3d7b 0a20    predicates={. 
+0000b1d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b1e0: 2020 2075 7269 5f64 6174 6174 7970 653a     uri_datatype:
+0000b1f0: 2064 6174 6174 7970 652c 0a20 2020 2020   datatype,.     
+0000b200: 2020 2020 2020 2020 2020 2020 2020 2075                 u
+0000b210: 7269 5f75 6e69 7473 3a20 756e 6974 732c  ri_units: units,
+0000b220: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000b230: 2020 2020 2075 7269 5f6d 696e 3a20 6d69       uri_min: mi
+0000b240: 6e2c 0a20 2020 2020 2020 2020 2020 2020  n,.             
+0000b250: 2020 2020 2020 2075 7269 5f6d 6178 3a20         uri_max: 
+0000b260: 6d61 782c 0a20 2020 2020 2020 2020 2020  max,.           
+0000b270: 2020 2020 207d 2c0a 2020 2020 2020 2020       },.        
+0000b280: 2020 2020 290a 0a20 2020 2072 6574 7572      )..    retur
+0000b290: 6e20 746d 700a 0a0a 6465 6620 4164 6443  n tmp...def AddC
+0000b2a0: 6f6e 6365 7074 546f 496e 7465 726c 6578  onceptToInterlex
+0000b2b0: 2869 6c78 5f6f 626a 2c20 6c61 6265 6c2c  (ilx_obj, label,
+0000b2c0: 2064 6566 696e 6974 696f 6e29 3a0a 2020   definition):.  
+0000b2d0: 2020 2222 220a 2020 2020 5468 6973 2066    """.    This f
+0000b2e0: 756e 6374 696f 6e20 7769 6c6c 2061 6464  unction will add
+0000b2f0: 2061 2063 6f6e 6365 7074 2074 6f20 496e   a concept to In
+0000b300: 7465 726c 6578 2075 7369 6e67 2074 6865  terlex using the
+0000b310: 2049 6e74 6572 6c65 7820 6f6e 7471 7565   Interlex ontque
+0000b320: 7279 2041 5049 2e0a 0a20 2020 203a 7061  ry API...    :pa
+0000b330: 7261 6d20 696c 785f 6f62 6a3a 204f 626a  ram ilx_obj: Obj
+0000b340: 6563 7420 6372 6561 7465 6420 7573 696e  ect created usin
+0000b350: 6720 6f6e 7471 7565 7279 2e70 6c75 6769  g ontquery.plugi
+0000b360: 6e2e 6765 7428 2920 6675 6e63 7469 6f6e  n.get() function
+0000b370: 2028 7365 653a 2068 7474 7073 3a2f 2f67   (see: https://g
+0000b380: 6974 6875 622e 636f 6d2f 7467 6275 6773  ithub.com/tgbugs
+0000b390: 2f6f 6e74 7175 6572 7929 0a20 2020 203a  /ontquery).    :
+0000b3a0: 7061 7261 6d20 6c61 6265 6c3a 204c 6162  param label: Lab
+0000b3b0: 656c 2066 6f72 2074 6572 6d20 656e 7469  el for term enti
+0000b3c0: 7479 2062 6569 6e67 2063 7265 6174 6564  ty being created
+0000b3d0: 0a20 2020 203a 7061 7261 6d20 6465 6669  .    :param defi
+0000b3e0: 6e69 7469 6f6e 3a20 4465 6669 6e69 7469  nition: Definiti
+0000b3f0: 6f6e 2066 6f72 2074 6572 6d20 656e 7469  on for term enti
+0000b400: 7479 2062 6569 6e67 2063 7265 6174 6564  ty being created
+0000b410: 0a20 2020 203a 7061 7261 6d20 636f 6d6d  .    :param comm
+0000b420: 656e 743a 2043 6f6d 6d65 6e74 7320 746f  ent: Comments to
+0000b430: 2068 656c 7020 756e 6465 7273 7461 6e64   help understand
+0000b440: 2074 6865 206f 626a 6563 740a 2020 2020   the object.    
+0000b450: 3a72 6574 7572 6e3a 2072 6573 706f 6e73  :return: respons
+0000b460: 6520 6672 6f6d 2049 6e74 6572 6c65 780a  e from Interlex.
+0000b470: 2020 2020 2222 220a 0a20 2020 2023 2049      """..    # I
+0000b480: 6e74 6572 6c65 7820 7572 6973 2066 6f72  nterlex uris for
+0000b490: 2070 7265 6469 6361 7465 732c 2074 6d70   predicates, tmp
+0000b4a0: 5f20 7072 6566 6978 2064 6f72 2062 6574  _ prefix dor bet
+0000b4b0: 6120 656e 6470 6f69 6e67 2c20 696c 785f  a endpoing, ilx_
+0000b4c0: 2066 6f72 2070 726f 6475 6374 696f 6e0a   for production.
+0000b4d0: 2020 2020 2320 7072 6566 6978 203d 2027      # prefix = '
+0000b4e0: 696c 7827 0a20 2020 2023 2066 6f72 2062  ilx'.    # for b
+0000b4f0: 6574 6120 7465 7374 696e 670a 2020 2020  eta testing.    
+0000b500: 746d 7020 3d20 696c 785f 6f62 6a2e 6164  tmp = ilx_obj.ad
+0000b510: 645f 7064 6528 6c61 6265 6c3d 6c61 6265  d_pde(label=labe
+0000b520: 6c2c 2064 6566 696e 6974 696f 6e3d 6465  l, definition=de
+0000b530: 6669 6e69 7469 6f6e 290a 2020 2020 7265  finition).    re
+0000b540: 7475 726e 2074 6d70 0a0a 0a64 6566 206c  turn tmp...def l
+0000b550: 6f61 645f 6e69 646d 5f74 6572 6d73 5f63  oad_nidm_terms_c
+0000b560: 6f6e 6365 7074 7328 293a 0a20 2020 2022  oncepts():.    "
+0000b570: 2222 0a20 2020 2054 6869 7320 6675 6e63  "".    This func
+0000b580: 7469 6f6e 2077 696c 6c20 7075 6c6c 204e  tion will pull N
+0000b590: 4944 4d2d 5465 726d 7320 7573 6564 2063  IDM-Terms used c
+0000b5a0: 6f6e 6365 7074 7320 6672 6f6d 2074 6865  oncepts from the
+0000b5b0: 204e 4944 4d2d 5465 726d 7320 7265 706f   NIDM-Terms repo
+0000b5c0: 2e20 5468 6573 6520 6172 6520 636f 6e63  . These are conc
+0000b5d0: 6570 7473 2075 7365 6420 696e 2061 6e6e  epts used in ann
+0000b5e0: 6f74 6174 696e 670a 2020 2020 6f74 6865  otating.    othe
+0000b5f0: 7220 6461 7461 7365 7473 2061 6e64 2073  r datasets and s
+0000b600: 686f 756c 6420 6265 2075 7365 6420 7072  hould be used pr
+0000b610: 696f 7220 746f 2062 726f 6164 656e 696e  ior to broadenin
+0000b620: 6720 7468 6520 7365 6172 6368 2074 6f20  g the search to 
+0000b630: 496e 7465 724c 6578 2061 6e64 2043 6f67  InterLex and Cog
+0000b640: 4174 6c61 7320 636f 6e63 6570 7473 2e20  Atlas concepts. 
+0000b650: 4279 2075 7369 6e67 2074 6865 7365 0a20  By using these. 
+0000b660: 2020 2066 6972 7374 2c20 6f6e 6573 2074     first, ones t
+0000b670: 6861 7420 6861 7665 2061 6c72 6561 6479  hat have already
+0000b680: 2062 6565 6e20 7573 6564 2074 6f20 616e   been used to an
+0000b690: 6e6f 7461 7465 2064 6174 6173 6574 732c  notate datasets,
+0000b6a0: 2077 6520 6d61 7869 6d69 7a65 206f 7572   we maximize our
+0000b6b0: 2061 6269 6c69 7479 2074 6f20 6669 6e64   ability to find
+0000b6c0: 2063 6f6e 6365 7074 2d62 6173 6564 2071   concept-based q
+0000b6d0: 7565 7279 0a20 2020 206d 6174 6368 6573  uery.    matches
+0000b6e0: 2061 6372 6f73 7320 6461 7461 7365 7473   across datasets
+0000b6f0: 0a20 2020 203a 7265 7475 726e 3a0a 2020  .    :return:.  
+0000b700: 2020 2222 220a 0a20 2020 2063 6f6e 6365    """..    conce
+0000b710: 7074 5f75 726c 203d 2022 6874 7470 733a  pt_url = "https:
+0000b720: 2f2f 7261 772e 6769 7468 7562 7573 6572  //raw.githubuser
+0000b730: 636f 6e74 656e 742e 636f 6d2f 4e49 444d  content.com/NIDM
+0000b740: 2d54 6572 6d73 2f74 6572 6d73 2f6d 6173  -Terms/terms/mas
+0000b750: 7465 722f 7465 726d 732f 4e49 444d 5f43  ter/terms/NIDM_C
+0000b760: 6f6e 6365 7074 732e 6a73 6f6e 6c64 220a  oncepts.jsonld".
+0000b770: 0a20 2020 2074 7279 3a0a 2020 2020 2020  .    try:.      
+0000b780: 2020 7220 3d20 7265 7175 6573 7473 2e67    r = requests.g
+0000b790: 6574 2863 6f6e 6365 7074 5f75 726c 290a  et(concept_url).
+0000b7a0: 2020 2020 2020 2020 722e 7261 6973 655f          r.raise_
+0000b7b0: 666f 725f 7374 6174 7573 2829 0a20 2020  for_status().   
+0000b7c0: 2020 2020 2063 6f6e 6365 7074 5f67 7261       concept_gra
+0000b7d0: 7068 203d 2072 2e6a 736f 6e28 290a 2020  ph = r.json().  
+0000b7e0: 2020 6578 6365 7074 2045 7863 6570 7469    except Excepti
+0000b7f0: 6f6e 3a0a 2020 2020 2020 2020 6c6f 6767  on:.        logg
+0000b800: 696e 672e 696e 666f 2822 4572 726f 7220  ing.info("Error 
+0000b810: 6f70 656e 696e 6720 2573 2075 7365 6420  opening %s used 
+0000b820: 636f 6e63 6570 7473 2066 696c 652e 2e63  concepts file..c
+0000b830: 6f6e 7469 6e75 696e 6722 2c20 636f 6e63  ontinuing", conc
+0000b840: 6570 745f 7572 6c29 0a20 2020 2020 2020  ept_url).       
+0000b850: 2072 6574 7572 6e20 4e6f 6e65 0a0a 2020   return None..  
+0000b860: 2020 7265 7475 726e 2063 6f6e 6365 7074    return concept
+0000b870: 5f67 7261 7068 0a0a 0a64 6566 206c 6f61  _graph...def loa
+0000b880: 645f 6e69 646d 5f6f 776c 5f66 696c 6573  d_nidm_owl_files
+0000b890: 2829 3a0a 2020 2020 2222 220a 2020 2020  ():.    """.    
+0000b8a0: 5468 6973 2066 756e 6374 696f 6e20 6c6f  This function lo
+0000b8b0: 6164 7320 7468 6520 4e49 444d 2d65 7870  ads the NIDM-exp
+0000b8c0: 6572 696d 656e 7420 7265 6c61 7465 6420  eriment related 
+0000b8d0: 4f57 4c20 6669 6c65 7320 616e 6420 696d  OWL files and im
+0000b8e0: 706f 7274 732c 2063 7265 6174 6573 2061  ports, creates a
+0000b8f0: 2075 6e69 6f6e 2067 7261 7068 2061 6e64   union graph and
+0000b900: 2072 6574 7572 6e73 2069 742e 0a20 2020   returns it..   
+0000b910: 203a 7265 7475 726e 3a20 6772 6170 6820   :return: graph 
+0000b920: 6f66 2061 6c6c 204f 574c 2066 696c 6573  of all OWL files
+0000b930: 2061 6e64 2069 6d70 6f72 7473 2066 726f   and imports fro
+0000b940: 6d20 5079 4e49 444d 2065 7870 6572 696d  m PyNIDM experim
+0000b950: 656e 740a 2020 2020 2222 220a 2020 2020  ent.    """.    
+0000b960: 2320 6c6f 6164 206e 6964 6d2d 6578 7065  # load nidm-expe
+0000b970: 7269 6d65 6e74 2e6f 776c 2066 696c 6520  riment.owl file 
+0000b980: 616e 6420 616c 6c20 696d 706f 7274 7320  and all imports 
+0000b990: 6469 7265 6374 6c79 0a20 2020 2023 2063  directly.    # c
+0000b9a0: 7265 6174 6520 656d 7074 7920 6772 6170  reate empty grap
+0000b9b0: 680a 2020 2020 756e 696f 6e5f 6772 6170  h.    union_grap
+0000b9c0: 6820 3d20 4772 6170 6828 290a 0a20 2020  h = Graph()..   
+0000b9d0: 2023 2320 434f 4d4d 454e 5445 4420 4f55   ## COMMENTED OU
+0000b9e0: 5420 4259 2044 424b 2028 352f 3133 2f32  T BY DBK (5/13/2
+0000b9f0: 3129 2e20 4348 414e 4749 4e47 2054 4f20  1). CHANGING TO 
+0000ba00: 4745 5420 4f57 4c20 4649 4c45 5320 4449  GET OWL FILES DI
+0000ba10: 5245 4354 4f52 5920 4652 4f4d 204e 4944  RECTORY FROM NID
+0000ba20: 4d2d 5350 4543 5320 5245 504f 0a20 2020  M-SPECS REPO.   
+0000ba30: 2023 0a20 2020 2023 2063 6865 636b 2069   #.    # check i
+0000ba40: 6620 7468 6572 6520 6973 2061 6e20 696e  f there is an in
+0000ba50: 7465 726e 6574 2063 6f6e 6e65 6374 696f  ternet connectio
+0000ba60: 6e2c 2069 6620 736f 206c 6f61 6420 6469  n, if so load di
+0000ba70: 7265 6374 6c79 2066 726f 6d20 6874 7470  rectly from http
+0000ba80: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f69  s://github.com/i
+0000ba90: 6e63 662d 6e69 6461 7368 2f6e 6964 6d2d  ncf-nidash/nidm-
+0000baa0: 7370 6563 732f 7472 6565 2f6d 6173 7465  specs/tree/maste
+0000bab0: 722f 6e69 646d 2f6e 6964 6d2d 6578 7065  r/nidm/nidm-expe
+0000bac0: 7269 6d65 6e74 2f74 6572 6d73 2061 6e64  riment/terms and
+0000bad0: 0a20 2020 2023 2062 6173 6570 6174 683d  .    # basepath=
+0000bae0: 6f73 2e70 6174 682e 6469 726e 616d 6528  os.path.dirname(
+0000baf0: 6f73 2e70 6174 682e 6469 726e 616d 6528  os.path.dirname(
+0000bb00: 5f5f 6669 6c65 5f5f 2929 0a20 2020 2023  __file__)).    #
+0000bb10: 2074 6572 6d73 5f70 6174 6820 3d20 6f73   terms_path = os
+0000bb20: 2e70 6174 682e 6a6f 696e 2862 6173 6570  .path.join(basep
+0000bb30: 6174 682c 2274 6572 6d73 2229 0a20 2020  ath,"terms").   
+0000bb40: 2023 2069 6d70 6f72 7473 5f70 6174 683d   # imports_path=
+0000bb50: 6f73 2e70 6174 682e 6a6f 696e 2862 6173  os.path.join(bas
+0000bb60: 6570 6174 682c 2274 6572 6d73 222c 2269  epath,"terms","i
+0000bb70: 6d70 6f72 7473 2229 0a20 2020 2023 0a20  mports").    #. 
+0000bb80: 2020 2023 2069 6d70 6f72 7473 3d5b 0a20     # imports=[. 
+0000bb90: 2020 2023 2020 2020 2020 2020 2263 7279     #        "cry
+0000bba0: 7074 6f5f 696d 706f 7274 2e74 746c 222c  pto_import.ttl",
+0000bbb0: 0a20 2020 2023 2020 2020 2020 2020 2264  .    #        "d
+0000bbc0: 635f 696d 706f 7274 2e74 746c 222c 0a20  c_import.ttl",. 
+0000bbd0: 2020 2023 2020 2020 2020 2020 2269 616f     #        "iao
+0000bbe0: 5f69 6d70 6f72 742e 7474 6c22 2c0a 2020  _import.ttl",.  
+0000bbf0: 2020 2320 2020 2020 2020 2022 6e66 6f5f    #        "nfo_
+0000bc00: 696d 706f 7274 2e74 746c 222c 0a20 2020  import.ttl",.   
+0000bc10: 2023 2020 2020 2020 2020 226e 6c78 5f69   #        "nlx_i
+0000bc20: 6d70 6f72 742e 7474 6c22 2c0a 2020 2020  mport.ttl",.    
+0000bc30: 2320 2020 2020 2020 2022 6f62 695f 696d  #        "obi_im
+0000bc40: 706f 7274 2e74 746c 222c 0a20 2020 2023  port.ttl",.    #
+0000bc50: 2020 2020 2020 2020 226f 6e74 6f6e 6575          "ontoneu
+0000bc60: 726f 6c6f 675f 696e 7374 7275 6d65 6e74  rolog_instrument
+0000bc70: 735f 696d 706f 7274 2e74 746c 222c 0a20  s_import.ttl",. 
+0000bc80: 2020 2023 2020 2020 2020 2020 2270 6174     #        "pat
+0000bc90: 6f5f 696d 706f 7274 2e74 746c 222c 0a20  o_import.ttl",. 
+0000bca0: 2020 2023 2020 2020 2020 2020 2270 7276     #        "prv
+0000bcb0: 5f69 6d70 6f72 742e 7474 6c22 2c0a 2020  _import.ttl",.  
+0000bcc0: 2020 2320 2020 2020 2020 2022 7169 626f    #        "qibo
+0000bcd0: 5f69 6d70 6f72 742e 7474 6c22 2c0a 2020  _import.ttl",.  
+0000bce0: 2020 2320 2020 2020 2020 2022 7369 6f5f    #        "sio_
+0000bcf0: 696d 706f 7274 2e74 746c 222c 0a20 2020  import.ttl",.   
+0000bd00: 2023 2020 2020 2020 2020 2273 7461 746f   #        "stato
+0000bd10: 5f69 6d70 6f72 742e 7474 6c22 0a20 2020  _import.ttl".   
+0000bd20: 2023 205d 0a0a 2020 2020 2320 2320 6c6f   # ]..    # # lo
+0000bd30: 6164 2065 6163 6820 696d 706f 7274 0a20  ad each import. 
+0000bd40: 2020 2023 2066 6f72 2072 6573 6f75 7263     # for resourc
+0000bd50: 6520 696e 2069 6d70 6f72 7473 3a0a 2020  e in imports:.  
+0000bd60: 2020 2320 2020 2074 656d 705f 6772 6170    #    temp_grap
+0000bd70: 6820 3d20 4772 6170 6828 290a 2020 2020  h = Graph().    
+0000bd80: 2320 2020 2074 7279 3a0a 2020 2020 230a  #    try:.    #.
+0000bd90: 2020 2020 2320 2020 2020 2020 2074 656d      #        tem
+0000bda0: 705f 6772 6170 682e 7061 7273 6528 6f73  p_graph.parse(os
+0000bdb0: 2e70 6174 682e 6a6f 696e 2869 6d70 6f72  .path.join(impor
+0000bdc0: 7473 5f70 6174 682c 7265 736f 7572 6365  ts_path,resource
+0000bdd0: 292c 666f 726d 6174 3d22 7475 7274 6c65  ),format="turtle
+0000bde0: 2229 0a20 2020 2023 2020 2020 2020 2020  ").    #        
+0000bdf0: 756e 696f 6e5f 6772 6170 683d 756e 696f  union_graph=unio
+0000be00: 6e5f 6772 6170 682b 7465 6d70 5f67 7261  n_graph+temp_gra
+0000be10: 7068 0a20 2020 2023 0a20 2020 2023 2020  ph.    #.    #  
+0000be20: 2020 6578 6365 7074 2045 7863 6570 7469    except Excepti
+0000be30: 6f6e 3a0a 2020 2020 2320 2020 2020 2020  on:.    #       
+0000be40: 206c 6f67 6769 6e67 2e69 6e66 6f28 2245   logging.info("E
+0000be50: 7272 6f72 206f 7065 6e69 6e67 2025 7320  rror opening %s 
+0000be60: 696d 706f 7274 2066 696c 652e 2e63 6f6e  import file..con
+0000be70: 7469 6e75 696e 6722 2c20 6f73 2e70 6174  tinuing", os.pat
+0000be80: 682e 6a6f 696e 2869 6d70 6f72 7473 5f70  h.join(imports_p
+0000be90: 6174 682c 7265 736f 7572 6365 2929 0a20  ath,resource)). 
+0000bea0: 2020 2023 2020 2020 2020 2020 636f 6e74     #        cont
+0000beb0: 696e 7565 0a0a 2020 2020 6f77 6c73 203d  inue..    owls =
+0000bec0: 205b 0a20 2020 2020 2020 2022 6874 7470   [.        "http
+0000bed0: 733a 2f2f 7261 772e 6769 7468 7562 7573  s://raw.githubus
+0000bee0: 6572 636f 6e74 656e 742e 636f 6d2f 696e  ercontent.com/in
+0000bef0: 6366 2d6e 6964 6173 682f 6e69 646d 2d73  cf-nidash/nidm-s
+0000bf00: 7065 6373 2f6d 6173 7465 722f 6e69 646d  pecs/master/nidm
+0000bf10: 2f6e 6964 6d2d 6578 7065 7269 6d65 6e74  /nidm-experiment
+0000bf20: 2f69 6d70 6f72 7473 2f63 7279 7074 6f5f  /imports/crypto_
+0000bf30: 696d 706f 7274 2e74 746c 222c 0a20 2020  import.ttl",.   
+0000bf40: 2020 2020 2022 6874 7470 733a 2f2f 7261       "https://ra
+0000bf50: 772e 6769 7468 7562 7573 6572 636f 6e74  w.githubusercont
+0000bf60: 656e 742e 636f 6d2f 696e 6366 2d6e 6964  ent.com/incf-nid
+0000bf70: 6173 682f 6e69 646d 2d73 7065 6373 2f6d  ash/nidm-specs/m
+0000bf80: 6173 7465 722f 6e69 646d 2f6e 6964 6d2d  aster/nidm/nidm-
+0000bf90: 6578 7065 7269 6d65 6e74 2f69 6d70 6f72  experiment/impor
+0000bfa0: 7473 2f64 635f 696d 706f 7274 2e74 746c  ts/dc_import.ttl
+0000bfb0: 222c 0a20 2020 2020 2020 2022 6874 7470  ",.        "http
+0000bfc0: 733a 2f2f 7261 772e 6769 7468 7562 7573  s://raw.githubus
+0000bfd0: 6572 636f 6e74 656e 742e 636f 6d2f 696e  ercontent.com/in
+0000bfe0: 6366 2d6e 6964 6173 682f 6e69 646d 2d73  cf-nidash/nidm-s
+0000bff0: 7065 6373 2f6d 6173 7465 722f 6e69 646d  pecs/master/nidm
+0000c000: 2f6e 6964 6d2d 6578 7065 7269 6d65 6e74  /nidm-experiment
+0000c010: 2f69 6d70 6f72 7473 2f64 6963 6f6d 5f69  /imports/dicom_i
+0000c020: 6d70 6f72 742e 7474 6c22 2c0a 2020 2020  mport.ttl",.    
+0000c030: 2020 2020 2268 7474 7073 3a2f 2f72 6177      "https://raw
+0000c040: 2e67 6974 6875 6275 7365 7263 6f6e 7465  .githubuserconte
+0000c050: 6e74 2e63 6f6d 2f69 6e63 662d 6e69 6461  nt.com/incf-nida
+0000c060: 7368 2f6e 6964 6d2d 7370 6563 732f 6d61  sh/nidm-specs/ma
+0000c070: 7374 6572 2f6e 6964 6d2f 6e69 646d 2d65  ster/nidm/nidm-e
+0000c080: 7870 6572 696d 656e 742f 696d 706f 7274  xperiment/import
+0000c090: 732f 6961 6f5f 696d 706f 7274 2e74 746c  s/iao_import.ttl
+0000c0a0: 222c 0a20 2020 2020 2020 2022 6874 7470  ",.        "http
+0000c0b0: 733a 2f2f 7261 772e 6769 7468 7562 7573  s://raw.githubus
+0000c0c0: 6572 636f 6e74 656e 742e 636f 6d2f 696e  ercontent.com/in
+0000c0d0: 6366 2d6e 6964 6173 682f 6e69 646d 2d73  cf-nidash/nidm-s
+0000c0e0: 7065 6373 2f6d 6173 7465 722f 6e69 646d  pecs/master/nidm
+0000c0f0: 2f6e 6964 6d2d 6578 7065 7269 6d65 6e74  /nidm-experiment
+0000c100: 2f69 6d70 6f72 7473 2f6e 666f 5f69 6d70  /imports/nfo_imp
+0000c110: 6f72 742e 7474 6c22 2c0a 2020 2020 2020  ort.ttl",.      
+0000c120: 2020 2268 7474 7073 3a2f 2f72 6177 2e67    "https://raw.g
+0000c130: 6974 6875 6275 7365 7263 6f6e 7465 6e74  ithubusercontent
+0000c140: 2e63 6f6d 2f69 6e63 662d 6e69 6461 7368  .com/incf-nidash
+0000c150: 2f6e 6964 6d2d 7370 6563 732f 6d61 7374  /nidm-specs/mast
+0000c160: 6572 2f6e 6964 6d2f 6e69 646d 2d65 7870  er/nidm/nidm-exp
+0000c170: 6572 696d 656e 742f 696d 706f 7274 732f  eriment/imports/
+0000c180: 6f62 695f 696d 706f 7274 2e74 746c 222c  obi_import.ttl",
+0000c190: 0a20 2020 2020 2020 2022 6874 7470 733a  .        "https:
+0000c1a0: 2f2f 7261 772e 6769 7468 7562 7573 6572  //raw.githubuser
+0000c1b0: 636f 6e74 656e 742e 636f 6d2f 696e 6366  content.com/incf
+0000c1c0: 2d6e 6964 6173 682f 6e69 646d 2d73 7065  -nidash/nidm-spe
+0000c1d0: 6373 2f6d 6173 7465 722f 6e69 646d 2f6e  cs/master/nidm/n
+0000c1e0: 6964 6d2d 6578 7065 7269 6d65 6e74 2f69  idm-experiment/i
+0000c1f0: 6d70 6f72 7473 2f6f 6e74 6f6e 6575 726f  mports/ontoneuro
+0000c200: 6c6f 675f 696e 7374 7275 6d65 6e74 735f  log_instruments_
+0000c210: 696d 706f 7274 2e74 746c 222c 0a20 2020  import.ttl",.   
+0000c220: 2020 2020 2022 6874 7470 733a 2f2f 7261       "https://ra
+0000c230: 772e 6769 7468 7562 7573 6572 636f 6e74  w.githubusercont
+0000c240: 656e 742e 636f 6d2f 696e 6366 2d6e 6964  ent.com/incf-nid
+0000c250: 6173 682f 6e69 646d 2d73 7065 6373 2f6d  ash/nidm-specs/m
+0000c260: 6173 7465 722f 6e69 646d 2f6e 6964 6d2d  aster/nidm/nidm-
+0000c270: 6578 7065 7269 6d65 6e74 2f69 6d70 6f72  experiment/impor
+0000c280: 7473 2f70 6174 6f5f 696d 706f 7274 2e74  ts/pato_import.t
+0000c290: 746c 222c 0a20 2020 2020 2020 2022 6874  tl",.        "ht
+0000c2a0: 7470 733a 2f2f 7261 772e 6769 7468 7562  tps://raw.github
+0000c2b0: 7573 6572 636f 6e74 656e 742e 636f 6d2f  usercontent.com/
+0000c2c0: 696e 6366 2d6e 6964 6173 682f 6e69 646d  incf-nidash/nidm
+0000c2d0: 2d73 7065 6373 2f6d 6173 7465 722f 6e69  -specs/master/ni
+0000c2e0: 646d 2f6e 6964 6d2d 6578 7065 7269 6d65  dm/nidm-experime
+0000c2f0: 6e74 2f69 6d70 6f72 7473 2f70 6174 6f5f  nt/imports/pato_
+0000c300: 696d 706f 7274 2e74 746c 222c 0a20 2020  import.ttl",.   
+0000c310: 2020 2020 2022 6874 7470 733a 2f2f 7261       "https://ra
+0000c320: 772e 6769 7468 7562 7573 6572 636f 6e74  w.githubusercont
+0000c330: 656e 742e 636f 6d2f 696e 6366 2d6e 6964  ent.com/incf-nid
+0000c340: 6173 682f 6e69 646d 2d73 7065 6373 2f6d  ash/nidm-specs/m
+0000c350: 6173 7465 722f 6e69 646d 2f6e 6964 6d2d  aster/nidm/nidm-
+0000c360: 6578 7065 7269 6d65 6e74 2f69 6d70 6f72  experiment/impor
+0000c370: 7473 2f70 7276 5f69 6d70 6f72 742e 7474  ts/prv_import.tt
+0000c380: 6c22 2c0a 2020 2020 2020 2020 2268 7474  l",.        "htt
+0000c390: 7073 3a2f 2f72 6177 2e67 6974 6875 6275  ps://raw.githubu
+0000c3a0: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f69  sercontent.com/i
+0000c3b0: 6e63 662d 6e69 6461 7368 2f6e 6964 6d2d  ncf-nidash/nidm-
+0000c3c0: 7370 6563 732f 6d61 7374 6572 2f6e 6964  specs/master/nid
+0000c3d0: 6d2f 6e69 646d 2d65 7870 6572 696d 656e  m/nidm-experimen
+0000c3e0: 742f 696d 706f 7274 732f 7369 6f5f 696d  t/imports/sio_im
+0000c3f0: 706f 7274 2e74 746c 222c 0a20 2020 2020  port.ttl",.     
+0000c400: 2020 2022 6874 7470 733a 2f2f 7261 772e     "https://raw.
+0000c410: 6769 7468 7562 7573 6572 636f 6e74 656e  githubuserconten
+0000c420: 742e 636f 6d2f 696e 6366 2d6e 6964 6173  t.com/incf-nidas
+0000c430: 682f 6e69 646d 2d73 7065 6373 2f6d 6173  h/nidm-specs/mas
+0000c440: 7465 722f 6e69 646d 2f6e 6964 6d2d 6578  ter/nidm/nidm-ex
+0000c450: 7065 7269 6d65 6e74 2f74 6572 6d73 2f6e  periment/terms/n
+0000c460: 6964 6d2d 6578 7065 7269 6d65 6e74 2e6f  idm-experiment.o
+0000c470: 776c 222c 0a20 2020 2020 2020 2022 6874  wl",.        "ht
+0000c480: 7470 733a 2f2f 7261 772e 6769 7468 7562  tps://raw.github
+0000c490: 7573 6572 636f 6e74 656e 742e 636f 6d2f  usercontent.com/
+0000c4a0: 696e 6366 2d6e 6964 6173 682f 6e69 646d  incf-nidash/nidm
+0000c4b0: 2d73 7065 6373 2f6d 6173 7465 722f 6e69  -specs/master/ni
+0000c4c0: 646d 2f6e 6964 6d2d 7265 7375 6c74 732f  dm/nidm-results/
+0000c4d0: 7465 726d 732f 6e69 646d 2d72 6573 756c  terms/nidm-resul
+0000c4e0: 7473 2e6f 776c 222c 0a20 2020 205d 0a0a  ts.owl",.    ]..
+0000c4f0: 2020 2020 2320 6c6f 6164 2065 6163 6820      # load each 
+0000c500: 6f77 6c20 6669 6c65 0a20 2020 2066 6f72  owl file.    for
+0000c510: 2072 6573 6f75 7263 6520 696e 206f 776c   resource in owl
+0000c520: 733a 0a20 2020 2020 2020 2074 656d 705f  s:.        temp_
+0000c530: 6772 6170 6820 3d20 4772 6170 6828 290a  graph = Graph().
+0000c540: 2020 2020 2020 2020 7472 793a 0a20 2020          try:.   
+0000c550: 2020 2020 2020 2020 2074 656d 705f 6772           temp_gr
+0000c560: 6170 682e 7061 7273 6528 6c6f 6361 7469  aph.parse(locati
+0000c570: 6f6e 3d72 6573 6f75 7263 652c 2066 6f72  on=resource, for
+0000c580: 6d61 743d 2274 7572 746c 6522 290a 2020  mat="turtle").  
+0000c590: 2020 2020 2020 2020 2020 756e 696f 6e5f            union_
+0000c5a0: 6772 6170 6820 3d20 756e 696f 6e5f 6772  graph = union_gr
+0000c5b0: 6170 6820 2b20 7465 6d70 5f67 7261 7068  aph + temp_graph
+0000c5c0: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
+0000c5d0: 4578 6365 7074 696f 6e3a 0a20 2020 2020  Exception:.     
+0000c5e0: 2020 2020 2020 206c 6f67 6769 6e67 2e69         logging.i
+0000c5f0: 6e66 6f28 2245 7272 6f72 206f 7065 6e69  nfo("Error openi
+0000c600: 6e67 2025 7320 6f77 6c20 6669 6c65 2e2e  ng %s owl file..
+0000c610: 636f 6e74 696e 7569 6e67 222c 2072 6573  continuing", res
+0000c620: 6f75 7263 6529 0a20 2020 2020 2020 2020  ource).         
+0000c630: 2020 2063 6f6e 7469 6e75 650a 0a20 2020     continue..   
+0000c640: 2072 6574 7572 6e20 756e 696f 6e5f 6772   return union_gr
+0000c650: 6170 680a 0a0a 6465 6620 6675 7a7a 795f  aph...def fuzzy_
+0000c660: 6d61 7463 685f 7465 726d 735f 6672 6f6d  match_terms_from
+0000c670: 5f67 7261 7068 2867 7261 7068 2c20 7175  _graph(graph, qu
+0000c680: 6572 795f 7374 7269 6e67 293a 0a20 2020  ery_string):.   
+0000c690: 2022 2222 0a20 2020 2054 6869 7320 6675   """.    This fu
+0000c6a0: 6e63 7469 6f6e 2070 6572 666f 726d 7320  nction performs 
+0000c6b0: 6120 6675 7a7a 7920 6d61 7463 6820 6f66  a fuzzy match of
+0000c6c0: 2074 6865 2063 6f6e 7374 616e 7473 2069   the constants i
+0000c6d0: 6e20 436f 6e73 7461 6e74 732e 7079 206c  n Constants.py l
+0000c6e0: 6973 7420 6e69 646d 5f65 7870 6572 696d  ist nidm_experim
+0000c6f0: 656e 745f 7465 726d 7320 666f 7220 7465  ent_terms for te
+0000c700: 726d 2063 6f6e 7374 616e 7473 206d 6174  rm constants mat
+0000c710: 6368 696e 6720 7468 6520 7175 6572 792e  ching the query.
+0000c720: 2e2e 2e69 0a20 2020 2069 6465 616c 6c79  ...i.    ideally
+0000c730: 2074 6869 7320 7368 6f75 6c64 2072 6561   this should rea
+0000c740: 6c6c 7920 6265 2073 6561 7263 6869 6e67  lly be searching
+0000c750: 2074 6865 204f 574c 2066 696c 6520 7768   the OWL file wh
+0000c760: 656e 2069 7427 7320 7265 6164 790a 2020  en it's ready.  
+0000c770: 2020 3a70 6172 616d 2071 7565 7279 5f73    :param query_s
+0000c780: 7472 696e 673a 2073 7472 696e 6720 746f  tring: string to
+0000c790: 2071 7565 7279 0a20 2020 203a 7265 7475   query.    :retu
+0000c7a0: 726e 3a20 6469 6374 696f 6e61 7279 2077  rn: dictionary w
+0000c7b0: 686f 7365 206b 6579 2069 7320 7468 6520  hose key is the 
+0000c7c0: 4e49 444d 2063 6f6e 7374 616e 7420 616e  NIDM constant an
+0000c7d0: 6420 7661 6c75 6520 6973 2074 6865 206d  d value is the m
+0000c7e0: 6174 6368 2073 636f 7265 2074 6f20 7468  atch score to th
+0000c7f0: 6520 7175 6572 790a 2020 2020 2222 220a  e query.    """.
+0000c800: 0a20 2020 206d 6174 6368 5f73 636f 7265  .    match_score
+0000c810: 7320 3d20 7b7d 0a0a 2020 2020 2320 7365  s = {}..    # se
+0000c820: 6172 6368 2066 6f72 206c 6162 656c 7320  arch for labels 
+0000c830: 7264 6673 3a6c 6162 656c 2061 6e64 206f  rdfs:label and o
+0000c840: 626f 3a49 414f 5f30 3030 3031 3135 2028  bo:IAO_0000115 (
+0000c850: 6465 7363 7269 7074 696f 6e29 2066 6f72  description) for
+0000c860: 2065 6163 6820 7264 663a 7479 7065 206f   each rdf:type o
+0000c870: 776c 3a43 6c61 7373 0a20 2020 2066 6f72  wl:Class.    for
+0000c880: 2074 6572 6d20 696e 2067 7261 7068 2e73   term in graph.s
+0000c890: 7562 6a65 6374 7328 7072 6564 6963 6174  ubjects(predicat
+0000c8a0: 653d 5244 462e 7479 7065 2c20 6f62 6a65  e=RDF.type, obje
+0000c8b0: 6374 3d43 6f6e 7374 616e 7473 2e4f 574c  ct=Constants.OWL
+0000c8c0: 5b22 436c 6173 7322 5d29 3a0a 2020 2020  ["Class"]):.    
+0000c8d0: 2020 2020 666f 7220 6c61 6265 6c20 696e      for label in
+0000c8e0: 2067 7261 7068 2e6f 626a 6563 7473 2873   graph.objects(s
+0000c8f0: 7562 6a65 6374 3d74 6572 6d2c 2070 7265  ubject=term, pre
+0000c900: 6469 6361 7465 3d43 6f6e 7374 616e 7473  dicate=Constants
+0000c910: 2e52 4446 535b 226c 6162 656c 225d 293a  .RDFS["label"]):
+0000c920: 0a20 2020 2020 2020 2020 2020 206d 6174  .            mat
+0000c930: 6368 5f73 636f 7265 735b 7465 726d 5d20  ch_scores[term] 
+0000c940: 3d20 7b7d 0a20 2020 2020 2020 2020 2020  = {}.           
+0000c950: 206d 6174 6368 5f73 636f 7265 735b 7465   match_scores[te
+0000c960: 726d 5d5b 2273 636f 7265 225d 203d 2066  rm]["score"] = f
+0000c970: 757a 7a2e 746f 6b65 6e5f 736f 7274 5f72  uzz.token_sort_r
+0000c980: 6174 696f 2871 7565 7279 5f73 7472 696e  atio(query_strin
+0000c990: 672c 206c 6162 656c 290a 2020 2020 2020  g, label).      
+0000c9a0: 2020 2020 2020 6d61 7463 685f 7363 6f72        match_scor
+0000c9b0: 6573 5b74 6572 6d5d 5b22 6c61 6265 6c22  es[term]["label"
+0000c9c0: 5d20 3d20 6c61 6265 6c0a 2020 2020 2020  ] = label.      
+0000c9d0: 2020 2020 2020 6d61 7463 685f 7363 6f72        match_scor
+0000c9e0: 6573 5b74 6572 6d5d 5b22 7572 6c22 5d20  es[term]["url"] 
+0000c9f0: 3d20 7465 726d 0a20 2020 2020 2020 2020  = term.         
+0000ca00: 2020 206d 6174 6368 5f73 636f 7265 735b     match_scores[
+0000ca10: 7465 726d 5d5b 2264 6566 696e 6974 696f  term]["definitio
+0000ca20: 6e22 5d20 3d20 4e6f 6e65 0a20 2020 2020  n"] = None.     
+0000ca30: 2020 2020 2020 2066 6f72 2064 6573 6372         for descr
+0000ca40: 6970 7469 6f6e 2069 6e20 6772 6170 682e  iption in graph.
+0000ca50: 6f62 6a65 6374 7328 0a20 2020 2020 2020  objects(.       
+0000ca60: 2020 2020 2020 2020 2073 7562 6a65 6374           subject
+0000ca70: 3d74 6572 6d2c 2070 7265 6469 6361 7465  =term, predicate
+0000ca80: 3d43 6f6e 7374 616e 7473 2e4f 424f 5b22  =Constants.OBO["
+0000ca90: 4941 4f5f 3030 3030 3131 3522 5d0a 2020  IAO_0000115"].  
+0000caa0: 2020 2020 2020 2020 2020 293a 0a20 2020            ):.   
+0000cab0: 2020 2020 2020 2020 2020 2020 206d 6174               mat
+0000cac0: 6368 5f73 636f 7265 735b 7465 726d 5d5b  ch_scores[term][
+0000cad0: 2264 6566 696e 6974 696f 6e22 5d20 3d20  "definition"] = 
+0000cae0: 6465 7363 7269 7074 696f 6e0a 0a20 2020  description..   
+0000caf0: 2023 2066 6f72 2074 6572 6d20 696e 206f   # for term in o
+0000cb00: 776c 5f67 7261 7068 2e63 6c61 7373 6573  wl_graph.classes
+0000cb10: 2829 3a0a 2020 2020 2320 2020 2070 7269  ():.    #    pri
+0000cb20: 6e74 2874 6572 6d2e 6765 745f 7072 6f70  nt(term.get_prop
+0000cb30: 6572 7469 6573 2829 290a 2020 2020 7265  erties()).    re
+0000cb40: 7475 726e 206d 6174 6368 5f73 636f 7265  turn match_score
+0000cb50: 730a 0a0a 6465 6620 6675 7a7a 795f 6d61  s...def fuzzy_ma
+0000cb60: 7463 685f 636f 6e63 6570 7473 5f66 726f  tch_concepts_fro
+0000cb70: 6d5f 6e69 646d 7465 726d 735f 6a73 6f6e  m_nidmterms_json
+0000cb80: 6c64 286a 736f 6e5f 7374 7275 6374 2c20  ld(json_struct, 
+0000cb90: 7175 6572 795f 7374 7269 6e67 293a 0a20  query_string):. 
+0000cba0: 2020 206d 6174 6368 5f73 636f 7265 7320     match_scores 
+0000cbb0: 3d20 7b7d 0a0a 2020 2020 2320 7365 6172  = {}..    # sear
+0000cbc0: 6368 2066 6f72 206c 6162 656c 7320 7264  ch for labels rd
+0000cbd0: 6673 3a6c 6162 656c 2061 6e64 206f 626f  fs:label and obo
+0000cbe0: 3a49 414f 5f30 3030 3031 3135 2028 6465  :IAO_0000115 (de
+0000cbf0: 7363 7269 7074 696f 6e29 2066 6f72 2065  scription) for e
+0000cc00: 6163 6820 7264 663a 7479 7065 206f 776c  ach rdf:type owl
+0000cc10: 3a43 6c61 7373 0a20 2020 2066 6f72 2065  :Class.    for e
+0000cc20: 6e74 7279 2069 6e20 6a73 6f6e 5f73 7472  ntry in json_str
+0000cc30: 7563 745b 2274 6572 6d73 225d 3a0a 2020  uct["terms"]:.  
+0000cc40: 2020 2020 2020 6d61 7463 685f 7363 6f72        match_scor
+0000cc50: 6573 5b65 6e74 7279 5b22 6c61 6265 6c22  es[entry["label"
+0000cc60: 5d5d 203d 207b 7d0a 2020 2020 2020 2020  ]] = {}.        
+0000cc70: 6d61 7463 685f 7363 6f72 6573 5b65 6e74  match_scores[ent
+0000cc80: 7279 5b22 6c61 6265 6c22 5d5d 5b22 7363  ry["label"]]["sc
+0000cc90: 6f72 6522 5d20 3d20 6675 7a7a 2e74 6f6b  ore"] = fuzz.tok
+0000cca0: 656e 5f73 6f72 745f 7261 7469 6f28 0a20  en_sort_ratio(. 
+0000ccb0: 2020 2020 2020 2020 2020 2071 7565 7279             query
+0000ccc0: 5f73 7472 696e 672c 2065 6e74 7279 5b22  _string, entry["
+0000ccd0: 6c61 6265 6c22 5d0a 2020 2020 2020 2020  label"].        
+0000cce0: 290a 2020 2020 2020 2020 6d61 7463 685f  ).        match_
+0000ccf0: 7363 6f72 6573 5b65 6e74 7279 5b22 6c61  scores[entry["la
+0000cd00: 6265 6c22 5d5d 5b22 6c61 6265 6c22 5d20  bel"]]["label"] 
+0000cd10: 3d20 656e 7472 795b 226c 6162 656c 225d  = entry["label"]
+0000cd20: 0a20 2020 2020 2020 2069 6620 2273 6368  .        if "sch
+0000cd30: 656d 613a 7572 6c22 2069 6e20 656e 7472  ema:url" in entr
+0000cd40: 792e 6b65 7973 2829 3a0a 2020 2020 2020  y.keys():.      
+0000cd50: 2020 2020 2020 6d61 7463 685f 7363 6f72        match_scor
+0000cd60: 6573 5b65 6e74 7279 5b22 6c61 6265 6c22  es[entry["label"
+0000cd70: 5d5d 5b22 7572 6c22 5d20 3d20 656e 7472  ]]["url"] = entr
+0000cd80: 795b 2273 6368 656d 613a 7572 6c22 5d0a  y["schema:url"].
+0000cd90: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+0000cda0: 2020 2020 2020 2020 2020 6d61 7463 685f            match_
+0000cdb0: 7363 6f72 6573 5b65 6e74 7279 5b22 6c61  scores[entry["la
+0000cdc0: 6265 6c22 5d5d 5b22 7572 6c22 5d20 3d20  bel"]]["url"] = 
+0000cdd0: 2222 0a20 2020 2020 2020 2069 6620 2264  "".        if "d
+0000cde0: 6573 6372 6970 7469 6f6e 2220 696e 2065  escription" in e
+0000cdf0: 6e74 7279 2e6b 6579 7328 293a 0a20 2020  ntry.keys():.   
+0000ce00: 2020 2020 2020 2020 206d 6174 6368 5f73           match_s
+0000ce10: 636f 7265 735b 656e 7472 795b 226c 6162  cores[entry["lab
+0000ce20: 656c 225d 5d5b 2264 6566 696e 6974 696f  el"]]["definitio
+0000ce30: 6e22 5d20 3d20 656e 7472 795b 2264 6573  n"] = entry["des
+0000ce40: 6372 6970 7469 6f6e 225d 0a20 2020 2020  cription"].     
+0000ce50: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0000ce60: 2020 2020 206d 6174 6368 5f73 636f 7265       match_score
+0000ce70: 735b 656e 7472 795b 226c 6162 656c 225d  s[entry["label"]
+0000ce80: 5d5b 2264 6566 696e 6974 696f 6e22 5d20  ]["definition"] 
+0000ce90: 3d20 2222 0a0a 2020 2020 2320 666f 7220  = ""..    # for 
+0000cea0: 7465 726d 2069 6e20 6f77 6c5f 6772 6170  term in owl_grap
+0000ceb0: 682e 636c 6173 7365 7328 293a 0a20 2020  h.classes():.   
+0000cec0: 2023 2020 2020 7072 696e 7428 7465 726d   #    print(term
+0000ced0: 2e67 6574 5f70 726f 7065 7274 6965 7328  .get_properties(
+0000cee0: 2929 0a20 2020 2072 6574 7572 6e20 6d61  )).    return ma
+0000cef0: 7463 685f 7363 6f72 6573 0a0a 0a64 6566  tch_scores...def
+0000cf00: 2066 757a 7a79 5f6d 6174 6368 5f74 6572   fuzzy_match_ter
+0000cf10: 6d73 5f66 726f 6d5f 636f 6761 746c 6173  ms_from_cogatlas
+0000cf20: 5f6a 736f 6e28 6a73 6f6e 5f73 7472 7563  _json(json_struc
+0000cf30: 742c 2071 7565 7279 5f73 7472 696e 6729  t, query_string)
+0000cf40: 3a0a 2020 2020 6d61 7463 685f 7363 6f72  :.    match_scor
+0000cf50: 6573 203d 207b 7d0a 0a20 2020 2023 2073  es = {}..    # s
+0000cf60: 6561 7263 6820 666f 7220 6c61 6265 6c73  earch for labels
+0000cf70: 2072 6466 733a 6c61 6265 6c20 616e 6420   rdfs:label and 
+0000cf80: 6f62 6f3a 4941 4f5f 3030 3030 3131 3520  obo:IAO_0000115 
+0000cf90: 2864 6573 6372 6970 7469 6f6e 2920 666f  (description) fo
+0000cfa0: 7220 6561 6368 2072 6466 3a74 7970 6520  r each rdf:type 
+0000cfb0: 6f77 6c3a 436c 6173 730a 2020 2020 666f  owl:Class.    fo
+0000cfc0: 7220 656e 7472 7920 696e 206a 736f 6e5f  r entry in json_
+0000cfd0: 7374 7275 6374 3a0a 2020 2020 2020 2020  struct:.        
+0000cfe0: 6d61 7463 685f 7363 6f72 6573 5b65 6e74  match_scores[ent
+0000cff0: 7279 5b22 6e61 6d65 225d 5d20 3d20 7b7d  ry["name"]] = {}
+0000d000: 0a20 2020 2020 2020 206d 6174 6368 5f73  .        match_s
+0000d010: 636f 7265 735b 656e 7472 795b 226e 616d  cores[entry["nam
+0000d020: 6522 5d5d 5b22 7363 6f72 6522 5d20 3d20  e"]]["score"] = 
+0000d030: 6675 7a7a 2e74 6f6b 656e 5f73 6f72 745f  fuzz.token_sort_
+0000d040: 7261 7469 6f28 0a20 2020 2020 2020 2020  ratio(.         
+0000d050: 2020 2071 7565 7279 5f73 7472 696e 672c     query_string,
+0000d060: 2065 6e74 7279 5b22 6e61 6d65 225d 0a20   entry["name"]. 
+0000d070: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0000d080: 206d 6174 6368 5f73 636f 7265 735b 656e   match_scores[en
+0000d090: 7472 795b 226e 616d 6522 5d5d 5b22 6c61  try["name"]]["la
+0000d0a0: 6265 6c22 5d20 3d20 656e 7472 795b 226e  bel"] = entry["n
+0000d0b0: 616d 6522 5d0a 2020 2020 2020 2020 6d61  ame"].        ma
+0000d0c0: 7463 685f 7363 6f72 6573 5b65 6e74 7279  tch_scores[entry
+0000d0d0: 5b22 6e61 6d65 225d 5d5b 2275 726c 225d  ["name"]]["url"]
+0000d0e0: 203d 2028 0a20 2020 2020 2020 2020 2020   = (.           
+0000d0f0: 2022 6874 7470 733a 2f2f 7777 772e 636f   "https://www.co
+0000d100: 676e 6974 6976 6561 746c 6173 2e6f 7267  gnitiveatlas.org
+0000d110: 2f63 6f6e 6365 7074 2f69 642f 2220 2b20  /concept/id/" + 
+0000d120: 656e 7472 795b 2269 6422 5d0a 2020 2020  entry["id"].    
+0000d130: 2020 2020 290a 2020 2020 2020 2020 6d61      ).        ma
+0000d140: 7463 685f 7363 6f72 6573 5b65 6e74 7279  tch_scores[entry
+0000d150: 5b22 6e61 6d65 225d 5d5b 2264 6566 696e  ["name"]]["defin
+0000d160: 6974 696f 6e22 5d20 3d20 656e 7472 795b  ition"] = entry[
+0000d170: 2264 6566 696e 6974 696f 6e5f 7465 7874  "definition_text
+0000d180: 225d 0a0a 2020 2020 2320 666f 7220 7465  "]..    # for te
+0000d190: 726d 2069 6e20 6f77 6c5f 6772 6170 682e  rm in owl_graph.
+0000d1a0: 636c 6173 7365 7328 293a 0a20 2020 2023  classes():.    #
+0000d1b0: 2020 2020 7072 696e 7428 7465 726d 2e67      print(term.g
+0000d1c0: 6574 5f70 726f 7065 7274 6965 7328 2929  et_properties())
+0000d1d0: 0a20 2020 2072 6574 7572 6e20 6d61 7463  .    return matc
+0000d1e0: 685f 7363 6f72 6573 0a0a 0a64 6566 2061  h_scores...def a
+0000d1f0: 7574 6865 6e74 6963 6174 655f 6769 7468  uthenticate_gith
+0000d200: 7562 2861 7574 6865 643d 4e6f 6e65 2c20  ub(authed=None, 
+0000d210: 6372 6564 656e 7469 616c 733d 4e6f 6e65  credentials=None
+0000d220: 293a 0a20 2020 2022 2222 0a20 2020 2054  ):.    """.    T
+0000d230: 6869 7320 6675 6e63 7469 6f6e 2077 696c  his function wil
+0000d240: 6c20 6861 6e67 6c65 2047 6974 4875 6220  l hangle GitHub 
+0000d250: 6175 7468 656e 7469 6361 7469 6f6e 2077  authentication w
+0000d260: 6974 6820 6f72 2077 6974 686f 7574 2061  ith or without a
+0000d270: 2074 6f6b 656e 2e20 2049 6620 7468 6520   token.  If the 
+0000d280: 7061 7261 6d65 7465 7220 6175 7468 6564  parameter authed
+0000d290: 2069 7320 6465 6669 6e65 6420 7468 650a   is defined the.
+0000d2a0: 2020 2020 6675 6e63 7469 6f6e 2077 696c      function wil
+0000d2b0: 6c20 6368 6563 6b20 7768 6574 6865 7220  l check whether 
+0000d2c0: 6974 2773 2061 6e20 6163 7469 7665 2f76  it's an active/v
+0000d2d0: 616c 6964 2061 7574 6865 6e74 6963 6174  alid authenticat
+0000d2e0: 696f 6e20 6f62 6a65 6374 2e20 2049 6620  ion object.  If 
+0000d2f0: 6e6f 742c 2061 6e64 2075 7365 726e 616d  not, and usernam
+0000d300: 652f 746f 6b65 6e20 6973 2073 7570 706c  e/token is suppl
+0000d310: 6965 6420 7468 656e 0a20 2020 2061 6e20  ied then.    an 
+0000d320: 6175 7468 656e 7469 6361 7469 6f6e 206f  authentication o
+0000d330: 626a 6563 7420 7769 6c6c 2062 6520 6372  bject will be cr
+0000d340: 6561 7465 642e 2020 4966 2075 7365 726e  eated.  If usern
+0000d350: 616d 6520 2b20 746f 6b65 6e20 6973 206e  ame + token is n
+0000d360: 6f74 2073 7570 706c 6965 6420 7468 656e  ot supplied then
+0000d370: 2074 6865 2075 7365 7220 7769 6c6c 2062   the user will b
+0000d380: 6520 7072 6f6d 7074 6564 2074 6f20 696e  e prompted to in
+0000d390: 7075 740a 2020 2020 7468 6520 696e 666f  put.    the info
+0000d3a0: 726d 6174 696f 6e2e 0a20 2020 203a 7061  rmation..    :pa
+0000d3b0: 7261 6d20 6175 7468 6564 3a20 4f70 7469  ram authed: Opti
+0000d3c0: 6f6e 616c 2061 7574 6865 6e74 6963 6169  onal authenticai
+0000d3d0: 6f6e 206f 626a 6563 7420 6672 6f6d 2050  on object from P
+0000d3e0: 7947 6974 6875 620a 2020 2020 3a70 6172  yGithub.    :par
+0000d3f0: 616d 2063 7265 6465 6e74 6961 6c73 3a20  am credentials: 
+0000d400: 4f70 7469 6f6e 616c 2047 6974 4875 6220  Optional GitHub 
+0000d410: 6372 6564 656e 7469 616c 206c 6973 7420  credential list 
+0000d420: 7573 6572 6e61 6d65 2c70 6173 7377 6f72  username,passwor
+0000d430: 6420 6f72 2075 7365 726e 616d 652c 746f  d or username,to
+0000d440: 6b65 6e0a 2020 2020 3a72 6574 7572 6e3a  ken.    :return:
+0000d450: 2047 6974 4875 6220 6175 7468 656e 7469   GitHub authenti
+0000d460: 6361 7469 6f6e 206f 626a 6563 7420 6f72  cation object or
+0000d470: 204e 6f6e 6520 6966 2075 6e73 7563 6365   None if unsucce
+0000d480: 7373 6675 6c0a 0a20 2020 2022 2222 0a0a  ssful..    """..
+0000d490: 2020 2020 7072 696e 7428 2247 6974 4875      print("GitHu
+0000d4a0: 6220 6175 7468 656e 7469 6361 7469 6f6e  b authentication
+0000d4b0: 2e2e 2e22 290a 2020 2020 696e 6478 203d  ...").    indx =
+0000d4c0: 2031 0a20 2020 206d 6178 7472 7920 3d20   1.    maxtry = 
+0000d4d0: 350a 2020 2020 7768 696c 6520 696e 6478  5.    while indx
+0000d4e0: 203c 206d 6178 7472 793a 0a20 2020 2020   < maxtry:.     
+0000d4f0: 2020 2069 6620 6c65 6e28 6372 6564 656e     if len(creden
+0000d500: 7469 616c 7329 203e 3d20 323a 0a20 2020  tials) >= 2:.   
+0000d510: 2020 2020 2020 2020 2023 2061 7574 6865           # authe
+0000d520: 6e74 6963 6174 6520 7769 7468 2074 6f6b  nticate with tok
+0000d530: 656e 0a20 2020 2020 2020 2020 2020 2067  en.            g
+0000d540: 203d 2047 6974 6875 6228 6372 6564 656e   = Github(creden
+0000d550: 7469 616c 735b 305d 2c20 6372 6564 656e  tials[0], creden
+0000d560: 7469 616c 735b 315d 290a 2020 2020 2020  tials[1]).      
+0000d570: 2020 656c 6966 206c 656e 2863 7265 6465    elif len(crede
+0000d580: 6e74 6961 6c73 2920 3d3d 2031 3a0a 2020  ntials) == 1:.  
+0000d590: 2020 2020 2020 2020 2020 7077 203d 2067            pw = g
+0000d5a0: 6574 7061 7373 2e67 6574 7061 7373 2822  etpass.getpass("
+0000d5b0: 506c 6561 7365 2065 6e74 6572 2079 6f75  Please enter you
+0000d5c0: 7220 4769 7448 7562 2070 6173 7377 6f72  r GitHub passwor
+0000d5d0: 643a 2022 290a 2020 2020 2020 2020 2020  d: ").          
+0000d5e0: 2020 6720 3d20 4769 7468 7562 2863 7265    g = Github(cre
+0000d5f0: 6465 6e74 6961 6c73 5b30 5d2c 2070 7729  dentials[0], pw)
+0000d600: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+0000d610: 2020 2020 2020 2020 2020 2075 7365 726e             usern
+0000d620: 616d 6520 3d20 696e 7075 7428 2250 6c65  ame = input("Ple
+0000d630: 6173 6520 656e 7465 7220 796f 7572 2047  ase enter your G
+0000d640: 6974 4875 6220 7573 6572 206e 616d 653a  itHub user name:
+0000d650: 2022 290a 2020 2020 2020 2020 2020 2020   ").            
+0000d660: 7077 203d 2067 6574 7061 7373 2e67 6574  pw = getpass.get
+0000d670: 7061 7373 2822 506c 6561 7365 2065 6e74  pass("Please ent
+0000d680: 6572 2079 6f75 7220 4769 7448 7562 2070  er your GitHub p
+0000d690: 6173 7377 6f72 643a 2022 290a 2020 2020  assword: ").    
+0000d6a0: 2020 2020 2020 2020 2320 7472 7920 746f          # try to
+0000d6b0: 206c 6f67 6769 6e67 2069 6e74 6f20 4769   logging into Gi
+0000d6c0: 7448 7562 0a20 2020 2020 2020 2020 2020  tHub.           
+0000d6d0: 2067 203d 2047 6974 6875 6228 7573 6572   g = Github(user
+0000d6e0: 6e61 6d65 2c20 7077 290a 0a20 2020 2020  name, pw)..     
+0000d6f0: 2020 2061 7574 6865 6420 3d20 672e 6765     authed = g.ge
+0000d700: 745f 7573 6572 2829 0a20 2020 2020 2020  t_user().       
+0000d710: 2074 7279 3a0a 2020 2020 2020 2020 2020   try:.          
+0000d720: 2020 2320 6368 6563 6b20 7765 2772 6520    # check we're 
+0000d730: 6c6f 6767 6564 2069 6e20 6279 2063 6865  logged in by che
+0000d740: 636b 696e 6720 7468 6174 2077 6520 6361  cking that we ca
+0000d750: 6e20 6163 6365 7373 2074 6865 2070 7562  n access the pub
+0000d760: 6c69 6320 7265 706f 7320 6c69 7374 0a20  lic repos list. 
+0000d770: 2020 2020 2020 2020 2020 2061 7574 6865             authe
+0000d780: 642e 7075 626c 6963 5f72 6570 6f73 0a20  d.public_repos. 
+0000d790: 2020 2020 2020 2020 2020 206c 6f67 6769             loggi
+0000d7a0: 6e67 2e69 6e66 6f28 2247 6974 6875 6220  ng.info("Github 
+0000d7b0: 6175 7468 656e 7469 6361 7469 6f6e 2073  authentication s
+0000d7c0: 7563 6365 7373 6675 6c22 290a 2020 2020  uccessful").    
+0000d7d0: 2020 2020 2020 2020 6272 6561 6b0a 2020          break.  
+0000d7e0: 2020 2020 2020 6578 6365 7074 2047 6974        except Git
+0000d7f0: 6875 6245 7863 6570 7469 6f6e 3a0a 2020  hubException:.  
+0000d800: 2020 2020 2020 2020 2020 6c6f 6767 696e            loggin
+0000d810: 672e 696e 666f 2822 6572 726f 7220 6c6f  g.info("error lo
+0000d820: 6767 696e 6720 696e 746f 2079 6f75 7220  gging into your 
+0000d830: 6769 7468 7562 2061 6363 6f75 6e74 2c20  github account, 
+0000d840: 706c 6561 7365 2074 7279 2061 6761 696e  please try again
+0000d850: 2e2e 2e22 290a 2020 2020 2020 2020 2020  ...").          
+0000d860: 2020 696e 6478 203d 2069 6e64 7820 2b20    indx = indx + 
+0000d870: 310a 0a20 2020 2069 6620 696e 6478 203d  1..    if indx =
+0000d880: 3d20 6d61 7874 7279 3a0a 2020 2020 2020  = maxtry:.      
+0000d890: 2020 6c6f 6767 696e 672e 6372 6974 6963    logging.critic
+0000d8a0: 616c 280a 2020 2020 2020 2020 2020 2020  al(.            
+0000d8b0: 2247 6974 4875 6220 6175 7468 656e 7469  "GitHub authenti
+0000d8c0: 6361 7469 6f6e 2066 6169 6c65 642e 2020  cation failed.  
+0000d8d0: 4368 6563 6b20 796f 7572 2075 7365 726e  Check your usern
+0000d8e0: 616d 6520 2f20 7061 7373 776f 7264 202f  ame / password /
+0000d8f0: 2074 6f6b 656e 2061 6e64 2074 7279 2061   token and try a
+0000d900: 6761 696e 220a 2020 2020 2020 2020 290a  gain".        ).
+0000d910: 2020 2020 2020 2020 7265 7475 726e 204e          return N
+0000d920: 6f6e 650a 2020 2020 656c 7365 3a0a 2020  one.    else:.  
+0000d930: 2020 2020 2020 7265 7475 726e 2061 7574        return aut
+0000d940: 6865 642c 2067 0a0a 0a64 6566 2067 6574  hed, g...def get
+0000d950: 5375 626a 4944 436f 6c75 6d6e 2863 6f6c  SubjIDColumn(col
+0000d960: 756d 6e5f 746f 5f74 6572 6d73 2c20 6466  umn_to_terms, df
+0000d970: 293a 0a20 2020 2022 2222 0a20 2020 2054  ):.    """.    T
+0000d980: 6869 7320 6675 6e63 7469 6f6e 2072 6574  his function ret
+0000d990: 7572 6e73 2063 6f6c 756d 6e20 6e75 6d62  urns column numb
+0000d9a0: 6572 2066 726f 6d20 4353 5620 6669 6c65  er from CSV file
+0000d9b0: 2074 6861 7420 6d61 7463 6865 7320 7375   that matches su
+0000d9c0: 626a 6964 2e20 2049 6620 6974 2063 616e  bjid.  If it can
+0000d9d0: 2774 2061 7574 6f6d 6174 6963 616c 6c79  't automatically
+0000d9e0: 0a20 2020 2064 6574 6563 7420 6974 2062  .    detect it b
+0000d9f0: 6173 6564 206f 6e20 7468 6520 436f 6e73  ased on the Cons
+0000da00: 7461 6e74 732e 4e49 444d 5f53 5542 4a45  tants.NIDM_SUBJE
+0000da10: 4354 4944 2074 6572 6d20 2869 2e65 2e20  CTID term (i.e. 
+0000da20: 6966 2074 6865 2075 7365 7220 7365 6c65  if the user sele
+0000da30: 6374 6564 2061 2064 6966 6665 7265 6e74  cted a different
+0000da40: 2074 6572 6d0a 2020 2020 746f 2061 6e6e   term.    to ann
+0000da50: 6f74 6174 6520 7375 626a 6563 7420 4944  otate subject ID
+0000da60: 2074 6865 6e20 6974 2061 736b 7320 7468   then it asks th
+0000da70: 6520 7573 6572 2e0a 2020 2020 3a70 6172  e user..    :par
+0000da80: 616d 2063 6f6c 756d 6e5f 746f 5f74 6572  am column_to_ter
+0000da90: 6d73 3a20 6a73 6f6e 2076 6172 6961 626c  ms: json variabl
+0000daa0: 652d 3e74 6572 6d20 6d61 7070 696e 6720  e->term mapping 
+0000dab0: 6469 6374 696f 6e61 7279 206d 6164 6520  dictionary made 
+0000dac0: 6279 206e 6964 6d2e 6578 7065 7269 6d65  by nidm.experime
+0000dad0: 6e74 2e55 7469 6c73 2e6d 6170 5f76 6172  nt.Utils.map_var
+0000dae0: 6961 626c 6573 5f74 6f5f 7465 726d 730a  iables_to_terms.
+0000daf0: 2020 2020 3a70 6172 616d 2064 663a 2064      :param df: d
+0000db00: 6174 6166 7261 6d65 206f 6620 4353 5620  ataframe of CSV 
+0000db10: 6669 6c65 2077 6974 6820 7461 6275 6c61  file with tabula
+0000db20: 7220 6461 7461 2074 6f20 636f 6e76 6572  r data to conver
+0000db30: 7420 746f 2052 4446 2e0a 2020 2020 3a72  t to RDF..    :r
+0000db40: 6574 7572 6e3a 2073 7562 6a65 6374 2049  eturn: subject I
+0000db50: 4420 636f 6c75 6d6e 206e 756d 6265 7220  D column number 
+0000db60: 696e 2043 5356 2064 6174 6166 7261 6d65  in CSV dataframe
+0000db70: 0a20 2020 2022 2222 0a0a 2020 2020 2320  .    """..    # 
+0000db80: 6c6f 6f6b 2061 7420 636f 6c75 6d6e 5f74  look at column_t
+0000db90: 6f5f 7465 726d 7320 6469 6374 696f 6e61  o_terms dictiona
+0000dba0: 7279 2066 6f72 204e 4944 4d20 5552 4c20  ry for NIDM URL 
+0000dbb0: 666f 7220 7375 626a 6563 7420 6964 2020  for subject id  
+0000dbc0: 2843 6f6e 7374 616e 7473 2e4e 4944 4d5f  (Constants.NIDM_
+0000dbd0: 5355 424a 4543 5449 4429 0a20 2020 2069  SUBJECTID).    i
+0000dbe0: 645f 6669 656c 6420 3d20 4e6f 6e65 0a20  d_field = None. 
+0000dbf0: 2020 2066 6f72 206b 6579 2c20 7661 6c75     for key, valu
+0000dc00: 6520 696e 2063 6f6c 756d 6e5f 746f 5f74  e in column_to_t
+0000dc10: 6572 6d73 2e69 7465 6d73 2829 3a0a 2020  erms.items():.  
+0000dc20: 2020 2020 2020 6966 2043 6f6e 7374 616e        if Constan
+0000dc30: 7473 2e4e 4944 4d5f 5355 424a 4543 5449  ts.NIDM_SUBJECTI
+0000dc40: 442e 5f73 7472 203d 3d20 7661 6c75 655b  D._str == value[
+0000dc50: 226c 6162 656c 225d 3a0a 2020 2020 2020  "label"]:.      
+0000dc60: 2020 2020 2020 6964 5f66 6965 6c64 203d        id_field =
+0000dc70: 206b 6579 0a0a 2020 2020 2320 6966 2077   key..    # if w
+0000dc80: 6520 636f 756c 646e 2774 2066 696e 6420  e couldn't find 
+0000dc90: 6120 7375 626a 6563 7420 4944 2066 6965  a subject ID fie
+0000dca0: 6c64 2069 6e20 636f 6c75 6d6e 5f74 6f5f  ld in column_to_
+0000dcb0: 7465 726d 732c 2061 736b 2075 7365 720a  terms, ask user.
+0000dcc0: 2020 2020 6966 2069 645f 6669 656c 6420      if id_field 
+0000dcd0: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
+0000dce0: 206f 7074 696f 6e20 3d20 310a 2020 2020   option = 1.    
+0000dcf0: 2020 2020 666f 7220 636f 6c75 6d6e 2069      for column i
+0000dd00: 6e20 6466 2e63 6f6c 756d 6e73 3a0a 2020  n df.columns:.  
+0000dd10: 2020 2020 2020 2020 2020 7072 696e 7428            print(
+0000dd20: 6622 7b6f 7074 696f 6e7d 3a20 7b63 6f6c  f"{option}: {col
+0000dd30: 756d 6e7d 2229 0a20 2020 2020 2020 2020  umn}").         
+0000dd40: 2020 206f 7074 696f 6e20 3d20 6f70 7469     option = opti
+0000dd50: 6f6e 202b 2031 0a20 2020 2020 2020 2073  on + 1.        s
+0000dd60: 656c 6563 7469 6f6e 203d 2069 6e70 7574  election = input
+0000dd70: 2822 506c 6561 7365 2073 656c 6563 7420  ("Please select 
+0000dd80: 7468 6520 7375 626a 6563 7420 4944 2066  the subject ID f
+0000dd90: 6965 6c64 2066 726f 6d20 7468 6520 6c69  ield from the li
+0000dda0: 7374 2061 626f 7665 3a20 2229 0a20 2020  st above: ").   
+0000ddb0: 2020 2020 2069 645f 6669 656c 6420 3d20       id_field = 
+0000ddc0: 6466 2e63 6f6c 756d 6e73 5b69 6e74 2873  df.columns[int(s
+0000ddd0: 656c 6563 7469 6f6e 2920 2d20 315d 0a20  election) - 1]. 
+0000dde0: 2020 2072 6574 7572 6e20 6964 5f66 6965     return id_fie
+0000ddf0: 6c64 0a0a 0a64 6566 2072 6564 6361 705f  ld...def redcap_
+0000de00: 6461 7461 6469 6374 696f 6e61 7279 5f74  datadictionary_t
+0000de10: 6f5f 6a73 6f6e 2872 6564 6361 705f 6464  o_json(redcap_dd
+0000de20: 5f66 696c 652c 2061 7373 6573 736d 656e  _file, assessmen
+0000de30: 745f 6e61 6d65 293a 0a20 2020 2022 2222  t_name):.    """
+0000de40: 0a20 2020 2054 6869 7320 6675 6e63 7469  .    This functi
+0000de50: 6f6e 2077 696c 6c20 636f 6e76 6572 7420  on will convert 
+0000de60: 6120 7265 6463 6170 2064 6174 6120 6469  a redcap data di
+0000de70: 6374 696f 6e61 7279 2074 6f20 6f75 7220  ctionary to our 
+0000de80: 6a73 6f6e 2064 6174 6120 656c 656d 656e  json data elemen
+0000de90: 7473 2073 7472 7563 7475 7265 0a20 2020  ts structure.   
+0000dea0: 203a 7061 7261 6d20 7265 6463 6170 5f64   :param redcap_d
+0000deb0: 643a 2052 6564 4361 7020 6461 7461 2064  d: RedCap data d
+0000dec0: 6963 7469 6f6e 6172 790a 2020 2020 3a72  ictionary.    :r
+0000ded0: 6574 7572 6e3a 206a 736f 6e20 6461 7461  eturn: json data
+0000dee0: 2065 6c65 6d65 6e74 2064 6566 696e 6974   element definit
+0000def0: 696f 6e73 0a20 2020 2022 2222 0a0a 2020  ions.    """..  
+0000df00: 2020 2320 6c6f 6164 2072 6564 6361 7020    # load redcap 
+0000df10: 6461 7461 2064 6963 7469 6f6e 6172 790a  data dictionary.
+0000df20: 2020 2020 7265 6463 6170 5f64 6420 3d20      redcap_dd = 
+0000df30: 7064 2e72 6561 645f 6373 7628 7265 6463  pd.read_csv(redc
+0000df40: 6170 5f64 645f 6669 6c65 290a 0a20 2020  ap_dd_file)..   
+0000df50: 206a 736f 6e5f 6d61 7020 3d20 7b7d 0a0a   json_map = {}..
+0000df60: 2020 2020 2320 6379 636c 6520 7468 726f      # cycle thro
+0000df70: 7567 6820 726f 7773 2061 6e64 2073 746f  ugh rows and sto
+0000df80: 7265 2076 6172 6961 626c 6520 6461 7461  re variable data
+0000df90: 2065 6c65 6d65 6e74 730a 2020 2020 666f   elements.    fo
+0000dfa0: 7220 5f2c 2072 6f77 2069 6e20 7265 6463  r _, row in redc
+0000dfb0: 6170 5f64 642e 6974 6572 726f 7773 2829  ap_dd.iterrows()
+0000dfc0: 3a0a 2020 2020 2020 2020 6375 7272 656e  :.        curren
+0000dfd0: 745f 7475 706c 6520 3d20 7374 7228 0a20  t_tuple = str(. 
+0000dfe0: 2020 2020 2020 2020 2020 2044 4428 736f             DD(so
+0000dff0: 7572 6365 3d61 7373 6573 736d 656e 745f  urce=assessment_
+0000e000: 6e61 6d65 2c20 7661 7269 6162 6c65 3d72  name, variable=r
+0000e010: 6f77 5b22 5661 7269 6162 6c65 202f 2046  ow["Variable / F
+0000e020: 6965 6c64 204e 616d 6522 5d29 0a20 2020  ield Name"]).   
+0000e030: 2020 2020 2029 0a20 2020 2020 2020 206a       ).        j
+0000e040: 736f 6e5f 6d61 705b 6375 7272 656e 745f  son_map[current_
+0000e050: 7475 706c 655d 203d 207b 7d0a 2020 2020  tuple] = {}.    
+0000e060: 2020 2020 6a73 6f6e 5f6d 6170 5b63 7572      json_map[cur
+0000e070: 7265 6e74 5f74 7570 6c65 5d5b 226c 6162  rent_tuple]["lab
+0000e080: 656c 225d 203d 2072 6f77 5b22 5661 7269  el"] = row["Vari
+0000e090: 6162 6c65 202f 2046 6965 6c64 204e 616d  able / Field Nam
+0000e0a0: 6522 5d0a 2020 2020 2020 2020 6a73 6f6e  e"].        json
+0000e0b0: 5f6d 6170 5b63 7572 7265 6e74 5f74 7570  _map[current_tup
+0000e0c0: 6c65 5d5b 2273 6f75 7263 655f 7661 7269  le]["source_vari
+0000e0d0: 6162 6c65 225d 203d 2072 6f77 5b22 5661  able"] = row["Va
+0000e0e0: 7269 6162 6c65 202f 2046 6965 6c64 204e  riable / Field N
+0000e0f0: 616d 6522 5d0a 2020 2020 2020 2020 6a73  ame"].        js
+0000e100: 6f6e 5f6d 6170 5b63 7572 7265 6e74 5f74  on_map[current_t
+0000e110: 7570 6c65 5d5b 2264 6573 6372 6970 7469  uple]["descripti
+0000e120: 6f6e 225d 203d 2072 6f77 5b22 4669 656c  on"] = row["Fiel
+0000e130: 6420 4c61 6265 6c22 5d0a 2020 2020 2020  d Label"].      
+0000e140: 2020 6966 206e 6f74 2070 642e 6973 6e75    if not pd.isnu
+0000e150: 6c6c 2872 6f77 5b22 4368 6f69 6365 7320  ll(row["Choices 
+0000e160: 4f52 2043 616c 6375 6c61 7469 6f6e 7322  OR Calculations"
+0000e170: 5d29 3a0a 2020 2020 2020 2020 2020 2020  ]):.            
+0000e180: 6966 2072 6f77 5b22 4669 656c 6420 5479  if row["Field Ty
+0000e190: 7065 225d 203d 3d20 2263 616c 6322 3a0a  pe"] == "calc":.
+0000e1a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e1b0: 2320 7468 6973 2069 7320 6120 6361 6c63  # this is a calc
+0000e1c0: 756c 6174 6564 2066 6965 6c64 2073 6f20  ulated field so 
+0000e1d0: 6974 2074 7970 6963 616c 6c79 2068 6173  it typically has
+0000e1e0: 2061 2073 756d 285b 7661 7231 5d2c 5b76   a sum([var1],[v
+0000e1f0: 6172 325d 2c2e 2e2c 6574 6329 2073 6f20  ar2],..,etc) so 
+0000e200: 7765 276c 6c20 6a75 7374 2073 746f 7265  we'll just store
+0000e210: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000e220: 2023 2069 7420 6861 7320 6173 2061 2073   # it has as a s
+0000e230: 696e 676c 6520 6c65 7665 6c0a 2020 2020  ingle level.    
+0000e240: 2020 2020 2020 2020 2020 2020 6a73 6f6e              json
+0000e250: 5f6d 6170 5b63 7572 7265 6e74 5f74 7570  _map[current_tup
+0000e260: 6c65 5d5b 226c 6576 656c 7322 5d20 3d20  le]["levels"] = 
+0000e270: 5b5d 0a20 2020 2020 2020 2020 2020 2020  [].             
+0000e280: 2020 206a 736f 6e5f 6d61 705b 6375 7272     json_map[curr
+0000e290: 656e 745f 7475 706c 655d 5b22 6c65 7665  ent_tuple]["leve
+0000e2a0: 6c73 225d 2e61 7070 656e 6428 0a20 2020  ls"].append(.   
+0000e2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e2c0: 2073 7472 2872 6f77 5b22 4368 6f69 6365   str(row["Choice
+0000e2d0: 7320 4f52 2043 616c 6375 6c61 7469 6f6e  s OR Calculation
+0000e2e0: 7322 5d29 0a20 2020 2020 2020 2020 2020  s"]).           
+0000e2f0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+0000e300: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+0000e310: 2020 2020 2020 2020 2073 706c 6974 5f63           split_c
+0000e320: 686f 6963 6573 203d 2072 6f77 5b22 4368  hoices = row["Ch
+0000e330: 6f69 6365 7320 4f52 2043 616c 6375 6c61  oices OR Calcula
+0000e340: 7469 6f6e 7322 5d2e 7370 6c69 7428 227c  tions"].split("|
+0000e350: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
+0000e360: 2020 2069 6620 6c65 6e28 7370 6c69 745f     if len(split_
+0000e370: 6368 6f69 6365 7329 203d 3d20 313a 0a20  choices) == 1:. 
 0000e380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e390: 2020 2063 6f6c 756d 6e5f 746f 5f74 6572     column_to_ter
-0000e3a0: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
-0000e3b0: 5d5b 2773 616d 6541 7327 5d20 3d20 6a73  ]['sameAs'] = js
-0000e3c0: 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65 795b  on_map[json_key[
-0000e3d0: 305d 5d5b 2773 616d 6541 7327 5d0a 2020  0]]['sameAs'].  
-0000e3e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e3f0: 2020 2020 2020 7072 696e 7428 2273 616d        print("sam
-0000e400: 6541 733a 2025 7322 2025 636f 6c75 6d6e  eAs: %s" %column
-0000e410: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
-0000e420: 745f 7475 706c 655d 5b27 7361 6d65 4173  t_tuple]['sameAs
-0000e430: 275d 290a 2020 2020 2020 2020 2020 2020  ']).            
-0000e440: 2020 2020 2020 2020 6966 2027 7572 6c27          if 'url'
-0000e450: 2069 6e20 6a73 6f6e 5f6d 6170 5b6a 736f   in json_map[jso
-0000e460: 6e5f 6b65 795b 305d 5d3a 0a20 2020 2020  n_key[0]]:.     
-0000e470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e480: 2020 2063 6f6c 756d 6e5f 746f 5f74 6572     column_to_ter
-0000e490: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
-0000e4a0: 5d5b 2775 726c 275d 203d 206a 736f 6e5f  ]['url'] = json_
-0000e4b0: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
-0000e4c0: 5b27 7572 6c27 5d0a 2020 2020 2020 2020  ['url'].        
+0000e390: 2020 206a 736f 6e5f 6d61 705b 6375 7272     json_map[curr
+0000e3a0: 656e 745f 7475 706c 655d 5b22 6c65 7665  ent_tuple]["leve
+0000e3b0: 6c73 225d 203d 205b 5d0a 2020 2020 2020  ls"] = [].      
+0000e3c0: 2020 2020 2020 2020 2020 2020 2020 6a73                js
+0000e3d0: 6f6e 5f6d 6170 5b63 7572 7265 6e74 5f74  on_map[current_t
+0000e3e0: 7570 6c65 5d5b 2276 616c 7565 5479 7065  uple]["valueType
+0000e3f0: 225d 203d 2055 5249 5265 6628 0a20 2020  "] = URIRef(.   
+0000e400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e410: 2020 2020 2043 6f6e 7374 616e 7473 2e58       Constants.X
+0000e420: 5344 5b22 636f 6d70 6c65 7854 7970 6522  SD["complexType"
+0000e430: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+0000e440: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+0000e450: 2020 2020 2020 2020 2020 2020 7370 6c69              spli
+0000e460: 745f 6368 6f69 6365 7320 3d20 726f 775b  t_choices = row[
+0000e470: 2243 686f 6963 6573 204f 5220 4361 6c63  "Choices OR Calc
+0000e480: 756c 6174 696f 6e73 225d 2e73 706c 6974  ulations"].split
+0000e490: 2822 2c22 290a 2020 2020 2020 2020 2020  (",").          
+0000e4a0: 2020 2020 2020 2020 2020 666f 7220 6368            for ch
+0000e4b0: 6f69 6365 7320 696e 2073 706c 6974 5f63  oices in split_c
+0000e4c0: 686f 6963 6573 3a0a 2020 2020 2020 2020  hoices:.        
 0000e4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e4e0: 7072 696e 7428 2275 726c 3a20 2573 2220  print("url: %s" 
-0000e4f0: 2520 636f 6c75 6d6e 5f74 6f5f 7465 726d  % column_to_term
-0000e500: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-0000e510: 5b27 7572 6c27 5d29 0a0a 2020 2020 2020  ['url'])..      
-0000e520: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0000e530: 2027 736f 7572 6365 5f76 6172 6961 626c   'source_variabl
-0000e540: 6527 2069 6e20 6a73 6f6e 5f6d 6170 5b6a  e' in json_map[j
-0000e550: 736f 6e5f 6b65 795b 305d 5d3a 0a20 2020  son_key[0]]:.   
-0000e560: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e570: 2020 2020 2063 6f6c 756d 6e5f 746f 5f74       column_to_t
-0000e580: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
-0000e590: 6c65 5d5b 2773 6f75 7263 655f 7661 7269  le]['source_vari
-0000e5a0: 6162 6c65 275d 203d 206a 736f 6e5f 6d61  able'] = json_ma
-0000e5b0: 705b 6a73 6f6e 5f6b 6579 5b30 5d5d 5b27  p[json_key[0]]['
-0000e5c0: 736f 7572 6365 5f76 6172 6961 626c 6527  source_variable'
-0000e5d0: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
-0000e5e0: 2020 2020 2020 2020 2020 7072 696e 7428            print(
-0000e5f0: 2273 6f75 7263 6520 7661 7269 6162 6c65  "source variable
-0000e600: 3a20 2573 2220 2520 636f 6c75 6d6e 5f74  : %s" % column_t
-0000e610: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
-0000e620: 7475 706c 655d 5b27 736f 7572 6365 5f76  tuple]['source_v
-0000e630: 6172 6961 626c 6527 5d29 0a20 2020 2020  ariable']).     
-0000e640: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0000e650: 6c69 6620 2773 6f75 7263 6556 6172 6961  lif 'sourceVaria
-0000e660: 626c 6527 2069 6e20 6a73 6f6e 5f6d 6170  ble' in json_map
-0000e670: 5b6a 736f 6e5f 6b65 795b 305d 5d3a 0a20  [json_key[0]]:. 
-0000e680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e690: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
-0000e6a0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-0000e6b0: 7570 6c65 5d5b 2773 6f75 7263 655f 7661  uple]['source_va
-0000e6c0: 7269 6162 6c65 275d 203d 206a 736f 6e5f  riable'] = json_
-0000e6d0: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
-0000e6e0: 5b27 736f 7572 6365 5661 7269 6162 6c65  ['sourceVariable
-0000e6f0: 275d 0a20 2020 2020 2020 2020 2020 2020  '].             
-0000e700: 2020 2020 2020 2020 2020 2070 7269 6e74             print
-0000e710: 2822 736f 7572 6365 2076 6172 6961 626c  ("source variabl
-0000e720: 653a 2025 7322 2025 2063 6f6c 756d 6e5f  e: %s" % column_
-0000e730: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-0000e740: 5f74 7570 6c65 5d5b 2773 6f75 7263 655f  _tuple]['source_
-0000e750: 7661 7269 6162 6c65 275d 290a 2020 2020  variable']).    
-0000e760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e770: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-0000e780: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-0000e790: 6164 6420 736f 7572 6365 2076 6172 6961  add source varia
-0000e7a0: 626c 6520 6966 206e 6f74 2074 6865 7265  ble if not there
-0000e7b0: 2e2e 2e0a 2020 2020 2020 2020 2020 2020  ....            
-0000e7c0: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
-0000e7d0: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
-0000e7e0: 656e 745f 7475 706c 655d 5b27 736f 7572  ent_tuple]['sour
-0000e7f0: 6365 5f76 6172 6961 626c 6527 5d20 3d20  ce_variable'] = 
-0000e800: 7374 7228 636f 6c75 6d6e 290a 2020 2020  str(column).    
-0000e810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e820: 2020 2020 7072 696e 7428 2241 6464 6564      print("Added
-0000e830: 2073 6f75 7263 6520 7661 7269 6162 6c65   source variable
-0000e840: 2028 2573 2920 746f 2061 6e6e 6f74 6174   (%s) to annotat
-0000e850: 696f 6e73 2220 2563 6f6c 756d 6e29 0a0a  ions" %column)..
-0000e860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e870: 2020 2020 6966 2022 6173 736f 6369 6174      if "associat
-0000e880: 6564 5769 7468 2220 696e 206a 736f 6e5f  edWith" in json_
-0000e890: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
-0000e8a0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000e8b0: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
-0000e8c0: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
-0000e8d0: 745f 7475 706c 655d 5b27 6173 736f 6369  t_tuple]['associ
-0000e8e0: 6174 6564 5769 7468 275d 203d 206a 736f  atedWith'] = jso
-0000e8f0: 6e5f 6d61 705b 6a73 6f6e 5f6b 6579 5b30  n_map[json_key[0
-0000e900: 5d5d 5b27 6173 736f 6369 6174 6564 5769  ]]['associatedWi
-0000e910: 7468 275d 0a20 2020 2020 2020 2020 2020  th'].           
-0000e920: 2020 2020 2020 2020 2020 2020 2070 7269               pri
-0000e930: 6e74 2822 6173 736f 6369 6174 6564 5769  nt("associatedWi
-0000e940: 7468 3a20 2573 2220 2520 636f 6c75 6d6e  th: %s" % column
-0000e950: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
-0000e960: 745f 7475 706c 655d 5b27 6173 736f 6369  t_tuple]['associ
-0000e970: 6174 6564 5769 7468 275d 290a 2020 2020  atedWith']).    
-0000e980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e990: 6966 2022 616c 6c6f 7761 626c 6556 616c  if "allowableVal
-0000e9a0: 7565 7322 2069 6e20 6a73 6f6e 5f6d 6170  ues" in json_map
-0000e9b0: 5b6a 736f 6e5f 6b65 795b 305d 5d3a 0a20  [json_key[0]]:. 
-0000e9c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e9d0: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
-0000e9e0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-0000e9f0: 7570 6c65 5d5b 2761 6c6c 6f77 6162 6c65  uple]['allowable
-0000ea00: 5661 6c75 6573 275d 203d 206a 736f 6e5f  Values'] = json_
-0000ea10: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
-0000ea20: 5b27 616c 6c6f 7761 626c 6556 616c 7565  ['allowableValue
-0000ea30: 7327 5d0a 2020 2020 2020 2020 2020 2020  s'].            
-0000ea40: 2020 2020 2020 2020 2020 2020 7072 696e              prin
-0000ea50: 7428 2261 6c6c 6f77 6162 6c65 5661 6c75  t("allowableValu
-0000ea60: 6573 3a20 2573 2220 2520 636f 6c75 6d6e  es: %s" % column
-0000ea70: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
-0000ea80: 745f 7475 706c 655d 5b27 616c 6c6f 7761  t_tuple]['allowa
-0000ea90: 626c 6556 616c 7565 7327 5d29 0a0a 2020  bleValues'])..  
-0000eaa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eab0: 2020 2320 6164 6465 6420 746f 2073 7570    # added to sup
-0000eac0: 706f 7274 2052 6570 726f 5363 6865 6d61  port ReproSchema
-0000ead0: 206a 736f 6e20 666f 726d 6174 0a20 2020   json format.   
-0000eae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eaf0: 2069 6620 2772 6573 706f 6e73 654f 7074   if 'responseOpt
-0000eb00: 696f 6e73 2720 696e 206a 736f 6e5f 6d61  ions' in json_ma
-0000eb10: 705b 6a73 6f6e 5f6b 6579 5b30 5d5d 3a0a  p[json_key[0]]:.
-0000eb20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eb30: 2020 2020 2020 2020 666f 7220 7375 626b          for subk
-0000eb40: 6579 2c20 7375 6276 616c 7965 2069 6e20  ey, subvalye in 
-0000eb50: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
-0000eb60: 795b 305d 5d5b 2772 6573 706f 6e73 654f  y[0]]['responseO
-0000eb70: 7074 696f 6e73 275d 2e69 7465 6d73 2829  ptions'].items()
-0000eb80: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000eb90: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0000eba0: 2027 7661 6c75 6554 7970 6527 2069 6e20   'valueType' in 
-0000ebb0: 7375 626b 6579 3a0a 2020 2020 2020 2020  subkey:.        
-0000ebc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ebd0: 2020 2020 2020 2020 6966 2027 7265 7370          if 'resp
-0000ebe0: 6f6e 7365 4f70 7469 6f6e 7327 206e 6f74  onseOptions' not
-0000ebf0: 2069 6e20 636f 6c75 6d6e 5f74 6f5f 7465   in column_to_te
-0000ec00: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
-0000ec10: 655d 2e6b 6579 7328 293a 0a20 2020 2020  e].keys():.     
-0000ec20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ec30: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-0000ec40: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
-0000ec50: 7572 7265 6e74 5f74 7570 6c65 5d5b 2772  urrent_tuple]['r
-0000ec60: 6573 706f 6e73 654f 7074 696f 6e73 275d  esponseOptions']
-0000ec70: 203d 207b 7d0a 0a20 2020 2020 2020 2020   = {}..         
-0000ec80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ec90: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
-0000eca0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-0000ecb0: 7570 6c65 5d5b 2772 6573 706f 6e73 654f  uple]['responseO
-0000ecc0: 7074 696f 6e73 275d 5b27 7661 6c75 6554  ptions']['valueT
-0000ecd0: 7970 6527 5d20 3d20 5c0a 2020 2020 2020  ype'] = \.      
-0000ece0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ecf0: 2020 2020 2020 2020 2020 2020 2020 6a73                js
-0000ed00: 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65 795b  on_map[json_key[
-0000ed10: 305d 5d5b 2772 6573 706f 6e73 654f 7074  0]]['responseOpt
-0000ed20: 696f 6e73 275d 5b27 7661 6c75 6554 7970  ions']['valueTyp
-0000ed30: 6527 5d0a 2020 2020 2020 2020 2020 2020  e'].            
-0000ed40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ed50: 2020 2020 7072 696e 7428 2276 616c 7565      print("value
-0000ed60: 5479 7065 3a20 2573 2220 2520 636f 6c75  Type: %s" % colu
-0000ed70: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
-0000ed80: 656e 745f 7475 706c 655d 5b27 7265 7370  ent_tuple]['resp
-0000ed90: 6f6e 7365 4f70 7469 6f6e 7327 5d5b 0a20  onseOptions'][. 
-0000eda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000edb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000edc0: 2020 2027 7661 6c75 6554 7970 6527 5d29     'valueType'])
-0000edd0: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000ede0: 2020 2020 2020 2020 2020 2020 2020 656c                el
-0000edf0: 6966 2027 6d69 6e56 616c 7565 2720 696e  if 'minValue' in
-0000ee00: 2073 7562 6b65 793a 0a20 2020 2020 2020   subkey:.       
-0000ee10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ee20: 2020 2020 2020 2020 2069 6620 2772 6573           if 'res
-0000ee30: 706f 6e73 654f 7074 696f 6e73 2720 6e6f  ponseOptions' no
-0000ee40: 7420 696e 2063 6f6c 756d 6e5f 746f 5f74  t in column_to_t
-0000ee50: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
-0000ee60: 6c65 5d2e 6b65 7973 2829 3a0a 2020 2020  le].keys():.    
-0000ee70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ee80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ee90: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
-0000eea0: 6375 7272 656e 745f 7475 706c 655d 5b27  current_tuple]['
-0000eeb0: 7265 7370 6f6e 7365 4f70 7469 6f6e 7327  responseOptions'
-0000eec0: 5d20 3d20 7b7d 0a0a 2020 2020 2020 2020  ] = {}..        
-0000eed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eee0: 2020 2020 2020 2020 636f 6c75 6d6e 5f74          column_t
-0000eef0: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
-0000ef00: 7475 706c 655d 5b27 7265 7370 6f6e 7365  tuple]['response
-0000ef10: 4f70 7469 6f6e 7327 5d5b 276d 696e 5661  Options']['minVa
-0000ef20: 6c75 6527 5d20 3d20 5c0a 2020 2020 2020  lue'] = \.      
-0000ef30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ef40: 2020 2020 2020 2020 2020 2020 2020 6a73                js
-0000ef50: 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65 795b  on_map[json_key[
-0000ef60: 305d 5d5b 2772 6573 706f 6e73 654f 7074  0]]['responseOpt
-0000ef70: 696f 6e73 275d 5b27 6d69 6e56 616c 7565  ions']['minValue
-0000ef80: 275d 0a20 2020 2020 2020 2020 2020 2020  '].             
-0000ef90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000efa0: 2020 2070 7269 6e74 280a 2020 2020 2020     print(.      
-0000efb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000efc0: 2020 2020 2020 2020 2020 2020 2020 226d                "m
-0000efd0: 696e 5661 6c75 653a 2025 7322 2025 2063  inValue: %s" % c
-0000efe0: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
-0000eff0: 7572 7265 6e74 5f74 7570 6c65 5d5b 2772  urrent_tuple]['r
-0000f000: 6573 706f 6e73 654f 7074 696f 6e73 275d  esponseOptions']
-0000f010: 5b27 6d69 6e56 616c 7565 275d 290a 0a20  ['minValue']).. 
-0000f020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f030: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
-0000f040: 276d 6178 5661 6c75 6527 2069 6e20 7375  'maxValue' in su
-0000f050: 626b 6579 3a0a 2020 2020 2020 2020 2020  bkey:.          
-0000f060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f070: 2020 2020 2020 6966 2027 7265 7370 6f6e        if 'respon
-0000f080: 7365 4f70 7469 6f6e 7327 206e 6f74 2069  seOptions' not i
-0000f090: 6e20 636f 6c75 6d6e 5f74 6f5f 7465 726d  n column_to_term
-0000f0a0: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-0000f0b0: 2e6b 6579 7328 293a 0a20 2020 2020 2020  .keys():.       
-0000f0c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f0d0: 2020 2020 2020 2020 2020 2020 2063 6f6c               col
-0000f0e0: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
-0000f0f0: 7265 6e74 5f74 7570 6c65 5d5b 2772 6573  rent_tuple]['res
-0000f100: 706f 6e73 654f 7074 696f 6e73 275d 203d  ponseOptions'] =
-0000f110: 207b 7d0a 0a20 2020 2020 2020 2020 2020   {}..           
-0000f120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f130: 2020 2020 2063 6f6c 756d 6e5f 746f 5f74       column_to_t
-0000f140: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
-0000f150: 6c65 5d5b 2772 6573 706f 6e73 654f 7074  le]['responseOpt
-0000f160: 696f 6e73 275d 5b27 6d61 7856 616c 7565  ions']['maxValue
-0000f170: 275d 203d 205c 0a20 2020 2020 2020 2020  '] = \.         
-0000f180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f190: 2020 2020 2020 2020 2020 206a 736f 6e5f             json_
-0000f1a0: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
-0000f1b0: 5b27 7265 7370 6f6e 7365 4f70 7469 6f6e  ['responseOption
-0000f1c0: 7327 5d5b 276d 6178 5661 6c75 6527 5d0a  s']['maxValue'].
-0000f1d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f1e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f1f0: 7072 696e 7428 0a20 2020 2020 2020 2020  print(.         
-0000f200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f210: 2020 2020 2020 2020 2020 2022 6d61 7856             "maxV
-0000f220: 616c 7565 3a20 2573 2220 2520 636f 6c75  alue: %s" % colu
-0000f230: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
-0000f240: 656e 745f 7475 706c 655d 5b27 7265 7370  ent_tuple]['resp
-0000f250: 6f6e 7365 4f70 7469 6f6e 7327 5d5b 276d  onseOptions']['m
-0000f260: 6178 5661 6c75 6527 5d29 0a20 2020 2020  axValue']).     
-0000f270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f280: 2020 2020 2020 2065 6c69 6620 2763 686f         elif 'cho
-0000f290: 6963 6573 2720 696e 2073 7562 6b65 793a  ices' in subkey:
-0000f2a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f2c0: 2069 6620 2772 6573 706f 6e73 654f 7074   if 'responseOpt
-0000f2d0: 696f 6e73 2720 6e6f 7420 696e 2063 6f6c  ions' not in col
-0000f2e0: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
-0000f2f0: 7265 6e74 5f74 7570 6c65 5d2e 6b65 7973  rent_tuple].keys
-0000f300: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
-0000f310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f320: 2020 2020 2020 2020 636f 6c75 6d6e 5f74          column_t
-0000f330: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
-0000f340: 7475 706c 655d 5b27 7265 7370 6f6e 7365  tuple]['response
-0000f350: 4f70 7469 6f6e 7327 5d20 3d20 7b7d 0a0a  Options'] = {}..
-0000f360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f380: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
-0000f390: 6375 7272 656e 745f 7475 706c 655d 5b27  current_tuple]['
-0000f3a0: 7265 7370 6f6e 7365 4f70 7469 6f6e 7327  responseOptions'
-0000f3b0: 5d5b 2763 686f 6963 6573 275d 203d 205c  ]['choices'] = \
-0000f3c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f3e0: 2020 2020 206a 736f 6e5f 6d61 705b 6a73       json_map[js
-0000f3f0: 6f6e 5f6b 6579 5b30 5d5d 5b27 7265 7370  on_key[0]]['resp
-0000f400: 6f6e 7365 4f70 7469 6f6e 7327 5d5b 2763  onseOptions']['c
-0000f410: 686f 6963 6573 275d 0a20 2020 2020 2020  hoices'].       
-0000f420: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f430: 2020 2020 2020 2020 2070 7269 6e74 2822           print("
-0000f440: 6c65 7665 6c73 3a20 2573 2220 2520 636f  levels: %s" % co
-0000f450: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
-0000f460: 7272 656e 745f 7475 706c 655d 5b27 7265  rrent_tuple]['re
-0000f470: 7370 6f6e 7365 4f70 7469 6f6e 7327 5d5b  sponseOptions'][
-0000f480: 2763 686f 6963 6573 275d 290a 2020 2020  'choices']).    
-0000f490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f4a0: 2020 2020 2020 2020 656c 6966 2027 6861          elif 'ha
-0000f4b0: 7355 6e69 7427 2069 6e20 7375 626b 6579  sUnit' in subkey
-0000f4c0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000f4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f4e0: 2020 6966 2027 7265 7370 6f6e 7365 4f70    if 'responseOp
-0000f4f0: 7469 6f6e 7327 206e 6f74 2069 6e20 636f  tions' not in co
-0000f500: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
-0000f510: 7272 656e 745f 7475 706c 655d 2e6b 6579  rrent_tuple].key
-0000f520: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
-0000f530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f540: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
-0000f550: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-0000f560: 5f74 7570 6c65 5d5b 2772 6573 706f 6e73  _tuple]['respons
-0000f570: 654f 7074 696f 6e73 275d 203d 207b 7d0a  eOptions'] = {}.
-0000f580: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f5a0: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
-0000f5b0: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
-0000f5c0: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
-0000f5d0: 275d 5b27 756e 6974 436f 6465 275d 203d  ']['unitCode'] =
-0000f5e0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-0000f5f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f600: 2020 2020 2020 206a 736f 6e5f 6d61 705b         json_map[
-0000f610: 6a73 6f6e 5f6b 6579 5b30 5d5d 5b27 7265  json_key[0]]['re
-0000f620: 7370 6f6e 7365 4f70 7469 6f6e 7327 5d5b  sponseOptions'][
-0000f630: 2768 6173 556e 6974 275d 0a20 2020 2020  'hasUnit'].     
-0000f640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f650: 2020 2020 2020 2020 2020 2070 7269 6e74             print
-0000f660: 2822 756e 6974 733a 2025 7322 2025 2063  ("units: %s" % c
-0000f670: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
-0000f680: 7572 7265 6e74 5f74 7570 6c65 5d5b 2772  urrent_tuple]['r
-0000f690: 6573 706f 6e73 654f 7074 696f 6e73 275d  esponseOptions']
-0000f6a0: 5b27 756e 6974 436f 6465 275d 290a 2020  ['unitCode']).  
-0000f6b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f6c0: 2020 2020 2020 2020 2020 656c 6966 2027            elif '
-0000f6d0: 756e 6974 436f 6465 2720 696e 2073 7562  unitCode' in sub
-0000f6e0: 6b65 793a 0a20 2020 2020 2020 2020 2020  key:.           
-0000f6f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f700: 2020 2020 2069 6620 2772 6573 706f 6e73       if 'respons
-0000f710: 654f 7074 696f 6e73 2720 6e6f 7420 696e  eOptions' not in
-0000f720: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
-0000f730: 5b63 7572 7265 6e74 5f74 7570 6c65 5d2e  [current_tuple].
-0000f740: 6b65 7973 2829 3a0a 2020 2020 2020 2020  keys():.        
-0000f750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f760: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
-0000f770: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
-0000f780: 656e 745f 7475 706c 655d 5b27 7265 7370  ent_tuple]['resp
-0000f790: 6f6e 7365 4f70 7469 6f6e 7327 5d20 3d20  onseOptions'] = 
-0000f7a0: 7b7d 0a0a 2020 2020 2020 2020 2020 2020  {}..            
-0000f7b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f7c0: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
-0000f7d0: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
-0000f7e0: 655d 5b27 7265 7370 6f6e 7365 4f70 7469  e]['responseOpti
-0000f7f0: 6f6e 7327 5d5b 2775 6e69 7443 6f64 6527  ons']['unitCode'
-0000f800: 5d20 3d20 5c0a 2020 2020 2020 2020 2020  ] = \.          
-0000f810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f820: 2020 2020 2020 2020 2020 6a73 6f6e 5f6d            json_m
-0000f830: 6170 5b6a 736f 6e5f 6b65 795b 305d 5d5b  ap[json_key[0]][
-0000f840: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
-0000f850: 275d 5b27 756e 6974 436f 6465 275d 0a20  ']['unitCode']. 
-0000f860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f870: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-0000f880: 7269 6e74 2822 756e 6974 733a 2025 7322  rint("units: %s"
-0000f890: 2025 2063 6f6c 756d 6e5f 746f 5f74 6572   % column_to_ter
-0000f8a0: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
-0000f8b0: 5d5b 2772 6573 706f 6e73 654f 7074 696f  ]['responseOptio
-0000f8c0: 6e73 275d 5b27 756e 6974 436f 6465 275d  ns']['unitCode']
-0000f8d0: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
-0000f8e0: 2020 2020 2020 2069 6620 276c 6576 656c         if 'level
-0000f8f0: 7327 2069 6e20 6a73 6f6e 5f6d 6170 5b6a  s' in json_map[j
-0000f900: 736f 6e5f 6b65 795b 305d 5d3a 0a20 2020  son_key[0]]:.   
-0000f910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f920: 2020 2020 2023 2075 7067 7261 6465 2027       # upgrade '
-0000f930: 6c65 7665 6c73 2720 746f 2027 7265 7370  levels' to 'resp
-0000f940: 6f6e 7365 4f70 7469 6f6e 7327 2d3e 2763  onseOptions'->'c
-0000f950: 686f 6963 6573 270a 2020 2020 2020 2020  hoices'.        
-0000f960: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f970: 6966 2027 7265 7370 6f6e 7365 4f70 7469  if 'responseOpti
-0000f980: 6f6e 7327 206e 6f74 2069 6e20 636f 6c75  ons' not in colu
-0000f990: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
-0000f9a0: 656e 745f 7475 706c 655d 2e6b 6579 7328  ent_tuple].keys(
-0000f9b0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-0000f9c0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-0000f9d0: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
-0000f9e0: 7572 7265 6e74 5f74 7570 6c65 5d5b 2772  urrent_tuple]['r
-0000f9f0: 6573 706f 6e73 654f 7074 696f 6e73 275d  esponseOptions']
-0000fa00: 203d 207b 7d0a 2020 2020 2020 2020 2020   = {}.          
-0000fa10: 2020 2020 2020 2020 2020 2020 2020 636f                co
-0000fa20: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
-0000fa30: 7272 656e 745f 7475 706c 655d 5b27 7265  rrent_tuple]['re
-0000fa40: 7370 6f6e 7365 4f70 7469 6f6e 7327 5d5b  sponseOptions'][
-0000fa50: 2763 686f 6963 6573 275d 203d 206a 736f  'choices'] = jso
-0000fa60: 6e5f 6d61 705b 6a73 6f6e 5f6b 6579 5b30  n_map[json_key[0
-0000fa70: 5d5d 5b0a 2020 2020 2020 2020 2020 2020  ]][.            
+0000e4e0: 6a73 6f6e 5f6d 6170 5b63 7572 7265 6e74  json_map[current
+0000e4f0: 5f74 7570 6c65 5d5b 226c 6576 656c 7322  _tuple]["levels"
+0000e500: 5d2e 6170 7065 6e64 2863 686f 6963 6573  ].append(choices
+0000e510: 2e73 7472 6970 2829 290a 0a20 2020 2020  .strip())..     
+0000e520: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+0000e530: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000e540: 2020 2020 206a 736f 6e5f 6d61 705b 6375       json_map[cu
+0000e550: 7272 656e 745f 7475 706c 655d 5b22 6c65  rrent_tuple]["le
+0000e560: 7665 6c73 225d 203d 207b 7d0a 2020 2020  vels"] = {}.    
+0000e570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e580: 6a73 6f6e 5f6d 6170 5b63 7572 7265 6e74  json_map[current
+0000e590: 5f74 7570 6c65 5d5b 2276 616c 7565 5479  _tuple]["valueTy
+0000e5a0: 7065 225d 203d 2055 5249 5265 6628 0a20  pe"] = URIRef(. 
+0000e5b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e5c0: 2020 2020 2020 2043 6f6e 7374 616e 7473         Constants
+0000e5d0: 2e58 5344 5b22 636f 6d70 6c65 7854 7970  .XSD["complexTyp
+0000e5e0: 6522 5d0a 2020 2020 2020 2020 2020 2020  e"].            
+0000e5f0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+0000e600: 2020 2020 2020 2020 2020 2020 2020 666f                fo
+0000e610: 7220 6368 6f69 6365 7320 696e 2073 706c  r choices in spl
+0000e620: 6974 5f63 686f 6963 6573 3a0a 2020 2020  it_choices:.    
+0000e630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e640: 2020 2020 6b65 795f 7661 6c75 6520 3d20      key_value = 
+0000e650: 6368 6f69 6365 732e 7370 6c69 7428 222c  choices.split(",
+0000e660: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
+0000e670: 2020 2020 2020 2020 2020 206a 736f 6e5f             json_
+0000e680: 6d61 705b 6375 7272 656e 745f 7475 706c  map[current_tupl
+0000e690: 655d 5b22 6c65 7665 6c73 225d 5b0a 2020  e]["levels"][.  
+0000e6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e6b0: 2020 2020 2020 2020 2020 7374 7228 6b65            str(ke
+0000e6c0: 795f 7661 6c75 655b 305d 292e 7374 7269  y_value[0]).stri
+0000e6d0: 7028 290a 2020 2020 2020 2020 2020 2020  p().            
+0000e6e0: 2020 2020 2020 2020 2020 2020 5d20 3d20              ] = 
+0000e6f0: 7374 7228 6b65 795f 7661 6c75 655b 315d  str(key_value[1]
+0000e700: 292e 7374 7269 7028 290a 2020 2020 2020  ).strip().      
+0000e710: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0000e720: 2020 2020 6a73 6f6e 5f6d 6170 5b63 7572      json_map[cur
+0000e730: 7265 6e74 5f74 7570 6c65 5d5b 2276 616c  rent_tuple]["val
+0000e740: 7565 5479 7065 225d 203d 2055 5249 5265  ueType"] = URIRe
+0000e750: 6628 436f 6e73 7461 6e74 732e 5853 445b  f(Constants.XSD[
+0000e760: 2273 7472 696e 6722 5d29 0a0a 2020 2020  "string"])..    
+0000e770: 7265 7475 726e 206a 736f 6e5f 6d61 700a  return json_map.
+0000e780: 0a0a 6465 6620 6465 7465 6374 5f6a 736f  ..def detect_jso
+0000e790: 6e5f 666f 726d 6174 286a 736f 6e5f 6d61  n_format(json_ma
+0000e7a0: 7029 3a0a 2020 2020 2222 220a 2020 2020  p):.    """.    
+0000e7b0: 5468 6973 2066 756e 6374 696f 6e20 7769  This function wi
+0000e7c0: 6c6c 2074 616b 6520 6120 6a73 6f6e 2022  ll take a json "
+0000e7d0: 7369 6465 6361 7222 2066 696c 6520 6f72  sidecar" file or
+0000e7e0: 206a 736f 6e20 616e 6e6f 7461 7469 6f6e   json annotation
+0000e7f0: 2064 6174 6120 6469 6374 696f 6e61 7279   data dictionary
+0000e800: 2073 7472 7563 7475 7265 0a20 2020 2061   structure.    a
+0000e810: 6e64 2064 6574 6572 6d69 6e65 2069 6620  nd determine if 
+0000e820: 6974 2727 7320 636f 6e73 6973 7465 6e74  it''s consistent
+0000e830: 2077 6974 6820 7468 6520 5265 7072 6f53   with the ReproS
+0000e840: 6368 656d 6120 7374 7275 6374 7572 6520  chema structure 
+0000e850: 2863 6f6d 706f 756e 6420 6b65 7973 2072  (compound keys r
+0000e860: 6f6f 742d 6c65 7665 6c20 6b65 7973 0a20  oot-level keys. 
+0000e870: 2020 2044 4428 736f 7572 6365 3d58 5858     DD(source=XXX
+0000e880: 2c76 6172 6961 626c 653d 5959 5929 2061  ,variable=YYY) a
+0000e890: 6e64 2027 7265 7370 6f6e 7365 4f70 7469  nd 'responseOpti
+0000e8a0: 6f6e 7327 2073 7562 6b65 7973 292c 2074  ons' subkeys), t
+0000e8b0: 6865 206f 6c64 6572 2070 796e 6964 6d20  he older pynidm 
+0000e8c0: 666f 726d 6174 2028 636f 6d70 6f75 6e64  format (compound
+0000e8d0: 0a20 2020 206b 6579 7320 6173 2052 6570  .    keys as Rep
+0000e8e0: 726f 5363 6865 6d61 2c20 6e6f 2072 6570  roSchema, no rep
+0000e8f0: 6f6e 7365 4f70 7469 6f6e 7320 7375 626b  onseOptions subk
+0000e900: 6579 7329 2c20 6f72 2074 6865 2042 4944  eys), or the BID
+0000e910: 5320 7369 6465 6361 7220 6669 6c65 2073  S sidecar file s
+0000e920: 7472 7563 7475 7265 0a20 2020 2028 666c  tructure.    (fl
+0000e930: 6174 2073 7472 7563 7475 7265 2c20 7661  at structure, va
+0000e940: 7269 6162 6c65 206e 616d 6573 2061 7320  riable names as 
+0000e950: 6b65 7973 2c20 6e6f 2072 6573 706f 6e73  keys, no respons
+0000e960: 6520 6f70 7469 6f6e 7329 2e20 2049 7420  e options).  It 
+0000e970: 7769 6c6c 2072 6574 7572 6e20 6120 7374  will return a st
+0000e980: 7269 6e67 2061 7373 6f63 6961 7465 640a  ring associated.
+0000e990: 2020 2020 7769 7468 2074 6865 2073 7472      with the str
+0000e9a0: 7563 7475 7265 3a20 4249 4453 207c 204f  ucture: BIDS | O
+0000e9b0: 4c44 5f50 594e 4944 4d20 7c20 5245 5052  LD_PYNIDM | REPR
+0000e9c0: 4f53 4348 454d 410a 0a20 2020 203a 7061  OSCHEMA..    :pa
+0000e9d0: 7261 6d20 6a73 6f6e 5f6d 6170 3a20 6a73  ram json_map: js
+0000e9e0: 6f6e 2061 6e6e 6f74 6174 696f 6e20 6669  on annotation fi
+0000e9f0: 6c65 2064 6963 7469 6f6e 6172 7920 2866  le dictionary (f
+0000ea00: 696c 6520 616c 7265 6164 7920 6c6f 6164  ile already load
+0000ea10: 6564 2077 6974 6820 6a73 6f6e 2e6c 6f61  ed with json.loa
+0000ea20: 6429 0a0a 2020 2020 2222 220a 0a20 2020  d)..    """..   
+0000ea30: 2066 6f72 206b 6579 2c20 7661 6c75 6520   for key, value 
+0000ea40: 696e 206a 736f 6e5f 6d61 702e 6b65 7973  in json_map.keys
+0000ea50: 2829 3a0a 2020 2020 2020 2020 6966 2022  ():.        if "
+0000ea60: 4444 2822 2069 6e20 6b65 793a 0a20 2020  DD(" in key:.   
+0000ea70: 2020 2020 2020 2020 2069 6620 2272 6573           if "res
+0000ea80: 706f 6e73 654f 7074 696f 6e73 2220 696e  ponseOptions" in
+0000ea90: 2076 616c 7565 2e6b 6579 7328 293a 0a20   value.keys():. 
+0000eaa0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+0000eab0: 6574 7572 6e20 2252 4550 524f 5343 4845  eturn "REPROSCHE
+0000eac0: 4d41 220a 2020 2020 2020 2020 2020 2020  MA".            
+0000ead0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+0000eae0: 2020 2020 2020 7265 7475 726e 2022 4f4c        return "OL
+0000eaf0: 445f 5059 4e49 444d 220a 2020 2020 2020  D_PYNIDM".      
+0000eb00: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0000eb10: 2020 2020 7265 7475 726e 2022 4249 4453      return "BIDS
+0000eb20: 220a 0a0a 6465 6620 6d61 7463 685f 7061  "...def match_pa
+0000eb30: 7274 6963 6970 616e 745f 6964 5f66 6965  rticipant_id_fie
+0000eb40: 6c64 2873 6f75 7263 655f 7661 7269 6162  ld(source_variab
+0000eb50: 6c65 293a 0a20 2020 2022 2222 0a20 2020  le):.    """.   
+0000eb60: 2054 6869 7320 6675 6e63 7469 6f6e 2077   This function w
+0000eb70: 696c 6c20 7465 7374 2077 6865 7468 6572  ill test whether
+0000eb80: 2074 6865 2073 6f75 7263 655f 7661 7269   the source_vari
+0000eb90: 6162 6c65 2069 7320 6120 7061 7274 6963  able is a partic
+0000eba0: 6970 616e 7420 4944 2066 6965 6c64 206f  ipant ID field o
+0000ebb0: 7220 6e6f 7420 6279 2073 7472 696e 6720  r not by string 
+0000ebc0: 6d61 7463 6869 6e67 2e0a 2020 2020 3a70  matching..    :p
+0000ebd0: 6172 616d 2073 6f75 7263 655f 7661 7269  aram source_vari
+0000ebe0: 6162 6c65 3a20 736f 7572 6365 2076 6172  able: source var
+0000ebf0: 6961 626c 6520 7374 7269 6e67 2074 6f20  iable string to 
+0000ec00: 7465 7374 0a20 2020 2022 2222 0a20 2020  test.    """.   
+0000ec10: 2073 6f75 7263 655f 7661 7269 6162 6c65   source_variable
+0000ec20: 203d 2073 6f75 7263 655f 7661 7269 6162   = source_variab
+0000ec30: 6c65 2e6c 6f77 6572 2829 0a20 2020 2072  le.lower().    r
+0000ec40: 6574 7572 6e20 280a 2020 2020 2020 2020  eturn (.        
+0000ec50: 2270 6172 7469 6369 7061 6e74 5f69 6422  "participant_id"
+0000ec60: 2069 6e20 736f 7572 6365 5f76 6172 6961   in source_varia
+0000ec70: 626c 650a 2020 2020 2020 2020 6f72 2022  ble.        or "
+0000ec80: 7375 626a 6563 745f 6964 2220 696e 2073  subject_id" in s
+0000ec90: 6f75 7263 655f 7661 7269 6162 6c65 0a20  ource_variable. 
+0000eca0: 2020 2020 2020 206f 7220 2822 7061 7274         or ("part
+0000ecb0: 6963 6970 616e 7422 2069 6e20 736f 7572  icipant" in sour
+0000ecc0: 6365 5f76 6172 6961 626c 6520 616e 6420  ce_variable and 
+0000ecd0: 2269 6422 2069 6e20 736f 7572 6365 5f76  "id" in source_v
+0000ece0: 6172 6961 626c 6529 0a20 2020 2020 2020  ariable).       
+0000ecf0: 206f 7220 2822 7375 626a 6563 7422 2069   or ("subject" i
+0000ed00: 6e20 736f 7572 6365 5f76 6172 6961 626c  n source_variabl
+0000ed10: 6520 616e 6420 2269 6422 2069 6e20 736f  e and "id" in so
+0000ed20: 7572 6365 5f76 6172 6961 626c 6529 0a20  urce_variable). 
+0000ed30: 2020 2020 2020 206f 7220 2822 7375 6222         or ("sub"
+0000ed40: 2069 6e20 736f 7572 6365 5f76 6172 6961   in source_varia
+0000ed50: 626c 6520 616e 6420 2269 6422 2069 6e20  ble and "id" in 
+0000ed60: 736f 7572 6365 5f76 6172 6961 626c 6529  source_variable)
+0000ed70: 0a20 2020 2029 0a0a 0a64 6566 206d 6170  .    )...def map
+0000ed80: 5f76 6172 6961 626c 6573 5f74 6f5f 7465  _variables_to_te
+0000ed90: 726d 7328 0a20 2020 2064 662c 0a20 2020  rms(.    df,.   
+0000eda0: 2064 6972 6563 746f 7279 2c0a 2020 2020   directory,.    
+0000edb0: 6173 7365 7373 6d65 6e74 5f6e 616d 652c  assessment_name,
+0000edc0: 0a20 2020 206f 7574 7075 745f 6669 6c65  .    output_file
+0000edd0: 3d4e 6f6e 652c 0a20 2020 206a 736f 6e5f  =None,.    json_
+0000ede0: 736f 7572 6365 3d4e 6f6e 652c 0a20 2020  source=None,.   
+0000edf0: 2062 6964 733d 4661 6c73 652c 0a20 2020   bids=False,.   
+0000ee00: 206f 776c 5f66 696c 653d 226e 6964 6d22   owl_file="nidm"
+0000ee10: 2c0a 2020 2020 6173 736f 6369 6174 655f  ,.    associate_
+0000ee20: 636f 6e63 6570 7473 3d54 7275 652c 0a20  concepts=True,. 
+0000ee30: 2020 2064 6174 6173 6574 5f69 6465 6e74     dataset_ident
+0000ee40: 6966 6965 723d 4e6f 6e65 2c0a 293a 0a20  ifier=None,.):. 
+0000ee50: 2020 2022 2222 0a0a 2020 2020 3a70 6172     """..    :par
+0000ee60: 616d 2064 663a 2064 6174 6120 6672 616d  am df: data fram
+0000ee70: 6520 7769 7468 2066 6972 7374 2072 6f77  e with first row
+0000ee80: 2063 6f6e 7461 696e 696e 6720 7661 7269   containing vari
+0000ee90: 6162 6c65 206e 616d 6573 0a20 2020 203a  able names.    :
+0000eea0: 7061 7261 6d20 6173 7365 7373 6d65 6e74  param assessment
+0000eeb0: 5f6e 616d 653a 204e 616d 6520 666f 7220  _name: Name for 
+0000eec0: 7468 6520 6173 7365 7373 6d65 6e74 2074  the assessment t
+0000eed0: 6f20 7573 6520 696e 2073 746f 7269 6e67  o use in storing
+0000eee0: 204a 534f 4e20 6d61 7070 696e 6720 6469   JSON mapping di
+0000eef0: 6374 696f 6e61 7279 206b 6579 730a 2020  ctionary keys.  
+0000ef00: 2020 3a70 6172 616d 206a 736f 6e5f 736f    :param json_so
+0000ef10: 7572 6365 3a20 6f70 7469 6f6e 616c 206a  urce: optional j
+0000ef20: 736f 6e20 646f 6375 6d65 6e74 2065 6974  son document eit
+0000ef30: 6865 7220 696e 2066 696c 6520 6f72 2073  her in file or s
+0000ef40: 7472 7563 7475 7265 0a20 2020 2020 2020  tructure.       
+0000ef50: 2020 2020 2077 6974 6820 7661 7269 6162       with variab
+0000ef60: 6c65 206e 616d 6573 2061 7320 6b65 7973  le names as keys
+0000ef70: 2061 6e64 206d 696e 696d 616c 2066 6965   and minimal fie
+0000ef80: 6c64 7320 2264 6566 696e 6974 696f 6e22  lds "definition"
+0000ef90: 2c22 6c61 6265 6c22 2c22 7572 6c22 0a20  ,"label","url". 
+0000efa0: 2020 203a 7061 7261 6d20 6f75 7470 7574     :param output
+0000efb0: 5f66 696c 653a 206f 7574 7075 7420 6669  _file: output fi
+0000efc0: 6c65 6e61 6d65 2074 6f20 7361 7665 2076  lename to save v
+0000efd0: 6172 6961 626c 652d 3e20 7465 726d 206d  ariable-> term m
+0000efe0: 6170 7069 6e67 730a 2020 2020 3a70 6172  appings.    :par
+0000eff0: 616d 2064 6972 6563 746f 7279 3a20 6966  am directory: if
+0000f000: 206f 7574 7075 745f 6669 6c65 2070 6172   output_file par
+0000f010: 616d 6574 6572 2069 7320 7365 7420 746f  ameter is set to
+0000f020: 204e 6f6e 6520 7468 656e 2075 7365 2074   None then use t
+0000f030: 6869 7320 6469 7265 6374 6f72 7920 746f  his directory to
+0000f040: 2073 746f 7265 2064 6566 6175 6c74 204a   store default J
+0000f050: 534f 4e20 6d61 7070 696e 6720 6669 6c65  SON mapping file
+0000f060: 0a20 2020 2069 6620 646f 696e 6720 7661  .    if doing va
+0000f070: 7269 6162 6c65 2d3e 7465 726d 206d 6170  riable->term map
+0000f080: 7069 6e67 730a 2020 2020 3a72 6574 7572  pings.    :retur
+0000f090: 6e3a 7265 7475 726e 2064 6963 7469 6f6e  n:return diction
+0000f0a0: 6172 7920 6d61 7070 696e 6720 7661 7269  ary mapping vari
+0000f0b0: 6162 6c65 206e 616d 6573 2028 692e 652e  able names (i.e.
+0000f0c0: 2063 6f6c 756d 6e73 2920 746f 2074 6572   columns) to ter
+0000f0d0: 6d73 0a20 2020 2022 2222 0a0a 2020 2020  ms.    """..    
+0000f0e0: 2320 6469 6374 696f 6e61 7279 206d 6170  # dictionary map
+0000f0f0: 7069 6e67 2063 6f6c 756d 6e20 6e61 6d65  ping column name
+0000f100: 2074 6f20 7072 6566 6572 7265 6420 7465   to preferred te
+0000f110: 726d 0a20 2020 2063 6f6c 756d 6e5f 746f  rm.    column_to
+0000f120: 5f74 6572 6d73 203d 207b 7d0a 0a20 2020  _terms = {}..   
+0000f130: 2023 2063 6865 636b 2069 6620 7573 6572   # check if user
+0000f140: 2073 7570 706c 6965 6420 6120 4a53 4f4e   supplied a JSON
+0000f150: 2066 696c 6520 6f72 2061 206a 736f 6e20   file or a json 
+0000f160: 6469 6374 696f 6e61 7279 0a20 2020 2069  dictionary.    i
+0000f170: 6620 6a73 6f6e 5f73 6f75 7263 6520 6973  f json_source is
+0000f180: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
+0000f190: 2020 2074 7279 3a0a 2020 2020 2020 2020     try:.        
+0000f1a0: 2020 2020 2320 6368 6563 6b20 6966 206a      # check if j
+0000f1b0: 736f 6e5f 736f 7572 6365 2069 7320 6120  son_source is a 
+0000f1c0: 6669 6c65 0a20 2020 2020 2020 2020 2020  file.           
+0000f1d0: 2069 6620 6f73 2e70 6174 682e 6973 6669   if os.path.isfi
+0000f1e0: 6c65 286a 736f 6e5f 736f 7572 6365 293a  le(json_source):
+0000f1f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f200: 2023 206c 6f61 6420 6669 6c65 0a20 2020   # load file.   
+0000f210: 2020 2020 2020 2020 2020 2020 2077 6974               wit
+0000f220: 6820 6f70 656e 286a 736f 6e5f 736f 7572  h open(json_sour
+0000f230: 6365 2c20 2272 222c 2065 6e63 6f64 696e  ce, "r", encodin
+0000f240: 673d 2275 7466 2d38 2229 2061 7320 663a  g="utf-8") as f:
+0000f250: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f260: 2020 2020 206a 736f 6e5f 6d61 7020 3d20       json_map = 
+0000f270: 6a73 6f6e 2e6c 6f61 6428 6629 0a20 2020  json.load(f).   
+0000f280: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+0000f290: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0000f2a0: 7269 6e74 2822 4552 524f 523a 2043 616e  rint("ERROR: Can
+0000f2b0: 2774 206f 7065 6e20 6a73 6f6e 206d 6170  't open json map
+0000f2c0: 7069 6e67 2066 696c 653a 222c 206a 736f  ping file:", jso
+0000f2d0: 6e5f 736f 7572 6365 290a 2020 2020 2020  n_source).      
+0000f2e0: 2020 2020 2020 2020 2020 7379 732e 6578            sys.ex
+0000f2f0: 6974 2829 0a20 2020 2020 2020 2065 7863  it().        exc
+0000f300: 6570 7420 4578 6365 7074 696f 6e3a 0a20  ept Exception:. 
+0000f310: 2020 2020 2020 2020 2020 2023 2069 6620             # if 
+0000f320: 6e6f 7420 7468 656e 2069 7427 7320 6120  not then it's a 
+0000f330: 6a73 6f6e 2073 7472 7563 7475 7265 2061  json structure a
+0000f340: 6c72 6561 6479 0a20 2020 2020 2020 2020  lready.         
+0000f350: 2020 206a 736f 6e5f 6d61 7020 3d20 6a73     json_map = js
+0000f360: 6f6e 5f73 6f75 7263 650a 2020 2020 2020  on_source.      
+0000f370: 2020 2020 2020 2320 6164 6465 6420 6368        # added ch
+0000f380: 6563 6b20 746f 206d 616b 6520 7375 7265  eck to make sure
+0000f390: 206a 736f 6e5f 6d61 7020 6973 2076 616c   json_map is val
+0000f3a0: 6964 2064 6963 7469 6f6e 6172 790a 2020  id dictionary.  
+0000f3b0: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
+0000f3c0: 2069 7369 6e73 7461 6e63 6528 6a73 6f6e   isinstance(json
+0000f3d0: 5f6d 6170 2c20 6469 6374 293a 0a20 2020  _map, dict):.   
+0000f3e0: 2020 2020 2020 2020 2020 2020 2070 7269               pri
+0000f3f0: 6e74 280a 2020 2020 2020 2020 2020 2020  nt(.            
+0000f400: 2020 2020 2020 2020 2245 5252 4f52 3a20          "ERROR: 
+0000f410: 496e 7661 6c69 6420 4a53 4f4e 2066 696c  Invalid JSON fil
+0000f420: 6520 7375 7070 6c69 6564 2e20 2050 6c65  e supplied.  Ple
+0000f430: 6173 6520 6368 6563 6b20 796f 7572 204a  ase check your J
+0000f440: 534f 4e20 6669 6c65 2077 6974 6820 6120  SON file with a 
+0000f450: 7661 6c69 6461 746f 7220 6669 7273 7421  validator first!
+0000f460: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+0000f470: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+0000f480: 2020 2020 7072 696e 7428 2265 7869 7469      print("exiti
+0000f490: 6e67 2122 290a 2020 2020 2020 2020 2020  ng!").          
+0000f4a0: 2020 2020 2020 7379 732e 6578 6974 2829        sys.exit()
+0000f4b0: 0a0a 2020 2020 2320 6966 206e 6f20 4a53  ..    # if no JS
+0000f4c0: 4f4e 206d 6170 7069 6e67 2066 696c 6520  ON mapping file 
+0000f4d0: 7761 7320 7370 6563 6966 6965 6420 7468  was specified th
+0000f4e0: 656e 2063 7265 6174 6520 6120 6465 6661  en create a defa
+0000f4f0: 756c 7420 6f6e 6520 666f 7220 7661 7269  ult one for vari
+0000f500: 6162 6c65 2d74 6572 6d20 6d61 7070 696e  able-term mappin
+0000f510: 6773 0a20 2020 2023 2063 7265 6174 6520  gs.    # create 
+0000f520: 6120 6a73 6f6e 5f66 696c 6520 6669 6c65  a json_file file
+0000f530: 6e61 6d65 2066 726f 6d20 7468 6520 6f75  name from the ou
+0000f540: 7470 7574 2066 696c 6520 6669 6c65 6e61  tput file filena
+0000f550: 6d65 0a20 2020 2069 6620 6f75 7470 7574  me.    if output
+0000f560: 5f66 696c 6520 6973 204e 6f6e 653a 0a20  _file is None:. 
+0000f570: 2020 2020 2020 206f 7574 7075 745f 6669         output_fi
+0000f580: 6c65 203d 206f 732e 7061 7468 2e6a 6f69  le = os.path.joi
+0000f590: 6e28 6469 7265 6374 6f72 792c 2022 6e69  n(directory, "ni
+0000f5a0: 646d 5f61 6e6e 6f74 6174 696f 6e73 2e6a  dm_annotations.j
+0000f5b0: 736f 6e22 290a 0a20 2020 2023 2069 6e69  son")..    # ini
+0000f5c0: 7469 616c 697a 6520 496e 7465 724c 6578  tialize InterLex
+0000f5d0: 2063 6f6e 6e65 6374 696f 6e0a 2020 2020   connection.    
+0000f5e0: 7472 793a 0a20 2020 2020 2020 2069 6c78  try:.        ilx
+0000f5f0: 5f6f 626a 203d 2049 6e69 7469 616c 697a  _obj = Initializ
+0000f600: 6549 6e74 6572 6c65 7852 656d 6f74 6528  eInterlexRemote(
+0000f610: 290a 2020 2020 6578 6365 7074 2045 7863  ).    except Exc
+0000f620: 6570 7469 6f6e 3a0a 2020 2020 2020 2020  eption:.        
+0000f630: 7072 696e 7428 2245 5252 4f52 3a20 696e  print("ERROR: in
+0000f640: 6974 6961 6c69 7a69 6e67 2049 6e74 6572  itializing Inter
+0000f650: 4c65 7820 636f 6e6e 6563 7469 6f6e 2e2e  Lex connection..
+0000f660: 2e22 290a 2020 2020 2020 2020 7072 696e  .").        prin
+0000f670: 7428 2259 6f75 2077 696c 6c20 6e6f 7420  t("You will not 
+0000f680: 6265 2061 626c 6520 746f 2061 6464 206f  be able to add o
+0000f690: 7220 7175 6572 7920 666f 7220 636f 6e63  r query for conc
+0000f6a0: 6570 7473 2e22 290a 2020 2020 2020 2020  epts.").        
+0000f6b0: 696c 785f 6f62 6a20 3d20 4e6f 6e65 0a20  ilx_obj = None. 
+0000f6c0: 2020 2023 206c 6f61 6420 4e49 444d 204f     # load NIDM O
+0000f6d0: 574c 2066 696c 6573 2069 6620 7573 6572  WL files if user
+0000f6e0: 2072 6571 7565 7374 6564 2069 740a 2020   requested it.  
+0000f6f0: 2020 6966 206f 776c 5f66 696c 6520 3d3d    if owl_file ==
+0000f700: 2022 6e69 646d 223a 0a20 2020 2020 2020   "nidm":.       
+0000f710: 2074 7279 3a0a 2020 2020 2020 2020 2020   try:.          
+0000f720: 2020 6e69 646d 5f6f 776c 5f67 7261 7068    nidm_owl_graph
+0000f730: 203d 206c 6f61 645f 6e69 646d 5f6f 776c   = load_nidm_owl
+0000f740: 5f66 696c 6573 2829 0a20 2020 2020 2020  _files().       
+0000f750: 2065 7863 6570 7420 4578 6365 7074 696f   except Exceptio
+0000f760: 6e3a 0a20 2020 2020 2020 2020 2020 2070  n:.            p
+0000f770: 7269 6e74 2829 0a20 2020 2020 2020 2020  rint().         
+0000f780: 2020 2070 7269 6e74 2822 4552 524f 523a     print("ERROR:
+0000f790: 2069 6e69 7469 616c 697a 696e 6720 696e   initializing in
+0000f7a0: 7465 726e 6574 2063 6f6e 6e65 6374 696f  ternet connectio
+0000f7b0: 6e20 746f 204e 4944 4d20 4f57 4c20 6669  n to NIDM OWL fi
+0000f7c0: 6c65 732e 2e2e 2229 0a20 2020 2020 2020  les...").       
+0000f7d0: 2020 2020 2070 7269 6e74 2822 596f 7520       print("You 
+0000f7e0: 7769 6c6c 206e 6f74 2062 6520 6162 6c65  will not be able
+0000f7f0: 2074 6f20 7365 6c65 6374 2074 6572 6d73   to select terms
+0000f800: 2066 726f 6d20 4e49 444d 204f 574c 2066   from NIDM OWL f
+0000f810: 696c 6573 2e22 290a 2020 2020 2020 2020  iles.").        
+0000f820: 2020 2020 6e69 646d 5f6f 776c 5f67 7261      nidm_owl_gra
+0000f830: 7068 203d 204e 6f6e 650a 2020 2020 2320  ph = None.    # 
+0000f840: 656c 7365 206c 6f61 6420 7573 6572 2d73  else load user-s
+0000f850: 7570 706c 6965 6420 6f77 6c20 6669 6c65  upplied owl file
+0000f860: 0a20 2020 2065 6c69 6620 6f77 6c5f 6669  .    elif owl_fi
+0000f870: 6c65 2069 7320 6e6f 7420 4e6f 6e65 3a0a  le is not None:.
+0000f880: 2020 2020 2020 2020 6e69 646d 5f6f 776c          nidm_owl
+0000f890: 5f67 7261 7068 203d 2047 7261 7068 2829  _graph = Graph()
+0000f8a0: 0a20 2020 2020 2020 206e 6964 6d5f 6f77  .        nidm_ow
+0000f8b0: 6c5f 6772 6170 682e 7061 7273 6528 6c6f  l_graph.parse(lo
+0000f8c0: 6361 7469 6f6e 3d6f 776c 5f66 696c 6529  cation=owl_file)
+0000f8d0: 0a20 2020 2065 6c73 653a 0a20 2020 2020  .    else:.     
+0000f8e0: 2020 206e 6964 6d5f 6f77 6c5f 6772 6170     nidm_owl_grap
+0000f8f0: 6820 3d20 4e6f 6e65 0a0a 2020 2020 2320  h = None..    # 
+0000f900: 6974 6572 6174 6520 6f76 6572 2063 6f6c  iterate over col
+0000f910: 756d 6e73 0a20 2020 2066 6f72 2063 6f6c  umns.    for col
+0000f920: 756d 6e20 696e 2064 662e 636f 6c75 6d6e  umn in df.column
+0000f930: 733a 0a20 2020 2020 2020 2023 2073 6574  s:.        # set
+0000f940: 2075 7020 6120 6469 6374 696f 6e61 7279   up a dictionary
+0000f950: 2065 6e74 7279 2066 6f72 2074 6869 7320   entry for this 
+0000f960: 636f 6c75 6d6e 0a20 2020 2020 2020 2063  column.        c
+0000f970: 7572 7265 6e74 5f74 7570 6c65 203d 2073  urrent_tuple = s
+0000f980: 7472 2844 4428 736f 7572 6365 3d61 7373  tr(DD(source=ass
+0000f990: 6573 736d 656e 745f 6e61 6d65 2c20 7661  essment_name, va
+0000f9a0: 7269 6162 6c65 3d63 6f6c 756d 6e29 290a  riable=column)).
+0000f9b0: 0a20 2020 2020 2020 2023 2069 6620 7765  .        # if we
+0000f9c0: 206c 6f61 6465 6420 6120 6a73 6f6e 2066   loaded a json f
+0000f9d0: 696c 6520 7769 7468 2065 7869 7374 696e  ile with existin
+0000f9e0: 6720 6d61 7070 696e 6773 0a20 2020 2020  g mappings.     
+0000f9f0: 2020 2069 6620 6a73 6f6e 5f73 6f75 7263     if json_sourc
+0000fa00: 6520 6973 206e 6f74 204e 6f6e 653a 0a20  e is not None:. 
+0000fa10: 2020 2020 2020 2020 2020 2023 2074 7279             # try
+0000fa20: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
+0000fa30: 6368 6563 6b20 666f 7220 636f 6c75 6d6e  check for column
+0000fa40: 2069 6e20 6a73 6f6e 2066 696c 650a 2020   in json file.  
+0000fa50: 2020 2020 2020 2020 2020 7472 793a 0a20            try:. 
+0000fa60: 2020 2020 2020 2020 2020 2020 2020 206a                 j
+0000fa70: 736f 6e5f 6b65 7920 3d20 5b0a 2020 2020  son_key = [.    
 0000fa80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fa90: 276c 6576 656c 7327 5d0a 2020 2020 2020  'levels'].      
-0000faa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fab0: 2020 7072 696e 7428 2263 686f 6963 6573    print("choices
-0000fac0: 3a20 2573 2220 2520 636f 6c75 6d6e 5f74  : %s" % column_t
-0000fad0: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
-0000fae0: 7475 706c 655d 5b27 7265 7370 6f6e 7365  tuple]['response
-0000faf0: 4f70 7469 6f6e 7327 5d5b 2763 686f 6963  Options']['choic
-0000fb00: 6573 275d 290a 2020 2020 2020 2020 2020  es']).          
-0000fb10: 2020 2020 2020 2020 2020 656c 6966 2027            elif '
-0000fb20: 4c65 7665 6c73 2720 696e 206a 736f 6e5f  Levels' in json_
-0000fb30: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
-0000fb40: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000fb50: 2020 2020 2020 2020 2020 2320 7570 6772            # upgr
-0000fb60: 6164 6520 276c 6576 656c 7327 2074 6f20  ade 'levels' to 
-0000fb70: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
-0000fb80: 272d 3e27 6368 6f69 6365 7327 0a20 2020  '->'choices'.   
-0000fb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fba0: 2020 2020 2069 6620 2772 6573 706f 6e73       if 'respons
-0000fbb0: 654f 7074 696f 6e73 2720 6e6f 7420 696e  eOptions' not in
-0000fbc0: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
-0000fbd0: 5b63 7572 7265 6e74 5f74 7570 6c65 5d2e  [current_tuple].
-0000fbe0: 6b65 7973 2829 3a0a 2020 2020 2020 2020  keys():.        
-0000fbf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fc00: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
-0000fc10: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
-0000fc20: 655d 5b27 7265 7370 6f6e 7365 4f70 7469  e]['responseOpti
-0000fc30: 6f6e 7327 5d20 3d20 7b7d 0a20 2020 2020  ons'] = {}.     
-0000fc40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fc50: 2020 2063 6f6c 756d 6e5f 746f 5f74 6572     column_to_ter
-0000fc60: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
-0000fc70: 5d5b 2772 6573 706f 6e73 654f 7074 696f  ]['responseOptio
-0000fc80: 6e73 275d 5b27 6368 6f69 6365 7327 5d20  ns']['choices'] 
-0000fc90: 3d20 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f  = json_map[json_
-0000fca0: 6b65 795b 305d 5d5b 0a20 2020 2020 2020  key[0]][.       
-0000fcb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fcc0: 2020 2020 2027 4c65 7665 6c73 275d 0a20       'Levels']. 
-0000fcd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fce0: 2020 2020 2020 2070 7269 6e74 2822 6c65         print("le
-0000fcf0: 7665 6c73 3a20 2573 2220 2520 636f 6c75  vels: %s" % colu
-0000fd00: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
-0000fd10: 656e 745f 7475 706c 655d 5b27 7265 7370  ent_tuple]['resp
-0000fd20: 6f6e 7365 4f70 7469 6f6e 7327 5d5b 2763  onseOptions']['c
-0000fd30: 686f 6963 6573 275d 290a 0a20 2020 2020  hoices'])..     
-0000fd40: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0000fd50: 6620 2776 616c 7565 5479 7065 2720 696e  f 'valueType' in
-0000fd60: 206a 736f 6e5f 6d61 705b 6a73 6f6e 5f6b   json_map[json_k
-0000fd70: 6579 5b30 5d5d 3a0a 2020 2020 2020 2020  ey[0]]:.        
+0000fa90: 6b65 790a 2020 2020 2020 2020 2020 2020  key.            
+0000faa0: 2020 2020 2020 2020 666f 7220 6b65 7920          for key 
+0000fab0: 696e 206a 736f 6e5f 6d61 700a 2020 2020  in json_map.    
+0000fac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fad0: 6966 2063 6f6c 756d 6e2e 6c73 7472 6970  if column.lstrip
+0000fae0: 2829 2e72 7374 7269 7028 290a 2020 2020  ().rstrip().    
+0000faf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fb00: 3d3d 206b 6579 2e73 706c 6974 2822 7661  == key.split("va
+0000fb10: 7269 6162 6c65 2229 5b31 5d0a 2020 2020  riable")[1].    
+0000fb20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fb30: 2e73 706c 6974 2822 3d22 295b 315d 0a20  .split("=")[1]. 
+0000fb40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fb50: 2020 202e 7370 6c69 7428 2229 2229 5b30     .split(")")[0
+0000fb60: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+0000fb70: 2020 2020 2020 2e6c 7374 7269 7028 2227        .lstrip("'
+0000fb80: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
+0000fb90: 2020 2020 2020 202e 7273 7472 6970 2822         .rstrip("
+0000fba0: 2722 290a 2020 2020 2020 2020 2020 2020  '").            
+0000fbb0: 2020 2020 5d0a 2020 2020 2020 2020 2020      ].          
+0000fbc0: 2020 6578 6365 7074 2049 6e64 6578 4572    except IndexEr
+0000fbd0: 726f 723a 0a20 2020 2020 2020 2020 2020  ror:.           
+0000fbe0: 2020 2020 206a 736f 6e5f 6b65 7920 3d20       json_key = 
+0000fbf0: 5b6b 6579 2066 6f72 206b 6579 2069 6e20  [key for key in 
+0000fc00: 6a73 6f6e 5f6d 6170 2069 6620 636f 6c75  json_map if colu
+0000fc10: 6d6e 2e6c 7374 7269 7028 292e 7273 7472  mn.lstrip().rstr
+0000fc20: 6970 2829 203d 3d20 6b65 795d 0a0a 2020  ip() == key]..  
+0000fc30: 2020 2020 2020 2020 2020 6966 206a 736f            if jso
+0000fc40: 6e5f 6d61 7020 6973 206e 6f74 204e 6f6e  n_map is not Non
+0000fc50: 6520 616e 6420 6c65 6e28 6a73 6f6e 5f6b  e and len(json_k
+0000fc60: 6579 2920 3e20 303a 0a20 2020 2020 2020  ey) > 0:.       
+0000fc70: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
+0000fc80: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+0000fc90: 5f74 7570 6c65 5d20 3d20 7b7d 0a0a 2020  _tuple] = {}..  
+0000fca0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+0000fcb0: 6164 6465 6420 696e 2063 6173 6520 666f  added in case fo
+0000fcc0: 7220 736f 6d65 2072 6561 736f 6e20 7468  r some reason th
+0000fcd0: 6572 6520 6973 6e27 7420 6120 6c61 6265  ere isn't a labe
+0000fce0: 6c20 6b65 792c 2074 7279 2073 6f75 7263  l key, try sourc
+0000fcf0: 655f 7661 7269 6162 6c65 2061 6e64 2069  e_variable and i
+0000fd00: 6620 6974 2773 0a20 2020 2020 2020 2020  f it's.         
+0000fd10: 2020 2020 2020 2023 2061 206b 6579 2074         # a key t
+0000fd20: 6865 6e20 6164 6420 7468 6973 2061 7320  hen add this as 
+0000fd30: 7468 6520 6c61 6265 6c20 6173 2077 656c  the label as wel
+0000fd40: 6c2e 0a20 2020 2020 2020 2020 2020 2020  l..             
+0000fd50: 2020 2069 6620 226c 6162 656c 2220 6e6f     if "label" no
+0000fd60: 7420 696e 206a 736f 6e5f 6d61 705b 6a73  t in json_map[js
+0000fd70: 6f6e 5f6b 6579 5b30 5d5d 3a0a 2020 2020  on_key[0]]:.    
 0000fd80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fd90: 2320 7570 6772 6164 6520 2776 616c 7565  # upgrade 'value
-0000fda0: 5479 7065 2720 746f 2027 7265 7370 6f6e  Type' to 'respon
-0000fdb0: 7365 4f70 7469 6f6e 7327 2d3e 2776 616c  seOptions'->'val
-0000fdc0: 7565 5479 7065 0a20 2020 2020 2020 2020  ueType.         
-0000fdd0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0000fde0: 6620 2772 6573 706f 6e73 654f 7074 696f  f 'responseOptio
-0000fdf0: 6e73 2720 6e6f 7420 696e 2063 6f6c 756d  ns' not in colum
-0000fe00: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
-0000fe10: 6e74 5f74 7570 6c65 5d2e 6b65 7973 2829  nt_tuple].keys()
-0000fe20: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000fe30: 2020 2020 2020 2020 2020 2020 2020 636f                co
-0000fe40: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
-0000fe50: 7272 656e 745f 7475 706c 655d 5b27 7265  rrent_tuple]['re
-0000fe60: 7370 6f6e 7365 4f70 7469 6f6e 7327 5d20  sponseOptions'] 
-0000fe70: 3d20 7b7d 0a20 2020 2020 2020 2020 2020  = {}.           
-0000fe80: 2020 2020 2020 2020 2020 2020 2063 6f6c               col
-0000fe90: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
-0000fea0: 7265 6e74 5f74 7570 6c65 5d5b 2772 6573  rent_tuple]['res
-0000feb0: 706f 6e73 654f 7074 696f 6e73 275d 5b27  ponseOptions']['
-0000fec0: 7661 6c75 6554 7970 6527 5d20 3d20 5c0a  valueType'] = \.
-0000fed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fee0: 2020 2020 2020 2020 2020 2020 6a73 6f6e              json
-0000fef0: 5f6d 6170 5b6a 736f 6e5f 6b65 795b 305d  _map[json_key[0]
-0000ff00: 5d5b 2776 616c 7565 5479 7065 275d 0a20  ]['valueType']. 
+0000fd90: 6966 2022 736f 7572 6365 5f76 6172 6961  if "source_varia
+0000fda0: 626c 6522 2069 6e20 6a73 6f6e 5f6d 6170  ble" in json_map
+0000fdb0: 5b6a 736f 6e5f 6b65 795b 305d 5d3a 0a20  [json_key[0]]:. 
+0000fdc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fdd0: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
+0000fde0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
+0000fdf0: 7570 6c65 5d5b 226c 6162 656c 225d 203d  uple]["label"] =
+0000fe00: 206a 736f 6e5f 6d61 705b 6a73 6f6e 5f6b   json_map[json_k
+0000fe10: 6579 5b30 5d5d 5b0a 2020 2020 2020 2020  ey[0]][.        
+0000fe20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fe30: 2020 2020 2273 6f75 7263 655f 7661 7269      "source_vari
+0000fe40: 6162 6c65 220a 2020 2020 2020 2020 2020  able".          
+0000fe50: 2020 2020 2020 2020 2020 2020 2020 5d0a                ].
+0000fe60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fe70: 2020 2020 656c 6966 2022 736f 7572 6365      elif "source
+0000fe80: 5661 7269 6162 6c65 2220 696e 206a 736f  Variable" in jso
+0000fe90: 6e5f 6d61 705b 6a73 6f6e 5f6b 6579 5b30  n_map[json_key[0
+0000fea0: 5d5d 2e6b 6579 7328 293a 0a20 2020 2020  ]].keys():.     
+0000feb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fec0: 2020 2063 6f6c 756d 6e5f 746f 5f74 6572     column_to_ter
+0000fed0: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
+0000fee0: 5d5b 226c 6162 656c 225d 203d 206a 736f  ]["label"] = jso
+0000fef0: 6e5f 6d61 705b 6a73 6f6e 5f6b 6579 5b30  n_map[json_key[0
+0000ff00: 5d5d 5b0a 2020 2020 2020 2020 2020 2020  ]][.            
 0000ff10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ff20: 2020 2020 2020 2070 7269 6e74 2822 7661         print("va
-0000ff30: 6c75 6554 7970 653a 2025 7322 2025 2063  lueType: %s" % c
-0000ff40: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
-0000ff50: 7572 7265 6e74 5f74 7570 6c65 5d5b 2772  urrent_tuple]['r
-0000ff60: 6573 706f 6e73 654f 7074 696f 6e73 275d  esponseOptions']
-0000ff70: 5b27 7661 6c75 6554 7970 6527 5d29 0a0a  ['valueType'])..
-0000ff80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ff90: 2020 2020 6966 2028 276d 696e 5661 6c75      if ('minValu
-0000ffa0: 6527 2069 6e20 6a73 6f6e 5f6d 6170 5b6a  e' in json_map[j
-0000ffb0: 736f 6e5f 6b65 795b 305d 5d29 3a0a 2020  son_key[0]]):.  
-0000ffc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ffd0: 2020 2020 2020 2320 7570 6772 6164 6520        # upgrade 
-0000ffe0: 276d 696e 5661 6c75 6527 2074 6f20 2772  'minValue' to 'r
-0000fff0: 6573 706f 6e73 654f 7074 696f 6e73 272d  esponseOptions'-
-00010000: 3e27 6d69 6e56 616c 7565 0a20 2020 2020  >'minValue.     
-00010010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010020: 2020 2069 6620 2772 6573 706f 6e73 654f     if 'responseO
-00010030: 7074 696f 6e73 2720 6e6f 7420 696e 2063  ptions' not in c
-00010040: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
-00010050: 7572 7265 6e74 5f74 7570 6c65 5d2e 6b65  urrent_tuple].ke
-00010060: 7973 2829 3a0a 2020 2020 2020 2020 2020  ys():.          
-00010070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010080: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
-00010090: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-000100a0: 5b27 7265 7370 6f6e 7365 4f70 7469 6f6e  ['responseOption
-000100b0: 7327 5d20 3d20 7b7d 0a20 2020 2020 2020  s'] = {}.       
-000100c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000100d0: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
-000100e0: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
-000100f0: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
-00010100: 275d 5b27 6d69 6e56 616c 7565 275d 203d  ']['minValue'] =
-00010110: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00010120: 2020 2020 2020 2020 2020 2020 2020 206a                 j
-00010130: 736f 6e5f 6d61 705b 6a73 6f6e 5f6b 6579  son_map[json_key
-00010140: 5b30 5d5d 5b27 6d69 6e56 616c 7565 275d  [0]]['minValue']
-00010150: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00010160: 2020 2020 2020 2020 2070 7269 6e74 2822           print("
-00010170: 6d69 6e56 616c 7565 3a20 2573 2220 2520  minValue: %s" % 
-00010180: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
-00010190: 6375 7272 656e 745f 7475 706c 655d 5b27  current_tuple]['
-000101a0: 7265 7370 6f6e 7365 4f70 7469 6f6e 7327  responseOptions'
-000101b0: 5d5b 276d 696e 5661 6c75 6527 5d29 0a20  ]['minValue']). 
-000101c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000101d0: 2020 2065 6c69 6620 2827 6d69 6e69 6d75     elif ('minimu
-000101e0: 6d56 616c 7565 2720 696e 206a 736f 6e5f  mValue' in json_
-000101f0: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
-00010200: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00010210: 2020 2020 2020 2020 2020 2023 2075 7067             # upg
-00010220: 7261 6465 2027 6d69 6e56 616c 7565 2720  rade 'minValue' 
-00010230: 746f 2027 7265 7370 6f6e 7365 4f70 7469  to 'responseOpti
-00010240: 6f6e 7327 2d3e 276d 696e 5661 6c75 650a  ons'->'minValue.
-00010250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010260: 2020 2020 2020 2020 6966 2027 7265 7370          if 'resp
-00010270: 6f6e 7365 4f70 7469 6f6e 7327 206e 6f74  onseOptions' not
-00010280: 2069 6e20 636f 6c75 6d6e 5f74 6f5f 7465   in column_to_te
-00010290: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
-000102a0: 655d 2e6b 6579 7328 293a 0a20 2020 2020  e].keys():.     
+0000ff20: 2273 6f75 7263 6556 6172 6961 626c 6522  "sourceVariable"
+0000ff30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ff40: 2020 2020 2020 2020 205d 0a20 2020 2020           ].     
+0000ff50: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+0000ff60: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+0000ff70: 2020 2020 2020 2020 2020 2020 2063 6f6c               col
+0000ff80: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
+0000ff90: 7265 6e74 5f74 7570 6c65 5d5b 226c 6162  rent_tuple]["lab
+0000ffa0: 656c 225d 203d 2022 220a 2020 2020 2020  el"] = "".      
+0000ffb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ffc0: 2020 7072 696e 7428 0a20 2020 2020 2020    print(.       
+0000ffd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ffe0: 2020 2020 2022 4e6f 206c 6162 656c 206f       "No label o
+0000fff0: 7220 736f 7572 6365 5f76 6172 6961 626c  r source_variabl
+00010000: 6520 6f72 2073 6f75 7263 6556 6172 6961  e or sourceVaria
+00010010: 626c 6520 6b65 7973 2066 6f75 6e64 2069  ble keys found i
+00010020: 6e20 6a73 6f6e 206d 6170 7069 6e67 2066  n json mapping f
+00010030: 696c 6520 666f 7220 7661 7269 6162 6c65  ile for variable
+00010040: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
+00010050: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00010060: 227b 6a73 6f6e 5f6b 6579 5b30 5d7d 2e20  "{json_key[0]}. 
+00010070: 436f 6e73 6964 6572 2061 6464 696e 6720  Consider adding 
+00010080: 7468 6573 6520 746f 2074 6865 206a 736f  these to the jso
+00010090: 6e20 6669 6c65 2061 7320 7468 6579 2061  n file as they a
+000100a0: 7265 2069 6d70 6f72 7461 6e74 220a 2020  re important".  
+000100b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000100c0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+000100d0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+000100e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000100f0: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
+00010100: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+00010110: 5b22 6c61 6265 6c22 5d20 3d20 6a73 6f6e  ["label"] = json
+00010120: 5f6d 6170 5b6a 736f 6e5f 6b65 795b 305d  _map[json_key[0]
+00010130: 5d5b 0a20 2020 2020 2020 2020 2020 2020  ][.             
+00010140: 2020 2020 2020 2020 2020 2022 6c61 6265             "labe
+00010150: 6c22 0a20 2020 2020 2020 2020 2020 2020  l".             
+00010160: 2020 2020 2020 205d 0a20 2020 2020 2020         ].       
+00010170: 2020 2020 2020 2020 2023 2061 6464 6564           # added
+00010180: 2074 6869 7320 6269 7420 746f 2061 6363   this bit to acc
+00010190: 6f75 6e74 2066 6f72 2042 4944 5320 6a73  ount for BIDS js
+000101a0: 6f6e 2066 696c 6573 2075 7369 6e67 2022  on files using "
+000101b0: 4465 7363 7269 7074 696f 6e22 2077 6865  Description" whe
+000101c0: 7265 6173 2077 6520 7573 6520 2264 6573  reas we use "des
+000101d0: 6372 6970 7469 6f6e 220a 2020 2020 2020  cription".      
+000101e0: 2020 2020 2020 2020 2020 2320 6576 6572            # ever
+000101f0: 7977 6865 7265 2065 6c73 650a 2020 2020  ywhere else.    
+00010200: 2020 2020 2020 2020 2020 2020 6966 2022              if "
+00010210: 6465 7363 7269 7074 696f 6e22 2069 6e20  description" in 
+00010220: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
+00010230: 795b 305d 5d2e 6b65 7973 2829 3a0a 2020  y[0]].keys():.  
+00010240: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010250: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
+00010260: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+00010270: 5b22 6465 7363 7269 7074 696f 6e22 5d20  ["description"] 
+00010280: 3d20 6a73 6f6e 5f6d 6170 5b0a 2020 2020  = json_map[.    
+00010290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000102a0: 2020 2020 6a73 6f6e 5f6b 6579 5b30 5d0a      json_key[0].
 000102b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000102c0: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
-000102d0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-000102e0: 7570 6c65 5d5b 2772 6573 706f 6e73 654f  uple]['responseO
-000102f0: 7074 696f 6e73 275d 203d 207b 7d0a 2020  ptions'] = {}.  
-00010300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010310: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
-00010320: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
-00010330: 706c 655d 5b27 7265 7370 6f6e 7365 4f70  ple]['responseOp
-00010340: 7469 6f6e 7327 5d5b 276d 696e 5661 6c75  tions']['minValu
-00010350: 6527 5d20 3d20 5c0a 2020 2020 2020 2020  e'] = \.        
-00010360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010370: 2020 2020 6a73 6f6e 5f6d 6170 5b6a 736f      json_map[jso
-00010380: 6e5f 6b65 795b 305d 5d5b 276d 696e 696d  n_key[0]]['minim
-00010390: 756d 5661 6c75 6527 5d0a 2020 2020 2020  umValue'].      
-000103a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000103b0: 2020 7072 696e 7428 226d 696e 5661 6c75    print("minValu
-000103c0: 653a 2025 7322 2025 2063 6f6c 756d 6e5f  e: %s" % column_
-000103d0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-000103e0: 5f74 7570 6c65 5d5b 2772 6573 706f 6e73  _tuple]['respons
-000103f0: 654f 7074 696f 6e73 275d 5b27 6d69 6e56  eOptions']['minV
-00010400: 616c 7565 275d 290a 0a20 2020 2020 2020  alue'])..       
-00010410: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00010420: 276d 6178 5661 6c75 6527 2069 6e20 6a73  'maxValue' in js
-00010430: 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65 795b  on_map[json_key[
-00010440: 305d 5d3a 0a20 2020 2020 2020 2020 2020  0]]:.           
-00010450: 2020 2020 2020 2020 2020 2020 2023 2075               # u
-00010460: 7067 7261 6465 2027 6d61 7856 616c 7565  pgrade 'maxValue
-00010470: 2720 746f 2027 7265 7370 6f6e 7365 4f70  ' to 'responseOp
-00010480: 7469 6f6e 7327 2d3e 276d 6178 5661 6c75  tions'->'maxValu
-00010490: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
-000104a0: 2020 2020 2020 2020 2020 6966 2027 7265            if 're
-000104b0: 7370 6f6e 7365 4f70 7469 6f6e 7327 206e  sponseOptions' n
-000104c0: 6f74 2069 6e20 636f 6c75 6d6e 5f74 6f5f  ot in column_to_
-000104d0: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
-000104e0: 706c 655d 2e6b 6579 7328 293a 0a20 2020  ple].keys():.   
-000104f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010500: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
-00010510: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-00010520: 5f74 7570 6c65 5d5b 2772 6573 706f 6e73  _tuple]['respons
-00010530: 654f 7074 696f 6e73 275d 203d 207b 7d0a  eOptions'] = {}.
-00010540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010550: 2020 2020 2020 2020 636f 6c75 6d6e 5f74          column_t
-00010560: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
-00010570: 7475 706c 655d 5b27 7265 7370 6f6e 7365  tuple]['response
-00010580: 4f70 7469 6f6e 7327 5d5b 276d 6178 5661  Options']['maxVa
-00010590: 6c75 6527 5d20 3d20 5c0a 2020 2020 2020  lue'] = \.      
-000105a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000105b0: 2020 2020 2020 6a73 6f6e 5f6d 6170 5b6a        json_map[j
-000105c0: 736f 6e5f 6b65 795b 305d 5d5b 276d 6178  son_key[0]]['max
-000105d0: 5661 6c75 6527 5d0a 2020 2020 2020 2020  Value'].        
-000105e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000105f0: 7072 696e 7428 226d 6178 5661 6c75 653a  print("maxValue:
-00010600: 2025 7322 2025 2063 6f6c 756d 6e5f 746f   %s" % column_to
-00010610: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-00010620: 7570 6c65 5d5b 2772 6573 706f 6e73 654f  uple]['responseO
-00010630: 7074 696f 6e73 275d 5b27 6d61 7856 616c  ptions']['maxVal
-00010640: 7565 275d 290a 2020 2020 2020 2020 2020  ue']).          
-00010650: 2020 2020 2020 2020 2020 656c 6966 2027            elif '
-00010660: 6d61 7869 6d75 6d56 616c 7565 2720 696e  maximumValue' in
-00010670: 206a 736f 6e5f 6d61 705b 6a73 6f6e 5f6b   json_map[json_k
-00010680: 6579 5b30 5d5d 3a0a 2020 2020 2020 2020  ey[0]]:.        
+000102c0: 2020 2020 5d5b 2264 6573 6372 6970 7469      ]["descripti
+000102d0: 6f6e 225d 0a20 2020 2020 2020 2020 2020  on"].           
+000102e0: 2020 2020 2065 6c69 6620 2244 6573 6372       elif "Descr
+000102f0: 6970 7469 6f6e 2220 696e 206a 736f 6e5f  iption" in json_
+00010300: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
+00010310: 2e6b 6579 7328 293a 0a20 2020 2020 2020  .keys():.       
+00010320: 2020 2020 2020 2020 2020 2020 2063 6f6c               col
+00010330: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
+00010340: 7265 6e74 5f74 7570 6c65 5d5b 2264 6573  rent_tuple]["des
+00010350: 6372 6970 7469 6f6e 225d 203d 206a 736f  cription"] = jso
+00010360: 6e5f 6d61 705b 0a20 2020 2020 2020 2020  n_map[.         
+00010370: 2020 2020 2020 2020 2020 2020 2020 206a                 j
+00010380: 736f 6e5f 6b65 795b 305d 0a20 2020 2020  son_key[0].     
+00010390: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
+000103a0: 5b22 4465 7363 7269 7074 696f 6e22 5d0a  ["Description"].
+000103b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000103c0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+000103d0: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
+000103e0: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
+000103f0: 745f 7475 706c 655d 5b22 6465 7363 7269  t_tuple]["descri
+00010400: 7074 696f 6e22 5d20 3d20 2222 0a20 2020  ption"] = "".   
+00010410: 2020 2020 2020 2020 2020 2020 2023 2063               # c
+00010420: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
+00010430: 7572 7265 6e74 5f74 7570 6c65 5d5b 2776  urrent_tuple]['v
+00010440: 6172 6961 626c 6527 5d20 3d20 6a73 6f6e  ariable'] = json
+00010450: 5f6d 6170 5b6a 736f 6e5f 6b65 795b 305d  _map[json_key[0]
+00010460: 5d5b 2776 6172 6961 626c 6527 5d0a 0a20  ]['variable'].. 
+00010470: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00010480: 7269 6e74 2822 5c6e 2220 2b20 2822 2a22  rint("\n" + ("*"
+00010490: 202a 2038 3529 290a 2020 2020 2020 2020   * 85)).        
+000104a0: 2020 2020 2020 2020 7072 696e 7428 0a20          print(. 
+000104b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000104c0: 2020 2066 2243 6f6c 756d 6e20 7b63 6f6c     f"Column {col
+000104d0: 756d 6e7d 2061 6c72 6561 6479 2061 6e6e  umn} already ann
+000104e0: 6f74 6174 6564 2069 6e20 7573 6572 2073  otated in user s
+000104f0: 7570 706c 6965 6420 4a53 4f4e 206d 6170  upplied JSON map
+00010500: 7069 6e67 2066 696c 6522 0a20 2020 2020  ping file".     
+00010510: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+00010520: 2020 2020 2020 2020 2020 2020 2070 7269               pri
+00010530: 6e74 2822 6c61 6265 6c3a 222c 2063 6f6c  nt("label:", col
+00010540: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
+00010550: 7265 6e74 5f74 7570 6c65 5d5b 226c 6162  rent_tuple]["lab
+00010560: 656c 225d 290a 2020 2020 2020 2020 2020  el"]).          
+00010570: 2020 2020 2020 7072 696e 7428 2264 6573        print("des
+00010580: 6372 6970 7469 6f6e 3a22 2c20 636f 6c75  cription:", colu
+00010590: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+000105a0: 656e 745f 7475 706c 655d 5b22 6465 7363  ent_tuple]["desc
+000105b0: 7269 7074 696f 6e22 5d29 0a20 2020 2020  ription"]).     
+000105c0: 2020 2020 2020 2020 2020 2069 6620 2275             if "u
+000105d0: 726c 2220 696e 206a 736f 6e5f 6d61 705b  rl" in json_map[
+000105e0: 6a73 6f6e 5f6b 6579 5b30 5d5d 3a0a 2020  json_key[0]]:.  
+000105f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010600: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
+00010610: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+00010620: 5b22 7572 6c22 5d20 3d20 6a73 6f6e 5f6d  ["url"] = json_m
+00010630: 6170 5b6a 736f 6e5f 6b65 795b 305d 5d5b  ap[json_key[0]][
+00010640: 2275 726c 225d 0a20 2020 2020 2020 2020  "url"].         
+00010650: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+00010660: 2822 7572 6c3a 222c 2063 6f6c 756d 6e5f  ("url:", column_
+00010670: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+00010680: 5f74 7570 6c65 5d5b 2275 726c 225d 290a  _tuple]["url"]).
 00010690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000106a0: 2320 7570 6772 6164 6520 276d 6178 5661  # upgrade 'maxVa
-000106b0: 6c75 6527 2074 6f20 2772 6573 706f 6e73  lue' to 'respons
-000106c0: 654f 7074 696f 6e73 272d 3e27 6d61 7856  eOptions'->'maxV
-000106d0: 616c 7565 0a20 2020 2020 2020 2020 2020  alue.           
-000106e0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-000106f0: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
-00010700: 2720 6e6f 7420 696e 2063 6f6c 756d 6e5f  ' not in column_
-00010710: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-00010720: 5f74 7570 6c65 5d2e 6b65 7973 2829 3a0a  _tuple].keys():.
-00010730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010740: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
-00010750: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
-00010760: 656e 745f 7475 706c 655d 5b27 7265 7370  ent_tuple]['resp
-00010770: 6f6e 7365 4f70 7469 6f6e 7327 5d20 3d20  onseOptions'] = 
-00010780: 7b7d 0a20 2020 2020 2020 2020 2020 2020  {}.             
-00010790: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
-000107a0: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
-000107b0: 6e74 5f74 7570 6c65 5d5b 2772 6573 706f  nt_tuple]['respo
-000107c0: 6e73 654f 7074 696f 6e73 275d 5b27 6d61  nseOptions']['ma
-000107d0: 7856 616c 7565 275d 203d 205c 0a20 2020  xValue'] = \.   
-000107e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000107f0: 2020 2020 2020 2020 206a 736f 6e5f 6d61           json_ma
-00010800: 705b 6a73 6f6e 5f6b 6579 5b30 5d5d 5b27  p[json_key[0]]['
-00010810: 6d61 7869 6d75 6d56 616c 7565 275d 0a20  maximumValue']. 
-00010820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010830: 2020 2020 2020 2070 7269 6e74 2822 6d61         print("ma
-00010840: 7856 616c 7565 3a20 2573 2220 2520 636f  xValue: %s" % co
-00010850: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
-00010860: 7272 656e 745f 7475 706c 655d 5b27 7265  rrent_tuple]['re
-00010870: 7370 6f6e 7365 4f70 7469 6f6e 7327 5d5b  sponseOptions'][
-00010880: 276d 6178 5661 6c75 6527 5d29 0a20 2020  'maxValue']).   
-00010890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000108a0: 2069 6620 2768 6173 556e 6974 2720 696e   if 'hasUnit' in
-000108b0: 206a 736f 6e5f 6d61 705b 6a73 6f6e 5f6b   json_map[json_k
-000108c0: 6579 5b30 5d5d 3a0a 2020 2020 2020 2020  ey[0]]:.        
-000108d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000108e0: 2320 7570 6772 6164 6520 2768 6173 556e  # upgrade 'hasUn
-000108f0: 6974 2720 746f 2027 7265 7370 6f6e 7365  it' to 'response
-00010900: 4f70 7469 6f6e 7327 2d3e 2775 6e69 7443  Options'->'unitC
-00010910: 6f64 650a 2020 2020 2020 2020 2020 2020  ode.            
-00010920: 2020 2020 2020 2020 2020 2020 6966 2027              if '
-00010930: 7265 7370 6f6e 7365 4f70 7469 6f6e 7327  responseOptions'
-00010940: 206e 6f74 2069 6e20 636f 6c75 6d6e 5f74   not in column_t
-00010950: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
-00010960: 7475 706c 655d 2e6b 6579 7328 293a 0a20  tuple].keys():. 
-00010970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010980: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
-00010990: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
-000109a0: 6e74 5f74 7570 6c65 5d5b 2772 6573 706f  nt_tuple]['respo
-000109b0: 6e73 654f 7074 696f 6e73 275d 203d 207b  nseOptions'] = {
-000109c0: 7d0a 2020 2020 2020 2020 2020 2020 2020  }.              
-000109d0: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
-000109e0: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
-000109f0: 745f 7475 706c 655d 5b27 7265 7370 6f6e  t_tuple]['respon
-00010a00: 7365 4f70 7469 6f6e 7327 5d5b 2775 6e69  seOptions']['uni
-00010a10: 7443 6f64 6527 5d20 3d20 5c0a 2020 2020  tCode'] = \.    
-00010a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010a30: 2020 2020 2020 2020 6a73 6f6e 5f6d 6170          json_map
-00010a40: 5b6a 736f 6e5f 6b65 795b 305d 5d5b 2768  [json_key[0]]['h
-00010a50: 6173 556e 6974 275d 0a20 2020 2020 2020  asUnit'].       
-00010a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010a70: 2070 7269 6e74 2822 756e 6974 436f 6465   print("unitCode
-00010a80: 3a20 2573 2220 2520 636f 6c75 6d6e 5f74  : %s" % column_t
-00010a90: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
-00010aa0: 7475 706c 655d 5b27 7265 7370 6f6e 7365  tuple]['response
-00010ab0: 4f70 7469 6f6e 7327 5d5b 2775 6e69 7443  Options']['unitC
-00010ac0: 6f64 6527 5d29 0a20 2020 2020 2020 2020  ode']).         
-00010ad0: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
-00010ae0: 2755 6e69 7473 2720 696e 206a 736f 6e5f  'Units' in json_
-00010af0: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
-00010b00: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00010b10: 2020 2020 2020 2020 2020 2320 7570 6772            # upgr
-00010b20: 6164 6520 2755 6e69 7473 2720 746f 2027  ade 'Units' to '
-00010b30: 7265 7370 6f6e 7365 4f70 7469 6f6e 7327  responseOptions'
-00010b40: 2d3e 2775 6e69 7443 6f64 650a 2020 2020  ->'unitCode.    
+000106a0: 2320 7072 696e 7428 2256 6172 6961 626c  # print("Variabl
+000106b0: 653a 222c 2063 6f6c 756d 6e5f 746f 5f74  e:", column_to_t
+000106c0: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
+000106d0: 6c65 5d5b 2776 6172 6961 626c 6527 5d29  le]['variable'])
+000106e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000106f0: 2069 6620 2273 616d 6541 7322 2069 6e20   if "sameAs" in 
+00010700: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
+00010710: 795b 305d 5d3a 0a20 2020 2020 2020 2020  y[0]]:.         
+00010720: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
+00010730: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
+00010740: 6e74 5f74 7570 6c65 5d5b 2273 616d 6541  nt_tuple]["sameA
+00010750: 7322 5d20 3d20 6a73 6f6e 5f6d 6170 5b6a  s"] = json_map[j
+00010760: 736f 6e5f 6b65 795b 305d 5d5b 0a20 2020  son_key[0]][.   
+00010770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010780: 2020 2020 2022 7361 6d65 4173 220a 2020       "sameAs".  
+00010790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000107a0: 2020 5d0a 2020 2020 2020 2020 2020 2020    ].            
+000107b0: 2020 2020 2020 2020 7072 696e 7428 2273          print("s
+000107c0: 616d 6541 733a 222c 2063 6f6c 756d 6e5f  ameAs:", column_
+000107d0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+000107e0: 5f74 7570 6c65 5d5b 2273 616d 6541 7322  _tuple]["sameAs"
+000107f0: 5d29 0a20 2020 2020 2020 2020 2020 2020  ]).             
+00010800: 2020 2069 6620 2275 726c 2220 696e 206a     if "url" in j
+00010810: 736f 6e5f 6d61 705b 6a73 6f6e 5f6b 6579  son_map[json_key
+00010820: 5b30 5d5d 3a0a 2020 2020 2020 2020 2020  [0]]:.          
+00010830: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
+00010840: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
+00010850: 745f 7475 706c 655d 5b22 7572 6c22 5d20  t_tuple]["url"] 
+00010860: 3d20 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f  = json_map[json_
+00010870: 6b65 795b 305d 5d5b 2275 726c 225d 0a20  key[0]]["url"]. 
+00010880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010890: 2020 2070 7269 6e74 2822 7572 6c3a 222c     print("url:",
+000108a0: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+000108b0: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+000108c0: 2275 726c 225d 290a 0a20 2020 2020 2020  "url"])..       
+000108d0: 2020 2020 2020 2020 2069 6620 2273 6f75           if "sou
+000108e0: 7263 655f 7661 7269 6162 6c65 2220 696e  rce_variable" in
+000108f0: 206a 736f 6e5f 6d61 705b 6a73 6f6e 5f6b   json_map[json_k
+00010900: 6579 5b30 5d5d 3a0a 2020 2020 2020 2020  ey[0]]:.        
+00010910: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
+00010920: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+00010930: 656e 745f 7475 706c 655d 5b22 736f 7572  ent_tuple]["sour
+00010940: 6365 5f76 6172 6961 626c 6522 5d20 3d20  ce_variable"] = 
+00010950: 6a73 6f6e 5f6d 6170 5b0a 2020 2020 2020  json_map[.      
+00010960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010970: 2020 6a73 6f6e 5f6b 6579 5b30 5d0a 2020    json_key[0].  
+00010980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010990: 2020 5d5b 2273 6f75 7263 655f 7661 7269    ]["source_vari
+000109a0: 6162 6c65 225d 0a20 2020 2020 2020 2020  able"].         
+000109b0: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+000109c0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+000109d0: 2020 2020 2020 2020 2020 2273 6f75 7263            "sourc
+000109e0: 6520 7661 7269 6162 6c65 3a22 2c0a 2020  e variable:",.  
+000109f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010a00: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
+00010a10: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
+00010a20: 706c 655d 5b22 736f 7572 6365 5f76 6172  ple]["source_var
+00010a30: 6961 626c 6522 5d2c 0a20 2020 2020 2020  iable"],.       
+00010a40: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+00010a50: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+00010a60: 6c69 6620 2273 6f75 7263 6556 6172 6961  lif "sourceVaria
+00010a70: 626c 6522 2069 6e20 6a73 6f6e 5f6d 6170  ble" in json_map
+00010a80: 5b6a 736f 6e5f 6b65 795b 305d 5d3a 0a20  [json_key[0]]:. 
+00010a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010aa0: 2020 2063 6f6c 756d 6e5f 746f 5f74 6572     column_to_ter
+00010ab0: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
+00010ac0: 5d5b 2273 6f75 7263 655f 7661 7269 6162  ]["source_variab
+00010ad0: 6c65 225d 203d 206a 736f 6e5f 6d61 705b  le"] = json_map[
+00010ae0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00010af0: 2020 2020 2020 2020 206a 736f 6e5f 6b65           json_ke
+00010b00: 795b 305d 0a20 2020 2020 2020 2020 2020  y[0].           
+00010b10: 2020 2020 2020 2020 205d 5b22 736f 7572           ]["sour
+00010b20: 6365 5661 7269 6162 6c65 225d 0a20 2020  ceVariable"].   
+00010b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010b40: 2070 7269 6e74 280a 2020 2020 2020 2020   print(.        
 00010b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010b60: 2020 2020 6966 2027 7265 7370 6f6e 7365      if 'response
-00010b70: 4f70 7469 6f6e 7327 206e 6f74 2069 6e20  Options' not in 
-00010b80: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
-00010b90: 6375 7272 656e 745f 7475 706c 655d 2e6b  current_tuple].k
-00010ba0: 6579 7328 293a 0a20 2020 2020 2020 2020  eys():.         
-00010bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010bc0: 2020 2063 6f6c 756d 6e5f 746f 5f74 6572     column_to_ter
-00010bd0: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
-00010be0: 5d5b 2772 6573 706f 6e73 654f 7074 696f  ]['responseOptio
-00010bf0: 6e73 275d 203d 207b 7d0a 2020 2020 2020  ns'] = {}.      
-00010c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010c10: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
-00010c20: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-00010c30: 5b27 7265 7370 6f6e 7365 4f70 7469 6f6e  ['responseOption
-00010c40: 7327 5d5b 2775 6e69 7443 6f64 6527 5d20  s']['unitCode'] 
-00010c50: 3d20 5c0a 2020 2020 2020 2020 2020 2020  = \.            
-00010c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010c70: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
-00010c80: 795b 305d 5d5b 2755 6e69 7473 275d 0a20  y[0]]['Units']. 
-00010c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010ca0: 2020 2020 2020 2070 7269 6e74 2822 756e         print("un
-00010cb0: 6974 436f 6465 3a20 2573 2220 2520 636f  itCode: %s" % co
-00010cc0: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
-00010cd0: 7272 656e 745f 7475 706c 655d 5b27 7265  rrent_tuple]['re
-00010ce0: 7370 6f6e 7365 4f70 7469 6f6e 7327 5d5b  sponseOptions'][
-00010cf0: 2775 6e69 7443 6f64 6527 5d29 0a0a 2020  'unitCode'])..  
-00010d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010d10: 2020 6966 2022 6973 4162 6f75 7422 2069    if "isAbout" i
-00010d20: 6e20 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f  n json_map[json_
-00010d30: 6b65 795b 305d 5d3a 0a20 2020 2020 2020  key[0]]:.       
-00010d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010d50: 2023 6368 6563 6b20 6966 2077 6520 6861   #check if we ha
-00010d60: 7665 2061 2073 696e 676c 6520 6973 4162  ve a single isAb
-00010d70: 6f75 7420 6f72 206d 756c 7469 706c 652e  out or multiple.
-00010d80: 2e2e 0a20 2020 2020 2020 2020 2020 2020  ...             
-00010d90: 2020 2020 2020 2020 2020 2069 6620 6973             if is
-00010da0: 696e 7374 616e 6365 286a 736f 6e5f 6d61  instance(json_ma
-00010db0: 705b 6a73 6f6e 5f6b 6579 5b30 5d5d 5b27  p[json_key[0]]['
-00010dc0: 6973 4162 6f75 7427 5d2c 6c69 7374 293a  isAbout'],list):
-00010dd0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00010de0: 2020 2020 2020 2020 2020 2020 2023 2069               # i
-00010df0: 7341 626f 7574 2069 7320 616e 2065 6d70  sAbout is an emp
-00010e00: 7479 206c 6973 742c 2064 6f20 636f 6e63  ty list, do conc
-00010e10: 6570 7420 6173 736f 6369 6174 696f 6e20  ept association 
-00010e20: 6966 2075 7365 7220 6173 6b65 6420 666f  if user asked fo
-00010e30: 7220 6974 2065 6c73 6520 736b 6970 0a20  r it else skip. 
-00010e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010e50: 2020 2020 2020 2020 2020 2069 6620 6e6f             if no
-00010e60: 7420 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f  t json_map[json_
-00010e70: 6b65 795b 305d 5d5b 2769 7341 626f 7574  key[0]]['isAbout
-00010e80: 275d 3a0a 2020 2020 2020 2020 2020 2020  ']:.            
-00010e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010ea0: 2020 2020 6966 2061 7373 6f63 6961 7465      if associate
-00010eb0: 5f63 6f6e 6365 7074 733a 0a20 2020 2020  _concepts:.     
-00010ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010ed0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-00010ee0: 2070 726f 7669 6465 2075 7365 7220 7769   provide user wi
-00010ef0: 7468 206f 7070 6f72 7475 6e69 7479 2074  th opportunity t
-00010f00: 6f20 6173 736f 6369 6174 6520 6120 636f  o associate a co
-00010f10: 6e63 6570 7420 7769 7468 2074 6869 7320  ncept with this 
-00010f20: 616e 6e6f 7461 7469 6f6e 0a20 2020 2020  annotation.     
-00010f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010f40: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00010f50: 696e 645f 636f 6e63 6570 745f 696e 7465  ind_concept_inte
-00010f60: 7261 6374 6976 6528 636f 6c75 6d6e 2c20  ractive(column, 
-00010f70: 6375 7272 656e 745f 7475 706c 652c 2063  current_tuple, c
-00010f80: 6f6c 756d 6e5f 746f 5f74 6572 6d73 2c20  olumn_to_terms, 
-00010f90: 696c 785f 6f62 6a2c 0a20 2020 2020 2020  ilx_obj,.       
-00010fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010fc0: 2020 2020 206e 6964 6d5f 6f77 6c5f 6772       nidm_owl_gr
-00010fd0: 6170 683d 6e69 646d 5f6f 776c 5f67 7261  aph=nidm_owl_gra
-00010fe0: 7068 290a 2020 2020 2020 2020 2020 2020  ph).            
-00010ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011000: 2020 2020 2020 2020 2320 7772 6974 6520          # write 
-00011010: 616e 6e6f 7461 7469 6f6e 7320 746f 206a  annotations to j
-00011020: 736f 6e20 6669 6c65 2073 6f20 7573 6572  son file so user
-00011030: 2063 616e 2073 7461 7274 2075 7020 6167   can start up ag
-00011040: 6169 6e20 6966 206e 6f74 2064 6f69 6e67  ain if not doing
-00011050: 2077 686f 6c65 2066 696c 650a 2020 2020   whole file.    
-00011060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011080: 7772 6974 655f 6a73 6f6e 5f6d 6170 7069  write_json_mappi
-00011090: 6e67 5f66 696c 6528 636f 6c75 6d6e 5f74  ng_file(column_t
-000110a0: 6f5f 7465 726d 732c 206f 7574 7075 745f  o_terms, output_
-000110b0: 6669 6c65 2c20 6269 6473 290a 2020 2020  file, bids).    
-000110c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000110d0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-000110e0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00010b60: 2273 6f75 7263 6520 7661 7269 6162 6c65  "source variable
+00010b70: 3a22 2c0a 2020 2020 2020 2020 2020 2020  :",.            
+00010b80: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
+00010b90: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+00010ba0: 656e 745f 7475 706c 655d 5b22 736f 7572  ent_tuple]["sour
+00010bb0: 6365 5f76 6172 6961 626c 6522 5d2c 0a20  ce_variable"],. 
+00010bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010bd0: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+00010be0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00010bf0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+00010c00: 2061 6464 2073 6f75 7263 6520 7661 7269   add source vari
+00010c10: 6162 6c65 2069 6620 6e6f 7420 7468 6572  able if not ther
+00010c20: 652e 2e2e 0a20 2020 2020 2020 2020 2020  e....           
+00010c30: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
+00010c40: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+00010c50: 5f74 7570 6c65 5d5b 2273 6f75 7263 655f  _tuple]["source_
+00010c60: 7661 7269 6162 6c65 225d 203d 2073 7472  variable"] = str
+00010c70: 2863 6f6c 756d 6e29 0a20 2020 2020 2020  (column).       
+00010c80: 2020 2020 2020 2020 2020 2020 2070 7269               pri
+00010c90: 6e74 2866 2241 6464 6564 2073 6f75 7263  nt(f"Added sourc
+00010ca0: 6520 7661 7269 6162 6c65 2028 7b63 6f6c  e variable ({col
+00010cb0: 756d 6e7d 2920 746f 2061 6e6e 6f74 6174  umn}) to annotat
+00010cc0: 696f 6e73 2229 0a0a 2020 2020 2020 2020  ions")..        
+00010cd0: 2020 2020 2020 2020 6966 2022 6173 736f          if "asso
+00010ce0: 6369 6174 6564 5769 7468 2220 696e 206a  ciatedWith" in j
+00010cf0: 736f 6e5f 6d61 705b 6a73 6f6e 5f6b 6579  son_map[json_key
+00010d00: 5b30 5d5d 3a0a 2020 2020 2020 2020 2020  [0]]:.          
+00010d10: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
+00010d20: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
+00010d30: 745f 7475 706c 655d 5b22 6173 736f 6369  t_tuple]["associ
+00010d40: 6174 6564 5769 7468 225d 203d 206a 736f  atedWith"] = jso
+00010d50: 6e5f 6d61 705b 0a20 2020 2020 2020 2020  n_map[.         
+00010d60: 2020 2020 2020 2020 2020 2020 2020 206a                 j
+00010d70: 736f 6e5f 6b65 795b 305d 0a20 2020 2020  son_key[0].     
+00010d80: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
+00010d90: 5b22 6173 736f 6369 6174 6564 5769 7468  ["associatedWith
+00010da0: 225d 0a20 2020 2020 2020 2020 2020 2020  "].             
+00010db0: 2020 2020 2020 2070 7269 6e74 280a 2020         print(.  
+00010dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010dd0: 2020 2020 2020 2261 7373 6f63 6961 7465        "associate
+00010de0: 6457 6974 683a 222c 0a20 2020 2020 2020  dWith:",.       
+00010df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010e00: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+00010e10: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+00010e20: 2261 7373 6f63 6961 7465 6457 6974 6822  "associatedWith"
+00010e30: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00010e40: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00010e50: 2020 2020 2020 2020 2069 6620 2261 6c6c           if "all
+00010e60: 6f77 6162 6c65 5661 6c75 6573 2220 696e  owableValues" in
+00010e70: 206a 736f 6e5f 6d61 705b 6a73 6f6e 5f6b   json_map[json_k
+00010e80: 6579 5b30 5d5d 3a0a 2020 2020 2020 2020  ey[0]]:.        
+00010e90: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
+00010ea0: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+00010eb0: 656e 745f 7475 706c 655d 5b22 616c 6c6f  ent_tuple]["allo
+00010ec0: 7761 626c 6556 616c 7565 7322 5d20 3d20  wableValues"] = 
+00010ed0: 6a73 6f6e 5f6d 6170 5b0a 2020 2020 2020  json_map[.      
+00010ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010ef0: 2020 6a73 6f6e 5f6b 6579 5b30 5d0a 2020    json_key[0].  
+00010f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010f10: 2020 5d5b 2261 6c6c 6f77 6162 6c65 5661    ]["allowableVa
+00010f20: 6c75 6573 225d 0a20 2020 2020 2020 2020  lues"].         
+00010f30: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+00010f40: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00010f50: 2020 2020 2020 2020 2020 2261 6c6c 6f77            "allow
+00010f60: 6162 6c65 5661 6c75 6573 3a22 2c0a 2020  ableValues:",.  
+00010f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010f80: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
+00010f90: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
+00010fa0: 706c 655d 5b22 616c 6c6f 7761 626c 6556  ple]["allowableV
+00010fb0: 616c 7565 7322 5d2c 0a20 2020 2020 2020  alues"],.       
+00010fc0: 2020 2020 2020 2020 2020 2020 2029 0a0a               )..
+00010fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010fe0: 2320 6164 6465 6420 746f 2073 7570 706f  # added to suppo
+00010ff0: 7274 2052 6570 726f 5363 6865 6d61 206a  rt ReproSchema j
+00011000: 736f 6e20 666f 726d 6174 0a20 2020 2020  son format.     
+00011010: 2020 2020 2020 2020 2020 2069 6620 2272             if "r
+00011020: 6573 706f 6e73 654f 7074 696f 6e73 2220  esponseOptions" 
+00011030: 696e 206a 736f 6e5f 6d61 705b 6a73 6f6e  in json_map[json
+00011040: 5f6b 6579 5b30 5d5d 3a0a 2020 2020 2020  _key[0]]:.      
+00011050: 2020 2020 2020 2020 2020 2020 2020 666f                fo
+00011060: 7220 7375 626b 6579 2069 6e20 6a73 6f6e  r subkey in json
+00011070: 5f6d 6170 5b6a 736f 6e5f 6b65 795b 305d  _map[json_key[0]
+00011080: 5d5b 2272 6573 706f 6e73 654f 7074 696f  ]["responseOptio
+00011090: 6e73 225d 3a0a 2020 2020 2020 2020 2020  ns"]:.          
+000110a0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+000110b0: 2022 7661 6c75 6554 7970 6522 2069 6e20   "valueType" in 
+000110c0: 7375 626b 6579 3a0a 2020 2020 2020 2020  subkey:.        
+000110d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000110e0: 2020 2020 6966 2028 0a20 2020 2020 2020      if (.       
 000110f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011100: 2020 2020 2020 7061 7373 0a20 2020 2020        pass.     
-00011110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011120: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-00011130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011140: 2020 2020 2020 2020 2020 2020 2023 2065               # e
-00011150: 6c73 6520 6372 6561 7465 2061 206e 6577  lse create a new
-00011160: 206c 6973 740a 2020 2020 2020 2020 2020   list.          
+00011100: 2020 2020 2020 2020 2022 7265 7370 6f6e           "respon
+00011110: 7365 4f70 7469 6f6e 7322 0a20 2020 2020  seOptions".     
+00011120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011130: 2020 2020 2020 2020 2020 206e 6f74 2069             not i
+00011140: 6e20 636f 6c75 6d6e 5f74 6f5f 7465 726d  n column_to_term
+00011150: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+00011160: 2e6b 6579 7328 290a 2020 2020 2020 2020  .keys().        
 00011170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011180: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
-00011190: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
-000111a0: 706c 655d 5b27 6973 4162 6f75 7427 5d20  ple]['isAbout'] 
-000111b0: 3d20 5b5d 0a20 2020 2020 2020 2020 2020  = [].           
-000111c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000111d0: 2020 2020 2023 2066 6f72 2065 6163 6820       # for each 
-000111e0: 6973 4162 6f75 7420 656e 7472 790a 2020  isAbout entry.  
-000111f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011200: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-00011210: 7220 7375 6264 6963 7420 696e 206a 736f  r subdict in jso
-00011220: 6e5f 6d61 705b 6a73 6f6e 5f6b 6579 5b30  n_map[json_key[0
-00011230: 5d5d 5b27 6973 4162 6f75 7427 5d3a 0a20  ]]['isAbout']:. 
-00011240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011260: 2020 2023 2073 6f6d 6520 656e 7472 6965     # some entrie
-00011270: 7320 6d61 7920 6e6f 7420 6861 7665 2027  s may not have '
-00011280: 6c61 6265 6c27 2073 6f20 6368 6563 6b0a  label' so check.
-00011290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000112a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000112b0: 2020 2020 6966 2027 6c61 6265 6c27 2069      if 'label' i
-000112c0: 6e20 7375 6264 6963 742e 6b65 7973 2829  n subdict.keys()
-000112d0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00011180: 2020 2020 293a 0a20 2020 2020 2020 2020      ):.         
+00011190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000111a0: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
+000111b0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
+000111c0: 7570 6c65 5d5b 2272 6573 706f 6e73 654f  uple]["responseO
+000111d0: 7074 696f 6e73 225d 203d 207b 7d0a 0a20  ptions"] = {}.. 
+000111e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000111f0: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
+00011200: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
+00011210: 6e74 5f74 7570 6c65 5d5b 2272 6573 706f  nt_tuple]["respo
+00011220: 6e73 654f 7074 696f 6e73 225d 5b0a 2020  nseOptions"][.  
+00011230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011240: 2020 2020 2020 2020 2020 2020 2020 2276                "v
+00011250: 616c 7565 5479 7065 220a 2020 2020 2020  alueType".      
+00011260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011270: 2020 2020 2020 5d20 3d20 6a73 6f6e 5f6d        ] = json_m
+00011280: 6170 5b6a 736f 6e5f 6b65 795b 305d 5d5b  ap[json_key[0]][
+00011290: 2272 6573 706f 6e73 654f 7074 696f 6e73  "responseOptions
+000112a0: 225d 5b22 7661 6c75 6554 7970 6522 5d0a  "]["valueType"].
+000112b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000112c0: 2020 2020 2020 2020 2020 2020 7072 696e              prin
+000112d0: 7428 0a20 2020 2020 2020 2020 2020 2020  t(.             
 000112e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000112f0: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
-00011300: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
-00011310: 745f 7475 706c 655d 5b27 6973 4162 6f75  t_tuple]['isAbou
-00011320: 7427 5d2e 6170 7065 6e64 287b 2740 6964  t'].append({'@id
-00011330: 273a 7375 6264 6963 745b 2740 6964 275d  ':subdict['@id']
-00011340: 2c27 6c61 6265 6c27 3a73 7562 6469 6374  ,'label':subdict
-00011350: 5b27 6c61 6265 6c27 5d7d 290a 2020 2020  ['label']}).    
+000112f0: 2020 2022 7661 6c75 6554 7970 653a 222c     "valueType:",
+00011300: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011320: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+00011330: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+00011340: 2272 6573 706f 6e73 654f 7074 696f 6e73  "responseOptions
+00011350: 225d 5b0a 2020 2020 2020 2020 2020 2020  "][.            
 00011360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011380: 2020 2020 7072 696e 7428 2269 7341 626f      print("isAbo
-00011390: 7574 3a20 2573 203d 2025 732c 2025 7320  ut: %s = %s, %s 
-000113a0: 3d20 2573 2220 2528 2740 6964 272c 7375  = %s" %('@id',su
-000113b0: 6264 6963 745b 2740 6964 275d 2c0a 2020  bdict['@id'],.  
-000113c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000113d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000113e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000113f0: 2020 276c 6162 656c 272c 7375 6264 6963    'label',subdic
-00011400: 745b 276c 6162 656c 275d 2929 0a20 2020  t['label'])).   
-00011410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011370: 2020 2020 2020 2020 2276 616c 7565 5479          "valueTy
+00011380: 7065 220a 2020 2020 2020 2020 2020 2020  pe".            
+00011390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000113a0: 2020 2020 5d2c 0a20 2020 2020 2020 2020      ],.         
+000113b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000113c0: 2020 2029 0a0a 2020 2020 2020 2020 2020     )..          
+000113d0: 2020 2020 2020 2020 2020 2020 2020 656c                el
+000113e0: 6966 2022 6d69 6e56 616c 7565 2220 696e  if "minValue" in
+000113f0: 2073 7562 6b65 793a 0a20 2020 2020 2020   subkey:.       
+00011400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011410: 2020 2020 2069 6620 280a 2020 2020 2020       if (.      
 00011420: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011430: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-00011440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011450: 2020 2020 2020 2020 2020 2020 2020 2063                 c
-00011460: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
-00011470: 7572 7265 6e74 5f74 7570 6c65 5d5b 2769  urrent_tuple]['i
-00011480: 7341 626f 7574 275d 2e61 7070 656e 6428  sAbout'].append(
-00011490: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011430: 2020 2020 2020 2020 2020 2272 6573 706f            "respo
+00011440: 6e73 654f 7074 696f 6e73 220a 2020 2020  nseOptions".    
+00011450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011460: 2020 2020 2020 2020 2020 2020 6e6f 7420              not 
+00011470: 696e 2063 6f6c 756d 6e5f 746f 5f74 6572  in column_to_ter
+00011480: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
+00011490: 5d2e 6b65 7973 2829 0a20 2020 2020 2020  ].keys().       
 000114a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000114b0: 2020 2020 2020 2020 2020 2020 207b 2740               {'@
-000114c0: 6964 273a 2073 7562 6469 6374 5b27 4069  id': subdict['@i
-000114d0: 6427 5d7d 290a 2020 2020 2020 2020 2020  d']}).          
-000114e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000114f0: 2020 2020 2020 2020 2020 2020 2020 7072                pr
-00011500: 696e 7428 2269 7341 626f 7574 3a20 2573  int("isAbout: %s
-00011510: 203d 2025 7322 2025 2028 2740 6964 272c   = %s" % ('@id',
-00011520: 2073 7562 6469 6374 5b27 4069 6427 5d29   subdict['@id'])
-00011530: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00011540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011550: 2020 2020 2020 2366 6f72 2069 7361 626f        #for isabo
-00011560: 7574 5f6b 6579 2c69 7361 626f 7574 5f76  ut_key,isabout_v
-00011570: 616c 7565 2069 6e20 7375 6264 6963 742e  alue in subdict.
-00011580: 6974 656d 7328 293a 0a20 2020 2020 2020  items():.       
+000114b0: 2020 2020 2029 3a0a 2020 2020 2020 2020       ):.        
+000114c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000114d0: 2020 2020 2020 2020 636f 6c75 6d6e 5f74          column_t
+000114e0: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
+000114f0: 7475 706c 655d 5b22 7265 7370 6f6e 7365  tuple]["response
+00011500: 4f70 7469 6f6e 7322 5d20 3d20 7b7d 0a0a  Options"] = {}..
+00011510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011520: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
+00011530: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+00011540: 656e 745f 7475 706c 655d 5b22 7265 7370  ent_tuple]["resp
+00011550: 6f6e 7365 4f70 7469 6f6e 7322 5d5b 0a20  onseOptions"][. 
+00011560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011570: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00011580: 6d69 6e56 616c 7565 220a 2020 2020 2020  minValue".      
 00011590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000115a0: 2020 2020 2020 2020 2020 2020 2023 2020               #  
-000115b0: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
-000115c0: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-000115d0: 5b27 6973 4162 6f75 7427 5d2e 6170 7065  ['isAbout'].appe
-000115e0: 6e64 287b 6973 6162 6f75 745f 6b65 793a  nd({isabout_key:
-000115f0: 6973 6162 6f75 745f 7661 6c75 657d 290a  isabout_value}).
-00011600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000115a0: 2020 2020 2020 5d20 3d20 6a73 6f6e 5f6d        ] = json_m
+000115b0: 6170 5b6a 736f 6e5f 6b65 795b 305d 5d5b  ap[json_key[0]][
+000115c0: 2272 6573 706f 6e73 654f 7074 696f 6e73  "responseOptions
+000115d0: 225d 5b22 6d69 6e56 616c 7565 225d 0a20  "]["minValue"]. 
+000115e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000115f0: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+00011600: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
 00011610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011620: 2020 2020 2320 2020 2070 7269 6e74 2822      #    print("
-00011630: 6973 4162 6f75 743a 2025 7320 3d20 2573  isAbout: %s = %s
-00011640: 2220 2528 6973 6162 6f75 745f 6b65 792c  " %(isabout_key,
-00011650: 2069 7361 626f 7574 5f76 616c 7565 2929   isabout_value))
-00011660: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011670: 2020 2020 2020 2020 2023 2069 6620 6973           # if is
-00011680: 4162 6f75 7420 6973 2061 2064 6963 7469  About is a dicti
-00011690: 6f6e 6172 7920 7468 656e 2077 6520 6f6e  onary then we on
-000116a0: 6c79 2068 6176 6520 3120 6973 4162 6f75  ly have 1 isAbou
-000116b0: 742e 2e2e 7765 276c 6c20 7570 6772 6164  t...we'll upgrad
-000116c0: 6520 6974 2074 6f20 6120 6c69 7374 0a20  e it to a list. 
-000116d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000116e0: 2020 2020 2020 2023 2074 6f20 6265 2063         # to be c
-000116f0: 6f6e 7369 7374 656e 7420 6d6f 7669 6e67  onsistent moving
-00011700: 2066 6f72 7761 7264 0a20 2020 2020 2020   forward.       
-00011710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011720: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00011620: 2020 226d 696e 5661 6c75 653a 222c 0a20    "minValue:",. 
+00011630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011640: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00011650: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
+00011660: 7572 7265 6e74 5f74 7570 6c65 5d5b 2272  urrent_tuple]["r
+00011670: 6573 706f 6e73 654f 7074 696f 6e73 225d  esponseOptions"]
+00011680: 5b0a 2020 2020 2020 2020 2020 2020 2020  [.              
+00011690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000116a0: 2020 2020 2020 226d 696e 5661 6c75 6522        "minValue"
+000116b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000116c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000116d0: 205d 2c0a 2020 2020 2020 2020 2020 2020   ],.            
+000116e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000116f0: 290a 0a20 2020 2020 2020 2020 2020 2020  )..             
+00011700: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+00011710: 226d 6178 5661 6c75 6522 2069 6e20 7375  "maxValue" in su
+00011720: 626b 6579 3a0a 2020 2020 2020 2020 2020  bkey:.          
 00011730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011740: 2020 2063 6f6c 756d 6e5f 746f 5f74 6572     column_to_ter
-00011750: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
-00011760: 5d5b 2769 7341 626f 7574 275d 203d 205b  ]['isAbout'] = [
-00011770: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
-00011780: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00011790: 2027 7572 6c27 2069 6e20 6a73 6f6e 5f6d   'url' in json_m
-000117a0: 6170 5b6a 736f 6e5f 6b65 795b 305d 5d5b  ap[json_key[0]][
-000117b0: 2769 7341 626f 7574 275d 2e6b 6579 7328  'isAbout'].keys(
-000117c0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+00011740: 2020 6966 2028 0a20 2020 2020 2020 2020    if (.         
+00011750: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011760: 2020 2020 2020 2022 7265 7370 6f6e 7365         "response
+00011770: 4f70 7469 6f6e 7322 0a20 2020 2020 2020  Options".       
+00011780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011790: 2020 2020 2020 2020 206e 6f74 2069 6e20           not in 
+000117a0: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
+000117b0: 6375 7272 656e 745f 7475 706c 655d 2e6b  current_tuple].k
+000117c0: 6579 7328 290a 2020 2020 2020 2020 2020  eys().          
 000117d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000117e0: 2020 2069 6620 276c 6162 656c 2720 696e     if 'label' in
-000117f0: 206a 736f 6e5f 6d61 705b 6a73 6f6e 5f6b   json_map[json_k
-00011800: 6579 5b30 5d5d 5b27 6973 4162 6f75 7427  ey[0]]['isAbout'
-00011810: 5d2e 6b65 7973 2829 3a0a 2020 2020 2020  ].keys():.      
-00011820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011830: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00011840: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
-00011850: 7272 656e 745f 7475 706c 655d 5b27 6973  rrent_tuple]['is
-00011860: 4162 6f75 7427 5d2e 6170 7065 6e64 287b  About'].append({
-00011870: 2740 6964 273a 0a20 2020 2020 2020 2020  '@id':.         
-00011880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011890: 2020 2020 2020 2020 2020 2020 2020 206a                 j
-000118a0: 736f 6e5f 6d61 705b 6a73 6f6e 5f6b 6579  son_map[json_key
-000118b0: 5b30 5d5d 5b27 6973 4162 6f75 7427 5d5b  [0]]['isAbout'][
-000118c0: 2775 726c 275d 2c27 6c61 6265 6c27 3a0a  'url'],'label':.
-000118d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000118e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000118f0: 2020 2020 2020 2020 6a73 6f6e 5f6d 6170          json_map
-00011900: 5b6a 736f 6e5f 6b65 795b 305d 5d5b 2769  [json_key[0]]['i
-00011910: 7341 626f 7574 275d 5b27 6c61 6265 6c27  sAbout']['label'
-00011920: 5d7d 290a 2020 2020 2020 2020 2020 2020  ]}).            
+000117e0: 2020 293a 0a20 2020 2020 2020 2020 2020    ):.           
+000117f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011800: 2020 2020 2063 6f6c 756d 6e5f 746f 5f74       column_to_t
+00011810: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
+00011820: 6c65 5d5b 2272 6573 706f 6e73 654f 7074  le]["responseOpt
+00011830: 696f 6e73 225d 203d 207b 7d0a 0a20 2020  ions"] = {}..   
+00011840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011850: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
+00011860: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+00011870: 5f74 7570 6c65 5d5b 2272 6573 706f 6e73  _tuple]["respons
+00011880: 654f 7074 696f 6e73 225d 5b0a 2020 2020  eOptions"][.    
+00011890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000118a0: 2020 2020 2020 2020 2020 2020 226d 6178              "max
+000118b0: 5661 6c75 6522 0a20 2020 2020 2020 2020  Value".         
+000118c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000118d0: 2020 205d 203d 206a 736f 6e5f 6d61 705b     ] = json_map[
+000118e0: 6a73 6f6e 5f6b 6579 5b30 5d5d 5b22 7265  json_key[0]]["re
+000118f0: 7370 6f6e 7365 4f70 7469 6f6e 7322 5d5b  sponseOptions"][
+00011900: 226d 6178 5661 6c75 6522 5d0a 2020 2020  "maxValue"].    
+00011910: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011920: 2020 2020 2020 2020 7072 696e 7428 0a20          print(. 
 00011930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011940: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00011950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011960: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00011970: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
-00011980: 7272 656e 745f 7475 706c 655d 5b27 6973  rrent_tuple]['is
-00011990: 4162 6f75 7427 5d2e 6170 7065 6e64 287b  About'].append({
-000119a0: 2740 6964 273a 0a20 2020 2020 2020 2020  '@id':.         
+00011940: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00011950: 6d61 7856 616c 7565 3a22 2c0a 2020 2020  maxValue:",.    
+00011960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011970: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
+00011980: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+00011990: 656e 745f 7475 706c 655d 5b22 7265 7370  ent_tuple]["resp
+000119a0: 6f6e 7365 4f70 7469 6f6e 7322 5d5b 0a20  onseOptions"][. 
 000119b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000119c0: 2020 2020 2020 2020 2020 2020 2020 206a                 j
-000119d0: 736f 6e5f 6d61 705b 6a73 6f6e 5f6b 6579  son_map[json_key
-000119e0: 5b30 5d5d 5b27 6973 4162 6f75 7427 5d5b  [0]]['isAbout'][
-000119f0: 2775 726c 275d 7d29 0a20 2020 2020 2020  'url']}).       
-00011a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011a10: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+000119c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000119d0: 2020 2022 6d61 7856 616c 7565 220a 2020     "maxValue".  
+000119e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000119f0: 2020 2020 2020 2020 2020 2020 2020 5d2c                ],
+00011a00: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011a10: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
 00011a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011a30: 2020 2020 2020 2020 2020 2069 6620 276c             if 'l
-00011a40: 6162 656c 2720 696e 206a 736f 6e5f 6d61  abel' in json_ma
-00011a50: 705b 6a73 6f6e 5f6b 6579 5b30 5d5d 5b27  p[json_key[0]]['
-00011a60: 6973 4162 6f75 7427 5d2e 6b65 7973 2829  isAbout'].keys()
-00011a70: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00011a30: 2020 2020 2020 2065 6c69 6620 2263 686f         elif "cho
+00011a40: 6963 6573 2220 696e 2073 7562 6b65 793a  ices" in subkey:
+00011a50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011a60: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00011a70: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
 00011a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011a90: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
-00011aa0: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
-00011ab0: 706c 655d 5b27 6973 4162 6f75 7427 5d2e  ple]['isAbout'].
-00011ac0: 6170 7065 6e64 287b 2740 6964 273a 0a20  append({'@id':. 
-00011ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011af0: 2020 2020 2020 206a 736f 6e5f 6d61 705b         json_map[
-00011b00: 6a73 6f6e 5f6b 6579 5b30 5d5d 5b27 6973  json_key[0]]['is
-00011b10: 4162 6f75 7427 5d5b 2740 6964 275d 2c27  About']['@id'],'
-00011b20: 6c61 6265 6c27 3a0a 2020 2020 2020 2020  label':.        
-00011b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011b50: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
-00011b60: 795b 305d 5d5b 2769 7341 626f 7574 275d  y[0]]['isAbout']
-00011b70: 5b27 6c61 6265 6c27 5d7d 290a 2020 2020  ['label']}).    
-00011b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011b90: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00011ba0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00011bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011bc0: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
-00011bd0: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
-00011be0: 706c 655d 5b27 6973 4162 6f75 7427 5d2e  ple]['isAbout'].
-00011bf0: 6170 7065 6e64 287b 2740 6964 273a 0a20  append({'@id':. 
-00011c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c20: 2020 2020 2020 206a 736f 6e5f 6d61 705b         json_map[
-00011c30: 6a73 6f6e 5f6b 6579 5b30 5d5d 5b27 6973  json_key[0]]['is
-00011c40: 4162 6f75 7427 5d5b 2740 6964 275d 7d29  About']['@id']})
-00011c50: 0a0a 0a20 2020 2020 2020 2020 2020 2020  ...             
-00011c60: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-00011c70: 7269 6e74 2822 6973 4162 6f75 743a 2025  rint("isAbout: %
-00011c80: 7320 3d20 2573 2c20 2573 203d 2025 7322  s = %s, %s = %s"
-00011c90: 2025 2827 4069 6427 2c63 6f6c 756d 6e5f   %('@id',column_
-00011ca0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-00011cb0: 5f74 7570 6c65 5d5b 2769 7341 626f 7574  _tuple]['isAbout
-00011cc0: 275d 5b27 4069 6427 5d2c 0a20 2020 2020  ']['@id'],.     
-00011cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011ce0: 2020 2020 2020 2020 2020 2020 2020 2027                 '
-00011cf0: 6c61 6265 6c27 2c63 6f6c 756d 6e5f 746f  label',column_to
-00011d00: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-00011d10: 7570 6c65 5d5b 2769 7341 626f 7574 275d  uple]['isAbout']
-00011d20: 5b27 6c61 6265 6c27 5d29 290a 2020 2020  ['label'])).    
+00011a90: 2020 2272 6573 706f 6e73 654f 7074 696f    "responseOptio
+00011aa0: 6e73 220a 2020 2020 2020 2020 2020 2020  ns".            
+00011ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ac0: 2020 2020 6e6f 7420 696e 2063 6f6c 756d      not in colum
+00011ad0: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
+00011ae0: 6e74 5f74 7570 6c65 5d2e 6b65 7973 2829  nt_tuple].keys()
+00011af0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011b00: 2020 2020 2020 2020 2020 2020 2029 3a0a               ):.
+00011b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b30: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
+00011b40: 6375 7272 656e 745f 7475 706c 655d 5b22  current_tuple]["
+00011b50: 7265 7370 6f6e 7365 4f70 7469 6f6e 7322  responseOptions"
+00011b60: 5d20 3d20 7b7d 0a0a 2020 2020 2020 2020  ] = {}..        
+00011b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b80: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
+00011b90: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
+00011ba0: 655d 5b22 7265 7370 6f6e 7365 4f70 7469  e]["responseOpti
+00011bb0: 6f6e 7322 5d5b 0a20 2020 2020 2020 2020  ons"][.         
+00011bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011bd0: 2020 2020 2020 2022 6368 6f69 6365 7322         "choices"
+00011be0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011bf0: 2020 2020 2020 2020 2020 2020 205d 203d               ] =
+00011c00: 206a 736f 6e5f 6d61 705b 6a73 6f6e 5f6b   json_map[json_k
+00011c10: 6579 5b30 5d5d 5b22 7265 7370 6f6e 7365  ey[0]]["response
+00011c20: 4f70 7469 6f6e 7322 5d5b 2263 686f 6963  Options"]["choic
+00011c30: 6573 225d 0a20 2020 2020 2020 2020 2020  es"].           
+00011c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011c50: 2070 7269 6e74 280a 2020 2020 2020 2020   print(.        
+00011c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011c70: 2020 2020 2020 2020 226c 6576 656c 733a          "levels:
+00011c80: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00011c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ca0: 2020 2063 6f6c 756d 6e5f 746f 5f74 6572     column_to_ter
+00011cb0: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
+00011cc0: 5d5b 2272 6573 706f 6e73 654f 7074 696f  ]["responseOptio
+00011cd0: 6e73 225d 5b0a 2020 2020 2020 2020 2020  ns"][.          
+00011ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011cf0: 2020 2020 2020 2020 2020 2263 686f 6963            "choic
+00011d00: 6573 220a 2020 2020 2020 2020 2020 2020  es".            
+00011d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011d20: 2020 2020 5d2c 0a20 2020 2020 2020 2020      ],.         
 00011d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011d40: 656c 7365 3a0a 0a20 2020 2020 2020 2020  else:..         
-00011d50: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-00011d60: 2069 6620 7573 6572 2072 616e 2069 6e20   if user ran in 
-00011d70: 6d6f 6465 2077 6865 7265 2074 6865 7920  mode where they 
-00011d80: 7761 6e74 2074 6f20 6173 736f 6369 6174  want to associat
-00011d90: 6520 636f 6e63 6570 7473 2061 6e64 2074  e concepts and t
-00011da0: 6869 7320 6973 6e27 7420 7468 6520 7061  his isn't the pa
-00011db0: 7274 6963 6970 616e 740a 2020 2020 2020  rticipant.      
-00011dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011dd0: 2020 2320 6964 2066 6965 6c64 2074 6865    # id field the
-00011de0: 6e20 6173 736f 6369 6174 6520 636f 6e63  n associate conc
-00011df0: 6570 7473 2e0a 2020 2020 2020 2020 2020  epts..          
-00011e00: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00011e10: 206d 6174 6368 5f70 6172 7469 6369 7061   match_participa
-00011e20: 6e74 5f69 645f 6669 656c 6428 6a73 6f6e  nt_id_field(json
-00011e30: 5f6d 6170 5b6a 736f 6e5f 6b65 795b 305d  _map[json_key[0]
-00011e40: 5d5b 2773 6f75 7263 6556 6172 6961 626c  ]['sourceVariabl
-00011e50: 6527 5d29 3a0a 2020 2020 2020 2020 2020  e']):.          
-00011e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011e70: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
-00011e80: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-00011e90: 5b27 6973 4162 6f75 7427 5d20 3d5b 5d0a  ['isAbout'] =[].
-00011ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011eb0: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
-00011ec0: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
-00011ed0: 656e 745f 7475 706c 655d 5b27 6973 4162  ent_tuple]['isAb
-00011ee0: 6f75 7427 5d2e 6170 7065 6e64 287b 2740  out'].append({'@
-00011ef0: 6964 273a 436f 6e73 7461 6e74 732e 4e49  id':Constants.NI
-00011f00: 444d 5f53 5542 4a45 4354 4944 2e75 7269  DM_SUBJECTID.uri
-00011f10: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00011f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011f30: 2020 2020 2020 2020 2020 276c 6162 656c            'label
-00011f40: 273a 436f 6e73 7461 6e74 732e 4e49 444d  ':Constants.NIDM
-00011f50: 5f53 5542 4a45 4354 4944 2e6c 6f63 616c  _SUBJECTID.local
-00011f60: 7061 7274 7d29 0a20 2020 2020 2020 2020  part}).         
-00011f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011f80: 2020 2077 7269 7465 5f6a 736f 6e5f 6d61     write_json_ma
-00011f90: 7070 696e 675f 6669 6c65 2863 6f6c 756d  pping_file(colum
-00011fa0: 6e5f 746f 5f74 6572 6d73 2c20 6f75 7470  n_to_terms, outp
-00011fb0: 7574 5f66 696c 652c 2062 6964 7329 0a20  ut_file, bids). 
-00011fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011fd0: 2020 2020 2020 2065 6c69 6620 6173 736f         elif asso
-00011fe0: 6369 6174 655f 636f 6e63 6570 7473 3a0a  ciate_concepts:.
-00011ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012000: 2020 2020 2020 2020 2020 2020 2320 7072              # pr
-00012010: 6f76 6964 6520 7573 6572 2077 6974 6820  ovide user with 
-00012020: 6f70 706f 7274 756e 6974 7920 746f 2061  opportunity to a
-00012030: 7373 6f63 6961 7465 2061 2063 6f6e 6365  ssociate a conce
-00012040: 7074 2077 6974 6820 7468 6973 2061 6e6e  pt with this ann
-00012050: 6f74 6174 696f 6e0a 2020 2020 2020 2020  otation.        
-00012060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012070: 2020 2020 6669 6e64 5f63 6f6e 6365 7074      find_concept
-00012080: 5f69 6e74 6572 6163 7469 7665 2863 6f6c  _interactive(col
-00012090: 756d 6e2c 6375 7272 656e 745f 7475 706c  umn,current_tupl
-000120a0: 652c 636f 6c75 6d6e 5f74 6f5f 7465 726d  e,column_to_term
-000120b0: 732c 696c 785f 6f62 6a2c 6e69 646d 5f6f  s,ilx_obj,nidm_o
-000120c0: 776c 5f67 7261 7068 3d6e 6964 6d5f 6f77  wl_graph=nidm_ow
-000120d0: 6c5f 6772 6170 6829 0a20 2020 2020 2020  l_graph).       
-000120e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000120f0: 2020 2020 2023 2077 7269 7465 2061 6e6e       # write ann
-00012100: 6f74 6174 696f 6e73 2074 6f20 6a73 6f6e  otations to json
-00012110: 2066 696c 6520 736f 2075 7365 7220 6361   file so user ca
-00012120: 6e20 7374 6172 7420 7570 2061 6761 696e  n start up again
-00012130: 2069 6620 6e6f 7420 646f 696e 6720 7768   if not doing wh
-00012140: 6f6c 6520 6669 6c65 0a20 2020 2020 2020  ole file.       
-00012150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012160: 2020 2020 2077 7269 7465 5f6a 736f 6e5f       write_json_
-00012170: 6d61 7070 696e 675f 6669 6c65 2863 6f6c  mapping_file(col
-00012180: 756d 6e5f 746f 5f74 6572 6d73 2c6f 7574  umn_to_terms,out
-00012190: 7075 745f 6669 6c65 2c62 6964 7329 0a0a  put_file,bids)..
-000121a0: 2020 2020 2020 2020 2020 2020 7072 696e              prin
-000121b0: 7428 222a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  t("*************
-000121c0: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-000121d0: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-000121e0: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-000121f0: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-00012200: 2a2a 2a2a 2a2a 2a2a 2a2a 2229 0a20 2020  **********").   
-00012210: 2020 2020 2020 2020 2070 7269 6e74 2822           print("
-00012220: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00012230: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00012240: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00012250: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00012260: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00012270: 2d2d 2d2d 2d2d 2d22 290a 0a20 2020 2020  -------")..     
-00012280: 2020 2020 2020 2069 6620 286a 736f 6e5f         if (json_
-00012290: 6d61 7020 6973 206e 6f74 204e 6f6e 6529  map is not None)
-000122a0: 2061 6e64 2028 6c65 6e28 6a73 6f6e 5f6b   and (len(json_k
-000122b0: 6579 293e 3029 3a0a 2020 2020 2020 2020  ey)>0):.        
-000122c0: 2020 2020 2020 2020 636f 6e74 696e 7565          continue
-000122d0: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
-000122e0: 4578 6365 7074 696f 6e20 6173 2065 3a0a  Exception as e:.
-000122f0: 2020 2020 2020 2020 2020 2020 2320 736f              # so
-00012300: 2069 6620 7468 6973 2069 7320 616e 2049   if this is an I
-00012310: 6e64 6578 4572 726f 7220 7468 656e 2069  ndexError then i
-00012320: 7427 7320 6c69 6b65 6c79 206f 7572 206a  t's likely our j
-00012330: 736f 6e20 6d61 7070 696e 6720 6669 6c65  son mapping file
-00012340: 206b 6579 7320 6172 6520 6f66 2074 6865   keys are of the
-00012350: 2042 4944 5320 7479 7065 0a20 2020 2020   BIDS type.     
-00012360: 2020 2020 2020 2023 2028 7369 6d70 6c79         # (simply
-00012370: 2076 6172 6961 626c 6520 6e61 6d65 7329   variable names)
-00012380: 2069 6e73 7465 6164 206f 6620 7468 6520   instead of the 
-00012390: 6d6f 7265 2063 6f6d 706c 6578 204e 4944  more complex NID
-000123a0: 4d20 6f6e 6573 2044 4428 6669 6c65 3d58  M ones DD(file=X
-000123b0: 582c 7661 7269 6162 6c65 3d59 5929 0a0a  X,variable=YY)..
-000123c0: 2020 2020 2020 2020 2020 2020 6966 2022              if "
-000123d0: 4e61 6d65 4572 726f 7222 2069 6e20 7374  NameError" in st
-000123e0: 7228 6529 3a0a 2020 2020 2020 2020 2020  r(e):.          
-000123f0: 2020 2020 2020 7072 696e 7428 226a 736f        print("jso
-00012400: 6e20 616e 6e6f 7461 7469 6f6e 2066 696c  n annotation fil
-00012410: 6520 6e6f 7420 7375 7070 6c69 6564 2229  e not supplied")
-00012420: 0a0a 2020 2020 2020 2020 7365 6172 6368  ..        search
-00012430: 5f74 6572 6d20 3d20 7374 7228 636f 6c75  _term = str(colu
-00012440: 6d6e 290a 2020 2020 2020 2020 2361 6464  mn).        #add
-00012450: 6564 2066 6f72 2061 6e20 6175 746f 6d61  ed for an automa
-00012460: 7469 6320 6d61 7070 696e 6720 6f66 2070  tic mapping of p
-00012470: 6172 7469 6369 7061 6e74 5f69 642c 2073  articipant_id, s
-00012480: 7562 6a65 6374 5f69 642c 2061 6e64 2076  ubject_id, and v
-00012490: 6172 6961 6e74 730a 2020 2020 2020 2020  ariants.        
-000124a0: 6966 206d 6174 6368 5f70 6172 7469 6369  if match_partici
-000124b0: 7061 6e74 5f69 645f 6669 656c 6428 7365  pant_id_field(se
-000124c0: 6172 6368 5f74 6572 6d2e 6c6f 7765 7228  arch_term.lower(
-000124d0: 2929 3a0a 0a20 2020 2020 2020 2020 2020  )):..           
-000124e0: 2023 206d 6170 2074 6869 7320 7465 726d   # map this term
-000124f0: 2074 6f20 436f 6e73 7461 6e74 732e 4e49   to Constants.NI
-00012500: 444d 5f53 5542 4a45 4354 4944 0a20 2020  DM_SUBJECTID.   
-00012510: 2020 2020 2020 2020 2023 2073 696e 6365           # since
-00012520: 206f 7572 2073 7562 6a65 6374 2069 6473   our subject ids
-00012530: 2061 7265 2073 7461 7469 6361 6c6c 7920   are statically 
-00012540: 6d61 7070 6564 2074 6f20 7468 6520 436f  mapped to the Co
-00012550: 6e73 7461 6e74 732e 4e49 444d 5f53 5542  nstants.NIDM_SUB
-00012560: 4a45 4354 4944 2077 6527 7265 2063 7265  JECTID we're cre
-00012570: 6174 696e 6720 6120 6e65 770a 2020 2020  ating a new.    
-00012580: 2020 2020 2020 2020 2320 6e61 6d65 6420          # named 
-00012590: 7475 706c 6520 666f 7220 7468 6973 206a  tuple for this j
-000125a0: 736f 6e20 6d61 7020 656e 7472 7920 6173  son map entry as
-000125b0: 2069 7427 7320 6e6f 7420 7468 6520 7361   it's not the sa
-000125c0: 6d65 2073 6f75 7263 6520 6173 2074 6865  me source as the
-000125d0: 2072 6573 7420 6f66 2074 6865 2064 6174   rest of the dat
-000125e0: 6120 6672 616d 6520 7768 6963 680a 2020  a frame which.  
-000125f0: 2020 2020 2020 2020 2020 2320 636f 6d65            # come
-00012600: 7320 6672 6f6d 2074 6865 2027 6173 7365  s from the 'asse
-00012610: 7373 6d65 6e74 5f6e 616d 6527 2066 756e  ssment_name' fun
-00012620: 6374 696f 6e20 7061 7261 6d65 7465 722e  ction parameter.
-00012630: 0a20 2020 2020 2020 2020 2020 2073 7562  .            sub
-00012640: 6a69 645f 7475 706c 6520 3d20 7374 7228  jid_tuple = str(
-00012650: 4444 2873 6f75 7263 653d 6173 7365 7373  DD(source=assess
-00012660: 6d65 6e74 5f6e 616d 652c 2076 6172 6961  ment_name, varia
-00012670: 626c 653d 7365 6172 6368 5f74 6572 6d29  ble=search_term)
-00012680: 290a 2020 2020 2020 2020 2020 2020 636f  ).            co
-00012690: 6c75 6d6e 5f74 6f5f 7465 726d 735b 7375  lumn_to_terms[su
-000126a0: 626a 6964 5f74 7570 6c65 5d20 3d20 7b7d  bjid_tuple] = {}
-000126b0: 0a20 2020 2020 2020 2020 2020 2063 6f6c  .            col
-000126c0: 756d 6e5f 746f 5f74 6572 6d73 5b73 7562  umn_to_terms[sub
-000126d0: 6a69 645f 7475 706c 655d 5b27 6c61 6265  jid_tuple]['labe
-000126e0: 6c27 5d20 3d20 7365 6172 6368 5f74 6572  l'] = search_ter
-000126f0: 6d0a 2020 2020 2020 2020 2020 2020 636f  m.            co
-00012700: 6c75 6d6e 5f74 6f5f 7465 726d 735b 7375  lumn_to_terms[su
-00012710: 626a 6964 5f74 7570 6c65 5d5b 2764 6573  bjid_tuple]['des
-00012720: 6372 6970 7469 6f6e 275d 203d 2022 7375  cription'] = "su
-00012730: 626a 6563 742f 7061 7274 6963 6970 616e  bject/participan
-00012740: 7420 6964 656e 7469 6669 6572 220a 2020  t identifier".  
-00012750: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
-00012760: 5f74 6f5f 7465 726d 735b 7375 626a 6964  _to_terms[subjid
-00012770: 5f74 7570 6c65 5d5b 2773 6f75 7263 655f  _tuple]['source_
-00012780: 7661 7269 6162 6c65 275d 203d 2073 7472  variable'] = str
-00012790: 2873 6561 7263 685f 7465 726d 290a 2020  (search_term).  
-000127a0: 2020 2020 2020 2020 2020 2320 6164 6465            # adde
-000127b0: 6420 746f 2073 7570 706f 7274 2072 6570  d to support rep
-000127c0: 726f 7363 6865 6d61 2066 6f72 6d61 740a  roschema format.
-000127d0: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
-000127e0: 6d6e 5f74 6f5f 7465 726d 735b 7375 626a  mn_to_terms[subj
-000127f0: 6964 5f74 7570 6c65 5d5b 2772 6573 706f  id_tuple]['respo
-00012800: 6e73 654f 7074 696f 6e73 275d 203d 207b  nseOptions'] = {
-00012810: 7d0a 2020 2020 2020 2020 2020 2020 636f  }.            co
-00012820: 6c75 6d6e 5f74 6f5f 7465 726d 735b 7375  lumn_to_terms[su
-00012830: 626a 6964 5f74 7570 6c65 5d5b 2772 6573  bjid_tuple]['res
-00012840: 706f 6e73 654f 7074 696f 6e73 275d 5b27  ponseOptions']['
-00012850: 7661 6c75 6554 7970 6527 5d20 3d20 5552  valueType'] = UR
-00012860: 4952 6566 2843 6f6e 7374 616e 7473 2e58  IRef(Constants.X
-00012870: 5344 5b22 7374 7269 6e67 225d 290a 2020  SD["string"]).  
-00012880: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
-00012890: 5f74 6f5f 7465 726d 735b 7375 626a 6964  _to_terms[subjid
-000128a0: 5f74 7570 6c65 5d5b 2769 7341 626f 7574  _tuple]['isAbout
-000128b0: 275d 203d 205b 5d0a 2020 2020 2020 2020  '] = [].        
-000128c0: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
-000128d0: 726d 735b 7375 626a 6964 5f74 7570 6c65  rms[subjid_tuple
-000128e0: 5d5b 2769 7341 626f 7574 275d 2e61 7070  ]['isAbout'].app
-000128f0: 656e 6428 7b27 4069 6427 3a43 6f6e 7374  end({'@id':Const
-00012900: 616e 7473 2e4e 4944 4d5f 5355 424a 4543  ants.NIDM_SUBJEC
-00012910: 5449 442e 7572 692c 0a20 2020 2020 2020  TID.uri,.       
-00012920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012930: 2027 6c61 6265 6c27 3a43 6f6e 7374 616e   'label':Constan
-00012940: 7473 2e4e 4944 4d5f 5355 424a 4543 5449  ts.NIDM_SUBJECTI
-00012950: 442e 6c6f 6361 6c70 6172 747d 290a 2020  D.localpart}).  
-00012960: 2020 2020 2020 2020 2020 2320 636f 6c75            # colu
-00012970: 6d6e 5f74 6f5f 7465 726d 735b 7375 626a  mn_to_terms[subj
-00012980: 6964 5f74 7570 6c65 5d5b 2776 6172 6961  id_tuple]['varia
-00012990: 626c 6527 5d20 3d20 7374 7228 636f 6c75  ble'] = str(colu
-000129a0: 6d6e 290a 0a20 2020 2020 2020 2020 2020  mn)..           
-000129b0: 2070 7269 6e74 2822 5661 7269 6162 6c65   print("Variable
-000129c0: 2025 7320 6175 746f 6d61 7469 6361 6c6c   %s automaticall
-000129d0: 7920 6d61 7070 6564 2074 6f20 7061 7274  y mapped to part
-000129e0: 6963 6970 616e 742f 7375 626a 6563 7420  icipant/subject 
-000129f0: 6964 656e 7469 6669 6572 2220 2573 6561  identifier" %sea
-00012a00: 7263 685f 7465 726d 290a 2020 2020 2020  rch_term).      
-00012a10: 2020 2020 2020 7072 696e 7428 224c 6162        print("Lab
-00012a20: 656c 3a20 2573 2220 2563 6f6c 756d 6e5f  el: %s" %column_
-00012a30: 746f 5f74 6572 6d73 5b73 7562 6a69 645f  to_terms[subjid_
-00012a40: 7475 706c 655d 5b27 6c61 6265 6c27 5d29  tuple]['label'])
-00012a50: 0a20 2020 2020 2020 2020 2020 2070 7269  .            pri
-00012a60: 6e74 2822 4465 7363 7269 7074 696f 6e3a  nt("Description:
-00012a70: 2025 7322 2025 636f 6c75 6d6e 5f74 6f5f   %s" %column_to_
-00012a80: 7465 726d 735b 7375 626a 6964 5f74 7570  terms[subjid_tup
-00012a90: 6c65 5d5b 2764 6573 6372 6970 7469 6f6e  le]['description
-00012aa0: 275d 290a 2020 2020 2020 2020 2020 2020  ']).            
-00012ab0: 2370 7269 6e74 2822 5572 6c3a 2025 7322  #print("Url: %s"
-00012ac0: 2025 636f 6c75 6d6e 5f74 6f5f 7465 726d   %column_to_term
-00012ad0: 735b 7375 626a 6964 5f74 7570 6c65 5d5b  s[subjid_tuple][
-00012ae0: 2775 726c 275d 290a 2020 2020 2020 2020  'url']).        
-00012af0: 2020 2020 7072 696e 7428 2253 6f75 7263      print("Sourc
-00012b00: 6520 5661 7269 6162 6c65 3a20 2573 2220  e Variable: %s" 
-00012b10: 2520 636f 6c75 6d6e 5f74 6f5f 7465 726d  % column_to_term
-00012b20: 735b 7375 626a 6964 5f74 7570 6c65 5d5b  s[subjid_tuple][
-00012b30: 2773 6f75 7263 655f 7661 7269 6162 6c65  'source_variable
-00012b40: 275d 290a 2020 2020 2020 2020 2020 2020  ']).            
-00012b50: 7072 696e 7428 222d 2d2d 2d2d 2d2d 2d2d  print("---------
-00012b60: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00012b70: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00012b80: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00012b90: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00012ba0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2229  --------------")
-00012bb0: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
-00012bc0: 7469 6e75 650a 2020 2020 2020 2020 2320  tinue.        # 
-00012bd0: 6966 2077 6520 6861 7665 6e27 7420 616c  if we haven't al
-00012be0: 7265 6164 7920 666f 756e 6420 616e 2061  ready found an a
-00012bf0: 6e6e 6f74 6174 696f 6e20 666f 7220 7468  nnotation for th
-00012c00: 6973 2063 6f6c 756d 6e20 7468 656e 2068  is column then h
-00012c10: 6176 6520 7573 6572 2063 7265 6174 6520  ave user create 
-00012c20: 6f6e 652e 0a20 2020 2020 2020 2069 6620  one..        if 
-00012c30: 6375 7272 656e 745f 7475 706c 6520 6e6f  current_tuple no
-00012c40: 7420 696e 2063 6f6c 756d 6e5f 746f 5f74  t in column_to_t
-00012c50: 6572 6d73 2e6b 6579 7328 293a 0a20 2020  erms.keys():.   
-00012c60: 2020 2020 2020 2020 2023 2063 7265 6174           # creat
-00012c70: 6520 656d 7074 7920 616e 6e6f 7461 7469  e empty annotati
-00012c80: 6f6e 2073 7472 7563 7475 7265 2066 6f72  on structure for
-00012c90: 2074 6869 7320 736f 7572 6365 2076 6172   this source var
-00012ca0: 6961 626c 650a 2020 2020 2020 2020 2020  iable.          
-00012cb0: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
-00012cc0: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-00012cd0: 203d 207b 7d0a 2020 2020 2020 2020 2020   = {}.          
-00012ce0: 2020 2320 656e 7465 7220 7573 6572 2069    # enter user i
-00012cf0: 6e74 6572 6163 7469 6f6e 2066 756e 6374  nteraction funct
-00012d00: 696f 6e20 746f 2067 6574 2064 6174 6120  ion to get data 
-00012d10: 6469 6374 696f 6e61 7279 2061 6e6e 6f74  dictionary annot
-00012d20: 6174 696f 6e73 2066 726f 6d20 7573 6572  ations from user
-00012d30: 0a20 2020 2020 2020 2020 2020 2061 6e6e  .            ann
-00012d40: 6f74 6174 655f 6461 7461 5f65 6c65 6d65  otate_data_eleme
-00012d50: 6e74 2863 6f6c 756d 6e2c 2063 7572 7265  nt(column, curre
-00012d60: 6e74 5f74 7570 6c65 2c20 636f 6c75 6d6e  nt_tuple, column
-00012d70: 5f74 6f5f 7465 726d 7329 0a20 2020 2020  _to_terms).     
-00012d80: 2020 2023 2074 6865 6e20 6173 6b20 7573     # then ask us
-00012d90: 6572 2074 6f20 6669 6e64 2061 2063 6f6e  er to find a con
-00012da0: 6365 7074 2069 6620 7468 6579 2073 656c  cept if they sel
-00012db0: 6563 7465 6420 746f 2064 6f20 736f 0a20  ected to do so. 
-00012dc0: 2020 2020 2020 2069 6620 6173 736f 6369         if associ
-00012dd0: 6174 655f 636f 6e63 6570 7473 3a0a 2020  ate_concepts:.  
-00012de0: 2020 2020 2020 2020 2020 2320 7072 6f76            # prov
-00012df0: 6964 6520 7573 6572 2077 6974 6820 6f70  ide user with op
-00012e00: 706f 7274 756e 6974 7920 746f 2061 7373  portunity to ass
-00012e10: 6f63 6961 7465 2061 2063 6f6e 6365 7074  ociate a concept
-00012e20: 2077 6974 6820 7468 6973 2061 6e6e 6f74   with this annot
-00012e30: 6174 696f 6e0a 2020 2020 2020 2020 2020  ation.          
-00012e40: 2020 6669 6e64 5f63 6f6e 6365 7074 5f69    find_concept_i
-00012e50: 6e74 6572 6163 7469 7665 2863 6f6c 756d  nteractive(colum
-00012e60: 6e2c 2063 7572 7265 6e74 5f74 7570 6c65  n, current_tuple
-00012e70: 2c20 636f 6c75 6d6e 5f74 6f5f 7465 726d  , column_to_term
-00012e80: 732c 2069 6c78 5f6f 626a 2c20 6e69 646d  s, ilx_obj, nidm
-00012e90: 5f6f 776c 5f67 7261 7068 3d6e 6964 6d5f  _owl_graph=nidm_
-00012ea0: 6f77 6c5f 6772 6170 6829 0a20 2020 2020  owl_graph).     
-00012eb0: 2020 2020 2020 2023 2077 7269 7465 2061         # write a
-00012ec0: 6e6e 6f74 6174 696f 6e73 2074 6f20 6a73  nnotations to js
-00012ed0: 6f6e 2066 696c 6520 736f 2075 7365 7220  on file so user 
-00012ee0: 6361 6e20 7374 6172 7420 7570 2061 6761  can start up aga
-00012ef0: 696e 2069 6620 6e6f 7420 646f 696e 6720  in if not doing 
-00012f00: 7768 6f6c 6520 6669 6c65 0a20 2020 2020  whole file.     
-00012f10: 2020 2020 2020 2077 7269 7465 5f6a 736f         write_jso
-00012f20: 6e5f 6d61 7070 696e 675f 6669 6c65 2863  n_mapping_file(c
-00012f30: 6f6c 756d 6e5f 746f 5f74 6572 6d73 2c20  olumn_to_terms, 
-00012f40: 6f75 7470 7574 5f66 696c 652c 2062 6964  output_file, bid
-00012f50: 7329 0a0a 0a20 2020 2020 2020 2074 7279  s)...        try
-00012f60: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
-00012f70: 6e6f 7720 7765 2073 686f 756c 6420 6164  now we should ad
-00012f80: 6420 7468 6520 6461 7461 2065 6c65 6d65  d the data eleme
-00012f90: 6e74 2064 6566 696e 6974 696f 6e20 7769  nt definition wi
-00012fa0: 7468 2063 6f6e 6365 7074 2061 6e6e 6f74  th concept annot
-00012fb0: 6174 696f 6e20 746f 2049 6e74 6572 4c65  ation to InterLe
-00012fc0: 780a 2020 2020 2020 2020 2020 2020 2320  x.            # 
-00012fd0: 6368 6563 6b20 6966 2074 6869 7320 6973  check if this is
-00012fe0: 2061 2063 6174 6567 6f72 6963 616c 2076   a categorical v
-00012ff0: 6172 6961 626c 652c 2069 6620 736f 2069  ariable, if so i
-00013000: 7420 7769 6c6c 2068 6176 6520 276c 6576  t will have 'lev
-00013010: 656c 7327 206b 6579 0a20 2020 2020 2020  els' key.       
-00013020: 2020 2020 2069 6620 276c 6576 656c 7327       if 'levels'
-00013030: 2069 6e20 636f 6c75 6d6e 5f74 6f5f 7465   in column_to_te
-00013040: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
-00013050: 655d 3a0a 2020 2020 2020 2020 2020 2020  e]:.            
-00013060: 2020 2020 6966 2027 6973 4162 6f75 7427      if 'isAbout'
-00013070: 2069 6e20 636f 6c75 6d6e 5f74 6f5f 7465   in column_to_te
-00013080: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
-00013090: 655d 3a0a 2020 2020 2020 2020 2020 2020  e]:.            
-000130a0: 2020 2020 2020 2020 696c 785f 6f75 7470          ilx_outp
-000130b0: 7574 203d 2041 6464 5044 4554 6f49 6e74  ut = AddPDEToInt
-000130c0: 6572 6c65 7828 696c 785f 6f62 6a3d 696c  erlex(ilx_obj=il
-000130d0: 785f 6f62 6a2c 206c 6162 656c 3d63 6f6c  x_obj, label=col
-000130e0: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
-000130f0: 7265 6e74 5f74 7570 6c65 5d5b 276c 6162  rent_tuple]['lab
-00013100: 656c 275d 2c0a 2020 2020 2020 2020 2020  el'],.          
-00013110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013120: 2020 2020 2020 6465 6669 6e69 7469 6f6e        definition
-00013130: 3d63 6f6c 756d 6e5f 746f 5f74 6572 6d73  =column_to_terms
-00013140: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
-00013150: 2764 6573 6372 6970 7469 6f6e 275d 2c20  'description'], 
-00013160: 6d69 6e20 3d0a 2020 2020 2020 2020 2020  min =.          
-00013170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013180: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
-00013190: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
-000131a0: 706c 655d 5b27 6d69 6e56 616c 7565 275d  ple]['minValue']
-000131b0: 2c20 6d61 7820 3d0a 2020 2020 2020 2020  , max =.        
+00011d40: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+00011d50: 2020 2020 2020 2020 2020 2020 2065 6c69               eli
+00011d60: 6620 2268 6173 556e 6974 2220 696e 2073  f "hasUnit" in s
+00011d70: 7562 6b65 793a 0a20 2020 2020 2020 2020  ubkey:.         
+00011d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011d90: 2020 2069 6620 280a 2020 2020 2020 2020     if (.        
+00011da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011db0: 2020 2020 2020 2020 2272 6573 706f 6e73          "respons
+00011dc0: 654f 7074 696f 6e73 220a 2020 2020 2020  eOptions".      
+00011dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011de0: 2020 2020 2020 2020 2020 6e6f 7420 696e            not in
+00011df0: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+00011e00: 5b63 7572 7265 6e74 5f74 7570 6c65 5d2e  [current_tuple].
+00011e10: 6b65 7973 2829 0a20 2020 2020 2020 2020  keys().         
+00011e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011e30: 2020 2029 3a0a 2020 2020 2020 2020 2020     ):.          
+00011e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011e50: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
+00011e60: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
+00011e70: 706c 655d 5b22 7265 7370 6f6e 7365 4f70  ple]["responseOp
+00011e80: 7469 6f6e 7322 5d20 3d20 7b7d 0a0a 2020  tions"] = {}..  
+00011e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ea0: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
+00011eb0: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
+00011ec0: 745f 7475 706c 655d 5b22 7265 7370 6f6e  t_tuple]["respon
+00011ed0: 7365 4f70 7469 6f6e 7322 5d5b 0a20 2020  seOptions"][.   
+00011ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ef0: 2020 2020 2020 2020 2020 2020 2022 756e               "un
+00011f00: 6974 436f 6465 220a 2020 2020 2020 2020  itCode".        
+00011f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f20: 2020 2020 5d20 3d20 6a73 6f6e 5f6d 6170      ] = json_map
+00011f30: 5b6a 736f 6e5f 6b65 795b 305d 5d5b 2272  [json_key[0]]["r
+00011f40: 6573 706f 6e73 654f 7074 696f 6e73 225d  esponseOptions"]
+00011f50: 5b22 6861 7355 6e69 7422 5d0a 2020 2020  ["hasUnit"].    
+00011f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f70: 2020 2020 2020 2020 7072 696e 7428 0a20          print(. 
+00011f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f90: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00011fa0: 756e 6974 733a 222c 0a20 2020 2020 2020  units:",.       
+00011fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011fc0: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
+00011fd0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+00011fe0: 5f74 7570 6c65 5d5b 2272 6573 706f 6e73  _tuple]["respons
+00011ff0: 654f 7074 696f 6e73 225d 5b0a 2020 2020  eOptions"][.    
+00012000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012020: 2275 6e69 7443 6f64 6522 0a20 2020 2020  "unitCode".     
+00012030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012040: 2020 2020 2020 2020 2020 205d 2c0a 2020             ],.  
+00012050: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012060: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+00012070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012080: 2020 2020 656c 6966 2022 756e 6974 436f      elif "unitCo
+00012090: 6465 2220 696e 2073 7562 6b65 793a 0a20  de" in subkey:. 
+000120a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000120b0: 2020 2020 2020 2020 2020 2069 6620 280a             if (.
+000120c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000120d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000120e0: 2272 6573 706f 6e73 654f 7074 696f 6e73  "responseOptions
+000120f0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+00012100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012110: 2020 6e6f 7420 696e 2063 6f6c 756d 6e5f    not in column_
+00012120: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+00012130: 5f74 7570 6c65 5d2e 6b65 7973 2829 0a20  _tuple].keys(). 
+00012140: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012150: 2020 2020 2020 2020 2020 2029 3a0a 2020             ):.  
+00012160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012170: 2020 2020 2020 2020 2020 2020 2020 636f                co
+00012180: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
+00012190: 7272 656e 745f 7475 706c 655d 5b22 7265  rrent_tuple]["re
+000121a0: 7370 6f6e 7365 4f70 7469 6f6e 7322 5d20  sponseOptions"] 
+000121b0: 3d20 7b7d 0a0a 2020 2020 2020 2020 2020  = {}..          
+000121c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000121d0: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
+000121e0: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+000121f0: 5b22 7265 7370 6f6e 7365 4f70 7469 6f6e  ["responseOption
+00012200: 7322 5d5b 0a20 2020 2020 2020 2020 2020  s"][.           
+00012210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012220: 2020 2020 2022 756e 6974 436f 6465 220a       "unitCode".
+00012230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012240: 2020 2020 2020 2020 2020 2020 5d20 3d20              ] = 
+00012250: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
+00012260: 795b 305d 5d5b 2272 6573 706f 6e73 654f  y[0]]["responseO
+00012270: 7074 696f 6e73 225d 5b22 756e 6974 436f  ptions"]["unitCo
+00012280: 6465 225d 0a20 2020 2020 2020 2020 2020  de"].           
+00012290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000122a0: 2070 7269 6e74 280a 2020 2020 2020 2020   print(.        
+000122b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000122c0: 2020 2020 2020 2020 2275 6e69 7473 3a22          "units:"
+000122d0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000122e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000122f0: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
+00012300: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+00012310: 5b22 7265 7370 6f6e 7365 4f70 7469 6f6e  ["responseOption
+00012320: 7322 5d5b 0a20 2020 2020 2020 2020 2020  s"][.           
+00012330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012340: 2020 2020 2020 2020 2022 756e 6974 436f           "unitCo
+00012350: 6465 220a 2020 2020 2020 2020 2020 2020  de".            
+00012360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012370: 2020 2020 5d2c 0a20 2020 2020 2020 2020      ],.         
+00012380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012390: 2020 2029 0a0a 2020 2020 2020 2020 2020     )..          
+000123a0: 2020 2020 2020 6966 2022 6c65 7665 6c73        if "levels
+000123b0: 2220 696e 206a 736f 6e5f 6d61 705b 6a73  " in json_map[js
+000123c0: 6f6e 5f6b 6579 5b30 5d5d 3a0a 2020 2020  on_key[0]]:.    
+000123d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000123e0: 2320 7570 6772 6164 6520 276c 6576 656c  # upgrade 'level
+000123f0: 7327 2074 6f20 2772 6573 706f 6e73 654f  s' to 'responseO
+00012400: 7074 696f 6e73 272d 3e27 6368 6f69 6365  ptions'->'choice
+00012410: 7327 0a20 2020 2020 2020 2020 2020 2020  s'.             
+00012420: 2020 2020 2020 2069 6620 2272 6573 706f         if "respo
+00012430: 6e73 654f 7074 696f 6e73 2220 6e6f 7420  nseOptions" not 
+00012440: 696e 2063 6f6c 756d 6e5f 746f 5f74 6572  in column_to_ter
+00012450: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
+00012460: 5d2e 6b65 7973 2829 3a0a 2020 2020 2020  ].keys():.      
+00012470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012480: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
+00012490: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+000124a0: 5b22 7265 7370 6f6e 7365 4f70 7469 6f6e  ["responseOption
+000124b0: 7322 5d20 3d20 7b7d 0a20 2020 2020 2020  s"] = {}.       
+000124c0: 2020 2020 2020 2020 2020 2020 2063 6f6c               col
+000124d0: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
+000124e0: 7265 6e74 5f74 7570 6c65 5d5b 2272 6573  rent_tuple]["res
+000124f0: 706f 6e73 654f 7074 696f 6e73 225d 5b0a  ponseOptions"][.
+00012500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012510: 2020 2020 2020 2020 2263 686f 6963 6573          "choices
+00012520: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+00012530: 2020 2020 2020 5d20 3d20 6a73 6f6e 5f6d        ] = json_m
+00012540: 6170 5b6a 736f 6e5f 6b65 795b 305d 5d5b  ap[json_key[0]][
+00012550: 226c 6576 656c 7322 5d0a 2020 2020 2020  "levels"].      
+00012560: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+00012570: 696e 7428 0a20 2020 2020 2020 2020 2020  int(.           
+00012580: 2020 2020 2020 2020 2020 2020 2022 6368               "ch
+00012590: 6f69 6365 733a 222c 0a20 2020 2020 2020  oices:",.       
+000125a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000125b0: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+000125c0: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+000125d0: 2272 6573 706f 6e73 654f 7074 696f 6e73  "responseOptions
+000125e0: 225d 5b22 6368 6f69 6365 7322 5d2c 0a20  "]["choices"],. 
+000125f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012600: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+00012610: 2020 2020 2065 6c69 6620 224c 6576 656c       elif "Level
+00012620: 7322 2069 6e20 6a73 6f6e 5f6d 6170 5b6a  s" in json_map[j
+00012630: 736f 6e5f 6b65 795b 305d 5d3a 0a20 2020  son_key[0]]:.   
+00012640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012650: 2023 2075 7067 7261 6465 2027 6c65 7665   # upgrade 'leve
+00012660: 6c73 2720 746f 2027 7265 7370 6f6e 7365  ls' to 'response
+00012670: 4f70 7469 6f6e 7327 2d3e 2763 686f 6963  Options'->'choic
+00012680: 6573 270a 2020 2020 2020 2020 2020 2020  es'.            
+00012690: 2020 2020 2020 2020 6966 2022 7265 7370          if "resp
+000126a0: 6f6e 7365 4f70 7469 6f6e 7322 206e 6f74  onseOptions" not
+000126b0: 2069 6e20 636f 6c75 6d6e 5f74 6f5f 7465   in column_to_te
+000126c0: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
+000126d0: 655d 2e6b 6579 7328 293a 0a20 2020 2020  e].keys():.     
+000126e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000126f0: 2020 2063 6f6c 756d 6e5f 746f 5f74 6572     column_to_ter
+00012700: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
+00012710: 5d5b 2272 6573 706f 6e73 654f 7074 696f  ]["responseOptio
+00012720: 6e73 225d 203d 207b 7d0a 2020 2020 2020  ns"] = {}.      
+00012730: 2020 2020 2020 2020 2020 2020 2020 636f                co
+00012740: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
+00012750: 7272 656e 745f 7475 706c 655d 5b22 7265  rrent_tuple]["re
+00012760: 7370 6f6e 7365 4f70 7469 6f6e 7322 5d5b  sponseOptions"][
+00012770: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012780: 2020 2020 2020 2020 2022 6368 6f69 6365           "choice
+00012790: 7322 0a20 2020 2020 2020 2020 2020 2020  s".             
+000127a0: 2020 2020 2020 205d 203d 206a 736f 6e5f         ] = json_
+000127b0: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
+000127c0: 5b22 4c65 7665 6c73 225d 0a20 2020 2020  ["Levels"].     
+000127d0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+000127e0: 7269 6e74 280a 2020 2020 2020 2020 2020  rint(.          
+000127f0: 2020 2020 2020 2020 2020 2020 2020 226c                "l
+00012800: 6576 656c 733a 222c 0a20 2020 2020 2020  evels:",.       
+00012810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012820: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+00012830: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+00012840: 2272 6573 706f 6e73 654f 7074 696f 6e73  "responseOptions
+00012850: 225d 5b22 6368 6f69 6365 7322 5d2c 0a20  "]["choices"],. 
+00012860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012870: 2020 2029 0a0a 2020 2020 2020 2020 2020     )..          
+00012880: 2020 2020 2020 6966 2022 7661 6c75 6554        if "valueT
+00012890: 7970 6522 2069 6e20 6a73 6f6e 5f6d 6170  ype" in json_map
+000128a0: 5b6a 736f 6e5f 6b65 795b 305d 5d3a 0a20  [json_key[0]]:. 
+000128b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000128c0: 2020 2023 2075 7067 7261 6465 2027 7661     # upgrade 'va
+000128d0: 6c75 6554 7970 6527 2074 6f20 2772 6573  lueType' to 'res
+000128e0: 706f 6e73 654f 7074 696f 6e73 272d 3e27  ponseOptions'->'
+000128f0: 7661 6c75 6554 7970 650a 2020 2020 2020  valueType.      
+00012900: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00012910: 2022 7265 7370 6f6e 7365 4f70 7469 6f6e   "responseOption
+00012920: 7322 206e 6f74 2069 6e20 636f 6c75 6d6e  s" not in column
+00012930: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
+00012940: 745f 7475 706c 655d 2e6b 6579 7328 293a  t_tuple].keys():
+00012950: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012960: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
+00012970: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+00012980: 5f74 7570 6c65 5d5b 2272 6573 706f 6e73  _tuple]["respons
+00012990: 654f 7074 696f 6e73 225d 203d 207b 7d0a  eOptions"] = {}.
+000129a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000129b0: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
+000129c0: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
+000129d0: 655d 5b22 7265 7370 6f6e 7365 4f70 7469  e]["responseOpti
+000129e0: 6f6e 7322 5d5b 0a20 2020 2020 2020 2020  ons"][.         
+000129f0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00012a00: 7661 6c75 6554 7970 6522 0a20 2020 2020  valueType".     
+00012a10: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
+00012a20: 203d 206a 736f 6e5f 6d61 705b 6a73 6f6e   = json_map[json
+00012a30: 5f6b 6579 5b30 5d5d 5b22 7661 6c75 6554  _key[0]]["valueT
+00012a40: 7970 6522 5d0a 2020 2020 2020 2020 2020  ype"].          
+00012a50: 2020 2020 2020 2020 2020 7072 696e 7428            print(
+00012a60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012a70: 2020 2020 2020 2020 2022 7661 6c75 6554           "valueT
+00012a80: 7970 653a 222c 0a20 2020 2020 2020 2020  ype:",.         
+00012a90: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00012aa0: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
+00012ab0: 7572 7265 6e74 5f74 7570 6c65 5d5b 2272  urrent_tuple]["r
+00012ac0: 6573 706f 6e73 654f 7074 696f 6e73 225d  esponseOptions"]
+00012ad0: 5b22 7661 6c75 6554 7970 6522 5d2c 0a20  ["valueType"],. 
+00012ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012af0: 2020 2029 0a0a 2020 2020 2020 2020 2020     )..          
+00012b00: 2020 2020 2020 6966 2022 6d69 6e56 616c        if "minVal
+00012b10: 7565 2220 696e 206a 736f 6e5f 6d61 705b  ue" in json_map[
+00012b20: 6a73 6f6e 5f6b 6579 5b30 5d5d 3a0a 2020  json_key[0]]:.  
+00012b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012b40: 2020 2320 7570 6772 6164 6520 276d 696e    # upgrade 'min
+00012b50: 5661 6c75 6527 2074 6f20 2772 6573 706f  Value' to 'respo
+00012b60: 6e73 654f 7074 696f 6e73 272d 3e27 6d69  nseOptions'->'mi
+00012b70: 6e56 616c 7565 0a20 2020 2020 2020 2020  nValue.         
+00012b80: 2020 2020 2020 2020 2020 2069 6620 2272             if "r
+00012b90: 6573 706f 6e73 654f 7074 696f 6e73 2220  esponseOptions" 
+00012ba0: 6e6f 7420 696e 2063 6f6c 756d 6e5f 746f  not in column_to
+00012bb0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
+00012bc0: 7570 6c65 5d2e 6b65 7973 2829 3a0a 2020  uple].keys():.  
+00012bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012be0: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
+00012bf0: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
+00012c00: 706c 655d 5b22 7265 7370 6f6e 7365 4f70  ple]["responseOp
+00012c10: 7469 6f6e 7322 5d20 3d20 7b7d 0a20 2020  tions"] = {}.   
+00012c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012c30: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+00012c40: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+00012c50: 2272 6573 706f 6e73 654f 7074 696f 6e73  "responseOptions
+00012c60: 225d 5b0a 2020 2020 2020 2020 2020 2020  "][.            
+00012c70: 2020 2020 2020 2020 2020 2020 226d 696e              "min
+00012c80: 5661 6c75 6522 0a20 2020 2020 2020 2020  Value".         
+00012c90: 2020 2020 2020 2020 2020 205d 203d 206a             ] = j
+00012ca0: 736f 6e5f 6d61 705b 6a73 6f6e 5f6b 6579  son_map[json_key
+00012cb0: 5b30 5d5d 5b22 6d69 6e56 616c 7565 225d  [0]]["minValue"]
+00012cc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012cd0: 2020 2020 2070 7269 6e74 280a 2020 2020       print(.    
+00012ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012cf0: 2020 2020 226d 696e 5661 6c75 653a 222c      "minValue:",
+00012d00: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012d10: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
+00012d20: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+00012d30: 5f74 7570 6c65 5d5b 2272 6573 706f 6e73  _tuple]["respons
+00012d40: 654f 7074 696f 6e73 225d 5b22 6d69 6e56  eOptions"]["minV
+00012d50: 616c 7565 225d 2c0a 2020 2020 2020 2020  alue"],.        
+00012d60: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00012d70: 2020 2020 2020 2020 2020 2020 2020 656c                el
+00012d80: 6966 2022 6d69 6e69 6d75 6d56 616c 7565  if "minimumValue
+00012d90: 2220 696e 206a 736f 6e5f 6d61 705b 6a73  " in json_map[js
+00012da0: 6f6e 5f6b 6579 5b30 5d5d 3a0a 2020 2020  on_key[0]]:.    
+00012db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012dc0: 2320 7570 6772 6164 6520 276d 696e 5661  # upgrade 'minVa
+00012dd0: 6c75 6527 2074 6f20 2772 6573 706f 6e73  lue' to 'respons
+00012de0: 654f 7074 696f 6e73 272d 3e27 6d69 6e56  eOptions'->'minV
+00012df0: 616c 7565 0a20 2020 2020 2020 2020 2020  alue.           
+00012e00: 2020 2020 2020 2020 2069 6620 2272 6573           if "res
+00012e10: 706f 6e73 654f 7074 696f 6e73 2220 6e6f  ponseOptions" no
+00012e20: 7420 696e 2063 6f6c 756d 6e5f 746f 5f74  t in column_to_t
+00012e30: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
+00012e40: 6c65 5d2e 6b65 7973 2829 3a0a 2020 2020  le].keys():.    
+00012e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012e60: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
+00012e70: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
+00012e80: 655d 5b22 7265 7370 6f6e 7365 4f70 7469  e]["responseOpti
+00012e90: 6f6e 7322 5d20 3d20 7b7d 0a20 2020 2020  ons"] = {}.     
+00012ea0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00012eb0: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
+00012ec0: 7572 7265 6e74 5f74 7570 6c65 5d5b 2272  urrent_tuple]["r
+00012ed0: 6573 706f 6e73 654f 7074 696f 6e73 225d  esponseOptions"]
+00012ee0: 5b0a 2020 2020 2020 2020 2020 2020 2020  [.              
+00012ef0: 2020 2020 2020 2020 2020 226d 696e 5661            "minVa
+00012f00: 6c75 6522 0a20 2020 2020 2020 2020 2020  lue".           
+00012f10: 2020 2020 2020 2020 205d 203d 206a 736f           ] = jso
+00012f20: 6e5f 6d61 705b 6a73 6f6e 5f6b 6579 5b30  n_map[json_key[0
+00012f30: 5d5d 5b22 6d69 6e69 6d75 6d56 616c 7565  ]]["minimumValue
+00012f40: 225d 0a20 2020 2020 2020 2020 2020 2020  "].             
+00012f50: 2020 2020 2020 2070 7269 6e74 280a 2020         print(.  
+00012f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012f70: 2020 2020 2020 226d 696e 5661 6c75 653a        "minValue:
+00012f80: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00012f90: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
+00012fa0: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
+00012fb0: 6e74 5f74 7570 6c65 5d5b 2272 6573 706f  nt_tuple]["respo
+00012fc0: 6e73 654f 7074 696f 6e73 225d 5b22 6d69  nseOptions"]["mi
+00012fd0: 6e56 616c 7565 225d 2c0a 2020 2020 2020  nValue"],.      
+00012fe0: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+00012ff0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00013000: 2069 6620 226d 6178 5661 6c75 6522 2069   if "maxValue" i
+00013010: 6e20 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f  n json_map[json_
+00013020: 6b65 795b 305d 5d3a 0a20 2020 2020 2020  key[0]]:.       
+00013030: 2020 2020 2020 2020 2020 2020 2023 2075               # u
+00013040: 7067 7261 6465 2027 6d61 7856 616c 7565  pgrade 'maxValue
+00013050: 2720 746f 2027 7265 7370 6f6e 7365 4f70  ' to 'responseOp
+00013060: 7469 6f6e 7327 2d3e 276d 6178 5661 6c75  tions'->'maxValu
+00013070: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
+00013080: 2020 2020 2020 6966 2022 7265 7370 6f6e        if "respon
+00013090: 7365 4f70 7469 6f6e 7322 206e 6f74 2069  seOptions" not i
+000130a0: 6e20 636f 6c75 6d6e 5f74 6f5f 7465 726d  n column_to_term
+000130b0: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+000130c0: 2e6b 6579 7328 293a 0a20 2020 2020 2020  .keys():.       
+000130d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000130e0: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+000130f0: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+00013100: 2272 6573 706f 6e73 654f 7074 696f 6e73  "responseOptions
+00013110: 225d 203d 207b 7d0a 2020 2020 2020 2020  "] = {}.        
+00013120: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
+00013130: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+00013140: 656e 745f 7475 706c 655d 5b22 7265 7370  ent_tuple]["resp
+00013150: 6f6e 7365 4f70 7469 6f6e 7322 5d5b 0a20  onseOptions"][. 
+00013160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013170: 2020 2020 2020 2022 6d61 7856 616c 7565         "maxValue
+00013180: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+00013190: 2020 2020 2020 5d20 3d20 6a73 6f6e 5f6d        ] = json_m
+000131a0: 6170 5b6a 736f 6e5f 6b65 795b 305d 5d5b  ap[json_key[0]][
+000131b0: 226d 6178 5661 6c75 6522 5d0a 2020 2020  "maxValue"].    
 000131c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000131d0: 2020 2020 2020 2020 636f 6c75 6d6e 5f74          column_t
-000131e0: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
-000131f0: 7475 706c 655d 5b27 6d61 7856 616c 7565  tuple]['maxValue
-00013200: 275d 2c20 756e 6974 7320 3d0a 2020 2020  '], units =.    
-00013210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013220: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
-00013230: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
-00013240: 656e 745f 7475 706c 655d 5b27 6861 7355  ent_tuple]['hasU
-00013250: 6e69 7427 5d2c 2064 6174 6174 7970 653d  nit'], datatype=
-00013260: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00013270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013280: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
-00013290: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
-000132a0: 2776 616c 7565 5479 7065 275d 2c20 6973  'valueType'], is
-000132b0: 6162 6f75 743d 0a20 2020 2020 2020 2020  about=.         
-000132c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000132d0: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
-000132e0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-000132f0: 7570 6c65 5d5b 2769 7341 626f 7574 275d  uple]['isAbout']
-00013300: 2c20 6361 7465 676f 7279 6d61 7070 696e  , categorymappin
-00013310: 6773 3d0a 2020 2020 2020 2020 2020 2020  gs=.            
-00013320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013330: 2020 2020 6a73 6f6e 2e64 756d 7073 2863      json.dumps(c
-00013340: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
-00013350: 7572 7265 6e74 5f74 7570 6c65 5d5b 276c  urrent_tuple]['l
-00013360: 6576 656c 7327 5d29 290a 2020 2020 2020  evels'])).      
-00013370: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-00013380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013390: 2020 2020 696c 785f 6f75 7470 7574 203d      ilx_output =
-000133a0: 2041 6464 5044 4554 6f49 6e74 6572 6c65   AddPDEToInterle
-000133b0: 7828 696c 785f 6f62 6a3d 696c 785f 6f62  x(ilx_obj=ilx_ob
-000133c0: 6a2c 206c 6162 656c 3d63 6f6c 756d 6e5f  j, label=column_
-000133d0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-000133e0: 5f74 7570 6c65 5d5b 276c 6162 656c 275d  _tuple]['label']
-000133f0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000131d0: 7072 696e 7428 0a20 2020 2020 2020 2020  print(.         
+000131e0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000131f0: 6d61 7856 616c 7565 3a22 2c0a 2020 2020  maxValue:",.    
+00013200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013210: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
+00013220: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
+00013230: 655d 5b22 7265 7370 6f6e 7365 4f70 7469  e]["responseOpti
+00013240: 6f6e 7322 5d5b 226d 6178 5661 6c75 6522  ons"]["maxValue"
+00013250: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00013260: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00013270: 2020 2020 2020 2020 2065 6c69 6620 226d           elif "m
+00013280: 6178 696d 756d 5661 6c75 6522 2069 6e20  aximumValue" in 
+00013290: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
+000132a0: 795b 305d 5d3a 0a20 2020 2020 2020 2020  y[0]]:.         
+000132b0: 2020 2020 2020 2020 2020 2023 2075 7067             # upg
+000132c0: 7261 6465 2027 6d61 7856 616c 7565 2720  rade 'maxValue' 
+000132d0: 746f 2027 7265 7370 6f6e 7365 4f70 7469  to 'responseOpti
+000132e0: 6f6e 7327 2d3e 276d 6178 5661 6c75 650a  ons'->'maxValue.
+000132f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013300: 2020 2020 6966 2022 7265 7370 6f6e 7365      if "response
+00013310: 4f70 7469 6f6e 7322 206e 6f74 2069 6e20  Options" not in 
+00013320: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
+00013330: 6375 7272 656e 745f 7475 706c 655d 2e6b  current_tuple].k
+00013340: 6579 7328 293a 0a20 2020 2020 2020 2020  eys():.         
+00013350: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00013360: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
+00013370: 7572 7265 6e74 5f74 7570 6c65 5d5b 2272  urrent_tuple]["r
+00013380: 6573 706f 6e73 654f 7074 696f 6e73 225d  esponseOptions"]
+00013390: 203d 207b 7d0a 2020 2020 2020 2020 2020   = {}.          
+000133a0: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
+000133b0: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
+000133c0: 745f 7475 706c 655d 5b22 7265 7370 6f6e  t_tuple]["respon
+000133d0: 7365 4f70 7469 6f6e 7322 5d5b 0a20 2020  seOptions"][.   
+000133e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000133f0: 2020 2020 2022 6d61 7856 616c 7565 220a       "maxValue".
 00013400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013410: 2020 6465 6669 6e69 7469 6f6e 3d63 6f6c    definition=col
-00013420: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
-00013430: 7265 6e74 5f74 7570 6c65 5d5b 2764 6573  rent_tuple]['des
-00013440: 6372 6970 7469 6f6e 275d 2c20 6d69 6e20  cription'], min 
-00013450: 3d0a 2020 2020 2020 2020 2020 2020 2020  =.              
+00013410: 2020 2020 5d20 3d20 6a73 6f6e 5f6d 6170      ] = json_map
+00013420: 5b6a 736f 6e5f 6b65 795b 305d 5d5b 226d  [json_key[0]]["m
+00013430: 6178 696d 756d 5661 6c75 6522 5d0a 2020  aximumValue"].  
+00013440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013450: 2020 7072 696e 7428 0a20 2020 2020 2020    print(.       
 00013460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013470: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
-00013480: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-00013490: 5b27 6d69 6e56 616c 7565 275d 2c20 6d61  ['minValue'], ma
-000134a0: 7820 3d0a 2020 2020 2020 2020 2020 2020  x =.            
-000134b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000134c0: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
-000134d0: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
-000134e0: 655d 5b27 6d61 7856 616c 7565 275d 2c20  e]['maxValue'], 
-000134f0: 756e 6974 7320 3d0a 2020 2020 2020 2020  units =.        
-00013500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013510: 2020 2020 2020 2020 636f 6c75 6d6e 5f74          column_t
-00013520: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
-00013530: 7475 706c 655d 5b27 6861 7355 6e69 7427  tuple]['hasUnit'
-00013540: 5d2c 2064 6174 6174 7970 653d 0a20 2020  ], datatype=.   
-00013550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013560: 2020 2020 2020 2020 2020 2020 2063 6f6c               col
-00013570: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
-00013580: 7265 6e74 5f74 7570 6c65 5d5b 2776 616c  rent_tuple]['val
-00013590: 7565 5479 7065 275d 2c20 6361 7465 676f  ueType'], catego
-000135a0: 7279 6d61 7070 696e 6773 3d0a 2020 2020  rymappings=.    
-000135b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000135c0: 2020 2020 2020 2020 2020 2020 6a73 6f6e              json
-000135d0: 2e64 756d 7073 2863 6f6c 756d 6e5f 746f  .dumps(column_to
-000135e0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-000135f0: 7570 6c65 5d5b 276c 6576 656c 7327 5d29  uple]['levels'])
-00013600: 290a 0a20 2020 2020 2020 2020 2020 2065  )..            e
-00013610: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00013620: 2020 2020 2069 6620 2769 7341 626f 7574       if 'isAbout
-00013630: 2720 696e 2063 6f6c 756d 6e5f 746f 5f74  ' in column_to_t
-00013640: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
-00013650: 6c65 5d3a 0a20 2020 2020 2020 2020 2020  le]:.           
-00013660: 2020 2020 2020 2020 2069 6c78 5f6f 7574           ilx_out
-00013670: 7075 7420 3d20 4164 6450 4445 546f 496e  put = AddPDEToIn
-00013680: 7465 726c 6578 2869 6c78 5f6f 626a 3d69  terlex(ilx_obj=i
-00013690: 6c78 5f6f 626a 2c20 6c61 6265 6c3d 636f  lx_obj, label=co
-000136a0: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
-000136b0: 7272 656e 745f 7475 706c 655d 5b27 6c61  rrent_tuple]['la
-000136c0: 6265 6c27 5d2c 0a20 2020 2020 2020 2020  bel'],.         
+00013470: 2022 6d61 7856 616c 7565 3a22 2c0a 2020   "maxValue:",.  
+00013480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013490: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
+000134a0: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
+000134b0: 706c 655d 5b22 7265 7370 6f6e 7365 4f70  ple]["responseOp
+000134c0: 7469 6f6e 7322 5d5b 226d 6178 5661 6c75  tions"]["maxValu
+000134d0: 6522 5d2c 0a20 2020 2020 2020 2020 2020  e"],.           
+000134e0: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+000134f0: 2020 2020 2020 2020 2020 2069 6620 2268             if "h
+00013500: 6173 556e 6974 2220 696e 206a 736f 6e5f  asUnit" in json_
+00013510: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
+00013520: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00013530: 2020 2020 2020 2320 7570 6772 6164 6520        # upgrade 
+00013540: 2768 6173 556e 6974 2720 746f 2027 7265  'hasUnit' to 're
+00013550: 7370 6f6e 7365 4f70 7469 6f6e 7327 2d3e  sponseOptions'->
+00013560: 2775 6e69 7443 6f64 650a 2020 2020 2020  'unitCode.      
+00013570: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00013580: 2022 7265 7370 6f6e 7365 4f70 7469 6f6e   "responseOption
+00013590: 7322 206e 6f74 2069 6e20 636f 6c75 6d6e  s" not in column
+000135a0: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
+000135b0: 745f 7475 706c 655d 2e6b 6579 7328 293a  t_tuple].keys():
+000135c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000135d0: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
+000135e0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+000135f0: 5f74 7570 6c65 5d5b 2272 6573 706f 6e73  _tuple]["respons
+00013600: 654f 7074 696f 6e73 225d 203d 207b 7d0a  eOptions"] = {}.
+00013610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013620: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
+00013630: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
+00013640: 655d 5b22 7265 7370 6f6e 7365 4f70 7469  e]["responseOpti
+00013650: 6f6e 7322 5d5b 0a20 2020 2020 2020 2020  ons"][.         
+00013660: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00013670: 756e 6974 436f 6465 220a 2020 2020 2020  unitCode".      
+00013680: 2020 2020 2020 2020 2020 2020 2020 5d20                ] 
+00013690: 3d20 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f  = json_map[json_
+000136a0: 6b65 795b 305d 5d5b 2268 6173 556e 6974  key[0]]["hasUnit
+000136b0: 225d 0a20 2020 2020 2020 2020 2020 2020  "].             
+000136c0: 2020 2020 2020 2070 7269 6e74 280a 2020         print(.  
 000136d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000136e0: 2020 2020 2020 2064 6566 696e 6974 696f         definitio
-000136f0: 6e3d 636f 6c75 6d6e 5f74 6f5f 7465 726d  n=column_to_term
-00013700: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-00013710: 5b27 6465 7363 7269 7074 696f 6e27 5d2c  ['description'],
-00013720: 206d 696e 203d 0a20 2020 2020 2020 2020   min =.         
-00013730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013740: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
-00013750: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-00013760: 7570 6c65 5d5b 276d 696e 5661 6c75 6527  uple]['minValue'
-00013770: 5d2c 206d 6178 203d 0a20 2020 2020 2020  ], max =.       
-00013780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013790: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
-000137a0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-000137b0: 5f74 7570 6c65 5d5b 276d 6178 5661 6c75  _tuple]['maxValu
-000137c0: 6527 5d2c 2075 6e69 7473 203d 0a20 2020  e'], units =.   
-000137d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000137e0: 2020 2020 2020 2020 2020 2020 2063 6f6c               col
-000137f0: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
-00013800: 7265 6e74 5f74 7570 6c65 5d5b 2768 6173  rent_tuple]['has
-00013810: 556e 6974 275d 2c20 6461 7461 7479 7065  Unit'], datatype
-00013820: 3d0a 2020 2020 2020 2020 2020 2020 2020  =.              
-00013830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013840: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
-00013850: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-00013860: 5b27 7661 6c75 6554 7970 6527 5d2c 2069  ['valueType'], i
-00013870: 7361 626f 7574 203d 0a20 2020 2020 2020  sabout =.       
-00013880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013890: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
-000138a0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
-000138b0: 5f74 7570 6c65 5d5b 2769 7341 626f 7574  _tuple]['isAbout
-000138c0: 275d 290a 2020 2020 2020 2020 2020 2020  ']).            
-000138d0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-000138e0: 2020 2020 2020 2020 2020 2020 2020 696c                il
-000138f0: 785f 6f75 7470 7574 203d 2041 6464 5044  x_output = AddPD
-00013900: 4554 6f49 6e74 6572 6c65 7828 696c 785f  EToInterlex(ilx_
-00013910: 6f62 6a3d 696c 785f 6f62 6a2c 206c 6162  obj=ilx_obj, lab
-00013920: 656c 3d63 6f6c 756d 6e5f 746f 5f74 6572  el=column_to_ter
-00013930: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
-00013940: 5d5b 276c 6162 656c 275d 2c0a 2020 2020  ]['label'],.    
-00013950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013960: 2020 2020 2020 2020 2020 2020 6465 6669              defi
-00013970: 6e69 7469 6f6e 3d63 6f6c 756d 6e5f 746f  nition=column_to
-00013980: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-00013990: 7570 6c65 5d5b 2764 6573 6372 6970 7469  uple]['descripti
-000139a0: 6f6e 275d 2c20 6d69 6e20 3d0a 2020 2020  on'], min =.    
-000139b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000139c0: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
-000139d0: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
-000139e0: 656e 745f 7475 706c 655d 5b27 6d69 6e56  ent_tuple]['minV
-000139f0: 616c 7565 275d 2c20 6d61 7820 3d0a 2020  alue'], max =.  
-00013a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013a10: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00013a20: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
-00013a30: 7272 656e 745f 7475 706c 655d 5b27 6d61  rrent_tuple]['ma
-00013a40: 7856 616c 7565 275d 2c20 756e 6974 7320  xValue'], units 
-00013a50: 3d0a 2020 2020 2020 2020 2020 2020 2020  =.              
-00013a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013a70: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
-00013a80: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-00013a90: 5b27 6861 7355 6e69 7427 5d2c 2064 6174  ['hasUnit'], dat
-00013aa0: 6174 7970 653d 0a20 2020 2020 2020 2020  atype=.         
-00013ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013ac0: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
-00013ad0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
-00013ae0: 7570 6c65 5d5b 2776 616c 7565 5479 7065  uple]['valueType
-00013af0: 275d 290a 0a20 2020 2020 2020 2020 2020  '])..           
-00013b00: 2023 206e 6f77 2073 746f 7265 2074 6865   # now store the
-00013b10: 2075 726c 2066 726f 6d20 496e 7465 726c   url from Interl
-00013b20: 6578 2066 6f72 206e 6577 2070 6572 736f  ex for new perso
-00013b30: 6e61 6c20 6461 7461 2065 6c65 6d65 6e74  nal data element
-00013b40: 2069 6e20 636f 6c75 6d6e 5f74 6f5f 7465   in column_to_te
-00013b50: 726d 7320 616e 6e6f 7461 7469 6f6e 0a20  rms annotation. 
-00013b60: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
-00013b70: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
-00013b80: 6e74 5f74 7570 6c65 5d5b 2775 726c 275d  nt_tuple]['url']
-00013b90: 203d 2069 6c78 5f6f 7574 7075 742e 6972   = ilx_output.ir
-00013ba0: 690a 2020 2020 2020 2020 6578 6365 7074  i.        except
-00013bb0: 2045 7863 6570 7469 6f6e 2061 7320 653a   Exception as e:
-00013bc0: 0a20 2020 2020 2020 2020 2020 2070 7269  .            pri
-00013bd0: 6e74 2822 5741 524e 494e 473a 2057 4950  nt("WARNING: WIP
-00013be0: 3a20 4461 7461 2065 6c65 6d65 6e74 206e  : Data element n
-00013bf0: 6f74 2073 7562 6d69 7474 6564 2074 6f20  ot submitted to 
-00013c00: 496e 7465 724c 6578 2e20 2022 290a 2020  InterLex.  ").  
-00013c10: 2020 2320 7772 6974 6520 616e 6e6f 7461    # write annota
-00013c20: 7469 6f6e 7320 746f 206a 736f 6e20 6669  tions to json fi
-00013c30: 6c65 2073 696e 6365 2064 6174 6120 656c  le since data el
-00013c40: 656d 656e 7420 616e 6e6f 7461 7469 6f6e  ement annotation
-00013c50: 7320 6172 6520 636f 6d70 6c65 7465 0a20  s are complete. 
-00013c60: 2020 2077 7269 7465 5f6a 736f 6e5f 6d61     write_json_ma
-00013c70: 7070 696e 675f 6669 6c65 2863 6f6c 756d  pping_file(colum
-00013c80: 6e5f 746f 5f74 6572 6d73 2c20 6f75 7470  n_to_terms, outp
-00013c90: 7574 5f66 696c 652c 2062 6964 7329 0a0a  ut_file, bids)..
-00013ca0: 2020 2020 2320 6765 7420 4344 4573 2066      # get CDEs f
-00013cb0: 6f72 2064 6174 6120 6469 6374 6f6e 6172  or data dictonar
-00013cc0: 7920 616e 6420 4e49 444d 2067 7261 7068  y and NIDM graph
-00013cd0: 2065 6e74 6974 7920 6f66 2064 6174 610a   entity of data.
-00013ce0: 2020 2020 6364 6520 3d20 4444 5f74 6f5f      cde = DD_to_
-00013cf0: 6e69 646d 2863 6f6c 756d 6e5f 746f 5f74  nidm(column_to_t
-00013d00: 6572 6d73 2c64 6174 6173 6574 5f69 6465  erms,dataset_ide
-00013d10: 6e74 6966 6965 723d 6461 7461 7365 745f  ntifier=dataset_
-00013d20: 6964 656e 7469 6669 6572 290a 0a20 2020  identifier)..   
-00013d30: 2072 6574 7572 6e20 5b63 6f6c 756d 6e5f   return [column_
-00013d40: 746f 5f74 6572 6d73 2c20 6364 655d 0a0a  to_terms, cde]..
-00013d50: 6465 6620 7772 6974 655f 6a73 6f6e 5f6d  def write_json_m
-00013d60: 6170 7069 6e67 5f66 696c 6528 736f 7572  apping_file(sour
-00013d70: 6365 5f76 6172 6961 626c 655f 616e 6e6f  ce_variable_anno
-00013d80: 7461 7469 6f6e 732c 206f 7574 7075 745f  tations, output_
-00013d90: 6669 6c65 2c20 6269 6473 3d46 616c 7365  file, bids=False
-00013da0: 293a 0a20 2020 2023 2069 6620 7765 2077  ):.    # if we w
-00013db0: 616e 7420 6120 6269 6473 2d73 7479 6c65  ant a bids-style
-00013dc0: 206a 736f 6e20 7369 6465 6361 7220 6669   json sidecar fi
-00013dd0: 6c65 0a20 2020 2069 6620 6269 6473 3a0a  le.    if bids:.
-00013de0: 2020 2020 2020 2020 2320 636f 6e76 6572          # conver
-00013df0: 7420 746f 2073 696d 706c 6520 6b65 7973  t to simple keys
-00013e00: 0a20 2020 2020 2020 2074 656d 705f 6469  .        temp_di
-00013e10: 6374 203d 2074 7570 6c65 4b65 7973 546f  ct = tupleKeysTo
-00013e20: 5369 6d70 6c65 4b65 7973 2873 6f75 7263  SimpleKeys(sourc
-00013e30: 655f 7661 7269 6162 6c65 5f61 6e6e 6f74  e_variable_annot
-00013e40: 6174 696f 6e73 290a 0a20 2020 2020 2020  ations)..       
-00013e50: 206e 6577 5f64 6963 7420 3d20 7b7d 0a20   new_dict = {}. 
-00013e60: 2020 2020 2020 2023 2072 656d 6f76 6520         # remove 
-00013e70: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
-00013e80: 2720 616e 6420 6d6f 7665 2027 6368 6f69  ' and move 'choi
-00013e90: 6365 7327 2074 6f20 276c 6576 656c 7327  ces' to 'levels'
-00013ea0: 206b 6579 0a20 2020 2020 2020 2066 6f72   key.        for
-00013eb0: 206b 6579 2c76 616c 7565 2069 6e20 7465   key,value in te
-00013ec0: 6d70 5f64 6963 742e 6974 656d 7328 293a  mp_dict.items():
-00013ed0: 0a20 2020 2020 2020 2020 2020 206e 6577  .            new
-00013ee0: 5f64 6963 745b 6b65 795d 203d 207b 7d0a  _dict[key] = {}.
-00013ef0: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-00013f00: 7375 626b 6579 2c73 7562 7661 6c75 6520  subkey,subvalue 
-00013f10: 696e 2074 656d 705f 6469 6374 5b6b 6579  in temp_dict[key
-00013f20: 5d2e 6974 656d 7328 293a 0a20 2020 2020  ].items():.     
-00013f30: 2020 2020 2020 2020 2020 2069 6620 7375             if su
-00013f40: 626b 6579 203d 3d20 2772 6573 706f 6e73  bkey == 'respons
-00013f50: 654f 7074 696f 6e73 273a 0a20 2020 2020  eOptions':.     
-00013f60: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00013f70: 6f72 2073 7562 6b65 7932 2c73 7562 7661  or subkey2,subva
-00013f80: 6c75 6532 2069 6e20 7465 6d70 5f64 6963  lue2 in temp_dic
-00013f90: 745b 6b65 795d 5b27 7265 7370 6f6e 7365  t[key]['response
-00013fa0: 4f70 7469 6f6e 7327 5d2e 6974 656d 7328  Options'].items(
-00013fb0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00013fc0: 2020 2020 2020 2020 2020 2069 6620 7375             if su
-00013fd0: 626b 6579 3220 3d3d 2022 6368 6f69 6365  bkey2 == "choice
-00013fe0: 7322 3a0a 2020 2020 2020 2020 2020 2020  s":.            
-00013ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014000: 6e65 775f 6469 6374 5b6b 6579 5d5b 226c  new_dict[key]["l
-00014010: 6576 656c 7322 5d20 3d20 7375 6276 616c  evels"] = subval
-00014020: 7565 320a 2020 2020 2020 2020 2020 2020  ue2.            
-00014030: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00014040: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00014050: 2020 2020 2020 2020 2020 2020 2020 6e65                ne
-00014060: 775f 6469 6374 5b6b 6579 5d5b 7375 626b  w_dict[key][subk
-00014070: 6579 325d 203d 2073 7562 7661 6c75 6532  ey2] = subvalue2
-00014080: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014090: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-000140a0: 2020 2020 2020 2020 2020 206e 6577 5f64             new_d
-000140b0: 6963 745b 6b65 795d 5b73 7562 6b65 795d  ict[key][subkey]
-000140c0: 203d 2073 7562 7661 6c75 650a 0a0a 2020   = subvalue...  
-000140d0: 2020 2020 2020 2320 7772 6974 650a 2020        # write.  
-000140e0: 2020 2020 2020 7769 7468 206f 7065 6e28        with open(
-000140f0: 6f73 2e70 6174 682e 6a6f 696e 286f 732e  os.path.join(os.
-00014100: 7061 7468 2e64 6972 6e61 6d65 286f 7574  path.dirname(out
-00014110: 7075 745f 6669 6c65 292c 206f 732e 7061  put_file), os.pa
-00014120: 7468 2e73 706c 6974 6578 7428 6f75 7470  th.splitext(outp
-00014130: 7574 5f66 696c 6529 5b30 5d20 2b20 222e  ut_file)[0] + ".
-00014140: 6a73 6f6e 2229 2c20 2777 2b27 2920 5c0a  json"), 'w+') \.
-00014150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014160: 2020 2020 6173 2066 703a 0a20 2020 2020      as fp:.     
-00014170: 2020 2020 2020 206a 736f 6e2e 6475 6d70         json.dump
-00014180: 286e 6577 5f64 6963 742c 2066 702c 696e  (new_dict, fp,in
-00014190: 6465 6e74 3d34 290a 2020 2020 656c 7365  dent=4).    else
-000141a0: 3a0a 0a20 2020 2020 2020 2023 206c 6f67  :..        # log
-000141b0: 6769 6e67 2e69 6e66 6f28 2273 6176 696e  ging.info("savin
-000141c0: 6720 6a73 6f6e 206d 6170 7069 6e67 2066  g json mapping f
-000141d0: 696c 653a 2025 7322 2025 6f73 2e70 6174  ile: %s" %os.pat
-000141e0: 682e 6a6f 696e 286f 732e 7061 7468 2e62  h.join(os.path.b
-000141f0: 6173 656e 616d 6528 6f75 7470 7574 5f66  asename(output_f
-00014200: 696c 6529 2c20 5c0a 2020 2020 2020 2020  ile), \.        
-00014210: 2320 2020 2020 2020 2020 2020 2020 2020  #               
-00014220: 2020 2020 2020 2020 2020 2020 206f 732e               os.
-00014230: 7061 7468 2e73 706c 6974 6578 7428 6f75  path.splitext(ou
-00014240: 7470 7574 5f66 696c 6529 5b30 5d2b 222e  tput_file)[0]+".
-00014250: 6a73 6f6e 2229 290a 2020 2020 2020 2020  json")).        
-00014260: 7769 7468 206f 7065 6e28 6f73 2e70 6174  with open(os.pat
-00014270: 682e 6a6f 696e 286f 732e 7061 7468 2e64  h.join(os.path.d
-00014280: 6972 6e61 6d65 286f 7574 7075 745f 6669  irname(output_fi
-00014290: 6c65 292c 206f 732e 7061 7468 2e73 706c  le), os.path.spl
-000142a0: 6974 6578 7428 6f75 7470 7574 5f66 696c  itext(output_fil
-000142b0: 6529 5b30 5d20 2b20 225f 616e 6e6f 7461  e)[0] + "_annota
-000142c0: 7469 6f6e 732e 6a73 6f6e 2229 2c20 2777  tions.json"), 'w
-000142d0: 2b27 2920 5c0a 2020 2020 2020 2020 2020  +') \.          
-000142e0: 2020 2020 2020 2020 2020 6173 2066 703a            as fp:
-000142f0: 0a20 2020 2020 2020 2020 2020 206a 736f  .            jso
-00014300: 6e2e 6475 6d70 2873 6f75 7263 655f 7661  n.dump(source_va
-00014310: 7269 6162 6c65 5f61 6e6e 6f74 6174 696f  riable_annotatio
-00014320: 6e73 2c20 6670 2c69 6e64 656e 743d 3429  ns, fp,indent=4)
-00014330: 0a0a 6465 6620 6669 6e64 5f63 6f6e 6365  ..def find_conce
-00014340: 7074 5f69 6e74 6572 6163 7469 7665 2873  pt_interactive(s
-00014350: 6f75 7263 655f 7661 7269 6162 6c65 2c20  ource_variable, 
-00014360: 6375 7272 656e 745f 7475 706c 652c 2073  current_tuple, s
-00014370: 6f75 7263 655f 7661 7269 6162 6c65 5f61  ource_variable_a
-00014380: 6e6e 6f74 6174 696f 6e73 2c20 696c 785f  nnotations, ilx_
-00014390: 6f62 6a2c 616e 6365 7374 6f72 3d54 7275  obj,ancestor=Tru
-000143a0: 652c 6e69 646d 5f6f 776c 5f67 7261 7068  e,nidm_owl_graph
-000143b0: 3d4e 6f6e 6529 3a0a 2020 2020 2727 270a  =None):.    '''.
-000143c0: 2020 2020 5468 6973 2066 756e 6374 696f      This functio
-000143d0: 6e20 7769 6c6c 2061 6c6c 6f77 2075 7365  n will allow use
-000143e0: 7220 746f 2069 6e74 6572 6163 7469 7665  r to interactive
-000143f0: 6c79 2066 696e 6420 6120 636f 6e63 6570  ly find a concep
-00014400: 7420 696e 2074 6865 2049 6e74 6572 4c65  t in the InterLe
-00014410: 782c 2043 6f67 4174 6c61 732c 2061 6e64  x, CogAtlas, and
-00014420: 204e 4944 4d20 746f 2061 7373 6f63 6961   NIDM to associa
-00014430: 7465 2077 6974 6820 7468 650a 2020 2020  te with the.    
-00014440: 736f 7572 6365 2076 6172 6961 626c 6520  source variable 
-00014450: 6672 6f6d 2074 6865 2061 7373 6573 736d  from the assessm
-00014460: 656e 7420 656e 636f 6465 6420 696e 2074  ent encoded in t
-00014470: 6865 2063 7572 7265 6e74 5f74 7570 6c65  he current_tuple
-00014480: 0a0a 2020 2020 5374 6172 7473 2062 7920  ..    Starts by 
-00014490: 7573 696e 6720 4e49 444d 2d54 6572 6d73  using NIDM-Terms
-000144a0: 2063 6f6e 6365 7074 7320 7768 6963 6820   concepts which 
-000144b0: 6172 6520 6f6e 6573 2074 6861 7420 6861  are ones that ha
-000144c0: 7665 2070 7265 7669 6f75 736c 7920 6265  ve previously be
-000144d0: 656e 2075 7365 6420 746f 2061 6e6e 6f74  en used to annot
-000144e0: 6174 6520 6461 7461 7365 7473 2e20 2042  ate datasets.  B
-000144f0: 790a 2020 2020 7374 6172 7469 6e67 2077  y.    starting w
-00014500: 6974 6820 7468 6573 6520 7765 206d 6178  ith these we max
-00014510: 696d 697a 6520 6368 616e 6365 7320 6f66  imize chances of
-00014520: 2062 6569 6e67 2061 626c 6520 746f 2071   being able to q
-00014530: 7565 7279 2061 6372 6f73 7320 6461 7461  uery across data
-00014540: 7365 7473 2075 7369 6e67 2063 6f6e 6365  sets using conce
-00014550: 7074 2d64 7269 7669 6e20 7175 6572 6965  pt-drivin querie
-00014560: 732e 0a0a 2020 2020 2727 270a 0a20 2020  s...    '''..   
-00014570: 2023 2042 6566 6f72 6520 7765 2072 756e   # Before we run
-00014580: 2061 6e79 7468 696e 6720 6865 7265 2069   anything here i
-00014590: 6620 626f 7468 2049 6e74 6572 4c65 7820  f both InterLex 
-000145a0: 616e 6420 4e49 444d 204f 574c 2066 696c  and NIDM OWL fil
-000145b0: 6520 6163 6365 7373 2069 7320 646f 776e  e access is down
-000145c0: 2077 6520 7368 6f75 6c64 206a 7573 7420   we should just 
-000145d0: 616c 6572 740a 2020 2020 2320 7468 6520  alert.    # the 
-000145e0: 7573 6572 2061 6e64 2072 6574 7572 6e20  user and return 
-000145f0: 6361 7573 6520 7765 2772 6520 6e6f 7420  cause we're not 
-00014600: 676f 696e 6720 746f 2062 6520 6162 6c65  going to be able
-00014610: 2074 6f20 646f 2072 6561 6c6c 7920 616e   to do really an
-00014620: 7974 6869 6e67 0a20 2020 2069 6620 286e  ything.    if (n
-00014630: 6964 6d5f 6f77 6c5f 6772 6170 6820 6973  idm_owl_graph is
-00014640: 204e 6f6e 6529 2061 6e64 2028 696c 785f   None) and (ilx_
-00014650: 6f62 6a20 6973 204e 6f6e 6529 3a0a 2020  obj is None):.  
-00014660: 2020 2020 2020 7072 696e 7428 2242 6f74        print("Bot
-00014670: 6820 496e 7465 724c 6578 2061 6e64 204e  h InterLex and N
-00014680: 4944 4d20 4f57 4c20 6669 6c65 2061 6363  IDM OWL file acc
-00014690: 6573 7320 6973 206e 6f74 2070 6f73 7369  ess is not possi
-000146a0: 626c 6522 290a 2020 2020 2020 2020 7072  ble").        pr
-000146b0: 696e 7428 2243 6865 636b 2079 6f75 7220  int("Check your 
-000146c0: 696e 7465 726e 6574 2063 6f6e 6e65 6374  internet connect
-000146d0: 696f 6e20 616e 6420 7472 7920 6167 6169  ion and try agai
-000146e0: 6e20 6f72 2073 7570 706c 7920 6120 4a53  n or supply a JS
-000146f0: 4f4e 2061 6e6e 6f74 6174 696f 6e20 6669  ON annotation fi
-00014700: 6c65 2077 6974 6820 616c 6c20 7468 6520  le with all the 
-00014710: 7661 7269 6162 6c65 7320 220a 2020 2020  variables ".    
-00014720: 2020 2020 2020 2020 2020 226d 6170 7065            "mappe
-00014730: 6420 746f 2074 6572 6d73 2229 0a20 2020  d to terms").   
-00014740: 2020 2020 2072 6574 7572 6e20 736f 7572       return sour
-00014750: 6365 5f76 6172 6961 626c 655f 616e 6e6f  ce_variable_anno
-00014760: 7461 7469 6f6e 730a 0a20 2020 2023 2061  tations..    # a
-00014770: 6464 6564 2062 7920 4442 4b20 352f 3134  dded by DBK 5/14
-00014780: 2f32 3120 746f 2073 7570 706f 7274 2070  /21 to support p
-00014790: 756c 6c69 6e67 2063 6f6e 6365 7074 7320  ulling concepts 
-000147a0: 7573 6564 2069 6e20 7072 6576 696f 7573  used in previous
-000147b0: 2064 6174 6173 6574 2061 6e6e 6f74 6174   dataset annotat
-000147c0: 696f 6e73 2069 6e20 6672 6f6d 204e 4944  ions in from NID
-000147d0: 4d2d 5465 726d 730a 2020 2020 2320 7265  M-Terms.    # re
-000147e0: 706f 2e0a 2020 2020 6e69 646d 7465 726d  po..    nidmterm
-000147f0: 735f 636f 6e63 6570 7473 203d 206c 6f61  s_concepts = loa
-00014800: 645f 6e69 646d 5f74 6572 6d73 5f63 6f6e  d_nidm_terms_con
-00014810: 6365 7074 7328 290a 0a20 2020 2023 2052  cepts()..    # R
-00014820: 6574 7269 6576 6520 636f 676e 6974 6976  etrieve cognitiv
-00014830: 6520 6174 6c61 7320 636f 6e63 6570 7473  e atlas concepts
-00014840: 2061 6e64 2064 6973 6f72 6465 7273 0a20   and disorders. 
-00014850: 2020 2063 6f67 6174 6c61 735f 636f 6e63     cogatlas_conc
-00014860: 6570 7473 203d 2067 6574 5f63 6f6e 6365  epts = get_conce
-00014870: 7074 2873 696c 656e 743d 5472 7565 290a  pt(silent=True).
-00014880: 2020 2020 636f 6761 746c 6173 5f64 6973      cogatlas_dis
-00014890: 6f72 6465 7273 203d 2067 6574 5f64 6973  orders = get_dis
-000148a0: 6f72 6465 7228 7369 6c65 6e74 3d54 7275  order(silent=Tru
-000148b0: 6529 0a20 2020 2023 2057 4950 2052 6574  e).    # WIP Ret
-000148c0: 7269 6576 6520 636f 676e 6974 6976 6520  rieve cognitive 
-000148d0: 6174 6c61 7320 7461 736b 730a 2020 2020  atlas tasks.    
-000148e0: 2320 646f 2061 2067 6574 2066 726f 6d20  # do a get from 
-000148f0: 7468 6520 666f 6c6c 6f77 696e 6720 7765  the following we
-00014900: 6273 6974 6520 616e 6420 7468 656e 2070  bsite and then p
-00014910: 6172 7365 2f6f 7267 616e 697a 6520 666f  arse/organize fo
-00014920: 7220 6c6f 6f6b 7570 0a20 2020 2023 2068  r lookup.    # h
-00014930: 7474 7073 3a2f 2f77 7777 2e63 6f67 6e69  ttps://www.cogni
-00014940: 7469 7665 6174 6c61 732e 6f72 672f 6170  tiveatlas.org/ap
-00014950: 692f 762d 616c 7068 612f 7461 736b 0a0a  i/v-alpha/task..
-00014960: 2020 2020 2320 6d69 6e69 6d75 6d20 6d61      # minimum ma
-00014970: 7463 6820 7363 6f72 6520 666f 7220 6675  tch score for fu
-00014980: 7a7a 7920 6d61 7463 6869 6e67 204e 4944  zzy matching NID
-00014990: 4d20 7465 726d 730a 2020 2020 6d69 6e5f  M terms.    min_
-000149a0: 6d61 7463 685f 7363 6f72 6520 3d20 3530  match_score = 50
-000149b0: 0a20 2020 2073 6561 7263 685f 7465 726d  .    search_term
-000149c0: 203d 2073 7472 2873 6f75 7263 655f 7661   = str(source_va
-000149d0: 7269 6162 6c65 290a 2020 2020 2320 6c6f  riable).    # lo
-000149e0: 6f70 2074 6f20 6669 6e64 2061 2063 6f6e  op to find a con
-000149f0: 6365 7074 2062 7920 6974 6572 6174 6976  cept by iterativ
-00014a00: 656c 7920 7365 6172 6368 696e 6720 496e  ely searching In
-00014a10: 7465 724c 6578 2e2e 2e6f 7220 6465 6669  terLex...or defi
-00014a20: 6e69 6e67 2079 6f75 7220 6f77 6e0a 2020  ning your own.  
-00014a30: 2020 676f 5f6c 6f6f 703d 5472 7565 0a20    go_loop=True. 
-00014a40: 2020 2077 6869 6c65 2067 6f5f 6c6f 6f70     while go_loop
-00014a50: 3a0a 2020 2020 2020 2020 2320 7661 7269  :.        # vari
-00014a60: 6162 6c65 2066 6f72 206e 756d 6265 7269  able for numberi
-00014a70: 6e67 206f 7074 696f 6e73 2072 6574 7572  ng options retur
-00014a80: 6e65 6420 6672 6f6d 2065 6c61 7374 6963  ned from elastic
-00014a90: 2073 6561 7263 680a 2020 2020 2020 2020   search.        
-00014aa0: 6f70 7469 6f6e 203d 2031 0a20 2020 2020  option = 1.     
-00014ab0: 2020 2070 7269 6e74 2829 0a20 2020 2020     print().     
-00014ac0: 2020 2070 7269 6e74 2822 436f 6e63 6570     print("Concep
-00014ad0: 7420 4173 736f 6369 6174 696f 6e22 290a  t Association").
-00014ae0: 2020 2020 2020 2020 7072 696e 7428 2251          print("Q
-00014af0: 7565 7279 2053 7472 696e 673a 2025 7320  uery String: %s 
-00014b00: 2220 2520 7365 6172 6368 5f74 6572 6d29  " % search_term)
-00014b10: 0a0a 2020 2020 2020 2020 2320 6d6f 6469  ..        # modi
-00014b20: 6669 6564 2062 7920 4442 4b20 352f 3134  fied by DBK 5/14
-00014b30: 2f32 3120 746f 2073 7461 7274 2077 6974  /21 to start wit
-00014b40: 6820 6e69 646d 2d74 6572 6d73 2075 7365  h nidm-terms use
-00014b50: 6420 636f 6e63 6570 7473 0a20 2020 2020  d concepts.     
-00014b60: 2020 2069 6620 6e69 646d 7465 726d 735f     if nidmterms_
-00014b70: 636f 6e63 6570 7473 2069 7320 6e6f 7420  concepts is not 
-00014b80: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-00014b90: 2020 6e69 646d 7465 726d 735f 636f 6e63    nidmterms_conc
-00014ba0: 6570 7473 5f71 7565 7279 203d 2066 757a  epts_query = fuz
-00014bb0: 7a79 5f6d 6174 6368 5f63 6f6e 6365 7074  zy_match_concept
-00014bc0: 735f 6672 6f6d 5f6e 6964 6d74 6572 6d73  s_from_nidmterms
-00014bd0: 5f6a 736f 6e6c 6428 6e69 646d 7465 726d  _jsonld(nidmterm
-00014be0: 735f 636f 6e63 6570 7473 2c20 7365 6172  s_concepts, sear
-00014bf0: 6368 5f74 6572 6d29 0a20 2020 2020 2020  ch_term).       
-00014c00: 2020 2020 2073 6561 7263 685f 7265 7375       search_resu
-00014c10: 6c74 203d 207b 7d0a 2020 2020 2020 2020  lt = {}.        
-00014c20: 2020 2020 6669 7273 745f 6e69 646d 5f74      first_nidm_t
-00014c30: 6572 6d20 3d20 5472 7565 0a20 2020 2020  erm = True.     
-00014c40: 2020 2020 2020 2066 6f72 206b 6579 2c20         for key, 
-00014c50: 7375 6264 6963 7420 696e 206e 6964 6d74  subdict in nidmt
-00014c60: 6572 6d73 5f63 6f6e 6365 7074 735f 7175  erms_concepts_qu
-00014c70: 6572 792e 6974 656d 7328 293a 0a20 2020  ery.items():.   
-00014c80: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00014c90: 6e69 646d 7465 726d 735f 636f 6e63 6570  nidmterms_concep
-00014ca0: 7473 5f71 7565 7279 5b6b 6579 5d5b 2773  ts_query[key]['s
-00014cb0: 636f 7265 275d 203e 206d 696e 5f6d 6174  core'] > min_mat
-00014cc0: 6368 5f73 636f 7265 3a0a 2020 2020 2020  ch_score:.      
-00014cd0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00014ce0: 2066 6972 7374 5f6e 6964 6d5f 7465 726d   first_nidm_term
-00014cf0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00014d00: 2020 2020 2020 2020 2020 7072 696e 7428            print(
-00014d10: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00014d20: 2020 2020 2020 2020 2020 7072 696e 7428            print(
-00014d30: 224e 4944 4d2d 5465 726d 7320 436f 6e63  "NIDM-Terms Conc
-00014d40: 6570 7473 3a22 290a 2020 2020 2020 2020  epts:").        
-00014d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014d60: 6669 7273 745f 6e69 646d 5f74 6572 6d20  first_nidm_term 
-00014d70: 3d20 4661 6c73 650a 0a20 2020 2020 2020  = False..       
-00014d80: 2020 2020 2020 2020 2020 2020 2070 7269               pri
-00014d90: 6e74 2822 2564 3a20 4c61 6265 6c3a 2025  nt("%d: Label: %
-00014da0: 7320 5c74 2044 6566 696e 6974 696f 6e3a  s \t Definition:
-00014db0: 2025 7320 5c74 2055 524c 3a20 2573 2220   %s \t URL: %s" 
-00014dc0: 2520 280a 2020 2020 2020 2020 2020 2020  % (.            
-00014dd0: 2020 2020 2020 2020 6f70 7469 6f6e 2c20          option, 
-00014de0: 6e69 646d 7465 726d 735f 636f 6e63 6570  nidmterms_concep
-00014df0: 7473 5f71 7565 7279 5b6b 6579 5d5b 276c  ts_query[key]['l
-00014e00: 6162 656c 275d 2c20 6e69 646d 7465 726d  abel'], nidmterm
-00014e10: 735f 636f 6e63 6570 7473 5f71 7565 7279  s_concepts_query
-00014e20: 5b6b 6579 5d5b 2764 6566 696e 6974 696f  [key]['definitio
-00014e30: 6e27 5d2c 0a20 2020 2020 2020 2020 2020  n'],.           
-00014e40: 2020 2020 2020 2020 206e 6964 6d74 6572           nidmter
-00014e50: 6d73 5f63 6f6e 6365 7074 735f 7175 6572  ms_concepts_quer
-00014e60: 795b 6b65 795d 5b27 7572 6c27 5d29 290a  y[key]['url'])).
-00014e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014e80: 2020 2020 7365 6172 6368 5f72 6573 756c      search_resul
-00014e90: 745b 6b65 795d 203d 207b 7d0a 2020 2020  t[key] = {}.    
-00014ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014eb0: 7365 6172 6368 5f72 6573 756c 745b 6b65  search_result[ke
-00014ec0: 795d 5b27 6c61 6265 6c27 5d20 3d20 6e69  y]['label'] = ni
-00014ed0: 646d 7465 726d 735f 636f 6e63 6570 7473  dmterms_concepts
-00014ee0: 5f71 7565 7279 5b6b 6579 5d5b 276c 6162  _query[key]['lab
-00014ef0: 656c 275d 0a20 2020 2020 2020 2020 2020  el'].           
-00014f00: 2020 2020 2020 2020 2073 6561 7263 685f           search_
-00014f10: 7265 7375 6c74 5b6b 6579 5d5b 2764 6566  result[key]['def
-00014f20: 696e 6974 696f 6e27 5d20 3d20 6e69 646d  inition'] = nidm
-00014f30: 7465 726d 735f 636f 6e63 6570 7473 5f71  terms_concepts_q
-00014f40: 7565 7279 5b6b 6579 5d5b 2764 6566 696e  uery[key]['defin
-00014f50: 6974 696f 6e27 5d0a 2020 2020 2020 2020  ition'].        
-00014f60: 2020 2020 2020 2020 2020 2020 7365 6172              sear
-00014f70: 6368 5f72 6573 756c 745b 6b65 795d 5b27  ch_result[key]['
-00014f80: 7072 6566 6572 7265 645f 7572 6c27 5d20  preferred_url'] 
-00014f90: 3d20 6e69 646d 7465 726d 735f 636f 6e63  = nidmterms_conc
-00014fa0: 6570 7473 5f71 7565 7279 5b6b 6579 5d5b  epts_query[key][
-00014fb0: 2775 726c 275d 0a20 2020 2020 2020 2020  'url'].         
-00014fc0: 2020 2020 2020 2020 2020 2073 6561 7263             searc
-00014fd0: 685f 7265 7375 6c74 5b73 7472 286f 7074  h_result[str(opt
-00014fe0: 696f 6e29 5d20 3d20 6b65 790a 2020 2020  ion)] = key.    
-00014ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015000: 6f70 7469 6f6e 203d 206f 7074 696f 6e20  option = option 
-00015010: 2b20 310a 0a0a 2020 2020 2020 2020 6966  + 1...        if
-00015020: 206e 6f74 2061 6e63 6573 746f 723a 0a20   not ancestor:. 
-00015030: 2020 2020 2020 2020 2020 2069 6620 696c             if il
-00015040: 785f 6f62 6a20 6973 206e 6f74 204e 6f6e  x_obj is not Non
-00015050: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-00015060: 2020 2023 2066 6f72 2065 6163 6820 636f     # for each co
-00015070: 6c75 6d6e 206e 616d 652c 2071 7565 7279  lumn name, query
-00015080: 2049 6e74 6572 6c65 7820 666f 7220 706f   Interlex for po
-00015090: 7373 6962 6c65 206d 6174 6368 6573 0a20  ssible matches. 
-000150a0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-000150b0: 6c78 5f72 6573 756c 7420 3d20 4765 744e  lx_result = GetN
-000150c0: 4944 4d54 6572 6d73 4672 6f6d 5363 6943  IDMTermsFromSciC
-000150d0: 7275 6e63 6828 7365 6172 6368 5f74 6572  runch(search_ter
-000150e0: 6d2c 2074 7970 653d 2774 6572 6d27 2c20  m, type='term', 
-000150f0: 616e 6365 7374 6f72 3d46 616c 7365 290a  ancestor=False).
-00015100: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00015110: 2023 7465 6d70 203d 2069 6c78 5f72 6573   #temp = ilx_res
-00015120: 756c 742e 636f 7079 2829 0a20 2020 2020  ult.copy().     
-00015130: 2020 2020 2020 2020 2020 2023 2070 7269             # pri
-00015140: 6e74 2822 5365 6172 6368 2054 6572 6d3a  nt("Search Term:
-00015150: 2025 7322 2025 7365 6172 6368 5f74 6572   %s" %search_ter
-00015160: 6d29 0a20 2020 2020 2020 2020 2020 2020  m).             
-00015170: 2020 2069 6620 6c65 6e28 696c 785f 7265     if len(ilx_re
-00015180: 7375 6c74 2920 213d 2030 3a0a 2020 2020  sult) != 0:.    
-00015190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000151a0: 7072 696e 7428 2249 6e74 6572 4c65 783a  print("InterLex:
-000151b0: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
-000151c0: 2020 2020 2020 2070 7269 6e74 2829 0a20         print(). 
+000136e0: 2020 2020 2020 2275 6e69 7443 6f64 653a        "unitCode:
+000136f0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00013700: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
+00013710: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
+00013720: 6e74 5f74 7570 6c65 5d5b 2272 6573 706f  nt_tuple]["respo
+00013730: 6e73 654f 7074 696f 6e73 225d 5b22 756e  nseOptions"]["un
+00013740: 6974 436f 6465 225d 2c0a 2020 2020 2020  itCode"],.      
+00013750: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+00013760: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013770: 656c 6966 2022 556e 6974 7322 2069 6e20  elif "Units" in 
+00013780: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
+00013790: 795b 305d 5d3a 0a20 2020 2020 2020 2020  y[0]]:.         
+000137a0: 2020 2020 2020 2020 2020 2023 2075 7067             # upg
+000137b0: 7261 6465 2027 556e 6974 7327 2074 6f20  rade 'Units' to 
+000137c0: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
+000137d0: 272d 3e27 756e 6974 436f 6465 0a20 2020  '->'unitCode.   
+000137e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000137f0: 2069 6620 2272 6573 706f 6e73 654f 7074   if "responseOpt
+00013800: 696f 6e73 2220 6e6f 7420 696e 2063 6f6c  ions" not in col
+00013810: 756d 6e5f 746f 5f74 6572 6d73 5b63 7572  umn_to_terms[cur
+00013820: 7265 6e74 5f74 7570 6c65 5d2e 6b65 7973  rent_tuple].keys
+00013830: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+00013840: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
+00013850: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+00013860: 656e 745f 7475 706c 655d 5b22 7265 7370  ent_tuple]["resp
+00013870: 6f6e 7365 4f70 7469 6f6e 7322 5d20 3d20  onseOptions"] = 
+00013880: 7b7d 0a20 2020 2020 2020 2020 2020 2020  {}.             
+00013890: 2020 2020 2020 2063 6f6c 756d 6e5f 746f         column_to
+000138a0: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
+000138b0: 7570 6c65 5d5b 2272 6573 706f 6e73 654f  uple]["responseO
+000138c0: 7074 696f 6e73 225d 5b0a 2020 2020 2020  ptions"][.      
+000138d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000138e0: 2020 2275 6e69 7443 6f64 6522 0a20 2020    "unitCode".   
+000138f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013900: 205d 203d 206a 736f 6e5f 6d61 705b 6a73   ] = json_map[js
+00013910: 6f6e 5f6b 6579 5b30 5d5d 5b22 556e 6974  on_key[0]]["Unit
+00013920: 7322 5d0a 2020 2020 2020 2020 2020 2020  s"].            
+00013930: 2020 2020 2020 2020 7072 696e 7428 0a20          print(. 
+00013940: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013950: 2020 2020 2020 2022 756e 6974 436f 6465         "unitCode
+00013960: 3a22 2c0a 2020 2020 2020 2020 2020 2020  :",.            
+00013970: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
+00013980: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+00013990: 656e 745f 7475 706c 655d 5b22 7265 7370  ent_tuple]["resp
+000139a0: 6f6e 7365 4f70 7469 6f6e 7322 5d5b 2275  onseOptions"]["u
+000139b0: 6e69 7443 6f64 6522 5d2c 0a20 2020 2020  nitCode"],.     
+000139c0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+000139d0: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000139e0: 2020 6966 2022 6973 4162 6f75 7422 2069    if "isAbout" i
+000139f0: 6e20 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f  n json_map[json_
+00013a00: 6b65 795b 305d 5d3a 0a20 2020 2020 2020  key[0]]:.       
+00013a10: 2020 2020 2020 2020 2020 2020 2023 2063               # c
+00013a20: 6865 636b 2069 6620 7765 2068 6176 6520  heck if we have 
+00013a30: 6120 7369 6e67 6c65 2069 7341 626f 7574  a single isAbout
+00013a40: 206f 7220 6d75 6c74 6970 6c65 2e2e 2e0a   or multiple....
+00013a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013a60: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
+00013a70: 6528 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f  e(json_map[json_
+00013a80: 6b65 795b 305d 5d5b 2269 7341 626f 7574  key[0]]["isAbout
+00013a90: 225d 2c20 6c69 7374 293a 0a20 2020 2020  "], list):.     
+00013aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013ab0: 2020 2023 2069 7341 626f 7574 2069 7320     # isAbout is 
+00013ac0: 616e 2065 6d70 7479 206c 6973 742c 2064  an empty list, d
+00013ad0: 6f20 636f 6e63 6570 7420 6173 736f 6369  o concept associ
+00013ae0: 6174 696f 6e20 6966 2075 7365 7220 6173  ation if user as
+00013af0: 6b65 6420 666f 7220 6974 2065 6c73 6520  ked for it else 
+00013b00: 736b 6970 0a20 2020 2020 2020 2020 2020  skip.           
+00013b10: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00013b20: 6e6f 7420 6a73 6f6e 5f6d 6170 5b6a 736f  not json_map[jso
+00013b30: 6e5f 6b65 795b 305d 5d5b 2269 7341 626f  n_key[0]]["isAbo
+00013b40: 7574 225d 3a0a 2020 2020 2020 2020 2020  ut"]:.          
+00013b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013b60: 2020 6966 2061 7373 6f63 6961 7465 5f63    if associate_c
+00013b70: 6f6e 6365 7074 733a 0a20 2020 2020 2020  oncepts:.       
+00013b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013b90: 2020 2020 2020 2020 2023 2070 726f 7669           # provi
+00013ba0: 6465 2075 7365 7220 7769 7468 206f 7070  de user with opp
+00013bb0: 6f72 7475 6e69 7479 2074 6f20 6173 736f  ortunity to asso
+00013bc0: 6369 6174 6520 6120 636f 6e63 6570 7420  ciate a concept 
+00013bd0: 7769 7468 2074 6869 7320 616e 6e6f 7461  with this annota
+00013be0: 7469 6f6e 0a20 2020 2020 2020 2020 2020  tion.           
+00013bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013c00: 2020 2020 2066 696e 645f 636f 6e63 6570       find_concep
+00013c10: 745f 696e 7465 7261 6374 6976 6528 0a20  t_interactive(. 
+00013c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013c40: 2020 2063 6f6c 756d 6e2c 0a20 2020 2020     column,.     
+00013c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013c60: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00013c70: 7572 7265 6e74 5f74 7570 6c65 2c0a 2020  urrent_tuple,.  
+00013c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013ca0: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
+00013cb0: 732c 0a20 2020 2020 2020 2020 2020 2020  s,.             
+00013cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013cd0: 2020 2020 2020 2069 6c78 5f6f 626a 2c0a         ilx_obj,.
+00013ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013d00: 2020 2020 6e69 646d 5f6f 776c 5f67 7261      nidm_owl_gra
+00013d10: 7068 3d6e 6964 6d5f 6f77 6c5f 6772 6170  ph=nidm_owl_grap
+00013d20: 682c 0a20 2020 2020 2020 2020 2020 2020  h,.             
+00013d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013d40: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+00013d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013d60: 2020 2020 2023 2077 7269 7465 2061 6e6e       # write ann
+00013d70: 6f74 6174 696f 6e73 2074 6f20 6a73 6f6e  otations to json
+00013d80: 2066 696c 6520 736f 2075 7365 7220 6361   file so user ca
+00013d90: 6e20 7374 6172 7420 7570 2061 6761 696e  n start up again
+00013da0: 2069 6620 6e6f 7420 646f 696e 6720 7768   if not doing wh
+00013db0: 6f6c 6520 6669 6c65 0a20 2020 2020 2020  ole file.       
+00013dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013dd0: 2020 2020 2020 2020 2077 7269 7465 5f6a           write_j
+00013de0: 736f 6e5f 6d61 7070 696e 675f 6669 6c65  son_mapping_file
+00013df0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+00013e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013e10: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
+00013e20: 7465 726d 732c 206f 7574 7075 745f 6669  terms, output_fi
+00013e30: 6c65 2c20 6269 6473 0a20 2020 2020 2020  le, bids.       
+00013e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013e50: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+00013e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013e70: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00013e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013e90: 2020 2020 2020 2020 2020 2020 2070 6173               pas
+00013ea0: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
+00013eb0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+00013ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013ed0: 2020 2020 2020 2020 2020 2020 2320 656c              # el
+00013ee0: 7365 2063 7265 6174 6520 6120 6e65 7720  se create a new 
+00013ef0: 6c69 7374 0a20 2020 2020 2020 2020 2020  list.           
+00013f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013f10: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+00013f20: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+00013f30: 2269 7341 626f 7574 225d 203d 205b 5d0a  "isAbout"] = [].
+00013f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013f50: 2020 2020 2020 2020 2020 2020 2320 666f              # fo
+00013f60: 7220 6561 6368 2069 7341 626f 7574 2065  r each isAbout e
+00013f70: 6e74 7279 0a20 2020 2020 2020 2020 2020  ntry.           
+00013f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013f90: 2066 6f72 2073 7562 6469 6374 2069 6e20   for subdict in 
+00013fa0: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
+00013fb0: 795b 305d 5d5b 2269 7341 626f 7574 225d  y[0]]["isAbout"]
+00013fc0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00013fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013fe0: 2020 2320 736f 6d65 2065 6e74 7269 6573    # some entries
+00013ff0: 206d 6179 206e 6f74 2068 6176 6520 276c   may not have 'l
+00014000: 6162 656c 2720 736f 2063 6865 636b 0a20  abel' so check. 
+00014010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014020: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00014030: 6620 226c 6162 656c 2220 696e 2073 7562  f "label" in sub
+00014040: 6469 6374 2e6b 6579 7328 293a 0a20 2020  dict.keys():.   
+00014050: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014070: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+00014080: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+00014090: 2269 7341 626f 7574 225d 2e61 7070 656e  "isAbout"].appen
+000140a0: 6428 0a20 2020 2020 2020 2020 2020 2020  d(.             
+000140b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000140c0: 2020 2020 2020 2020 2020 207b 0a20 2020             {.   
+000140d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000140e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000140f0: 2020 2020 2020 2020 2022 4069 6422 3a20           "@id": 
+00014100: 7375 6264 6963 745b 2240 6964 225d 2c0a  subdict["@id"],.
+00014110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014130: 2020 2020 2020 2020 2020 2020 226c 6162              "lab
+00014140: 656c 223a 2073 7562 6469 6374 5b22 6c61  el": subdict["la
+00014150: 6265 6c22 5d2c 0a20 2020 2020 2020 2020  bel"],.         
+00014160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014170: 2020 2020 2020 2020 2020 2020 2020 207d                 }
+00014180: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000141a0: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+000141b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000141c0: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+000141d0: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+000141e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000141f0: 2020 2020 2020 2020 2020 6622 6973 4162            f"isAb
+00014200: 6f75 743a 2040 6964 203d 207b 7375 6264  out: @id = {subd
+00014210: 6963 745b 2740 6964 275d 7d2c 206c 6162  ict['@id']}, lab
+00014220: 656c 203d 207b 7375 6264 6963 745b 276c  el = {subdict['l
+00014230: 6162 656c 275d 7d22 0a20 2020 2020 2020  abel']}".       
+00014240: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014250: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+00014260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014270: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+00014280: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00014290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000142a0: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
+000142b0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+000142c0: 5f74 7570 6c65 5d5b 2269 7341 626f 7574  _tuple]["isAbout
+000142d0: 225d 2e61 7070 656e 6428 0a20 2020 2020  "].append(.     
+000142e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000142f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014300: 2020 207b 2240 6964 223a 2073 7562 6469     {"@id": subdi
+00014310: 6374 5b22 4069 6422 5d7d 0a20 2020 2020  ct["@id"]}.     
+00014320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014330: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00014340: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014360: 2020 2020 2070 7269 6e74 2866 2269 7341       print(f"isA
+00014370: 626f 7574 3a20 4069 6420 3d20 7b73 7562  bout: @id = {sub
+00014380: 6469 6374 5b27 4069 6427 5d7d 2229 0a20  dict['@id']}"). 
+00014390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000143a0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+000143b0: 2066 6f72 2069 7361 626f 7574 5f6b 6579   for isabout_key
+000143c0: 2c69 7361 626f 7574 5f76 616c 7565 2069  ,isabout_value i
+000143d0: 6e20 7375 6264 6963 742e 6974 656d 7328  n subdict.items(
+000143e0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+000143f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014400: 2020 2023 2020 2020 636f 6c75 6d6e 5f74     #    column_t
+00014410: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
+00014420: 7475 706c 655d 5b27 6973 4162 6f75 7427  tuple]['isAbout'
+00014430: 5d2e 6170 7065 6e64 287b 6973 6162 6f75  ].append({isabou
+00014440: 745f 6b65 793a 6973 6162 6f75 745f 7661  t_key:isabout_va
+00014450: 6c75 657d 290a 2020 2020 2020 2020 2020  lue}).          
+00014460: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014470: 2020 2020 2020 2320 2020 2070 7269 6e74        #    print
+00014480: 2866 2269 7341 626f 7574 3a20 7b69 7361  (f"isAbout: {isa
+00014490: 626f 7574 5f6b 6579 7d20 3d20 7b69 7361  bout_key} = {isa
+000144a0: 626f 7574 5f76 616c 7565 7d22 290a 2020  bout_value}").  
+000144b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000144c0: 2020 2320 6966 2069 7341 626f 7574 2069    # if isAbout i
+000144d0: 7320 6120 6469 6374 696f 6e61 7279 2074  s a dictionary t
+000144e0: 6865 6e20 7765 206f 6e6c 7920 6861 7665  hen we only have
+000144f0: 2031 2069 7341 626f 7574 2e2e 2e77 6527   1 isAbout...we'
+00014500: 6c6c 2075 7067 7261 6465 2069 7420 746f  ll upgrade it to
+00014510: 2061 206c 6973 740a 2020 2020 2020 2020   a list.        
+00014520: 2020 2020 2020 2020 2020 2020 2320 746f              # to
+00014530: 2062 6520 636f 6e73 6973 7465 6e74 206d   be consistent m
+00014540: 6f76 696e 6720 666f 7277 6172 640a 2020  oving forward.  
+00014550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014560: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00014570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014580: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
+00014590: 6375 7272 656e 745f 7475 706c 655d 5b22  current_tuple]["
+000145a0: 6973 4162 6f75 7422 5d20 3d20 5b5d 0a20  isAbout"] = []. 
+000145b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000145c0: 2020 2020 2020 2069 6620 2275 726c 2220         if "url" 
+000145d0: 696e 206a 736f 6e5f 6d61 705b 6a73 6f6e  in json_map[json
+000145e0: 5f6b 6579 5b30 5d5d 5b22 6973 4162 6f75  _key[0]]["isAbou
+000145f0: 7422 5d2e 6b65 7973 2829 3a0a 2020 2020  t"].keys():.    
+00014600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014610: 2020 2020 2020 2020 6966 2022 6c61 6265          if "labe
+00014620: 6c22 2069 6e20 6a73 6f6e 5f6d 6170 5b6a  l" in json_map[j
+00014630: 736f 6e5f 6b65 795b 305d 5d5b 2269 7341  son_key[0]]["isA
+00014640: 626f 7574 225d 2e6b 6579 7328 293a 0a20  bout"].keys():. 
+00014650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014660: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00014670: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
+00014680: 7572 7265 6e74 5f74 7570 6c65 5d5b 2269  urrent_tuple]["i
+00014690: 7341 626f 7574 225d 2e61 7070 656e 6428  sAbout"].append(
+000146a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000146b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000146c0: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
+000146d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000146e0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000146f0: 4069 6422 3a20 6a73 6f6e 5f6d 6170 5b6a  @id": json_map[j
+00014700: 736f 6e5f 6b65 795b 305d 5d5b 2269 7341  son_key[0]]["isA
+00014710: 626f 7574 225d 5b22 7572 6c22 5d2c 0a20  bout"]["url"],. 
+00014720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014730: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014740: 2020 2020 2020 2022 6c61 6265 6c22 3a20         "label": 
+00014750: 6a73 6f6e 5f6d 6170 5b6a 736f 6e5f 6b65  json_map[json_ke
+00014760: 795b 305d 5d5b 2269 7341 626f 7574 225d  y[0]]["isAbout"]
+00014770: 5b0a 2020 2020 2020 2020 2020 2020 2020  [.              
+00014780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014790: 2020 2020 2020 2020 2020 2020 2020 226c                "l
+000147a0: 6162 656c 220a 2020 2020 2020 2020 2020  abel".          
+000147b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000147c0: 2020 2020 2020 2020 2020 2020 2020 5d2c                ],
+000147d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000147e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000147f0: 2020 2020 207d 0a20 2020 2020 2020 2020       }.         
+00014800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014810: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+00014820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014830: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00014840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014850: 2020 2020 2020 2020 2020 2063 6f6c 756d             colum
+00014860: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
+00014870: 6e74 5f74 7570 6c65 5d5b 2269 7341 626f  nt_tuple]["isAbo
+00014880: 7574 225d 2e61 7070 656e 6428 0a20 2020  ut"].append(.   
+00014890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000148a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000148b0: 207b 2240 6964 223a 206a 736f 6e5f 6d61   {"@id": json_ma
+000148c0: 705b 6a73 6f6e 5f6b 6579 5b30 5d5d 5b22  p[json_key[0]]["
+000148d0: 6973 4162 6f75 7422 5d5b 2275 726c 225d  isAbout"]["url"]
+000148e0: 7d0a 2020 2020 2020 2020 2020 2020 2020  }.              
+000148f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014900: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+00014910: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00014920: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00014930: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00014940: 2022 6c61 6265 6c22 2069 6e20 6a73 6f6e   "label" in json
+00014950: 5f6d 6170 5b6a 736f 6e5f 6b65 795b 305d  _map[json_key[0]
+00014960: 5d5b 2269 7341 626f 7574 225d 2e6b 6579  ]["isAbout"].key
+00014970: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
+00014980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014990: 2020 2020 2063 6f6c 756d 6e5f 746f 5f74       column_to_t
+000149a0: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
+000149b0: 6c65 5d5b 2269 7341 626f 7574 225d 2e61  le]["isAbout"].a
+000149c0: 7070 656e 6428 0a20 2020 2020 2020 2020  ppend(.         
+000149d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000149e0: 2020 2020 2020 2020 2020 207b 0a20 2020             {.   
+000149f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014a10: 2020 2020 2022 4069 6422 3a20 6a73 6f6e       "@id": json
+00014a20: 5f6d 6170 5b6a 736f 6e5f 6b65 795b 305d  _map[json_key[0]
+00014a30: 5d5b 2269 7341 626f 7574 225d 5b22 4069  ]["isAbout"]["@i
+00014a40: 6422 5d2c 0a20 2020 2020 2020 2020 2020  d"],.           
+00014a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014a60: 2020 2020 2020 2020 2020 2020 2022 6c61               "la
+00014a70: 6265 6c22 3a20 6a73 6f6e 5f6d 6170 5b6a  bel": json_map[j
+00014a80: 736f 6e5f 6b65 795b 305d 5d5b 2269 7341  son_key[0]]["isA
+00014a90: 626f 7574 225d 5b0a 2020 2020 2020 2020  bout"][.        
+00014aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014ac0: 2020 2020 226c 6162 656c 220a 2020 2020      "label".    
+00014ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014af0: 2020 2020 5d2c 0a20 2020 2020 2020 2020      ],.         
+00014b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014b10: 2020 2020 2020 2020 2020 207d 0a20 2020             }.   
+00014b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014b30: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+00014b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014b50: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+00014b60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014b80: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+00014b90: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+00014ba0: 2269 7341 626f 7574 225d 2e61 7070 656e  "isAbout"].appen
+00014bb0: 6428 0a20 2020 2020 2020 2020 2020 2020  d(.             
+00014bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014bd0: 2020 2020 2020 207b 2240 6964 223a 206a         {"@id": j
+00014be0: 736f 6e5f 6d61 705b 6a73 6f6e 5f6b 6579  son_map[json_key
+00014bf0: 5b30 5d5d 5b22 6973 4162 6f75 7422 5d5b  [0]]["isAbout"][
+00014c00: 2240 6964 225d 7d0a 2020 2020 2020 2020  "@id"]}.        
+00014c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014c20: 2020 2020 2020 2020 290a 0a20 2020 2020          )..     
+00014c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014c40: 2020 2070 7269 6e74 280a 2020 2020 2020     print(.      
+00014c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014c60: 2020 2020 2020 6622 6973 4162 6f75 743a        f"isAbout:
+00014c70: 2040 6964 203d 207b 636f 6c75 6d6e 5f74   @id = {column_t
+00014c80: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
+00014c90: 7475 706c 655d 5b27 6973 4162 6f75 7427  tuple]['isAbout'
+00014ca0: 5d5b 2740 6964 275d 7d2c 206c 6162 656c  ]['@id']}, label
+00014cb0: 203d 207b 636f 6c75 6d6e 5f74 6f5f 7465   = {column_to_te
+00014cc0: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
+00014cd0: 655d 5b27 6973 4162 6f75 7427 5d5b 276c  e]['isAbout']['l
+00014ce0: 6162 656c 275d 7d22 0a20 2020 2020 2020  abel']}".       
+00014cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014d00: 2029 0a20 2020 2020 2020 2020 2020 2020   ).             
+00014d10: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00014d20: 2020 2020 2020 2020 2020 2020 2023 2069               # i
+00014d30: 6620 7573 6572 2072 616e 2069 6e20 6d6f  f user ran in mo
+00014d40: 6465 2077 6865 7265 2074 6865 7920 7761  de where they wa
+00014d50: 6e74 2074 6f20 6173 736f 6369 6174 6520  nt to associate 
+00014d60: 636f 6e63 6570 7473 2061 6e64 2074 6869  concepts and thi
+00014d70: 7320 6973 6e27 7420 7468 6520 7061 7274  s isn't the part
+00014d80: 6963 6970 616e 740a 2020 2020 2020 2020  icipant.        
+00014d90: 2020 2020 2020 2020 2020 2020 2320 6964              # id
+00014da0: 2066 6965 6c64 2074 6865 6e20 6173 736f   field then asso
+00014db0: 6369 6174 6520 636f 6e63 6570 7473 2e0a  ciate concepts..
+00014dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014dd0: 2020 2020 6966 206d 6174 6368 5f70 6172      if match_par
+00014de0: 7469 6369 7061 6e74 5f69 645f 6669 656c  ticipant_id_fiel
+00014df0: 6428 0a20 2020 2020 2020 2020 2020 2020  d(.             
+00014e00: 2020 2020 2020 2020 2020 206a 736f 6e5f             json_
+00014e10: 6d61 705b 6a73 6f6e 5f6b 6579 5b30 5d5d  map[json_key[0]]
+00014e20: 5b22 736f 7572 6365 5661 7269 6162 6c65  ["sourceVariable
+00014e30: 225d 0a20 2020 2020 2020 2020 2020 2020  "].             
+00014e40: 2020 2020 2020 2029 3a0a 2020 2020 2020         ):.      
+00014e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014e60: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
+00014e70: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+00014e80: 5b22 6973 4162 6f75 7422 5d20 3d20 5b5d  ["isAbout"] = []
+00014e90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014ea0: 2020 2020 2020 2020 2063 6f6c 756d 6e5f           column_
+00014eb0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+00014ec0: 5f74 7570 6c65 5d5b 2269 7341 626f 7574  _tuple]["isAbout
+00014ed0: 225d 2e61 7070 656e 6428 0a20 2020 2020  "].append(.     
+00014ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014ef0: 2020 2020 2020 207b 0a20 2020 2020 2020         {.       
+00014f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014f10: 2020 2020 2020 2020 2022 4069 6422 3a20           "@id": 
+00014f20: 436f 6e73 7461 6e74 732e 4e49 444d 5f53  Constants.NIDM_S
+00014f30: 5542 4a45 4354 4944 2e75 7269 2c0a 2020  UBJECTID.uri,.  
+00014f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014f50: 2020 2020 2020 2020 2020 2020 2020 226c                "l
+00014f60: 6162 656c 223a 2043 6f6e 7374 616e 7473  abel": Constants
+00014f70: 2e4e 4944 4d5f 5355 424a 4543 5449 442e  .NIDM_SUBJECTID.
+00014f80: 6c6f 6361 6c70 6172 742c 0a20 2020 2020  localpart,.     
+00014f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014fa0: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+00014fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014fc0: 2029 0a20 2020 2020 2020 2020 2020 2020   ).             
+00014fd0: 2020 2020 2020 2020 2020 2077 7269 7465             write
+00014fe0: 5f6a 736f 6e5f 6d61 7070 696e 675f 6669  _json_mapping_fi
+00014ff0: 6c65 2863 6f6c 756d 6e5f 746f 5f74 6572  le(column_to_ter
+00015000: 6d73 2c20 6f75 7470 7574 5f66 696c 652c  ms, output_file,
+00015010: 2062 6964 7329 0a20 2020 2020 2020 2020   bids).         
+00015020: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+00015030: 6173 736f 6369 6174 655f 636f 6e63 6570  associate_concep
+00015040: 7473 3a0a 2020 2020 2020 2020 2020 2020  ts:.            
+00015050: 2020 2020 2020 2020 2020 2020 2320 7072              # pr
+00015060: 6f76 6964 6520 7573 6572 2077 6974 6820  ovide user with 
+00015070: 6f70 706f 7274 756e 6974 7920 746f 2061  opportunity to a
+00015080: 7373 6f63 6961 7465 2061 2063 6f6e 6365  ssociate a conce
+00015090: 7074 2077 6974 6820 7468 6973 2061 6e6e  pt with this ann
+000150a0: 6f74 6174 696f 6e0a 2020 2020 2020 2020  otation.        
+000150b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000150c0: 6669 6e64 5f63 6f6e 6365 7074 5f69 6e74  find_concept_int
+000150d0: 6572 6163 7469 7665 280a 2020 2020 2020  eractive(.      
+000150e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000150f0: 2020 2020 2020 636f 6c75 6d6e 2c0a 2020        column,.  
+00015100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015110: 2020 2020 2020 2020 2020 6375 7272 656e            curren
+00015120: 745f 7475 706c 652c 0a20 2020 2020 2020  t_tuple,.       
+00015130: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015140: 2020 2020 2063 6f6c 756d 6e5f 746f 5f74       column_to_t
+00015150: 6572 6d73 2c0a 2020 2020 2020 2020 2020  erms,.          
+00015160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015170: 2020 696c 785f 6f62 6a2c 0a20 2020 2020    ilx_obj,.     
+00015180: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015190: 2020 2020 2020 206e 6964 6d5f 6f77 6c5f         nidm_owl_
+000151a0: 6772 6170 683d 6e69 646d 5f6f 776c 5f67  graph=nidm_owl_g
+000151b0: 7261 7068 2c0a 2020 2020 2020 2020 2020  raph,.          
+000151c0: 2020 2020 2020 2020 2020 2020 2020 290a                ).
 000151d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000151e0: 2020 2023 2070 7269 6e74 2822 5365 6172     # print("Sear
-000151f0: 6368 2052 6573 756c 7473 3a20 2229 0a20  ch Results: "). 
-00015200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015210: 2020 2066 6f72 206b 6579 2c20 7661 6c75     for key, valu
-00015220: 6520 696e 2069 6c78 5f72 6573 756c 742e  e in ilx_result.
-00015230: 6974 656d 7328 293a 0a20 2020 2020 2020  items():.       
+000151e0: 2020 2020 2020 2020 2320 7772 6974 6520          # write 
+000151f0: 616e 6e6f 7461 7469 6f6e 7320 746f 206a  annotations to j
+00015200: 736f 6e20 6669 6c65 2073 6f20 7573 6572  son file so user
+00015210: 2063 616e 2073 7461 7274 2075 7020 6167   can start up ag
+00015220: 6169 6e20 6966 206e 6f74 2064 6f69 6e67  ain if not doing
+00015230: 2077 686f 6c65 2066 696c 650a 2020 2020   whole file.    
 00015240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015250: 2070 7269 6e74 2822 2564 3a20 4c61 6265   print("%d: Labe
-00015260: 6c3a 2025 7320 5c74 2044 6566 696e 6974  l: %s \t Definit
-00015270: 696f 6e3a 2025 7320 5c74 2050 7265 6665  ion: %s \t Prefe
-00015280: 7272 6564 2055 524c 3a20 2573 2022 2025  rred URL: %s " %
-00015290: 2028 0a20 2020 2020 2020 2020 2020 2020   (.             
-000152a0: 2020 2020 2020 2020 2020 206f 7074 696f             optio
-000152b0: 6e2c 2069 6c78 5f72 6573 756c 745b 6b65  n, ilx_result[ke
-000152c0: 795d 5b27 6c61 6265 6c27 5d2c 2069 6c78  y]['label'], ilx
-000152d0: 5f72 6573 756c 745b 6b65 795d 5b27 6465  _result[key]['de
-000152e0: 6669 6e69 7469 6f6e 275d 2c0a 2020 2020  finition'],.    
-000152f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015300: 2020 2020 696c 785f 7265 7375 6c74 5b6b      ilx_result[k
-00015310: 6579 5d5b 2770 7265 6665 7272 6564 5f75  ey]['preferred_u
-00015320: 726c 275d 2929 0a0a 2020 2020 2020 2020  rl']))..        
-00015330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015340: 7365 6172 6368 5f72 6573 756c 745b 6b65  search_result[ke
-00015350: 795d 3d7b 7d0a 2020 2020 2020 2020 2020  y]={}.          
-00015360: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00015370: 6172 6368 5f72 6573 756c 745b 6b65 795d  arch_result[key]
-00015380: 5b27 6c61 6265 6c27 5d20 3d20 696c 785f  ['label'] = ilx_
-00015390: 7265 7375 6c74 5b6b 6579 5d5b 276c 6162  result[key]['lab
-000153a0: 656c 275d 0a20 2020 2020 2020 2020 2020  el'].           
-000153b0: 2020 2020 2020 2020 2020 2020 2073 6561               sea
-000153c0: 7263 685f 7265 7375 6c74 5b6b 6579 5d5b  rch_result[key][
-000153d0: 2764 6566 696e 6974 696f 6e27 5d20 3d20  'definition'] = 
-000153e0: 696c 785f 7265 7375 6c74 5b6b 6579 5d5b  ilx_result[key][
-000153f0: 2764 6566 696e 6974 696f 6e27 5d0a 2020  'definition'].  
-00015400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015410: 2020 2020 2020 7365 6172 6368 5f72 6573        search_res
-00015420: 756c 745b 6b65 795d 5b27 7072 6566 6572  ult[key]['prefer
-00015430: 7265 645f 7572 6c27 5d20 3d20 696c 785f  red_url'] = ilx_
-00015440: 7265 7375 6c74 5b6b 6579 5d5b 2770 7265  result[key]['pre
-00015450: 6665 7272 6564 5f75 726c 275d 0a20 2020  ferred_url'].   
-00015460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015470: 2020 2020 2073 6561 7263 685f 7265 7375       search_resu
-00015480: 6c74 5b73 7472 286f 7074 696f 6e29 5d20  lt[str(option)] 
-00015490: 3d20 6b65 790a 2020 2020 2020 2020 2020  = key.          
-000154a0: 2020 2020 2020 2020 2020 2020 2020 6f70                op
-000154b0: 7469 6f6e 203d 206f 7074 696f 6e20 2b20  tion = option + 
-000154c0: 310a 0a0a 2020 2020 2020 2020 2020 2020  1...            
-000154d0: 2320 436f 676e 6974 6976 6520 4174 6c61  # Cognitive Atla
-000154e0: 7320 436f 6e63 6570 7473 2053 6561 7263  s Concepts Searc
-000154f0: 680a 2020 2020 2020 2020 2020 2020 7472  h.            tr
-00015500: 793a 0a20 2020 2020 2020 2020 2020 2020  y:.             
-00015510: 2020 2063 6f67 6174 6c61 735f 636f 6e63     cogatlas_conc
-00015520: 6570 7473 5f71 7565 7279 203d 2066 757a  epts_query = fuz
-00015530: 7a79 5f6d 6174 6368 5f74 6572 6d73 5f66  zy_match_terms_f
-00015540: 726f 6d5f 636f 6761 746c 6173 5f6a 736f  rom_cogatlas_jso
-00015550: 6e28 636f 6761 746c 6173 5f63 6f6e 6365  n(cogatlas_conce
-00015560: 7074 732e 6a73 6f6e 2c73 6561 7263 685f  pts.json,search_
-00015570: 7465 726d 290a 2020 2020 2020 2020 2020  term).          
-00015580: 2020 2020 2020 6669 7273 745f 636f 6761        first_coga
-00015590: 746c 6173 5f63 6f6e 6365 7074 203d 2054  tlas_concept = T
-000155a0: 7275 650a 2020 2020 2020 2020 2020 2020  rue.            
-000155b0: 2020 2020 666f 7220 6b65 792c 2073 7562      for key, sub
-000155c0: 6469 6374 2069 6e20 636f 6761 746c 6173  dict in cogatlas
-000155d0: 5f63 6f6e 6365 7074 735f 7175 6572 792e  _concepts_query.
-000155e0: 6974 656d 7328 293a 0a20 2020 2020 2020  items():.       
-000155f0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00015600: 636f 6761 746c 6173 5f63 6f6e 6365 7074  cogatlas_concept
-00015610: 735f 7175 6572 795b 6b65 795d 5b27 7363  s_query[key]['sc
-00015620: 6f72 6527 5d20 3e20 6d69 6e5f 6d61 7463  ore'] > min_matc
-00015630: 685f 7363 6f72 652b 3230 3a0a 2020 2020  h_score+20:.    
-00015640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015650: 2020 2020 6966 2066 6972 7374 5f63 6f67      if first_cog
-00015660: 6174 6c61 735f 636f 6e63 6570 743a 0a20  atlas_concept:. 
-00015670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015680: 2020 2020 2020 2020 2020 2070 7269 6e74             print
-00015690: 2829 0a20 2020 2020 2020 2020 2020 2020  ().             
-000156a0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-000156b0: 7269 6e74 2822 436f 676e 6974 6976 6520  rint("Cognitive 
-000156c0: 4174 6c61 733a 2229 0a20 2020 2020 2020  Atlas:").       
-000156d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000156e0: 2020 2020 2070 7269 6e74 2829 0a20 2020       print().   
-000156f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015700: 2020 2020 2020 2020 2066 6972 7374 5f63           first_c
-00015710: 6f67 6174 6c61 735f 636f 6e63 6570 7420  ogatlas_concept 
-00015720: 3d20 4661 6c73 650a 0a20 2020 2020 2020  = False..       
-00015730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015740: 2070 7269 6e74 2822 2564 3a20 4c61 6265   print("%d: Labe
-00015750: 6c3a 2025 7320 5c74 2044 6566 696e 6974  l: %s \t Definit
-00015760: 696f 6e3a 2020 2025 7320 2220 2520 280a  ion:   %s " % (.
-00015770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015780: 2020 2020 2020 2020 2020 2020 6f70 7469              opti
-00015790: 6f6e 2c20 636f 6761 746c 6173 5f63 6f6e  on, cogatlas_con
-000157a0: 6365 7074 735f 7175 6572 795b 6b65 795d  cepts_query[key]
-000157b0: 5b27 6c61 6265 6c27 5d2c 2063 6f67 6174  ['label'], cogat
-000157c0: 6c61 735f 636f 6e63 6570 7473 5f71 7565  las_concepts_que
-000157d0: 7279 5b6b 6579 5d5b 2764 6566 696e 6974  ry[key]['definit
-000157e0: 696f 6e27 5d2e 7273 7472 6970 2827 5c72  ion'].rstrip('\r
-000157f0: 5c6e 2729 2929 0a20 2020 2020 2020 2020  \n'))).         
-00015800: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00015810: 6561 7263 685f 7265 7375 6c74 5b6b 6579  earch_result[key
-00015820: 5d20 3d20 7b7d 0a20 2020 2020 2020 2020  ] = {}.         
-00015830: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00015840: 6561 7263 685f 7265 7375 6c74 5b6b 6579  earch_result[key
-00015850: 5d5b 276c 6162 656c 275d 203d 2063 6f67  ]['label'] = cog
-00015860: 6174 6c61 735f 636f 6e63 6570 7473 5f71  atlas_concepts_q
-00015870: 7565 7279 5b6b 6579 5d5b 276c 6162 656c  uery[key]['label
-00015880: 275d 0a20 2020 2020 2020 2020 2020 2020  '].             
-00015890: 2020 2020 2020 2020 2020 2073 6561 7263             searc
-000158a0: 685f 7265 7375 6c74 5b6b 6579 5d5b 2764  h_result[key]['d
-000158b0: 6566 696e 6974 696f 6e27 5d20 3d20 636f  efinition'] = co
-000158c0: 6761 746c 6173 5f63 6f6e 6365 7074 735f  gatlas_concepts_
-000158d0: 7175 6572 795b 6b65 795d 5b27 6465 6669  query[key]['defi
-000158e0: 6e69 7469 6f6e 275d 2e72 7374 7269 7028  nition'].rstrip(
-000158f0: 275c 725c 6e27 290a 2020 2020 2020 2020  '\r\n').        
-00015900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015910: 7365 6172 6368 5f72 6573 756c 745b 6b65  search_result[ke
-00015920: 795d 5b27 7072 6566 6572 7265 645f 7572  y]['preferred_ur
-00015930: 6c27 5d20 3d20 636f 6761 746c 6173 5f63  l'] = cogatlas_c
-00015940: 6f6e 6365 7074 735f 7175 6572 795b 6b65  oncepts_query[ke
-00015950: 795d 5b27 7572 6c27 5d0a 2020 2020 2020  y]['url'].      
-00015960: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015970: 2020 7365 6172 6368 5f72 6573 756c 745b    search_result[
-00015980: 7374 7228 6f70 7469 6f6e 295d 203d 206b  str(option)] = k
-00015990: 6579 0a20 2020 2020 2020 2020 2020 2020  ey.             
-000159a0: 2020 2020 2020 2020 2020 206f 7074 696f             optio
-000159b0: 6e20 3d20 6f70 7469 6f6e 202b 2031 0a20  n = option + 1. 
-000159c0: 2020 2020 2020 2020 2020 2065 7863 6570             excep
-000159d0: 743a 0a20 2020 2020 2020 2020 2020 2020  t:.             
-000159e0: 2020 2070 6173 730a 0a20 2020 2020 2020     pass..       
-000159f0: 2020 2020 2023 2043 6f67 6e69 7469 7665       # Cognitive
-00015a00: 2041 746c 6173 2044 6973 6f72 6465 7273   Atlas Disorders
-00015a10: 2053 6561 7263 680a 2020 2020 2020 2020   Search.        
-00015a20: 2020 2020 7472 793a 0a20 2020 2020 2020      try:.       
-00015a30: 2020 2020 2020 2020 2063 6f67 6174 6c61           cogatla
-00015a40: 735f 6469 736f 7264 6572 735f 7175 6572  s_disorders_quer
-00015a50: 7920 3d20 6675 7a7a 795f 6d61 7463 685f  y = fuzzy_match_
-00015a60: 7465 726d 735f 6672 6f6d 5f63 6f67 6174  terms_from_cogat
-00015a70: 6c61 735f 6a73 6f6e 2863 6f67 6174 6c61  las_json(cogatla
-00015a80: 735f 6469 736f 7264 6572 732e 6a73 6f6e  s_disorders.json
-00015a90: 2c20 7365 6172 6368 5f74 6572 6d29 0a20  , search_term). 
-00015aa0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00015ab0: 6f72 206b 6579 2c20 7375 6264 6963 7420  or key, subdict 
-00015ac0: 696e 2063 6f67 6174 6c61 735f 6469 736f  in cogatlas_diso
-00015ad0: 7264 6572 735f 7175 6572 792e 6974 656d  rders_query.item
-00015ae0: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
-00015af0: 2020 2020 2020 2020 2069 6620 636f 6761           if coga
-00015b00: 746c 6173 5f64 6973 6f72 6465 7273 5f71  tlas_disorders_q
-00015b10: 7565 7279 5b6b 6579 5d5b 2773 636f 7265  uery[key]['score
-00015b20: 275d 203e 206d 696e 5f6d 6174 6368 5f73  '] > min_match_s
-00015b30: 636f 7265 2b32 303a 0a20 2020 2020 2020  core+20:.       
-00015b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015b50: 2070 7269 6e74 2822 2564 3a20 4c61 6265   print("%d: Labe
-00015b60: 6c3a 2025 7320 5c74 2044 6566 696e 6974  l: %s \t Definit
-00015b70: 696f 6e3a 2020 2025 7320 2220 2520 280a  ion:   %s " % (.
-00015b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015b90: 2020 2020 2020 2020 2020 2020 6f70 7469              opti
-00015ba0: 6f6e 2c20 636f 6761 746c 6173 5f64 6973  on, cogatlas_dis
-00015bb0: 6f72 6465 7273 5f71 7565 7279 5b6b 6579  orders_query[key
-00015bc0: 5d5b 276c 6162 656c 275d 2c20 636f 6761  ]['label'], coga
-00015bd0: 746c 6173 5f64 6973 6f72 6465 7273 5f71  tlas_disorders_q
-00015be0: 7565 7279 5b6b 6579 5d5b 2764 6566 696e  uery[key]['defin
-00015bf0: 6974 696f 6e27 5d2e 7273 7472 6970 2827  ition'].rstrip('
-00015c00: 5c72 5c6e 2729 2c0a 2020 2020 2020 2020  \r\n'),.        
-00015c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015c20: 2020 2020 2929 0a20 2020 2020 2020 2020      )).         
-00015c30: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00015c40: 6561 7263 685f 7265 7375 6c74 5b6b 6579  earch_result[key
-00015c50: 5d20 3d20 7b7d 0a20 2020 2020 2020 2020  ] = {}.         
-00015c60: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00015c70: 6561 7263 685f 7265 7375 6c74 5b6b 6579  earch_result[key
-00015c80: 5d5b 276c 6162 656c 275d 203d 2063 6f67  ]['label'] = cog
-00015c90: 6174 6c61 735f 6469 736f 7264 6572 735f  atlas_disorders_
-00015ca0: 7175 6572 795b 6b65 795d 5b27 6c61 6265  query[key]['labe
-00015cb0: 6c27 5d0a 2020 2020 2020 2020 2020 2020  l'].            
-00015cc0: 2020 2020 2020 2020 2020 2020 7365 6172              sear
-00015cd0: 6368 5f72 6573 756c 745b 6b65 795d 5b27  ch_result[key]['
-00015ce0: 6465 6669 6e69 7469 6f6e 275d 203d 2063  definition'] = c
-00015cf0: 6f67 6174 6c61 735f 6469 736f 7264 6572  ogatlas_disorder
-00015d00: 735f 7175 6572 795b 6b65 795d 5b27 6465  s_query[key]['de
-00015d10: 6669 6e69 7469 6f6e 275d 2e72 7374 7269  finition'].rstri
-00015d20: 7028 275c 725c 6e27 290a 2020 2020 2020  p('\r\n').      
-00015d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015d40: 2020 7365 6172 6368 5f72 6573 756c 745b    search_result[
-00015d50: 6b65 795d 5b27 7072 6566 6572 7265 645f  key]['preferred_
-00015d60: 7572 6c27 5d20 3d20 636f 6761 746c 6173  url'] = cogatlas
-00015d70: 5f64 6973 6f72 6465 7273 5f71 7565 7279  _disorders_query
-00015d80: 5b6b 6579 5d5b 2775 726c 275d 0a20 2020  [key]['url'].   
-00015d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015da0: 2020 2020 2073 6561 7263 685f 7265 7375       search_resu
-00015db0: 6c74 5b73 7472 286f 7074 696f 6e29 5d20  lt[str(option)] 
-00015dc0: 3d20 6b65 790a 2020 2020 2020 2020 2020  = key.          
-00015dd0: 2020 2020 2020 2020 2020 2020 2020 6f70                op
-00015de0: 7469 6f6e 203d 206f 7074 696f 6e20 2b20  tion = option + 
-00015df0: 310a 2020 2020 2020 2020 2020 2020 6578  1.            ex
-00015e00: 6365 7074 3a0a 2020 2020 2020 2020 2020  cept:.          
-00015e10: 2020 2020 2020 7061 7373 0a0a 2020 2020        pass..    
-00015e20: 2020 2020 2020 2020 2320 6966 2075 7365          # if use
-00015e30: 7220 7375 7070 6c69 6564 2061 6e20 4f57  r supplied an OW
-00015e40: 4c20 6669 6c65 2074 6f20 7365 6172 6368  L file to search
-00015e50: 2069 6e20 666f 7220 7465 726d 730a 2020   in for terms.  
-00015e60: 2020 2020 2020 2020 2020 2320 6966 206f            # if o
-00015e70: 776c 5f66 696c 653a 0a0a 2020 2020 2020  wl_file:..      
-00015e80: 2020 2020 2020 6966 206e 6964 6d5f 6f77        if nidm_ow
-00015e90: 6c5f 6772 6170 6820 6973 206e 6f74 204e  l_graph is not N
-00015ea0: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-00015eb0: 2020 2020 2023 2041 6464 2065 7869 7374       # Add exist
-00015ec0: 696e 6720 4e49 444d 2054 6572 6d73 2061  ing NIDM Terms a
-00015ed0: 7320 706f 7373 6962 6c65 2073 656c 6563  s possible selec
-00015ee0: 7469 6f6e 7320 7768 6963 6820 6675 7a7a  tions which fuzz
-00015ef0: 7920 6d61 7463 6820 7468 6520 7365 6172  y match the sear
-00015f00: 6368 5f74 6572 6d0a 2020 2020 2020 2020  ch_term.        
-00015f10: 2020 2020 2020 2020 6e69 646d 5f63 6f6e          nidm_con
-00015f20: 7374 616e 7473 5f71 7565 7279 203d 2066  stants_query = f
-00015f30: 757a 7a79 5f6d 6174 6368 5f74 6572 6d73  uzzy_match_terms
-00015f40: 5f66 726f 6d5f 6772 6170 6828 6e69 646d  _from_graph(nidm
-00015f50: 5f6f 776c 5f67 7261 7068 2c20 7365 6172  _owl_graph, sear
-00015f60: 6368 5f74 6572 6d29 0a0a 2020 2020 2020  ch_term)..      
-00015f70: 2020 2020 2020 2020 2020 6669 7273 745f            first_
-00015f80: 6e69 646d 5f74 6572 6d20 3d20 5472 7565  nidm_term = True
-00015f90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00015fa0: 2066 6f72 206b 6579 2c20 7375 6264 6963   for key, subdic
-00015fb0: 7420 696e 206e 6964 6d5f 636f 6e73 7461  t in nidm_consta
-00015fc0: 6e74 735f 7175 6572 792e 6974 656d 7328  nts_query.items(
-00015fd0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00015fe0: 2020 2020 2020 2069 6620 6e69 646d 5f63         if nidm_c
-00015ff0: 6f6e 7374 616e 7473 5f71 7565 7279 5b6b  onstants_query[k
-00016000: 6579 5d5b 2773 636f 7265 275d 203e 206d  ey]['score'] > m
-00016010: 696e 5f6d 6174 6368 5f73 636f 7265 3a0a  in_match_score:.
-00016020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016030: 2020 2020 2020 2020 6966 2066 6972 7374          if first
-00016040: 5f6e 6964 6d5f 7465 726d 3a0a 2020 2020  _nidm_term:.    
-00016050: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016060: 2020 2020 2020 2020 7072 696e 7428 290a          print().
+00015250: 2020 2020 7772 6974 655f 6a73 6f6e 5f6d      write_json_m
+00015260: 6170 7069 6e67 5f66 696c 6528 636f 6c75  apping_file(colu
+00015270: 6d6e 5f74 6f5f 7465 726d 732c 206f 7574  mn_to_terms, out
+00015280: 7075 745f 6669 6c65 2c20 6269 6473 290a  put_file, bids).
+00015290: 0a20 2020 2020 2020 2020 2020 2070 7269  .            pri
+000152a0: 6e74 2822 2a22 202a 2038 3729 0a20 2020  nt("*" * 87).   
+000152b0: 2020 2020 2020 2020 2070 7269 6e74 2822           print("
+000152c0: 2d22 202a 2038 3729 0a0a 2020 2020 2020  -" * 87)..      
+000152d0: 2020 2020 2020 6966 2028 6a73 6f6e 5f6d        if (json_m
+000152e0: 6170 2069 7320 6e6f 7420 4e6f 6e65 2920  ap is not None) 
+000152f0: 616e 6420 286c 656e 286a 736f 6e5f 6b65  and (len(json_ke
+00015300: 7929 203e 2030 293a 0a20 2020 2020 2020  y) > 0):.       
+00015310: 2020 2020 2020 2020 2063 6f6e 7469 6e75           continu
+00015320: 650a 2020 2020 2020 2020 656c 7365 3a0a  e.        else:.
+00015330: 2020 2020 2020 2020 2020 2020 7072 696e              prin
+00015340: 7428 226a 736f 6e20 616e 6e6f 7461 7469  t("json annotati
+00015350: 6f6e 2066 696c 6520 6e6f 7420 7375 7070  on file not supp
+00015360: 6c69 6564 2229 0a0a 2020 2020 2020 2020  lied")..        
+00015370: 7365 6172 6368 5f74 6572 6d20 3d20 7374  search_term = st
+00015380: 7228 636f 6c75 6d6e 290a 2020 2020 2020  r(column).      
+00015390: 2020 2320 6164 6465 6420 666f 7220 616e    # added for an
+000153a0: 2061 7574 6f6d 6174 6963 206d 6170 7069   automatic mappi
+000153b0: 6e67 206f 6620 7061 7274 6963 6970 616e  ng of participan
+000153c0: 745f 6964 2c20 7375 626a 6563 745f 6964  t_id, subject_id
+000153d0: 2c20 616e 6420 7661 7269 616e 7473 0a20  , and variants. 
+000153e0: 2020 2020 2020 2069 6620 6d61 7463 685f         if match_
+000153f0: 7061 7274 6963 6970 616e 745f 6964 5f66  participant_id_f
+00015400: 6965 6c64 2873 6561 7263 685f 7465 726d  ield(search_term
+00015410: 2e6c 6f77 6572 2829 293a 0a20 2020 2020  .lower()):.     
+00015420: 2020 2020 2020 2023 206d 6170 2074 6869         # map thi
+00015430: 7320 7465 726d 2074 6f20 436f 6e73 7461  s term to Consta
+00015440: 6e74 732e 4e49 444d 5f53 5542 4a45 4354  nts.NIDM_SUBJECT
+00015450: 4944 0a20 2020 2020 2020 2020 2020 2023  ID.            #
+00015460: 2073 696e 6365 206f 7572 2073 7562 6a65   since our subje
+00015470: 6374 2069 6473 2061 7265 2073 7461 7469  ct ids are stati
+00015480: 6361 6c6c 7920 6d61 7070 6564 2074 6f20  cally mapped to 
+00015490: 7468 6520 436f 6e73 7461 6e74 732e 4e49  the Constants.NI
+000154a0: 444d 5f53 5542 4a45 4354 4944 2077 6527  DM_SUBJECTID we'
+000154b0: 7265 2063 7265 6174 696e 6720 6120 6e65  re creating a ne
+000154c0: 770a 2020 2020 2020 2020 2020 2020 2320  w.            # 
+000154d0: 6e61 6d65 6420 7475 706c 6520 666f 7220  named tuple for 
+000154e0: 7468 6973 206a 736f 6e20 6d61 7020 656e  this json map en
+000154f0: 7472 7920 6173 2069 7427 7320 6e6f 7420  try as it's not 
+00015500: 7468 6520 7361 6d65 2073 6f75 7263 6520  the same source 
+00015510: 6173 2074 6865 2072 6573 7420 6f66 2074  as the rest of t
+00015520: 6865 2064 6174 6120 6672 616d 6520 7768  he data frame wh
+00015530: 6963 680a 2020 2020 2020 2020 2020 2020  ich.            
+00015540: 2320 636f 6d65 7320 6672 6f6d 2074 6865  # comes from the
+00015550: 2027 6173 7365 7373 6d65 6e74 5f6e 616d   'assessment_nam
+00015560: 6527 2066 756e 6374 696f 6e20 7061 7261  e' function para
+00015570: 6d65 7465 722e 0a20 2020 2020 2020 2020  meter..         
+00015580: 2020 2073 7562 6a69 645f 7475 706c 6520     subjid_tuple 
+00015590: 3d20 7374 7228 4444 2873 6f75 7263 653d  = str(DD(source=
+000155a0: 6173 7365 7373 6d65 6e74 5f6e 616d 652c  assessment_name,
+000155b0: 2076 6172 6961 626c 653d 7365 6172 6368   variable=search
+000155c0: 5f74 6572 6d29 290a 2020 2020 2020 2020  _term)).        
+000155d0: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
+000155e0: 726d 735b 7375 626a 6964 5f74 7570 6c65  rms[subjid_tuple
+000155f0: 5d20 3d20 7b7d 0a20 2020 2020 2020 2020  ] = {}.         
+00015600: 2020 2063 6f6c 756d 6e5f 746f 5f74 6572     column_to_ter
+00015610: 6d73 5b73 7562 6a69 645f 7475 706c 655d  ms[subjid_tuple]
+00015620: 5b22 6c61 6265 6c22 5d20 3d20 7365 6172  ["label"] = sear
+00015630: 6368 5f74 6572 6d0a 2020 2020 2020 2020  ch_term.        
+00015640: 2020 2020 636f 6c75 6d6e 5f74 6f5f 7465      column_to_te
+00015650: 726d 735b 7375 626a 6964 5f74 7570 6c65  rms[subjid_tuple
+00015660: 5d5b 0a20 2020 2020 2020 2020 2020 2020  ][.             
+00015670: 2020 2022 6465 7363 7269 7074 696f 6e22     "description"
+00015680: 0a20 2020 2020 2020 2020 2020 205d 203d  .            ] =
+00015690: 2022 7375 626a 6563 742f 7061 7274 6963   "subject/partic
+000156a0: 6970 616e 7420 6964 656e 7469 6669 6572  ipant identifier
+000156b0: 220a 2020 2020 2020 2020 2020 2020 636f  ".            co
+000156c0: 6c75 6d6e 5f74 6f5f 7465 726d 735b 7375  lumn_to_terms[su
+000156d0: 626a 6964 5f74 7570 6c65 5d5b 2273 6f75  bjid_tuple]["sou
+000156e0: 7263 655f 7661 7269 6162 6c65 225d 203d  rce_variable"] =
+000156f0: 2073 7472 2873 6561 7263 685f 7465 726d   str(search_term
+00015700: 290a 2020 2020 2020 2020 2020 2020 2320  ).            # 
+00015710: 6164 6465 6420 746f 2073 7570 706f 7274  added to support
+00015720: 2072 6570 726f 7363 6865 6d61 2066 6f72   reproschema for
+00015730: 6d61 740a 2020 2020 2020 2020 2020 2020  mat.            
+00015740: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
+00015750: 7375 626a 6964 5f74 7570 6c65 5d5b 2272  subjid_tuple]["r
+00015760: 6573 706f 6e73 654f 7074 696f 6e73 225d  esponseOptions"]
+00015770: 203d 207b 7d0a 2020 2020 2020 2020 2020   = {}.          
+00015780: 2020 636f 6c75 6d6e 5f74 6f5f 7465 726d    column_to_term
+00015790: 735b 7375 626a 6964 5f74 7570 6c65 5d5b  s[subjid_tuple][
+000157a0: 2272 6573 706f 6e73 654f 7074 696f 6e73  "responseOptions
+000157b0: 225d 5b22 7661 6c75 6554 7970 6522 5d20  "]["valueType"] 
+000157c0: 3d20 5552 4952 6566 280a 2020 2020 2020  = URIRef(.      
+000157d0: 2020 2020 2020 2020 2020 436f 6e73 7461            Consta
+000157e0: 6e74 732e 5853 445b 2273 7472 696e 6722  nts.XSD["string"
+000157f0: 5d0a 2020 2020 2020 2020 2020 2020 290a  ].            ).
+00015800: 2020 2020 2020 2020 2020 2020 636f 6c75              colu
+00015810: 6d6e 5f74 6f5f 7465 726d 735b 7375 626a  mn_to_terms[subj
+00015820: 6964 5f74 7570 6c65 5d5b 2269 7341 626f  id_tuple]["isAbo
+00015830: 7574 225d 203d 205b 5d0a 2020 2020 2020  ut"] = [].      
+00015840: 2020 2020 2020 636f 6c75 6d6e 5f74 6f5f        column_to_
+00015850: 7465 726d 735b 7375 626a 6964 5f74 7570  terms[subjid_tup
+00015860: 6c65 5d5b 2269 7341 626f 7574 225d 2e61  le]["isAbout"].a
+00015870: 7070 656e 6428 0a20 2020 2020 2020 2020  ppend(.         
+00015880: 2020 2020 2020 207b 0a20 2020 2020 2020         {.       
+00015890: 2020 2020 2020 2020 2020 2020 2022 4069               "@i
+000158a0: 6422 3a20 436f 6e73 7461 6e74 732e 4e49  d": Constants.NI
+000158b0: 444d 5f53 5542 4a45 4354 4944 2e75 7269  DM_SUBJECTID.uri
+000158c0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000158d0: 2020 2020 2020 226c 6162 656c 223a 2043        "label": C
+000158e0: 6f6e 7374 616e 7473 2e4e 4944 4d5f 5355  onstants.NIDM_SU
+000158f0: 424a 4543 5449 442e 6c6f 6361 6c70 6172  BJECTID.localpar
+00015900: 742c 0a20 2020 2020 2020 2020 2020 2020  t,.             
+00015910: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
+00015920: 2029 0a20 2020 2020 2020 2020 2020 2023   ).            #
+00015930: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+00015940: 5b73 7562 6a69 645f 7475 706c 655d 5b27  [subjid_tuple]['
+00015950: 7661 7269 6162 6c65 275d 203d 2073 7472  variable'] = str
+00015960: 2863 6f6c 756d 6e29 0a0a 2020 2020 2020  (column)..      
+00015970: 2020 2020 2020 7072 696e 7428 0a20 2020        print(.   
+00015980: 2020 2020 2020 2020 2020 2020 2066 2256               f"V
+00015990: 6172 6961 626c 6520 7b73 6561 7263 685f  ariable {search_
+000159a0: 7465 726d 7d20 6175 746f 6d61 7469 6361  term} automatica
+000159b0: 6c6c 7920 6d61 7070 6564 2074 6f20 7061  lly mapped to pa
+000159c0: 7274 6963 6970 616e 742f 7375 626a 6563  rticipant/subjec
+000159d0: 7420 6964 656e 7469 6669 6572 220a 2020  t identifier".  
+000159e0: 2020 2020 2020 2020 2020 290a 2020 2020            ).    
+000159f0: 2020 2020 2020 2020 7072 696e 7428 224c          print("L
+00015a00: 6162 656c 3a22 2c20 636f 6c75 6d6e 5f74  abel:", column_t
+00015a10: 6f5f 7465 726d 735b 7375 626a 6964 5f74  o_terms[subjid_t
+00015a20: 7570 6c65 5d5b 226c 6162 656c 225d 290a  uple]["label"]).
+00015a30: 2020 2020 2020 2020 2020 2020 7072 696e              prin
+00015a40: 7428 2244 6573 6372 6970 7469 6f6e 3a22  t("Description:"
+00015a50: 2c20 636f 6c75 6d6e 5f74 6f5f 7465 726d  , column_to_term
+00015a60: 735b 7375 626a 6964 5f74 7570 6c65 5d5b  s[subjid_tuple][
+00015a70: 2264 6573 6372 6970 7469 6f6e 225d 290a  "description"]).
+00015a80: 2020 2020 2020 2020 2020 2020 2320 7072              # pr
+00015a90: 696e 7428 2255 726c 3a22 2c20 636f 6c75  int("Url:", colu
+00015aa0: 6d6e 5f74 6f5f 7465 726d 735b 7375 626a  mn_to_terms[subj
+00015ab0: 6964 5f74 7570 6c65 5d5b 2775 726c 275d  id_tuple]['url']
+00015ac0: 290a 2020 2020 2020 2020 2020 2020 7072  ).            pr
+00015ad0: 696e 7428 2253 6f75 7263 6520 5661 7269  int("Source Vari
+00015ae0: 6162 6c65 3a22 2c20 636f 6c75 6d6e 5f74  able:", column_t
+00015af0: 6f5f 7465 726d 735b 7375 626a 6964 5f74  o_terms[subjid_t
+00015b00: 7570 6c65 5d5b 2273 6f75 7263 655f 7661  uple]["source_va
+00015b10: 7269 6162 6c65 225d 290a 2020 2020 2020  riable"]).      
+00015b20: 2020 2020 2020 7072 696e 7428 222d 2220        print("-" 
+00015b30: 2a20 3837 290a 2020 2020 2020 2020 2020  * 87).          
+00015b40: 2020 636f 6e74 696e 7565 0a20 2020 2020    continue.     
+00015b50: 2020 2023 2069 6620 7765 2068 6176 656e     # if we haven
+00015b60: 2774 2061 6c72 6561 6479 2066 6f75 6e64  't already found
+00015b70: 2061 6e20 616e 6e6f 7461 7469 6f6e 2066   an annotation f
+00015b80: 6f72 2074 6869 7320 636f 6c75 6d6e 2074  or this column t
+00015b90: 6865 6e20 6861 7665 2075 7365 7220 6372  hen have user cr
+00015ba0: 6561 7465 206f 6e65 2e0a 2020 2020 2020  eate one..      
+00015bb0: 2020 6966 2063 7572 7265 6e74 5f74 7570    if current_tup
+00015bc0: 6c65 206e 6f74 2069 6e20 636f 6c75 6d6e  le not in column
+00015bd0: 5f74 6f5f 7465 726d 733a 0a20 2020 2020  _to_terms:.     
+00015be0: 2020 2020 2020 2023 2063 7265 6174 6520         # create 
+00015bf0: 656d 7074 7920 616e 6e6f 7461 7469 6f6e  empty annotation
+00015c00: 2073 7472 7563 7475 7265 2066 6f72 2074   structure for t
+00015c10: 6869 7320 736f 7572 6365 2076 6172 6961  his source varia
+00015c20: 626c 650a 2020 2020 2020 2020 2020 2020  ble.            
+00015c30: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
+00015c40: 6375 7272 656e 745f 7475 706c 655d 203d  current_tuple] =
+00015c50: 207b 7d0a 2020 2020 2020 2020 2020 2020   {}.            
+00015c60: 2320 656e 7465 7220 7573 6572 2069 6e74  # enter user int
+00015c70: 6572 6163 7469 6f6e 2066 756e 6374 696f  eraction functio
+00015c80: 6e20 746f 2067 6574 2064 6174 6120 6469  n to get data di
+00015c90: 6374 696f 6e61 7279 2061 6e6e 6f74 6174  ctionary annotat
+00015ca0: 696f 6e73 2066 726f 6d20 7573 6572 0a20  ions from user. 
+00015cb0: 2020 2020 2020 2020 2020 2061 6e6e 6f74             annot
+00015cc0: 6174 655f 6461 7461 5f65 6c65 6d65 6e74  ate_data_element
+00015cd0: 2863 6f6c 756d 6e2c 2063 7572 7265 6e74  (column, current
+00015ce0: 5f74 7570 6c65 2c20 636f 6c75 6d6e 5f74  _tuple, column_t
+00015cf0: 6f5f 7465 726d 7329 0a20 2020 2020 2020  o_terms).       
+00015d00: 2023 2074 6865 6e20 6173 6b20 7573 6572   # then ask user
+00015d10: 2074 6f20 6669 6e64 2061 2063 6f6e 6365   to find a conce
+00015d20: 7074 2069 6620 7468 6579 2073 656c 6563  pt if they selec
+00015d30: 7465 6420 746f 2064 6f20 736f 0a20 2020  ted to do so.   
+00015d40: 2020 2020 2069 6620 6173 736f 6369 6174       if associat
+00015d50: 655f 636f 6e63 6570 7473 3a0a 2020 2020  e_concepts:.    
+00015d60: 2020 2020 2020 2020 2320 7072 6f76 6964          # provid
+00015d70: 6520 7573 6572 2077 6974 6820 6f70 706f  e user with oppo
+00015d80: 7274 756e 6974 7920 746f 2061 7373 6f63  rtunity to assoc
+00015d90: 6961 7465 2061 2063 6f6e 6365 7074 2077  iate a concept w
+00015da0: 6974 6820 7468 6973 2061 6e6e 6f74 6174  ith this annotat
+00015db0: 696f 6e0a 2020 2020 2020 2020 2020 2020  ion.            
+00015dc0: 6669 6e64 5f63 6f6e 6365 7074 5f69 6e74  find_concept_int
+00015dd0: 6572 6163 7469 7665 280a 2020 2020 2020  eractive(.      
+00015de0: 2020 2020 2020 2020 2020 636f 6c75 6d6e            column
+00015df0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00015e00: 2020 6375 7272 656e 745f 7475 706c 652c    current_tuple,
+00015e10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00015e20: 2063 6f6c 756d 6e5f 746f 5f74 6572 6d73   column_to_terms
+00015e30: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00015e40: 2020 696c 785f 6f62 6a2c 0a20 2020 2020    ilx_obj,.     
+00015e50: 2020 2020 2020 2020 2020 206e 6964 6d5f             nidm_
+00015e60: 6f77 6c5f 6772 6170 683d 6e69 646d 5f6f  owl_graph=nidm_o
+00015e70: 776c 5f67 7261 7068 2c0a 2020 2020 2020  wl_graph,.      
+00015e80: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00015e90: 2020 2020 2320 7772 6974 6520 616e 6e6f      # write anno
+00015ea0: 7461 7469 6f6e 7320 746f 206a 736f 6e20  tations to json 
+00015eb0: 6669 6c65 2073 6f20 7573 6572 2063 616e  file so user can
+00015ec0: 2073 7461 7274 2075 7020 6167 6169 6e20   start up again 
+00015ed0: 6966 206e 6f74 2064 6f69 6e67 2077 686f  if not doing who
+00015ee0: 6c65 2066 696c 650a 2020 2020 2020 2020  le file.        
+00015ef0: 2020 2020 7772 6974 655f 6a73 6f6e 5f6d      write_json_m
+00015f00: 6170 7069 6e67 5f66 696c 6528 636f 6c75  apping_file(colu
+00015f10: 6d6e 5f74 6f5f 7465 726d 732c 206f 7574  mn_to_terms, out
+00015f20: 7075 745f 6669 6c65 2c20 6269 6473 290a  put_file, bids).
+00015f30: 0a20 2020 2020 2020 2074 7279 3a0a 2020  .        try:.  
+00015f40: 2020 2020 2020 2020 2020 2320 6e6f 7720            # now 
+00015f50: 7765 2073 686f 756c 6420 6164 6420 7468  we should add th
+00015f60: 6520 6461 7461 2065 6c65 6d65 6e74 2064  e data element d
+00015f70: 6566 696e 6974 696f 6e20 7769 7468 2063  efinition with c
+00015f80: 6f6e 6365 7074 2061 6e6e 6f74 6174 696f  oncept annotatio
+00015f90: 6e20 746f 2049 6e74 6572 4c65 780a 2020  n to InterLex.  
+00015fa0: 2020 2020 2020 2020 2020 2320 6368 6563            # chec
+00015fb0: 6b20 6966 2074 6869 7320 6973 2061 2063  k if this is a c
+00015fc0: 6174 6567 6f72 6963 616c 2076 6172 6961  ategorical varia
+00015fd0: 626c 652c 2069 6620 736f 2069 7420 7769  ble, if so it wi
+00015fe0: 6c6c 2068 6176 6520 276c 6576 656c 7327  ll have 'levels'
+00015ff0: 206b 6579 0a20 2020 2020 2020 2020 2020   key.           
+00016000: 2069 6620 226c 6576 656c 7322 2069 6e20   if "levels" in 
+00016010: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
+00016020: 6375 7272 656e 745f 7475 706c 655d 3a0a  current_tuple]:.
+00016030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016040: 6966 2022 6973 4162 6f75 7422 2069 6e20  if "isAbout" in 
+00016050: 636f 6c75 6d6e 5f74 6f5f 7465 726d 735b  column_to_terms[
+00016060: 6375 7272 656e 745f 7475 706c 655d 3a0a  current_tuple]:.
 00016070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016080: 2020 2020 2020 2020 2020 2020 7072 696e              prin
-00016090: 7428 224e 4944 4d20 4f6e 746f 6c6f 6779  t("NIDM Ontology
-000160a0: 2054 6572 6d73 3a22 290a 2020 2020 2020   Terms:").      
-000160b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000160c0: 2020 2020 2020 6669 7273 745f 6e69 646d        first_nidm
-000160d0: 5f74 6572 6d20 3d20 4661 6c73 650a 0a20  _term = False.. 
-000160e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000160f0: 2020 2020 2020 2070 7269 6e74 2822 2564         print("%d
-00016100: 3a20 4c61 6265 6c3a 2025 7320 5c74 2044  : Label: %s \t D
-00016110: 6566 696e 6974 696f 6e3a 2025 7320 5c74  efinition: %s \t
-00016120: 2055 524c 3a20 2573 2220 2520 280a 2020   URL: %s" % (.  
-00016130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016140: 2020 2020 2020 2020 2020 2020 2020 6f70                op
-00016150: 7469 6f6e 2c20 6e69 646d 5f63 6f6e 7374  tion, nidm_const
-00016160: 616e 7473 5f71 7565 7279 5b6b 6579 5d5b  ants_query[key][
-00016170: 276c 6162 656c 275d 2c20 6e69 646d 5f63  'label'], nidm_c
-00016180: 6f6e 7374 616e 7473 5f71 7565 7279 5b6b  onstants_query[k
-00016190: 6579 5d5b 2764 6566 696e 6974 696f 6e27  ey]['definition'
-000161a0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00016080: 2020 2020 696c 785f 6f75 7470 7574 203d      ilx_output =
+00016090: 2041 6464 5044 4554 6f49 6e74 6572 6c65   AddPDEToInterle
+000160a0: 7828 0a20 2020 2020 2020 2020 2020 2020  x(.             
+000160b0: 2020 2020 2020 2020 2020 2069 6c78 5f6f             ilx_o
+000160c0: 626a 3d69 6c78 5f6f 626a 2c0a 2020 2020  bj=ilx_obj,.    
+000160d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000160e0: 2020 2020 6c61 6265 6c3d 636f 6c75 6d6e      label=column
+000160f0: 5f74 6f5f 7465 726d 735b 6375 7272 656e  _to_terms[curren
+00016100: 745f 7475 706c 655d 5b22 6c61 6265 6c22  t_tuple]["label"
+00016110: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00016120: 2020 2020 2020 2020 2020 2064 6566 696e             defin
+00016130: 6974 696f 6e3d 636f 6c75 6d6e 5f74 6f5f  ition=column_to_
+00016140: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
+00016150: 706c 655d 5b22 6465 7363 7269 7074 696f  ple]["descriptio
+00016160: 6e22 5d2c 0a20 2020 2020 2020 2020 2020  n"],.           
+00016170: 2020 2020 2020 2020 2020 2020 206d 696e               min
+00016180: 3d63 6f6c 756d 6e5f 746f 5f74 6572 6d73  =column_to_terms
+00016190: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+000161a0: 226d 696e 5661 6c75 6522 5d2c 0a20 2020  "minValue"],.   
 000161b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000161c0: 2020 206e 6964 6d5f 636f 6e73 7461 6e74     nidm_constant
-000161d0: 735f 7175 6572 795b 6b65 795d 5b27 7572  s_query[key]['ur
-000161e0: 6c27 5d29 290a 2020 2020 2020 2020 2020  l'])).          
-000161f0: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00016200: 6172 6368 5f72 6573 756c 745b 6b65 795d  arch_result[key]
-00016210: 203d 207b 7d0a 2020 2020 2020 2020 2020   = {}.          
-00016220: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00016230: 6172 6368 5f72 6573 756c 745b 6b65 795d  arch_result[key]
-00016240: 5b27 6c61 6265 6c27 5d20 3d20 6e69 646d  ['label'] = nidm
-00016250: 5f63 6f6e 7374 616e 7473 5f71 7565 7279  _constants_query
-00016260: 5b6b 6579 5d5b 276c 6162 656c 275d 0a20  [key]['label']. 
-00016270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016280: 2020 2020 2020 2073 6561 7263 685f 7265         search_re
-00016290: 7375 6c74 5b6b 6579 5d5b 2764 6566 696e  sult[key]['defin
-000162a0: 6974 696f 6e27 5d20 3d20 6e69 646d 5f63  ition'] = nidm_c
-000162b0: 6f6e 7374 616e 7473 5f71 7565 7279 5b6b  onstants_query[k
-000162c0: 6579 5d5b 2764 6566 696e 6974 696f 6e27  ey]['definition'
-000162d0: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
-000162e0: 2020 2020 2020 2020 2020 7365 6172 6368            search
-000162f0: 5f72 6573 756c 745b 6b65 795d 5b27 7072  _result[key]['pr
-00016300: 6566 6572 7265 645f 7572 6c27 5d20 3d20  eferred_url'] = 
-00016310: 6e69 646d 5f63 6f6e 7374 616e 7473 5f71  nidm_constants_q
-00016320: 7565 7279 5b6b 6579 5d5b 2775 726c 275d  uery[key]['url']
-00016330: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00016340: 2020 2020 2020 2020 2073 6561 7263 685f           search_
-00016350: 7265 7375 6c74 5b73 7472 286f 7074 696f  result[str(optio
-00016360: 6e29 5d20 3d20 6b65 790a 2020 2020 2020  n)] = key.      
+000161c0: 2020 2020 206d 6178 3d63 6f6c 756d 6e5f       max=column_
+000161d0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+000161e0: 5f74 7570 6c65 5d5b 226d 6178 5661 6c75  _tuple]["maxValu
+000161f0: 6522 5d2c 0a20 2020 2020 2020 2020 2020  e"],.           
+00016200: 2020 2020 2020 2020 2020 2020 2075 6e69               uni
+00016210: 7473 3d63 6f6c 756d 6e5f 746f 5f74 6572  ts=column_to_ter
+00016220: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
+00016230: 5d5b 2268 6173 556e 6974 225d 2c0a 2020  ]["hasUnit"],.  
+00016240: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016250: 2020 2020 2020 6461 7461 7479 7065 3d63        datatype=c
+00016260: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
+00016270: 7572 7265 6e74 5f74 7570 6c65 5d5b 2276  urrent_tuple]["v
+00016280: 616c 7565 5479 7065 225d 2c0a 2020 2020  alueType"],.    
+00016290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000162a0: 2020 2020 6973 6162 6f75 743d 636f 6c75      isabout=colu
+000162b0: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+000162c0: 656e 745f 7475 706c 655d 5b22 6973 4162  ent_tuple]["isAb
+000162d0: 6f75 7422 5d2c 0a20 2020 2020 2020 2020  out"],.         
+000162e0: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+000162f0: 6174 6567 6f72 796d 6170 7069 6e67 733d  ategorymappings=
+00016300: 6a73 6f6e 2e64 756d 7073 280a 2020 2020  json.dumps(.    
+00016310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016320: 2020 2020 2020 2020 636f 6c75 6d6e 5f74          column_t
+00016330: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
+00016340: 7475 706c 655d 5b22 6c65 7665 6c73 225d  tuple]["levels"]
+00016350: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00016360: 2020 2020 2020 2020 2029 2c0a 2020 2020           ),.    
 00016370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016380: 2020 6f70 7469 6f6e 203d 206f 7074 696f    option = optio
-00016390: 6e20 2b20 310a 0a20 2020 2020 2020 2070  n + 1..        p
-000163a0: 7269 6e74 2829 0a20 2020 2020 2020 2069  rint().        i
-000163b0: 6620 616e 6365 7374 6f72 3a0a 2020 2020  f ancestor:.    
-000163c0: 2020 2020 2020 2020 2320 4272 6f61 6465          # Broade
-000163d0: 6e20 496e 7465 726c 6578 2073 6561 7263  n Interlex searc
-000163e0: 680a 2020 2020 2020 2020 2020 2020 7072  h.            pr
-000163f0: 696e 7428 2225 643a 2042 726f 6164 656e  int("%d: Broaden
-00016400: 2053 6561 7263 6820 2869 6e63 6c75 6465   Search (include
-00016410: 7320 696e 7465 726c 6578 2c20 636f 6761  s interlex, coga
-00016420: 746c 6173 2c20 616e 6420 6e69 646d 206f  tlas, and nidm o
-00016430: 6e74 6f6c 6f67 7929 2022 2025 206f 7074  ntology) " % opt
-00016440: 696f 6e29 0a20 2020 2020 2020 2065 6c73  ion).        els
-00016450: 653a 0a20 2020 2020 2020 2020 2020 2023  e:.            #
-00016460: 204e 6172 726f 7720 496e 7465 726c 6578   Narrow Interlex
-00016470: 2073 6561 7263 680a 2020 2020 2020 2020   search.        
-00016480: 2020 2020 7072 696e 7428 2225 643a 204e      print("%d: N
-00016490: 6172 726f 7720 5365 6172 6368 2028 696e  arrow Search (in
-000164a0: 636c 7564 6573 206e 6964 6d2d 7465 726d  cludes nidm-term
-000164b0: 7320 7072 6576 696f 7573 6c79 2075 7365  s previously use
-000164c0: 6420 636f 6e63 6570 7473 2920 2220 2520  d concepts) " % 
-000164d0: 6f70 7469 6f6e 290a 2020 2020 2020 2020  option).        
-000164e0: 6f70 7469 6f6e 203d 206f 7074 696f 6e20  option = option 
-000164f0: 2b20 310a 0a20 2020 2020 2020 2023 2041  + 1..        # A
-00016500: 6464 206f 7074 696f 6e20 746f 2063 6861  dd option to cha
-00016510: 6e67 6520 7175 6572 7920 7374 7269 6e67  nge query string
-00016520: 0a20 2020 2020 2020 2070 7269 6e74 2822  .        print("
-00016530: 2564 3a20 4368 616e 6765 2071 7565 7279  %d: Change query
-00016540: 2073 7472 696e 6720 6672 6f6d 3a20 5c22   string from: \"
-00016550: 2573 5c22 2220 2520 286f 7074 696f 6e2c  %s\"" % (option,
-00016560: 2073 6561 7263 685f 7465 726d 2929 0a0a   search_term))..
-00016570: 2020 2020 2020 2020 2323 2323 2323 2323          ########
-00016580: 4445 4649 4e45 204e 4557 2043 4f4e 4345  DEFINE NEW CONCE
-00016590: 5054 2043 4f4d 4d45 4e54 4544 204f 5554  PT COMMENTED OUT
-000165a0: 2052 4947 4854 204e 4f57 2323 2323 2323   RIGHT NOW######
-000165b0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-000165c0: 2323 2323 2323 2323 2323 2323 2323 0a20  ##############. 
-000165d0: 2020 2020 2020 2023 2320 4164 6420 6f70         ## Add op
-000165e0: 7469 6f6e 2074 6f20 6465 6669 6e65 2079  tion to define y
-000165f0: 6f75 7220 6f77 6e20 7465 726d 0a20 2020  our own term.   
-00016600: 2020 2020 2023 6f70 7469 6f6e 203d 206f       #option = o
-00016610: 7074 696f 6e20 2b20 310a 2020 2020 2020  ption + 1.      
-00016620: 2020 2370 7269 6e74 2822 2564 3a20 4465    #print("%d: De
-00016630: 6669 6e65 206d 7920 6f77 6e20 636f 6e63  fine my own conc
-00016640: 6570 7420 666f 7220 7468 6973 2076 6172  ept for this var
-00016650: 6961 626c 6522 2025 206f 7074 696f 6e29  iable" % option)
-00016660: 0a20 2020 2020 2020 2023 2323 2323 2323  .        #######
-00016670: 2344 4546 494e 4520 4e45 5720 434f 4e43  #DEFINE NEW CONC
-00016680: 4550 5420 434f 4d4d 454e 5445 4420 4f55  EPT COMMENTED OU
-00016690: 5420 5249 4748 5420 4e4f 5723 2323 2323  T RIGHT NOW#####
-000166a0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-000166b0: 2323 2323 2323 2323 2323 2323 2323 230a  ###############.
-000166c0: 2020 2020 2020 2020 2320 4164 6420 6f70          # Add op
-000166d0: 7469 6f6e 2074 6f20 6465 6669 6e65 2079  tion to define y
-000166e0: 6f75 7220 6f77 6e20 7465 726d 0a20 2020  our own term.   
-000166f0: 2020 2020 206f 7074 696f 6e20 3d20 6f70       option = op
-00016700: 7469 6f6e 202b 2031 0a20 2020 2020 2020  tion + 1.       
-00016710: 2070 7269 6e74 2822 2564 3a20 4e6f 2063   print("%d: No c
-00016720: 6f6e 6365 7074 206e 6565 6465 6420 666f  oncept needed fo
-00016730: 7220 7468 6973 2076 6172 6961 626c 6522  r this variable"
-00016740: 2025 206f 7074 696f 6e29 0a0a 2020 2020   % option)..    
-00016750: 2020 2020 7072 696e 7428 222d 2d2d 2d2d      print("-----
-00016760: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00016770: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00016780: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00016790: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-000167a0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-000167b0: 2d2d 2229 0a20 2020 2020 2020 2023 2057  --").        # W
-000167c0: 6169 7420 666f 7220 7573 6572 2069 6e70  ait for user inp
-000167d0: 7574 0a20 2020 2020 2020 2073 656c 6563  ut.        selec
-000167e0: 7469 6f6e 203d 2069 6e70 7574 2822 506c  tion = input("Pl
-000167f0: 6561 7365 2073 656c 6563 7420 616e 206f  ease select an o
-00016800: 7074 696f 6e20 2831 3a25 6429 2066 726f  ption (1:%d) fro
-00016810: 6d20 6162 6f76 653a 205c 7422 2025 206f  m above: \t" % o
-00016820: 7074 696f 6e29 0a0a 2020 2020 2020 2020  ption)..        
-00016830: 2320 4d61 6b65 2073 7572 6520 7573 6572  # Make sure user
-00016840: 2073 656c 6563 7465 6420 6f6e 6520 6f66   selected one of
-00016850: 2074 6865 206f 7074 696f 6e73 2e20 2049   the options.  I
-00016860: 6620 6e6f 7420 7072 6573 656e 7420 7573  f not present us
-00016870: 6572 2077 6974 6820 7365 6c65 6374 696f  er with selectio
-00016880: 6e20 696e 7075 7420 6167 6169 6e0a 2020  n input again.  
-00016890: 2020 2020 2020 7768 696c 6520 286e 6f74        while (not
-000168a0: 2073 656c 6563 7469 6f6e 2e69 7364 6967   selection.isdig
-000168b0: 6974 2829 2920 6f72 2028 696e 7428 7365  it()) or (int(se
-000168c0: 6c65 6374 696f 6e29 203e 2069 6e74 286f  lection) > int(o
-000168d0: 7074 696f 6e29 293a 0a20 2020 2020 2020  ption)):.       
-000168e0: 2020 2020 2023 2057 6169 7420 666f 7220       # Wait for 
-000168f0: 7573 6572 2069 6e70 7574 0a20 2020 2020  user input.     
-00016900: 2020 2020 2020 2073 656c 6563 7469 6f6e         selection
-00016910: 203d 2069 6e70 7574 2822 506c 6561 7365   = input("Please
-00016920: 2073 656c 6563 7420 616e 206f 7074 696f   select an optio
-00016930: 6e20 2831 3a25 6429 2066 726f 6d20 6162  n (1:%d) from ab
-00016940: 6f76 653a 205c 7422 2025 206f 7074 696f  ove: \t" % optio
-00016950: 6e29 0a0a 2020 2020 2020 2020 2320 746f  n)..        # to
-00016960: 6767 6c65 2075 7365 206f 6620 616e 6365  ggle use of ance
-00016970: 7374 6f72 7320 696e 2069 6e74 6572 6c65  stors in interle
-00016980: 7820 7175 6572 7920 6f72 206e 6f74 0a20  x query or not. 
-00016990: 2020 2020 2020 2069 6620 696e 7428 7365         if int(se
-000169a0: 6c65 6374 696f 6e29 203d 3d20 286f 7074  lection) == (opt
-000169b0: 696f 6e20 2d20 3229 3a0a 2020 2020 2020  ion - 2):.      
-000169c0: 2020 2020 2020 616e 6365 7374 6f72 203d        ancestor =
-000169d0: 206e 6f74 2061 6e63 6573 746f 720a 2020   not ancestor.  
-000169e0: 2020 2020 2020 2320 6368 6563 6b20 6966        # check if
-000169f0: 2073 656c 6563 7469 6f6e 2069 7320 746f   selection is to
-00016a00: 2072 652d 7275 6e20 7175 6572 7920 7769   re-run query wi
-00016a10: 7468 206e 6577 2073 6561 7263 6820 7465  th new search te
-00016a20: 726d 0a20 2020 2020 2020 2065 6c69 6620  rm.        elif 
-00016a30: 696e 7428 7365 6c65 6374 696f 6e29 203d  int(selection) =
-00016a40: 3d20 286f 7074 696f 6e20 2d20 3129 3a0a  = (option - 1):.
-00016a50: 2020 2020 2020 2020 2020 2020 2320 6173              # as
-00016a60: 6b20 7573 6572 2066 6f72 206e 6577 2073  k user for new s
-00016a70: 6561 7263 6820 7374 7269 6e67 0a20 2020  earch string.   
-00016a80: 2020 2020 2020 2020 2073 6561 7263 685f           search_
-00016a90: 7465 726d 203d 2069 6e70 7574 2822 506c  term = input("Pl
-00016aa0: 6561 7365 2069 6e70 7574 206e 6577 2073  ease input new s
-00016ab0: 6561 7263 6820 7374 7269 6e67 2066 6f72  earch string for
-00016ac0: 2043 5356 2063 6f6c 756d 6e3a 2025 7320   CSV column: %s 
-00016ad0: 5c74 3a22 2025 2073 6f75 7263 655f 7661  \t:" % source_va
-00016ae0: 7269 6162 6c65 290a 2020 2020 2020 2020  riable).        
-00016af0: 2020 2020 7072 696e 7428 222d 2d2d 2d2d      print("-----
-00016b00: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00016b10: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00016b20: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00016b30: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00016b40: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00016b50: 2d2d 2229 0a0a 2020 2020 2020 2020 2323  --")..        ##
-00016b60: 2323 2323 2323 4445 4649 4e45 204e 4557  ######DEFINE NEW
-00016b70: 2043 4f4e 4345 5054 2043 4f4d 4d45 4e54   CONCEPT COMMENT
-00016b80: 4544 204f 5554 2052 4947 4854 204e 4f57  ED OUT RIGHT NOW
-00016b90: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00016ba0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00016bb0: 2323 2323 0a20 2020 2020 2020 2023 656c  ####.        #el
-00016bc0: 6966 2069 6e74 2873 656c 6563 7469 6f6e  if int(selection
-00016bd0: 2920 3d3d 2028 6f70 7469 6f6e 202d 2031  ) == (option - 1
-00016be0: 293a 0a20 2020 2020 2020 2023 2020 2020  ):.        #    
-00016bf0: 6e65 775f 636f 6e63 6570 7420 3d20 6465  new_concept = de
-00016c00: 6669 6e65 5f6e 6577 5f63 6f6e 6365 7074  fine_new_concept
-00016c10: 2873 6f75 7263 655f 7661 7269 6162 6c65  (source_variable
-00016c20: 2c69 6c78 5f6f 626a 290a 2020 2020 2020  ,ilx_obj).      
-00016c30: 2020 2020 2020 2320 6164 6420 6e65 7720        # add new 
-00016c40: 636f 6e63 6570 7420 746f 2049 6e74 6572  concept to Inter
-00016c50: 4c65 7820 616e 6420 7265 7472 6965 7665  Lex and retrieve
-00016c60: 2055 524c 2066 6f72 2069 7341 626f 7574   URL for isAbout
-00016c70: 0a20 2020 2020 2020 2020 2020 2023 0a20  .            #. 
-00016c80: 2020 2020 2020 2020 2020 2023 0a20 2020             #.   
-00016c90: 2020 2020 2020 2020 2023 0a20 2020 2020           #.     
-00016ca0: 2020 2023 2020 2020 736f 7572 6365 5f76     #    source_v
-00016cb0: 6172 6961 626c 655f 616e 6e6f 7461 7469  ariable_annotati
-00016cc0: 6f6e 735b 6375 7272 656e 745f 7475 706c  ons[current_tupl
-00016cd0: 655d 5b27 6973 4162 6f75 7427 5d20 3d20  e]['isAbout'] = 
-00016ce0: 6e65 775f 636f 6e63 6570 742e 6972 6920  new_concept.iri 
-00016cf0: 2b20 2723 270a 2020 2020 2020 2020 2320  + '#'.        # 
-00016d00: 2020 2067 6f5f 6c6f 6f70 203d 2046 616c     go_loop = Fal
-00016d10: 7365 0a20 2020 2020 2020 2020 2020 2023  se.            #
-00016d20: 2069 6620 7573 6572 2073 6179 7320 6e6f   if user says no
-00016d30: 2063 6f6e 6365 7074 206d 6170 7069 6e67   concept mapping
-00016d40: 206e 6565 6465 6420 7468 656e 206a 7573   needed then jus
-00016d50: 7420 6578 6974 2074 6869 7320 6c6f 6f70  t exit this loop
-00016d60: 0a20 2020 2020 2020 2023 2323 2323 2323  .        #######
-00016d70: 2344 4546 494e 4520 4e45 5720 434f 4e43  #DEFINE NEW CONC
-00016d80: 4550 5420 434f 4d4d 454e 5445 4420 4f55  EPT COMMENTED OU
-00016d90: 5420 5249 4748 5420 4e4f 5723 2323 2323  T RIGHT NOW#####
-00016da0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00016db0: 2323 2323 2323 2323 2323 2323 2323 230a  ###############.
-00016dc0: 2020 2020 2020 2020 656c 6966 2069 6e74          elif int
-00016dd0: 2873 656c 6563 7469 6f6e 2920 3d3d 2028  (selection) == (
-00016de0: 6f70 7469 6f6e 293a 0a20 2020 2020 2020  option):.       
-00016df0: 2020 2020 2023 2064 6f6e 2774 206e 6565       # don't nee
-00016e00: 6420 746f 2063 6f6e 7469 6e75 6520 7768  d to continue wh
-00016e10: 696c 6520 6c6f 6f70 2062 6563 6175 7365  ile loop because
-00016e20: 2077 6527 7665 2064 6563 6964 6564 206e   we've decided n
-00016e30: 6f74 2074 6f20 6173 736f 6369 6174 6520  ot to associate 
-00016e40: 6120 636f 6e63 6570 7420 7769 7468 2074  a concept with t
-00016e50: 6869 7320 7661 7269 6162 6c65 2e0a 2020  his variable..  
-00016e60: 2020 2020 2020 2020 2020 676f 5f6c 6f6f            go_loo
-00016e70: 7020 3d20 4661 6c73 650a 2020 2020 2020  p = False.      
-00016e80: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00016e90: 2020 2020 2320 7573 6572 2073 656c 6563      # user selec
-00016ea0: 7465 6420 6f6e 6520 6f66 2074 6865 2065  ted one of the e
-00016eb0: 7869 7374 696e 6720 636f 6e63 6570 7473  xisting concepts
-00016ec0: 2074 6f20 6164 6420 6974 7320 5552 4c20   to add its URL 
-00016ed0: 746f 2074 6865 2069 7341 626f 7574 2070  to the isAbout p
-00016ee0: 726f 7065 7274 790a 2020 2020 2020 2020  roperty.        
-00016ef0: 2020 2020 2320 6164 6465 6420 6c61 6265      # added labe
-00016f00: 6c73 2074 6f20 7468 6573 6520 6973 4162  ls to these isAb
-00016f10: 6f75 7420 7572 6c73 2066 6f72 2065 6173  out urls for eas
-00016f20: 7920 7175 6572 7969 6e67 206c 6174 6572  y querying later
-00016f30: 0a20 2020 2020 2020 2020 2020 2073 6f75  .            sou
-00016f40: 7263 655f 7661 7269 6162 6c65 5f61 6e6e  rce_variable_ann
-00016f50: 6f74 6174 696f 6e73 5b63 7572 7265 6e74  otations[current
-00016f60: 5f74 7570 6c65 5d5b 2769 7341 626f 7574  _tuple]['isAbout
-00016f70: 275d 203d 205b 5d0a 2020 2020 2020 2020  '] = [].        
-00016f80: 2020 2020 736f 7572 6365 5f76 6172 6961      source_varia
-00016f90: 626c 655f 616e 6e6f 7461 7469 6f6e 735b  ble_annotations[
-00016fa0: 6375 7272 656e 745f 7475 706c 655d 5b27  current_tuple]['
-00016fb0: 6973 4162 6f75 7427 5d2e 6170 7065 6e64  isAbout'].append
-00016fc0: 287b 2740 6964 273a 0a20 2020 2020 2020  ({'@id':.       
-00016fd0: 2020 2020 2020 2020 2020 2020 2073 6561               sea
-00016fe0: 7263 685f 7265 7375 6c74 5b73 6561 7263  rch_result[searc
-00016ff0: 685f 7265 7375 6c74 5b73 656c 6563 7469  h_result[selecti
-00017000: 6f6e 5d5d 5b27 7072 6566 6572 7265 645f  on]]['preferred_
-00017010: 7572 6c27 5d2c 276c 6162 656c 273a 0a20  url'],'label':. 
-00017020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017030: 2020 2073 6561 7263 685f 7265 7375 6c74     search_result
-00017040: 5b73 6561 7263 685f 7265 7375 6c74 5b73  [search_result[s
-00017050: 656c 6563 7469 6f6e 5d5d 5b27 6c61 6265  election]]['labe
-00017060: 6c27 5d7d 290a 2020 2020 2020 2020 2020  l']}).          
-00017070: 2020 7072 696e 7428 225c 6e43 6f6e 6365    print("\nConce
-00017080: 7074 2061 6e6e 6f74 6174 696f 6e20 6164  pt annotation ad
-00017090: 6465 6420 666f 7220 736f 7572 6365 2076  ded for source v
-000170a0: 6172 6961 626c 653a 2025 7322 2025 736f  ariable: %s" %so
-000170b0: 7572 6365 5f76 6172 6961 626c 6529 0a20  urce_variable). 
-000170c0: 2020 2020 2020 2020 2020 2067 6f5f 6c6f             go_lo
-000170d0: 6f70 203d 2046 616c 7365 0a0a 0a0a 0a64  op = False.....d
-000170e0: 6566 2064 6566 696e 655f 6e65 775f 636f  ef define_new_co
-000170f0: 6e63 6570 7428 736f 7572 6365 5f76 6172  ncept(source_var
-00017100: 6961 626c 652c 2069 6c78 5f6f 626a 293a  iable, ilx_obj):
-00017110: 0a20 2020 2023 2075 7365 7220 7761 6e74  .    # user want
-00017120: 7320 746f 2064 6566 696e 6520 7468 6569  s to define thei
-00017130: 7220 6f77 6e20 7465 726d 2e20 2041 736b  r own term.  Ask
-00017140: 2066 6f72 2074 6572 6d20 6c61 6265 6c20   for term label 
-00017150: 616e 6420 6465 6669 6e69 7469 6f6e 0a20  and definition. 
-00017160: 2020 2070 7269 6e74 2822 5c6e 596f 7520     print("\nYou 
-00017170: 7365 6c65 6374 6564 2074 6f20 656e 7465  selected to ente
-00017180: 7220 6120 6e65 7720 636f 6e63 6570 7420  r a new concept 
-00017190: 666f 7220 4353 5620 636f 6c75 6d6e 3a20  for CSV column: 
-000171a0: 2573 2220 2520 736f 7572 6365 5f76 6172  %s" % source_var
-000171b0: 6961 626c 6529 0a0a 2020 2020 2320 636f  iable)..    # co
-000171c0: 6c6c 6563 7420 7465 726d 2069 6e66 6f72  llect term infor
-000171d0: 6d61 7469 6f6e 2066 726f 6d20 7573 6572  mation from user
-000171e0: 0a20 2020 2063 6f6e 6365 7074 5f6c 6162  .    concept_lab
-000171f0: 656c 203d 2069 6e70 7574 2822 506c 6561  el = input("Plea
-00017200: 7365 2065 6e74 6572 2061 206c 6162 656c  se enter a label
-00017210: 2066 6f72 2074 6865 206e 6577 2063 6f6e   for the new con
-00017220: 6365 7074 205b 2573 5d3a 5c74 2220 2520  cept [%s]:\t" % 
-00017230: 736f 7572 6365 5f76 6172 6961 626c 6529  source_variable)
-00017240: 0a20 2020 2063 6f6e 6365 7074 5f64 6566  .    concept_def
-00017250: 696e 6974 696f 6e20 3d20 696e 7075 7428  inition = input(
-00017260: 2250 6c65 6173 6520 656e 7465 7220 6120  "Please enter a 
-00017270: 6465 6669 6e69 7469 6f6e 2066 6f72 2074  definition for t
-00017280: 6869 7320 636f 6e63 6570 743a 5c74 2229  his concept:\t")
-00017290: 0a0a 2020 2020 2320 6164 6420 636f 6e63  ..    # add conc
-000172a0: 6570 7420 746f 2049 6e74 6572 4c65 7820  ept to InterLex 
-000172b0: 616e 6420 6765 7420 5552 4c0a 2020 2020  and get URL.    
-000172c0: 2320 4164 6420 7065 7273 6f6e 616c 2064  # Add personal d
-000172d0: 6174 6120 656c 656d 656e 7420 746f 2049  ata element to I
-000172e0: 6e74 6572 4c65 780a 0a20 2020 2069 6c78  nterLex..    ilx
-000172f0: 5f6f 7574 7075 7420 3d20 4164 6443 6f6e  _output = AddCon
-00017300: 6365 7074 546f 496e 7465 726c 6578 2869  ceptToInterlex(i
-00017310: 6c78 5f6f 626a 3d69 6c78 5f6f 626a 2c20  lx_obj=ilx_obj, 
-00017320: 6c61 6265 6c3d 636f 6e63 6570 745f 6c61  label=concept_la
-00017330: 6265 6c2c 2064 6566 696e 6974 696f 6e3d  bel, definition=
-00017340: 636f 6e63 6570 745f 6465 6669 6e69 7469  concept_definiti
-00017350: 6f6e 290a 0a20 2020 2072 6574 7572 6e20  on)..    return 
-00017360: 696c 785f 6f75 7470 7574 0a0a 6465 6620  ilx_output..def 
-00017370: 616e 6e6f 7461 7465 5f64 6174 615f 656c  annotate_data_el
-00017380: 656d 656e 7428 736f 7572 6365 5f76 6172  ement(source_var
-00017390: 6961 626c 652c 2063 7572 7265 6e74 5f74  iable, current_t
-000173a0: 7570 6c65 2c20 736f 7572 6365 5f76 6172  uple, source_var
-000173b0: 6961 626c 655f 616e 6e6f 7461 7469 6f6e  iable_annotation
-000173c0: 7329 3a0a 2020 2020 2727 270a 2020 2020  s):.    '''.    
-000173d0: 3a73 6f75 7263 655f 7661 7269 6162 6c65  :source_variable
-000173e0: 3a20 7661 7269 6162 6c65 206e 616d 6520  : variable name 
-000173f0: 666f 7220 7768 6963 6820 7765 2772 6520  for which we're 
-00017400: 616e 6e6f 7461 7469 6e67 0a20 2020 203a  annotating.    :
-00017410: 6375 7272 656e 745f 7475 706c 653a 2074  current_tuple: t
-00017420: 6869 7320 6973 2074 6865 2074 7570 6c65  his is the tuple
-00017430: 206b 6579 206f 6620 7468 6520 3a73 6f75   key of the :sou
-00017440: 7263 655f 7661 7269 6162 6c65 3a20 696e  rce_variable: in
-00017450: 2074 6865 0a20 2020 2064 6963 7469 6f6e   the.    diction
-00017460: 6172 7920 3a73 6f75 7263 655f 7661 7269  ary :source_vari
-00017470: 6162 6c65 5f61 6e6e 6f74 6174 696f 6e73  able_annotations
-00017480: 3a2e 2020 5468 6573 6520 6172 6520 636f  :.  These are co
-00017490: 6d70 6f75 6e64 206b 6579 730a 2020 2020  mpound keys.    
-000174a0: 3a73 6f75 7263 655f 7661 7269 6162 6c65  :source_variable
-000174b0: 5f61 6e6e 6f74 6174 696f 6e73 3a20 6469  _annotations: di
-000174c0: 6374 696f 6e61 7279 206f 6620 7661 7269  ctionary of vari
-000174d0: 6162 6c65 2061 6e6e 6f74 6174 696f 6e73  able annotations
-000174e0: 2e0a 2020 2020 2727 270a 0a20 2020 2023  ..    '''..    #
-000174f0: 2075 7365 7220 696e 7374 7275 6374 696f   user instructio
-00017500: 6e73 0a20 2020 2070 7269 6e74 2822 5c6e  ns.    print("\n
-00017510: 596f 7520 7769 6c6c 206e 6f77 2062 6520  You will now be 
-00017520: 6173 6b65 6420 6120 7365 7269 6573 206f  asked a series o
-00017530: 6620 7175 6573 7469 6f6e 7320 746f 2061  f questions to a
-00017540: 6e6e 6f74 6174 6520 796f 7572 2074 6572  nnotate your ter
-00017550: 6d3a 2025 7322 2025 2073 6f75 7263 655f  m: %s" % source_
-00017560: 7661 7269 6162 6c65 290a 0a20 2020 2023  variable)..    #
-00017570: 2063 6f6c 6c65 6374 2074 6572 6d20 696e   collect term in
-00017580: 666f 726d 6174 696f 6e20 6672 6f6d 2075  formation from u
-00017590: 7365 720a 2020 2020 7465 726d 5f6c 6162  ser.    term_lab
-000175a0: 656c 203d 2069 6e70 7574 2822 506c 6561  el = input("Plea
-000175b0: 7365 2065 6e74 6572 2061 2066 756c 6c20  se enter a full 
-000175c0: 6e61 6d65 2074 6f20 6173 736f 6369 6174  name to associat
-000175d0: 6520 7769 7468 2074 6865 2074 6572 6d20  e with the term 
-000175e0: 5b25 735d 3a5c 7422 2025 2073 6f75 7263  [%s]:\t" % sourc
-000175f0: 655f 7661 7269 6162 6c65 290a 2020 2020  e_variable).    
-00017600: 6966 2074 6572 6d5f 6c61 6265 6c20 3d3d  if term_label ==
-00017610: 2027 273a 0a20 2020 2020 2020 2074 6572   '':.        ter
-00017620: 6d5f 6c61 6265 6c20 3d20 736f 7572 6365  m_label = source
-00017630: 5f76 6172 6961 626c 650a 0a20 2020 2074  _variable..    t
-00017640: 6572 6d5f 6465 6669 6e69 7469 6f6e 203d  erm_definition =
-00017650: 2069 6e70 7574 2822 506c 6561 7365 2065   input("Please e
-00017660: 6e74 6572 2061 2064 6566 696e 6974 696f  nter a definitio
-00017670: 6e20 666f 7220 7468 6973 2074 6572 6d3a  n for this term:
-00017680: 5c74 2229 0a0a 2020 2020 2320 6765 7420  \t")..    # get 
-00017690: 6461 7461 7479 7065 0a20 2020 2077 6869  datatype.    whi
-000176a0: 6c65 2054 7275 653a 0a20 2020 2020 2020  le True:.       
-000176b0: 2070 7269 6e74 2822 506c 6561 7365 2065   print("Please e
-000176c0: 6e74 6572 2074 6865 2076 616c 7565 2074  nter the value t
-000176d0: 7970 6520 666f 7220 7468 6973 2074 6572  ype for this ter
-000176e0: 6d20 6672 6f6d 2074 6865 2066 6f6c 6c6f  m from the follo
-000176f0: 7769 6e67 206c 6973 743a 2229 0a20 2020  wing list:").   
-00017700: 2020 2020 2070 7269 6e74 2822 5c74 2031       print("\t 1
-00017710: 3a20 7374 7269 6e67 202d 2054 6865 2073  : string - The s
-00017720: 7472 696e 6720 6461 7461 7479 7065 2072  tring datatype r
-00017730: 6570 7265 7365 6e74 7320 6368 6172 6163  epresents charac
-00017740: 7465 7220 7374 7269 6e67 7322 290a 2020  ter strings").  
-00017750: 2020 2020 2020 7072 696e 7428 225c 7420        print("\t 
-00017760: 323a 2063 6174 6567 6f72 6963 616c 202d  2: categorical -
-00017770: 2041 2076 6172 6961 626c 6520 7468 6174   A variable that
-00017780: 2063 616e 2074 616b 6520 6f6e 206f 6e65   can take on one
-00017790: 206f 6620 6120 6c69 6d69 7465 6420 6e75   of a limited nu
-000177a0: 6d62 6572 206f 6620 706f 7373 6962 6c65  mber of possible
-000177b0: 2076 616c 7565 732c 2061 7373 6967 6e69   values, assigni
-000177c0: 6e67 2065 6163 6820 746f 2061 206e 6f6d  ng each to a nom
-000177d0: 696e 616c 2063 6174 6567 6f72 7920 6f6e  inal category on
-000177e0: 2074 6865 2062 6173 6973 206f 6620 736f   the basis of so
-000177f0: 6d65 2071 7561 6c69 7461 7469 7665 2070  me qualitative p
-00017800: 726f 7065 7274 792e 2229 0a20 2020 2020  roperty.").     
-00017810: 2020 2070 7269 6e74 2822 5c74 2033 3a20     print("\t 3: 
-00017820: 626f 6f6c 6561 6e20 2d20 4269 6e61 7279  boolean - Binary
-00017830: 2d76 616c 7565 6420 6c6f 6769 633a 7b74  -valued logic:{t
-00017840: 7275 652c 6661 6c73 657d 2229 0a20 2020  rue,false}").   
-00017850: 2020 2020 2070 7269 6e74 2822 5c74 2034       print("\t 4
-00017860: 3a20 696e 7465 6765 7220 2d20 496e 7465  : integer - Inte
-00017870: 6765 7220 6973 2061 206e 756d 6265 7220  ger is a number 
-00017880: 7468 6174 2063 616e 2062 6520 7772 6974  that can be writ
-00017890: 7465 6e20 7769 7468 6f75 7420 6120 6672  ten without a fr
-000178a0: 6163 7469 6f6e 616c 2063 6f6d 706f 6e65  actional compone
-000178b0: 6e74 2229 0a20 2020 2020 2020 2070 7269  nt").        pri
-000178c0: 6e74 2822 5c74 2035 3a20 666c 6f61 7420  nt("\t 5: float 
-000178d0: 2d20 466c 6f61 7420 636f 6e73 6973 7473  - Float consists
-000178e0: 206f 6620 7468 6520 7661 6c75 6573 206d   of the values m
-000178f0: 20c3 9720 325e 652c 2077 6865 7265 206d   .. 2^e, where m
-00017900: 2069 7320 616e 2069 6e74 6567 6572 2077   is an integer w
-00017910: 686f 7365 2061 6273 6f6c 7574 6520 7661  hose absolute va
-00017920: 6c75 6520 6973 206c 6573 7320 7468 616e  lue is less than
-00017930: 2032 5e32 342c 2061 6e64 2065 2069 7320   2^24, and e is 
-00017940: 616e 2069 6e74 6567 6572 2062 6574 7765  an integer betwe
-00017950: 656e 202d 3134 3920 616e 6420 3130 342c  en -149 and 104,
-00017960: 2069 6e63 6c75 7369 7665 2229 0a20 2020   inclusive").   
-00017970: 2020 2020 2070 7269 6e74 2822 5c74 2036       print("\t 6
-00017980: 3a20 646f 7562 6c65 202d 2044 6f75 626c  : double - Doubl
-00017990: 6520 636f 6e73 6973 7473 206f 6620 7468  e consists of th
-000179a0: 6520 7661 6c75 6573 206d 20c3 9720 325e  e values m .. 2^
-000179b0: 652c 2077 6865 7265 206d 2069 7320 616e  e, where m is an
-000179c0: 2069 6e74 6567 6572 2077 686f 7365 2061   integer whose a
-000179d0: 6273 6f6c 7574 6520 7661 6c75 6520 6973  bsolute value is
-000179e0: 206c 6573 7320 7468 616e 2032 5e35 332c   less than 2^53,
-000179f0: 2061 6e64 2065 2069 7320 616e 2069 6e74   and e is an int
-00017a00: 6567 6572 2062 6574 7765 656e 202d 3130  eger between -10
-00017a10: 3735 2061 6e64 2039 3730 2c20 696e 636c  75 and 970, incl
-00017a20: 7573 6976 6522 290a 2020 2020 2020 2020  usive").        
-00017a30: 7072 696e 7428 225c 7420 373a 2064 7572  print("\t 7: dur
-00017a40: 6174 696f 6e20 2d20 4475 7261 7469 6f6e  ation - Duration
-00017a50: 2072 6570 7265 7365 6e74 7320 6120 6475   represents a du
-00017a60: 7261 7469 6f6e 206f 6620 7469 6d65 2229  ration of time")
-00017a70: 0a20 2020 2020 2020 2070 7269 6e74 2822  .        print("
-00017a80: 5c74 2038 3a20 6461 7465 5469 6d65 202d  \t 8: dateTime -
-00017a90: 2056 616c 7565 7320 7769 7468 2069 6e74   Values with int
-00017aa0: 6567 6572 2d76 616c 7565 6420 7965 6172  eger-valued year
-00017ab0: 2c20 6d6f 6e74 682c 2064 6179 2c20 686f  , month, day, ho
-00017ac0: 7572 2061 6e64 206d 696e 7574 6520 7072  ur and minute pr
-00017ad0: 6f70 6572 7469 6573 2c20 6120 6465 6369  operties, a deci
-00017ae0: 6d61 6c2d 7661 6c75 6564 2073 6563 6f6e  mal-valued secon
-00017af0: 6420 7072 6f70 6572 7479 2c20 616e 6420  d property, and 
-00017b00: 6120 626f 6f6c 6561 6e20 7469 6d65 7a6f  a boolean timezo
-00017b10: 6e65 6420 7072 6f70 6572 7479 2e22 290a  ned property.").
-00017b20: 2020 2020 2020 2020 7072 696e 7428 225c          print("\
-00017b30: 7420 393a 2074 696d 6520 2d20 5469 6d65  t 9: time - Time
-00017b40: 2072 6570 7265 7365 6e74 7320 616e 2069   represents an i
-00017b50: 6e73 7461 6e74 206f 6620 7469 6d65 2074  nstant of time t
-00017b60: 6861 7420 7265 6375 7273 2065 7665 7279  hat recurs every
-00017b70: 2064 6179 2229 0a20 2020 2020 2020 2070   day").        p
-00017b80: 7269 6e74 2822 5c74 2031 303a 2064 6174  rint("\t 10: dat
-00017b90: 6520 2d20 4461 7465 2063 6f6e 7369 7374  e - Date consist
-00017ba0: 7320 6f66 2074 6f70 2d6f 7065 6e20 696e  s of top-open in
-00017bb0: 7465 7276 616c 7320 6f66 2065 7861 6374  tervals of exact
-00017bc0: 6c79 206f 6e65 2064 6179 2069 6e20 6c65  ly one day in le
-00017bd0: 6e67 7468 206f 6e20 7468 6520 7469 6d65  ngth on the time
-00017be0: 6c69 6e65 7320 6f66 2064 6174 6554 696d  lines of dateTim
-00017bf0: 652c 2062 6567 696e 6e69 6e67 206f 6e20  e, beginning on 
-00017c00: 7468 6520 6265 6769 6e6e 696e 6720 6d6f  the beginning mo
-00017c10: 6d65 6e74 206f 6620 6561 6368 2064 6179  ment of each day
-00017c20: 2028 696e 2065 6163 6820 7469 6d65 7a6f   (in each timezo
-00017c30: 6e65 2922 290a 2020 2020 2020 2020 7072  ne)").        pr
-00017c40: 696e 7428 225c 7420 3131 3a20 616e 7955  int("\t 11: anyU
-00017c50: 5249 202d 2061 6e79 5552 4920 7265 7072  RI - anyURI repr
-00017c60: 6573 656e 7473 2061 2055 6e69 666f 726d  esents a Uniform
-00017c70: 2052 6573 6f75 7263 6520 4964 656e 7469   Resource Identi
-00017c80: 6669 6572 2052 6566 6572 656e 6365 2028  fier Reference (
-00017c90: 5552 4929 2e20 416e 2061 6e79 5552 4920  URI). An anyURI 
-00017ca0: 7661 6c75 6520 6361 6e20 6265 2061 6273  value can be abs
-00017cb0: 6f6c 7574 6520 6f72 2072 656c 6174 6976  olute or relativ
-00017cc0: 652c 2061 6e64 206d 6179 2068 6176 6520  e, and may have 
-00017cd0: 616e 206f 7074 696f 6e61 6c20 6672 6167  an optional frag
-00017ce0: 6d65 6e74 2069 6465 6e74 6966 6965 7222  ment identifier"
-00017cf0: 290a 2020 2020 2020 2020 7465 726d 5f64  ).        term_d
-00017d00: 6174 6174 7970 6520 3d20 696e 7075 7428  atatype = input(
-00017d10: 2250 6c65 6173 6520 656e 7465 7220 7468  "Please enter th
-00017d20: 6520 6461 7461 7479 7065 205b 313a 3131  e datatype [1:11
-00017d30: 5d3a 5c74 2229 0a20 2020 2020 2020 2023  ]:\t").        #
-00017d40: 2063 6865 636b 2064 6174 6174 7970 6573   check datatypes
-00017d50: 2069 6620 6e6f 7420 696e 205b 696e 7465   if not in [inte
-00017d60: 6765 722c 7265 616c 2c63 6174 6567 6f72  ger,real,categor
-00017d70: 6963 616c 5d20 7265 7065 6174 2075 6e74  ical] repeat unt
-00017d80: 696c 2069 7420 6973 0a20 2020 2020 2020  il it is.       
-00017d90: 2069 6620 696e 7428 7465 726d 5f64 6174   if int(term_dat
-00017da0: 6174 7970 6529 203e 3d20 3120 616e 6420  atype) >= 1 and 
-00017db0: 696e 7428 7465 726d 5f64 6174 6174 7970  int(term_datatyp
-00017dc0: 6529 203c 3d20 3131 3a0a 2020 2020 2020  e) <= 11:.      
-00017dd0: 2020 2020 2020 6966 2869 6e74 2874 6572        if(int(ter
-00017de0: 6d5f 6461 7461 7479 7065 2920 3d3d 2031  m_datatype) == 1
-00017df0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00017e00: 2020 2074 6572 6d5f 6461 7461 7479 7065     term_datatype
-00017e10: 203d 2055 5249 5265 6628 436f 6e73 7461   = URIRef(Consta
-00017e20: 6e74 732e 5853 445b 2273 7472 696e 6722  nts.XSD["string"
-00017e30: 5d29 0a20 2020 2020 2020 2020 2020 2065  ]).            e
-00017e40: 6c69 6620 2869 6e74 2874 6572 6d5f 6461  lif (int(term_da
-00017e50: 7461 7479 7065 2920 3d3d 2033 293a 0a20  tatype) == 3):. 
-00017e60: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00017e70: 6572 6d5f 6461 7461 7479 7065 203d 2055  erm_datatype = U
-00017e80: 5249 5265 6628 436f 6e73 7461 6e74 732e  RIRef(Constants.
-00017e90: 5853 445b 2262 6f6f 6c65 616e 225d 290a  XSD["boolean"]).
-00017ea0: 2020 2020 2020 2020 2020 2020 656c 6966              elif
-00017eb0: 2028 696e 7428 7465 726d 5f64 6174 6174   (int(term_datat
-00017ec0: 7970 6529 203d 3d20 3429 3a0a 2020 2020  ype) == 4):.    
-00017ed0: 2020 2020 2020 2020 2020 2020 7465 726d              term
-00017ee0: 5f64 6174 6174 7970 6520 3d20 5552 4952  _datatype = URIR
-00017ef0: 6566 2843 6f6e 7374 616e 7473 2e58 5344  ef(Constants.XSD
-00017f00: 5b22 696e 7465 6765 7222 5d29 0a20 2020  ["integer"]).   
-00017f10: 2020 2020 2020 2020 2065 6c69 6620 2869           elif (i
-00017f20: 6e74 2874 6572 6d5f 6461 7461 7479 7065  nt(term_datatype
-00017f30: 2920 3d3d 2035 293a 0a20 2020 2020 2020  ) == 5):.       
-00017f40: 2020 2020 2020 2020 2074 6572 6d5f 6461           term_da
-00017f50: 7461 7479 7065 203d 2055 5249 5265 6628  tatype = URIRef(
-00017f60: 436f 6e73 7461 6e74 732e 5853 445b 2266  Constants.XSD["f
-00017f70: 6c6f 6174 225d 290a 2020 2020 2020 2020  loat"]).        
-00017f80: 2020 2020 656c 6966 2028 696e 7428 7465      elif (int(te
-00017f90: 726d 5f64 6174 6174 7970 6529 203d 3d20  rm_datatype) == 
-00017fa0: 3629 3a0a 2020 2020 2020 2020 2020 2020  6):.            
-00017fb0: 2020 2020 7465 726d 5f64 6174 6174 7970      term_datatyp
-00017fc0: 6520 3d20 5552 4952 6566 2843 6f6e 7374  e = URIRef(Const
-00017fd0: 616e 7473 2e58 5344 5b22 646f 7562 6c65  ants.XSD["double
-00017fe0: 225d 290a 2020 2020 2020 2020 2020 2020  "]).            
-00017ff0: 656c 6966 2028 696e 7428 7465 726d 5f64  elif (int(term_d
-00018000: 6174 6174 7970 6529 203d 3d20 3729 3a0a  atatype) == 7):.
-00018010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018020: 7465 726d 5f64 6174 6174 7970 6520 3d20  term_datatype = 
-00018030: 5552 4952 6566 2843 6f6e 7374 616e 7473  URIRef(Constants
-00018040: 2e58 5344 5b22 6475 7261 7469 6f6e 225d  .XSD["duration"]
-00018050: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-00018060: 6966 2028 696e 7428 7465 726d 5f64 6174  if (int(term_dat
-00018070: 6174 7970 6529 203d 3d20 3829 3a0a 2020  atype) == 8):.  
-00018080: 2020 2020 2020 2020 2020 2020 2020 7465                te
-00018090: 726d 5f64 6174 6174 7970 6520 3d20 5552  rm_datatype = UR
-000180a0: 4952 6566 2843 6f6e 7374 616e 7473 2e58  IRef(Constants.X
-000180b0: 5344 5b22 6461 7465 5469 6d65 225d 290a  SD["dateTime"]).
-000180c0: 2020 2020 2020 2020 2020 2020 656c 6966              elif
-000180d0: 2028 696e 7428 7465 726d 5f64 6174 6174   (int(term_datat
-000180e0: 7970 6529 203d 3d20 3929 3a0a 2020 2020  ype) == 9):.    
-000180f0: 2020 2020 2020 2020 2020 2020 7465 726d              term
-00018100: 5f64 6174 6174 7970 6520 3d20 5552 4952  _datatype = URIR
-00018110: 6566 2843 6f6e 7374 616e 7473 2e58 5344  ef(Constants.XSD
-00018120: 5b22 7469 6d65 225d 290a 2020 2020 2020  ["time"]).      
-00018130: 2020 2020 2020 656c 6966 2028 696e 7428        elif (int(
-00018140: 7465 726d 5f64 6174 6174 7970 6529 203d  term_datatype) =
-00018150: 3d20 3130 293a 0a20 2020 2020 2020 2020  = 10):.         
-00018160: 2020 2020 2020 2074 6572 6d5f 6461 7461         term_data
-00018170: 7479 7065 203d 2055 5249 5265 6628 436f  type = URIRef(Co
-00018180: 6e73 7461 6e74 732e 5853 445b 2264 6174  nstants.XSD["dat
-00018190: 6522 5d29 0a20 2020 2020 2020 2020 2020  e"]).           
-000181a0: 2065 6c69 6620 2869 6e74 2874 6572 6d5f   elif (int(term_
-000181b0: 6461 7461 7479 7065 2920 3d3d 2031 3129  datatype) == 11)
-000181c0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000181d0: 2020 7465 726d 5f64 6174 6174 7970 6520    term_datatype 
-000181e0: 3d20 5552 4952 6566 2843 6f6e 7374 616e  = URIRef(Constan
-000181f0: 7473 2e58 5344 5b22 616e 7955 5249 225d  ts.XSD["anyURI"]
-00018200: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-00018210: 6966 2028 696e 7428 7465 726d 5f64 6174  if (int(term_dat
-00018220: 6174 7970 6529 203d 3d20 3229 3a0a 2020  atype) == 2):.  
-00018230: 2020 2020 2020 2020 2020 2020 2020 7465                te
-00018240: 726d 5f64 6174 6174 7970 6520 3d20 5552  rm_datatype = UR
-00018250: 4952 6566 2843 6f6e 7374 616e 7473 2e58  IRef(Constants.X
-00018260: 5344 5b22 636f 6d70 6c65 7854 7970 6522  SD["complexType"
-00018270: 5d29 0a20 2020 2020 2020 2020 2020 2062  ]).            b
-00018280: 7265 616b 0a0a 2020 2020 2320 6e6f 7720  reak..    # now 
-00018290: 6368 6563 6b20 6966 2074 6572 6d5f 6461  check if term_da
-000182a0: 7461 7479 7065 2069 7320 6361 7465 676f  tatype is catego
-000182b0: 7269 6361 6c20 616e 6420 6966 2073 6f20  rical and if so 
-000182c0: 6c65 7427 7320 6765 7420 7468 6520 6c61  let's get the la
-000182d0: 6265 6c20 3c2d 3e20 7661 6c75 6520 6d61  bel <-> value ma
-000182e0: 7070 696e 6773 0a20 2020 2069 6620 7465  ppings.    if te
-000182f0: 726d 5f64 6174 6174 7970 6520 3d3d 2055  rm_datatype == U
-00018300: 5249 5265 6628 436f 6e73 7461 6e74 732e  RIRef(Constants.
-00018310: 5853 445b 2263 6f6d 706c 6578 5479 7065  XSD["complexType
-00018320: 225d 293a 0a0a 2020 2020 2020 2020 2320  "]):..        # 
-00018330: 6173 6b20 7573 6572 2066 6f72 2074 6865  ask user for the
-00018340: 206e 756d 6265 7220 6f66 2063 6174 6567   number of categ
-00018350: 6f72 6965 730a 2020 2020 2020 2020 7768  ories.        wh
-00018360: 696c 6520 5472 7565 3a0a 2020 2020 2020  ile True:.      
-00018370: 2020 2020 2020 6e75 6d5f 6361 7465 676f        num_catego
-00018380: 7269 6573 203d 2069 6e70 7574 2822 506c  ries = input("Pl
-00018390: 6561 7365 2065 6e74 6572 2074 6865 206e  ease enter the n
-000183a0: 756d 6265 7220 6f66 2063 6174 6567 6f72  umber of categor
-000183b0: 6965 732f 6c61 6265 6c73 2066 6f72 2074  ies/labels for t
-000183c0: 6869 7320 7465 726d 3a5c 7422 290a 2020  his term:\t").  
-000183d0: 2020 2020 2020 2020 2020 2320 6368 6563            # chec
-000183e0: 6b20 6966 2075 7365 7220 7375 7070 6c69  k if user suppli
-000183f0: 6564 2061 206e 756d 6265 7220 656c 7365  ed a number else
-00018400: 2072 6570 6561 7420 7175 6573 7469 6f6e   repeat question
-00018410: 0a20 2020 2020 2020 2020 2020 2074 7279  .            try
-00018420: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00018430: 2020 7661 6c20 3d20 696e 7428 6e75 6d5f    val = int(num_
-00018440: 6361 7465 676f 7269 6573 290a 2020 2020  categories).    
-00018450: 2020 2020 2020 2020 2020 2020 6272 6561              brea
-00018460: 6b0a 2020 2020 2020 2020 2020 2020 6578  k.            ex
-00018470: 6365 7074 2056 616c 7565 4572 726f 723a  cept ValueError:
-00018480: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00018490: 2070 7269 6e74 2822 5468 6174 2773 206e   print("That's n
-000184a0: 6f74 2061 6e20 696e 7465 6765 722c 2070  ot an integer, p
-000184b0: 6c65 6173 6520 7472 7920 6167 6169 6e21  lease try again!
-000184c0: 2229 0a0a 2020 2020 2020 2020 2320 6c6f  ")..        # lo
-000184d0: 6f70 206f 7665 7220 6e75 6d62 6572 206f  op over number o
-000184e0: 6620 6361 7465 676f 7269 6573 2061 6e64  f categories and
-000184f0: 2063 6f6c 6c65 6374 2069 6e66 6f72 6d61   collect informa
-00018500: 7469 6f6e 0a20 2020 2020 2020 2063 6174  tion.        cat
-00018510: 5f76 616c 7565 203d 2069 6e70 7574 2822  _value = input("
-00018520: 4172 6520 7468 6572 6520 6e75 6d65 7269  Are there numeri
-00018530: 6361 6c20 7661 6c75 6573 2061 7373 6f63  cal values assoc
-00018540: 6961 7465 6420 7769 7468 2079 6f75 7220  iated with your 
-00018550: 7465 7874 2d62 6173 6564 2063 6174 6567  text-based categ
-00018560: 6f72 6965 7320 5b79 6573 5d3f 5c74 2229  ories [yes]?\t")
-00018570: 0a20 2020 2020 2020 2069 6620 2863 6174  .        if (cat
-00018580: 5f76 616c 7565 2069 6e20 5b27 5927 2c20  _value in ['Y', 
-00018590: 2779 272c 2027 5945 5327 2c20 2779 6573  'y', 'YES', 'yes
-000185a0: 272c 2027 5965 7327 5d29 206f 7220 2863  ', 'Yes']) or (c
-000185b0: 6174 5f76 616c 7565 203d 3d20 2222 293a  at_value == ""):
-000185c0: 0a20 2020 2020 2020 2020 2020 2023 2069  .            # i
-000185d0: 6620 7965 7320 7468 656e 2073 746f 7265  f yes then store
-000185e0: 2074 6869 7320 6173 2061 2064 6963 7469   this as a dicti
-000185f0: 6f6e 6172 7920 6361 745f 6c61 6265 6c3a  onary cat_label:
-00018600: 2063 6174 5f76 616c 7565 0a20 2020 2020   cat_value.     
-00018610: 2020 2020 2020 2074 6572 6d5f 6361 7465         term_cate
-00018620: 676f 7279 203d 207b 7d0a 0a20 2020 2020  gory = {}..     
-00018630: 2020 2020 2020 2066 6f72 2063 6174 6567         for categ
-00018640: 6f72 7920 696e 2072 616e 6765 2831 2c20  ory in range(1, 
-00018650: 696e 7428 6e75 6d5f 6361 7465 676f 7269  int(num_categori
-00018660: 6573 2920 2b20 3129 3a0a 2020 2020 2020  es) + 1):.      
-00018670: 2020 2020 2020 2020 2020 2320 7465 726d            # term
-00018680: 2063 6174 6567 6f72 7920 6469 6374 696f   category dictio
-00018690: 6e61 7279 2068 6173 206c 6162 656c 7320  nary has labels 
-000186a0: 6173 206b 6579 7320 616e 6420 7661 6c75  as keys and valu
-000186b0: 6520 6173 736f 6369 6174 6564 2077 6974  e associated wit
-000186c0: 6820 6c61 6265 6c20 6173 2076 616c 7565  h label as value
-000186d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000186e0: 2063 6174 5f6c 6162 656c 203d 2069 6e70   cat_label = inp
-000186f0: 7574 2822 506c 6561 7365 2065 6e74 6572  ut("Please enter
-00018700: 2074 6865 2074 6578 7420 7374 7269 6e67   the text string
-00018710: 206c 6162 656c 2066 6f72 2074 6865 2063   label for the c
-00018720: 6174 6567 6f72 7920 2564 3a5c 7422 2025  ategory %d:\t" %
-00018730: 2063 6174 6567 6f72 7929 0a20 2020 2020   category).     
-00018740: 2020 2020 2020 2020 2020 2063 6174 5f76             cat_v
-00018750: 616c 7565 203d 2069 6e70 7574 2822 506c  alue = input("Pl
-00018760: 6561 7365 2065 6e74 6572 2074 6865 2076  ease enter the v
-00018770: 616c 7565 2061 7373 6f63 6961 7465 6420  alue associated 
-00018780: 7769 7468 206c 6162 656c 205c 2225 735c  with label \"%s\
-00018790: 223a 5c74 2220 2520 6361 745f 6c61 6265  ":\t" % cat_labe
-000187a0: 6c29 0a20 2020 2020 2020 2020 2020 2020  l).             
-000187b0: 2020 2074 6572 6d5f 6361 7465 676f 7279     term_category
-000187c0: 5b63 6174 5f6c 6162 656c 5d20 3d20 6361  [cat_label] = ca
-000187d0: 745f 7661 6c75 650a 0a20 2020 2020 2020  t_value..       
-000187e0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-000187f0: 2020 2023 2069 6620 7765 206f 6e6c 7920     # if we only 
-00018800: 6861 7665 2074 6578 742d 6261 7365 6420  have text-based 
-00018810: 6361 7465 676f 7269 6573 2074 6865 6e20  categories then 
-00018820: 7374 6f72 6520 6173 2061 206c 6973 740a  store as a list.
-00018830: 2020 2020 2020 2020 2020 2020 7465 726d              term
-00018840: 5f63 6174 6567 6f72 7920 3d20 5b5d 0a20  _category = []. 
-00018850: 2020 2020 2020 2020 2020 2066 6f72 2063             for c
-00018860: 6174 6567 6f72 7920 696e 2072 616e 6765  ategory in range
-00018870: 2831 2c20 696e 7428 6e75 6d5f 6361 7465  (1, int(num_cate
-00018880: 676f 7269 6573 2920 2b20 3129 3a0a 2020  gories) + 1):.  
-00018890: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-000188a0: 7465 726d 2063 6174 6567 6f72 7920 6469  term category di
-000188b0: 6374 696f 6e61 7279 2068 6173 206c 6162  ctionary has lab
-000188c0: 656c 7320 6173 206b 6579 7320 616e 6420  els as keys and 
-000188d0: 7661 6c75 6520 6173 736f 6369 6174 6564  value associated
-000188e0: 2077 6974 6820 6c61 6265 6c20 6173 2076   with label as v
-000188f0: 616c 7565 0a20 2020 2020 2020 2020 2020  alue.           
-00018900: 2020 2020 2063 6174 5f6c 6162 656c 203d       cat_label =
-00018910: 2069 6e70 7574 2822 506c 6561 7365 2065   input("Please e
-00018920: 6e74 6572 2074 6865 2074 6578 7420 7374  nter the text st
-00018930: 7269 6e67 206c 6162 656c 2066 6f72 2074  ring label for t
-00018940: 6865 2063 6174 6567 6f72 7920 2564 3a5c  he category %d:\
-00018950: 7422 2025 2063 6174 6567 6f72 7929 0a20  t" % category). 
-00018960: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00018970: 6572 6d5f 6361 7465 676f 7279 2e61 7070  erm_category.app
-00018980: 656e 6428 6361 745f 6c61 6265 6c29 0a0a  end(cat_label)..
-00018990: 2020 2020 2320 6966 2074 6572 6d20 6973      # if term is
-000189a0: 206e 6f74 2063 6174 6567 6f72 6963 616c   not categorical
-000189b0: 2074 6865 6e20 6173 6b20 666f 7220 6d69   then ask for mi
-000189c0: 6e2f 6d61 7820 7661 6c75 6573 2e20 2049  n/max values.  I
-000189d0: 6620 6974 2069 7320 6361 7465 676f 7269  f it is categori
-000189e0: 6361 6c20 7468 656e 2073 696d 706c 7920  cal then simply 
-000189f0: 6578 7472 6163 740a 2020 2020 2320 6974  extract.    # it
-00018a00: 2066 726f 6d20 7468 6520 7465 726d 5f63   from the term_c
-00018a10: 6174 6567 6f72 7920 6469 6374 696f 6e61  ategory dictiona
-00018a20: 7279 0a20 2020 2069 6620 7465 726d 5f64  ry.    if term_d
-00018a30: 6174 6174 7970 6520 213d 2055 5249 5265  atatype != URIRe
-00018a40: 6628 436f 6e73 7461 6e74 732e 5853 445b  f(Constants.XSD[
-00018a50: 2263 6f6d 706c 6578 5479 7065 225d 293a  "complexType"]):
-00018a60: 0a20 2020 2020 2020 2074 6572 6d5f 6d69  .        term_mi
-00018a70: 6e20 3d20 696e 7075 7428 2250 6c65 6173  n = input("Pleas
-00018a80: 6520 656e 7465 7220 7468 6520 6d69 6e69  e enter the mini
-00018a90: 6d75 6d20 7661 6c75 6520 5b4e 415d 3a5c  mum value [NA]:\
-00018aa0: 7422 290a 2020 2020 2020 2020 7465 726d  t").        term
-00018ab0: 5f6d 6178 203d 2069 6e70 7574 2822 506c  _max = input("Pl
-00018ac0: 6561 7365 2065 6e74 6572 2074 6865 206d  ease enter the m
-00018ad0: 6178 696d 756d 2076 616c 7565 205b 4e41  aximum value [NA
-00018ae0: 5d3a 5c74 2229 0a20 2020 2020 2020 2074  ]:\t").        t
-00018af0: 6572 6d5f 756e 6974 7320 3d20 696e 7075  erm_units = inpu
-00018b00: 7428 2250 6c65 6173 6520 656e 7465 7220  t("Please enter 
-00018b10: 7468 6520 756e 6974 7320 5b4e 415d 3a5c  the units [NA]:\
-00018b20: 7422 290a 2020 2020 2020 2020 2320 6368  t").        # ch
-00018b30: 6563 6b20 6966 2072 6573 706f 6e73 654f  eck if responseO
-00018b40: 7074 696f 6e73 2069 7320 6120 6b65 792c  ptions is a key,
-00018b50: 2069 6620 6e6f 7420 6372 6561 7465 2069   if not create i
-00018b60: 740a 2020 2020 2020 2020 6966 2027 7265  t.        if 're
-00018b70: 7370 6f6e 7365 4f70 7469 6f6e 7327 206e  sponseOptions' n
-00018b80: 6f74 2069 6e20 736f 7572 6365 5f76 6172  ot in source_var
-00018b90: 6961 626c 655f 616e 6e6f 7461 7469 6f6e  iable_annotation
-00018ba0: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-00018bb0: 2e6b 6579 7328 293a 0a20 2020 2020 2020  .keys():.       
-00018bc0: 2020 2020 2073 6f75 7263 655f 7661 7269       source_vari
-00018bd0: 6162 6c65 5f61 6e6e 6f74 6174 696f 6e73  able_annotations
-00018be0: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
-00018bf0: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
-00018c00: 275d 203d 207b 7d0a 2020 2020 2020 2020  '] = {}.        
-00018c10: 2320 6966 2075 7365 7220 7365 7420 616e  # if user set an
-00018c20: 7920 6f66 2074 6865 7365 2074 6865 6e20  y of these then 
-00018c30: 7374 6f72 6520 656c 7365 2069 676e 6f72  store else ignor
-00018c40: 650a 2020 2020 2020 2020 736f 7572 6365  e.        source
-00018c50: 5f76 6172 6961 626c 655f 616e 6e6f 7461  _variable_annota
-00018c60: 7469 6f6e 735b 6375 7272 656e 745f 7475  tions[current_tu
-00018c70: 706c 655d 5b27 7265 7370 6f6e 7365 4f70  ple]['responseOp
-00018c80: 7469 6f6e 7327 5d5b 2775 6e69 7443 6f64  tions']['unitCod
-00018c90: 6527 5d20 3d20 7465 726d 5f75 6e69 7473  e'] = term_units
-00018ca0: 0a20 2020 2020 2020 2073 6f75 7263 655f  .        source_
-00018cb0: 7661 7269 6162 6c65 5f61 6e6e 6f74 6174  variable_annotat
-00018cc0: 696f 6e73 5b63 7572 7265 6e74 5f74 7570  ions[current_tup
-00018cd0: 6c65 5d5b 2772 6573 706f 6e73 654f 7074  le]['responseOpt
-00018ce0: 696f 6e73 275d 5b27 6d69 6e56 616c 7565  ions']['minValue
-00018cf0: 275d 203d 2074 6572 6d5f 6d69 6e0a 2020  '] = term_min.  
-00018d00: 2020 2020 2020 736f 7572 6365 5f76 6172        source_var
-00018d10: 6961 626c 655f 616e 6e6f 7461 7469 6f6e  iable_annotation
-00018d20: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-00018d30: 5b27 7265 7370 6f6e 7365 4f70 7469 6f6e  ['responseOption
-00018d40: 7327 5d5b 276d 6178 5661 6c75 6527 5d20  s']['maxValue'] 
-00018d50: 3d20 7465 726d 5f6d 6178 0a0a 2020 2020  = term_max..    
-00018d60: 2320 6966 2074 6865 2063 6174 6567 6f72  # if the categor
-00018d70: 6963 616c 2064 6174 6120 6861 7320 6e75  ical data has nu
-00018d80: 6d65 7269 6320 7661 6c75 6573 2074 6865  meric values the
-00018d90: 6e20 7765 2063 616e 2069 6e66 6572 2061  n we can infer a
-00018da0: 206d 696e 2f6d 6178 0a20 2020 2065 6c69   min/max.    eli
-00018db0: 6620 6361 745f 7661 6c75 6520 696e 205b  f cat_value in [
-00018dc0: 2759 272c 2027 7927 2c20 2759 4553 272c  'Y', 'y', 'YES',
-00018dd0: 2027 7965 7327 2c20 2759 6573 275d 3a0a   'yes', 'Yes']:.
-00018de0: 2020 2020 2020 2020 2320 6368 6563 6b20          # check 
-00018df0: 6966 2072 6573 706f 6e73 654f 7074 696f  if responseOptio
-00018e00: 6e73 2069 7320 6120 6b65 792c 2069 6620  ns is a key, if 
-00018e10: 6e6f 7420 6372 6561 7465 2069 740a 2020  not create it.  
-00018e20: 2020 2020 2020 6966 2027 7265 7370 6f6e        if 'respon
-00018e30: 7365 4f70 7469 6f6e 7327 206e 6f74 2069  seOptions' not i
-00018e40: 6e20 736f 7572 6365 5f76 6172 6961 626c  n source_variabl
-00018e50: 655f 616e 6e6f 7461 7469 6f6e 735b 6375  e_annotations[cu
-00018e60: 7272 656e 745f 7475 706c 655d 2e6b 6579  rrent_tuple].key
-00018e70: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
-00018e80: 2073 6f75 7263 655f 7661 7269 6162 6c65   source_variable
-00018e90: 5f61 6e6e 6f74 6174 696f 6e73 5b63 7572  _annotations[cur
-00018ea0: 7265 6e74 5f74 7570 6c65 5d5b 2772 6573  rent_tuple]['res
-00018eb0: 706f 6e73 654f 7074 696f 6e73 275d 203d  ponseOptions'] =
-00018ec0: 207b 7d0a 2020 2020 2020 2020 736f 7572   {}.        sour
-00018ed0: 6365 5f76 6172 6961 626c 655f 616e 6e6f  ce_variable_anno
-00018ee0: 7461 7469 6f6e 735b 6375 7272 656e 745f  tations[current_
-00018ef0: 7475 706c 655d 5b27 7265 7370 6f6e 7365  tuple]['response
-00018f00: 4f70 7469 6f6e 7327 5d5b 276d 696e 5661  Options']['minVa
-00018f10: 6c75 6527 5d20 3d20 6d69 6e28 7465 726d  lue'] = min(term
-00018f20: 5f63 6174 6567 6f72 792e 7661 6c75 6573  _category.values
-00018f30: 2829 290a 2020 2020 2020 2020 736f 7572  ()).        sour
-00018f40: 6365 5f76 6172 6961 626c 655f 616e 6e6f  ce_variable_anno
-00018f50: 7461 7469 6f6e 735b 6375 7272 656e 745f  tations[current_
-00018f60: 7475 706c 655d 5b27 7265 7370 6f6e 7365  tuple]['response
-00018f70: 4f70 7469 6f6e 7327 5d5b 276d 6178 5661  Options']['maxVa
-00018f80: 6c75 6527 5d20 3d20 6d61 7828 7465 726d  lue'] = max(term
-00018f90: 5f63 6174 6567 6f72 792e 7661 6c75 6573  _category.values
-00018fa0: 2829 290a 2020 2020 2020 2020 736f 7572  ()).        sour
-00018fb0: 6365 5f76 6172 6961 626c 655f 616e 6e6f  ce_variable_anno
-00018fc0: 7461 7469 6f6e 735b 6375 7272 656e 745f  tations[current_
-00018fd0: 7475 706c 655d 5b27 7265 7370 6f6e 7365  tuple]['response
-00018fe0: 4f70 7469 6f6e 7327 5d5b 2775 6e69 7443  Options']['unitC
-00018ff0: 6f64 6527 5d20 3d20 274e 4127 0a20 2020  ode'] = 'NA'.   
-00019000: 2023 2063 6174 6567 6f72 6963 616c 2077   # categorical w
-00019010: 6974 6820 6e6f 206d 696e 2f6d 6178 2076  ith no min/max v
-00019020: 616c 7565 730a 2020 2020 656c 7365 3a0a  alues.    else:.
-00019030: 2020 2020 2020 2020 2320 6368 6563 6b20          # check 
-00019040: 6966 2072 6573 706f 6e73 654f 7074 696f  if responseOptio
-00019050: 6e73 2069 7320 6120 6b65 792c 2069 6620  ns is a key, if 
-00019060: 6e6f 7420 6372 6561 7465 2069 740a 2020  not create it.  
-00019070: 2020 2020 2020 6966 2027 7265 7370 6f6e        if 'respon
-00019080: 7365 4f70 7469 6f6e 7327 206e 6f74 2069  seOptions' not i
-00019090: 6e20 736f 7572 6365 5f76 6172 6961 626c  n source_variabl
-000190a0: 655f 616e 6e6f 7461 7469 6f6e 735b 6375  e_annotations[cu
-000190b0: 7272 656e 745f 7475 706c 655d 2e6b 6579  rrent_tuple].key
-000190c0: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
-000190d0: 2073 6f75 7263 655f 7661 7269 6162 6c65   source_variable
-000190e0: 5f61 6e6e 6f74 6174 696f 6e73 5b63 7572  _annotations[cur
-000190f0: 7265 6e74 5f74 7570 6c65 5d5b 2772 6573  rent_tuple]['res
-00019100: 706f 6e73 654f 7074 696f 6e73 275d 203d  ponseOptions'] =
-00019110: 207b 7d0a 2020 2020 2020 2020 736f 7572   {}.        sour
-00019120: 6365 5f76 6172 6961 626c 655f 616e 6e6f  ce_variable_anno
-00019130: 7461 7469 6f6e 735b 6375 7272 656e 745f  tations[current_
-00019140: 7475 706c 655d 5b27 7265 7370 6f6e 7365  tuple]['response
-00019150: 4f70 7469 6f6e 7327 5d5b 276d 696e 5661  Options']['minVa
-00019160: 6c75 6527 5d20 3d20 274e 4127 0a20 2020  lue'] = 'NA'.   
-00019170: 2020 2020 2073 6f75 7263 655f 7661 7269       source_vari
-00019180: 6162 6c65 5f61 6e6e 6f74 6174 696f 6e73  able_annotations
-00019190: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
-000191a0: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
-000191b0: 275d 5b27 6d61 7856 616c 7565 275d 203d  ']['maxValue'] =
-000191c0: 2027 4e41 270a 2020 2020 2020 2020 736f   'NA'.        so
-000191d0: 7572 6365 5f76 6172 6961 626c 655f 616e  urce_variable_an
-000191e0: 6e6f 7461 7469 6f6e 735b 6375 7272 656e  notations[curren
-000191f0: 745f 7475 706c 655d 5b27 7265 7370 6f6e  t_tuple]['respon
-00019200: 7365 4f70 7469 6f6e 7327 5d5b 2775 6e69  seOptions']['uni
-00019210: 7443 6f64 6527 5d20 3d20 274e 4127 0a0a  tCode'] = 'NA'..
-00019220: 2020 2020 2320 7365 7420 7465 726d 2076      # set term v
-00019230: 6172 6961 626c 6520 6e61 6d65 2061 7320  ariable name as 
-00019240: 636f 6c75 6d6e 2066 726f 6d20 4353 5620  column from CSV 
-00019250: 6669 6c65 2077 6527 7265 2063 7572 7265  file we're curre
-00019260: 6e74 6c79 2069 6e74 6572 726f 6761 7469  ntly interrogati
-00019270: 6e67 0a20 2020 2074 6572 6d5f 7661 7269  ng.    term_vari
-00019280: 6162 6c65 5f6e 616d 6520 3d20 736f 7572  able_name = sour
-00019290: 6365 5f76 6172 6961 626c 650a 0a20 2020  ce_variable..   
-000192a0: 2023 2073 746f 7265 2074 6572 6d20 696e   # store term in
-000192b0: 666f 2069 6e20 6469 6374 696f 6e61 7279  fo in dictionary
-000192c0: 0a20 2020 2023 2063 6865 636b 2069 6620  .    # check if 
-000192d0: 7265 7370 6f6e 7365 4f70 7469 6f6e 7320  responseOptions 
-000192e0: 6973 2061 206b 6579 2c20 6966 206e 6f74  is a key, if not
-000192f0: 2063 7265 6174 6520 6974 0a20 2020 2069   create it.    i
-00019300: 6620 2772 6573 706f 6e73 654f 7074 696f  f 'responseOptio
-00019310: 6e73 2720 6e6f 7420 696e 2073 6f75 7263  ns' not in sourc
-00019320: 655f 7661 7269 6162 6c65 5f61 6e6e 6f74  e_variable_annot
-00019330: 6174 696f 6e73 5b63 7572 7265 6e74 5f74  ations[current_t
-00019340: 7570 6c65 5d2e 6b65 7973 2829 3a0a 2020  uple].keys():.  
-00019350: 2020 2020 2020 736f 7572 6365 5f76 6172        source_var
-00019360: 6961 626c 655f 616e 6e6f 7461 7469 6f6e  iable_annotation
-00019370: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
-00019380: 5b27 7265 7370 6f6e 7365 4f70 7469 6f6e  ['responseOption
-00019390: 7327 5d20 3d20 7b7d 0a20 2020 2073 6f75  s'] = {}.    sou
-000193a0: 7263 655f 7661 7269 6162 6c65 5f61 6e6e  rce_variable_ann
-000193b0: 6f74 6174 696f 6e73 5b63 7572 7265 6e74  otations[current
-000193c0: 5f74 7570 6c65 5d5b 276c 6162 656c 275d  _tuple]['label']
-000193d0: 203d 2074 6572 6d5f 6c61 6265 6c0a 2020   = term_label.  
-000193e0: 2020 736f 7572 6365 5f76 6172 6961 626c    source_variabl
-000193f0: 655f 616e 6e6f 7461 7469 6f6e 735b 6375  e_annotations[cu
-00019400: 7272 656e 745f 7475 706c 655d 5b27 6465  rrent_tuple]['de
-00019410: 7363 7269 7074 696f 6e27 5d20 3d20 7465  scription'] = te
-00019420: 726d 5f64 6566 696e 6974 696f 6e0a 2020  rm_definition.  
-00019430: 2020 736f 7572 6365 5f76 6172 6961 626c    source_variabl
-00019440: 655f 616e 6e6f 7461 7469 6f6e 735b 6375  e_annotations[cu
-00019450: 7272 656e 745f 7475 706c 655d 5b27 736f  rrent_tuple]['so
-00019460: 7572 6365 5f76 6172 6961 626c 6527 5d20  urce_variable'] 
-00019470: 3d20 7374 7228 736f 7572 6365 5f76 6172  = str(source_var
-00019480: 6961 626c 6529 0a20 2020 2073 6f75 7263  iable).    sourc
-00019490: 655f 7661 7269 6162 6c65 5f61 6e6e 6f74  e_variable_annot
-000194a0: 6174 696f 6e73 5b63 7572 7265 6e74 5f74  ations[current_t
-000194b0: 7570 6c65 5d5b 2772 6573 706f 6e73 654f  uple]['responseO
-000194c0: 7074 696f 6e73 275d 5b27 7661 6c75 6554  ptions']['valueT
-000194d0: 7970 6527 5d20 3d20 7465 726d 5f64 6174  ype'] = term_dat
-000194e0: 6174 7970 650a 2020 2020 736f 7572 6365  atype.    source
-000194f0: 5f76 6172 6961 626c 655f 616e 6e6f 7461  _variable_annota
-00019500: 7469 6f6e 735b 6375 7272 656e 745f 7475  tions[current_tu
-00019510: 706c 655d 5b27 6173 736f 6369 6174 6564  ple]['associated
-00019520: 5769 7468 275d 203d 2022 4e49 444d 220a  With'] = "NIDM".
-00019530: 0a20 2020 2069 6620 7465 726d 5f64 6174  .    if term_dat
-00019540: 6174 7970 6520 3d3d 2055 5249 5265 6628  atype == URIRef(
-00019550: 436f 6e73 7461 6e74 732e 5853 445b 2263  Constants.XSD["c
-00019560: 6f6d 706c 6578 5479 7065 225d 293a 0a20  omplexType"]):. 
-00019570: 2020 2020 2020 2073 6f75 7263 655f 7661         source_va
-00019580: 7269 6162 6c65 5f61 6e6e 6f74 6174 696f  riable_annotatio
-00019590: 6e73 5b63 7572 7265 6e74 5f74 7570 6c65  ns[current_tuple
-000195a0: 5d5b 2772 6573 706f 6e73 654f 7074 696f  ]['responseOptio
-000195b0: 6e73 275d 5b27 6368 6f69 6365 7327 5d20  ns']['choices'] 
-000195c0: 3d20 7465 726d 5f63 6174 6567 6f72 790a  = term_category.
-000195d0: 0a20 2020 2023 2070 7269 6e74 206d 6170  .    # print map
-000195e0: 7069 6e67 730a 2020 2020 7072 696e 7428  pings.    print(
-000195f0: 225c 6e2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  "\n*************
-00019600: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-00019610: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-00019620: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-00019630: 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a 2a2a  ****************
-00019640: 2a2a 2a2a 2a2a 2a2a 2229 0a20 2020 2070  ********").    p
-00019650: 7269 6e74 2822 5374 6f72 6564 206d 6170  rint("Stored map
-00019660: 7069 6e67 3a20 2573 202d 3e20 2022 2025  ping: %s ->  " %
-00019670: 2073 6f75 7263 655f 7661 7269 6162 6c65   source_variable
-00019680: 290a 2020 2020 7072 696e 7428 226c 6162  ).    print("lab
-00019690: 656c 3a20 2573 2220 2520 736f 7572 6365  el: %s" % source
-000196a0: 5f76 6172 6961 626c 655f 616e 6e6f 7461  _variable_annota
-000196b0: 7469 6f6e 735b 6375 7272 656e 745f 7475  tions[current_tu
-000196c0: 706c 655d 5b27 6c61 6265 6c27 5d29 0a20  ple]['label']). 
-000196d0: 2020 2070 7269 6e74 2822 736f 7572 6365     print("source
-000196e0: 2076 6172 6961 626c 653a 2025 7322 2025   variable: %s" %
-000196f0: 2073 6f75 7263 655f 7661 7269 6162 6c65   source_variable
-00019700: 5f61 6e6e 6f74 6174 696f 6e73 5b63 7572  _annotations[cur
-00019710: 7265 6e74 5f74 7570 6c65 5d5b 2773 6f75  rent_tuple]['sou
-00019720: 7263 655f 7661 7269 6162 6c65 275d 290a  rce_variable']).
-00019730: 2020 2020 7072 696e 7428 2264 6573 6372      print("descr
-00019740: 6970 7469 6f6e 3a20 2573 2220 2520 736f  iption: %s" % so
-00019750: 7572 6365 5f76 6172 6961 626c 655f 616e  urce_variable_an
-00019760: 6e6f 7461 7469 6f6e 735b 6375 7272 656e  notations[curren
-00019770: 745f 7475 706c 655d 5b27 6465 7363 7269  t_tuple]['descri
-00019780: 7074 696f 6e27 5d29 0a20 2020 2070 7269  ption']).    pri
-00019790: 6e74 2822 7661 6c75 6554 7970 653a 2025  nt("valueType: %
-000197a0: 7322 2025 2073 6f75 7263 655f 7661 7269  s" % source_vari
-000197b0: 6162 6c65 5f61 6e6e 6f74 6174 696f 6e73  able_annotations
-000197c0: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
-000197d0: 2772 6573 706f 6e73 654f 7074 696f 6e73  'responseOptions
-000197e0: 275d 5b27 7661 6c75 6554 7970 6527 5d29  ']['valueType'])
-000197f0: 0a20 2020 2023 206c 6566 7420 666f 7220  .    # left for 
-00019800: 6c65 6761 6379 2070 7572 706f 7365 730a  legacy purposes.
-00019810: 2020 2020 6966 2027 6861 7355 6e69 7427      if 'hasUnit'
-00019820: 2069 6e20 736f 7572 6365 5f76 6172 6961   in source_varia
-00019830: 626c 655f 616e 6e6f 7461 7469 6f6e 735b  ble_annotations[
-00019840: 6375 7272 656e 745f 7475 706c 655d 3a0a  current_tuple]:.
-00019850: 2020 2020 2020 2020 7072 696e 7428 2268          print("h
-00019860: 6173 556e 6974 3a20 2573 2220 2520 736f  asUnit: %s" % so
-00019870: 7572 6365 5f76 6172 6961 626c 655f 616e  urce_variable_an
-00019880: 6e6f 7461 7469 6f6e 735b 6375 7272 656e  notations[curren
-00019890: 745f 7475 706c 655d 5b27 6861 7355 6e69  t_tuple]['hasUni
-000198a0: 7427 5d29 0a20 2020 2065 6c69 6620 2775  t']).    elif 'u
-000198b0: 6e69 7443 6f64 6527 2069 6e20 736f 7572  nitCode' in sour
-000198c0: 6365 5f76 6172 6961 626c 655f 616e 6e6f  ce_variable_anno
-000198d0: 7461 7469 6f6e 735b 6375 7272 656e 745f  tations[current_
-000198e0: 7475 706c 655d 5b27 7265 7370 6f6e 7365  tuple]['response
-000198f0: 4f70 7469 6f6e 7327 5d3a 0a20 2020 2020  Options']:.     
-00019900: 2020 2070 7269 6e74 2822 6861 7355 6e69     print("hasUni
-00019910: 743a 2025 7322 2025 2073 6f75 7263 655f  t: %s" % source_
-00019920: 7661 7269 6162 6c65 5f61 6e6e 6f74 6174  variable_annotat
-00019930: 696f 6e73 5b63 7572 7265 6e74 5f74 7570  ions[current_tup
-00019940: 6c65 5d5b 2772 6573 706f 6e73 654f 7074  le]['responseOpt
-00019950: 696f 6e73 275d 5b27 756e 6974 436f 6465  ions']['unitCode
-00019960: 275d 290a 2020 2020 6966 2027 6d69 6e56  ']).    if 'minV
-00019970: 616c 7565 2720 696e 2073 6f75 7263 655f  alue' in source_
-00019980: 7661 7269 6162 6c65 5f61 6e6e 6f74 6174  variable_annotat
-00019990: 696f 6e73 5b63 7572 7265 6e74 5f74 7570  ions[current_tup
-000199a0: 6c65 5d5b 2772 6573 706f 6e73 654f 7074  le]['responseOpt
-000199b0: 696f 6e73 275d 3a0a 2020 2020 2020 2020  ions']:.        
-000199c0: 7072 696e 7428 226d 696e 696d 756d 5661  print("minimumVa
-000199d0: 6c75 653a 2025 7322 2025 2073 6f75 7263  lue: %s" % sourc
-000199e0: 655f 7661 7269 6162 6c65 5f61 6e6e 6f74  e_variable_annot
-000199f0: 6174 696f 6e73 5b63 7572 7265 6e74 5f74  ations[current_t
-00019a00: 7570 6c65 5d5b 2772 6573 706f 6e73 654f  uple]['responseO
-00019a10: 7074 696f 6e73 275d 5b27 6d69 6e56 616c  ptions']['minVal
-00019a20: 7565 275d 290a 2020 2020 6966 2027 6d61  ue']).    if 'ma
-00019a30: 7856 616c 7565 2720 696e 2073 6f75 7263  xValue' in sourc
-00019a40: 655f 7661 7269 6162 6c65 5f61 6e6e 6f74  e_variable_annot
-00019a50: 6174 696f 6e73 5b63 7572 7265 6e74 5f74  ations[current_t
-00019a60: 7570 6c65 5d5b 2772 6573 706f 6e73 654f  uple]['responseO
-00019a70: 7074 696f 6e73 275d 3a0a 2020 2020 2020  ptions']:.      
-00019a80: 2020 7072 696e 7428 226d 6178 696d 756d    print("maximum
-00019a90: 5661 6c75 653a 2025 7322 2025 2073 6f75  Value: %s" % sou
-00019aa0: 7263 655f 7661 7269 6162 6c65 5f61 6e6e  rce_variable_ann
-00019ab0: 6f74 6174 696f 6e73 5b63 7572 7265 6e74  otations[current
-00019ac0: 5f74 7570 6c65 5d5b 2772 6573 706f 6e73  _tuple]['respons
-00019ad0: 654f 7074 696f 6e73 275d 5b27 6d61 7856  eOptions']['maxV
-00019ae0: 616c 7565 275d 290a 2020 2020 6966 2074  alue']).    if t
-00019af0: 6572 6d5f 6461 7461 7479 7065 203d 3d20  erm_datatype == 
-00019b00: 5552 4952 6566 2843 6f6e 7374 616e 7473  URIRef(Constants
-00019b10: 2e58 5344 5b22 636f 6d70 6c65 7854 7970  .XSD["complexTyp
-00019b20: 6522 5d29 3a0a 2020 2020 2020 2020 7072  e"]):.        pr
-00019b30: 696e 7428 2263 686f 6963 6573 3a20 2573  int("choices: %s
-00019b40: 2220 2520 736f 7572 6365 5f76 6172 6961  " % source_varia
-00019b50: 626c 655f 616e 6e6f 7461 7469 6f6e 735b  ble_annotations[
-00019b60: 6375 7272 656e 745f 7475 706c 655d 5b27  current_tuple]['
-00019b70: 7265 7370 6f6e 7365 4f70 7469 6f6e 7327  responseOptions'
-00019b80: 5d5b 2763 686f 6963 6573 275d 290a 2020  ]['choices']).  
-00019b90: 2020 7072 696e 7428 222d 2d2d 2d2d 2d2d    print("-------
-00019ba0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00019bb0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00019bc0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00019bd0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00019be0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00019bf0: 2229 0a0a 6465 6620 4444 5f55 5549 4420  ")..def DD_UUID 
-00019c00: 2865 6c65 6d65 6e74 2c64 645f 7374 7275  (element,dd_stru
-00019c10: 6374 2c64 6174 6173 6574 5f69 6465 6e74  ct,dataset_ident
-00019c20: 6966 6965 723d 4e6f 6e65 293a 0a20 2020  ifier=None):.   
-00019c30: 2027 2727 0a20 2020 2054 6869 7320 6675   '''.    This fu
-00019c40: 6e63 7469 6f6e 2077 696c 6c20 7072 6f64  nction will prod
-00019c50: 7563 6520 6120 6861 7368 206f 6620 7468  uce a hash of th
-00019c60: 6520 6461 7461 2064 6963 7469 6f6e 6172  e data dictionar
-00019c70: 7920 2870 6572 736f 6e61 6c20 6461 7461  y (personal data
-00019c80: 2065 6c65 6d65 6e74 2920 7072 6f70 6572   element) proper
-00019c90: 7469 6573 2064 6566 696e 6564 0a20 2020  ties defined.   
-00019ca0: 2062 7920 7468 6520 7573 6572 2066 6f72   by the user for
-00019cb0: 2075 7365 2061 7320 6120 5555 4944 2e20   use as a UUID. 
-00019cc0: 2054 6865 2064 6174 6120 6469 6374 696f   The data dictio
-00019cd0: 6e61 7279 206b 6579 2069 7320 6120 7475  nary key is a tu
-00019ce0: 706c 6520 6964 656e 7469 6679 696e 6720  ple identifying 
-00019cf0: 7468 6520 6669 6c65 2061 6e64 2076 6172  the file and var
-00019d00: 6961 626c 650a 2020 2020 6e61 6d65 2077  iable.    name w
-00019d10: 6974 6869 6e20 7468 6174 2066 696c 6520  ithin that file 
-00019d20: 746f 2062 6520 656e 636f 6465 6420 7769  to be encoded wi
-00019d30: 7468 2061 2055 5549 442e 2020 5468 6520  th a UUID.  The 
-00019d40: 6964 6561 2069 7320 7468 6174 2069 6620  idea is that if 
-00019d50: 7468 6520 6461 7461 2064 6963 7469 6f6e  the data diction
-00019d60: 6172 6965 7320 666f 7220 610a 2020 2020  aries for a.    
-00019d70: 7065 7273 6f6e 616c 2064 6174 6120 656c  personal data el
-00019d80: 656d 656e 7420 7072 6563 6973 656c 7920  ement precisely 
-00019d90: 6d61 7463 6820 7468 656e 2074 6865 2073  match then the s
-00019da0: 616d 6520 5555 4944 2077 696c 6c20 6265  ame UUID will be
-00019db0: 2067 656e 6572 6174 6564 2e0a 2020 2020   generated..    
-00019dc0: 3a70 6172 616d 2065 6c65 6d65 6e74 3a20  :param element: 
-00019dd0: 656c 656d 656e 7420 696e 2064 645f 7374  element in dd_st
-00019de0: 7275 6374 2074 6f20 6372 6561 7465 2055  ruct to create U
-00019df0: 5549 4420 666f 7220 7769 7468 696e 2074  UID for within t
-00019e00: 6865 2064 645f 7374 7275 6374 0a20 2020  he dd_struct.   
-00019e10: 203a 7061 7261 6d20 6464 5f73 7472 7563   :param dd_struc
-00019e20: 743a 2064 6174 6120 6469 6374 696f 6e61  t: data dictiona
-00019e30: 7279 206a 736f 6e20 7374 7275 6374 7572  ry json structur
-00019e40: 650a 2020 2020 3a72 6574 7572 6e3a 2068  e.    :return: h
-00019e50: 6173 6820 6f66 0a20 2020 2027 2727 0a0a  ash of.    '''..
-00019e60: 2020 2020 2320 6576 616c 7561 7465 2074      # evaluate t
-00019e70: 6865 2063 6f6d 706f 756e 6420 6461 7461  he compound data
-00019e80: 2064 6963 7469 6f6e 6172 7920 6b65 7920   dictionary key 
-00019e90: 616e 6420 6c6f 6f70 206f 7665 7220 7468  and loop over th
-00019ea0: 6520 7072 6f70 6572 7469 6573 0a20 2020  e properties.   
-00019eb0: 206b 6579 5f74 7570 6c65 203d 2065 7661   key_tuple = eva
-00019ec0: 6c28 656c 656d 656e 7429 0a0a 2020 2020  l(element)..    
-00019ed0: 2320 6164 6465 6420 6765 7455 5549 4420  # added getUUID 
-00019ee0: 746f 2070 726f 7065 7274 7920 7374 7269  to property stri
-00019ef0: 6e67 2074 6f20 736f 6c76 6520 7072 6f62  ng to solve prob
-00019f00: 6c65 6d20 7768 6572 6520 616c 6c20 6f70  lem where all op
-00019f10: 656e 6e65 7572 6f20 6461 7461 7365 7473  enneuro datasets
-00019f20: 2074 6861 7420 6861 7665 2074 6865 2073   that have the s
-00019f30: 616d 650a 2020 2020 2320 736f 7572 6365  ame.    # source
-00019f40: 2076 6172 6961 626c 6520 6e61 6d65 2061   variable name a
-00019f50: 6e64 2070 726f 7065 7274 6965 7320 646f  nd properties do
-00019f60: 6e27 7420 656e 6420 7570 2068 6176 696e  n't end up havin
-00019f70: 6720 7468 6520 7361 6d65 2055 5549 4420  g the same UUID 
-00019f80: 6173 2074 6865 7920 6172 6520 736f 6d65  as they are some
-00019f90: 7469 6d65 7320 6e6f 740a 2020 2020 2320  times not.    # 
-00019fa0: 7468 6520 7361 6d65 2061 6e64 2065 6e64  the same and end
-00019fb0: 2075 7020 6265 696e 6720 6164 6465 6420   up being added 
-00019fc0: 746f 2074 6865 2073 616d 6520 656e 7469  to the same enti
-00019fd0: 7479 2077 6865 6e20 6d65 7267 696e 6720  ty when merging 
-00019fe0: 6772 6170 6873 2061 6372 6f73 7320 616c  graphs across al
-00019ff0: 6c20 6f70 656e 6e65 7572 6f20 7072 6f6a  l openneuro proj
-0001a000: 6563 7473 0a20 2020 2023 2069 6620 6120  ects.    # if a 
-0001a010: 6461 7461 7365 7420 6964 656e 7469 6669  dataset identifi
-0001a020: 6572 2069 7320 6e6f 7420 7072 6f76 6964  er is not provid
-0001a030: 6564 2074 6865 6e20 7765 2075 7365 2061  ed then we use a
-0001a040: 2072 616e 646f 6d20 5555 4944 200a 2020   random UUID .  
-0001a050: 2020 6966 2064 6174 6173 6574 5f69 6465    if dataset_ide
-0001a060: 6e74 6966 6965 7220 6973 206e 6f74 204e  ntifier is not N
-0001a070: 6f6e 653a 0a20 2020 2020 2020 2070 726f  one:.        pro
-0001a080: 7065 7274 795f 7374 7269 6e67 203d 2064  perty_string = d
-0001a090: 6174 6173 6574 5f69 6465 6e74 6966 6965  ataset_identifie
-0001a0a0: 720a 2020 2020 656c 7365 3a0a 2020 2020  r.    else:.    
-0001a0b0: 2020 2020 7072 6f70 6572 7479 5f73 7472      property_str
-0001a0c0: 696e 6720 3d20 6765 7455 5549 4428 290a  ing = getUUID().
-0001a0d0: 2020 2020 666f 7220 6b65 792c 2076 616c      for key, val
-0001a0e0: 7565 2069 6e20 6464 5f73 7472 7563 745b  ue in dd_struct[
-0001a0f0: 7374 7228 6b65 795f 7475 706c 6529 5d2e  str(key_tuple)].
-0001a100: 6974 656d 7328 293a 0a20 2020 2020 2020  items():.       
-0001a110: 2069 6620 6b65 7920 3d3d 2027 6c61 6265   if key == 'labe
-0001a120: 6c27 3a0a 2020 2020 2020 2020 2020 2020  l':.            
-0001a130: 7072 6f70 6572 7479 5f73 7472 696e 6720  property_string 
-0001a140: 3d20 7072 6f70 6572 7479 5f73 7472 696e  = property_strin
-0001a150: 6720 2b20 7374 7228 7661 6c75 6529 0a20  g + str(value). 
-0001a160: 2020 2020 2020 2023 2061 6464 6564 2074         # added t
-0001a170: 6f20 7375 7070 6f72 7420 2772 6570 6f6e  o support 'repon
-0001a180: 7365 4f70 7469 6f6e 7327 2072 6570 726f  seOptions' repro
-0001a190: 7363 6865 6d61 2066 6f72 6d61 740a 2020  schema format.  
-0001a1a0: 2020 2020 2020 6966 2028 6b65 7920 3d3d        if (key ==
-0001a1b0: 2027 7265 7370 6f6e 7365 4f70 7469 6f6e   'responseOption
-0001a1c0: 7327 293a 0a20 2020 2020 2020 2020 2020  s'):.           
-0001a1d0: 2066 6f72 2073 7562 6b65 792c 7375 6276   for subkey,subv
-0001a1e0: 616c 7565 2069 6e20 6464 5f73 7472 7563  alue in dd_struc
-0001a1f0: 745b 7374 7228 6b65 795f 7475 706c 6529  t[str(key_tuple)
-0001a200: 5d5b 2772 6573 706f 6e73 654f 7074 696f  ]['responseOptio
-0001a210: 6e73 275d 2e69 7465 6d73 2829 3a0a 2020  ns'].items():.  
-0001a220: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0001a230: 2028 7375 626b 6579 203d 3d20 276c 6576   (subkey == 'lev
-0001a240: 656c 7327 2920 6f72 2028 7375 626b 6579  els') or (subkey
-0001a250: 203d 3d20 274c 6576 656c 7327 2920 6f72   == 'Levels') or
-0001a260: 2028 7375 626b 6579 203d 3d20 2763 686f   (subkey == 'cho
-0001a270: 6963 6573 2729 3a0a 2020 2020 2020 2020  ices'):.        
-0001a280: 2020 2020 2020 2020 2020 2020 7072 6f70              prop
-0001a290: 6572 7479 5f73 7472 696e 6720 3d20 7072  erty_string = pr
-0001a2a0: 6f70 6572 7479 5f73 7472 696e 6720 2b20  operty_string + 
-0001a2b0: 7374 7228 7375 6276 616c 7565 290a 2020  str(subvalue).  
-0001a2c0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0001a2d0: 2073 7562 6b65 7920 3d3d 2027 7661 6c75   subkey == 'valu
-0001a2e0: 6554 7970 6527 3a0a 2020 2020 2020 2020  eType':.        
-0001a2f0: 2020 2020 2020 2020 2020 2020 7072 6f70              prop
-0001a300: 6572 7479 5f73 7472 696e 6720 3d20 7072  erty_string = pr
-0001a310: 6f70 6572 7479 5f73 7472 696e 6720 2b20  operty_string + 
-0001a320: 7374 7228 7375 6276 616c 7565 290a 2020  str(subvalue).  
-0001a330: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0001a340: 2028 7375 626b 6579 203d 3d20 2768 6173   (subkey == 'has
-0001a350: 556e 6974 2729 206f 7220 2873 7562 6b65  Unit') or (subke
-0001a360: 7920 3d3d 2027 756e 6974 436f 6465 2729  y == 'unitCode')
-0001a370: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001a380: 2020 2020 2020 7072 6f70 6572 7479 5f73        property_s
-0001a390: 7472 696e 6720 3d20 7072 6f70 6572 7479  tring = property
-0001a3a0: 5f73 7472 696e 6720 2b20 7374 7228 7375  _string + str(su
-0001a3b0: 6276 616c 7565 290a 2020 2020 2020 2020  bvalue).        
-0001a3c0: 6966 206b 6579 203d 3d20 2773 6f75 7263  if key == 'sourc
-0001a3d0: 655f 7661 7269 6162 6c65 273a 0a20 2020  e_variable':.   
-0001a3e0: 2020 2020 2020 2020 2076 6172 6961 626c           variabl
-0001a3f0: 655f 6e61 6d65 203d 2076 616c 7565 0a0a  e_name = value..
-0001a400: 0a20 2020 2063 7263 3332 6861 7368 203d  .    crc32hash =
-0001a410: 2062 6173 655f 7265 7072 2863 7263 3332   base_repr(crc32
-0001a420: 2873 7472 2870 726f 7065 7274 795f 7374  (str(property_st
-0001a430: 7269 6e67 292e 656e 636f 6465 2829 292c  ring).encode()),
-0001a440: 2033 3229 2e6c 6f77 6572 2829 0a20 2020   32).lower().   
-0001a450: 206e 6969 7269 5f6e 7320 3d20 4e61 6d65   niiri_ns = Name
-0001a460: 7370 6163 6528 436f 6e73 7461 6e74 732e  space(Constants.
-0001a470: 4e49 4952 4929 0a20 2020 2063 6465 5f69  NIIRI).    cde_i
-0001a480: 6420 3d20 5552 4952 6566 286e 6969 7269  d = URIRef(niiri
-0001a490: 5f6e 7320 2b20 7361 6665 5f73 7472 696e  _ns + safe_strin
-0001a4a0: 6728 7661 7269 6162 6c65 5f6e 616d 6529  g(variable_name)
-0001a4b0: 202b 2022 5f22 202b 2073 7472 2863 7263   + "_" + str(crc
-0001a4c0: 3332 6861 7368 2929 0a20 2020 2072 6574  32hash)).    ret
-0001a4d0: 7572 6e20 6364 655f 6964 0a0a 6465 6620  urn cde_id..def 
-0001a4e0: 4444 5f74 6f5f 6e69 646d 2864 645f 7374  DD_to_nidm(dd_st
-0001a4f0: 7275 6374 2c64 6174 6173 6574 5f69 6465  ruct,dataset_ide
-0001a500: 6e74 6966 6965 723d 4e6f 6e65 293a 0a20  ntifier=None):. 
-0001a510: 2020 2027 2727 0a0a 2020 2020 5461 6b65     '''..    Take
-0001a520: 7320 6120 4444 206a 736f 6e20 7374 7275  s a DD json stru
-0001a530: 6374 7572 6520 616e 6420 7265 7475 726e  cture and return
-0001a540: 7320 6e69 646d 2043 4445 2d73 7479 6c65  s nidm CDE-style
-0001a550: 2067 7261 7068 2074 6f20 6265 2061 6464   graph to be add
-0001a560: 6564 2074 6f20 4e49 444d 2064 6f63 756d  ed to NIDM docum
-0001a570: 656e 7473 0a20 2020 203a 7061 7261 6d20  ents.    :param 
-0001a580: 4444 3a0a 2020 2020 3a72 6574 7572 6e3a  DD:.    :return:
-0001a590: 204e 4944 4d20 6772 6170 680a 2020 2020   NIDM graph.    
-0001a5a0: 2727 270a 0a20 2020 2023 2063 7265 6174  '''..    # creat
-0001a5b0: 6520 656d 7074 7920 6772 6170 6820 666f  e empty graph fo
-0001a5c0: 7220 4344 4573 0a20 2020 2067 3d47 7261  r CDEs.    g=Gra
-0001a5d0: 7068 2829 0a20 2020 2067 2e62 696e 6428  ph().    g.bind(
-0001a5e0: 7072 6566 6978 3d27 7072 6f76 272c 6e61  prefix='prov',na
-0001a5f0: 6d65 7370 6163 653d 436f 6e73 7461 6e74  mespace=Constant
-0001a600: 732e 5052 4f56 290a 2020 2020 672e 6269  s.PROV).    g.bi
-0001a610: 6e64 2870 7265 6669 783d 2764 6374 272c  nd(prefix='dct',
-0001a620: 6e61 6d65 7370 6163 653d 436f 6e73 7461  namespace=Consta
-0001a630: 6e74 732e 4443 5429 0a20 2020 2067 2e62  nts.DCT).    g.b
-0001a640: 696e 6428 7072 6566 6978 3d27 6269 6473  ind(prefix='bids
-0001a650: 272c 6e61 6d65 7370 6163 653d 436f 6e73  ',namespace=Cons
-0001a660: 7461 6e74 732e 4249 4453 290a 0a20 2020  tants.BIDS)..   
-0001a670: 2023 206b 6579 5f6e 756d 203d 2030 0a20   # key_num = 0. 
-0001a680: 2020 2023 2066 6f72 2065 6163 6820 6e61     # for each na
-0001a690: 6d65 6420 7475 706c 6520 6b65 7920 696e  med tuple key in
-0001a6a0: 2064 6174 6120 6469 6374 696f 6e61 7279   data dictionary
-0001a6b0: 0a20 2020 2066 6f72 206b 6579 2069 6e20  .    for key in 
-0001a6c0: 6464 5f73 7472 7563 743a 0a20 2020 2020  dd_struct:.     
-0001a6d0: 2020 2023 2062 696e 6420 6120 6e61 6d65     # bind a name
-0001a6e0: 7370 6163 6520 666f 7220 7468 6520 7468  space for the th
-0001a6f0: 6520 6461 7461 2064 6963 7469 6f6e 6172  e data dictionar
-0001a700: 7920 736f 7572 6365 2066 6965 6c64 206f  y source field o
-0001a710: 6620 7468 6520 6b65 7920 7475 706c 650a  f the key tuple.
-0001a720: 2020 2020 2020 2020 2320 666f 7220 6561          # for ea
-0001a730: 6368 2073 6f75 7263 6520 7661 7269 6162  ch source variab
-0001a740: 6c65 2063 7265 6174 6520 656e 7469 7479  le create entity
-0001a750: 2077 6865 7265 2074 6865 206e 616d 6573   where the names
-0001a760: 7061 6365 2069 7320 7468 6520 736f 7572  pace is the sour
-0001a770: 6365 2061 6e64 2049 4420 6973 2074 6865  ce and ID is the
-0001a780: 2076 6172 6961 626c 650a 2020 2020 2020   variable.      
-0001a790: 2020 2320 652e 672e 2063 616c 6761 7279    # e.g. calgary
-0001a7a0: 3a46 4953 4341 4c5f 342c 2061 696d 733a  :FISCAL_4, aims:
-0001a7b0: 4649 4149 4d5f 390a 2020 2020 2020 2020  FIAIM_9.        
-0001a7c0: 230a 2020 2020 2020 2020 2320 5468 656e  #.        # Then
-0001a7d0: 2077 6865 6e20 7765 2772 6520 7374 6f72   when we're stor
-0001a7e0: 696e 6720 6163 7175 6972 6564 2064 6174  ing acquired dat
-0001a7f0: 6120 696e 2065 6e74 6974 7920 7765 276c  a in entity we'l
-0001a800: 6c20 7573 6520 7468 6520 656e 7469 7479  l use the entity
-0001a810: 2049 4473 2061 626f 7665 2074 6f20 7265   IDs above to re
-0001a820: 6665 7265 6e63 6520 6120 7061 7274 6963  ference a partic
-0001a830: 756c 6172 0a20 2020 2020 2020 2023 2043  ular.        # C
-0001a840: 4445 2e20 2054 6865 2043 4445 2064 6566  DE.  The CDE def
-0001a850: 696e 6974 696f 6e73 2077 696c 6c20 6861  initions will ha
-0001a860: 7665 206d 6574 6164 6174 6120 6162 6f75  ve metadata abou
-0001a870: 7420 7468 6520 7661 7269 6f75 7320 6173  t the various as
-0001a880: 7065 6374 7320 6f66 2074 6865 2064 6174  pects of the dat
-0001a890: 6120 6469 6374 696f 6e61 7279 2043 4445  a dictionary CDE
-0001a8a0: 2e0a 0a20 2020 2020 2020 2023 2061 6464  ...        # add
-0001a8b0: 2074 6865 2044 6174 6145 6c65 6d65 6e74   the DataElement
-0001a8c0: 2052 4446 2074 7970 6520 696e 2074 6865   RDF type in the
-0001a8d0: 2073 6f75 7263 6520 6e61 6d65 7370 6163   source namespac
-0001a8e0: 650a 2020 2020 2020 2020 6b65 795f 7475  e.        key_tu
-0001a8f0: 706c 6520 3d20 6576 616c 286b 6579 290a  ple = eval(key).
-0001a900: 2020 2020 2020 2020 666f 7220 7375 626b          for subk
-0001a910: 6579 2c20 6974 656d 2069 6e20 6b65 795f  ey, item in key_
-0001a920: 7475 706c 652e 5f61 7364 6963 7428 292e  tuple._asdict().
-0001a930: 6974 656d 7328 293a 0a0a 2020 2020 2020  items():..      
-0001a940: 2020 2020 2020 6966 2073 7562 6b65 7920        if subkey 
-0001a950: 3d3d 2027 7661 7269 6162 6c65 273a 0a0a  == 'variable':..
-0001a960: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a970: 2369 7465 6d5f 6e73 203d 204e 616d 6573  #item_ns = Names
-0001a980: 7061 6365 2864 645f 7374 7275 6374 5b73  pace(dd_struct[s
-0001a990: 7472 286b 6579 5f74 7570 6c65 295d 5b22  tr(key_tuple)]["
-0001a9a0: 7572 6c22 5d2b 222f 2229 0a20 2020 2020  url"]+"/").     
-0001a9b0: 2020 2020 2020 2020 2020 2023 672e 6269             #g.bi
-0001a9c0: 6e64 2870 7265 6669 783d 7361 6665 5f73  nd(prefix=safe_s
-0001a9d0: 7472 696e 6728 6974 656d 292c 206e 616d  tring(item), nam
-0001a9e0: 6573 7061 6365 3d69 7465 6d5f 6e73 290a  espace=item_ns).
-0001a9f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001aa00: 206e 6964 6d5f 6e73 203d 204e 616d 6573   nidm_ns = Names
-0001aa10: 7061 6365 2843 6f6e 7374 616e 7473 2e4e  pace(Constants.N
-0001aa20: 4944 4d29 0a20 2020 2020 2020 2020 2020  IDM).           
-0001aa30: 2020 2020 2067 2e62 696e 6428 7072 6566       g.bind(pref
-0001aa40: 6978 3d27 6e69 646d 272c 206e 616d 6573  ix='nidm', names
-0001aa50: 7061 6365 3d6e 6964 6d5f 6e73 290a 2020  pace=nidm_ns).  
-0001aa60: 2020 2020 2020 2020 2020 2020 2020 6e69                ni
-0001aa70: 6972 695f 6e73 203d 204e 616d 6573 7061  iri_ns = Namespa
-0001aa80: 6365 2843 6f6e 7374 616e 7473 2e4e 4949  ce(Constants.NII
-0001aa90: 5249 290a 2020 2020 2020 2020 2020 2020  RI).            
-0001aaa0: 2020 2020 672e 6269 6e64 2870 7265 6669      g.bind(prefi
-0001aab0: 783d 276e 6969 7269 272c 206e 616d 6573  x='niiri', names
-0001aac0: 7061 6365 3d6e 6969 7269 5f6e 7329 0a20  pace=niiri_ns). 
-0001aad0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0001aae0: 6c78 5f6e 7320 3d20 4e61 6d65 7370 6163  lx_ns = Namespac
-0001aaf0: 6528 436f 6e73 7461 6e74 732e 494e 5445  e(Constants.INTE
-0001ab00: 524c 4558 290a 2020 2020 2020 2020 2020  RLEX).          
-0001ab10: 2020 2020 2020 672e 6269 6e64 2870 7265        g.bind(pre
-0001ab20: 6669 783d 2769 6c78 272c 206e 616d 6573  fix='ilx', names
-0001ab30: 7061 6365 3d69 6c78 5f6e 7329 0a0a 2020  pace=ilx_ns)..  
-0001ab40: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-0001ab50: 6364 655f 6964 203d 2069 7465 6d5f 6e73  cde_id = item_ns
-0001ab60: 5b73 7472 286b 6579 5f6e 756d 292e 7a66  [str(key_num).zf
-0001ab70: 696c 6c28 3429 5d0a 0a20 2020 2020 2020  ill(4)]..       
-0001ab80: 2020 2020 2020 2020 2023 2068 6173 6820           # hash 
-0001ab90: 7468 6520 6b65 795f 7475 706c 6520 2865  the key_tuple (e
-0001aba0: 2e67 2e20 4444 2873 6f75 7263 653d 5b46  .g. DD(source=[F
-0001abb0: 494c 454e 414d 455d 2c76 6172 6961 626c  ILENAME],variabl
-0001abc0: 653d 5b56 4152 4e41 4d45 5d29 290a 2020  e=[VARNAME])).  
-0001abd0: 2020 2020 2020 2020 2020 2020 2020 2363                #c
-0001abe0: 7263 3332 6861 7368 203d 2062 6173 655f  rc32hash = base_
-0001abf0: 7265 7072 2863 7263 3332 2873 7472 286b  repr(crc32(str(k
-0001ac00: 6579 292e 656e 636f 6465 2829 292c 3332  ey).encode()),32
-0001ac10: 292e 6c6f 7765 7228 290a 2020 2020 2020  ).lower().      
-0001ac20: 2020 2020 2020 2020 2020 2320 6d64 3568            # md5h
-0001ac30: 6173 6820 3d20 6861 7368 6c69 622e 6d64  ash = hashlib.md
-0001ac40: 3528 7374 7228 6b65 7929 2e65 6e63 6f64  5(str(key).encod
-0001ac50: 6528 2929 2e68 6578 6469 6765 7374 2829  e()).hexdigest()
-0001ac60: 0a0a 0a20 2020 2020 2020 2020 2020 2020  ...             
-0001ac70: 2020 2063 6465 5f69 6420 3d20 4444 5f55     cde_id = DD_U
-0001ac80: 5549 4428 6b65 792c 6464 5f73 7472 7563  UID(key,dd_struc
-0001ac90: 742c 6461 7461 7365 745f 6964 656e 7469  t,dataset_identi
-0001aca0: 6669 6572 290a 2020 2020 2020 2020 2020  fier).          
-0001acb0: 2020 2020 2020 2363 6465 5f69 6420 3d20        #cde_id = 
-0001acc0: 5552 4952 6566 286e 6969 7269 5f6e 7320  URIRef(niiri_ns 
-0001acd0: 2b20 7361 6665 5f73 7472 696e 6728 6974  + safe_string(it
-0001ace0: 656d 2920 2b20 225f 2220 2b20 7374 7228  em) + "_" + str(
-0001acf0: 6372 6333 3268 6173 6829 290a 2020 2020  crc32hash)).    
-0001ad00: 2020 2020 2020 2020 2020 2020 672e 6164              g.ad
-0001ad10: 6428 2863 6465 5f69 642c 5244 462e 7479  d((cde_id,RDF.ty
-0001ad20: 7065 2c20 436f 6e73 7461 6e74 732e 4e49  pe, Constants.NI
-0001ad30: 444d 5b27 5065 7273 6f6e 616c 4461 7461  DM['PersonalData
-0001ad40: 456c 656d 656e 7427 5d29 290a 2020 2020  Element'])).    
-0001ad50: 2020 2020 2020 2020 2020 2020 672e 6164              g.ad
-0001ad60: 6428 2863 6465 5f69 642c 5244 462e 7479  d((cde_id,RDF.ty
-0001ad70: 7065 2c20 436f 6e73 7461 6e74 732e 5052  pe, Constants.PR
-0001ad80: 4f56 5b27 456e 7469 7479 275d 2929 0a20  OV['Entity'])). 
-0001ad90: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-0001ada0: 2044 424b 3a20 332f 3235 2f32 3120 2d20   DBK: 3/25/21 - 
-0001adb0: 6164 6465 6420 746f 2063 6f6e 6e65 6374  added to connect
-0001adc0: 206e 6964 6d3a 5065 7273 6f6e 616c 4461   nidm:PersonalDa
-0001add0: 7461 456c 656d 656e 7420 746f 2074 6865  taElement to the
-0001ade0: 206d 6f72 6520 6765 6e65 7261 6c20 6e69   more general ni
-0001adf0: 646d 3a44 6174 6145 6c65 6d65 6e74 2061  dm:DataElement a
-0001ae00: 730a 2020 2020 2020 2020 2020 2020 2020  s.              
-0001ae10: 2020 2320 7375 6263 6c61 7373 2074 6f20    # subclass to 
-0001ae20: 6169 6420 696e 2071 7565 7269 6573 0a20  aid in queries. 
-0001ae30: 2020 2020 2020 2020 2020 2020 2020 2067                 g
-0001ae40: 2e61 6464 2828 436f 6e73 7461 6e74 732e  .add((Constants.
-0001ae50: 4e49 444d 5b27 5065 7273 6f6e 616c 4461  NIDM['PersonalDa
-0001ae60: 7461 456c 656d 656e 7427 5d2c 2043 6f6e  taElement'], Con
-0001ae70: 7374 616e 7473 2e52 4446 535b 2773 7562  stants.RDFS['sub
-0001ae80: 436c 6173 734f 6627 5d2c 0a20 2020 2020  ClassOf'],.     
-0001ae90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001aea0: 2020 436f 6e73 7461 6e74 732e 4e49 444d    Constants.NIDM
-0001aeb0: 5b27 4461 7461 456c 656d 656e 7427 5d29  ['DataElement'])
-0001aec0: 290a 0a20 2020 2020 2020 2023 2074 6869  )..        # thi
-0001aed0: 7320 636f 6465 2061 6464 7320 7468 6520  s code adds the 
-0001aee0: 7072 6f70 6572 7469 6573 2061 626f 7574  properties about
-0001aef0: 2074 6865 2070 6172 7469 6375 6c61 7220   the particular 
-0001af00: 4344 4520 696e 746f 204e 4944 4d20 646f  CDE into NIDM do
-0001af10: 6375 6d65 6e74 0a20 2020 2020 2020 2066  cument.        f
-0001af20: 6f72 206b 6579 2c20 7661 6c75 6520 696e  or key, value in
-0001af30: 2064 645f 7374 7275 6374 5b73 7472 286b   dd_struct[str(k
-0001af40: 6579 5f74 7570 6c65 295d 2e69 7465 6d73  ey_tuple)].items
-0001af50: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
-0001af60: 6966 206b 6579 203d 3d20 2764 6566 696e  if key == 'defin
-0001af70: 6974 696f 6e27 3a0a 2020 2020 2020 2020  ition':.        
-0001af80: 2020 2020 2020 2020 672e 6164 6428 2863          g.add((c
-0001af90: 6465 5f69 642c 5244 4653 5b27 636f 6d6d  de_id,RDFS['comm
-0001afa0: 656e 7427 5d2c 4c69 7465 7261 6c28 7661  ent'],Literal(va
-0001afb0: 6c75 6529 2929 0a20 2020 2020 2020 2020  lue))).         
-0001afc0: 2020 2065 6c69 6620 6b65 7920 3d3d 2027     elif key == '
-0001afd0: 6465 7363 7269 7074 696f 6e27 3a0a 2020  description':.  
-0001afe0: 2020 2020 2020 2020 2020 2020 2020 672e                g.
-0001aff0: 6164 6428 2863 6465 5f69 642c 436f 6e73  add((cde_id,Cons
-0001b000: 7461 6e74 732e 4443 545b 2764 6573 6372  tants.DCT['descr
-0001b010: 6970 7469 6f6e 275d 2c4c 6974 6572 616c  iption'],Literal
-0001b020: 2876 616c 7565 2929 290a 2020 2020 2020  (value))).      
-0001b030: 2020 2020 2020 656c 6966 206b 6579 203d        elif key =
-0001b040: 3d20 2775 726c 273a 0a20 2020 2020 2020  = 'url':.       
-0001b050: 2020 2020 2020 2020 2067 2e61 6464 2828           g.add((
-0001b060: 6364 655f 6964 2c43 6f6e 7374 616e 7473  cde_id,Constants
-0001b070: 2e4e 4944 4d5b 2775 726c 275d 2c55 5249  .NIDM['url'],URI
-0001b080: 5265 6628 7661 6c75 6529 2929 0a20 2020  Ref(value))).   
-0001b090: 2020 2020 2020 2020 2065 6c69 6620 6b65           elif ke
-0001b0a0: 7920 3d3d 2027 6c61 6265 6c27 3a0a 2020  y == 'label':.  
-0001b0b0: 2020 2020 2020 2020 2020 2020 2020 672e                g.
-0001b0c0: 6164 6428 2863 6465 5f69 642c 436f 6e73  add((cde_id,Cons
-0001b0d0: 7461 6e74 732e 5244 4653 5b27 6c61 6265  tants.RDFS['labe
-0001b0e0: 6c27 5d2c 4c69 7465 7261 6c28 7661 6c75  l'],Literal(valu
-0001b0f0: 6529 2929 0a20 2020 2020 2020 2020 2020  e))).           
-0001b100: 2065 6c69 6620 286b 6579 203d 3d20 276c   elif (key == 'l
-0001b110: 6576 656c 7327 2920 6f72 2028 6b65 7920  evels') or (key 
-0001b120: 3d3d 2027 4c65 7665 6c73 2729 3a0a 2020  == 'Levels'):.  
-0001b130: 2020 2020 2020 2020 2020 2020 2020 672e                g.
-0001b140: 6164 6428 2863 6465 5f69 642c 436f 6e73  add((cde_id,Cons
-0001b150: 7461 6e74 732e 4e49 444d 5b27 6c65 7665  tants.NIDM['leve
-0001b160: 6c73 275d 2c4c 6974 6572 616c 2876 616c  ls'],Literal(val
-0001b170: 7565 2929 290a 2020 2020 2020 2020 2020  ue))).          
-0001b180: 2020 656c 6966 206b 6579 203d 3d20 2773    elif key == 's
-0001b190: 6f75 7263 655f 7661 7269 6162 6c65 273a  ource_variable':
-0001b1a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b1b0: 2067 2e61 6464 2828 6364 655f 6964 2c20   g.add((cde_id, 
-0001b1c0: 436f 6e73 7461 6e74 732e 4e49 444d 5b27  Constants.NIDM['
-0001b1d0: 736f 7572 6365 5661 7269 6162 6c65 275d  sourceVariable']
-0001b1e0: 2c20 4c69 7465 7261 6c28 7661 6c75 6529  , Literal(value)
-0001b1f0: 2929 0a20 2020 2020 2020 2020 2020 2065  )).            e
-0001b200: 6c69 6620 6b65 7920 3d3d 2027 6973 4162  lif key == 'isAb
-0001b210: 6f75 7427 3a0a 2020 2020 2020 2020 2020  out':.          
-0001b220: 2020 2020 2020 2364 6374 5f6e 7320 3d20        #dct_ns = 
-0001b230: 4e61 6d65 7370 6163 6528 436f 6e73 7461  Namespace(Consta
-0001b240: 6e74 732e 4443 5429 0a20 2020 2020 2020  nts.DCT).       
-0001b250: 2020 2020 2020 2020 2023 672e 6269 6e64           #g.bind
-0001b260: 2870 7265 6669 783d 2764 6374 272c 206e  (prefix='dct', n
-0001b270: 616d 6573 7061 6365 3d64 6374 5f6e 7329  amespace=dct_ns)
-0001b280: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b290: 2023 2061 6464 6564 2062 7920 4442 4b20   # added by DBK 
-0001b2a0: 666f 7220 6d75 6c74 6970 6c65 2069 7341  for multiple isA
-0001b2b0: 626f 7574 2055 524c 7320 616e 6420 7374  bout URLs and st
-0001b2c0: 6f72 696e 6720 7468 6520 6c61 6265 6c73  oring the labels
-0001b2d0: 2061 6c6f 6e67 2077 6974 6820 5552 4c73   along with URLs
-0001b2e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b2f0: 2023 2066 6972 7374 2067 6574 2061 2075   # first get a u
-0001b300: 7569 6420 6861 7320 666f 7220 7468 6520  uid has for the 
-0001b310: 6973 4162 6f75 7420 636f 6c6c 6563 7469  isAbout collecti
-0001b320: 6f6e 2066 6f72 2074 6869 7320 7765 276c  on for this we'l
-0001b330: 6c20 7573 6520 6120 6861 7368 206f 6620  l use a hash of 
-0001b340: 7468 6520 6973 4162 6f75 7420 6c69 7374  the isAbout list
-0001b350: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b360: 2023 2061 7320 6120 7374 7269 6e67 0a20   # as a string. 
-0001b370: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-0001b380: 6372 6333 3268 6173 6820 3d20 6261 7365  crc32hash = base
-0001b390: 5f72 6570 7228 6372 6333 3228 7374 7228  _repr(crc32(str(
-0001b3a0: 7661 6c75 6529 2e65 6e63 6f64 6528 2929  value).encode())
-0001b3b0: 2c20 3332 292e 6c6f 7765 7228 290a 2020  , 32).lower().  
-0001b3c0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-0001b3d0: 6e6f 7720 6372 6561 7465 2074 6865 2063  now create the c
-0001b3e0: 6f6c 6c65 6374 696f 6e20 616e 6420 666f  ollection and fo
-0001b3f0: 7220 6561 6368 2069 7341 626f 7574 2063  r each isAbout c
-0001b400: 7265 6174 6520 616e 2065 6e74 6974 7920  reate an entity 
-0001b410: 746f 2061 6464 2074 6f20 636f 6c6c 6563  to add to collec
-0001b420: 7469 6f6e 2077 6974 680a 2020 2020 2020  tion with.      
-0001b430: 2020 2020 2020 2020 2020 2320 7072 6f70            # prop
-0001b440: 6572 7469 6573 2066 6f72 206c 6162 656c  erties for label
-0001b450: 2061 6e64 2075 726c 0a20 2020 2020 2020   and url.       
-0001b460: 2020 2020 2020 2020 2023 672e 6164 6428           #g.add(
-0001b470: 2869 7361 626f 7574 5f63 6f6c 6c65 6374  (isabout_collect
-0001b480: 696f 6e5f 6964 2c20 5244 462e 7479 7065  ion_id, RDF.type
-0001b490: 2c20 436f 6e73 7461 6e74 732e 5052 4f56  , Constants.PROV
-0001b4a0: 5b27 436f 6c6c 6563 7469 6f6e 275d 2929  ['Collection']))
-0001b4b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b4c0: 2023 2066 6f72 2065 6163 6820 6973 4162   # for each isAb
-0001b4d0: 6f75 7420 656e 7472 792c 2063 7265 6174  out entry, creat
-0001b4e0: 6520 6e65 7720 7072 6f76 3a45 6e74 6974  e new prov:Entit
-0001b4f0: 792c 2073 746f 7265 206d 6574 6164 6174  y, store metadat
-0001b500: 6120 616e 6420 6c69 6e6b 2069 7420 746f  a and link it to
-0001b510: 2074 6865 2063 6f6c 6c65 6374 696f 6e0a   the collection.
-0001b520: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b530: 2023 6966 2077 6520 6861 7665 206d 756c   #if we have mul
-0001b540: 7469 706c 6520 6973 4162 6f75 7473 2074  tiple isAbouts t
-0001b550: 6865 6e20 6974 2077 696c 6c20 6265 2073  hen it will be s
-0001b560: 746f 7265 6420 6173 2061 206c 6973 7420  tored as a list 
-0001b570: 6f66 2064 6963 7473 0a20 2020 2020 2020  of dicts.       
-0001b580: 2020 2020 2020 2020 2069 6620 6973 696e           if isin
-0001b590: 7374 616e 6365 2876 616c 7565 2c20 6c69  stance(value, li
-0001b5a0: 7374 293a 0a20 2020 2020 2020 2020 2020  st):.           
-0001b5b0: 2020 2020 2020 2020 2066 6f72 2073 7562           for sub
-0001b5c0: 6469 6374 2069 6e20 7661 6c75 653a 0a20  dict in value:. 
-0001b5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b5e0: 2020 2020 2020 2066 6f72 2069 7361 626f         for isabo
-0001b5f0: 7574 5f6b 6579 2c20 6973 6162 6f75 745f  ut_key, isabout_
-0001b600: 7661 6c75 6520 696e 2073 7562 6469 6374  value in subdict
-0001b610: 2e69 7465 6d73 2829 3a0a 2020 2020 2020  .items():.      
-0001b620: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b630: 2020 2020 2020 6966 2028 6973 6162 6f75        if (isabou
-0001b640: 745f 6b65 7920 3d3d 2027 4069 6427 2920  t_key == '@id') 
-0001b650: 6f72 2028 6973 6162 6f75 745f 6b65 7920  or (isabout_key 
-0001b660: 3d3d 2027 7572 6c27 293a 0a20 2020 2020  == 'url'):.     
-0001b670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b680: 2020 2020 2020 2020 2020 206c 6173 745f             last_
-0001b690: 6964 203d 2069 7361 626f 7574 5f76 616c  id = isabout_val
-0001b6a0: 7565 0a20 2020 2020 2020 2020 2020 2020  ue.             
-0001b6b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b6c0: 2020 2023 2061 6464 2069 7341 626f 7574     # add isAbout
-0001b6d0: 206b 6579 2077 6869 6368 2069 7320 7468   key which is th
-0001b6e0: 6520 7572 6c0a 2020 2020 2020 2020 2020  e url.          
-0001b6f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b700: 2020 2020 2020 672e 6164 6428 2863 6465        g.add((cde
-0001b710: 5f69 642c 2043 6f6e 7374 616e 7473 2e4e  _id, Constants.N
-0001b720: 4944 4d5b 2769 7341 626f 7574 275d 2c20  IDM['isAbout'], 
-0001b730: 5552 4952 6566 2869 7361 626f 7574 5f76  URIRef(isabout_v
-0001b740: 616c 7565 2929 290a 2020 2020 2020 2020  alue))).        
-0001b750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b760: 2020 2020 656c 6966 2069 7361 626f 7574      elif isabout
-0001b770: 5f6b 6579 203d 3d20 276c 6162 656c 273a  _key == 'label':
-0001b780: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b7a0: 2023 206e 6f77 2061 6464 2061 6e6f 7468   # now add anoth
-0001b7b0: 6572 2065 6e74 6974 7920 746f 2063 6f6e  er entity to con
-0001b7c0: 7461 696e 2074 6865 206c 6162 656c 0a20  tain the label. 
-0001b7d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b7e0: 2020 2020 2020 2020 2020 2020 2020 2067                 g
-0001b7f0: 2e61 6464 2828 5552 4952 6566 286c 6173  .add((URIRef(las
-0001b800: 745f 6964 292c 2052 4446 2e74 7970 652c  t_id), RDF.type,
-0001b810: 436f 6e73 7461 6e74 732e 5052 4f56 5b27  Constants.PROV['
-0001b820: 456e 7469 7479 275d 2929 0a20 2020 2020  Entity'])).     
-0001b830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b840: 2020 2020 2020 2020 2020 2067 2e61 6464             g.add
-0001b850: 2828 5552 4952 6566 286c 6173 745f 6964  ((URIRef(last_id
-0001b860: 292c 2043 6f6e 7374 616e 7473 2e52 4446  ), Constants.RDF
-0001b870: 535b 276c 6162 656c 275d 2c20 4c69 7465  S['label'], Lite
-0001b880: 7261 6c28 6973 6162 6f75 745f 7661 6c75  ral(isabout_valu
-0001b890: 6529 2929 0a20 2020 2020 2020 2020 2020  e))).           
-0001b8a0: 2020 2020 2023 2065 6c73 6520 7765 206f       # else we o
-0001b8b0: 6e6c 7920 6861 7665 2031 2069 7361 626f  nly have 1 isabo
-0001b8c0: 7574 2077 6869 6368 2069 7320 6120 6469  ut which is a di
-0001b8d0: 6374 0a20 2020 2020 2020 2020 2020 2020  ct.             
-0001b8e0: 2020 2065 6c73 653a 0a0a 2020 2020 2020     else:..      
-0001b8f0: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-0001b900: 7220 6973 6162 6f75 745f 6b65 792c 2069  r isabout_key, i
-0001b910: 7361 626f 7574 5f76 616c 7565 2069 6e20  sabout_value in 
-0001b920: 7661 6c75 652e 6974 656d 7328 293a 0a20  value.items():. 
-0001b930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b940: 2020 2020 2020 2069 6620 2869 7361 626f         if (isabo
-0001b950: 7574 5f6b 6579 203d 3d20 2740 6964 2729  ut_key == '@id')
-0001b960: 206f 7220 2869 7361 626f 7574 5f6b 6579   or (isabout_key
-0001b970: 203d 3d20 2775 726c 2729 3a0a 2020 2020   == 'url'):.    
-0001b980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b990: 2020 2020 2020 2020 6c61 7374 5f69 6420          last_id 
-0001b9a0: 3d20 6973 6162 6f75 745f 7661 6c75 650a  = isabout_value.
-0001b9b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b9c0: 2020 2020 2020 2020 2020 2020 2320 6164              # ad
-0001b9d0: 6420 6973 4162 6f75 7420 6b65 7920 7768  d isAbout key wh
-0001b9e0: 6963 6820 6973 2074 6865 2075 726c 0a20  ich is the url. 
-0001b9f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ba00: 2020 2020 2020 2020 2020 2067 2e61 6464             g.add
-0001ba10: 2828 6364 655f 6964 2c20 436f 6e73 7461  ((cde_id, Consta
-0001ba20: 6e74 732e 4e49 444d 5b27 6973 4162 6f75  nts.NIDM['isAbou
-0001ba30: 7427 5d2c 2055 5249 5265 6628 6973 6162  t'], URIRef(isab
-0001ba40: 6f75 745f 7661 6c75 6529 2929 0a20 2020  out_value))).   
-0001ba50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ba60: 2020 2020 2065 6c69 6620 6973 6162 6f75       elif isabou
-0001ba70: 745f 6b65 7920 3d3d 2027 6c61 6265 6c27  t_key == 'label'
-0001ba80: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001ba90: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-0001baa0: 6e6f 7720 6164 6420 616e 6f74 6865 7220  now add another 
-0001bab0: 656e 7469 7479 2074 6f20 636f 6e74 6169  entity to contai
-0001bac0: 6e20 7468 6520 6c61 6265 6c0a 2020 2020  n the label.    
-0001bad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bae0: 2020 2020 2020 2020 672e 6164 6428 2855          g.add((U
-0001baf0: 5249 5265 6628 6c61 7374 5f69 6429 2c20  RIRef(last_id), 
-0001bb00: 5244 462e 7479 7065 2c43 6f6e 7374 616e  RDF.type,Constan
-0001bb10: 7473 2e50 524f 565b 2745 6e74 6974 7927  ts.PROV['Entity'
-0001bb20: 5d29 290a 2020 2020 2020 2020 2020 2020  ])).            
-0001bb30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bb40: 672e 6164 6428 2855 5249 5265 6628 6c61  g.add((URIRef(la
-0001bb50: 7374 5f69 6429 2c20 436f 6e73 7461 6e74  st_id), Constant
-0001bb60: 732e 5244 4653 5b27 6c61 6265 6c27 5d2c  s.RDFS['label'],
-0001bb70: 204c 6974 6572 616c 2869 7361 626f 7574   Literal(isabout
-0001bb80: 5f76 616c 7565 2929 290a 0a20 2020 2020  _value)))..     
-0001bb90: 2020 2020 2020 2065 6c69 6620 6b65 7920         elif key 
-0001bba0: 3d3d 2027 7661 6c75 6554 7970 6527 3a0a  == 'valueType':.
-0001bbb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bbc0: 672e 6164 6428 2863 6465 5f69 642c 2043  g.add((cde_id, C
-0001bbd0: 6f6e 7374 616e 7473 2e4e 4944 4d5b 2776  onstants.NIDM['v
-0001bbe0: 616c 7565 5479 7065 275d 2c20 5552 4952  alueType'], URIR
-0001bbf0: 6566 2876 616c 7565 2929 290a 2020 2020  ef(value))).    
-0001bc00: 2020 2020 2020 2020 656c 6966 2028 6b65          elif (ke
-0001bc10: 7920 3d3d 2027 6d69 6e56 616c 7565 2729  y == 'minValue')
-0001bc20: 206f 7220 286b 6579 203d 3d20 276d 696e   or (key == 'min
-0001bc30: 696d 756d 5661 6c75 6527 293a 0a20 2020  imumValue'):.   
-0001bc40: 2020 2020 2020 2020 2020 2020 2067 2e61               g.a
-0001bc50: 6464 2828 6364 655f 6964 2c20 436f 6e73  dd((cde_id, Cons
-0001bc60: 7461 6e74 732e 4e49 444d 5b27 6d69 6e56  tants.NIDM['minV
-0001bc70: 616c 7565 275d 2c20 4c69 7465 7261 6c28  alue'], Literal(
-0001bc80: 7661 6c75 6529 2929 0a20 2020 2020 2020  value))).       
-0001bc90: 2020 2020 2065 6c69 6620 286b 6579 203d       elif (key =
-0001bca0: 3d20 276d 6178 5661 6c75 6527 2920 6f72  = 'maxValue') or
-0001bcb0: 2028 6b65 7920 3d3d 2027 6d61 7869 6d75   (key == 'maximu
-0001bcc0: 6d56 616c 7565 2729 3a0a 2020 2020 2020  mValue'):.      
-0001bcd0: 2020 2020 2020 2020 2020 672e 6164 6428            g.add(
-0001bce0: 2863 6465 5f69 642c 2043 6f6e 7374 616e  (cde_id, Constan
-0001bcf0: 7473 2e4e 4944 4d5b 276d 6178 5661 6c75  ts.NIDM['maxValu
-0001bd00: 6527 5d2c 204c 6974 6572 616c 2876 616c  e'], Literal(val
-0001bd10: 7565 2929 290a 2020 2020 2020 2020 2020  ue))).          
-0001bd20: 2020 656c 6966 206b 6579 203d 3d20 2768    elif key == 'h
-0001bd30: 6173 556e 6974 273a 0a20 2020 2020 2020  asUnit':.       
-0001bd40: 2020 2020 2020 2020 2067 2e61 6464 2828           g.add((
-0001bd50: 6364 655f 6964 2c20 436f 6e73 7461 6e74  cde_id, Constant
-0001bd60: 732e 4e49 444d 5b27 756e 6974 436f 6465  s.NIDM['unitCode
-0001bd70: 275d 2c20 4c69 7465 7261 6c28 7661 6c75  '], Literal(valu
-0001bd80: 6529 2929 0a20 2020 2020 2020 2020 2020  e))).           
-0001bd90: 2065 6c69 6620 6b65 7920 3d3d 2027 7361   elif key == 'sa
-0001bda0: 6d65 4173 273a 0a20 2020 2020 2020 2020  meAs':.         
-0001bdb0: 2020 2020 2020 2067 2e61 6464 2828 6364         g.add((cd
-0001bdc0: 655f 6964 2c20 436f 6e73 7461 6e74 732e  e_id, Constants.
-0001bdd0: 4e49 444d 5b27 7361 6d65 4173 275d 2c20  NIDM['sameAs'], 
-0001bde0: 5552 4952 6566 2876 616c 7565 2929 290a  URIRef(value))).
-0001bdf0: 2020 2020 2020 2020 2020 2020 656c 6966              elif
-0001be00: 206b 6579 203d 3d20 2761 7373 6f63 6961   key == 'associa
-0001be10: 7465 6457 6974 6827 3a0a 2020 2020 2020  tedWith':.      
-0001be20: 2020 2020 2020 2020 2020 672e 6164 6428            g.add(
-0001be30: 2863 6465 5f69 642c 2043 6f6e 7374 616e  (cde_id, Constan
-0001be40: 7473 2e49 4e54 4552 4c45 585b 2769 6c78  ts.INTERLEX['ilx
-0001be50: 5f30 3733 3932 3839 275d 2c20 4c69 7465  _0739289'], Lite
-0001be60: 7261 6c28 7661 6c75 6529 2929 0a20 2020  ral(value))).   
-0001be70: 2020 2020 2020 2020 2065 6c69 6620 6b65           elif ke
-0001be80: 7920 3d3d 2027 616c 6c6f 7761 626c 6556  y == 'allowableV
-0001be90: 616c 7565 7327 3a0a 2020 2020 2020 2020  alues':.        
-0001bea0: 2020 2020 2020 2020 672e 6164 6428 2863          g.add((c
-0001beb0: 6465 5f69 642c 2043 6f6e 7374 616e 7473  de_id, Constants
-0001bec0: 2e42 4944 535b 2761 6c6c 6f77 6162 6c65  .BIDS['allowable
-0001bed0: 5661 6c75 6573 275d 2c20 4c69 7465 7261  Values'], Litera
-0001bee0: 6c28 7661 6c75 6529 2929 0a20 2020 2020  l(value))).     
-0001bef0: 2020 2020 2020 2023 2074 6573 7469 6e67         # testing
-0001bf00: 0a20 2020 2020 2020 2020 2020 2023 2067  .            # g
-0001bf10: 2e73 6572 6961 6c69 7a65 2864 6573 7469  .serialize(desti
-0001bf20: 6e61 7469 6f6e 3d22 2f55 7365 7273 2f64  nation="/Users/d
-0001bf30: 626b 6561 746f 722f 446f 776e 6c6f 6164  bkeator/Download
-0001bf40: 732f 6373 7632 6e69 646d 5f63 6465 2e74  s/csv2nidm_cde.t
-0001bf50: 746c 222c 2066 6f72 6d61 743d 2774 7572  tl", format='tur
-0001bf60: 746c 6527 290a 0a0a 0a20 2020 2072 6574  tle')....    ret
-0001bf70: 7572 6e20 670a 0a64 6566 2061 6464 5f61  urn g..def add_a
-0001bf80: 7474 7269 6275 7465 735f 7769 7468 5f63  ttributes_with_c
-0001bf90: 6465 2870 726f 765f 6f62 6a65 6374 2c20  de(prov_object, 
-0001bfa0: 6364 652c 2072 6f77 5f76 6172 6961 626c  cde, row_variabl
-0001bfb0: 652c 2076 616c 7565 293a 0a0a 2020 2020  e, value):..    
-0001bfc0: 2320 6669 6e64 2074 6865 2049 4420 696e  # find the ID in
-0001bfd0: 2063 6465 7320 7768 6572 6520 6e69 646d   cdes where nidm
-0001bfe0: 3a73 6f75 7263 655f 7661 7269 6162 6c65  :source_variable
-0001bff0: 206d 6174 6368 6573 2074 6865 2072 6f77   matches the row
-0001c000: 5f76 6172 6961 626c 650a 2020 2020 2320  _variable.    # 
-0001c010: 7172 6573 203d 2063 6465 2e73 7562 6a65  qres = cde.subje
-0001c020: 6374 7328 7072 6564 6963 6174 653d 436f  cts(predicate=Co
-0001c030: 6e73 7461 6e74 732e 5244 4653 5b27 6c61  nstants.RDFS['la
-0001c040: 6265 6c27 5d2c 6f62 6a65 6374 3d4c 6974  bel'],object=Lit
-0001c050: 6572 616c 2872 6f77 5f76 6172 6961 626c  eral(row_variabl
-0001c060: 6529 290a 2020 2020 7172 6573 203d 2063  e)).    qres = c
-0001c070: 6465 2e73 7562 6a65 6374 7328 7072 6564  de.subjects(pred
-0001c080: 6963 6174 653d 436f 6e73 7461 6e74 732e  icate=Constants.
-0001c090: 4e49 444d 5b27 736f 7572 6365 5661 7269  NIDM['sourceVari
-0001c0a0: 6162 6c65 275d 2c6f 626a 6563 743d 4c69  able'],object=Li
-0001c0b0: 7465 7261 6c28 726f 775f 7661 7269 6162  teral(row_variab
-0001c0c0: 6c65 2929 0a20 2020 2066 6f72 2073 2069  le)).    for s i
-0001c0d0: 6e20 7172 6573 3a0a 2020 2020 2020 2020  n qres:.        
-0001c0e0: 656e 7469 7479 5f69 6420 3d20 730a 2020  entity_id = s.  
-0001c0f0: 2020 2020 2020 2320 6669 6e64 2070 7265        # find pre
-0001c100: 6669 7820 6d61 7463 6869 6e67 206f 7572  fix matching our
-0001c110: 2075 726c 2069 6e20 7264 666c 6962 2067   url in rdflib g
-0001c120: 7261 7068 2e2e 2e74 6869 7320 6973 2062  raph...this is b
-0001c130: 6563 6175 7365 2077 6527 7265 2062 6f75  ecause we're bou
-0001c140: 6e63 696e 6720 6265 7477 6565 6e0a 2020  ncing between.  
-0001c150: 2020 2020 2020 2320 7072 6f76 2061 6e64        # prov and
-0001c160: 2072 6466 6c69 6220 6f62 6a65 6374 730a   rdflib objects.
-0001c170: 2020 2020 2020 2020 666f 7220 7072 6566          for pref
-0001c180: 6978 2c6e 616d 6573 7061 6365 2069 6e20  ix,namespace in 
-0001c190: 6364 652e 6e61 6d65 7370 6163 6573 2829  cde.namespaces()
-0001c1a0: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
-0001c1b0: 206e 616d 6573 7061 6365 203d 3d20 5552   namespace == UR
-0001c1c0: 4952 6566 2865 6e74 6974 795f 6964 2e72  IRef(entity_id.r
-0001c1d0: 7370 6c69 7428 272f 272c 3129 5b30 5d2b  split('/',1)[0]+
-0001c1e0: 222f 2229 3a0a 2020 2020 2020 2020 2020  "/"):.          
-0001c1f0: 2020 2020 2020 6364 655f 7072 6566 6978        cde_prefix
-0001c200: 203d 2070 7265 6669 780a 2020 2020 2020   = prefix.      
-0001c210: 2020 2020 2020 2320 7468 6973 2062 6173        # this bas
-0001c220: 6963 616c 6c79 2073 746f 7265 7320 7468  ically stores th
-0001c230: 6520 726f 775f 6461 7461 2077 6974 6820  e row_data with 
-0001c240: 7468 6520 7072 6564 6963 6174 6520 6265  the predicate be
-0001c250: 696e 6720 7468 6520 6364 6520 6964 2066  ing the cde id f
-0001c260: 726f 6d20 6162 6f76 652e 0a20 2020 2020  rom above..     
-0001c270: 2020 2020 2020 2020 2020 2070 726f 765f             prov_
-0001c280: 6f62 6a65 6374 2e61 6464 5f61 7474 7269  object.add_attri
-0001c290: 6275 7465 7328 7b51 7561 6c69 6669 6564  butes({Qualified
-0001c2a0: 4e61 6d65 2870 726f 764e 616d 6573 7061  Name(provNamespa
-0001c2b0: 6365 2870 7265 6669 783d 6364 655f 7072  ce(prefix=cde_pr
-0001c2c0: 6566 6978 2c20 5c0a 2020 2020 2020 2020  efix, \.        
-0001c2d0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0001c2e0: 7269 3d65 6e74 6974 795f 6964 2e72 7370  ri=entity_id.rsp
-0001c2f0: 6c69 7428 272f 272c 3129 5b30 5d2b 222f  lit('/',1)[0]+"/
-0001c300: 2229 2c65 6e74 6974 795f 6964 2e72 7370  "),entity_id.rsp
-0001c310: 6c69 7428 272f 272c 2031 295b 2d31 5d29  lit('/', 1)[-1])
-0001c320: 3a76 616c 7565 7d29 0a20 2020 2020 2020  :value}).       
-0001c330: 2023 7072 6f76 5f6f 626a 6563 742e 6164   #prov_object.ad
-0001c340: 645f 6174 7472 6962 7574 6573 287b 5175  d_attributes({Qu
-0001c350: 616c 6966 6965 644e 616d 6528 436f 6e73  alifiedName(Cons
-0001c360: 7461 6e74 732e 4e49 4952 492c 656e 7469  tants.NIIRI,enti
-0001c370: 7479 5f69 6429 3a76 616c 7565 7d29 0a20  ty_id):value}). 
-0001c380: 2020 2020 2020 2020 2020 2020 2020 2062                 b
-0001c390: 7265 616b 0a0a 0a0a 6465 6620 6164 6444  reak....def addD
-0001c3a0: 6174 616c 6164 4461 7461 7365 7455 5549  ataladDatasetUUI
-0001c3b0: 4428 7072 6f6a 6563 745f 7575 6964 2c62  D(project_uuid,b
-0001c3c0: 6964 7372 6f6f 745f 6469 7265 6374 6f72  idsroot_director
-0001c3d0: 792c 6772 6170 6829 3a0a 2020 2020 2727  y,graph):.    ''
-0001c3e0: 270a 2020 2020 5468 6973 2066 756e 6374  '.    This funct
-0001c3f0: 696f 6e20 7769 6c6c 2061 6464 2074 6865  ion will add the
-0001c400: 2064 6174 616c 6164 2075 6e69 7175 6520   datalad unique 
-0001c410: 4944 2066 6f72 2074 6869 7320 6461 7461  ID for this data
-0001c420: 7365 7420 746f 2074 6865 2070 726f 6a65  set to the proje
-0001c430: 6374 2065 6e74 6974 7920 7575 6964 2069  ct entity uuid i
-0001c440: 6e20 6772 6170 682e 2054 6869 730a 2020  n graph. This.  
-0001c450: 2020 5555 4944 2077 696c 6c20 756c 7469    UUID will ulti
-0001c460: 6d61 7465 6c79 2062 6520 7573 6564 2062  mately be used b
-0001c470: 7920 6461 7461 6c61 6420 746f 2069 6465  y datalad to ide
-0001c480: 6e74 6966 7920 7468 6520 6461 7461 7365  ntify the datase
-0001c490: 740a 2020 2020 3a70 6172 616d 2070 726f  t.    :param pro
-0001c4a0: 6a65 6374 5f75 7569 643a 2075 6e69 7175  ject_uuid: uniqu
-0001c4b0: 6520 7072 6f6a 6563 7420 6163 7469 7669  e project activi
-0001c4c0: 7479 2049 4420 696e 2067 7261 7068 2074  ty ID in graph t
-0001c4d0: 6f20 6164 6420 7475 706c 650a 2020 2020  o add tuple.    
-0001c4e0: 3a70 6172 616d 2062 6964 7372 6f6f 745f  :param bidsroot_
-0001c4f0: 6469 7265 6374 6f72 793a 2072 6f6f 7420  directory: root 
-0001c500: 6469 7265 6374 6f72 7920 666f 7220 7768  directory for wh
-0001c510: 6963 6820 746f 2063 6f6c 6c65 6374 2064  ich to collect d
-0001c520: 6174 616c 6164 2075 7569 6473 0a20 2020  atalad uuids.   
-0001c530: 203a 7265 7475 726e 3a20 6175 676d 656e   :return: augmen
-0001c540: 7465 6420 6772 6170 6820 7769 7468 2064  ted graph with d
-0001c550: 6174 616c 6164 2075 6e69 7175 6520 4944  atalad unique ID
-0001c560: 730a 2020 2020 2727 270a 0a64 6566 2061  s.    '''..def a
-0001c570: 6464 4769 7441 6e6e 6578 536f 7572 6365  ddGitAnnexSource
-0001c580: 7328 6f62 6a2c 2062 6964 735f 726f 6f74  s(obj, bids_root
-0001c590: 2c20 6669 6c65 7061 7468 203d 204e 6f6e  , filepath = Non
-0001c5a0: 6529 3a0a 2020 2020 2727 270a 2020 2020  e):.    '''.    
-0001c5b0: 5468 6973 2066 756e 6374 696f 6e20 7769  This function wi
-0001c5c0: 6c6c 2061 6464 2067 6974 2d61 6e6e 6578  ll add git-annex
-0001c5d0: 2073 6f75 7263 6573 2061 7320 7475 706c   sources as tupl
-0001c5e0: 6573 2074 6f20 656e 7469 7479 2075 7569  es to entity uui
-0001c5f0: 6420 696e 2067 7261 7068 2e20 5468 6573  d in graph. Thes
-0001c600: 6520 736f 7572 6365 730a 2020 2020 6361  e sources.    ca
-0001c610: 6e20 756c 7469 6d61 7465 6c79 2062 6520  n ultimately be 
-0001c620: 7573 6564 2074 6f20 7265 7472 6965 7665  used to retrieve
-0001c630: 2074 6865 2066 696c 6528 7329 2064 6573   the file(s) des
-0001c640: 6372 6962 6564 2069 6e20 7468 6520 656e  cribed in the en
-0001c650: 7469 7479 2075 7569 6420 7573 696e 6720  tity uuid using 
-0001c660: 6769 742d 616e 6e65 7820 286f 7220 6461  git-annex (or da
-0001c670: 7461 6c61 6429 0a20 2020 203a 7061 7261  talad).    :para
-0001c680: 6d20 6f62 6a3a 2065 6e74 6974 792f 6163  m obj: entity/ac
-0001c690: 7469 7669 7479 206f 626a 6563 7420 746f  tivity object to
-0001c6a0: 2061 6464 2074 7570 6c65 730a 2020 2020   add tuples.    
-0001c6b0: 3a70 6172 616d 2066 696c 6570 6174 683a  :param filepath:
-0001c6c0: 2072 656c 6174 6976 6520 7061 7468 2074   relative path t
-0001c6d0: 6f20 6669 6c65 2028 6f72 2064 6972 6563  o file (or direc
-0001c6e0: 746f 7279 2920 666f 7220 7768 6963 6820  tory) for which 
-0001c6f0: 746f 2061 6464 2073 6f75 7263 6573 2074  to add sources t
-0001c700: 6f20 6772 6170 682e 2020 4966 206e 6f74  o graph.  If not
-0001c710: 2073 6574 2074 6865 6e20 6269 6473 5f72   set then bids_r
-0001c720: 6f6f 740a 2020 2020 6769 7420 616e 6e65  oot.    git anne
-0001c730: 7820 736f 7572 6365 2075 726c 2077 696c  x source url wil
-0001c740: 6c20 6265 2061 6464 6564 2074 6f20 6f62  l be added to ob
-0001c750: 6a20 696e 7374 6561 6420 6f66 2066 696c  j instead of fil
-0001c760: 6570 6174 6820 6769 7420 616e 6e65 7820  epath git annex 
-0001c770: 736f 7572 6365 2075 726c 2e0a 2020 2020  source url..    
-0001c780: 3a70 6172 616d 2062 6964 735f 726f 6f74  :param bids_root
-0001c790: 3a20 726f 6f74 2064 6972 6563 746f 7279  : root directory
-0001c7a0: 206f 6620 4249 4453 2064 6174 6173 6574   of BIDS dataset
-0001c7b0: 0a20 2020 203a 7265 7475 726e 3a20 6e75  .    :return: nu
-0001c7c0: 6d62 6572 206f 6620 736f 7572 6365 7320  mber of sources 
-0001c7d0: 666f 756e 640a 2020 2020 2727 270a 0a20  found.    '''.. 
-0001c7e0: 2020 2023 206c 6f61 6420 6769 7420 616e     # load git an
-0001c7f0: 6e65 7820 696e 666f 726d 6174 696f 6e20  nex information 
-0001c800: 6966 2065 7869 7374 730a 2020 2020 7472  if exists.    tr
-0001c810: 793a 0a20 2020 2020 2020 2072 6570 6f20  y:.        repo 
-0001c820: 3d20 416e 6e65 7852 6570 6f28 6269 6473  = AnnexRepo(bids
-0001c830: 5f72 6f6f 742c 6372 6561 7465 3d46 616c  _root,create=Fal
-0001c840: 7365 290a 2020 2020 2020 2020 6966 2066  se).        if f
-0001c850: 696c 6570 6174 6820 6973 206e 6f74 204e  ilepath is not N
-0001c860: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-0001c870: 2073 6f75 7263 6573 203d 2072 6570 6f2e   sources = repo.
-0001c880: 6765 745f 7572 6c73 2866 696c 6570 6174  get_urls(filepat
-0001c890: 6829 0a20 2020 2020 2020 2065 6c73 653a  h).        else:
-0001c8a0: 0a20 2020 2020 2020 2020 2020 2073 6f75  .            sou
-0001c8b0: 7263 6573 203d 2072 6570 6f2e 6765 745f  rces = repo.get_
-0001c8c0: 7572 6c73 2862 6964 735f 726f 6f74 290a  urls(bids_root).
-0001c8d0: 0a20 2020 2020 2020 2066 6f72 2073 6f75  .        for sou
-0001c8e0: 7263 6520 696e 2073 6f75 7263 6573 3a0a  rce in sources:.
-0001c8f0: 2020 2020 2020 2020 2020 2020 2320 6164              # ad
-0001c900: 6420 746f 2067 7261 7068 2075 7569 640a  d to graph uuid.
-0001c910: 2020 2020 2020 2020 2020 2020 6f62 6a2e              obj.
-0001c920: 6164 645f 6174 7472 6962 7574 6573 287b  add_attributes({
-0001c930: 436f 6e73 7461 6e74 732e 5052 4f56 5b22  Constants.PROV["
-0001c940: 4c6f 6361 7469 6f6e 225d 3a20 5552 4952  Location"]: URIR
-0001c950: 6566 2873 6f75 7263 6529 7d29 0a0a 0a20  ef(source)})... 
-0001c960: 2020 2020 2020 2072 6574 7572 6e20 6c65         return le
-0001c970: 6e28 736f 7572 6365 7329 0a20 2020 2065  n(sources).    e
-0001c980: 7863 6570 7420 4578 6365 7074 696f 6e20  xcept Exception 
-0001c990: 6173 2065 3a0a 2020 2020 2020 2020 2369  as e:.        #i
-0001c9a0: 6620 224e 6f20 616e 6e65 7820 666f 756e  f "No annex foun
-0001c9b0: 6420 6174 2220 6e6f 7420 696e 2073 7472  d at" not in str
-0001c9c0: 2865 293a 0a20 2020 2020 2020 2023 2020  (e):.        #  
-0001c9d0: 2020 7072 696e 7428 2257 6172 6e69 6e67    print("Warning
-0001c9e0: 2c20 6572 726f 7220 7769 7468 2041 6e6e  , error with Ann
-0001c9f0: 6578 5265 706f 2028 5574 696c 732e 7079  exRepo (Utils.py
-0001ca00: 2c20 6164 6447 6974 416e 6e65 7853 6f75  , addGitAnnexSou
-0001ca10: 7263 6573 293a 2025 7322 2025 7374 7228  rces): %s" %str(
-0001ca20: 6529 290a 2020 2020 2020 2020 7265 7475  e)).        retu
-0001ca30: 726e 2030 0a0a 0a64 6566 2074 7570 6c65  rn 0...def tuple
-0001ca40: 4b65 7973 546f 5369 6d70 6c65 4b65 7973  KeysToSimpleKeys
-0001ca50: 2864 6963 7429 3a0a 2020 2020 2727 270a  (dict):.    '''.
-0001ca60: 2020 2020 5468 6973 2066 756e 6374 696f      This functio
-0001ca70: 6e20 7769 6c6c 2063 6861 6e67 6520 7468  n will change th
-0001ca80: 6520 6b65 7973 2069 6e20 7468 6520 7375  e keys in the su
-0001ca90: 7070 6c69 6564 2064 6963 7469 6f6e 6172  pplied dictionar
-0001caa0: 7920 6672 6f6d 2074 7570 6c65 206b 6579  y from tuple key
-0001cab0: 7320 2865 2e67 2e20 6672 6f6d 202e 2e63  s (e.g. from ..c
-0001cac0: 6f72 652e 436f 6e73 7461 6e74 7320 696d  ore.Constants im
-0001cad0: 706f 7274 2044 4429 0a20 2020 2074 6f20  port DD).    to 
-0001cae0: 7369 6d70 6c65 206b 6579 7320 7768 6572  simple keys wher
-0001caf0: 6520 6b65 7920 6973 2076 6172 6961 626c  e key is variabl
-0001cb00: 6520 6e61 6d65 0a20 2020 203a 7061 7261  e name.    :para
-0001cb10: 6d20 6469 6374 3a20 6469 6374 696f 6e61  m dict: dictiona
-0001cb20: 7279 2063 7265 6174 6564 2066 726f 6d20  ry created from 
-0001cb30: 6d61 705f 7661 7269 6162 6c65 735f 746f  map_variables_to
-0001cb40: 5f74 6572 6d73 0a20 2020 203a 7265 7475  _terms.    :retu
-0001cb50: 726e 3a20 6e65 7720 6469 6374 696f 6e61  rn: new dictiona
-0001cb60: 7279 2077 6974 6820 7369 6d70 6c65 206b  ry with simple k
-0001cb70: 6579 730a 2020 2020 2727 270a 0a20 2020  eys.    '''..   
-0001cb80: 206e 6577 5f64 6963 743d 7b7d 0a0a 2020   new_dict={}..  
-0001cb90: 2020 666f 7220 6b65 7920 696e 2064 6963    for key in dic
-0001cba0: 743a 0a20 2020 2020 2020 206b 6579 5f74  t:.        key_t
-0001cbb0: 7570 6c65 203d 2065 7661 6c28 6b65 7929  uple = eval(key)
-0001cbc0: 0a20 2020 2020 2020 2066 6f72 2073 7562  .        for sub
-0001cbd0: 6b65 792c 2069 7465 6d20 696e 206b 6579  key, item in key
-0001cbe0: 5f74 7570 6c65 2e5f 6173 6469 6374 2829  _tuple._asdict()
-0001cbf0: 2e69 7465 6d73 2829 3a0a 2020 2020 2020  .items():.      
-0001cc00: 2020 2020 2020 6966 2073 7562 6b65 7920        if subkey 
-0001cc10: 3d3d 2027 7661 7269 6162 6c65 273a 0a20  == 'variable':. 
-0001cc20: 2020 2020 2020 2020 2020 2020 2020 206e                 n
-0001cc30: 6577 5f64 6963 745b 6974 656d 5d3d 7b7d  ew_dict[item]={}
-0001cc40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001cc50: 2066 6f72 2076 6172 6b65 7973 2c20 7661   for varkeys, va
-0001cc60: 7276 616c 7565 7320 696e 2064 6963 745b  rvalues in dict[
-0001cc70: 7374 7228 6b65 795f 7475 706c 6529 5d2e  str(key_tuple)].
-0001cc80: 6974 656d 7328 293a 0a20 2020 2020 2020  items():.       
-0001cc90: 2020 2020 2020 2020 2020 2020 206e 6577               new
-0001cca0: 5f64 6963 745b 6974 656d 5d5b 7661 726b  _dict[item][vark
-0001ccb0: 6579 735d 203d 2076 6172 7661 6c75 6573  eys] = varvalues
-0001ccc0: 0a0a 0a20 2020 2072 6574 7572 6e20 6e65  ...    return ne
-0001ccd0: 775f 6469 6374 0a0a 0a0a 6465 6620 7661  w_dict....def va
-0001cce0: 6c69 6461 7465 5f75 7569 6428 7575 6964  lidate_uuid(uuid
-0001ccf0: 5f73 7472 696e 6729 3a0a 0a20 2020 2022  _string):..    "
-0001cd00: 2222 0a20 2020 2056 616c 6964 6174 6520  "".    Validate 
-0001cd10: 7468 6174 2061 2055 5549 4420 7374 7269  that a UUID stri
-0001cd20: 6e67 2069 7320 696e 0a20 2020 2066 6163  ng is in.    fac
-0001cd30: 7420 6120 7661 6c69 6420 7575 6964 342e  t a valid uuid4.
-0001cd40: 0a20 2020 2048 6170 7069 6c79 2c20 7468  .    Happily, th
-0001cd50: 6520 7575 6964 206d 6f64 756c 6520 646f  e uuid module do
-0001cd60: 6573 2074 6865 2061 6374 7561 6c0a 2020  es the actual.  
-0001cd70: 2020 6368 6563 6b69 6e67 2066 6f72 2075    checking for u
-0001cd80: 732e 0a20 2020 2049 7420 6973 2076 6974  s..    It is vit
-0001cd90: 616c 2074 6861 7420 7468 6520 2776 6572  al that the 'ver
-0001cda0: 7369 6f6e 2720 6b77 6172 6720 6265 2070  sion' kwarg be p
-0001cdb0: 6173 7365 640a 2020 2020 746f 2074 6865  assed.    to the
-0001cdc0: 2055 5549 4428 2920 6361 6c6c 2c20 6f74   UUID() call, ot
-0001cdd0: 6865 7277 6973 6520 616e 7920 3332 2d63  herwise any 32-c
-0001cde0: 6861 7261 6374 6572 0a20 2020 2068 6578  haracter.    hex
-0001cdf0: 2073 7472 696e 6720 6973 2063 6f6e 7369   string is consi
-0001ce00: 6465 7265 6420 7661 6c69 642e 0a20 2020  dered valid..   
-0001ce10: 2022 2222 0a0a 2020 2020 7472 793a 0a20   """..    try:. 
-0001ce20: 2020 2020 2020 2076 616c 203d 2055 5549         val = UUI
-0001ce30: 4428 7575 6964 5f73 7472 696e 6729 0a20  D(uuid_string). 
-0001ce40: 2020 2065 7863 6570 7420 5661 6c75 6545     except ValueE
-0001ce50: 7272 6f72 3a0a 2020 2020 2020 2020 2320  rror:.        # 
-0001ce60: 4966 2069 7427 7320 6120 7661 6c75 6520  If it's a value 
-0001ce70: 6572 726f 722c 2074 6865 6e20 7468 6520  error, then the 
-0001ce80: 7374 7269 6e67 0a20 2020 2020 2020 2023  string.        #
-0001ce90: 2069 7320 6e6f 7420 6120 7661 6c69 6420   is not a valid 
-0001cea0: 6865 7820 636f 6465 2066 6f72 2061 2055  hex code for a U
-0001ceb0: 5549 442e 0a20 2020 2020 2020 2072 6574  UID..        ret
-0001cec0: 7572 6e20 4661 6c73 650a 0a20 2020 2072  urn False..    r
-0001ced0: 6574 7572 6e20 5472 7565 0a              eturn True.
+00016380: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+00016390: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+000163a0: 2020 2020 2020 2020 2020 2020 696c 785f              ilx_
+000163b0: 6f75 7470 7574 203d 2041 6464 5044 4554  output = AddPDET
+000163c0: 6f49 6e74 6572 6c65 7828 0a20 2020 2020  oInterlex(.     
+000163d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000163e0: 2020 2069 6c78 5f6f 626a 3d69 6c78 5f6f     ilx_obj=ilx_o
+000163f0: 626a 2c0a 2020 2020 2020 2020 2020 2020  bj,.            
+00016400: 2020 2020 2020 2020 2020 2020 6c61 6265              labe
+00016410: 6c3d 636f 6c75 6d6e 5f74 6f5f 7465 726d  l=column_to_term
+00016420: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+00016430: 5b22 6c61 6265 6c22 5d2c 0a20 2020 2020  ["label"],.     
+00016440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016450: 2020 2064 6566 696e 6974 696f 6e3d 636f     definition=co
+00016460: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
+00016470: 7272 656e 745f 7475 706c 655d 5b22 6465  rrent_tuple]["de
+00016480: 7363 7269 7074 696f 6e22 5d2c 0a20 2020  scription"],.   
+00016490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000164a0: 2020 2020 206d 696e 3d63 6f6c 756d 6e5f       min=column_
+000164b0: 746f 5f74 6572 6d73 5b63 7572 7265 6e74  to_terms[current
+000164c0: 5f74 7570 6c65 5d5b 226d 696e 5661 6c75  _tuple]["minValu
+000164d0: 6522 5d2c 0a20 2020 2020 2020 2020 2020  e"],.           
+000164e0: 2020 2020 2020 2020 2020 2020 206d 6178               max
+000164f0: 3d63 6f6c 756d 6e5f 746f 5f74 6572 6d73  =column_to_terms
+00016500: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+00016510: 226d 6178 5661 6c75 6522 5d2c 0a20 2020  "maxValue"],.   
+00016520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016530: 2020 2020 2075 6e69 7473 3d63 6f6c 756d       units=colum
+00016540: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
+00016550: 6e74 5f74 7570 6c65 5d5b 2268 6173 556e  nt_tuple]["hasUn
+00016560: 6974 225d 2c0a 2020 2020 2020 2020 2020  it"],.          
+00016570: 2020 2020 2020 2020 2020 2020 2020 6461                da
+00016580: 7461 7479 7065 3d63 6f6c 756d 6e5f 746f  tatype=column_to
+00016590: 5f74 6572 6d73 5b63 7572 7265 6e74 5f74  _terms[current_t
+000165a0: 7570 6c65 5d5b 2276 616c 7565 5479 7065  uple]["valueType
+000165b0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+000165c0: 2020 2020 2020 2020 2020 2020 6361 7465              cate
+000165d0: 676f 7279 6d61 7070 696e 6773 3d6a 736f  gorymappings=jso
+000165e0: 6e2e 6475 6d70 7328 0a20 2020 2020 2020  n.dumps(.       
+000165f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016600: 2020 2020 2063 6f6c 756d 6e5f 746f 5f74       column_to_t
+00016610: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
+00016620: 6c65 5d5b 226c 6576 656c 7322 5d0a 2020  le]["levels"].  
+00016630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016640: 2020 2020 2020 292c 0a20 2020 2020 2020        ),.       
+00016650: 2020 2020 2020 2020 2020 2020 2029 0a0a               )..
+00016660: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00016670: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00016680: 2020 6966 2022 6973 4162 6f75 7422 2069    if "isAbout" i
+00016690: 6e20 636f 6c75 6d6e 5f74 6f5f 7465 726d  n column_to_term
+000166a0: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+000166b0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000166c0: 2020 2020 2020 696c 785f 6f75 7470 7574        ilx_output
+000166d0: 203d 2041 6464 5044 4554 6f49 6e74 6572   = AddPDEToInter
+000166e0: 6c65 7828 0a20 2020 2020 2020 2020 2020  lex(.           
+000166f0: 2020 2020 2020 2020 2020 2020 2069 6c78               ilx
+00016700: 5f6f 626a 3d69 6c78 5f6f 626a 2c0a 2020  _obj=ilx_obj,.  
+00016710: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016720: 2020 2020 2020 6c61 6265 6c3d 636f 6c75        label=colu
+00016730: 6d6e 5f74 6f5f 7465 726d 735b 6375 7272  mn_to_terms[curr
+00016740: 656e 745f 7475 706c 655d 5b22 6c61 6265  ent_tuple]["labe
+00016750: 6c22 5d2c 0a20 2020 2020 2020 2020 2020  l"],.           
+00016760: 2020 2020 2020 2020 2020 2020 2064 6566               def
+00016770: 696e 6974 696f 6e3d 636f 6c75 6d6e 5f74  inition=column_t
+00016780: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
+00016790: 7475 706c 655d 5b22 6465 7363 7269 7074  tuple]["descript
+000167a0: 696f 6e22 5d2c 0a20 2020 2020 2020 2020  ion"],.         
+000167b0: 2020 2020 2020 2020 2020 2020 2020 206d                 m
+000167c0: 696e 3d63 6f6c 756d 6e5f 746f 5f74 6572  in=column_to_ter
+000167d0: 6d73 5b63 7572 7265 6e74 5f74 7570 6c65  ms[current_tuple
+000167e0: 5d5b 226d 696e 5661 6c75 6522 5d2c 0a20  ]["minValue"],. 
+000167f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016800: 2020 2020 2020 206d 6178 3d63 6f6c 756d         max=colum
+00016810: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
+00016820: 6e74 5f74 7570 6c65 5d5b 226d 6178 5661  nt_tuple]["maxVa
+00016830: 6c75 6522 5d2c 0a20 2020 2020 2020 2020  lue"],.         
+00016840: 2020 2020 2020 2020 2020 2020 2020 2075                 u
+00016850: 6e69 7473 3d63 6f6c 756d 6e5f 746f 5f74  nits=column_to_t
+00016860: 6572 6d73 5b63 7572 7265 6e74 5f74 7570  erms[current_tup
+00016870: 6c65 5d5b 2268 6173 556e 6974 225d 2c0a  le]["hasUnit"],.
+00016880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016890: 2020 2020 2020 2020 6461 7461 7479 7065          datatype
+000168a0: 3d63 6f6c 756d 6e5f 746f 5f74 6572 6d73  =column_to_terms
+000168b0: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+000168c0: 2276 616c 7565 5479 7065 225d 2c0a 2020  "valueType"],.  
+000168d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000168e0: 2020 2020 2020 6973 6162 6f75 743d 636f        isabout=co
+000168f0: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
+00016900: 7272 656e 745f 7475 706c 655d 5b22 6973  rrent_tuple]["is
+00016910: 4162 6f75 7422 5d2c 0a20 2020 2020 2020  About"],.       
+00016920: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+00016930: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+00016940: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00016950: 2020 2020 2020 2020 2069 6c78 5f6f 7574           ilx_out
+00016960: 7075 7420 3d20 4164 6450 4445 546f 496e  put = AddPDEToIn
+00016970: 7465 726c 6578 280a 2020 2020 2020 2020  terlex(.        
+00016980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016990: 696c 785f 6f62 6a3d 696c 785f 6f62 6a2c  ilx_obj=ilx_obj,
+000169a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000169b0: 2020 2020 2020 2020 206c 6162 656c 3d63           label=c
+000169c0: 6f6c 756d 6e5f 746f 5f74 6572 6d73 5b63  olumn_to_terms[c
+000169d0: 7572 7265 6e74 5f74 7570 6c65 5d5b 226c  urrent_tuple]["l
+000169e0: 6162 656c 225d 2c0a 2020 2020 2020 2020  abel"],.        
+000169f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016a00: 6465 6669 6e69 7469 6f6e 3d63 6f6c 756d  definition=colum
+00016a10: 6e5f 746f 5f74 6572 6d73 5b63 7572 7265  n_to_terms[curre
+00016a20: 6e74 5f74 7570 6c65 5d5b 2264 6573 6372  nt_tuple]["descr
+00016a30: 6970 7469 6f6e 225d 2c0a 2020 2020 2020  iption"],.      
+00016a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016a50: 2020 6d69 6e3d 636f 6c75 6d6e 5f74 6f5f    min=column_to_
+00016a60: 7465 726d 735b 6375 7272 656e 745f 7475  terms[current_tu
+00016a70: 706c 655d 5b22 6d69 6e56 616c 7565 225d  ple]["minValue"]
+00016a80: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00016a90: 2020 2020 2020 2020 2020 6d61 783d 636f            max=co
+00016aa0: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
+00016ab0: 7272 656e 745f 7475 706c 655d 5b22 6d61  rrent_tuple]["ma
+00016ac0: 7856 616c 7565 225d 2c0a 2020 2020 2020  xValue"],.      
+00016ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016ae0: 2020 756e 6974 733d 636f 6c75 6d6e 5f74    units=column_t
+00016af0: 6f5f 7465 726d 735b 6375 7272 656e 745f  o_terms[current_
+00016b00: 7475 706c 655d 5b22 6861 7355 6e69 7422  tuple]["hasUnit"
+00016b10: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00016b20: 2020 2020 2020 2020 2020 2064 6174 6174             datat
+00016b30: 7970 653d 636f 6c75 6d6e 5f74 6f5f 7465  ype=column_to_te
+00016b40: 726d 735b 6375 7272 656e 745f 7475 706c  rms[current_tupl
+00016b50: 655d 5b22 7661 6c75 6554 7970 6522 5d2c  e]["valueType"],
+00016b60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00016b70: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
+00016b80: 2020 2020 2320 6e6f 7720 7374 6f72 6520      # now store 
+00016b90: 7468 6520 7572 6c20 6672 6f6d 2049 6e74  the url from Int
+00016ba0: 6572 6c65 7820 666f 7220 6e65 7720 7065  erlex for new pe
+00016bb0: 7273 6f6e 616c 2064 6174 6120 656c 656d  rsonal data elem
+00016bc0: 656e 7420 696e 2063 6f6c 756d 6e5f 746f  ent in column_to
+00016bd0: 5f74 6572 6d73 2061 6e6e 6f74 6174 696f  _terms annotatio
+00016be0: 6e0a 2020 2020 2020 2020 2020 2020 636f  n.            co
+00016bf0: 6c75 6d6e 5f74 6f5f 7465 726d 735b 6375  lumn_to_terms[cu
+00016c00: 7272 656e 745f 7475 706c 655d 5b22 7572  rrent_tuple]["ur
+00016c10: 6c22 5d20 3d20 696c 785f 6f75 7470 7574  l"] = ilx_output
+00016c20: 2e69 7269 0a20 2020 2020 2020 2065 7863  .iri.        exc
+00016c30: 6570 7420 4578 6365 7074 696f 6e3a 0a20  ept Exception:. 
+00016c40: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+00016c50: 2822 5741 524e 494e 473a 2057 4950 3a20  ("WARNING: WIP: 
+00016c60: 4461 7461 2065 6c65 6d65 6e74 206e 6f74  Data element not
+00016c70: 2073 7562 6d69 7474 6564 2074 6f20 496e   submitted to In
+00016c80: 7465 724c 6578 2e20 2022 290a 2020 2020  terLex.  ").    
+00016c90: 2320 7772 6974 6520 616e 6e6f 7461 7469  # write annotati
+00016ca0: 6f6e 7320 746f 206a 736f 6e20 6669 6c65  ons to json file
+00016cb0: 2073 696e 6365 2064 6174 6120 656c 656d   since data elem
+00016cc0: 656e 7420 616e 6e6f 7461 7469 6f6e 7320  ent annotations 
+00016cd0: 6172 6520 636f 6d70 6c65 7465 0a20 2020  are complete.   
+00016ce0: 2077 7269 7465 5f6a 736f 6e5f 6d61 7070   write_json_mapp
+00016cf0: 696e 675f 6669 6c65 2863 6f6c 756d 6e5f  ing_file(column_
+00016d00: 746f 5f74 6572 6d73 2c20 6f75 7470 7574  to_terms, output
+00016d10: 5f66 696c 652c 2062 6964 7329 0a0a 2020  _file, bids)..  
+00016d20: 2020 2320 6765 7420 4344 4573 2066 6f72    # get CDEs for
+00016d30: 2064 6174 6120 6469 6374 696f 6e61 7279   data dictionary
+00016d40: 2061 6e64 204e 4944 4d20 6772 6170 6820   and NIDM graph 
+00016d50: 656e 7469 7479 206f 6620 6461 7461 0a20  entity of data. 
+00016d60: 2020 2063 6465 203d 2044 445f 746f 5f6e     cde = DD_to_n
+00016d70: 6964 6d28 636f 6c75 6d6e 5f74 6f5f 7465  idm(column_to_te
+00016d80: 726d 732c 2064 6174 6173 6574 5f69 6465  rms, dataset_ide
+00016d90: 6e74 6966 6965 723d 6461 7461 7365 745f  ntifier=dataset_
+00016da0: 6964 656e 7469 6669 6572 290a 0a20 2020  identifier)..   
+00016db0: 2072 6574 7572 6e20 5b63 6f6c 756d 6e5f   return [column_
+00016dc0: 746f 5f74 6572 6d73 2c20 6364 655d 0a0a  to_terms, cde]..
+00016dd0: 0a64 6566 2077 7269 7465 5f6a 736f 6e5f  .def write_json_
+00016de0: 6d61 7070 696e 675f 6669 6c65 2873 6f75  mapping_file(sou
+00016df0: 7263 655f 7661 7269 6162 6c65 5f61 6e6e  rce_variable_ann
+00016e00: 6f74 6174 696f 6e73 2c20 6f75 7470 7574  otations, output
+00016e10: 5f66 696c 652c 2062 6964 733d 4661 6c73  _file, bids=Fals
+00016e20: 6529 3a0a 2020 2020 2320 6966 2077 6520  e):.    # if we 
+00016e30: 7761 6e74 2061 2062 6964 732d 7374 796c  want a bids-styl
+00016e40: 6520 6a73 6f6e 2073 6964 6563 6172 2066  e json sidecar f
+00016e50: 696c 650a 2020 2020 6966 2062 6964 733a  ile.    if bids:
+00016e60: 0a20 2020 2020 2020 2023 2063 6f6e 7665  .        # conve
+00016e70: 7274 2074 6f20 7369 6d70 6c65 206b 6579  rt to simple key
+00016e80: 730a 2020 2020 2020 2020 7465 6d70 5f64  s.        temp_d
+00016e90: 6963 7420 3d20 7475 706c 654b 6579 7354  ict = tupleKeysT
+00016ea0: 6f53 696d 706c 654b 6579 7328 736f 7572  oSimpleKeys(sour
+00016eb0: 6365 5f76 6172 6961 626c 655f 616e 6e6f  ce_variable_anno
+00016ec0: 7461 7469 6f6e 7329 0a0a 2020 2020 2020  tations)..      
+00016ed0: 2020 6e65 775f 6469 6374 203d 207b 7d0a    new_dict = {}.
+00016ee0: 2020 2020 2020 2020 2320 7265 6d6f 7665          # remove
+00016ef0: 2027 7265 7370 6f6e 7365 4f70 7469 6f6e   'responseOption
+00016f00: 7327 2061 6e64 206d 6f76 6520 2763 686f  s' and move 'cho
+00016f10: 6963 6573 2720 746f 2027 6c65 7665 6c73  ices' to 'levels
+00016f20: 2720 6b65 790a 2020 2020 2020 2020 666f  ' key.        fo
+00016f30: 7220 6b65 792c 2076 616c 7565 2069 6e20  r key, value in 
+00016f40: 7465 6d70 5f64 6963 742e 6974 656d 7328  temp_dict.items(
+00016f50: 293a 0a20 2020 2020 2020 2020 2020 206e  ):.            n
+00016f60: 6577 5f64 6963 745b 6b65 795d 203d 207b  ew_dict[key] = {
+00016f70: 7d0a 2020 2020 2020 2020 2020 2020 666f  }.            fo
+00016f80: 7220 7375 626b 6579 2c20 7375 6276 616c  r subkey, subval
+00016f90: 7565 2069 6e20 7661 6c75 652e 6974 656d  ue in value.item
+00016fa0: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
+00016fb0: 2020 2020 2069 6620 7375 626b 6579 203d       if subkey =
+00016fc0: 3d20 2272 6573 706f 6e73 654f 7074 696f  = "responseOptio
+00016fd0: 6e73 223a 0a20 2020 2020 2020 2020 2020  ns":.           
+00016fe0: 2020 2020 2020 2020 2066 6f72 2073 7562           for sub
+00016ff0: 6b65 7932 2c20 7375 6276 616c 7565 3220  key2, subvalue2 
+00017000: 696e 2076 616c 7565 5b22 7265 7370 6f6e  in value["respon
+00017010: 7365 4f70 7469 6f6e 7322 5d2e 6974 656d  seOptions"].item
+00017020: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
+00017030: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00017040: 7375 626b 6579 3220 3d3d 2022 6368 6f69  subkey2 == "choi
+00017050: 6365 7322 3a0a 2020 2020 2020 2020 2020  ces":.          
+00017060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017070: 2020 6e65 775f 6469 6374 5b6b 6579 5d5b    new_dict[key][
+00017080: 226c 6576 656c 7322 5d20 3d20 7375 6276  "levels"] = subv
+00017090: 616c 7565 320a 2020 2020 2020 2020 2020  alue2.          
+000170a0: 2020 2020 2020 2020 2020 2020 2020 656c                el
+000170b0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+000170c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000170d0: 6e65 775f 6469 6374 5b6b 6579 5d5b 7375  new_dict[key][su
+000170e0: 626b 6579 325d 203d 2073 7562 7661 6c75  bkey2] = subvalu
+000170f0: 6532 0a20 2020 2020 2020 2020 2020 2020  e2.             
+00017100: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00017110: 2020 2020 2020 2020 2020 2020 206e 6577               new
+00017120: 5f64 6963 745b 6b65 795d 5b73 7562 6b65  _dict[key][subke
+00017130: 795d 203d 2073 7562 7661 6c75 650a 0a20  y] = subvalue.. 
+00017140: 2020 2020 2020 2023 2077 7269 7465 0a20         # write. 
+00017150: 2020 2020 2020 2077 6974 6820 6f70 656e         with open
+00017160: 280a 2020 2020 2020 2020 2020 2020 6f73  (.            os
+00017170: 2e70 6174 682e 6a6f 696e 280a 2020 2020  .path.join(.    
+00017180: 2020 2020 2020 2020 2020 2020 6f73 2e70              os.p
+00017190: 6174 682e 6469 726e 616d 6528 6f75 7470  ath.dirname(outp
+000171a0: 7574 5f66 696c 6529 2c20 6f73 2e70 6174  ut_file), os.pat
+000171b0: 682e 7370 6c69 7465 7874 286f 7574 7075  h.splitext(outpu
+000171c0: 745f 6669 6c65 295b 305d 202b 2022 2e6a  t_file)[0] + ".j
+000171d0: 736f 6e22 0a20 2020 2020 2020 2020 2020  son".           
+000171e0: 2029 2c0a 2020 2020 2020 2020 2020 2020   ),.            
+000171f0: 2277 2b22 2c0a 2020 2020 2020 2020 2020  "w+",.          
+00017200: 2020 656e 636f 6469 6e67 3d22 7574 662d    encoding="utf-
+00017210: 3822 2c0a 2020 2020 2020 2020 2920 6173  8",.        ) as
+00017220: 2066 703a 0a20 2020 2020 2020 2020 2020   fp:.           
+00017230: 206a 736f 6e2e 6475 6d70 286e 6577 5f64   json.dump(new_d
+00017240: 6963 742c 2066 702c 2069 6e64 656e 743d  ict, fp, indent=
+00017250: 3429 0a20 2020 2065 6c73 653a 0a20 2020  4).    else:.   
+00017260: 2020 2020 2023 206c 6f67 6769 6e67 2e69       # logging.i
+00017270: 6e66 6f28 2273 6176 696e 6720 6a73 6f6e  nfo("saving json
+00017280: 206d 6170 7069 6e67 2066 696c 653a 2025   mapping file: %
+00017290: 7322 2c20 6f73 2e70 6174 682e 6a6f 696e  s", os.path.join
+000172a0: 286f 732e 7061 7468 2e62 6173 656e 616d  (os.path.basenam
+000172b0: 6528 6f75 7470 7574 5f66 696c 6529 2c20  e(output_file), 
+000172c0: 5c0a 2020 2020 2020 2020 2320 2020 2020  \.        #     
+000172d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000172e0: 2020 2020 2020 206f 732e 7061 7468 2e73         os.path.s
+000172f0: 706c 6974 6578 7428 6f75 7470 7574 5f66  plitext(output_f
+00017300: 696c 6529 5b30 5d2b 222e 6a73 6f6e 2229  ile)[0]+".json")
+00017310: 290a 2020 2020 2020 2020 7769 7468 206f  ).        with o
+00017320: 7065 6e28 0a20 2020 2020 2020 2020 2020  pen(.           
+00017330: 206f 732e 7061 7468 2e6a 6f69 6e28 0a20   os.path.join(. 
+00017340: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00017350: 732e 7061 7468 2e64 6972 6e61 6d65 286f  s.path.dirname(o
+00017360: 7574 7075 745f 6669 6c65 292c 0a20 2020  utput_file),.   
+00017370: 2020 2020 2020 2020 2020 2020 206f 732e               os.
+00017380: 7061 7468 2e73 706c 6974 6578 7428 6f75  path.splitext(ou
+00017390: 7470 7574 5f66 696c 6529 5b30 5d20 2b20  tput_file)[0] + 
+000173a0: 225f 616e 6e6f 7461 7469 6f6e 732e 6a73  "_annotations.js
+000173b0: 6f6e 222c 0a20 2020 2020 2020 2020 2020  on",.           
+000173c0: 2029 2c0a 2020 2020 2020 2020 2020 2020   ),.            
+000173d0: 2277 2b22 2c0a 2020 2020 2020 2020 2020  "w+",.          
+000173e0: 2020 656e 636f 6469 6e67 3d22 7574 662d    encoding="utf-
+000173f0: 3822 2c0a 2020 2020 2020 2020 2920 6173  8",.        ) as
+00017400: 2066 703a 0a20 2020 2020 2020 2020 2020   fp:.           
+00017410: 206a 736f 6e2e 6475 6d70 2873 6f75 7263   json.dump(sourc
+00017420: 655f 7661 7269 6162 6c65 5f61 6e6e 6f74  e_variable_annot
+00017430: 6174 696f 6e73 2c20 6670 2c20 696e 6465  ations, fp, inde
+00017440: 6e74 3d34 290a 0a0a 6465 6620 6669 6e64  nt=4)...def find
+00017450: 5f63 6f6e 6365 7074 5f69 6e74 6572 6163  _concept_interac
+00017460: 7469 7665 280a 2020 2020 736f 7572 6365  tive(.    source
+00017470: 5f76 6172 6961 626c 652c 0a20 2020 2063  _variable,.    c
+00017480: 7572 7265 6e74 5f74 7570 6c65 2c0a 2020  urrent_tuple,.  
+00017490: 2020 736f 7572 6365 5f76 6172 6961 626c    source_variabl
+000174a0: 655f 616e 6e6f 7461 7469 6f6e 732c 0a20  e_annotations,. 
+000174b0: 2020 2069 6c78 5f6f 626a 2c0a 2020 2020     ilx_obj,.    
+000174c0: 616e 6365 7374 6f72 3d54 7275 652c 0a20  ancestor=True,. 
+000174d0: 2020 206e 6964 6d5f 6f77 6c5f 6772 6170     nidm_owl_grap
+000174e0: 683d 4e6f 6e65 2c0a 293a 0a20 2020 2022  h=None,.):.    "
+000174f0: 2222 0a20 2020 2054 6869 7320 6675 6e63  "".    This func
+00017500: 7469 6f6e 2077 696c 6c20 616c 6c6f 7720  tion will allow 
+00017510: 7573 6572 2074 6f20 696e 7465 7261 6374  user to interact
+00017520: 6976 656c 7920 6669 6e64 2061 2063 6f6e  ively find a con
+00017530: 6365 7074 2069 6e20 7468 6520 496e 7465  cept in the Inte
+00017540: 724c 6578 2c20 436f 6741 746c 6173 2c20  rLex, CogAtlas, 
+00017550: 616e 6420 4e49 444d 2074 6f20 6173 736f  and NIDM to asso
+00017560: 6369 6174 6520 7769 7468 2074 6865 0a20  ciate with the. 
+00017570: 2020 2073 6f75 7263 6520 7661 7269 6162     source variab
+00017580: 6c65 2066 726f 6d20 7468 6520 6173 7365  le from the asse
+00017590: 7373 6d65 6e74 2065 6e63 6f64 6564 2069  ssment encoded i
+000175a0: 6e20 7468 6520 6375 7272 656e 745f 7475  n the current_tu
+000175b0: 706c 650a 0a20 2020 2053 7461 7274 7320  ple..    Starts 
+000175c0: 6279 2075 7369 6e67 204e 4944 4d2d 5465  by using NIDM-Te
+000175d0: 726d 7320 636f 6e63 6570 7473 2077 6869  rms concepts whi
+000175e0: 6368 2061 7265 206f 6e65 7320 7468 6174  ch are ones that
+000175f0: 2068 6176 6520 7072 6576 696f 7573 6c79   have previously
+00017600: 2062 6565 6e20 7573 6564 2074 6f20 616e   been used to an
+00017610: 6e6f 7461 7465 2064 6174 6173 6574 732e  notate datasets.
+00017620: 2020 4279 0a20 2020 2073 7461 7274 696e    By.    startin
+00017630: 6720 7769 7468 2074 6865 7365 2077 6520  g with these we 
+00017640: 6d61 7869 6d69 7a65 2063 6861 6e63 6573  maximize chances
+00017650: 206f 6620 6265 696e 6720 6162 6c65 2074   of being able t
+00017660: 6f20 7175 6572 7920 6163 726f 7373 2064  o query across d
+00017670: 6174 6173 6574 7320 7573 696e 6720 636f  atasets using co
+00017680: 6e63 6570 742d 6472 6976 696e 2071 7565  ncept-drivin que
+00017690: 7269 6573 2e0a 0a20 2020 2022 2222 0a0a  ries...    """..
+000176a0: 2020 2020 2320 4265 666f 7265 2077 6520      # Before we 
+000176b0: 7275 6e20 616e 7974 6869 6e67 2068 6572  run anything her
+000176c0: 6520 6966 2062 6f74 6820 496e 7465 724c  e if both InterL
+000176d0: 6578 2061 6e64 204e 4944 4d20 4f57 4c20  ex and NIDM OWL 
+000176e0: 6669 6c65 2061 6363 6573 7320 6973 2064  file access is d
+000176f0: 6f77 6e20 7765 2073 686f 756c 6420 6a75  own we should ju
+00017700: 7374 2061 6c65 7274 0a20 2020 2023 2074  st alert.    # t
+00017710: 6865 2075 7365 7220 616e 6420 7265 7475  he user and retu
+00017720: 726e 2063 6175 7365 2077 6527 7265 206e  rn cause we're n
+00017730: 6f74 2067 6f69 6e67 2074 6f20 6265 2061  ot going to be a
+00017740: 626c 6520 746f 2064 6f20 7265 616c 6c79  ble to do really
+00017750: 2061 6e79 7468 696e 670a 2020 2020 6966   anything.    if
+00017760: 2028 6e69 646d 5f6f 776c 5f67 7261 7068   (nidm_owl_graph
+00017770: 2069 7320 4e6f 6e65 2920 616e 6420 2869   is None) and (i
+00017780: 6c78 5f6f 626a 2069 7320 4e6f 6e65 293a  lx_obj is None):
+00017790: 0a20 2020 2020 2020 2070 7269 6e74 2822  .        print("
+000177a0: 426f 7468 2049 6e74 6572 4c65 7820 616e  Both InterLex an
+000177b0: 6420 4e49 444d 204f 574c 2066 696c 6520  d NIDM OWL file 
+000177c0: 6163 6365 7373 2069 7320 6e6f 7420 706f  access is not po
+000177d0: 7373 6962 6c65 2229 0a20 2020 2020 2020  ssible").       
+000177e0: 2070 7269 6e74 280a 2020 2020 2020 2020   print(.        
+000177f0: 2020 2020 2243 6865 636b 2079 6f75 7220      "Check your 
+00017800: 696e 7465 726e 6574 2063 6f6e 6e65 6374  internet connect
+00017810: 696f 6e20 616e 6420 7472 7920 6167 6169  ion and try agai
+00017820: 6e20 6f72 2073 7570 706c 7920 6120 4a53  n or supply a JS
+00017830: 4f4e 2061 6e6e 6f74 6174 696f 6e20 6669  ON annotation fi
+00017840: 6c65 2077 6974 6820 616c 6c20 7468 6520  le with all the 
+00017850: 7661 7269 6162 6c65 7320 220a 2020 2020  variables ".    
+00017860: 2020 2020 2020 2020 226d 6170 7065 6420          "mapped 
+00017870: 746f 2074 6572 6d73 220a 2020 2020 2020  to terms".      
+00017880: 2020 290a 2020 2020 2020 2020 7265 7475    ).        retu
+00017890: 726e 2073 6f75 7263 655f 7661 7269 6162  rn source_variab
+000178a0: 6c65 5f61 6e6e 6f74 6174 696f 6e73 0a0a  le_annotations..
+000178b0: 2020 2020 2320 6164 6465 6420 6279 2044      # added by D
+000178c0: 424b 2035 2f31 342f 3231 2074 6f20 7375  BK 5/14/21 to su
+000178d0: 7070 6f72 7420 7075 6c6c 696e 6720 636f  pport pulling co
+000178e0: 6e63 6570 7473 2075 7365 6420 696e 2070  ncepts used in p
+000178f0: 7265 7669 6f75 7320 6461 7461 7365 7420  revious dataset 
+00017900: 616e 6e6f 7461 7469 6f6e 7320 696e 2066  annotations in f
+00017910: 726f 6d20 4e49 444d 2d54 6572 6d73 0a20  rom NIDM-Terms. 
+00017920: 2020 2023 2072 6570 6f2e 0a20 2020 206e     # repo..    n
+00017930: 6964 6d74 6572 6d73 5f63 6f6e 6365 7074  idmterms_concept
+00017940: 7320 3d20 6c6f 6164 5f6e 6964 6d5f 7465  s = load_nidm_te
+00017950: 726d 735f 636f 6e63 6570 7473 2829 0a0a  rms_concepts()..
+00017960: 2020 2020 2320 5265 7472 6965 7665 2063      # Retrieve c
+00017970: 6f67 6e69 7469 7665 2061 746c 6173 2063  ognitive atlas c
+00017980: 6f6e 6365 7074 7320 616e 6420 6469 736f  oncepts and diso
+00017990: 7264 6572 730a 2020 2020 636f 6761 746c  rders.    cogatl
+000179a0: 6173 5f63 6f6e 6365 7074 7320 3d20 6765  as_concepts = ge
+000179b0: 745f 636f 6e63 6570 7428 7369 6c65 6e74  t_concept(silent
+000179c0: 3d54 7275 6529 0a20 2020 2063 6f67 6174  =True).    cogat
+000179d0: 6c61 735f 6469 736f 7264 6572 7320 3d20  las_disorders = 
+000179e0: 6765 745f 6469 736f 7264 6572 2873 696c  get_disorder(sil
+000179f0: 656e 743d 5472 7565 290a 2020 2020 2320  ent=True).    # 
+00017a00: 5749 5020 5265 7472 6965 7665 2063 6f67  WIP Retrieve cog
+00017a10: 6e69 7469 7665 2061 746c 6173 2074 6173  nitive atlas tas
+00017a20: 6b73 0a20 2020 2023 2064 6f20 6120 6765  ks.    # do a ge
+00017a30: 7420 6672 6f6d 2074 6865 2066 6f6c 6c6f  t from the follo
+00017a40: 7769 6e67 2077 6562 7369 7465 2061 6e64  wing website and
+00017a50: 2074 6865 6e20 7061 7273 652f 6f72 6761   then parse/orga
+00017a60: 6e69 7a65 2066 6f72 206c 6f6f 6b75 700a  nize for lookup.
+00017a70: 2020 2020 2320 6874 7470 733a 2f2f 7777      # https://ww
+00017a80: 772e 636f 676e 6974 6976 6561 746c 6173  w.cognitiveatlas
+00017a90: 2e6f 7267 2f61 7069 2f76 2d61 6c70 6861  .org/api/v-alpha
+00017aa0: 2f74 6173 6b0a 0a20 2020 2023 206d 696e  /task..    # min
+00017ab0: 696d 756d 206d 6174 6368 2073 636f 7265  imum match score
+00017ac0: 2066 6f72 2066 757a 7a79 206d 6174 6368   for fuzzy match
+00017ad0: 696e 6720 4e49 444d 2074 6572 6d73 0a20  ing NIDM terms. 
+00017ae0: 2020 206d 696e 5f6d 6174 6368 5f73 636f     min_match_sco
+00017af0: 7265 203d 2035 300a 2020 2020 7365 6172  re = 50.    sear
+00017b00: 6368 5f74 6572 6d20 3d20 7374 7228 736f  ch_term = str(so
+00017b10: 7572 6365 5f76 6172 6961 626c 6529 0a20  urce_variable). 
+00017b20: 2020 2023 206c 6f6f 7020 746f 2066 696e     # loop to fin
+00017b30: 6420 6120 636f 6e63 6570 7420 6279 2069  d a concept by i
+00017b40: 7465 7261 7469 7665 6c79 2073 6561 7263  teratively searc
+00017b50: 6869 6e67 2049 6e74 6572 4c65 782e 2e2e  hing InterLex...
+00017b60: 6f72 2064 6566 696e 696e 6720 796f 7572  or defining your
+00017b70: 206f 776e 0a20 2020 2067 6f5f 6c6f 6f70   own.    go_loop
+00017b80: 203d 2054 7275 650a 2020 2020 7768 696c   = True.    whil
+00017b90: 6520 676f 5f6c 6f6f 703a 0a20 2020 2020  e go_loop:.     
+00017ba0: 2020 2023 2076 6172 6961 626c 6520 666f     # variable fo
+00017bb0: 7220 6e75 6d62 6572 696e 6720 6f70 7469  r numbering opti
+00017bc0: 6f6e 7320 7265 7475 726e 6564 2066 726f  ons returned fro
+00017bd0: 6d20 656c 6173 7469 6320 7365 6172 6368  m elastic search
+00017be0: 0a20 2020 2020 2020 206f 7074 696f 6e20  .        option 
+00017bf0: 3d20 310a 2020 2020 2020 2020 7072 696e  = 1.        prin
+00017c00: 7428 290a 2020 2020 2020 2020 7072 696e  t().        prin
+00017c10: 7428 2243 6f6e 6365 7074 2041 7373 6f63  t("Concept Assoc
+00017c20: 6961 7469 6f6e 2229 0a20 2020 2020 2020  iation").       
+00017c30: 2070 7269 6e74 2866 2251 7565 7279 2053   print(f"Query S
+00017c40: 7472 696e 673a 207b 7365 6172 6368 5f74  tring: {search_t
+00017c50: 6572 6d7d 2022 290a 0a20 2020 2020 2020  erm} ")..       
+00017c60: 2023 206d 6f64 6966 6965 6420 6279 2044   # modified by D
+00017c70: 424b 2035 2f31 342f 3231 2074 6f20 7374  BK 5/14/21 to st
+00017c80: 6172 7420 7769 7468 206e 6964 6d2d 7465  art with nidm-te
+00017c90: 726d 7320 7573 6564 2063 6f6e 6365 7074  rms used concept
+00017ca0: 730a 2020 2020 2020 2020 6966 206e 6964  s.        if nid
+00017cb0: 6d74 6572 6d73 5f63 6f6e 6365 7074 7320  mterms_concepts 
+00017cc0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
+00017cd0: 2020 2020 2020 2020 206e 6964 6d74 6572           nidmter
+00017ce0: 6d73 5f63 6f6e 6365 7074 735f 7175 6572  ms_concepts_quer
+00017cf0: 7920 3d20 6675 7a7a 795f 6d61 7463 685f  y = fuzzy_match_
+00017d00: 636f 6e63 6570 7473 5f66 726f 6d5f 6e69  concepts_from_ni
+00017d10: 646d 7465 726d 735f 6a73 6f6e 6c64 280a  dmterms_jsonld(.
+00017d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017d30: 6e69 646d 7465 726d 735f 636f 6e63 6570  nidmterms_concep
+00017d40: 7473 2c20 7365 6172 6368 5f74 6572 6d0a  ts, search_term.
+00017d50: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+00017d60: 2020 2020 2020 2020 2020 7365 6172 6368            search
+00017d70: 5f72 6573 756c 7420 3d20 7b7d 0a20 2020  _result = {}.   
+00017d80: 2020 2020 2020 2020 2066 6972 7374 5f6e           first_n
+00017d90: 6964 6d5f 7465 726d 203d 2054 7275 650a  idm_term = True.
+00017da0: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+00017db0: 6b65 792c 2076 616c 7565 2069 6e20 6e69  key, value in ni
+00017dc0: 646d 7465 726d 735f 636f 6e63 6570 7473  dmterms_concepts
+00017dd0: 5f71 7565 7279 2e69 7465 6d73 2829 3a0a  _query.items():.
+00017de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017df0: 6966 2076 616c 7565 5b22 7363 6f72 6522  if value["score"
+00017e00: 5d20 3e20 6d69 6e5f 6d61 7463 685f 7363  ] > min_match_sc
+00017e10: 6f72 653a 0a20 2020 2020 2020 2020 2020  ore:.           
+00017e20: 2020 2020 2020 2020 2069 6620 6669 7273           if firs
+00017e30: 745f 6e69 646d 5f74 6572 6d3a 0a20 2020  t_nidm_term:.   
+00017e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017e50: 2020 2020 2070 7269 6e74 2829 0a20 2020       print().   
+00017e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017e70: 2020 2020 2070 7269 6e74 2822 4e49 444d       print("NIDM
+00017e80: 2d54 6572 6d73 2043 6f6e 6365 7074 733a  -Terms Concepts:
+00017e90: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
+00017ea0: 2020 2020 2020 2020 2020 2066 6972 7374             first
+00017eb0: 5f6e 6964 6d5f 7465 726d 203d 2046 616c  _nidm_term = Fal
+00017ec0: 7365 0a0a 2020 2020 2020 2020 2020 2020  se..            
+00017ed0: 2020 2020 2020 2020 7072 696e 7428 0a20          print(. 
+00017ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017ef0: 2020 2020 2020 2066 227b 6f70 7469 6f6e         f"{option
+00017f00: 7d3a 204c 6162 656c 3a22 2c0a 2020 2020  }: Label:",.    
+00017f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017f20: 2020 2020 7661 6c75 655b 226c 6162 656c      value["label
+00017f30: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+00017f40: 2020 2020 2020 2020 2020 2020 225c 7420              "\t 
+00017f50: 4465 6669 6e69 7469 6f6e 3a22 2c0a 2020  Definition:",.  
+00017f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017f70: 2020 2020 2020 7661 6c75 655b 2264 6566        value["def
+00017f80: 696e 6974 696f 6e22 5d2c 0a20 2020 2020  inition"],.     
+00017f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017fa0: 2020 2022 5c74 2055 524c 3a22 2c0a 2020     "\t URL:",.  
+00017fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017fc0: 2020 2020 2020 7661 6c75 655b 2275 726c        value["url
+00017fd0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+00017fe0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00017ff0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00018000: 6172 6368 5f72 6573 756c 745b 6b65 795d  arch_result[key]
+00018010: 203d 207b 7d0a 2020 2020 2020 2020 2020   = {}.          
+00018020: 2020 2020 2020 2020 2020 7365 6172 6368            search
+00018030: 5f72 6573 756c 745b 6b65 795d 5b22 6c61  _result[key]["la
+00018040: 6265 6c22 5d20 3d20 7661 6c75 655b 226c  bel"] = value["l
+00018050: 6162 656c 225d 0a20 2020 2020 2020 2020  abel"].         
+00018060: 2020 2020 2020 2020 2020 2073 6561 7263             searc
+00018070: 685f 7265 7375 6c74 5b6b 6579 5d5b 2264  h_result[key]["d
+00018080: 6566 696e 6974 696f 6e22 5d20 3d20 7661  efinition"] = va
+00018090: 6c75 655b 2264 6566 696e 6974 696f 6e22  lue["definition"
+000180a0: 5d0a 2020 2020 2020 2020 2020 2020 2020  ].              
+000180b0: 2020 2020 2020 7365 6172 6368 5f72 6573        search_res
+000180c0: 756c 745b 6b65 795d 5b22 7072 6566 6572  ult[key]["prefer
+000180d0: 7265 645f 7572 6c22 5d20 3d20 7661 6c75  red_url"] = valu
+000180e0: 655b 2275 726c 225d 0a20 2020 2020 2020  e["url"].       
+000180f0: 2020 2020 2020 2020 2020 2020 2073 6561               sea
+00018100: 7263 685f 7265 7375 6c74 5b73 7472 286f  rch_result[str(o
+00018110: 7074 696f 6e29 5d20 3d20 6b65 790a 2020  ption)] = key.  
+00018120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018130: 2020 6f70 7469 6f6e 203d 206f 7074 696f    option = optio
+00018140: 6e20 2b20 310a 0a20 2020 2020 2020 2069  n + 1..        i
+00018150: 6620 6e6f 7420 616e 6365 7374 6f72 3a0a  f not ancestor:.
+00018160: 2020 2020 2020 2020 2020 2020 6966 2069              if i
+00018170: 6c78 5f6f 626a 2069 7320 6e6f 7420 4e6f  lx_obj is not No
+00018180: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+00018190: 2020 2020 2320 666f 7220 6561 6368 2063      # for each c
+000181a0: 6f6c 756d 6e20 6e61 6d65 2c20 7175 6572  olumn name, quer
+000181b0: 7920 496e 7465 726c 6578 2066 6f72 2070  y Interlex for p
+000181c0: 6f73 7369 626c 6520 6d61 7463 6865 730a  ossible matches.
+000181d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000181e0: 696c 785f 7265 7375 6c74 203d 2047 6574  ilx_result = Get
+000181f0: 4e49 444d 5465 726d 7346 726f 6d53 6369  NIDMTermsFromSci
+00018200: 4372 756e 6368 280a 2020 2020 2020 2020  Crunch(.        
+00018210: 2020 2020 2020 2020 2020 2020 7365 6172              sear
+00018220: 6368 5f74 6572 6d2c 2074 7970 653d 2274  ch_term, type="t
+00018230: 6572 6d22 2c20 616e 6365 7374 6f72 3d46  erm", ancestor=F
+00018240: 616c 7365 0a20 2020 2020 2020 2020 2020  alse.           
+00018250: 2020 2020 2029 0a0a 2020 2020 2020 2020       )..        
+00018260: 2020 2020 2020 2020 2320 7465 6d70 203d          # temp =
+00018270: 2069 6c78 5f72 6573 756c 742e 636f 7079   ilx_result.copy
+00018280: 2829 0a20 2020 2020 2020 2020 2020 2020  ().             
+00018290: 2020 2023 2070 7269 6e74 2822 5365 6172     # print("Sear
+000182a0: 6368 2054 6572 6d3a 222c 2073 6561 7263  ch Term:", searc
+000182b0: 685f 7465 726d 290a 2020 2020 2020 2020  h_term).        
+000182c0: 2020 2020 2020 2020 6966 206c 656e 2869          if len(i
+000182d0: 6c78 5f72 6573 756c 7429 2021 3d20 303a  lx_result) != 0:
+000182e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000182f0: 2020 2020 2070 7269 6e74 2822 496e 7465       print("Inte
+00018300: 724c 6578 3a22 290a 2020 2020 2020 2020  rLex:").        
+00018310: 2020 2020 2020 2020 2020 2020 7072 696e              prin
+00018320: 7428 290a 2020 2020 2020 2020 2020 2020  t().            
+00018330: 2020 2020 2020 2020 2320 7072 696e 7428          # print(
+00018340: 2253 6561 7263 6820 5265 7375 6c74 733a  "Search Results:
+00018350: 2022 290a 2020 2020 2020 2020 2020 2020   ").            
+00018360: 2020 2020 2020 2020 666f 7220 6b65 792c          for key,
+00018370: 2076 616c 7565 2069 6e20 696c 785f 7265   value in ilx_re
+00018380: 7375 6c74 2e69 7465 6d73 2829 3a0a 2020  sult.items():.  
+00018390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000183a0: 2020 2020 2020 7072 696e 7428 0a20 2020        print(.   
+000183b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000183c0: 2020 2020 2020 2020 2066 227b 6f70 7469           f"{opti
+000183d0: 6f6e 7d3a 204c 6162 656c 3a22 2c0a 2020  on}: Label:",.  
+000183e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000183f0: 2020 2020 2020 2020 2020 7661 6c75 655b            value[
+00018400: 226c 6162 656c 225d 2c0a 2020 2020 2020  "label"],.      
+00018410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018420: 2020 2020 2020 225c 7420 4465 6669 6e69        "\t Defini
+00018430: 7469 6f6e 3a22 2c0a 2020 2020 2020 2020  tion:",.        
+00018440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018450: 2020 2020 7661 6c75 655b 2264 6566 696e      value["defin
+00018460: 6974 696f 6e22 5d2c 0a20 2020 2020 2020  ition"],.       
+00018470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018480: 2020 2020 2022 5c74 2050 7265 6665 7272       "\t Preferr
+00018490: 6564 2055 524c 3a22 2c0a 2020 2020 2020  ed URL:",.      
+000184a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000184b0: 2020 2020 2020 7661 6c75 655b 2270 7265        value["pre
+000184c0: 6665 7272 6564 5f75 726c 225d 2c0a 2020  ferred_url"],.  
+000184d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000184e0: 2020 2020 2020 290a 0a20 2020 2020 2020        )..       
+000184f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018500: 2073 6561 7263 685f 7265 7375 6c74 5b6b   search_result[k
+00018510: 6579 5d20 3d20 7b7d 0a20 2020 2020 2020  ey] = {}.       
+00018520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018530: 2073 6561 7263 685f 7265 7375 6c74 5b6b   search_result[k
+00018540: 6579 5d5b 226c 6162 656c 225d 203d 2069  ey]["label"] = i
+00018550: 6c78 5f72 6573 756c 745b 6b65 795d 5b22  lx_result[key]["
+00018560: 6c61 6265 6c22 5d0a 2020 2020 2020 2020  label"].        
+00018570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018580: 7365 6172 6368 5f72 6573 756c 745b 6b65  search_result[ke
+00018590: 795d 5b22 6465 6669 6e69 7469 6f6e 225d  y]["definition"]
+000185a0: 203d 2069 6c78 5f72 6573 756c 745b 6b65   = ilx_result[ke
+000185b0: 795d 5b22 6465 6669 6e69 7469 6f6e 225d  y]["definition"]
+000185c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000185d0: 2020 2020 2020 2020 2073 6561 7263 685f           search_
+000185e0: 7265 7375 6c74 5b6b 6579 5d5b 2270 7265  result[key]["pre
+000185f0: 6665 7272 6564 5f75 726c 225d 203d 2069  ferred_url"] = i
+00018600: 6c78 5f72 6573 756c 745b 6b65 795d 5b0a  lx_result[key][.
+00018610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018620: 2020 2020 2020 2020 2020 2020 2270 7265              "pre
+00018630: 6665 7272 6564 5f75 726c 220a 2020 2020  ferred_url".    
+00018640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018650: 2020 2020 5d0a 2020 2020 2020 2020 2020      ].          
+00018660: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00018670: 6172 6368 5f72 6573 756c 745b 7374 7228  arch_result[str(
+00018680: 6f70 7469 6f6e 295d 203d 206b 6579 0a20  option)] = key. 
+00018690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000186a0: 2020 2020 2020 206f 7074 696f 6e20 3d20         option = 
+000186b0: 6f70 7469 6f6e 202b 2031 0a0a 2020 2020  option + 1..    
+000186c0: 2020 2020 2020 2020 2320 436f 676e 6974          # Cognit
+000186d0: 6976 6520 4174 6c61 7320 436f 6e63 6570  ive Atlas Concep
+000186e0: 7473 2053 6561 7263 680a 2020 2020 2020  ts Search.      
+000186f0: 2020 2020 2020 7472 793a 0a20 2020 2020        try:.     
+00018700: 2020 2020 2020 2020 2020 2063 6f67 6174             cogat
+00018710: 6c61 735f 636f 6e63 6570 7473 5f71 7565  las_concepts_que
+00018720: 7279 203d 2066 757a 7a79 5f6d 6174 6368  ry = fuzzy_match
+00018730: 5f74 6572 6d73 5f66 726f 6d5f 636f 6761  _terms_from_coga
+00018740: 746c 6173 5f6a 736f 6e28 0a20 2020 2020  tlas_json(.     
+00018750: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+00018760: 6f67 6174 6c61 735f 636f 6e63 6570 7473  ogatlas_concepts
+00018770: 2e6a 736f 6e2c 2073 6561 7263 685f 7465  .json, search_te
+00018780: 726d 0a20 2020 2020 2020 2020 2020 2020  rm.             
+00018790: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+000187a0: 2020 2020 2066 6972 7374 5f63 6f67 6174       first_cogat
+000187b0: 6c61 735f 636f 6e63 6570 7420 3d20 5472  las_concept = Tr
+000187c0: 7565 0a20 2020 2020 2020 2020 2020 2020  ue.             
+000187d0: 2020 2066 6f72 206b 6579 2c20 7661 6c75     for key, valu
+000187e0: 6520 696e 2063 6f67 6174 6c61 735f 636f  e in cogatlas_co
+000187f0: 6e63 6570 7473 5f71 7565 7279 2e69 7465  ncepts_query.ite
+00018800: 6d73 2829 3a0a 2020 2020 2020 2020 2020  ms():.          
+00018810: 2020 2020 2020 2020 2020 6966 2076 616c            if val
+00018820: 7565 5b22 7363 6f72 6522 5d20 3e20 6d69  ue["score"] > mi
+00018830: 6e5f 6d61 7463 685f 7363 6f72 6520 2b20  n_match_score + 
+00018840: 3230 3a0a 2020 2020 2020 2020 2020 2020  20:.            
+00018850: 2020 2020 2020 2020 2020 2020 6966 2066              if f
+00018860: 6972 7374 5f63 6f67 6174 6c61 735f 636f  irst_cogatlas_co
+00018870: 6e63 6570 743a 0a20 2020 2020 2020 2020  ncept:.         
+00018880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018890: 2020 2070 7269 6e74 2829 0a20 2020 2020     print().     
+000188a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000188b0: 2020 2020 2020 2070 7269 6e74 2822 436f         print("Co
+000188c0: 676e 6974 6976 6520 4174 6c61 733a 2229  gnitive Atlas:")
+000188d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000188e0: 2020 2020 2020 2020 2020 2020 2070 7269               pri
+000188f0: 6e74 2829 0a20 2020 2020 2020 2020 2020  nt().           
+00018900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018910: 2066 6972 7374 5f63 6f67 6174 6c61 735f   first_cogatlas_
+00018920: 636f 6e63 6570 7420 3d20 4661 6c73 650a  concept = False.
+00018930: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00018940: 2020 2020 2020 2020 2070 7269 6e74 280a           print(.
+00018950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018960: 2020 2020 2020 2020 2020 2020 6622 7b6f              f"{o
+00018970: 7074 696f 6e7d 3a20 4c61 6265 6c3a 222c  ption}: Label:",
+00018980: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00018990: 2020 2020 2020 2020 2020 2020 2076 616c               val
+000189a0: 7565 5b22 6c61 6265 6c22 5d2c 0a20 2020  ue["label"],.   
+000189b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000189c0: 2020 2020 2020 2020 2022 5c74 2044 6566           "\t Def
+000189d0: 696e 6974 696f 6e3a 2020 222c 0a20 2020  inition:  ",.   
+000189e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000189f0: 2020 2020 2020 2020 2076 616c 7565 5b22           value["
+00018a00: 6465 6669 6e69 7469 6f6e 225d 2e72 7374  definition"].rst
+00018a10: 7269 7028 225c 725c 6e22 292c 0a20 2020  rip("\r\n"),.   
+00018a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018a30: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+00018a40: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00018a50: 6561 7263 685f 7265 7375 6c74 5b6b 6579  earch_result[key
+00018a60: 5d20 3d20 7b7d 0a20 2020 2020 2020 2020  ] = {}.         
+00018a70: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00018a80: 6561 7263 685f 7265 7375 6c74 5b6b 6579  earch_result[key
+00018a90: 5d5b 226c 6162 656c 225d 203d 2076 616c  ]["label"] = val
+00018aa0: 7565 5b22 6c61 6265 6c22 5d0a 2020 2020  ue["label"].    
+00018ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018ac0: 2020 2020 7365 6172 6368 5f72 6573 756c      search_resul
+00018ad0: 745b 6b65 795d 5b22 6465 6669 6e69 7469  t[key]["definiti
+00018ae0: 6f6e 225d 203d 2076 616c 7565 5b22 6465  on"] = value["de
+00018af0: 6669 6e69 7469 6f6e 225d 2e72 7374 7269  finition"].rstri
+00018b00: 7028 0a20 2020 2020 2020 2020 2020 2020  p(.             
+00018b10: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00018b20: 5c72 5c6e 220a 2020 2020 2020 2020 2020  \r\n".          
+00018b30: 2020 2020 2020 2020 2020 2020 2020 290a                ).
+00018b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018b50: 2020 2020 2020 2020 7365 6172 6368 5f72          search_r
+00018b60: 6573 756c 745b 6b65 795d 5b22 7072 6566  esult[key]["pref
+00018b70: 6572 7265 645f 7572 6c22 5d20 3d20 7661  erred_url"] = va
+00018b80: 6c75 655b 2275 726c 225d 0a20 2020 2020  lue["url"].     
+00018b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018ba0: 2020 2073 6561 7263 685f 7265 7375 6c74     search_result
+00018bb0: 5b73 7472 286f 7074 696f 6e29 5d20 3d20  [str(option)] = 
+00018bc0: 6b65 790a 2020 2020 2020 2020 2020 2020  key.            
+00018bd0: 2020 2020 2020 2020 2020 2020 6f70 7469              opti
+00018be0: 6f6e 202b 3d20 310a 2020 2020 2020 2020  on += 1.        
+00018bf0: 2020 2020 6578 6365 7074 2045 7863 6570      except Excep
+00018c00: 7469 6f6e 3a0a 2020 2020 2020 2020 2020  tion:.          
+00018c10: 2020 2020 2020 7061 7373 0a0a 2020 2020        pass..    
+00018c20: 2020 2020 2020 2020 2320 436f 676e 6974          # Cognit
+00018c30: 6976 6520 4174 6c61 7320 4469 736f 7264  ive Atlas Disord
+00018c40: 6572 7320 5365 6172 6368 0a20 2020 2020  ers Search.     
+00018c50: 2020 2020 2020 2074 7279 3a0a 2020 2020         try:.    
+00018c60: 2020 2020 2020 2020 2020 2020 636f 6761              coga
+00018c70: 746c 6173 5f64 6973 6f72 6465 7273 5f71  tlas_disorders_q
+00018c80: 7565 7279 203d 2066 757a 7a79 5f6d 6174  uery = fuzzy_mat
+00018c90: 6368 5f74 6572 6d73 5f66 726f 6d5f 636f  ch_terms_from_co
+00018ca0: 6761 746c 6173 5f6a 736f 6e28 0a20 2020  gatlas_json(.   
+00018cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018cc0: 2063 6f67 6174 6c61 735f 6469 736f 7264   cogatlas_disord
+00018cd0: 6572 732e 6a73 6f6e 2c20 7365 6172 6368  ers.json, search
+00018ce0: 5f74 6572 6d0a 2020 2020 2020 2020 2020  _term.          
+00018cf0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+00018d00: 2020 2020 2020 2020 666f 7220 6b65 792c          for key,
+00018d10: 2076 616c 7565 2069 6e20 636f 6761 746c   value in cogatl
+00018d20: 6173 5f64 6973 6f72 6465 7273 5f71 7565  as_disorders_que
+00018d30: 7279 2e69 7465 6d73 2829 3a0a 2020 2020  ry.items():.    
+00018d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018d50: 6966 2076 616c 7565 5b22 7363 6f72 6522  if value["score"
+00018d60: 5d20 3e20 6d69 6e5f 6d61 7463 685f 7363  ] > min_match_sc
+00018d70: 6f72 6520 2b20 3230 3a0a 2020 2020 2020  ore + 20:.      
+00018d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018d90: 2020 7072 696e 7428 0a20 2020 2020 2020    print(.       
+00018da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018db0: 2020 2020 2066 227b 6f70 7469 6f6e 7d3a       f"{option}:
+00018dc0: 204c 6162 656c 3a22 2c0a 2020 2020 2020   Label:",.      
+00018dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018de0: 2020 2020 2020 7661 6c75 655b 226c 6162        value["lab
+00018df0: 656c 225d 2c0a 2020 2020 2020 2020 2020  el"],.          
+00018e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018e10: 2020 225c 7420 4465 6669 6e69 7469 6f6e    "\t Definition
+00018e20: 3a20 2020 222c 0a20 2020 2020 2020 2020  :   ",.         
+00018e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018e40: 2020 2076 616c 7565 5b22 6465 6669 6e69     value["defini
+00018e50: 7469 6f6e 225d 2e72 7374 7269 7028 225c  tion"].rstrip("\
+00018e60: 725c 6e22 292c 0a20 2020 2020 2020 2020  r\n"),.         
+00018e70: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00018e80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00018e90: 2020 2020 2020 2020 2073 6561 7263 685f           search_
+00018ea0: 7265 7375 6c74 5b6b 6579 5d20 3d20 7b7d  result[key] = {}
+00018eb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00018ec0: 2020 2020 2020 2020 2073 6561 7263 685f           search_
+00018ed0: 7265 7375 6c74 5b6b 6579 5d5b 226c 6162  result[key]["lab
+00018ee0: 656c 225d 203d 2076 616c 7565 5b22 6c61  el"] = value["la
+00018ef0: 6265 6c22 5d0a 2020 2020 2020 2020 2020  bel"].          
+00018f00: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00018f10: 6172 6368 5f72 6573 756c 745b 6b65 795d  arch_result[key]
+00018f20: 5b22 6465 6669 6e69 7469 6f6e 225d 203d  ["definition"] =
+00018f30: 2076 616c 7565 5b22 6465 6669 6e69 7469   value["definiti
+00018f40: 6f6e 225d 2e72 7374 7269 7028 0a20 2020  on"].rstrip(.   
+00018f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018f60: 2020 2020 2020 2020 2022 5c72 5c6e 220a           "\r\n".
+00018f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018f80: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+00018f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00018fa0: 2020 7365 6172 6368 5f72 6573 756c 745b    search_result[
+00018fb0: 6b65 795d 5b22 7072 6566 6572 7265 645f  key]["preferred_
+00018fc0: 7572 6c22 5d20 3d20 7661 6c75 655b 2275  url"] = value["u
+00018fd0: 726c 225d 0a20 2020 2020 2020 2020 2020  rl"].           
+00018fe0: 2020 2020 2020 2020 2020 2020 2073 6561               sea
+00018ff0: 7263 685f 7265 7375 6c74 5b73 7472 286f  rch_result[str(o
+00019000: 7074 696f 6e29 5d20 3d20 6b65 790a 2020  ption)] = key.  
+00019010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019020: 2020 2020 2020 6f70 7469 6f6e 203d 206f        option = o
+00019030: 7074 696f 6e20 2b20 310a 2020 2020 2020  ption + 1.      
+00019040: 2020 2020 2020 6578 6365 7074 2045 7863        except Exc
+00019050: 6570 7469 6f6e 3a0a 2020 2020 2020 2020  eption:.        
+00019060: 2020 2020 2020 2020 7061 7373 0a0a 2020          pass..  
+00019070: 2020 2020 2020 2020 2020 2320 6966 2075            # if u
+00019080: 7365 7220 7375 7070 6c69 6564 2061 6e20  ser supplied an 
+00019090: 4f57 4c20 6669 6c65 2074 6f20 7365 6172  OWL file to sear
+000190a0: 6368 2069 6e20 666f 7220 7465 726d 730a  ch in for terms.
+000190b0: 2020 2020 2020 2020 2020 2020 2320 6966              # if
+000190c0: 206f 776c 5f66 696c 653a 0a0a 2020 2020   owl_file:..    
+000190d0: 2020 2020 2020 2020 6966 206e 6964 6d5f          if nidm_
+000190e0: 6f77 6c5f 6772 6170 6820 6973 206e 6f74  owl_graph is not
+000190f0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00019100: 2020 2020 2020 2023 2041 6464 2065 7869         # Add exi
+00019110: 7374 696e 6720 4e49 444d 2054 6572 6d73  sting NIDM Terms
+00019120: 2061 7320 706f 7373 6962 6c65 2073 656c   as possible sel
+00019130: 6563 7469 6f6e 7320 7768 6963 6820 6675  ections which fu
+00019140: 7a7a 7920 6d61 7463 6820 7468 6520 7365  zzy match the se
+00019150: 6172 6368 5f74 6572 6d0a 2020 2020 2020  arch_term.      
+00019160: 2020 2020 2020 2020 2020 6e69 646d 5f63            nidm_c
+00019170: 6f6e 7374 616e 7473 5f71 7565 7279 203d  onstants_query =
+00019180: 2066 757a 7a79 5f6d 6174 6368 5f74 6572   fuzzy_match_ter
+00019190: 6d73 5f66 726f 6d5f 6772 6170 6828 0a20  ms_from_graph(. 
+000191a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000191b0: 2020 206e 6964 6d5f 6f77 6c5f 6772 6170     nidm_owl_grap
+000191c0: 682c 2073 6561 7263 685f 7465 726d 0a20  h, search_term. 
+000191d0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+000191e0: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000191f0: 2020 6669 7273 745f 6e69 646d 5f74 6572    first_nidm_ter
+00019200: 6d20 3d20 5472 7565 0a20 2020 2020 2020  m = True.       
+00019210: 2020 2020 2020 2020 2066 6f72 206b 6579           for key
+00019220: 2c20 7661 6c75 6520 696e 206e 6964 6d5f  , value in nidm_
+00019230: 636f 6e73 7461 6e74 735f 7175 6572 792e  constants_query.
+00019240: 6974 656d 7328 293a 0a20 2020 2020 2020  items():.       
+00019250: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00019260: 7661 6c75 655b 2273 636f 7265 225d 203e  value["score"] >
+00019270: 206d 696e 5f6d 6174 6368 5f73 636f 7265   min_match_score
+00019280: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00019290: 2020 2020 2020 2020 2020 6966 2066 6972            if fir
+000192a0: 7374 5f6e 6964 6d5f 7465 726d 3a0a 2020  st_nidm_term:.  
+000192b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000192c0: 2020 2020 2020 2020 2020 7072 696e 7428            print(
+000192d0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+000192e0: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+000192f0: 696e 7428 224e 4944 4d20 4f6e 746f 6c6f  int("NIDM Ontolo
+00019300: 6779 2054 6572 6d73 3a22 290a 2020 2020  gy Terms:").    
+00019310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019320: 2020 2020 2020 2020 6669 7273 745f 6e69          first_ni
+00019330: 646d 5f74 6572 6d20 3d20 4661 6c73 650a  dm_term = False.
+00019340: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00019350: 2020 2020 2020 2020 2070 7269 6e74 280a           print(.
+00019360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019370: 2020 2020 2020 2020 2020 2020 6622 7b6f              f"{o
+00019380: 7074 696f 6e7d 3a20 4c61 6265 6c3a 222c  ption}: Label:",
+00019390: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000193a0: 2020 2020 2020 2020 2020 2020 2076 616c               val
+000193b0: 7565 5b22 6c61 6265 6c22 5d2c 0a20 2020  ue["label"],.   
+000193c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000193d0: 2020 2020 2020 2020 2022 5c74 2044 6566           "\t Def
+000193e0: 696e 6974 696f 6e3a 222c 0a20 2020 2020  inition:",.     
+000193f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019400: 2020 2020 2020 2076 616c 7565 5b22 6465         value["de
+00019410: 6669 6e69 7469 6f6e 225d 2c0a 2020 2020  finition"],.    
+00019420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019430: 2020 2020 2020 2020 225c 7420 5552 4c3a          "\t URL:
+00019440: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00019450: 2020 2020 2020 2020 2020 2020 2020 2076                 v
+00019460: 616c 7565 5b22 7572 6c22 5d2c 0a20 2020  alue["url"],.   
+00019470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019480: 2020 2020 2029 0a20 2020 2020 2020 2020       ).         
+00019490: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+000194a0: 6561 7263 685f 7265 7375 6c74 5b6b 6579  earch_result[key
+000194b0: 5d20 3d20 7b7d 0a20 2020 2020 2020 2020  ] = {}.         
+000194c0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+000194d0: 6561 7263 685f 7265 7375 6c74 5b6b 6579  earch_result[key
+000194e0: 5d5b 226c 6162 656c 225d 203d 2076 616c  ]["label"] = val
+000194f0: 7565 5b22 6c61 6265 6c22 5d0a 2020 2020  ue["label"].    
+00019500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019510: 2020 2020 7365 6172 6368 5f72 6573 756c      search_resul
+00019520: 745b 6b65 795d 5b22 6465 6669 6e69 7469  t[key]["definiti
+00019530: 6f6e 225d 203d 2076 616c 7565 5b22 6465  on"] = value["de
+00019540: 6669 6e69 7469 6f6e 225d 0a20 2020 2020  finition"].     
+00019550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019560: 2020 2073 6561 7263 685f 7265 7375 6c74     search_result
+00019570: 5b6b 6579 5d5b 2270 7265 6665 7272 6564  [key]["preferred
+00019580: 5f75 726c 225d 203d 2076 616c 7565 5b22  _url"] = value["
+00019590: 7572 6c22 5d0a 2020 2020 2020 2020 2020  url"].          
+000195a0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+000195b0: 6172 6368 5f72 6573 756c 745b 7374 7228  arch_result[str(
+000195c0: 6f70 7469 6f6e 295d 203d 206b 6579 0a20  option)] = key. 
+000195d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000195e0: 2020 2020 2020 206f 7074 696f 6e20 3d20         option = 
+000195f0: 6f70 7469 6f6e 202b 2031 0a0a 2020 2020  option + 1..    
+00019600: 2020 2020 7072 696e 7428 290a 2020 2020      print().    
+00019610: 2020 2020 6966 2061 6e63 6573 746f 723a      if ancestor:
+00019620: 0a20 2020 2020 2020 2020 2020 2023 2042  .            # B
+00019630: 726f 6164 656e 2049 6e74 6572 6c65 7820  roaden Interlex 
+00019640: 7365 6172 6368 0a20 2020 2020 2020 2020  search.         
+00019650: 2020 2070 7269 6e74 280a 2020 2020 2020     print(.      
+00019660: 2020 2020 2020 2020 2020 6622 7b6f 7074            f"{opt
+00019670: 696f 6e7d 3a20 4272 6f61 6465 6e20 5365  ion}: Broaden Se
+00019680: 6172 6368 2028 696e 636c 7564 6573 2069  arch (includes i
+00019690: 6e74 6572 6c65 782c 2063 6f67 6174 6c61  nterlex, cogatla
+000196a0: 732c 2061 6e64 206e 6964 6d20 6f6e 746f  s, and nidm onto
+000196b0: 6c6f 6779 2920 220a 2020 2020 2020 2020  logy) ".        
+000196c0: 2020 2020 290a 2020 2020 2020 2020 656c      ).        el
+000196d0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+000196e0: 2320 4e61 7272 6f77 2049 6e74 6572 6c65  # Narrow Interle
+000196f0: 7820 7365 6172 6368 0a20 2020 2020 2020  x search.       
+00019700: 2020 2020 2070 7269 6e74 280a 2020 2020       print(.    
+00019710: 2020 2020 2020 2020 2020 2020 6622 7b6f              f"{o
+00019720: 7074 696f 6e7d 3a20 4e61 7272 6f77 2053  ption}: Narrow S
+00019730: 6561 7263 6820 2869 6e63 6c75 6465 7320  earch (includes 
+00019740: 6e69 646d 2d74 6572 6d73 2070 7265 7669  nidm-terms previ
+00019750: 6f75 736c 7920 7573 6564 2063 6f6e 6365  ously used conce
+00019760: 7074 7329 2022 0a20 2020 2020 2020 2020  pts) ".         
+00019770: 2020 2029 0a20 2020 2020 2020 206f 7074     ).        opt
+00019780: 696f 6e20 3d20 6f70 7469 6f6e 202b 2031  ion = option + 1
+00019790: 0a0a 2020 2020 2020 2020 2320 4164 6420  ..        # Add 
+000197a0: 6f70 7469 6f6e 2074 6f20 6368 616e 6765  option to change
+000197b0: 2071 7565 7279 2073 7472 696e 670a 2020   query string.  
+000197c0: 2020 2020 2020 7072 696e 7428 6627 7b6f        print(f'{o
+000197d0: 7074 696f 6e7d 3a20 4368 616e 6765 2071  ption}: Change q
+000197e0: 7565 7279 2073 7472 696e 6720 6672 6f6d  uery string from
+000197f0: 3a20 227b 7365 6172 6368 5f74 6572 6d7d  : "{search_term}
+00019800: 2227 290a 0a20 2020 2020 2020 2023 2023  "')..        # #
+00019810: 2323 2323 2323 2044 4546 494e 4520 4e45  ###### DEFINE NE
+00019820: 5720 434f 4e43 4550 5420 434f 4d4d 454e  W CONCEPT COMMEN
+00019830: 5445 4420 4f55 5420 5249 4748 5420 4e4f  TED OUT RIGHT NO
+00019840: 5720 2323 2323 2323 2323 2323 2323 2323  W ##############
+00019850: 2323 2323 0a20 2020 2020 2020 2023 2023  ####.        # #
+00019860: 2041 6464 206f 7074 696f 6e20 746f 2064   Add option to d
+00019870: 6566 696e 6520 796f 7572 206f 776e 2074  efine your own t
+00019880: 6572 6d0a 2020 2020 2020 2020 2320 6f70  erm.        # op
+00019890: 7469 6f6e 203d 206f 7074 696f 6e20 2b20  tion = option + 
+000198a0: 310a 2020 2020 2020 2020 2320 7072 696e  1.        # prin
+000198b0: 7428 6622 7b6f 7074 696f 6e7d 3a20 4465  t(f"{option}: De
+000198c0: 6669 6e65 206d 7920 6f77 6e20 636f 6e63  fine my own conc
+000198d0: 6570 7420 666f 7220 7468 6973 2076 6172  ept for this var
+000198e0: 6961 626c 6522 290a 2020 2020 2020 2020  iable").        
+000198f0: 2320 2323 2323 2323 2320 4445 4649 4e45  # ####### DEFINE
+00019900: 204e 4557 2043 4f4e 4345 5054 2043 4f4d   NEW CONCEPT COM
+00019910: 4d45 4e54 4544 204f 5554 2052 4947 4854  MENTED OUT RIGHT
+00019920: 204e 4f57 2023 2323 2323 2323 2323 2323   NOW ###########
+00019930: 2323 2323 2323 230a 2020 2020 2020 2020  #######.        
+00019940: 2320 4164 6420 6f70 7469 6f6e 2074 6f20  # Add option to 
+00019950: 6465 6669 6e65 2079 6f75 7220 6f77 6e20  define your own 
+00019960: 7465 726d 0a20 2020 2020 2020 206f 7074  term.        opt
+00019970: 696f 6e20 3d20 6f70 7469 6f6e 202b 2031  ion = option + 1
+00019980: 0a20 2020 2020 2020 2070 7269 6e74 2866  .        print(f
+00019990: 227b 6f70 7469 6f6e 7d3a 204e 6f20 636f  "{option}: No co
+000199a0: 6e63 6570 7420 6e65 6564 6564 2066 6f72  ncept needed for
+000199b0: 2074 6869 7320 7661 7269 6162 6c65 2229   this variable")
+000199c0: 0a0a 2020 2020 2020 2020 7072 696e 7428  ..        print(
+000199d0: 222a 2220 2a20 3837 290a 2020 2020 2020  "*" * 87).      
+000199e0: 2020 2320 5761 6974 2066 6f72 2075 7365    # Wait for use
+000199f0: 7220 696e 7075 740a 2020 2020 2020 2020  r input.        
+00019a00: 7365 6c65 6374 696f 6e20 3d20 696e 7075  selection = inpu
+00019a10: 7428 6622 506c 6561 7365 2073 656c 6563  t(f"Please selec
+00019a20: 7420 616e 206f 7074 696f 6e20 2831 3a7b  t an option (1:{
+00019a30: 6f70 7469 6f6e 7d29 2066 726f 6d20 6162  option}) from ab
+00019a40: 6f76 653a 205c 7422 290a 0a20 2020 2020  ove: \t")..     
+00019a50: 2020 2023 204d 616b 6520 7375 7265 2075     # Make sure u
+00019a60: 7365 7220 7365 6c65 6374 6564 206f 6e65  ser selected one
+00019a70: 206f 6620 7468 6520 6f70 7469 6f6e 732e   of the options.
+00019a80: 2020 4966 206e 6f74 2070 7265 7365 6e74    If not present
+00019a90: 2075 7365 7220 7769 7468 2073 656c 6563   user with selec
+00019aa0: 7469 6f6e 2069 6e70 7574 2061 6761 696e  tion input again
+00019ab0: 0a20 2020 2020 2020 2077 6869 6c65 2028  .        while (
+00019ac0: 6e6f 7420 7365 6c65 6374 696f 6e2e 6973  not selection.is
+00019ad0: 6469 6769 7428 2929 206f 7220 2869 6e74  digit()) or (int
+00019ae0: 2873 656c 6563 7469 6f6e 2920 3e20 696e  (selection) > in
+00019af0: 7428 6f70 7469 6f6e 2929 3a0a 2020 2020  t(option)):.    
+00019b00: 2020 2020 2020 2020 2320 5761 6974 2066          # Wait f
+00019b10: 6f72 2075 7365 7220 696e 7075 740a 2020  or user input.  
+00019b20: 2020 2020 2020 2020 2020 7365 6c65 6374            select
+00019b30: 696f 6e20 3d20 696e 7075 7428 6622 506c  ion = input(f"Pl
+00019b40: 6561 7365 2073 656c 6563 7420 616e 206f  ease select an o
+00019b50: 7074 696f 6e20 2831 3a7b 6f70 7469 6f6e  ption (1:{option
+00019b60: 7d29 2066 726f 6d20 6162 6f76 653a 205c  }) from above: \
+00019b70: 7422 290a 0a20 2020 2020 2020 2023 2074  t")..        # t
+00019b80: 6f67 676c 6520 7573 6520 6f66 2061 6e63  oggle use of anc
+00019b90: 6573 746f 7273 2069 6e20 696e 7465 726c  estors in interl
+00019ba0: 6578 2071 7565 7279 206f 7220 6e6f 740a  ex query or not.
+00019bb0: 2020 2020 2020 2020 6966 2069 6e74 2873          if int(s
+00019bc0: 656c 6563 7469 6f6e 2920 3d3d 2028 6f70  election) == (op
+00019bd0: 7469 6f6e 202d 2032 293a 0a20 2020 2020  tion - 2):.     
+00019be0: 2020 2020 2020 2061 6e63 6573 746f 7220         ancestor 
+00019bf0: 3d20 6e6f 7420 616e 6365 7374 6f72 0a20  = not ancestor. 
+00019c00: 2020 2020 2020 2023 2063 6865 636b 2069         # check i
+00019c10: 6620 7365 6c65 6374 696f 6e20 6973 2074  f selection is t
+00019c20: 6f20 7265 2d72 756e 2071 7565 7279 2077  o re-run query w
+00019c30: 6974 6820 6e65 7720 7365 6172 6368 2074  ith new search t
+00019c40: 6572 6d0a 2020 2020 2020 2020 656c 6966  erm.        elif
+00019c50: 2069 6e74 2873 656c 6563 7469 6f6e 2920   int(selection) 
+00019c60: 3d3d 2028 6f70 7469 6f6e 202d 2031 293a  == (option - 1):
+00019c70: 0a20 2020 2020 2020 2020 2020 2023 2061  .            # a
+00019c80: 736b 2075 7365 7220 666f 7220 6e65 7720  sk user for new 
+00019c90: 7365 6172 6368 2073 7472 696e 670a 2020  search string.  
+00019ca0: 2020 2020 2020 2020 2020 7365 6172 6368            search
+00019cb0: 5f74 6572 6d20 3d20 696e 7075 7428 0a20  _term = input(. 
+00019cc0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00019cd0: 2250 6c65 6173 6520 696e 7075 7420 6e65  "Please input ne
+00019ce0: 7720 7365 6172 6368 2073 7472 696e 6720  w search string 
+00019cf0: 666f 7220 4353 5620 636f 6c75 6d6e 3a20  for CSV column: 
+00019d00: 7b73 6f75 7263 655f 7661 7269 6162 6c65  {source_variable
+00019d10: 7d20 5c74 3a22 0a20 2020 2020 2020 2020  } \t:".         
+00019d20: 2020 2029 0a20 2020 2020 2020 2020 2020     ).           
+00019d30: 2070 7269 6e74 2822 2a22 202a 2038 3729   print("*" * 87)
+00019d40: 0a0a 2020 2020 2020 2020 2320 2323 2323  ..        # ####
+00019d50: 2323 2320 4445 4649 4e45 204e 4557 2043  ### DEFINE NEW C
+00019d60: 4f4e 4345 5054 2043 4f4d 4d45 4e54 4544  ONCEPT COMMENTED
+00019d70: 204f 5554 2052 4947 4854 204e 4f57 2023   OUT RIGHT NOW #
+00019d80: 2323 2323 2323 2323 2323 2323 2323 2323  ################
+00019d90: 230a 2020 2020 2020 2020 2320 656c 6966  #.        # elif
+00019da0: 2069 6e74 2873 656c 6563 7469 6f6e 2920   int(selection) 
+00019db0: 3d3d 2028 6f70 7469 6f6e 202d 2031 293a  == (option - 1):
+00019dc0: 0a20 2020 2020 2020 2023 2020 2020 6e65  .        #    ne
+00019dd0: 775f 636f 6e63 6570 7420 3d20 6465 6669  w_concept = defi
+00019de0: 6e65 5f6e 6577 5f63 6f6e 6365 7074 2873  ne_new_concept(s
+00019df0: 6f75 7263 655f 7661 7269 6162 6c65 2c69  ource_variable,i
+00019e00: 6c78 5f6f 626a 290a 2020 2020 2020 2020  lx_obj).        
+00019e10: 2320 6164 6420 6e65 7720 636f 6e63 6570  # add new concep
+00019e20: 7420 746f 2049 6e74 6572 4c65 7820 616e  t to InterLex an
+00019e30: 6420 7265 7472 6965 7665 2055 524c 2066  d retrieve URL f
+00019e40: 6f72 2069 7341 626f 7574 0a20 2020 2020  or isAbout.     
+00019e50: 2020 2023 0a20 2020 2020 2020 2023 0a20     #.        #. 
+00019e60: 2020 2020 2020 2023 0a20 2020 2020 2020         #.       
+00019e70: 2023 2020 2020 736f 7572 6365 5f76 6172   #    source_var
+00019e80: 6961 626c 655f 616e 6e6f 7461 7469 6f6e  iable_annotation
+00019e90: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+00019ea0: 5b27 6973 4162 6f75 7427 5d20 3d20 6e65  ['isAbout'] = ne
+00019eb0: 775f 636f 6e63 6570 742e 6972 6920 2b20  w_concept.iri + 
+00019ec0: 2723 270a 2020 2020 2020 2020 2320 2020  '#'.        #   
+00019ed0: 2067 6f5f 6c6f 6f70 203d 2046 616c 7365   go_loop = False
+00019ee0: 0a20 2020 2020 2020 2023 2069 6620 7573  .        # if us
+00019ef0: 6572 2073 6179 7320 6e6f 2063 6f6e 6365  er says no conce
+00019f00: 7074 206d 6170 7069 6e67 206e 6565 6465  pt mapping neede
+00019f10: 6420 7468 656e 206a 7573 7420 6578 6974  d then just exit
+00019f20: 2074 6869 7320 6c6f 6f70 0a20 2020 2020   this loop.     
+00019f30: 2020 2023 2023 2323 2323 2323 2044 4546     # ####### DEF
+00019f40: 494e 4520 4e45 5720 434f 4e43 4550 5420  INE NEW CONCEPT 
+00019f50: 434f 4d4d 454e 5445 4420 4f55 5420 5249  COMMENTED OUT RI
+00019f60: 4748 5420 4e4f 5720 2323 2323 2323 2323  GHT NOW ########
+00019f70: 2323 2323 2323 2323 2323 0a20 2020 2020  ##########.     
+00019f80: 2020 2065 6c69 6620 696e 7428 7365 6c65     elif int(sele
+00019f90: 6374 696f 6e29 203d 3d20 286f 7074 696f  ction) == (optio
+00019fa0: 6e29 3a0a 2020 2020 2020 2020 2020 2020  n):.            
+00019fb0: 2320 646f 6e27 7420 6e65 6564 2074 6f20  # don't need to 
+00019fc0: 636f 6e74 696e 7565 2077 6869 6c65 206c  continue while l
+00019fd0: 6f6f 7020 6265 6361 7573 6520 7765 2776  oop because we'v
+00019fe0: 6520 6465 6369 6465 6420 6e6f 7420 746f  e decided not to
+00019ff0: 2061 7373 6f63 6961 7465 2061 2063 6f6e   associate a con
+0001a000: 6365 7074 2077 6974 6820 7468 6973 2076  cept with this v
+0001a010: 6172 6961 626c 652e 0a20 2020 2020 2020  ariable..       
+0001a020: 2020 2020 2067 6f5f 6c6f 6f70 203d 2046       go_loop = F
+0001a030: 616c 7365 0a20 2020 2020 2020 2065 6c73  alse.        els
+0001a040: 653a 0a20 2020 2020 2020 2020 2020 2023  e:.            #
+0001a050: 2075 7365 7220 7365 6c65 6374 6564 206f   user selected o
+0001a060: 6e65 206f 6620 7468 6520 6578 6973 7469  ne of the existi
+0001a070: 6e67 2063 6f6e 6365 7074 7320 746f 2061  ng concepts to a
+0001a080: 6464 2069 7473 2055 524c 2074 6f20 7468  dd its URL to th
+0001a090: 6520 6973 4162 6f75 7420 7072 6f70 6572  e isAbout proper
+0001a0a0: 7479 0a20 2020 2020 2020 2020 2020 2023  ty.            #
+0001a0b0: 2061 6464 6564 206c 6162 656c 7320 746f   added labels to
+0001a0c0: 2074 6865 7365 2069 7341 626f 7574 2075   these isAbout u
+0001a0d0: 726c 7320 666f 7220 6561 7379 2071 7565  rls for easy que
+0001a0e0: 7279 696e 6720 6c61 7465 720a 2020 2020  rying later.    
+0001a0f0: 2020 2020 2020 2020 736f 7572 6365 5f76          source_v
+0001a100: 6172 6961 626c 655f 616e 6e6f 7461 7469  ariable_annotati
+0001a110: 6f6e 735b 6375 7272 656e 745f 7475 706c  ons[current_tupl
+0001a120: 655d 5b22 6973 4162 6f75 7422 5d20 3d20  e]["isAbout"] = 
+0001a130: 5b5d 0a20 2020 2020 2020 2020 2020 2073  [].            s
+0001a140: 6f75 7263 655f 7661 7269 6162 6c65 5f61  ource_variable_a
+0001a150: 6e6e 6f74 6174 696f 6e73 5b63 7572 7265  nnotations[curre
+0001a160: 6e74 5f74 7570 6c65 5d5b 2269 7341 626f  nt_tuple]["isAbo
+0001a170: 7574 225d 2e61 7070 656e 6428 0a20 2020  ut"].append(.   
+0001a180: 2020 2020 2020 2020 2020 2020 207b 0a20               {. 
+0001a190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a1a0: 2020 2022 4069 6422 3a20 7365 6172 6368     "@id": search
+0001a1b0: 5f72 6573 756c 745b 7365 6172 6368 5f72  _result[search_r
+0001a1c0: 6573 756c 745b 7365 6c65 6374 696f 6e5d  esult[selection]
+0001a1d0: 5d5b 2270 7265 6665 7272 6564 5f75 726c  ]["preferred_url
+0001a1e0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+0001a1f0: 2020 2020 2020 2020 226c 6162 656c 223a          "label":
+0001a200: 2073 6561 7263 685f 7265 7375 6c74 5b73   search_result[s
+0001a210: 6561 7263 685f 7265 7375 6c74 5b73 656c  earch_result[sel
+0001a220: 6563 7469 6f6e 5d5d 5b22 6c61 6265 6c22  ection]]["label"
+0001a230: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+0001a240: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
+0001a250: 2029 0a20 2020 2020 2020 2020 2020 2070   ).            p
+0001a260: 7269 6e74 2822 5c6e 436f 6e63 6570 7420  rint("\nConcept 
+0001a270: 616e 6e6f 7461 7469 6f6e 2061 6464 6564  annotation added
+0001a280: 2066 6f72 2073 6f75 7263 6520 7661 7269   for source vari
+0001a290: 6162 6c65 3a22 2c20 736f 7572 6365 5f76  able:", source_v
+0001a2a0: 6172 6961 626c 6529 0a20 2020 2020 2020  ariable).       
+0001a2b0: 2020 2020 2067 6f5f 6c6f 6f70 203d 2046       go_loop = F
+0001a2c0: 616c 7365 0a0a 0a64 6566 2064 6566 696e  alse...def defin
+0001a2d0: 655f 6e65 775f 636f 6e63 6570 7428 736f  e_new_concept(so
+0001a2e0: 7572 6365 5f76 6172 6961 626c 652c 2069  urce_variable, i
+0001a2f0: 6c78 5f6f 626a 293a 0a20 2020 2023 2075  lx_obj):.    # u
+0001a300: 7365 7220 7761 6e74 7320 746f 2064 6566  ser wants to def
+0001a310: 696e 6520 7468 6569 7220 6f77 6e20 7465  ine their own te
+0001a320: 726d 2e20 2041 736b 2066 6f72 2074 6572  rm.  Ask for ter
+0001a330: 6d20 6c61 6265 6c20 616e 6420 6465 6669  m label and defi
+0001a340: 6e69 7469 6f6e 0a20 2020 2070 7269 6e74  nition.    print
+0001a350: 2822 5c6e 596f 7520 7365 6c65 6374 6564  ("\nYou selected
+0001a360: 2074 6f20 656e 7465 7220 6120 6e65 7720   to enter a new 
+0001a370: 636f 6e63 6570 7420 666f 7220 4353 5620  concept for CSV 
+0001a380: 636f 6c75 6d6e 3a22 2c20 736f 7572 6365  column:", source
+0001a390: 5f76 6172 6961 626c 6529 0a0a 2020 2020  _variable)..    
+0001a3a0: 2320 636f 6c6c 6563 7420 7465 726d 2069  # collect term i
+0001a3b0: 6e66 6f72 6d61 7469 6f6e 2066 726f 6d20  nformation from 
+0001a3c0: 7573 6572 0a20 2020 2063 6f6e 6365 7074  user.    concept
+0001a3d0: 5f6c 6162 656c 203d 2069 6e70 7574 280a  _label = input(.
+0001a3e0: 2020 2020 2020 2020 6622 506c 6561 7365          f"Please
+0001a3f0: 2065 6e74 6572 2061 206c 6162 656c 2066   enter a label f
+0001a400: 6f72 2074 6865 206e 6577 2063 6f6e 6365  or the new conce
+0001a410: 7074 205b 7b73 6f75 7263 655f 7661 7269  pt [{source_vari
+0001a420: 6162 6c65 7d5d 3a5c 7422 0a20 2020 2029  able}]:\t".    )
+0001a430: 0a20 2020 2063 6f6e 6365 7074 5f64 6566  .    concept_def
+0001a440: 696e 6974 696f 6e20 3d20 696e 7075 7428  inition = input(
+0001a450: 2250 6c65 6173 6520 656e 7465 7220 6120  "Please enter a 
+0001a460: 6465 6669 6e69 7469 6f6e 2066 6f72 2074  definition for t
+0001a470: 6869 7320 636f 6e63 6570 743a 5c74 2229  his concept:\t")
+0001a480: 0a0a 2020 2020 2320 6164 6420 636f 6e63  ..    # add conc
+0001a490: 6570 7420 746f 2049 6e74 6572 4c65 7820  ept to InterLex 
+0001a4a0: 616e 6420 6765 7420 5552 4c0a 2020 2020  and get URL.    
+0001a4b0: 2320 4164 6420 7065 7273 6f6e 616c 2064  # Add personal d
+0001a4c0: 6174 6120 656c 656d 656e 7420 746f 2049  ata element to I
+0001a4d0: 6e74 6572 4c65 780a 0a20 2020 2069 6c78  nterLex..    ilx
+0001a4e0: 5f6f 7574 7075 7420 3d20 4164 6443 6f6e  _output = AddCon
+0001a4f0: 6365 7074 546f 496e 7465 726c 6578 280a  ceptToInterlex(.
+0001a500: 2020 2020 2020 2020 696c 785f 6f62 6a3d          ilx_obj=
+0001a510: 696c 785f 6f62 6a2c 206c 6162 656c 3d63  ilx_obj, label=c
+0001a520: 6f6e 6365 7074 5f6c 6162 656c 2c20 6465  oncept_label, de
+0001a530: 6669 6e69 7469 6f6e 3d63 6f6e 6365 7074  finition=concept
+0001a540: 5f64 6566 696e 6974 696f 6e0a 2020 2020  _definition.    
+0001a550: 290a 0a20 2020 2072 6574 7572 6e20 696c  )..    return il
+0001a560: 785f 6f75 7470 7574 0a0a 0a64 6566 2061  x_output...def a
+0001a570: 6e6e 6f74 6174 655f 6461 7461 5f65 6c65  nnotate_data_ele
+0001a580: 6d65 6e74 2873 6f75 7263 655f 7661 7269  ment(source_vari
+0001a590: 6162 6c65 2c20 6375 7272 656e 745f 7475  able, current_tu
+0001a5a0: 706c 652c 2073 6f75 7263 655f 7661 7269  ple, source_vari
+0001a5b0: 6162 6c65 5f61 6e6e 6f74 6174 696f 6e73  able_annotations
+0001a5c0: 293a 0a20 2020 2022 2222 0a20 2020 203a  ):.    """.    :
+0001a5d0: 736f 7572 6365 5f76 6172 6961 626c 653a  source_variable:
+0001a5e0: 2076 6172 6961 626c 6520 6e61 6d65 2066   variable name f
+0001a5f0: 6f72 2077 6869 6368 2077 6527 7265 2061  or which we're a
+0001a600: 6e6e 6f74 6174 696e 670a 2020 2020 3a63  nnotating.    :c
+0001a610: 7572 7265 6e74 5f74 7570 6c65 3a20 7468  urrent_tuple: th
+0001a620: 6973 2069 7320 7468 6520 7475 706c 6520  is is the tuple 
+0001a630: 6b65 7920 6f66 2074 6865 203a 736f 7572  key of the :sour
+0001a640: 6365 5f76 6172 6961 626c 653a 2069 6e20  ce_variable: in 
+0001a650: 7468 650a 2020 2020 6469 6374 696f 6e61  the.    dictiona
+0001a660: 7279 203a 736f 7572 6365 5f76 6172 6961  ry :source_varia
+0001a670: 626c 655f 616e 6e6f 7461 7469 6f6e 733a  ble_annotations:
+0001a680: 2e20 2054 6865 7365 2061 7265 2063 6f6d  .  These are com
+0001a690: 706f 756e 6420 6b65 7973 0a20 2020 203a  pound keys.    :
+0001a6a0: 736f 7572 6365 5f76 6172 6961 626c 655f  source_variable_
+0001a6b0: 616e 6e6f 7461 7469 6f6e 733a 2064 6963  annotations: dic
+0001a6c0: 7469 6f6e 6172 7920 6f66 2076 6172 6961  tionary of varia
+0001a6d0: 626c 6520 616e 6e6f 7461 7469 6f6e 732e  ble annotations.
+0001a6e0: 0a20 2020 2022 2222 0a0a 2020 2020 2320  .    """..    # 
+0001a6f0: 7573 6572 2069 6e73 7472 7563 7469 6f6e  user instruction
+0001a700: 730a 2020 2020 7072 696e 7428 0a20 2020  s.    print(.   
+0001a710: 2020 2020 2022 5c6e 596f 7520 7769 6c6c       "\nYou will
+0001a720: 206e 6f77 2062 6520 6173 6b65 6420 6120   now be asked a 
+0001a730: 7365 7269 6573 206f 6620 7175 6573 7469  series of questi
+0001a740: 6f6e 7320 746f 2061 6e6e 6f74 6174 6520  ons to annotate 
+0001a750: 796f 7572 2074 6572 6d3a 222c 0a20 2020  your term:",.   
+0001a760: 2020 2020 2073 6f75 7263 655f 7661 7269       source_vari
+0001a770: 6162 6c65 2c0a 2020 2020 290a 0a20 2020  able,.    )..   
+0001a780: 2023 2063 6f6c 6c65 6374 2074 6572 6d20   # collect term 
+0001a790: 696e 666f 726d 6174 696f 6e20 6672 6f6d  information from
+0001a7a0: 2075 7365 720a 2020 2020 7465 726d 5f6c   user.    term_l
+0001a7b0: 6162 656c 203d 2069 6e70 7574 280a 2020  abel = input(.  
+0001a7c0: 2020 2020 2020 6622 506c 6561 7365 2065        f"Please e
+0001a7d0: 6e74 6572 2061 2066 756c 6c20 6e61 6d65  nter a full name
+0001a7e0: 2074 6f20 6173 736f 6369 6174 6520 7769   to associate wi
+0001a7f0: 7468 2074 6865 2074 6572 6d20 5b7b 736f  th the term [{so
+0001a800: 7572 6365 5f76 6172 6961 626c 657d 5d3a  urce_variable}]:
+0001a810: 5c74 220a 2020 2020 290a 2020 2020 6966  \t".    ).    if
+0001a820: 2074 6572 6d5f 6c61 6265 6c20 3d3d 2022   term_label == "
+0001a830: 223a 0a20 2020 2020 2020 2074 6572 6d5f  ":.        term_
+0001a840: 6c61 6265 6c20 3d20 736f 7572 6365 5f76  label = source_v
+0001a850: 6172 6961 626c 650a 0a20 2020 2074 6572  ariable..    ter
+0001a860: 6d5f 6465 6669 6e69 7469 6f6e 203d 2069  m_definition = i
+0001a870: 6e70 7574 2822 506c 6561 7365 2065 6e74  nput("Please ent
+0001a880: 6572 2061 2064 6566 696e 6974 696f 6e20  er a definition 
+0001a890: 666f 7220 7468 6973 2074 6572 6d3a 5c74  for this term:\t
+0001a8a0: 2229 0a0a 2020 2020 2320 6765 7420 6461  ")..    # get da
+0001a8b0: 7461 7479 7065 0a20 2020 2077 6869 6c65  tatype.    while
+0001a8c0: 2054 7275 653a 0a20 2020 2020 2020 2070   True:.        p
+0001a8d0: 7269 6e74 2822 506c 6561 7365 2065 6e74  rint("Please ent
+0001a8e0: 6572 2074 6865 2076 616c 7565 2074 7970  er the value typ
+0001a8f0: 6520 666f 7220 7468 6973 2074 6572 6d20  e for this term 
+0001a900: 6672 6f6d 2074 6865 2066 6f6c 6c6f 7769  from the followi
+0001a910: 6e67 206c 6973 743a 2229 0a20 2020 2020  ng list:").     
+0001a920: 2020 2070 7269 6e74 2822 5c74 2031 3a20     print("\t 1: 
+0001a930: 7374 7269 6e67 202d 2054 6865 2073 7472  string - The str
+0001a940: 696e 6720 6461 7461 7479 7065 2072 6570  ing datatype rep
+0001a950: 7265 7365 6e74 7320 6368 6172 6163 7465  resents characte
+0001a960: 7220 7374 7269 6e67 7322 290a 2020 2020  r strings").    
+0001a970: 2020 2020 7072 696e 7428 0a20 2020 2020      print(.     
+0001a980: 2020 2020 2020 2022 5c74 2032 3a20 6361         "\t 2: ca
+0001a990: 7465 676f 7269 6361 6c20 2d20 4120 7661  tegorical - A va
+0001a9a0: 7269 6162 6c65 2074 6861 7420 6361 6e20  riable that can 
+0001a9b0: 7461 6b65 206f 6e20 6f6e 6520 6f66 2061  take on one of a
+0001a9c0: 206c 696d 6974 6564 206e 756d 6265 7220   limited number 
+0001a9d0: 6f66 2070 6f73 7369 626c 6520 7661 6c75  of possible valu
+0001a9e0: 6573 2c20 6173 7369 676e 696e 6720 6561  es, assigning ea
+0001a9f0: 6368 2074 6f20 6120 6e6f 6d69 6e61 6c20  ch to a nominal 
+0001aa00: 6361 7465 676f 7279 206f 6e20 7468 6520  category on the 
+0001aa10: 6261 7369 7320 6f66 2073 6f6d 6520 7175  basis of some qu
+0001aa20: 616c 6974 6174 6976 6520 7072 6f70 6572  alitative proper
+0001aa30: 7479 2e22 0a20 2020 2020 2020 2029 0a20  ty.".        ). 
+0001aa40: 2020 2020 2020 2070 7269 6e74 2822 5c74         print("\t
+0001aa50: 2033 3a20 626f 6f6c 6561 6e20 2d20 4269   3: boolean - Bi
+0001aa60: 6e61 7279 2d76 616c 7565 6420 6c6f 6769  nary-valued logi
+0001aa70: 633a 7b74 7275 652c 6661 6c73 657d 2229  c:{true,false}")
+0001aa80: 0a20 2020 2020 2020 2070 7269 6e74 280a  .        print(.
+0001aa90: 2020 2020 2020 2020 2020 2020 225c 7420              "\t 
+0001aaa0: 343a 2069 6e74 6567 6572 202d 2049 6e74  4: integer - Int
+0001aab0: 6567 6572 2069 7320 6120 6e75 6d62 6572  eger is a number
+0001aac0: 2074 6861 7420 6361 6e20 6265 2077 7269   that can be wri
+0001aad0: 7474 656e 2077 6974 686f 7574 2061 2066  tten without a f
+0001aae0: 7261 6374 696f 6e61 6c20 636f 6d70 6f6e  ractional compon
+0001aaf0: 656e 7422 0a20 2020 2020 2020 2029 0a20  ent".        ). 
+0001ab00: 2020 2020 2020 2070 7269 6e74 280a 2020         print(.  
+0001ab10: 2020 2020 2020 2020 2020 225c 7420 353a            "\t 5:
+0001ab20: 2066 6c6f 6174 202d 2046 6c6f 6174 2063   float - Float c
+0001ab30: 6f6e 7369 7374 7320 6f66 2074 6865 2076  onsists of the v
+0001ab40: 616c 7565 7320 6d20 c397 2032 5e65 2c20  alues m .. 2^e, 
+0001ab50: 7768 6572 6520 6d20 6973 2061 6e20 696e  where m is an in
+0001ab60: 7465 6765 7220 7768 6f73 6520 6162 736f  teger whose abso
+0001ab70: 6c75 7465 2076 616c 7565 2069 7320 6c65  lute value is le
+0001ab80: 7373 2074 6861 6e20 325e 3234 2c20 616e  ss than 2^24, an
+0001ab90: 6420 6520 6973 2061 6e20 696e 7465 6765  d e is an intege
+0001aba0: 7220 6265 7477 6565 6e20 2d31 3439 2061  r between -149 a
+0001abb0: 6e64 2031 3034 2c20 696e 636c 7573 6976  nd 104, inclusiv
+0001abc0: 6522 0a20 2020 2020 2020 2029 0a20 2020  e".        ).   
+0001abd0: 2020 2020 2070 7269 6e74 280a 2020 2020       print(.    
+0001abe0: 2020 2020 2020 2020 225c 7420 363a 2064          "\t 6: d
+0001abf0: 6f75 626c 6520 2d20 446f 7562 6c65 2063  ouble - Double c
+0001ac00: 6f6e 7369 7374 7320 6f66 2074 6865 2076  onsists of the v
+0001ac10: 616c 7565 7320 6d20 c397 2032 5e65 2c20  alues m .. 2^e, 
+0001ac20: 7768 6572 6520 6d20 6973 2061 6e20 696e  where m is an in
+0001ac30: 7465 6765 7220 7768 6f73 6520 6162 736f  teger whose abso
+0001ac40: 6c75 7465 2076 616c 7565 2069 7320 6c65  lute value is le
+0001ac50: 7373 2074 6861 6e20 325e 3533 2c20 616e  ss than 2^53, an
+0001ac60: 6420 6520 6973 2061 6e20 696e 7465 6765  d e is an intege
+0001ac70: 7220 6265 7477 6565 6e20 2d31 3037 3520  r between -1075 
+0001ac80: 616e 6420 3937 302c 2069 6e63 6c75 7369  and 970, inclusi
+0001ac90: 7665 220a 2020 2020 2020 2020 290a 2020  ve".        ).  
+0001aca0: 2020 2020 2020 7072 696e 7428 225c 7420        print("\t 
+0001acb0: 373a 2064 7572 6174 696f 6e20 2d20 4475  7: duration - Du
+0001acc0: 7261 7469 6f6e 2072 6570 7265 7365 6e74  ration represent
+0001acd0: 7320 6120 6475 7261 7469 6f6e 206f 6620  s a duration of 
+0001ace0: 7469 6d65 2229 0a20 2020 2020 2020 2070  time").        p
+0001acf0: 7269 6e74 280a 2020 2020 2020 2020 2020  rint(.          
+0001ad00: 2020 225c 7420 383a 2064 6174 6554 696d    "\t 8: dateTim
+0001ad10: 6520 2d20 5661 6c75 6573 2077 6974 6820  e - Values with 
+0001ad20: 696e 7465 6765 722d 7661 6c75 6564 2079  integer-valued y
+0001ad30: 6561 722c 206d 6f6e 7468 2c20 6461 792c  ear, month, day,
+0001ad40: 2068 6f75 7220 616e 6420 6d69 6e75 7465   hour and minute
+0001ad50: 2070 726f 7065 7274 6965 732c 2061 2064   properties, a d
+0001ad60: 6563 696d 616c 2d76 616c 7565 6420 7365  ecimal-valued se
+0001ad70: 636f 6e64 2070 726f 7065 7274 792c 2061  cond property, a
+0001ad80: 6e64 2061 2062 6f6f 6c65 616e 2074 696d  nd a boolean tim
+0001ad90: 657a 6f6e 6564 2070 726f 7065 7274 792e  ezoned property.
+0001ada0: 220a 2020 2020 2020 2020 290a 2020 2020  ".        ).    
+0001adb0: 2020 2020 7072 696e 7428 225c 7420 393a      print("\t 9:
+0001adc0: 2074 696d 6520 2d20 5469 6d65 2072 6570   time - Time rep
+0001add0: 7265 7365 6e74 7320 616e 2069 6e73 7461  resents an insta
+0001ade0: 6e74 206f 6620 7469 6d65 2074 6861 7420  nt of time that 
+0001adf0: 7265 6375 7273 2065 7665 7279 2064 6179  recurs every day
+0001ae00: 2229 0a20 2020 2020 2020 2070 7269 6e74  ").        print
+0001ae10: 280a 2020 2020 2020 2020 2020 2020 225c  (.            "\
+0001ae20: 7420 3130 3a20 6461 7465 202d 2044 6174  t 10: date - Dat
+0001ae30: 6520 636f 6e73 6973 7473 206f 6620 746f  e consists of to
+0001ae40: 702d 6f70 656e 2069 6e74 6572 7661 6c73  p-open intervals
+0001ae50: 206f 6620 6578 6163 746c 7920 6f6e 6520   of exactly one 
+0001ae60: 6461 7920 696e 206c 656e 6774 6820 6f6e  day in length on
+0001ae70: 2074 6865 2074 696d 656c 696e 6573 206f   the timelines o
+0001ae80: 6620 6461 7465 5469 6d65 2c20 6265 6769  f dateTime, begi
+0001ae90: 6e6e 696e 6720 6f6e 2074 6865 2062 6567  nning on the beg
+0001aea0: 696e 6e69 6e67 206d 6f6d 656e 7420 6f66  inning moment of
+0001aeb0: 2065 6163 6820 6461 7920 2869 6e20 6561   each day (in ea
+0001aec0: 6368 2074 696d 657a 6f6e 6529 220a 2020  ch timezone)".  
+0001aed0: 2020 2020 2020 290a 2020 2020 2020 2020        ).        
+0001aee0: 7072 696e 7428 0a20 2020 2020 2020 2020  print(.         
+0001aef0: 2020 2022 5c74 2031 313a 2061 6e79 5552     "\t 11: anyUR
+0001af00: 4920 2d20 616e 7955 5249 2072 6570 7265  I - anyURI repre
+0001af10: 7365 6e74 7320 6120 556e 6966 6f72 6d20  sents a Uniform 
+0001af20: 5265 736f 7572 6365 2049 6465 6e74 6966  Resource Identif
+0001af30: 6965 7220 5265 6665 7265 6e63 6520 2855  ier Reference (U
+0001af40: 5249 292e 2041 6e20 616e 7955 5249 2076  RI). An anyURI v
+0001af50: 616c 7565 2063 616e 2062 6520 6162 736f  alue can be abso
+0001af60: 6c75 7465 206f 7220 7265 6c61 7469 7665  lute or relative
+0001af70: 2c20 616e 6420 6d61 7920 6861 7665 2061  , and may have a
+0001af80: 6e20 6f70 7469 6f6e 616c 2066 7261 676d  n optional fragm
+0001af90: 656e 7420 6964 656e 7469 6669 6572 220a  ent identifier".
+0001afa0: 2020 2020 2020 2020 290a 2020 2020 2020          ).      
+0001afb0: 2020 7465 726d 5f64 6174 6174 7970 6520    term_datatype 
+0001afc0: 3d20 696e 7075 7428 2250 6c65 6173 6520  = input("Please 
+0001afd0: 656e 7465 7220 7468 6520 6461 7461 7479  enter the dataty
+0001afe0: 7065 205b 313a 3131 5d3a 5c74 2229 0a20  pe [1:11]:\t"). 
+0001aff0: 2020 2020 2020 2023 2063 6865 636b 2064         # check d
+0001b000: 6174 6174 7970 6573 2069 6620 6e6f 7420  atatypes if not 
+0001b010: 696e 205b 696e 7465 6765 722c 7265 616c  in [integer,real
+0001b020: 2c63 6174 6567 6f72 6963 616c 5d20 7265  ,categorical] re
+0001b030: 7065 6174 2075 6e74 696c 2069 7420 6973  peat until it is
+0001b040: 0a20 2020 2020 2020 2069 6620 696e 7428  .        if int(
+0001b050: 7465 726d 5f64 6174 6174 7970 6529 203e  term_datatype) >
+0001b060: 3d20 3120 616e 6420 696e 7428 7465 726d  = 1 and int(term
+0001b070: 5f64 6174 6174 7970 6529 203c 3d20 3131  _datatype) <= 11
+0001b080: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
+0001b090: 2069 6e74 2874 6572 6d5f 6461 7461 7479   int(term_dataty
+0001b0a0: 7065 2920 3d3d 2031 3a0a 2020 2020 2020  pe) == 1:.      
+0001b0b0: 2020 2020 2020 2020 2020 7465 726d 5f64            term_d
+0001b0c0: 6174 6174 7970 6520 3d20 5552 4952 6566  atatype = URIRef
+0001b0d0: 2843 6f6e 7374 616e 7473 2e58 5344 5b22  (Constants.XSD["
+0001b0e0: 7374 7269 6e67 225d 290a 2020 2020 2020  string"]).      
+0001b0f0: 2020 2020 2020 656c 6966 2069 6e74 2874        elif int(t
+0001b100: 6572 6d5f 6461 7461 7479 7065 2920 3d3d  erm_datatype) ==
+0001b110: 2033 3a0a 2020 2020 2020 2020 2020 2020   3:.            
+0001b120: 2020 2020 7465 726d 5f64 6174 6174 7970      term_datatyp
+0001b130: 6520 3d20 5552 4952 6566 2843 6f6e 7374  e = URIRef(Const
+0001b140: 616e 7473 2e58 5344 5b22 626f 6f6c 6561  ants.XSD["boolea
+0001b150: 6e22 5d29 0a20 2020 2020 2020 2020 2020  n"]).           
+0001b160: 2065 6c69 6620 696e 7428 7465 726d 5f64   elif int(term_d
+0001b170: 6174 6174 7970 6529 203d 3d20 343a 0a20  atatype) == 4:. 
+0001b180: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+0001b190: 6572 6d5f 6461 7461 7479 7065 203d 2055  erm_datatype = U
+0001b1a0: 5249 5265 6628 436f 6e73 7461 6e74 732e  RIRef(Constants.
+0001b1b0: 5853 445b 2269 6e74 6567 6572 225d 290a  XSD["integer"]).
+0001b1c0: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+0001b1d0: 2069 6e74 2874 6572 6d5f 6461 7461 7479   int(term_dataty
+0001b1e0: 7065 2920 3d3d 2035 3a0a 2020 2020 2020  pe) == 5:.      
+0001b1f0: 2020 2020 2020 2020 2020 7465 726d 5f64            term_d
+0001b200: 6174 6174 7970 6520 3d20 5552 4952 6566  atatype = URIRef
+0001b210: 2843 6f6e 7374 616e 7473 2e58 5344 5b22  (Constants.XSD["
+0001b220: 666c 6f61 7422 5d29 0a20 2020 2020 2020  float"]).       
+0001b230: 2020 2020 2065 6c69 6620 696e 7428 7465       elif int(te
+0001b240: 726d 5f64 6174 6174 7970 6529 203d 3d20  rm_datatype) == 
+0001b250: 363a 0a20 2020 2020 2020 2020 2020 2020  6:.             
+0001b260: 2020 2074 6572 6d5f 6461 7461 7479 7065     term_datatype
+0001b270: 203d 2055 5249 5265 6628 436f 6e73 7461   = URIRef(Consta
+0001b280: 6e74 732e 5853 445b 2264 6f75 626c 6522  nts.XSD["double"
+0001b290: 5d29 0a20 2020 2020 2020 2020 2020 2065  ]).            e
+0001b2a0: 6c69 6620 696e 7428 7465 726d 5f64 6174  lif int(term_dat
+0001b2b0: 6174 7970 6529 203d 3d20 373a 0a20 2020  atype) == 7:.   
+0001b2c0: 2020 2020 2020 2020 2020 2020 2074 6572               ter
+0001b2d0: 6d5f 6461 7461 7479 7065 203d 2055 5249  m_datatype = URI
+0001b2e0: 5265 6628 436f 6e73 7461 6e74 732e 5853  Ref(Constants.XS
+0001b2f0: 445b 2264 7572 6174 696f 6e22 5d29 0a20  D["duration"]). 
+0001b300: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+0001b310: 696e 7428 7465 726d 5f64 6174 6174 7970  int(term_datatyp
+0001b320: 6529 203d 3d20 383a 0a20 2020 2020 2020  e) == 8:.       
+0001b330: 2020 2020 2020 2020 2074 6572 6d5f 6461           term_da
+0001b340: 7461 7479 7065 203d 2055 5249 5265 6628  tatype = URIRef(
+0001b350: 436f 6e73 7461 6e74 732e 5853 445b 2264  Constants.XSD["d
+0001b360: 6174 6554 696d 6522 5d29 0a20 2020 2020  ateTime"]).     
+0001b370: 2020 2020 2020 2065 6c69 6620 696e 7428         elif int(
+0001b380: 7465 726d 5f64 6174 6174 7970 6529 203d  term_datatype) =
+0001b390: 3d20 393a 0a20 2020 2020 2020 2020 2020  = 9:.           
+0001b3a0: 2020 2020 2074 6572 6d5f 6461 7461 7479       term_dataty
+0001b3b0: 7065 203d 2055 5249 5265 6628 436f 6e73  pe = URIRef(Cons
+0001b3c0: 7461 6e74 732e 5853 445b 2274 696d 6522  tants.XSD["time"
+0001b3d0: 5d29 0a20 2020 2020 2020 2020 2020 2065  ]).            e
+0001b3e0: 6c69 6620 696e 7428 7465 726d 5f64 6174  lif int(term_dat
+0001b3f0: 6174 7970 6529 203d 3d20 3130 3a0a 2020  atype) == 10:.  
+0001b400: 2020 2020 2020 2020 2020 2020 2020 7465                te
+0001b410: 726d 5f64 6174 6174 7970 6520 3d20 5552  rm_datatype = UR
+0001b420: 4952 6566 2843 6f6e 7374 616e 7473 2e58  IRef(Constants.X
+0001b430: 5344 5b22 6461 7465 225d 290a 2020 2020  SD["date"]).    
+0001b440: 2020 2020 2020 2020 656c 6966 2069 6e74          elif int
+0001b450: 2874 6572 6d5f 6461 7461 7479 7065 2920  (term_datatype) 
+0001b460: 3d3d 2031 313a 0a20 2020 2020 2020 2020  == 11:.         
+0001b470: 2020 2020 2020 2074 6572 6d5f 6461 7461         term_data
+0001b480: 7479 7065 203d 2055 5249 5265 6628 436f  type = URIRef(Co
+0001b490: 6e73 7461 6e74 732e 5853 445b 2261 6e79  nstants.XSD["any
+0001b4a0: 5552 4922 5d29 0a20 2020 2020 2020 2020  URI"]).         
+0001b4b0: 2020 2065 6c69 6620 696e 7428 7465 726d     elif int(term
+0001b4c0: 5f64 6174 6174 7970 6529 203d 3d20 323a  _datatype) == 2:
+0001b4d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001b4e0: 2074 6572 6d5f 6461 7461 7479 7065 203d   term_datatype =
+0001b4f0: 2055 5249 5265 6628 436f 6e73 7461 6e74   URIRef(Constant
+0001b500: 732e 5853 445b 2263 6f6d 706c 6578 5479  s.XSD["complexTy
+0001b510: 7065 225d 290a 2020 2020 2020 2020 2020  pe"]).          
+0001b520: 2020 6272 6561 6b0a 0a20 2020 2023 206e    break..    # n
+0001b530: 6f77 2063 6865 636b 2069 6620 7465 726d  ow check if term
+0001b540: 5f64 6174 6174 7970 6520 6973 2063 6174  _datatype is cat
+0001b550: 6567 6f72 6963 616c 2061 6e64 2069 6620  egorical and if 
+0001b560: 736f 206c 6574 2773 2067 6574 2074 6865  so let's get the
+0001b570: 206c 6162 656c 203c 2d3e 2076 616c 7565   label <-> value
+0001b580: 206d 6170 7069 6e67 730a 2020 2020 6966   mappings.    if
+0001b590: 2074 6572 6d5f 6461 7461 7479 7065 203d   term_datatype =
+0001b5a0: 3d20 5552 4952 6566 2843 6f6e 7374 616e  = URIRef(Constan
+0001b5b0: 7473 2e58 5344 5b22 636f 6d70 6c65 7854  ts.XSD["complexT
+0001b5c0: 7970 6522 5d29 3a0a 2020 2020 2020 2020  ype"]):.        
+0001b5d0: 2320 6173 6b20 7573 6572 2066 6f72 2074  # ask user for t
+0001b5e0: 6865 206e 756d 6265 7220 6f66 2063 6174  he number of cat
+0001b5f0: 6567 6f72 6965 730a 2020 2020 2020 2020  egories.        
+0001b600: 7768 696c 6520 5472 7565 3a0a 2020 2020  while True:.    
+0001b610: 2020 2020 2020 2020 6e75 6d5f 6361 7465          num_cate
+0001b620: 676f 7269 6573 203d 2069 6e70 7574 280a  gories = input(.
+0001b630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b640: 2250 6c65 6173 6520 656e 7465 7220 7468  "Please enter th
+0001b650: 6520 6e75 6d62 6572 206f 6620 6361 7465  e number of cate
+0001b660: 676f 7269 6573 2f6c 6162 656c 7320 666f  gories/labels fo
+0001b670: 7220 7468 6973 2074 6572 6d3a 5c74 220a  r this term:\t".
+0001b680: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+0001b690: 2020 2020 2020 2020 2020 2320 6368 6563            # chec
+0001b6a0: 6b20 6966 2075 7365 7220 7375 7070 6c69  k if user suppli
+0001b6b0: 6564 2061 206e 756d 6265 7220 656c 7365  ed a number else
+0001b6c0: 2072 6570 6561 7420 7175 6573 7469 6f6e   repeat question
+0001b6d0: 0a20 2020 2020 2020 2020 2020 2074 7279  .            try
+0001b6e0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0001b6f0: 2020 696e 7428 6e75 6d5f 6361 7465 676f    int(num_catego
+0001b700: 7269 6573 290a 2020 2020 2020 2020 2020  ries).          
+0001b710: 2020 2020 2020 6272 6561 6b0a 2020 2020        break.    
+0001b720: 2020 2020 2020 2020 6578 6365 7074 2056          except V
+0001b730: 616c 7565 4572 726f 723a 0a20 2020 2020  alueError:.     
+0001b740: 2020 2020 2020 2020 2020 2070 7269 6e74             print
+0001b750: 2822 5468 6174 2773 206e 6f74 2061 6e20  ("That's not an 
+0001b760: 696e 7465 6765 722c 2070 6c65 6173 6520  integer, please 
+0001b770: 7472 7920 6167 6169 6e21 2229 0a0a 2020  try again!")..  
+0001b780: 2020 2020 2020 2320 6c6f 6f70 206f 7665        # loop ove
+0001b790: 7220 6e75 6d62 6572 206f 6620 6361 7465  r number of cate
+0001b7a0: 676f 7269 6573 2061 6e64 2063 6f6c 6c65  gories and colle
+0001b7b0: 6374 2069 6e66 6f72 6d61 7469 6f6e 0a20  ct information. 
+0001b7c0: 2020 2020 2020 2063 6174 5f76 616c 7565         cat_value
+0001b7d0: 203d 2069 6e70 7574 280a 2020 2020 2020   = input(.      
+0001b7e0: 2020 2020 2020 2241 7265 2074 6865 7265        "Are there
+0001b7f0: 206e 756d 6572 6963 616c 2076 616c 7565   numerical value
+0001b800: 7320 6173 736f 6369 6174 6564 2077 6974  s associated wit
+0001b810: 6820 796f 7572 2074 6578 742d 6261 7365  h your text-base
+0001b820: 6420 6361 7465 676f 7269 6573 205b 7965  d categories [ye
+0001b830: 735d 3f5c 7422 0a20 2020 2020 2020 2029  s]?\t".        )
+0001b840: 0a20 2020 2020 2020 2069 6620 2863 6174  .        if (cat
+0001b850: 5f76 616c 7565 2069 6e20 5b22 5922 2c20  _value in ["Y", 
+0001b860: 2279 222c 2022 5945 5322 2c20 2279 6573  "y", "YES", "yes
+0001b870: 222c 2022 5965 7322 5d29 206f 7220 2863  ", "Yes"]) or (c
+0001b880: 6174 5f76 616c 7565 203d 3d20 2222 293a  at_value == ""):
+0001b890: 0a20 2020 2020 2020 2020 2020 2023 2069  .            # i
+0001b8a0: 6620 7965 7320 7468 656e 2073 746f 7265  f yes then store
+0001b8b0: 2074 6869 7320 6173 2061 2064 6963 7469   this as a dicti
+0001b8c0: 6f6e 6172 7920 6361 745f 6c61 6265 6c3a  onary cat_label:
+0001b8d0: 2063 6174 5f76 616c 7565 0a20 2020 2020   cat_value.     
+0001b8e0: 2020 2020 2020 2074 6572 6d5f 6361 7465         term_cate
+0001b8f0: 676f 7279 203d 207b 7d0a 0a20 2020 2020  gory = {}..     
+0001b900: 2020 2020 2020 2066 6f72 2063 6174 6567         for categ
+0001b910: 6f72 7920 696e 2072 616e 6765 2831 2c20  ory in range(1, 
+0001b920: 696e 7428 6e75 6d5f 6361 7465 676f 7269  int(num_categori
+0001b930: 6573 2920 2b20 3129 3a0a 2020 2020 2020  es) + 1):.      
+0001b940: 2020 2020 2020 2020 2020 2320 7465 726d            # term
+0001b950: 2063 6174 6567 6f72 7920 6469 6374 696f   category dictio
+0001b960: 6e61 7279 2068 6173 206c 6162 656c 7320  nary has labels 
+0001b970: 6173 206b 6579 7320 616e 6420 7661 6c75  as keys and valu
+0001b980: 6520 6173 736f 6369 6174 6564 2077 6974  e associated wit
+0001b990: 6820 6c61 6265 6c20 6173 2076 616c 7565  h label as value
+0001b9a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001b9b0: 2063 6174 5f6c 6162 656c 203d 2069 6e70   cat_label = inp
+0001b9c0: 7574 280a 2020 2020 2020 2020 2020 2020  ut(.            
+0001b9d0: 2020 2020 2020 2020 6622 506c 6561 7365          f"Please
+0001b9e0: 2065 6e74 6572 2074 6865 2074 6578 7420   enter the text 
+0001b9f0: 7374 7269 6e67 206c 6162 656c 2066 6f72  string label for
+0001ba00: 2074 6865 2063 6174 6567 6f72 7920 7b63   the category {c
+0001ba10: 6174 6567 6f72 797d 3a5c 7422 0a20 2020  ategory}:\t".   
+0001ba20: 2020 2020 2020 2020 2020 2020 2029 0a20               ). 
+0001ba30: 2020 2020 2020 2020 2020 2020 2020 2063                 c
+0001ba40: 6174 5f76 616c 7565 203d 2069 6e70 7574  at_value = input
+0001ba50: 280a 2020 2020 2020 2020 2020 2020 2020  (.              
+0001ba60: 2020 2020 2020 6627 506c 6561 7365 2065        f'Please e
+0001ba70: 6e74 6572 2074 6865 2076 616c 7565 2061  nter the value a
+0001ba80: 7373 6f63 6961 7465 6420 7769 7468 206c  ssociated with l
+0001ba90: 6162 656c 2022 7b63 6174 5f6c 6162 656c  abel "{cat_label
+0001baa0: 7d22 3a5c 7427 0a20 2020 2020 2020 2020  }":\t'.         
+0001bab0: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0001bac0: 2020 2020 2020 2020 2074 6572 6d5f 6361           term_ca
+0001bad0: 7465 676f 7279 5b63 6174 5f6c 6162 656c  tegory[cat_label
+0001bae0: 5d20 3d20 6361 745f 7661 6c75 650a 0a20  ] = cat_value.. 
+0001baf0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+0001bb00: 2020 2020 2020 2020 2023 2069 6620 7765           # if we
+0001bb10: 206f 6e6c 7920 6861 7665 2074 6578 742d   only have text-
+0001bb20: 6261 7365 6420 6361 7465 676f 7269 6573  based categories
+0001bb30: 2074 6865 6e20 7374 6f72 6520 6173 2061   then store as a
+0001bb40: 206c 6973 740a 2020 2020 2020 2020 2020   list.          
+0001bb50: 2020 7465 726d 5f63 6174 6567 6f72 7920    term_category 
+0001bb60: 3d20 5b5d 0a20 2020 2020 2020 2020 2020  = [].           
+0001bb70: 2066 6f72 2063 6174 6567 6f72 7920 696e   for category in
+0001bb80: 2072 616e 6765 2831 2c20 696e 7428 6e75   range(1, int(nu
+0001bb90: 6d5f 6361 7465 676f 7269 6573 2920 2b20  m_categories) + 
+0001bba0: 3129 3a0a 2020 2020 2020 2020 2020 2020  1):.            
+0001bbb0: 2020 2020 2320 7465 726d 2063 6174 6567      # term categ
+0001bbc0: 6f72 7920 6469 6374 696f 6e61 7279 2068  ory dictionary h
+0001bbd0: 6173 206c 6162 656c 7320 6173 206b 6579  as labels as key
+0001bbe0: 7320 616e 6420 7661 6c75 6520 6173 736f  s and value asso
+0001bbf0: 6369 6174 6564 2077 6974 6820 6c61 6265  ciated with labe
+0001bc00: 6c20 6173 2076 616c 7565 0a20 2020 2020  l as value.     
+0001bc10: 2020 2020 2020 2020 2020 2063 6174 5f6c             cat_l
+0001bc20: 6162 656c 203d 2069 6e70 7574 280a 2020  abel = input(.  
+0001bc30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001bc40: 2020 6622 506c 6561 7365 2065 6e74 6572    f"Please enter
+0001bc50: 2074 6865 2074 6578 7420 7374 7269 6e67   the text string
+0001bc60: 206c 6162 656c 2066 6f72 2074 6865 2063   label for the c
+0001bc70: 6174 6567 6f72 7920 7b63 6174 6567 6f72  ategory {categor
+0001bc80: 797d 3a5c 7422 0a20 2020 2020 2020 2020  y}:\t".         
+0001bc90: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0001bca0: 2020 2020 2020 2020 2074 6572 6d5f 6361           term_ca
+0001bcb0: 7465 676f 7279 2e61 7070 656e 6428 6361  tegory.append(ca
+0001bcc0: 745f 6c61 6265 6c29 0a0a 2020 2020 2320  t_label)..    # 
+0001bcd0: 6966 2074 6572 6d20 6973 206e 6f74 2063  if term is not c
+0001bce0: 6174 6567 6f72 6963 616c 2074 6865 6e20  ategorical then 
+0001bcf0: 6173 6b20 666f 7220 6d69 6e2f 6d61 7820  ask for min/max 
+0001bd00: 7661 6c75 6573 2e20 2049 6620 6974 2069  values.  If it i
+0001bd10: 7320 6361 7465 676f 7269 6361 6c20 7468  s categorical th
+0001bd20: 656e 2073 696d 706c 7920 6578 7472 6163  en simply extrac
+0001bd30: 740a 2020 2020 2320 6974 2066 726f 6d20  t.    # it from 
+0001bd40: 7468 6520 7465 726d 5f63 6174 6567 6f72  the term_categor
+0001bd50: 7920 6469 6374 696f 6e61 7279 0a20 2020  y dictionary.   
+0001bd60: 2069 6620 7465 726d 5f64 6174 6174 7970   if term_datatyp
+0001bd70: 6520 213d 2055 5249 5265 6628 436f 6e73  e != URIRef(Cons
+0001bd80: 7461 6e74 732e 5853 445b 2263 6f6d 706c  tants.XSD["compl
+0001bd90: 6578 5479 7065 225d 293a 0a20 2020 2020  exType"]):.     
+0001bda0: 2020 2074 6572 6d5f 6d69 6e20 3d20 696e     term_min = in
+0001bdb0: 7075 7428 2250 6c65 6173 6520 656e 7465  put("Please ente
+0001bdc0: 7220 7468 6520 6d69 6e69 6d75 6d20 7661  r the minimum va
+0001bdd0: 6c75 6520 5b4e 415d 3a5c 7422 290a 2020  lue [NA]:\t").  
+0001bde0: 2020 2020 2020 7465 726d 5f6d 6178 203d        term_max =
+0001bdf0: 2069 6e70 7574 2822 506c 6561 7365 2065   input("Please e
+0001be00: 6e74 6572 2074 6865 206d 6178 696d 756d  nter the maximum
+0001be10: 2076 616c 7565 205b 4e41 5d3a 5c74 2229   value [NA]:\t")
+0001be20: 0a20 2020 2020 2020 2074 6572 6d5f 756e  .        term_un
+0001be30: 6974 7320 3d20 696e 7075 7428 2250 6c65  its = input("Ple
+0001be40: 6173 6520 656e 7465 7220 7468 6520 756e  ase enter the un
+0001be50: 6974 7320 5b4e 415d 3a5c 7422 290a 2020  its [NA]:\t").  
+0001be60: 2020 2020 2020 2320 6368 6563 6b20 6966        # check if
+0001be70: 2072 6573 706f 6e73 654f 7074 696f 6e73   responseOptions
+0001be80: 2069 7320 6120 6b65 792c 2069 6620 6e6f   is a key, if no
+0001be90: 7420 6372 6561 7465 2069 740a 2020 2020  t create it.    
+0001bea0: 2020 2020 6966 2022 7265 7370 6f6e 7365      if "response
+0001beb0: 4f70 7469 6f6e 7322 206e 6f74 2069 6e20  Options" not in 
+0001bec0: 736f 7572 6365 5f76 6172 6961 626c 655f  source_variable_
+0001bed0: 616e 6e6f 7461 7469 6f6e 735b 6375 7272  annotations[curr
+0001bee0: 656e 745f 7475 706c 655d 2e6b 6579 7328  ent_tuple].keys(
+0001bef0: 293a 0a20 2020 2020 2020 2020 2020 2073  ):.            s
+0001bf00: 6f75 7263 655f 7661 7269 6162 6c65 5f61  ource_variable_a
+0001bf10: 6e6e 6f74 6174 696f 6e73 5b63 7572 7265  nnotations[curre
+0001bf20: 6e74 5f74 7570 6c65 5d5b 2272 6573 706f  nt_tuple]["respo
+0001bf30: 6e73 654f 7074 696f 6e73 225d 203d 207b  nseOptions"] = {
+0001bf40: 7d0a 2020 2020 2020 2020 2320 6966 2075  }.        # if u
+0001bf50: 7365 7220 7365 7420 616e 7920 6f66 2074  ser set any of t
+0001bf60: 6865 7365 2074 6865 6e20 7374 6f72 6520  hese then store 
+0001bf70: 656c 7365 2069 676e 6f72 650a 2020 2020  else ignore.    
+0001bf80: 2020 2020 736f 7572 6365 5f76 6172 6961      source_varia
+0001bf90: 626c 655f 616e 6e6f 7461 7469 6f6e 735b  ble_annotations[
+0001bfa0: 6375 7272 656e 745f 7475 706c 655d 5b22  current_tuple]["
+0001bfb0: 7265 7370 6f6e 7365 4f70 7469 6f6e 7322  responseOptions"
+0001bfc0: 5d5b 0a20 2020 2020 2020 2020 2020 2022  ][.            "
+0001bfd0: 756e 6974 436f 6465 220a 2020 2020 2020  unitCode".      
+0001bfe0: 2020 5d20 3d20 7465 726d 5f75 6e69 7473    ] = term_units
+0001bff0: 0a20 2020 2020 2020 2073 6f75 7263 655f  .        source_
+0001c000: 7661 7269 6162 6c65 5f61 6e6e 6f74 6174  variable_annotat
+0001c010: 696f 6e73 5b63 7572 7265 6e74 5f74 7570  ions[current_tup
+0001c020: 6c65 5d5b 2272 6573 706f 6e73 654f 7074  le]["responseOpt
+0001c030: 696f 6e73 225d 5b0a 2020 2020 2020 2020  ions"][.        
+0001c040: 2020 2020 226d 696e 5661 6c75 6522 0a20      "minValue". 
+0001c050: 2020 2020 2020 205d 203d 2074 6572 6d5f         ] = term_
+0001c060: 6d69 6e0a 2020 2020 2020 2020 736f 7572  min.        sour
+0001c070: 6365 5f76 6172 6961 626c 655f 616e 6e6f  ce_variable_anno
+0001c080: 7461 7469 6f6e 735b 6375 7272 656e 745f  tations[current_
+0001c090: 7475 706c 655d 5b22 7265 7370 6f6e 7365  tuple]["response
+0001c0a0: 4f70 7469 6f6e 7322 5d5b 0a20 2020 2020  Options"][.     
+0001c0b0: 2020 2020 2020 2022 6d61 7856 616c 7565         "maxValue
+0001c0c0: 220a 2020 2020 2020 2020 5d20 3d20 7465  ".        ] = te
+0001c0d0: 726d 5f6d 6178 0a0a 2020 2020 2320 6966  rm_max..    # if
+0001c0e0: 2074 6865 2063 6174 6567 6f72 6963 616c   the categorical
+0001c0f0: 2064 6174 6120 6861 7320 6e75 6d65 7269   data has numeri
+0001c100: 6320 7661 6c75 6573 2074 6865 6e20 7765  c values then we
+0001c110: 2063 616e 2069 6e66 6572 2061 206d 696e   can infer a min
+0001c120: 2f6d 6178 0a20 2020 2065 6c69 6620 6361  /max.    elif ca
+0001c130: 745f 7661 6c75 6520 696e 205b 2259 222c  t_value in ["Y",
+0001c140: 2022 7922 2c20 2259 4553 222c 2022 7965   "y", "YES", "ye
+0001c150: 7322 2c20 2259 6573 225d 3a0a 2020 2020  s", "Yes"]:.    
+0001c160: 2020 2020 2320 6368 6563 6b20 6966 2072      # check if r
+0001c170: 6573 706f 6e73 654f 7074 696f 6e73 2069  esponseOptions i
+0001c180: 7320 6120 6b65 792c 2069 6620 6e6f 7420  s a key, if not 
+0001c190: 6372 6561 7465 2069 740a 2020 2020 2020  create it.      
+0001c1a0: 2020 6966 2022 7265 7370 6f6e 7365 4f70    if "responseOp
+0001c1b0: 7469 6f6e 7322 206e 6f74 2069 6e20 736f  tions" not in so
+0001c1c0: 7572 6365 5f76 6172 6961 626c 655f 616e  urce_variable_an
+0001c1d0: 6e6f 7461 7469 6f6e 735b 6375 7272 656e  notations[curren
+0001c1e0: 745f 7475 706c 655d 2e6b 6579 7328 293a  t_tuple].keys():
+0001c1f0: 0a20 2020 2020 2020 2020 2020 2073 6f75  .            sou
+0001c200: 7263 655f 7661 7269 6162 6c65 5f61 6e6e  rce_variable_ann
+0001c210: 6f74 6174 696f 6e73 5b63 7572 7265 6e74  otations[current
+0001c220: 5f74 7570 6c65 5d5b 2272 6573 706f 6e73  _tuple]["respons
+0001c230: 654f 7074 696f 6e73 225d 203d 207b 7d0a  eOptions"] = {}.
+0001c240: 2020 2020 2020 2020 736f 7572 6365 5f76          source_v
+0001c250: 6172 6961 626c 655f 616e 6e6f 7461 7469  ariable_annotati
+0001c260: 6f6e 735b 6375 7272 656e 745f 7475 706c  ons[current_tupl
+0001c270: 655d 5b22 7265 7370 6f6e 7365 4f70 7469  e]["responseOpti
+0001c280: 6f6e 7322 5d5b 226d 696e 5661 6c75 6522  ons"]["minValue"
+0001c290: 5d20 3d20 6d69 6e28 0a20 2020 2020 2020  ] = min(.       
+0001c2a0: 2020 2020 2074 6572 6d5f 6361 7465 676f       term_catego
+0001c2b0: 7279 2e76 616c 7565 7328 290a 2020 2020  ry.values().    
+0001c2c0: 2020 2020 290a 2020 2020 2020 2020 736f      ).        so
+0001c2d0: 7572 6365 5f76 6172 6961 626c 655f 616e  urce_variable_an
+0001c2e0: 6e6f 7461 7469 6f6e 735b 6375 7272 656e  notations[curren
+0001c2f0: 745f 7475 706c 655d 5b22 7265 7370 6f6e  t_tuple]["respon
+0001c300: 7365 4f70 7469 6f6e 7322 5d5b 226d 6178  seOptions"]["max
+0001c310: 5661 6c75 6522 5d20 3d20 6d61 7828 0a20  Value"] = max(. 
+0001c320: 2020 2020 2020 2020 2020 2074 6572 6d5f             term_
+0001c330: 6361 7465 676f 7279 2e76 616c 7565 7328  category.values(
+0001c340: 290a 2020 2020 2020 2020 290a 2020 2020  ).        ).    
+0001c350: 2020 2020 736f 7572 6365 5f76 6172 6961      source_varia
+0001c360: 626c 655f 616e 6e6f 7461 7469 6f6e 735b  ble_annotations[
+0001c370: 6375 7272 656e 745f 7475 706c 655d 5b22  current_tuple]["
+0001c380: 7265 7370 6f6e 7365 4f70 7469 6f6e 7322  responseOptions"
+0001c390: 5d5b 2275 6e69 7443 6f64 6522 5d20 3d20  ]["unitCode"] = 
+0001c3a0: 224e 4122 0a20 2020 2023 2063 6174 6567  "NA".    # categ
+0001c3b0: 6f72 6963 616c 2077 6974 6820 6e6f 206d  orical with no m
+0001c3c0: 696e 2f6d 6178 2076 616c 7565 730a 2020  in/max values.  
+0001c3d0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0001c3e0: 2320 6368 6563 6b20 6966 2072 6573 706f  # check if respo
+0001c3f0: 6e73 654f 7074 696f 6e73 2069 7320 6120  nseOptions is a 
+0001c400: 6b65 792c 2069 6620 6e6f 7420 6372 6561  key, if not crea
+0001c410: 7465 2069 740a 2020 2020 2020 2020 6966  te it.        if
+0001c420: 2022 7265 7370 6f6e 7365 4f70 7469 6f6e   "responseOption
+0001c430: 7322 206e 6f74 2069 6e20 736f 7572 6365  s" not in source
+0001c440: 5f76 6172 6961 626c 655f 616e 6e6f 7461  _variable_annota
+0001c450: 7469 6f6e 735b 6375 7272 656e 745f 7475  tions[current_tu
+0001c460: 706c 655d 2e6b 6579 7328 293a 0a20 2020  ple].keys():.   
+0001c470: 2020 2020 2020 2020 2073 6f75 7263 655f           source_
+0001c480: 7661 7269 6162 6c65 5f61 6e6e 6f74 6174  variable_annotat
+0001c490: 696f 6e73 5b63 7572 7265 6e74 5f74 7570  ions[current_tup
+0001c4a0: 6c65 5d5b 2272 6573 706f 6e73 654f 7074  le]["responseOpt
+0001c4b0: 696f 6e73 225d 203d 207b 7d0a 2020 2020  ions"] = {}.    
+0001c4c0: 2020 2020 736f 7572 6365 5f76 6172 6961      source_varia
+0001c4d0: 626c 655f 616e 6e6f 7461 7469 6f6e 735b  ble_annotations[
+0001c4e0: 6375 7272 656e 745f 7475 706c 655d 5b22  current_tuple]["
+0001c4f0: 7265 7370 6f6e 7365 4f70 7469 6f6e 7322  responseOptions"
+0001c500: 5d5b 226d 696e 5661 6c75 6522 5d20 3d20  ]["minValue"] = 
+0001c510: 224e 4122 0a20 2020 2020 2020 2073 6f75  "NA".        sou
+0001c520: 7263 655f 7661 7269 6162 6c65 5f61 6e6e  rce_variable_ann
+0001c530: 6f74 6174 696f 6e73 5b63 7572 7265 6e74  otations[current
+0001c540: 5f74 7570 6c65 5d5b 2272 6573 706f 6e73  _tuple]["respons
+0001c550: 654f 7074 696f 6e73 225d 5b22 6d61 7856  eOptions"]["maxV
+0001c560: 616c 7565 225d 203d 2022 4e41 220a 2020  alue"] = "NA".  
+0001c570: 2020 2020 2020 736f 7572 6365 5f76 6172        source_var
+0001c580: 6961 626c 655f 616e 6e6f 7461 7469 6f6e  iable_annotation
+0001c590: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+0001c5a0: 5b22 7265 7370 6f6e 7365 4f70 7469 6f6e  ["responseOption
+0001c5b0: 7322 5d5b 2275 6e69 7443 6f64 6522 5d20  s"]["unitCode"] 
+0001c5c0: 3d20 224e 4122 0a0a 2020 2020 2320 7374  = "NA"..    # st
+0001c5d0: 6f72 6520 7465 726d 2069 6e66 6f20 696e  ore term info in
+0001c5e0: 2064 6963 7469 6f6e 6172 790a 2020 2020   dictionary.    
+0001c5f0: 2320 6368 6563 6b20 6966 2072 6573 706f  # check if respo
+0001c600: 6e73 654f 7074 696f 6e73 2069 7320 6120  nseOptions is a 
+0001c610: 6b65 792c 2069 6620 6e6f 7420 6372 6561  key, if not crea
+0001c620: 7465 2069 740a 2020 2020 6966 2022 7265  te it.    if "re
+0001c630: 7370 6f6e 7365 4f70 7469 6f6e 7322 206e  sponseOptions" n
+0001c640: 6f74 2069 6e20 736f 7572 6365 5f76 6172  ot in source_var
+0001c650: 6961 626c 655f 616e 6e6f 7461 7469 6f6e  iable_annotation
+0001c660: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+0001c670: 2e6b 6579 7328 293a 0a20 2020 2020 2020  .keys():.       
+0001c680: 2073 6f75 7263 655f 7661 7269 6162 6c65   source_variable
+0001c690: 5f61 6e6e 6f74 6174 696f 6e73 5b63 7572  _annotations[cur
+0001c6a0: 7265 6e74 5f74 7570 6c65 5d5b 2272 6573  rent_tuple]["res
+0001c6b0: 706f 6e73 654f 7074 696f 6e73 225d 203d  ponseOptions"] =
+0001c6c0: 207b 7d0a 2020 2020 736f 7572 6365 5f76   {}.    source_v
+0001c6d0: 6172 6961 626c 655f 616e 6e6f 7461 7469  ariable_annotati
+0001c6e0: 6f6e 735b 6375 7272 656e 745f 7475 706c  ons[current_tupl
+0001c6f0: 655d 5b22 6c61 6265 6c22 5d20 3d20 7465  e]["label"] = te
+0001c700: 726d 5f6c 6162 656c 0a20 2020 2073 6f75  rm_label.    sou
+0001c710: 7263 655f 7661 7269 6162 6c65 5f61 6e6e  rce_variable_ann
+0001c720: 6f74 6174 696f 6e73 5b63 7572 7265 6e74  otations[current
+0001c730: 5f74 7570 6c65 5d5b 2264 6573 6372 6970  _tuple]["descrip
+0001c740: 7469 6f6e 225d 203d 2074 6572 6d5f 6465  tion"] = term_de
+0001c750: 6669 6e69 7469 6f6e 0a20 2020 2073 6f75  finition.    sou
+0001c760: 7263 655f 7661 7269 6162 6c65 5f61 6e6e  rce_variable_ann
+0001c770: 6f74 6174 696f 6e73 5b63 7572 7265 6e74  otations[current
+0001c780: 5f74 7570 6c65 5d5b 2273 6f75 7263 655f  _tuple]["source_
+0001c790: 7661 7269 6162 6c65 225d 203d 2073 7472  variable"] = str
+0001c7a0: 2873 6f75 7263 655f 7661 7269 6162 6c65  (source_variable
+0001c7b0: 290a 2020 2020 736f 7572 6365 5f76 6172  ).    source_var
+0001c7c0: 6961 626c 655f 616e 6e6f 7461 7469 6f6e  iable_annotation
+0001c7d0: 735b 6375 7272 656e 745f 7475 706c 655d  s[current_tuple]
+0001c7e0: 5b22 7265 7370 6f6e 7365 4f70 7469 6f6e  ["responseOption
+0001c7f0: 7322 5d5b 0a20 2020 2020 2020 2022 7661  s"][.        "va
+0001c800: 6c75 6554 7970 6522 0a20 2020 205d 203d  lueType".    ] =
+0001c810: 2074 6572 6d5f 6461 7461 7479 7065 0a20   term_datatype. 
+0001c820: 2020 2073 6f75 7263 655f 7661 7269 6162     source_variab
+0001c830: 6c65 5f61 6e6e 6f74 6174 696f 6e73 5b63  le_annotations[c
+0001c840: 7572 7265 6e74 5f74 7570 6c65 5d5b 2261  urrent_tuple]["a
+0001c850: 7373 6f63 6961 7465 6457 6974 6822 5d20  ssociatedWith"] 
+0001c860: 3d20 224e 4944 4d22 0a0a 2020 2020 6966  = "NIDM"..    if
+0001c870: 2074 6572 6d5f 6461 7461 7479 7065 203d   term_datatype =
+0001c880: 3d20 5552 4952 6566 2843 6f6e 7374 616e  = URIRef(Constan
+0001c890: 7473 2e58 5344 5b22 636f 6d70 6c65 7854  ts.XSD["complexT
+0001c8a0: 7970 6522 5d29 3a0a 2020 2020 2020 2020  ype"]):.        
+0001c8b0: 736f 7572 6365 5f76 6172 6961 626c 655f  source_variable_
+0001c8c0: 616e 6e6f 7461 7469 6f6e 735b 6375 7272  annotations[curr
+0001c8d0: 656e 745f 7475 706c 655d 5b22 7265 7370  ent_tuple]["resp
+0001c8e0: 6f6e 7365 4f70 7469 6f6e 7322 5d5b 0a20  onseOptions"][. 
+0001c8f0: 2020 2020 2020 2020 2020 2022 6368 6f69             "choi
+0001c900: 6365 7322 0a20 2020 2020 2020 205d 203d  ces".        ] =
+0001c910: 2074 6572 6d5f 6361 7465 676f 7279 0a0a   term_category..
+0001c920: 2020 2020 2320 7072 696e 7420 6d61 7070      # print mapp
+0001c930: 696e 6773 0a20 2020 2070 7269 6e74 2822  ings.    print("
+0001c940: 5c6e 2220 2b20 2822 2a22 202a 2038 3529  \n" + ("*" * 85)
+0001c950: 290a 2020 2020 7072 696e 7428 6622 5374  ).    print(f"St
+0001c960: 6f72 6564 206d 6170 7069 6e67 3a20 7b73  ored mapping: {s
+0001c970: 6f75 7263 655f 7661 7269 6162 6c65 7d20  ource_variable} 
+0001c980: 2d3e 2020 2229 0a20 2020 2070 7269 6e74  ->  ").    print
+0001c990: 2822 6c61 6265 6c3a 222c 2073 6f75 7263  ("label:", sourc
+0001c9a0: 655f 7661 7269 6162 6c65 5f61 6e6e 6f74  e_variable_annot
+0001c9b0: 6174 696f 6e73 5b63 7572 7265 6e74 5f74  ations[current_t
+0001c9c0: 7570 6c65 5d5b 226c 6162 656c 225d 290a  uple]["label"]).
+0001c9d0: 2020 2020 7072 696e 7428 0a20 2020 2020      print(.     
+0001c9e0: 2020 2022 736f 7572 6365 2076 6172 6961     "source varia
+0001c9f0: 626c 653a 222c 0a20 2020 2020 2020 2073  ble:",.        s
+0001ca00: 6f75 7263 655f 7661 7269 6162 6c65 5f61  ource_variable_a
+0001ca10: 6e6e 6f74 6174 696f 6e73 5b63 7572 7265  nnotations[curre
+0001ca20: 6e74 5f74 7570 6c65 5d5b 2273 6f75 7263  nt_tuple]["sourc
+0001ca30: 655f 7661 7269 6162 6c65 225d 2c0a 2020  e_variable"],.  
+0001ca40: 2020 290a 2020 2020 7072 696e 7428 2264    ).    print("d
+0001ca50: 6573 6372 6970 7469 6f6e 3a22 2c20 736f  escription:", so
+0001ca60: 7572 6365 5f76 6172 6961 626c 655f 616e  urce_variable_an
+0001ca70: 6e6f 7461 7469 6f6e 735b 6375 7272 656e  notations[curren
+0001ca80: 745f 7475 706c 655d 5b22 6465 7363 7269  t_tuple]["descri
+0001ca90: 7074 696f 6e22 5d29 0a20 2020 2070 7269  ption"]).    pri
+0001caa0: 6e74 280a 2020 2020 2020 2020 2276 616c  nt(.        "val
+0001cab0: 7565 5479 7065 3a22 2c0a 2020 2020 2020  ueType:",.      
+0001cac0: 2020 736f 7572 6365 5f76 6172 6961 626c    source_variabl
+0001cad0: 655f 616e 6e6f 7461 7469 6f6e 735b 6375  e_annotations[cu
+0001cae0: 7272 656e 745f 7475 706c 655d 5b22 7265  rrent_tuple]["re
+0001caf0: 7370 6f6e 7365 4f70 7469 6f6e 7322 5d5b  sponseOptions"][
+0001cb00: 2276 616c 7565 5479 7065 225d 2c0a 2020  "valueType"],.  
+0001cb10: 2020 290a 2020 2020 2320 6c65 6674 2066    ).    # left f
+0001cb20: 6f72 206c 6567 6163 7920 7075 7270 6f73  or legacy purpos
+0001cb30: 6573 0a20 2020 2069 6620 2268 6173 556e  es.    if "hasUn
+0001cb40: 6974 2220 696e 2073 6f75 7263 655f 7661  it" in source_va
+0001cb50: 7269 6162 6c65 5f61 6e6e 6f74 6174 696f  riable_annotatio
+0001cb60: 6e73 5b63 7572 7265 6e74 5f74 7570 6c65  ns[current_tuple
+0001cb70: 5d3a 0a20 2020 2020 2020 2070 7269 6e74  ]:.        print
+0001cb80: 2822 6861 7355 6e69 743a 222c 2073 6f75  ("hasUnit:", sou
+0001cb90: 7263 655f 7661 7269 6162 6c65 5f61 6e6e  rce_variable_ann
+0001cba0: 6f74 6174 696f 6e73 5b63 7572 7265 6e74  otations[current
+0001cbb0: 5f74 7570 6c65 5d5b 2268 6173 556e 6974  _tuple]["hasUnit
+0001cbc0: 225d 290a 2020 2020 656c 6966 2022 756e  "]).    elif "un
+0001cbd0: 6974 436f 6465 2220 696e 2073 6f75 7263  itCode" in sourc
+0001cbe0: 655f 7661 7269 6162 6c65 5f61 6e6e 6f74  e_variable_annot
+0001cbf0: 6174 696f 6e73 5b63 7572 7265 6e74 5f74  ations[current_t
+0001cc00: 7570 6c65 5d5b 2272 6573 706f 6e73 654f  uple]["responseO
+0001cc10: 7074 696f 6e73 225d 3a0a 2020 2020 2020  ptions"]:.      
+0001cc20: 2020 7072 696e 7428 0a20 2020 2020 2020    print(.       
+0001cc30: 2020 2020 2022 6861 7355 6e69 743a 222c       "hasUnit:",
+0001cc40: 0a20 2020 2020 2020 2020 2020 2073 6f75  .            sou
+0001cc50: 7263 655f 7661 7269 6162 6c65 5f61 6e6e  rce_variable_ann
+0001cc60: 6f74 6174 696f 6e73 5b63 7572 7265 6e74  otations[current
+0001cc70: 5f74 7570 6c65 5d5b 2272 6573 706f 6e73  _tuple]["respons
+0001cc80: 654f 7074 696f 6e73 225d 5b22 756e 6974  eOptions"]["unit
+0001cc90: 436f 6465 225d 2c0a 2020 2020 2020 2020  Code"],.        
+0001cca0: 290a 2020 2020 6966 2022 6d69 6e56 616c  ).    if "minVal
+0001ccb0: 7565 2220 696e 2073 6f75 7263 655f 7661  ue" in source_va
+0001ccc0: 7269 6162 6c65 5f61 6e6e 6f74 6174 696f  riable_annotatio
+0001ccd0: 6e73 5b63 7572 7265 6e74 5f74 7570 6c65  ns[current_tuple
+0001cce0: 5d5b 2272 6573 706f 6e73 654f 7074 696f  ]["responseOptio
+0001ccf0: 6e73 225d 3a0a 2020 2020 2020 2020 7072  ns"]:.        pr
+0001cd00: 696e 7428 0a20 2020 2020 2020 2020 2020  int(.           
+0001cd10: 2022 6d69 6e69 6d75 6d56 616c 7565 3a22   "minimumValue:"
+0001cd20: 2c0a 2020 2020 2020 2020 2020 2020 736f  ,.            so
+0001cd30: 7572 6365 5f76 6172 6961 626c 655f 616e  urce_variable_an
+0001cd40: 6e6f 7461 7469 6f6e 735b 6375 7272 656e  notations[curren
+0001cd50: 745f 7475 706c 655d 5b22 7265 7370 6f6e  t_tuple]["respon
+0001cd60: 7365 4f70 7469 6f6e 7322 5d5b 226d 696e  seOptions"]["min
+0001cd70: 5661 6c75 6522 5d2c 0a20 2020 2020 2020  Value"],.       
+0001cd80: 2029 0a20 2020 2069 6620 226d 6178 5661   ).    if "maxVa
+0001cd90: 6c75 6522 2069 6e20 736f 7572 6365 5f76  lue" in source_v
+0001cda0: 6172 6961 626c 655f 616e 6e6f 7461 7469  ariable_annotati
+0001cdb0: 6f6e 735b 6375 7272 656e 745f 7475 706c  ons[current_tupl
+0001cdc0: 655d 5b22 7265 7370 6f6e 7365 4f70 7469  e]["responseOpti
+0001cdd0: 6f6e 7322 5d3a 0a20 2020 2020 2020 2070  ons"]:.        p
+0001cde0: 7269 6e74 280a 2020 2020 2020 2020 2020  rint(.          
+0001cdf0: 2020 226d 6178 696d 756d 5661 6c75 653a    "maximumValue:
+0001ce00: 222c 0a20 2020 2020 2020 2020 2020 2073  ",.            s
+0001ce10: 6f75 7263 655f 7661 7269 6162 6c65 5f61  ource_variable_a
+0001ce20: 6e6e 6f74 6174 696f 6e73 5b63 7572 7265  nnotations[curre
+0001ce30: 6e74 5f74 7570 6c65 5d5b 2272 6573 706f  nt_tuple]["respo
+0001ce40: 6e73 654f 7074 696f 6e73 225d 5b22 6d61  nseOptions"]["ma
+0001ce50: 7856 616c 7565 225d 2c0a 2020 2020 2020  xValue"],.      
+0001ce60: 2020 290a 2020 2020 6966 2074 6572 6d5f    ).    if term_
+0001ce70: 6461 7461 7479 7065 203d 3d20 5552 4952  datatype == URIR
+0001ce80: 6566 2843 6f6e 7374 616e 7473 2e58 5344  ef(Constants.XSD
+0001ce90: 5b22 636f 6d70 6c65 7854 7970 6522 5d29  ["complexType"])
+0001cea0: 3a0a 2020 2020 2020 2020 7072 696e 7428  :.        print(
+0001ceb0: 0a20 2020 2020 2020 2020 2020 2022 6368  .            "ch
+0001cec0: 6f69 6365 733a 222c 0a20 2020 2020 2020  oices:",.       
+0001ced0: 2020 2020 2073 6f75 7263 655f 7661 7269       source_vari
+0001cee0: 6162 6c65 5f61 6e6e 6f74 6174 696f 6e73  able_annotations
+0001cef0: 5b63 7572 7265 6e74 5f74 7570 6c65 5d5b  [current_tuple][
+0001cf00: 2272 6573 706f 6e73 654f 7074 696f 6e73  "responseOptions
+0001cf10: 225d 5b22 6368 6f69 6365 7322 5d2c 0a20  "]["choices"],. 
+0001cf20: 2020 2020 2020 2029 0a20 2020 2070 7269         ).    pri
+0001cf30: 6e74 2822 2d22 202a 2038 3729 0a0a 0a64  nt("-" * 87)...d
+0001cf40: 6566 2044 445f 5555 4944 2865 6c65 6d65  ef DD_UUID(eleme
+0001cf50: 6e74 2c20 6464 5f73 7472 7563 742c 2064  nt, dd_struct, d
+0001cf60: 6174 6173 6574 5f69 6465 6e74 6966 6965  ataset_identifie
+0001cf70: 723d 4e6f 6e65 293a 0a20 2020 2022 2222  r=None):.    """
+0001cf80: 0a20 2020 2054 6869 7320 6675 6e63 7469  .    This functi
+0001cf90: 6f6e 2077 696c 6c20 7072 6f64 7563 6520  on will produce 
+0001cfa0: 6120 6861 7368 206f 6620 7468 6520 6461  a hash of the da
+0001cfb0: 7461 2064 6963 7469 6f6e 6172 7920 2870  ta dictionary (p
+0001cfc0: 6572 736f 6e61 6c20 6461 7461 2065 6c65  ersonal data ele
+0001cfd0: 6d65 6e74 2920 7072 6f70 6572 7469 6573  ment) properties
+0001cfe0: 2064 6566 696e 6564 0a20 2020 2062 7920   defined.    by 
+0001cff0: 7468 6520 7573 6572 2066 6f72 2075 7365  the user for use
+0001d000: 2061 7320 6120 5555 4944 2e20 2054 6865   as a UUID.  The
+0001d010: 2064 6174 6120 6469 6374 696f 6e61 7279   data dictionary
+0001d020: 206b 6579 2069 7320 6120 7475 706c 6520   key is a tuple 
+0001d030: 6964 656e 7469 6679 696e 6720 7468 6520  identifying the 
+0001d040: 6669 6c65 2061 6e64 2076 6172 6961 626c  file and variabl
+0001d050: 650a 2020 2020 6e61 6d65 2077 6974 6869  e.    name withi
+0001d060: 6e20 7468 6174 2066 696c 6520 746f 2062  n that file to b
+0001d070: 6520 656e 636f 6465 6420 7769 7468 2061  e encoded with a
+0001d080: 2055 5549 442e 2020 5468 6520 6964 6561   UUID.  The idea
+0001d090: 2069 7320 7468 6174 2069 6620 7468 6520   is that if the 
+0001d0a0: 6461 7461 2064 6963 7469 6f6e 6172 6965  data dictionarie
+0001d0b0: 7320 666f 7220 610a 2020 2020 7065 7273  s for a.    pers
+0001d0c0: 6f6e 616c 2064 6174 6120 656c 656d 656e  onal data elemen
+0001d0d0: 7420 7072 6563 6973 656c 7920 6d61 7463  t precisely matc
+0001d0e0: 6820 7468 656e 2074 6865 2073 616d 6520  h then the same 
+0001d0f0: 5555 4944 2077 696c 6c20 6265 2067 656e  UUID will be gen
+0001d100: 6572 6174 6564 2e0a 2020 2020 3a70 6172  erated..    :par
+0001d110: 616d 2065 6c65 6d65 6e74 3a20 656c 656d  am element: elem
+0001d120: 656e 7420 696e 2064 645f 7374 7275 6374  ent in dd_struct
+0001d130: 2074 6f20 6372 6561 7465 2055 5549 4420   to create UUID 
+0001d140: 666f 7220 7769 7468 696e 2074 6865 2064  for within the d
+0001d150: 645f 7374 7275 6374 0a20 2020 203a 7061  d_struct.    :pa
+0001d160: 7261 6d20 6464 5f73 7472 7563 743a 2064  ram dd_struct: d
+0001d170: 6174 6120 6469 6374 696f 6e61 7279 206a  ata dictionary j
+0001d180: 736f 6e20 7374 7275 6374 7572 650a 2020  son structure.  
+0001d190: 2020 3a72 6574 7572 6e3a 2068 6173 6820    :return: hash 
+0001d1a0: 6f66 0a20 2020 2022 2222 0a0a 2020 2020  of.    """..    
+0001d1b0: 2320 6576 616c 7561 7465 2074 6865 2063  # evaluate the c
+0001d1c0: 6f6d 706f 756e 6420 6461 7461 2064 6963  ompound data dic
+0001d1d0: 7469 6f6e 6172 7920 6b65 7920 616e 6420  tionary key and 
+0001d1e0: 6c6f 6f70 206f 7665 7220 7468 6520 7072  loop over the pr
+0001d1f0: 6f70 6572 7469 6573 0a20 2020 206b 6579  operties.    key
+0001d200: 5f74 7570 6c65 203d 2065 7661 6c28 656c  _tuple = eval(el
+0001d210: 656d 656e 7429 0a0a 2020 2020 2320 6164  ement)..    # ad
+0001d220: 6465 6420 6765 7455 5549 4420 746f 2070  ded getUUID to p
+0001d230: 726f 7065 7274 7920 7374 7269 6e67 2074  roperty string t
+0001d240: 6f20 736f 6c76 6520 7072 6f62 6c65 6d20  o solve problem 
+0001d250: 7768 6572 6520 616c 6c20 6f70 656e 6e65  where all openne
+0001d260: 7572 6f20 6461 7461 7365 7473 2074 6861  uro datasets tha
+0001d270: 7420 6861 7665 2074 6865 2073 616d 650a  t have the same.
+0001d280: 2020 2020 2320 736f 7572 6365 2076 6172      # source var
+0001d290: 6961 626c 6520 6e61 6d65 2061 6e64 2070  iable name and p
+0001d2a0: 726f 7065 7274 6965 7320 646f 6e27 7420  roperties don't 
+0001d2b0: 656e 6420 7570 2068 6176 696e 6720 7468  end up having th
+0001d2c0: 6520 7361 6d65 2055 5549 4420 6173 2074  e same UUID as t
+0001d2d0: 6865 7920 6172 6520 736f 6d65 7469 6d65  hey are sometime
+0001d2e0: 7320 6e6f 740a 2020 2020 2320 7468 6520  s not.    # the 
+0001d2f0: 7361 6d65 2061 6e64 2065 6e64 2075 7020  same and end up 
+0001d300: 6265 696e 6720 6164 6465 6420 746f 2074  being added to t
+0001d310: 6865 2073 616d 6520 656e 7469 7479 2077  he same entity w
+0001d320: 6865 6e20 6d65 7267 696e 6720 6772 6170  hen merging grap
+0001d330: 6873 2061 6372 6f73 7320 616c 6c20 6f70  hs across all op
+0001d340: 656e 6e65 7572 6f20 7072 6f6a 6563 7473  enneuro projects
+0001d350: 0a20 2020 2023 2069 6620 6120 6461 7461  .    # if a data
+0001d360: 7365 7420 6964 656e 7469 6669 6572 2069  set identifier i
+0001d370: 7320 6e6f 7420 7072 6f76 6964 6564 2074  s not provided t
+0001d380: 6865 6e20 7765 2075 7365 2061 2072 616e  hen we use a ran
+0001d390: 646f 6d20 5555 4944 0a20 2020 2069 6620  dom UUID.    if 
+0001d3a0: 6461 7461 7365 745f 6964 656e 7469 6669  dataset_identifi
+0001d3b0: 6572 2069 7320 6e6f 7420 4e6f 6e65 3a0a  er is not None:.
+0001d3c0: 2020 2020 2020 2020 7072 6f70 6572 7479          property
+0001d3d0: 5f73 7472 696e 6720 3d20 6461 7461 7365  _string = datase
+0001d3e0: 745f 6964 656e 7469 6669 6572 0a20 2020  t_identifier.   
+0001d3f0: 2065 6c73 653a 0a20 2020 2020 2020 2070   else:.        p
+0001d400: 726f 7065 7274 795f 7374 7269 6e67 203d  roperty_string =
+0001d410: 2067 6574 5555 4944 2829 0a20 2020 2066   getUUID().    f
+0001d420: 6f72 206b 6579 2c20 7661 6c75 6520 696e  or key, value in
+0001d430: 2064 645f 7374 7275 6374 5b73 7472 286b   dd_struct[str(k
+0001d440: 6579 5f74 7570 6c65 295d 2e69 7465 6d73  ey_tuple)].items
+0001d450: 2829 3a0a 2020 2020 2020 2020 6966 206b  ():.        if k
+0001d460: 6579 203d 3d20 226c 6162 656c 223a 0a20  ey == "label":. 
+0001d470: 2020 2020 2020 2020 2020 2070 726f 7065             prope
+0001d480: 7274 795f 7374 7269 6e67 203d 2070 726f  rty_string = pro
+0001d490: 7065 7274 795f 7374 7269 6e67 202b 2073  perty_string + s
+0001d4a0: 7472 2876 616c 7565 290a 2020 2020 2020  tr(value).      
+0001d4b0: 2020 2320 6164 6465 6420 746f 2073 7570    # added to sup
+0001d4c0: 706f 7274 2027 7265 706f 6e73 654f 7074  port 'reponseOpt
+0001d4d0: 696f 6e73 2720 7265 7072 6f73 6368 656d  ions' reproschem
+0001d4e0: 6120 666f 726d 6174 0a20 2020 2020 2020  a format.       
+0001d4f0: 2069 6620 6b65 7920 3d3d 2022 7265 7370   if key == "resp
+0001d500: 6f6e 7365 4f70 7469 6f6e 7322 3a0a 2020  onseOptions":.  
+0001d510: 2020 2020 2020 2020 2020 666f 7220 7375            for su
+0001d520: 626b 6579 2c20 7375 6276 616c 7565 2069  bkey, subvalue i
+0001d530: 6e20 6464 5f73 7472 7563 745b 7374 7228  n dd_struct[str(
+0001d540: 6b65 795f 7475 706c 6529 5d5b 0a20 2020  key_tuple)][.   
+0001d550: 2020 2020 2020 2020 2020 2020 2022 7265               "re
+0001d560: 7370 6f6e 7365 4f70 7469 6f6e 7322 0a20  sponseOptions". 
+0001d570: 2020 2020 2020 2020 2020 205d 2e69 7465             ].ite
+0001d580: 6d73 2829 3a0a 2020 2020 2020 2020 2020  ms():.          
+0001d590: 2020 2020 2020 6966 2073 7562 6b65 7920        if subkey 
+0001d5a0: 696e 2028 226c 6576 656c 7322 2c20 224c  in ("levels", "L
+0001d5b0: 6576 656c 7322 2c20 2263 686f 6963 6573  evels", "choices
+0001d5c0: 2229 3a0a 2020 2020 2020 2020 2020 2020  "):.            
+0001d5d0: 2020 2020 2020 2020 7072 6f70 6572 7479          property
+0001d5e0: 5f73 7472 696e 6720 2b3d 2073 7472 2873  _string += str(s
+0001d5f0: 7562 7661 6c75 6529 0a20 2020 2020 2020  ubvalue).       
+0001d600: 2020 2020 2020 2020 2069 6620 7375 626b           if subk
+0001d610: 6579 203d 3d20 2276 616c 7565 5479 7065  ey == "valueType
+0001d620: 223a 0a20 2020 2020 2020 2020 2020 2020  ":.             
+0001d630: 2020 2020 2020 2070 726f 7065 7274 795f         property_
+0001d640: 7374 7269 6e67 202b 3d20 7374 7228 7375  string += str(su
+0001d650: 6276 616c 7565 290a 2020 2020 2020 2020  bvalue).        
+0001d660: 2020 2020 2020 2020 6966 2073 7562 6b65          if subke
+0001d670: 7920 696e 2028 2268 6173 556e 6974 222c  y in ("hasUnit",
+0001d680: 2022 756e 6974 436f 6465 2229 3a0a 2020   "unitCode"):.  
+0001d690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d6a0: 2020 7072 6f70 6572 7479 5f73 7472 696e    property_strin
+0001d6b0: 6720 2b3d 2073 7472 2873 7562 7661 6c75  g += str(subvalu
+0001d6c0: 6529 0a20 2020 2020 2020 2069 6620 6b65  e).        if ke
+0001d6d0: 7920 3d3d 2022 736f 7572 6365 5f76 6172  y == "source_var
+0001d6e0: 6961 626c 6522 3a0a 2020 2020 2020 2020  iable":.        
+0001d6f0: 2020 2020 7661 7269 6162 6c65 5f6e 616d      variable_nam
+0001d700: 6520 3d20 7661 6c75 650a 0a20 2020 2063  e = value..    c
+0001d710: 7263 3332 6861 7368 203d 2062 6173 655f  rc32hash = base_
+0001d720: 7265 7072 2863 7263 3332 2873 7472 2870  repr(crc32(str(p
+0001d730: 726f 7065 7274 795f 7374 7269 6e67 292e  roperty_string).
+0001d740: 656e 636f 6465 2829 292c 2033 3229 2e6c  encode()), 32).l
+0001d750: 6f77 6572 2829 0a20 2020 206e 6969 7269  ower().    niiri
+0001d760: 5f6e 7320 3d20 4e61 6d65 7370 6163 6528  _ns = Namespace(
+0001d770: 436f 6e73 7461 6e74 732e 4e49 4952 4929  Constants.NIIRI)
+0001d780: 0a20 2020 2063 6465 5f69 6420 3d20 5552  .    cde_id = UR
+0001d790: 4952 6566 286e 6969 7269 5f6e 7320 2b20  IRef(niiri_ns + 
+0001d7a0: 7361 6665 5f73 7472 696e 6728 7661 7269  safe_string(vari
+0001d7b0: 6162 6c65 5f6e 616d 6529 202b 2022 5f22  able_name) + "_"
+0001d7c0: 202b 2073 7472 2863 7263 3332 6861 7368   + str(crc32hash
+0001d7d0: 2929 0a20 2020 2072 6574 7572 6e20 6364  )).    return cd
+0001d7e0: 655f 6964 0a0a 0a64 6566 2044 445f 746f  e_id...def DD_to
+0001d7f0: 5f6e 6964 6d28 6464 5f73 7472 7563 742c  _nidm(dd_struct,
+0001d800: 2064 6174 6173 6574 5f69 6465 6e74 6966   dataset_identif
+0001d810: 6965 723d 4e6f 6e65 293a 0a20 2020 2022  ier=None):.    "
+0001d820: 2222 0a0a 2020 2020 5461 6b65 7320 6120  ""..    Takes a 
+0001d830: 4444 206a 736f 6e20 7374 7275 6374 7572  DD json structur
+0001d840: 6520 616e 6420 7265 7475 726e 7320 6e69  e and returns ni
+0001d850: 646d 2043 4445 2d73 7479 6c65 2067 7261  dm CDE-style gra
+0001d860: 7068 2074 6f20 6265 2061 6464 6564 2074  ph to be added t
+0001d870: 6f20 4e49 444d 2064 6f63 756d 656e 7473  o NIDM documents
+0001d880: 0a20 2020 203a 7061 7261 6d20 4444 3a0a  .    :param DD:.
+0001d890: 2020 2020 3a72 6574 7572 6e3a 204e 4944      :return: NID
+0001d8a0: 4d20 6772 6170 680a 2020 2020 2222 220a  M graph.    """.
+0001d8b0: 0a20 2020 2023 2063 7265 6174 6520 656d  .    # create em
+0001d8c0: 7074 7920 6772 6170 6820 666f 7220 4344  pty graph for CD
+0001d8d0: 4573 0a20 2020 2067 203d 2047 7261 7068  Es.    g = Graph
+0001d8e0: 2829 0a20 2020 2067 2e62 696e 6428 7072  ().    g.bind(pr
+0001d8f0: 6566 6978 3d22 7072 6f76 222c 206e 616d  efix="prov", nam
+0001d900: 6573 7061 6365 3d43 6f6e 7374 616e 7473  espace=Constants
+0001d910: 2e50 524f 5629 0a20 2020 2067 2e62 696e  .PROV).    g.bin
+0001d920: 6428 7072 6566 6978 3d22 6463 7422 2c20  d(prefix="dct", 
+0001d930: 6e61 6d65 7370 6163 653d 436f 6e73 7461  namespace=Consta
+0001d940: 6e74 732e 4443 5429 0a20 2020 2067 2e62  nts.DCT).    g.b
+0001d950: 696e 6428 7072 6566 6978 3d22 6269 6473  ind(prefix="bids
+0001d960: 222c 206e 616d 6573 7061 6365 3d43 6f6e  ", namespace=Con
+0001d970: 7374 616e 7473 2e42 4944 5329 0a0a 2020  stants.BIDS)..  
+0001d980: 2020 2320 6b65 795f 6e75 6d20 3d20 300a    # key_num = 0.
+0001d990: 2020 2020 2320 666f 7220 6561 6368 206e      # for each n
+0001d9a0: 616d 6564 2074 7570 6c65 206b 6579 2069  amed tuple key i
+0001d9b0: 6e20 6461 7461 2064 6963 7469 6f6e 6172  n data dictionar
+0001d9c0: 790a 2020 2020 666f 7220 6b65 7920 696e  y.    for key in
+0001d9d0: 2064 645f 7374 7275 6374 3a0a 2020 2020   dd_struct:.    
+0001d9e0: 2020 2020 2320 6269 6e64 2061 206e 616d      # bind a nam
+0001d9f0: 6573 7061 6365 2066 6f72 2074 6865 2074  espace for the t
+0001da00: 6865 2064 6174 6120 6469 6374 696f 6e61  he data dictiona
+0001da10: 7279 2073 6f75 7263 6520 6669 656c 6420  ry source field 
+0001da20: 6f66 2074 6865 206b 6579 2074 7570 6c65  of the key tuple
+0001da30: 0a20 2020 2020 2020 2023 2066 6f72 2065  .        # for e
+0001da40: 6163 6820 736f 7572 6365 2076 6172 6961  ach source varia
+0001da50: 626c 6520 6372 6561 7465 2065 6e74 6974  ble create entit
+0001da60: 7920 7768 6572 6520 7468 6520 6e61 6d65  y where the name
+0001da70: 7370 6163 6520 6973 2074 6865 2073 6f75  space is the sou
+0001da80: 7263 6520 616e 6420 4944 2069 7320 7468  rce and ID is th
+0001da90: 6520 7661 7269 6162 6c65 0a20 2020 2020  e variable.     
+0001daa0: 2020 2023 2065 2e67 2e20 6361 6c67 6172     # e.g. calgar
+0001dab0: 793a 4649 5343 414c 5f34 2c20 6169 6d73  y:FISCAL_4, aims
+0001dac0: 3a46 4941 494d 5f39 0a20 2020 2020 2020  :FIAIM_9.       
+0001dad0: 2023 0a20 2020 2020 2020 2023 2054 6865   #.        # The
+0001dae0: 6e20 7768 656e 2077 6527 7265 2073 746f  n when we're sto
+0001daf0: 7269 6e67 2061 6371 7569 7265 6420 6461  ring acquired da
+0001db00: 7461 2069 6e20 656e 7469 7479 2077 6527  ta in entity we'
+0001db10: 6c6c 2075 7365 2074 6865 2065 6e74 6974  ll use the entit
+0001db20: 7920 4944 7320 6162 6f76 6520 746f 2072  y IDs above to r
+0001db30: 6566 6572 656e 6365 2061 2070 6172 7469  eference a parti
+0001db40: 6375 6c61 720a 2020 2020 2020 2020 2320  cular.        # 
+0001db50: 4344 452e 2020 5468 6520 4344 4520 6465  CDE.  The CDE de
+0001db60: 6669 6e69 7469 6f6e 7320 7769 6c6c 2068  finitions will h
+0001db70: 6176 6520 6d65 7461 6461 7461 2061 626f  ave metadata abo
+0001db80: 7574 2074 6865 2076 6172 696f 7573 2061  ut the various a
+0001db90: 7370 6563 7473 206f 6620 7468 6520 6461  spects of the da
+0001dba0: 7461 2064 6963 7469 6f6e 6172 7920 4344  ta dictionary CD
+0001dbb0: 452e 0a0a 2020 2020 2020 2020 2320 6164  E...        # ad
+0001dbc0: 6420 7468 6520 4461 7461 456c 656d 656e  d the DataElemen
+0001dbd0: 7420 5244 4620 7479 7065 2069 6e20 7468  t RDF type in th
+0001dbe0: 6520 736f 7572 6365 206e 616d 6573 7061  e source namespa
+0001dbf0: 6365 0a20 2020 2020 2020 206b 6579 5f74  ce.        key_t
+0001dc00: 7570 6c65 203d 2065 7661 6c28 6b65 7929  uple = eval(key)
+0001dc10: 0a20 2020 2020 2020 2066 6f72 2073 7562  .        for sub
+0001dc20: 6b65 7920 696e 206b 6579 5f74 7570 6c65  key in key_tuple
+0001dc30: 2e5f 6173 6469 6374 2829 2e6b 6579 7328  ._asdict().keys(
+0001dc40: 293a 0a20 2020 2020 2020 2020 2020 2069  ):.            i
+0001dc50: 6620 7375 626b 6579 203d 3d20 2276 6172  f subkey == "var
+0001dc60: 6961 626c 6522 3a0a 2020 2020 2020 2020  iable":.        
+0001dc70: 2020 2020 2020 2020 2320 6974 656d 5f6e          # item_n
+0001dc80: 7320 3d20 4e61 6d65 7370 6163 6528 6464  s = Namespace(dd
+0001dc90: 5f73 7472 7563 745b 7374 7228 6b65 795f  _struct[str(key_
+0001dca0: 7475 706c 6529 5d5b 2275 726c 225d 2b22  tuple)]["url"]+"
+0001dcb0: 2f22 290a 2020 2020 2020 2020 2020 2020  /").            
+0001dcc0: 2020 2020 2320 672e 6269 6e64 2870 7265      # g.bind(pre
+0001dcd0: 6669 783d 7361 6665 5f73 7472 696e 6728  fix=safe_string(
+0001dce0: 6974 656d 292c 206e 616d 6573 7061 6365  item), namespace
+0001dcf0: 3d69 7465 6d5f 6e73 290a 0a20 2020 2020  =item_ns)..     
+0001dd00: 2020 2020 2020 2020 2020 206e 6964 6d5f             nidm_
+0001dd10: 6e73 203d 204e 616d 6573 7061 6365 2843  ns = Namespace(C
+0001dd20: 6f6e 7374 616e 7473 2e4e 4944 4d29 0a20  onstants.NIDM). 
+0001dd30: 2020 2020 2020 2020 2020 2020 2020 2067                 g
+0001dd40: 2e62 696e 6428 7072 6566 6978 3d22 6e69  .bind(prefix="ni
+0001dd50: 646d 222c 206e 616d 6573 7061 6365 3d6e  dm", namespace=n
+0001dd60: 6964 6d5f 6e73 290a 2020 2020 2020 2020  idm_ns).        
+0001dd70: 2020 2020 2020 2020 6e69 6972 695f 6e73          niiri_ns
+0001dd80: 203d 204e 616d 6573 7061 6365 2843 6f6e   = Namespace(Con
+0001dd90: 7374 616e 7473 2e4e 4949 5249 290a 2020  stants.NIIRI).  
+0001dda0: 2020 2020 2020 2020 2020 2020 2020 672e                g.
+0001ddb0: 6269 6e64 2870 7265 6669 783d 226e 6969  bind(prefix="nii
+0001ddc0: 7269 222c 206e 616d 6573 7061 6365 3d6e  ri", namespace=n
+0001ddd0: 6969 7269 5f6e 7329 0a20 2020 2020 2020  iiri_ns).       
+0001dde0: 2020 2020 2020 2020 2069 6c78 5f6e 7320           ilx_ns 
+0001ddf0: 3d20 4e61 6d65 7370 6163 6528 436f 6e73  = Namespace(Cons
+0001de00: 7461 6e74 732e 494e 5445 524c 4558 290a  tants.INTERLEX).
+0001de10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001de20: 672e 6269 6e64 2870 7265 6669 783d 2269  g.bind(prefix="i
+0001de30: 6c78 222c 206e 616d 6573 7061 6365 3d69  lx", namespace=i
+0001de40: 6c78 5f6e 7329 0a0a 2020 2020 2020 2020  lx_ns)..        
+0001de50: 2020 2020 2020 2020 2320 6364 655f 6964          # cde_id
+0001de60: 203d 2069 7465 6d5f 6e73 5b73 7472 286b   = item_ns[str(k
+0001de70: 6579 5f6e 756d 292e 7a66 696c 6c28 3429  ey_num).zfill(4)
+0001de80: 5d0a 0a20 2020 2020 2020 2020 2020 2020  ]..             
+0001de90: 2020 2023 2068 6173 6820 7468 6520 6b65     # hash the ke
+0001dea0: 795f 7475 706c 6520 2865 2e67 2e20 4444  y_tuple (e.g. DD
+0001deb0: 2873 6f75 7263 653d 5b46 494c 454e 414d  (source=[FILENAM
+0001dec0: 455d 2c76 6172 6961 626c 653d 5b56 4152  E],variable=[VAR
+0001ded0: 4e41 4d45 5d29 290a 2020 2020 2020 2020  NAME])).        
+0001dee0: 2020 2020 2020 2020 2320 6372 6333 3268          # crc32h
+0001def0: 6173 6820 3d20 6261 7365 5f72 6570 7228  ash = base_repr(
+0001df00: 6372 6333 3228 7374 7228 6b65 7929 2e65  crc32(str(key).e
+0001df10: 6e63 6f64 6528 2929 2c33 3229 2e6c 6f77  ncode()),32).low
+0001df20: 6572 2829 0a20 2020 2020 2020 2020 2020  er().           
+0001df30: 2020 2020 2023 206d 6435 6861 7368 203d       # md5hash =
+0001df40: 2068 6173 686c 6962 2e6d 6435 2873 7472   hashlib.md5(str
+0001df50: 286b 6579 292e 656e 636f 6465 2829 292e  (key).encode()).
+0001df60: 6865 7864 6967 6573 7428 290a 0a20 2020  hexdigest()..   
+0001df70: 2020 2020 2020 2020 2020 2020 2063 6465               cde
+0001df80: 5f69 6420 3d20 4444 5f55 5549 4428 6b65  _id = DD_UUID(ke
+0001df90: 792c 2064 645f 7374 7275 6374 2c20 6461  y, dd_struct, da
+0001dfa0: 7461 7365 745f 6964 656e 7469 6669 6572  taset_identifier
+0001dfb0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0001dfc0: 2020 2320 6364 655f 6964 203d 2055 5249    # cde_id = URI
+0001dfd0: 5265 6628 6e69 6972 695f 6e73 202b 2073  Ref(niiri_ns + s
+0001dfe0: 6166 655f 7374 7269 6e67 2869 7465 6d29  afe_string(item)
+0001dff0: 202b 2022 5f22 202b 2073 7472 2863 7263   + "_" + str(crc
+0001e000: 3332 6861 7368 2929 0a20 2020 2020 2020  32hash)).       
+0001e010: 2020 2020 2020 2020 2067 2e61 6464 2828           g.add((
+0001e020: 6364 655f 6964 2c20 5244 462e 7479 7065  cde_id, RDF.type
+0001e030: 2c20 436f 6e73 7461 6e74 732e 4e49 444d  , Constants.NIDM
+0001e040: 5b22 5065 7273 6f6e 616c 4461 7461 456c  ["PersonalDataEl
+0001e050: 656d 656e 7422 5d29 290a 2020 2020 2020  ement"])).      
+0001e060: 2020 2020 2020 2020 2020 672e 6164 6428            g.add(
+0001e070: 2863 6465 5f69 642c 2052 4446 2e74 7970  (cde_id, RDF.typ
+0001e080: 652c 2043 6f6e 7374 616e 7473 2e50 524f  e, Constants.PRO
+0001e090: 565b 2245 6e74 6974 7922 5d29 290a 2020  V["Entity"])).  
+0001e0a0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+0001e0b0: 4442 4b3a 2033 2f32 352f 3231 202d 2061  DBK: 3/25/21 - a
+0001e0c0: 6464 6564 2074 6f20 636f 6e6e 6563 7420  dded to connect 
+0001e0d0: 6e69 646d 3a50 6572 736f 6e61 6c44 6174  nidm:PersonalDat
+0001e0e0: 6145 6c65 6d65 6e74 2074 6f20 7468 6520  aElement to the 
+0001e0f0: 6d6f 7265 2067 656e 6572 616c 206e 6964  more general nid
+0001e100: 6d3a 4461 7461 456c 656d 656e 7420 6173  m:DataElement as
+0001e110: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001e120: 2023 2073 7562 636c 6173 7320 746f 2061   # subclass to a
+0001e130: 6964 2069 6e20 7175 6572 6965 730a 2020  id in queries.  
+0001e140: 2020 2020 2020 2020 2020 2020 2020 672e                g.
+0001e150: 6164 6428 0a20 2020 2020 2020 2020 2020  add(.           
+0001e160: 2020 2020 2020 2020 2028 0a20 2020 2020           (.     
+0001e170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e180: 2020 2043 6f6e 7374 616e 7473 2e4e 4944     Constants.NID
+0001e190: 4d5b 2250 6572 736f 6e61 6c44 6174 6145  M["PersonalDataE
+0001e1a0: 6c65 6d65 6e74 225d 2c0a 2020 2020 2020  lement"],.      
+0001e1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e1c0: 2020 436f 6e73 7461 6e74 732e 5244 4653    Constants.RDFS
+0001e1d0: 5b22 7375 6243 6c61 7373 4f66 225d 2c0a  ["subClassOf"],.
+0001e1e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e1f0: 2020 2020 2020 2020 436f 6e73 7461 6e74          Constant
+0001e200: 732e 4e49 444d 5b22 4461 7461 456c 656d  s.NIDM["DataElem
+0001e210: 656e 7422 5d2c 0a20 2020 2020 2020 2020  ent"],.         
+0001e220: 2020 2020 2020 2020 2020 2029 0a20 2020             ).   
+0001e230: 2020 2020 2020 2020 2020 2020 2029 0a0a               )..
+0001e240: 2020 2020 2020 2020 2320 7468 6973 2063          # this c
+0001e250: 6f64 6520 6164 6473 2074 6865 2070 726f  ode adds the pro
+0001e260: 7065 7274 6965 7320 6162 6f75 7420 7468  perties about th
+0001e270: 6520 7061 7274 6963 756c 6172 2043 4445  e particular CDE
+0001e280: 2069 6e74 6f20 4e49 444d 2064 6f63 756d   into NIDM docum
+0001e290: 656e 740a 2020 2020 2020 2020 666f 7220  ent.        for 
+0001e2a0: 6b65 792c 2076 616c 7565 2069 6e20 6464  key, value in dd
+0001e2b0: 5f73 7472 7563 745b 7374 7228 6b65 795f  _struct[str(key_
+0001e2c0: 7475 706c 6529 5d2e 6974 656d 7328 293a  tuple)].items():
+0001e2d0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+0001e2e0: 6b65 7920 3d3d 2022 6465 6669 6e69 7469  key == "definiti
+0001e2f0: 6f6e 223a 0a20 2020 2020 2020 2020 2020  on":.           
+0001e300: 2020 2020 2067 2e61 6464 2828 6364 655f       g.add((cde_
+0001e310: 6964 2c20 5244 4653 5b22 636f 6d6d 656e  id, RDFS["commen
+0001e320: 7422 5d2c 204c 6974 6572 616c 2876 616c  t"], Literal(val
+0001e330: 7565 2929 290a 2020 2020 2020 2020 2020  ue))).          
+0001e340: 2020 656c 6966 206b 6579 203d 3d20 2264    elif key == "d
+0001e350: 6573 6372 6970 7469 6f6e 223a 0a20 2020  escription":.   
+0001e360: 2020 2020 2020 2020 2020 2020 2067 2e61               g.a
+0001e370: 6464 2828 6364 655f 6964 2c20 436f 6e73  dd((cde_id, Cons
+0001e380: 7461 6e74 732e 4443 545b 2264 6573 6372  tants.DCT["descr
+0001e390: 6970 7469 6f6e 225d 2c20 4c69 7465 7261  iption"], Litera
+0001e3a0: 6c28 7661 6c75 6529 2929 0a20 2020 2020  l(value))).     
+0001e3b0: 2020 2020 2020 2065 6c69 6620 6b65 7920         elif key 
+0001e3c0: 3d3d 2022 7572 6c22 3a0a 2020 2020 2020  == "url":.      
+0001e3d0: 2020 2020 2020 2020 2020 672e 6164 6428            g.add(
+0001e3e0: 2863 6465 5f69 642c 2043 6f6e 7374 616e  (cde_id, Constan
+0001e3f0: 7473 2e4e 4944 4d5b 2275 726c 225d 2c20  ts.NIDM["url"], 
+0001e400: 5552 4952 6566 2876 616c 7565 2929 290a  URIRef(value))).
+0001e410: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+0001e420: 206b 6579 203d 3d20 226c 6162 656c 223a   key == "label":
+0001e430: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001e440: 2067 2e61 6464 2828 6364 655f 6964 2c20   g.add((cde_id, 
+0001e450: 436f 6e73 7461 6e74 732e 5244 4653 5b22  Constants.RDFS["
+0001e460: 6c61 6265 6c22 5d2c 204c 6974 6572 616c  label"], Literal
+0001e470: 2876 616c 7565 2929 290a 2020 2020 2020  (value))).      
+0001e480: 2020 2020 2020 656c 6966 206b 6579 2069        elif key i
+0001e490: 6e20 2822 6c65 7665 6c73 222c 2022 4c65  n ("levels", "Le
+0001e4a0: 7665 6c73 2229 3a0a 2020 2020 2020 2020  vels"):.        
+0001e4b0: 2020 2020 2020 2020 672e 6164 6428 2863          g.add((c
+0001e4c0: 6465 5f69 642c 2043 6f6e 7374 616e 7473  de_id, Constants
+0001e4d0: 2e4e 4944 4d5b 226c 6576 656c 7322 5d2c  .NIDM["levels"],
+0001e4e0: 204c 6974 6572 616c 2876 616c 7565 2929   Literal(value))
+0001e4f0: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
+0001e500: 6966 206b 6579 203d 3d20 2273 6f75 7263  if key == "sourc
+0001e510: 655f 7661 7269 6162 6c65 223a 0a20 2020  e_variable":.   
+0001e520: 2020 2020 2020 2020 2020 2020 2067 2e61               g.a
+0001e530: 6464 2828 6364 655f 6964 2c20 436f 6e73  dd((cde_id, Cons
+0001e540: 7461 6e74 732e 4e49 444d 5b22 736f 7572  tants.NIDM["sour
+0001e550: 6365 5661 7269 6162 6c65 225d 2c20 4c69  ceVariable"], Li
+0001e560: 7465 7261 6c28 7661 6c75 6529 2929 0a20  teral(value))). 
+0001e570: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+0001e580: 6b65 7920 3d3d 2022 6973 4162 6f75 7422  key == "isAbout"
+0001e590: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0001e5a0: 2020 2320 6463 745f 6e73 203d 204e 616d    # dct_ns = Nam
+0001e5b0: 6573 7061 6365 2843 6f6e 7374 616e 7473  espace(Constants
+0001e5c0: 2e44 4354 290a 2020 2020 2020 2020 2020  .DCT).          
+0001e5d0: 2020 2020 2020 2320 672e 6269 6e64 2870        # g.bind(p
+0001e5e0: 7265 6669 783d 2764 6374 272c 206e 616d  refix='dct', nam
+0001e5f0: 6573 7061 6365 3d64 6374 5f6e 7329 0a20  espace=dct_ns). 
+0001e600: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+0001e610: 2061 6464 6564 2062 7920 4442 4b20 666f   added by DBK fo
+0001e620: 7220 6d75 6c74 6970 6c65 2069 7341 626f  r multiple isAbo
+0001e630: 7574 2055 524c 7320 616e 6420 7374 6f72  ut URLs and stor
+0001e640: 696e 6720 7468 6520 6c61 6265 6c73 2061  ing the labels a
+0001e650: 6c6f 6e67 2077 6974 6820 5552 4c73 0a20  long with URLs. 
+0001e660: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+0001e670: 2066 6972 7374 2067 6574 2061 2075 7569   first get a uui
+0001e680: 6420 6861 7320 666f 7220 7468 6520 6973  d has for the is
+0001e690: 4162 6f75 7420 636f 6c6c 6563 7469 6f6e  About collection
+0001e6a0: 2066 6f72 2074 6869 7320 7765 276c 6c20   for this we'll 
+0001e6b0: 7573 6520 6120 6861 7368 206f 6620 7468  use a hash of th
+0001e6c0: 6520 6973 4162 6f75 7420 6c69 7374 0a20  e isAbout list. 
+0001e6d0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+0001e6e0: 2061 7320 6120 7374 7269 6e67 0a20 2020   as a string.   
+0001e6f0: 2020 2020 2020 2020 2020 2020 2023 2063               # c
+0001e700: 7263 3332 6861 7368 203d 2062 6173 655f  rc32hash = base_
+0001e710: 7265 7072 2863 7263 3332 2873 7472 2876  repr(crc32(str(v
+0001e720: 616c 7565 292e 656e 636f 6465 2829 292c  alue).encode()),
+0001e730: 2033 3229 2e6c 6f77 6572 2829 0a20 2020   32).lower().   
+0001e740: 2020 2020 2020 2020 2020 2020 2023 206e               # n
+0001e750: 6f77 2063 7265 6174 6520 7468 6520 636f  ow create the co
+0001e760: 6c6c 6563 7469 6f6e 2061 6e64 2066 6f72  llection and for
+0001e770: 2065 6163 6820 6973 4162 6f75 7420 6372   each isAbout cr
+0001e780: 6561 7465 2061 6e20 656e 7469 7479 2074  eate an entity t
+0001e790: 6f20 6164 6420 746f 2063 6f6c 6c65 6374  o add to collect
+0001e7a0: 696f 6e20 7769 7468 0a20 2020 2020 2020  ion with.       
+0001e7b0: 2020 2020 2020 2020 2023 2070 726f 7065           # prope
+0001e7c0: 7274 6965 7320 666f 7220 6c61 6265 6c20  rties for label 
+0001e7d0: 616e 6420 7572 6c0a 2020 2020 2020 2020  and url.        
+0001e7e0: 2020 2020 2020 2020 2320 672e 6164 6428          # g.add(
+0001e7f0: 2869 7361 626f 7574 5f63 6f6c 6c65 6374  (isabout_collect
+0001e800: 696f 6e5f 6964 2c20 5244 462e 7479 7065  ion_id, RDF.type
+0001e810: 2c20 436f 6e73 7461 6e74 732e 5052 4f56  , Constants.PROV
+0001e820: 5b27 436f 6c6c 6563 7469 6f6e 275d 2929  ['Collection']))
+0001e830: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001e840: 2023 2066 6f72 2065 6163 6820 6973 4162   # for each isAb
+0001e850: 6f75 7420 656e 7472 792c 2063 7265 6174  out entry, creat
+0001e860: 6520 6e65 7720 7072 6f76 3a45 6e74 6974  e new prov:Entit
+0001e870: 792c 2073 746f 7265 206d 6574 6164 6174  y, store metadat
+0001e880: 6120 616e 6420 6c69 6e6b 2069 7420 746f  a and link it to
+0001e890: 2074 6865 2063 6f6c 6c65 6374 696f 6e0a   the collection.
+0001e8a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001e8b0: 2023 2069 6620 7765 2068 6176 6520 6d75   # if we have mu
+0001e8c0: 6c74 6970 6c65 2069 7341 626f 7574 7320  ltiple isAbouts 
+0001e8d0: 7468 656e 2069 7420 7769 6c6c 2062 6520  then it will be 
+0001e8e0: 7374 6f72 6564 2061 7320 6120 6c69 7374  stored as a list
+0001e8f0: 206f 6620 6469 6374 730a 2020 2020 2020   of dicts.      
+0001e900: 2020 2020 2020 2020 2020 6966 2069 7369            if isi
+0001e910: 6e73 7461 6e63 6528 7661 6c75 652c 206c  nstance(value, l
+0001e920: 6973 7429 3a0a 2020 2020 2020 2020 2020  ist):.          
+0001e930: 2020 2020 2020 2020 2020 666f 7220 7375            for su
+0001e940: 6264 6963 7420 696e 2076 616c 7565 3a0a  bdict in value:.
+0001e950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e960: 2020 2020 2020 2020 666f 7220 6973 6162          for isab
+0001e970: 6f75 745f 6b65 792c 2069 7361 626f 7574  out_key, isabout
+0001e980: 5f76 616c 7565 2069 6e20 7375 6264 6963  _value in subdic
+0001e990: 742e 6974 656d 7328 293a 0a20 2020 2020  t.items():.     
+0001e9a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e9b0: 2020 2020 2020 2069 6620 6973 6162 6f75         if isabou
+0001e9c0: 745f 6b65 7920 696e 2028 2240 6964 222c  t_key in ("@id",
+0001e9d0: 2022 7572 6c22 293a 0a20 2020 2020 2020   "url"):.       
+0001e9e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e9f0: 2020 2020 2020 2020 206c 6173 745f 6964           last_id
+0001ea00: 203d 2069 7361 626f 7574 5f76 616c 7565   = isabout_value
+0001ea10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001ea20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ea30: 2023 2061 6464 2069 7341 626f 7574 206b   # add isAbout k
+0001ea40: 6579 2077 6869 6368 2069 7320 7468 6520  ey which is the 
+0001ea50: 7572 6c0a 2020 2020 2020 2020 2020 2020  url.            
+0001ea60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ea70: 2020 2020 672e 6164 6428 0a20 2020 2020      g.add(.     
+0001ea80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ea90: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+0001eaa0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001eab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eac0: 2020 2020 2020 2020 2063 6465 5f69 642c           cde_id,
+0001ead0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001eae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eaf0: 2020 2020 2020 2020 2043 6f6e 7374 616e           Constan
+0001eb00: 7473 2e4e 4944 4d5b 2269 7341 626f 7574  ts.NIDM["isAbout
+0001eb10: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+0001eb20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eb30: 2020 2020 2020 2020 2020 2020 5552 4952              URIR
+0001eb40: 6566 2869 7361 626f 7574 5f76 616c 7565  ef(isabout_value
+0001eb50: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
+0001eb60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eb70: 2020 2020 2020 2029 0a20 2020 2020 2020         ).       
+0001eb80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eb90: 2020 2020 2020 2020 2029 0a20 2020 2020           ).     
+0001eba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ebb0: 2020 2020 2020 2065 6c69 6620 6973 6162         elif isab
+0001ebc0: 6f75 745f 6b65 7920 3d3d 2022 6c61 6265  out_key == "labe
+0001ebd0: 6c22 3a0a 2020 2020 2020 2020 2020 2020  l":.            
+0001ebe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ebf0: 2020 2020 2320 6e6f 7720 6164 6420 616e      # now add an
+0001ec00: 6f74 6865 7220 656e 7469 7479 2074 6f20  other entity to 
+0001ec10: 636f 6e74 6169 6e20 7468 6520 6c61 6265  contain the labe
+0001ec20: 6c0a 2020 2020 2020 2020 2020 2020 2020  l.              
+0001ec30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ec40: 2020 672e 6164 6428 0a20 2020 2020 2020    g.add(.       
+0001ec50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ec60: 2020 2020 2020 2020 2020 2020 2028 0a20               (. 
+0001ec70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ec80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ec90: 2020 2020 2020 2055 5249 5265 6628 6c61         URIRef(la
+0001eca0: 7374 5f69 6429 2c0a 2020 2020 2020 2020  st_id),.        
+0001ecb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ecc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ecd0: 5244 462e 7479 7065 2c0a 2020 2020 2020  RDF.type,.      
+0001ece0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ecf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ed00: 2020 436f 6e73 7461 6e74 732e 5052 4f56    Constants.PROV
+0001ed10: 5b22 456e 7469 7479 225d 2c0a 2020 2020  ["Entity"],.    
+0001ed20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ed30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ed40: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0001ed50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ed60: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+0001ed70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ed80: 2020 2020 672e 6164 6428 0a20 2020 2020      g.add(.     
+0001ed90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eda0: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+0001edb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001edc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001edd0: 2020 2020 2020 2020 2055 5249 5265 6628           URIRef(
+0001ede0: 6c61 7374 5f69 6429 2c0a 2020 2020 2020  last_id),.      
+0001edf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ee00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ee10: 2020 436f 6e73 7461 6e74 732e 5244 4653    Constants.RDFS
+0001ee20: 5b22 6c61 6265 6c22 5d2c 0a20 2020 2020  ["label"],.     
+0001ee30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ee40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ee50: 2020 204c 6974 6572 616c 2869 7361 626f     Literal(isabo
+0001ee60: 7574 5f76 616c 7565 292c 0a20 2020 2020  ut_value),.     
+0001ee70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ee80: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+0001ee90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001eea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001eeb0: 2029 0a20 2020 2020 2020 2020 2020 2020   ).             
+0001eec0: 2020 2023 2065 6c73 6520 7765 206f 6e6c     # else we onl
+0001eed0: 7920 6861 7665 2031 2069 7361 626f 7574  y have 1 isabout
+0001eee0: 2077 6869 6368 2069 7320 6120 6469 6374   which is a dict
+0001eef0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001ef00: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+0001ef10: 2020 2020 2020 2020 2020 2066 6f72 2069             for i
+0001ef20: 7361 626f 7574 5f6b 6579 2c20 6973 6162  sabout_key, isab
+0001ef30: 6f75 745f 7661 6c75 6520 696e 2076 616c  out_value in val
+0001ef40: 7565 2e69 7465 6d73 2829 3a0a 2020 2020  ue.items():.    
+0001ef50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ef60: 2020 2020 6966 2069 7361 626f 7574 5f6b      if isabout_k
+0001ef70: 6579 2069 6e20 2822 4069 6422 2c20 2275  ey in ("@id", "u
+0001ef80: 726c 2229 3a0a 2020 2020 2020 2020 2020  rl"):.          
+0001ef90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001efa0: 2020 6c61 7374 5f69 6420 3d20 6973 6162    last_id = isab
+0001efb0: 6f75 745f 7661 6c75 650a 2020 2020 2020  out_value.      
+0001efc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001efd0: 2020 2020 2020 2320 6164 6420 6973 4162        # add isAb
+0001efe0: 6f75 7420 6b65 7920 7768 6963 6820 6973  out key which is
+0001eff0: 2074 6865 2075 726c 0a20 2020 2020 2020   the url.       
+0001f000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f010: 2020 2020 2067 2e61 6464 280a 2020 2020       g.add(.    
+0001f020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f030: 2020 2020 2020 2020 2020 2020 280a 2020              (.  
+0001f040: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f050: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f060: 2020 6364 655f 6964 2c0a 2020 2020 2020    cde_id,.      
+0001f070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f080: 2020 2020 2020 2020 2020 2020 2020 436f                Co
+0001f090: 6e73 7461 6e74 732e 4e49 444d 5b22 6973  nstants.NIDM["is
+0001f0a0: 4162 6f75 7422 5d2c 0a20 2020 2020 2020  About"],.       
+0001f0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f0c0: 2020 2020 2020 2020 2020 2020 2055 5249               URI
+0001f0d0: 5265 6628 6973 6162 6f75 745f 7661 6c75  Ref(isabout_valu
+0001f0e0: 6529 2c0a 2020 2020 2020 2020 2020 2020  e),.            
+0001f0f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f100: 2020 2020 290a 2020 2020 2020 2020 2020      ).          
+0001f110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f120: 2020 290a 2020 2020 2020 2020 2020 2020    ).            
+0001f130: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+0001f140: 2069 7361 626f 7574 5f6b 6579 203d 3d20   isabout_key == 
+0001f150: 226c 6162 656c 223a 0a20 2020 2020 2020  "label":.       
+0001f160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f170: 2020 2020 2023 206e 6f77 2061 6464 2061       # now add a
+0001f180: 6e6f 7468 6572 2065 6e74 6974 7920 746f  nother entity to
+0001f190: 2063 6f6e 7461 696e 2074 6865 206c 6162   contain the lab
+0001f1a0: 656c 0a20 2020 2020 2020 2020 2020 2020  el.             
+0001f1b0: 2020 2020 2020 2020 2020 2020 2020 2067                 g
+0001f1c0: 2e61 6464 2828 5552 4952 6566 286c 6173  .add((URIRef(las
+0001f1d0: 745f 6964 292c 2052 4446 2e74 7970 652c  t_id), RDF.type,
+0001f1e0: 2043 6f6e 7374 616e 7473 2e50 524f 565b   Constants.PROV[
+0001f1f0: 2245 6e74 6974 7922 5d29 290a 2020 2020  "Entity"])).    
+0001f200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f210: 2020 2020 2020 2020 672e 6164 6428 0a20          g.add(. 
+0001f220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f230: 2020 2020 2020 2020 2020 2020 2020 2028                 (
+0001f240: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001f250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f260: 2020 2020 2055 5249 5265 6628 6c61 7374       URIRef(last
+0001f270: 5f69 6429 2c0a 2020 2020 2020 2020 2020  _id),.          
+0001f280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f290: 2020 2020 2020 2020 2020 436f 6e73 7461            Consta
+0001f2a0: 6e74 732e 5244 4653 5b22 6c61 6265 6c22  nts.RDFS["label"
+0001f2b0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+0001f2c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f2d0: 2020 2020 2020 204c 6974 6572 616c 2869         Literal(i
+0001f2e0: 7361 626f 7574 5f76 616c 7565 292c 0a20  sabout_value),. 
+0001f2f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f300: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+0001f310: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001f320: 2020 2020 2020 2020 2020 2020 2029 0a0a               )..
+0001f330: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+0001f340: 206b 6579 203d 3d20 2276 616c 7565 5479   key == "valueTy
+0001f350: 7065 223a 0a20 2020 2020 2020 2020 2020  pe":.           
+0001f360: 2020 2020 2067 2e61 6464 2828 6364 655f       g.add((cde_
+0001f370: 6964 2c20 436f 6e73 7461 6e74 732e 4e49  id, Constants.NI
+0001f380: 444d 5b22 7661 6c75 6554 7970 6522 5d2c  DM["valueType"],
+0001f390: 2055 5249 5265 6628 7661 6c75 6529 2929   URIRef(value)))
+0001f3a0: 0a20 2020 2020 2020 2020 2020 2065 6c69  .            eli
+0001f3b0: 6620 6b65 7920 696e 2028 226d 696e 5661  f key in ("minVa
+0001f3c0: 6c75 6522 2c20 226d 696e 696d 756d 5661  lue", "minimumVa
+0001f3d0: 6c75 6522 293a 0a20 2020 2020 2020 2020  lue"):.         
+0001f3e0: 2020 2020 2020 2067 2e61 6464 2828 6364         g.add((cd
+0001f3f0: 655f 6964 2c20 436f 6e73 7461 6e74 732e  e_id, Constants.
+0001f400: 4e49 444d 5b22 6d69 6e56 616c 7565 225d  NIDM["minValue"]
+0001f410: 2c20 4c69 7465 7261 6c28 7661 6c75 6529  , Literal(value)
+0001f420: 2929 0a20 2020 2020 2020 2020 2020 2065  )).            e
+0001f430: 6c69 6620 6b65 7920 696e 2028 226d 6178  lif key in ("max
+0001f440: 5661 6c75 6522 2c20 226d 6178 696d 756d  Value", "maximum
+0001f450: 5661 6c75 6522 293a 0a20 2020 2020 2020  Value"):.       
+0001f460: 2020 2020 2020 2020 2067 2e61 6464 2828           g.add((
+0001f470: 6364 655f 6964 2c20 436f 6e73 7461 6e74  cde_id, Constant
+0001f480: 732e 4e49 444d 5b22 6d61 7856 616c 7565  s.NIDM["maxValue
+0001f490: 225d 2c20 4c69 7465 7261 6c28 7661 6c75  "], Literal(valu
+0001f4a0: 6529 2929 0a20 2020 2020 2020 2020 2020  e))).           
+0001f4b0: 2065 6c69 6620 6b65 7920 3d3d 2022 6861   elif key == "ha
+0001f4c0: 7355 6e69 7422 3a0a 2020 2020 2020 2020  sUnit":.        
+0001f4d0: 2020 2020 2020 2020 672e 6164 6428 2863          g.add((c
+0001f4e0: 6465 5f69 642c 2043 6f6e 7374 616e 7473  de_id, Constants
+0001f4f0: 2e4e 4944 4d5b 2275 6e69 7443 6f64 6522  .NIDM["unitCode"
+0001f500: 5d2c 204c 6974 6572 616c 2876 616c 7565  ], Literal(value
+0001f510: 2929 290a 2020 2020 2020 2020 2020 2020  ))).            
+0001f520: 656c 6966 206b 6579 203d 3d20 2273 616d  elif key == "sam
+0001f530: 6541 7322 3a0a 2020 2020 2020 2020 2020  eAs":.          
+0001f540: 2020 2020 2020 672e 6164 6428 2863 6465        g.add((cde
+0001f550: 5f69 642c 2043 6f6e 7374 616e 7473 2e4e  _id, Constants.N
+0001f560: 4944 4d5b 2273 616d 6541 7322 5d2c 2055  IDM["sameAs"], U
+0001f570: 5249 5265 6628 7661 6c75 6529 2929 0a20  RIRef(value))). 
+0001f580: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+0001f590: 6b65 7920 3d3d 2022 6173 736f 6369 6174  key == "associat
+0001f5a0: 6564 5769 7468 223a 0a20 2020 2020 2020  edWith":.       
+0001f5b0: 2020 2020 2020 2020 2067 2e61 6464 2828           g.add((
+0001f5c0: 6364 655f 6964 2c20 436f 6e73 7461 6e74  cde_id, Constant
+0001f5d0: 732e 494e 5445 524c 4558 5b22 696c 785f  s.INTERLEX["ilx_
+0001f5e0: 3037 3339 3238 3922 5d2c 204c 6974 6572  0739289"], Liter
+0001f5f0: 616c 2876 616c 7565 2929 290a 2020 2020  al(value))).    
+0001f600: 2020 2020 2020 2020 656c 6966 206b 6579          elif key
+0001f610: 203d 3d20 2261 6c6c 6f77 6162 6c65 5661   == "allowableVa
+0001f620: 6c75 6573 223a 0a20 2020 2020 2020 2020  lues":.         
+0001f630: 2020 2020 2020 2067 2e61 6464 2828 6364         g.add((cd
+0001f640: 655f 6964 2c20 436f 6e73 7461 6e74 732e  e_id, Constants.
+0001f650: 4249 4453 5b22 616c 6c6f 7761 626c 6556  BIDS["allowableV
+0001f660: 616c 7565 7322 5d2c 204c 6974 6572 616c  alues"], Literal
+0001f670: 2876 616c 7565 2929 290a 2020 2020 2020  (value))).      
+0001f680: 2020 2020 2020 2320 7465 7374 696e 670a        # testing.
+0001f690: 2020 2020 2020 2020 2020 2020 2320 672e              # g.
+0001f6a0: 7365 7269 616c 697a 6528 6465 7374 696e  serialize(destin
+0001f6b0: 6174 696f 6e3d 222f 5573 6572 732f 6462  ation="/Users/db
+0001f6c0: 6b65 6174 6f72 2f44 6f77 6e6c 6f61 6473  keator/Downloads
+0001f6d0: 2f63 7376 326e 6964 6d5f 6364 652e 7474  /csv2nidm_cde.tt
+0001f6e0: 6c22 2c20 666f 726d 6174 3d27 7475 7274  l", format='turt
+0001f6f0: 6c65 2729 0a0a 2020 2020 7265 7475 726e  le')..    return
+0001f700: 2067 0a0a 0a64 6566 2061 6464 5f61 7474   g...def add_att
+0001f710: 7269 6275 7465 735f 7769 7468 5f63 6465  ributes_with_cde
+0001f720: 2870 726f 765f 6f62 6a65 6374 2c20 6364  (prov_object, cd
+0001f730: 652c 2072 6f77 5f76 6172 6961 626c 652c  e, row_variable,
+0001f740: 2076 616c 7565 293a 0a20 2020 2023 2066   value):.    # f
+0001f750: 696e 6420 7468 6520 4944 2069 6e20 6364  ind the ID in cd
+0001f760: 6573 2077 6865 7265 206e 6964 6d3a 736f  es where nidm:so
+0001f770: 7572 6365 5f76 6172 6961 626c 6520 6d61  urce_variable ma
+0001f780: 7463 6865 7320 7468 6520 726f 775f 7661  tches the row_va
+0001f790: 7269 6162 6c65 0a20 2020 2023 2071 7265  riable.    # qre
+0001f7a0: 7320 3d20 6364 652e 7375 626a 6563 7473  s = cde.subjects
+0001f7b0: 2870 7265 6469 6361 7465 3d43 6f6e 7374  (predicate=Const
+0001f7c0: 616e 7473 2e52 4446 535b 276c 6162 656c  ants.RDFS['label
+0001f7d0: 275d 2c6f 626a 6563 743d 4c69 7465 7261  '],object=Litera
+0001f7e0: 6c28 726f 775f 7661 7269 6162 6c65 2929  l(row_variable))
+0001f7f0: 0a20 2020 2071 7265 7320 3d20 6364 652e  .    qres = cde.
+0001f800: 7375 626a 6563 7473 280a 2020 2020 2020  subjects(.      
+0001f810: 2020 7072 6564 6963 6174 653d 436f 6e73    predicate=Cons
+0001f820: 7461 6e74 732e 4e49 444d 5b22 736f 7572  tants.NIDM["sour
+0001f830: 6365 5661 7269 6162 6c65 225d 2c20 6f62  ceVariable"], ob
+0001f840: 6a65 6374 3d4c 6974 6572 616c 2872 6f77  ject=Literal(row
+0001f850: 5f76 6172 6961 626c 6529 0a20 2020 2029  _variable).    )
+0001f860: 0a20 2020 2066 6f72 2073 2069 6e20 7172  .    for s in qr
+0001f870: 6573 3a0a 2020 2020 2020 2020 656e 7469  es:.        enti
+0001f880: 7479 5f69 6420 3d20 730a 2020 2020 2020  ty_id = s.      
+0001f890: 2020 2320 6669 6e64 2070 7265 6669 7820    # find prefix 
+0001f8a0: 6d61 7463 6869 6e67 206f 7572 2075 726c  matching our url
+0001f8b0: 2069 6e20 7264 666c 6962 2067 7261 7068   in rdflib graph
+0001f8c0: 2e2e 2e74 6869 7320 6973 2062 6563 6175  ...this is becau
+0001f8d0: 7365 2077 6527 7265 2062 6f75 6e63 696e  se we're bouncin
+0001f8e0: 6720 6265 7477 6565 6e0a 2020 2020 2020  g between.      
+0001f8f0: 2020 2320 7072 6f76 2061 6e64 2072 6466    # prov and rdf
+0001f900: 6c69 6220 6f62 6a65 6374 730a 2020 2020  lib objects.    
+0001f910: 2020 2020 666f 7220 7072 6566 6978 2c20      for prefix, 
+0001f920: 6e61 6d65 7370 6163 6520 696e 2063 6465  namespace in cde
+0001f930: 2e6e 616d 6573 7061 6365 7328 293a 0a20  .namespaces():. 
+0001f940: 2020 2020 2020 2020 2020 2069 6620 6e61             if na
+0001f950: 6d65 7370 6163 6520 3d3d 2055 5249 5265  mespace == URIRe
+0001f960: 6628 656e 7469 7479 5f69 642e 7273 706c  f(entity_id.rspl
+0001f970: 6974 2822 2f22 2c20 3129 5b30 5d20 2b20  it("/", 1)[0] + 
+0001f980: 222f 2229 3a0a 2020 2020 2020 2020 2020  "/"):.          
+0001f990: 2020 2020 2020 6364 655f 7072 6566 6978        cde_prefix
+0001f9a0: 203d 2070 7265 6669 780a 2020 2020 2020   = prefix.      
+0001f9b0: 2020 2020 2020 2020 2020 2320 7468 6973            # this
+0001f9c0: 2062 6173 6963 616c 6c79 2073 746f 7265   basically store
+0001f9d0: 7320 7468 6520 726f 775f 6461 7461 2077  s the row_data w
+0001f9e0: 6974 6820 7468 6520 7072 6564 6963 6174  ith the predicat
+0001f9f0: 6520 6265 696e 6720 7468 6520 6364 6520  e being the cde 
+0001fa00: 6964 2066 726f 6d20 6162 6f76 652e 0a20  id from above.. 
+0001fa10: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0001fa20: 726f 765f 6f62 6a65 6374 2e61 6464 5f61  rov_object.add_a
+0001fa30: 7474 7269 6275 7465 7328 0a20 2020 2020  ttributes(.     
+0001fa40: 2020 2020 2020 2020 2020 2020 2020 207b                 {
+0001fa50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001fa60: 2020 2020 2020 2020 2051 7561 6c69 6669           Qualifi
+0001fa70: 6564 4e61 6d65 280a 2020 2020 2020 2020  edName(.        
+0001fa80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fa90: 2020 2020 7072 6f76 4e61 6d65 7370 6163      provNamespac
+0001faa0: 6528 0a20 2020 2020 2020 2020 2020 2020  e(.             
+0001fab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fac0: 2020 2070 7265 6669 783d 6364 655f 7072     prefix=cde_pr
+0001fad0: 6566 6978 2c20 7572 693d 656e 7469 7479  efix, uri=entity
+0001fae0: 5f69 642e 7273 706c 6974 2822 2f22 2c20  _id.rsplit("/", 
+0001faf0: 3129 5b30 5d20 2b20 222f 220a 2020 2020  1)[0] + "/".    
+0001fb00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fb10: 2020 2020 2020 2020 292c 0a20 2020 2020          ),.     
+0001fb20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fb30: 2020 2020 2020 2065 6e74 6974 795f 6964         entity_id
+0001fb40: 2e72 7370 6c69 7428 222f 222c 2031 295b  .rsplit("/", 1)[
+0001fb50: 2d31 5d2c 0a20 2020 2020 2020 2020 2020  -1],.           
+0001fb60: 2020 2020 2020 2020 2020 2020 2029 3a20               ): 
+0001fb70: 7661 6c75 650a 2020 2020 2020 2020 2020  value.          
+0001fb80: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+0001fb90: 2020 2020 2020 2020 2020 2020 290a 2020              ).  
+0001fba0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+0001fbb0: 7072 6f76 5f6f 626a 6563 742e 6164 645f  prov_object.add_
+0001fbc0: 6174 7472 6962 7574 6573 287b 5175 616c  attributes({Qual
+0001fbd0: 6966 6965 644e 616d 6528 436f 6e73 7461  ifiedName(Consta
+0001fbe0: 6e74 732e 4e49 4952 492c 656e 7469 7479  nts.NIIRI,entity
+0001fbf0: 5f69 6429 3a76 616c 7565 7d29 0a20 2020  _id):value}).   
+0001fc00: 2020 2020 2020 2020 2020 2020 2062 7265               bre
+0001fc10: 616b 0a0a 0a64 6566 2061 6464 4461 7461  ak...def addData
+0001fc20: 6c61 6444 6174 6173 6574 5555 4944 2870  ladDatasetUUID(p
+0001fc30: 726f 6a65 6374 5f75 7569 642c 2062 6964  roject_uuid, bid
+0001fc40: 7372 6f6f 745f 6469 7265 6374 6f72 792c  sroot_directory,
+0001fc50: 2067 7261 7068 293a 0a20 2020 2022 2222   graph):.    """
+0001fc60: 0a20 2020 2054 6869 7320 6675 6e63 7469  .    This functi
+0001fc70: 6f6e 2077 696c 6c20 6164 6420 7468 6520  on will add the 
+0001fc80: 6461 7461 6c61 6420 756e 6971 7565 2049  datalad unique I
+0001fc90: 4420 666f 7220 7468 6973 2064 6174 6173  D for this datas
+0001fca0: 6574 2074 6f20 7468 6520 7072 6f6a 6563  et to the projec
+0001fcb0: 7420 656e 7469 7479 2075 7569 6420 696e  t entity uuid in
+0001fcc0: 2067 7261 7068 2e20 5468 6973 0a20 2020   graph. This.   
+0001fcd0: 2055 5549 4420 7769 6c6c 2075 6c74 696d   UUID will ultim
+0001fce0: 6174 656c 7920 6265 2075 7365 6420 6279  ately be used by
+0001fcf0: 2064 6174 616c 6164 2074 6f20 6964 656e   datalad to iden
+0001fd00: 7469 6679 2074 6865 2064 6174 6173 6574  tify the dataset
+0001fd10: 0a20 2020 203a 7061 7261 6d20 7072 6f6a  .    :param proj
+0001fd20: 6563 745f 7575 6964 3a20 756e 6971 7565  ect_uuid: unique
+0001fd30: 2070 726f 6a65 6374 2061 6374 6976 6974   project activit
+0001fd40: 7920 4944 2069 6e20 6772 6170 6820 746f  y ID in graph to
+0001fd50: 2061 6464 2074 7570 6c65 0a20 2020 203a   add tuple.    :
+0001fd60: 7061 7261 6d20 6269 6473 726f 6f74 5f64  param bidsroot_d
+0001fd70: 6972 6563 746f 7279 3a20 726f 6f74 2064  irectory: root d
+0001fd80: 6972 6563 746f 7279 2066 6f72 2077 6869  irectory for whi
+0001fd90: 6368 2074 6f20 636f 6c6c 6563 7420 6461  ch to collect da
+0001fda0: 7461 6c61 6420 7575 6964 730a 2020 2020  talad uuids.    
+0001fdb0: 3a72 6574 7572 6e3a 2061 7567 6d65 6e74  :return: augment
+0001fdc0: 6564 2067 7261 7068 2077 6974 6820 6461  ed graph with da
+0001fdd0: 7461 6c61 6420 756e 6971 7565 2049 4473  talad unique IDs
+0001fde0: 0a20 2020 2022 2222 0a0a 0a64 6566 2061  .    """...def a
+0001fdf0: 6464 4769 7441 6e6e 6578 536f 7572 6365  ddGitAnnexSource
+0001fe00: 7328 6f62 6a2c 2062 6964 735f 726f 6f74  s(obj, bids_root
+0001fe10: 2c20 6669 6c65 7061 7468 3d4e 6f6e 6529  , filepath=None)
+0001fe20: 3a0a 2020 2020 2222 220a 2020 2020 5468  :.    """.    Th
+0001fe30: 6973 2066 756e 6374 696f 6e20 7769 6c6c  is function will
+0001fe40: 2061 6464 2067 6974 2d61 6e6e 6578 2073   add git-annex s
+0001fe50: 6f75 7263 6573 2061 7320 7475 706c 6573  ources as tuples
+0001fe60: 2074 6f20 656e 7469 7479 2075 7569 6420   to entity uuid 
+0001fe70: 696e 2067 7261 7068 2e20 5468 6573 6520  in graph. These 
+0001fe80: 736f 7572 6365 730a 2020 2020 6361 6e20  sources.    can 
+0001fe90: 756c 7469 6d61 7465 6c79 2062 6520 7573  ultimately be us
+0001fea0: 6564 2074 6f20 7265 7472 6965 7665 2074  ed to retrieve t
+0001feb0: 6865 2066 696c 6528 7329 2064 6573 6372  he file(s) descr
+0001fec0: 6962 6564 2069 6e20 7468 6520 656e 7469  ibed in the enti
+0001fed0: 7479 2075 7569 6420 7573 696e 6720 6769  ty uuid using gi
+0001fee0: 742d 616e 6e65 7820 286f 7220 6461 7461  t-annex (or data
+0001fef0: 6c61 6429 0a20 2020 203a 7061 7261 6d20  lad).    :param 
+0001ff00: 6f62 6a3a 2065 6e74 6974 792f 6163 7469  obj: entity/acti
+0001ff10: 7669 7479 206f 626a 6563 7420 746f 2061  vity object to a
+0001ff20: 6464 2074 7570 6c65 730a 2020 2020 3a70  dd tuples.    :p
+0001ff30: 6172 616d 2066 696c 6570 6174 683a 2072  aram filepath: r
+0001ff40: 656c 6174 6976 6520 7061 7468 2074 6f20  elative path to 
+0001ff50: 6669 6c65 2028 6f72 2064 6972 6563 746f  file (or directo
+0001ff60: 7279 2920 666f 7220 7768 6963 6820 746f  ry) for which to
+0001ff70: 2061 6464 2073 6f75 7263 6573 2074 6f20   add sources to 
+0001ff80: 6772 6170 682e 2020 4966 206e 6f74 2073  graph.  If not s
+0001ff90: 6574 2074 6865 6e20 6269 6473 5f72 6f6f  et then bids_roo
+0001ffa0: 740a 2020 2020 6769 7420 616e 6e65 7820  t.    git annex 
+0001ffb0: 736f 7572 6365 2075 726c 2077 696c 6c20  source url will 
+0001ffc0: 6265 2061 6464 6564 2074 6f20 6f62 6a20  be added to obj 
+0001ffd0: 696e 7374 6561 6420 6f66 2066 696c 6570  instead of filep
+0001ffe0: 6174 6820 6769 7420 616e 6e65 7820 736f  ath git annex so
+0001fff0: 7572 6365 2075 726c 2e0a 2020 2020 3a70  urce url..    :p
+00020000: 6172 616d 2062 6964 735f 726f 6f74 3a20  aram bids_root: 
+00020010: 726f 6f74 2064 6972 6563 746f 7279 206f  root directory o
+00020020: 6620 4249 4453 2064 6174 6173 6574 0a20  f BIDS dataset. 
+00020030: 2020 203a 7265 7475 726e 3a20 6e75 6d62     :return: numb
+00020040: 6572 206f 6620 736f 7572 6365 7320 666f  er of sources fo
+00020050: 756e 640a 2020 2020 2222 220a 0a20 2020  und.    """..   
+00020060: 2023 206c 6f61 6420 6769 7420 616e 6e65   # load git anne
+00020070: 7820 696e 666f 726d 6174 696f 6e20 6966  x information if
+00020080: 2065 7869 7374 730a 2020 2020 7472 793a   exists.    try:
+00020090: 0a20 2020 2020 2020 2072 6570 6f20 3d20  .        repo = 
+000200a0: 416e 6e65 7852 6570 6f28 6269 6473 5f72  AnnexRepo(bids_r
+000200b0: 6f6f 742c 2063 7265 6174 653d 4661 6c73  oot, create=Fals
+000200c0: 6529 0a20 2020 2020 2020 2069 6620 6669  e).        if fi
+000200d0: 6c65 7061 7468 2069 7320 6e6f 7420 4e6f  lepath is not No
+000200e0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+000200f0: 736f 7572 6365 7320 3d20 7265 706f 2e67  sources = repo.g
+00020100: 6574 5f75 726c 7328 6669 6c65 7061 7468  et_urls(filepath
+00020110: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
+00020120: 2020 2020 2020 2020 2020 2020 736f 7572              sour
+00020130: 6365 7320 3d20 7265 706f 2e67 6574 5f75  ces = repo.get_u
+00020140: 726c 7328 6269 6473 5f72 6f6f 7429 0a0a  rls(bids_root)..
+00020150: 2020 2020 2020 2020 666f 7220 736f 7572          for sour
+00020160: 6365 2069 6e20 736f 7572 6365 733a 0a20  ce in sources:. 
+00020170: 2020 2020 2020 2020 2020 2023 2061 6464             # add
+00020180: 2074 6f20 6772 6170 6820 7575 6964 0a20   to graph uuid. 
+00020190: 2020 2020 2020 2020 2020 206f 626a 2e61             obj.a
+000201a0: 6464 5f61 7474 7269 6275 7465 7328 7b43  dd_attributes({C
+000201b0: 6f6e 7374 616e 7473 2e50 524f 565b 224c  onstants.PROV["L
+000201c0: 6f63 6174 696f 6e22 5d3a 2055 5249 5265  ocation"]: URIRe
+000201d0: 6628 736f 7572 6365 297d 290a 0a20 2020  f(source)})..   
+000201e0: 2020 2020 2072 6574 7572 6e20 6c65 6e28       return len(
+000201f0: 736f 7572 6365 7329 0a20 2020 2065 7863  sources).    exc
+00020200: 6570 7420 4578 6365 7074 696f 6e3a 0a20  ept Exception:. 
+00020210: 2020 2020 2020 2023 2069 6620 224e 6f20         # if "No 
+00020220: 616e 6e65 7820 666f 756e 6420 6174 2220  annex found at" 
+00020230: 6e6f 7420 696e 2073 7472 2865 293a 0a20  not in str(e):. 
+00020240: 2020 2020 2020 2023 2020 2020 7072 696e         #    prin
+00020250: 7428 2257 6172 6e69 6e67 2c20 6572 726f  t("Warning, erro
+00020260: 7220 7769 7468 2041 6e6e 6578 5265 706f  r with AnnexRepo
+00020270: 2028 5574 696c 732e 7079 2c20 6164 6447   (Utils.py, addG
+00020280: 6974 416e 6e65 7853 6f75 7263 6573 293a  itAnnexSources):
+00020290: 222c 2065 290a 2020 2020 2020 2020 7265  ", e).        re
+000202a0: 7475 726e 2030 0a0a 0a64 6566 2074 7570  turn 0...def tup
+000202b0: 6c65 4b65 7973 546f 5369 6d70 6c65 4b65  leKeysToSimpleKe
+000202c0: 7973 2864 6963 7469 6f6e 6172 7929 3a0a  ys(dictionary):.
+000202d0: 2020 2020 2222 220a 2020 2020 5468 6973      """.    This
+000202e0: 2066 756e 6374 696f 6e20 7769 6c6c 2063   function will c
+000202f0: 6861 6e67 6520 7468 6520 6b65 7973 2069  hange the keys i
+00020300: 6e20 7468 6520 7375 7070 6c69 6564 2064  n the supplied d
+00020310: 6963 7469 6f6e 6172 7920 6672 6f6d 2074  ictionary from t
+00020320: 7570 6c65 206b 6579 7320 2865 2e67 2e20  uple keys (e.g. 
+00020330: 6672 6f6d 202e 2e63 6f72 652e 436f 6e73  from ..core.Cons
+00020340: 7461 6e74 7320 696d 706f 7274 2044 4429  tants import DD)
+00020350: 0a20 2020 2074 6f20 7369 6d70 6c65 206b  .    to simple k
+00020360: 6579 7320 7768 6572 6520 6b65 7920 6973  eys where key is
+00020370: 2076 6172 6961 626c 6520 6e61 6d65 0a20   variable name. 
+00020380: 2020 203a 7061 7261 6d20 6469 6374 696f     :param dictio
+00020390: 6e61 7279 3a20 6469 6374 696f 6e61 7279  nary: dictionary
+000203a0: 2063 7265 6174 6564 2066 726f 6d20 6d61   created from ma
+000203b0: 705f 7661 7269 6162 6c65 735f 746f 5f74  p_variables_to_t
+000203c0: 6572 6d73 0a20 2020 203a 7265 7475 726e  erms.    :return
+000203d0: 3a20 6e65 7720 6469 6374 696f 6e61 7279  : new dictionary
+000203e0: 2077 6974 6820 7369 6d70 6c65 206b 6579   with simple key
+000203f0: 730a 2020 2020 2222 220a 0a20 2020 206e  s.    """..    n
+00020400: 6577 5f64 6963 7420 3d20 7b7d 0a0a 2020  ew_dict = {}..  
+00020410: 2020 666f 7220 6b65 7920 696e 2064 6963    for key in dic
+00020420: 7469 6f6e 6172 793a 0a20 2020 2020 2020  tionary:.       
+00020430: 206b 6579 5f74 7570 6c65 203d 2065 7661   key_tuple = eva
+00020440: 6c28 6b65 7929 0a20 2020 2020 2020 2066  l(key).        f
+00020450: 6f72 2073 7562 6b65 792c 2069 7465 6d20  or subkey, item 
+00020460: 696e 206b 6579 5f74 7570 6c65 2e5f 6173  in key_tuple._as
+00020470: 6469 6374 2829 2e69 7465 6d73 2829 3a0a  dict().items():.
+00020480: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00020490: 7562 6b65 7920 3d3d 2022 7661 7269 6162  ubkey == "variab
+000204a0: 6c65 223a 0a20 2020 2020 2020 2020 2020  le":.           
+000204b0: 2020 2020 206e 6577 5f64 6963 745b 6974       new_dict[it
+000204c0: 656d 5d20 3d20 7b7d 0a20 2020 2020 2020  em] = {}.       
+000204d0: 2020 2020 2020 2020 2066 6f72 2076 6172           for var
+000204e0: 6b65 7973 2c20 7661 7276 616c 7565 7320  keys, varvalues 
+000204f0: 696e 2064 6963 7469 6f6e 6172 795b 7374  in dictionary[st
+00020500: 7228 6b65 795f 7475 706c 6529 5d2e 6974  r(key_tuple)].it
+00020510: 656d 7328 293a 0a20 2020 2020 2020 2020  ems():.         
+00020520: 2020 2020 2020 2020 2020 206e 6577 5f64             new_d
+00020530: 6963 745b 6974 656d 5d5b 7661 726b 6579  ict[item][varkey
+00020540: 735d 203d 2076 6172 7661 6c75 6573 0a0a  s] = varvalues..
+00020550: 2020 2020 7265 7475 726e 206e 6577 5f64      return new_d
+00020560: 6963 740a 0a0a 6465 6620 7661 6c69 6461  ict...def valida
+00020570: 7465 5f75 7569 6428 7575 6964 5f73 7472  te_uuid(uuid_str
+00020580: 696e 6729 3a0a 2020 2020 2222 220a 2020  ing):.    """.  
+00020590: 2020 5661 6c69 6461 7465 2074 6861 7420    Validate that 
+000205a0: 6120 5555 4944 2073 7472 696e 6720 6973  a UUID string is
+000205b0: 2069 6e0a 2020 2020 6661 6374 2061 2076   in.    fact a v
+000205c0: 616c 6964 2075 7569 6434 2e0a 2020 2020  alid uuid4..    
+000205d0: 4861 7070 696c 792c 2074 6865 2075 7569  Happily, the uui
+000205e0: 6420 6d6f 6475 6c65 2064 6f65 7320 7468  d module does th
+000205f0: 6520 6163 7475 616c 0a20 2020 2063 6865  e actual.    che
+00020600: 636b 696e 6720 666f 7220 7573 2e0a 2020  cking for us..  
+00020610: 2020 4974 2069 7320 7669 7461 6c20 7468    It is vital th
+00020620: 6174 2074 6865 2027 7665 7273 696f 6e27  at the 'version'
+00020630: 206b 7761 7267 2062 6520 7061 7373 6564   kwarg be passed
+00020640: 0a20 2020 2074 6f20 7468 6520 5555 4944  .    to the UUID
+00020650: 2829 2063 616c 6c2c 206f 7468 6572 7769  () call, otherwi
+00020660: 7365 2061 6e79 2033 322d 6368 6172 6163  se any 32-charac
+00020670: 7465 720a 2020 2020 6865 7820 7374 7269  ter.    hex stri
+00020680: 6e67 2069 7320 636f 6e73 6964 6572 6564  ng is considered
+00020690: 2076 616c 6964 2e0a 2020 2020 2222 220a   valid..    """.
+000206a0: 0a20 2020 2074 7279 3a0a 2020 2020 2020  .    try:.      
+000206b0: 2020 5555 4944 2875 7569 645f 7374 7269    UUID(uuid_stri
+000206c0: 6e67 290a 2020 2020 6578 6365 7074 2056  ng).    except V
+000206d0: 616c 7565 4572 726f 723a 0a20 2020 2020  alueError:.     
+000206e0: 2020 2023 2049 6620 6974 2773 2061 2076     # If it's a v
+000206f0: 616c 7565 2065 7272 6f72 2c20 7468 656e  alue error, then
+00020700: 2074 6865 2073 7472 696e 670a 2020 2020   the string.    
+00020710: 2020 2020 2320 6973 206e 6f74 2061 2076      # is not a v
+00020720: 616c 6964 2068 6578 2063 6f64 6520 666f  alid hex code fo
+00020730: 7220 6120 5555 4944 2e0a 2020 2020 2020  r a UUID..      
+00020740: 2020 7265 7475 726e 2046 616c 7365 0a0a    return False..
+00020750: 2020 2020 7265 7475 726e 2054 7275 650a      return True.
```

### Comparing `pynidm-3.9.7/nidm/experiment/tests/create_testfile.py` & `pynidm-4.0.0/tests/experiment/create_testfile.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,70 +1,87 @@
-import os,sys
-
-from nidm.experiment import Project,Session,MRAcquisition,MRObject, \
-    AssessmentAcquisition, AssessmentObject, DemographicsObject
 from nidm.core import Constants
+from nidm.experiment import (
+    AssessmentAcquisition,
+    AssessmentObject,
+    DemographicsObject,
+    MRAcquisition,
+    MRObject,
+    Project,
+    Session,
+)
 
 
 # dj TODO: adding more tests; I only put the Dave's pipeline to a function
-def main(argv):
-    #create new nidm-experiment document with project
-    kwargs={Constants.NIDM_PROJECT_NAME:"Test Project name",Constants.NIDM_PROJECT_IDENTIFIER:"123456",Constants.NIDM_PROJECT_DESCRIPTION:"Test Project Description"}
+def main():
+    # create new nidm-experiment document with project
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "Test Project name",
+        Constants.NIDM_PROJECT_IDENTIFIER: "123456",
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test Project Description",
+    }
     project = Project(attributes=kwargs)
 
-
-    #test add string attribute with existing namespace
-    #nidm_doc.addLiteralAttribute("nidm","isFun","ForMe")
+    # test add string attribute with existing namespace
+    # nidm_doc.addLiteralAttribute("nidm","isFun","ForMe")
     # project.add_attributes({Constants.PROV["Location"]:"http://nidm.nidash.org/"})
 
-    #test add PI to investigation
-    project_PI = project.add_person(attributes={Constants.NIDM_FAMILY_NAME:"Doe", Constants.NIDM_GIVEN_NAME:"John"})
+    # test add PI to investigation
+    project_PI = project.add_person(
+        attributes={
+            Constants.NIDM_FAMILY_NAME: "Doe",
+            Constants.NIDM_GIVEN_NAME: "John",
+        }
+    )
 
-    #add qualified association of project PI to project activity
-    project.add_qualified_association(person=project_PI,role=Constants.NIDM_PI)
+    # add qualified association of project PI to project activity
+    project.add_qualified_association(person=project_PI, role=Constants.NIDM_PI)
 
-    #test add session to graph and associate with project
+    # test add session to graph and associate with project
     session = Session(project)
-    session.add_attributes({Constants.NIDM_DESCRIPTION:"test session activity"})
+    session.add_attributes({Constants.NIDM_DESCRIPTION: "test session activity"})
 
-    #test add MR acquisition activity / entity to graph and associate with session
+    # test add MR acquisition activity / entity to graph and associate with session
     acq_act = MRAcquisition(session=session)
-    #test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
+    # test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
     acq_entity = MRObject(acquisition=acq_act)
 
-    #add person to graph
-    person = acq_act.add_person(attributes={Constants.NIDM_GIVEN_NAME:"George"})
-    #add qualified association of person with role NIDM_PARTICIPANT, and associated with acquistion activity
+    # add person to graph
+    person = acq_act.add_person(attributes={Constants.NIDM_GIVEN_NAME: "George"})
+    # add qualified association of person with role NIDM_PARTICIPANT, and associated with acquistion activity
     acq_act.add_qualified_association(person=person, role=Constants.NIDM_PARTICIPANT)
 
-
-    #test add Assessment acquisition activity / entity to graph and associate with session
+    # test add Assessment acquisition activity / entity to graph and associate with session
     acq_act = AssessmentAcquisition(session=session)
-    #test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
+    # test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
     acq_entity = AssessmentObject(acquisition=acq_act)
-    acq_entity.add_attributes({Constants.NIDM["Q1"]:"Q1 Answer",Constants.NIDM["Q2"]:"Q2 Answer" })
-    #associate person as participant
+    acq_entity.add_attributes(
+        {Constants.NIDM["Q1"]: "Q1 Answer", Constants.NIDM["Q2"]: "Q2 Answer"}
+    )
+    # associate person as participant
     acq_act.add_qualified_association(person=person, role=Constants.NIDM_PARTICIPANT)
 
-
-    #test add DemographicsAssessment acquisition activity / entity to graph and associate with session
+    # test add DemographicsAssessment acquisition activity / entity to graph and associate with session
     acq_act = AssessmentAcquisition(session=session)
-    #test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
+    # test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
     acq_entity = DemographicsObject(acquisition=acq_act)
-    #add new person to graph
-    person2 = acq_act.add_person(attributes={Constants.NIDM_FAMILY_NAME:"Doe", \
-            Constants.NIDM_GIVEN_NAME:"John"})
-    #associate person2 with assessment acquisition
+    # add new person to graph
+    person2 = acq_act.add_person(
+        attributes={
+            Constants.NIDM_FAMILY_NAME: "Doe",
+            Constants.NIDM_GIVEN_NAME: "John",
+        }
+    )
+    # associate person2 with assessment acquisition
     acq_act.add_qualified_association(person=person2, role=Constants.NIDM_PARTICIPANT)
 
-    acq_entity.add_attributes({Constants.NIDM_AGE:60,Constants.NIDM_GENDER:"Male" })
+    acq_entity.add_attributes({Constants.NIDM_AGE: 60, Constants.NIDM_GENDER: "Male"})
 
+    # save a turtle file
+    with open("test_nidm.ttl", "w", encoding="utf-8") as f:
+        f.write(project.serializeTurtle())
 
-    #save a turtle file
-    with open("test_nidm.ttl",'w') as f:
-        f.write (project.serializeTurtle())
+    # save a DOT graph as PDF
+    project.save_DotGraph("test_nidm.png", format="png")
 
-    #save a DOT graph as PDF
-    project.save_DotGraph("test_nidm.png",format="png")
 
 if __name__ == "__main__":
-   main(sys.argv[1:])
+    main()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tests/termsearch.py` & `pynidm-4.0.0/tests/experiment/termsearch.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,52 +1,61 @@
-import os,sys
-import pytest, pdb
-from pprint import pprint
-
 from argparse import ArgumentParser
+from pprint import pprint
 from nidm.experiment import Utils
 
-def main(argv):
-    parser = ArgumentParser(description='This program will query SciCrunch term labels for query_string using key and print out the return JSON packet.')
-    parser.add_argument('-query_string', dest='query_string', required=True, help="Query String")
-    parser.add_argument('-key', dest='key', required=True, help="SciCrunch API key to use for query")
+
+def main():
+    parser = ArgumentParser(
+        description="This program will query SciCrunch term labels for query_string using key and print out the return JSON packet."
+    )
+    parser.add_argument(
+        "-query_string", dest="query_string", required=True, help="Query String"
+    )
+    parser.add_argument(
+        "-key", dest="key", required=True, help="SciCrunch API key to use for query"
+    )
     args = parser.parse_args()
 
-    #Test exact match search returning JSON package
+    # Test exact match search returning JSON package
     print("Testing term label search...")
     json_data = Utils.QuerySciCrunchTermLabel(args.key, args.query_string)
     print("Term label search returns:")
     print("-------------------------------------------")
     pprint(json_data)
     print("\n\n")
 
-    #Test elastic search using CDEs and Terms + ancestors (simulates tagging sets of terms for NIDM use) returning JSON package
+    # Test elastic search using CDEs and Terms + ancestors (simulates tagging sets of terms for NIDM use) returning JSON package
     print("Testing elastic search...")
     json_data = Utils.QuerySciCrunchElasticSearch(args.key, args.query_string)
     print("Elastic search returns:")
     print("-------------------------------------------")
     pprint(json_data)
-  #  print("\n\n-------------------------------------------")
-  #  print("Example terms listing from elastic search:")
+    #  print("\n\n-------------------------------------------")
+    #  print("Example terms listing from elastic search:")
 
-    #example printing term label, definition, and preferred URL
-  #  for term in json_data['hits']['hits']:
-  #      #find preferred URL
-  #      for items in term['_source']['existing_ids']:
-  #          if items['preferred']=='1':
-  #              preferred_url=items['iri']
-  #      print("Label = %s \t Definition = %s \t Preferred URL = %s " %(term['_source']['label'],term['_source']['definition'],preferred_url))
+    # example printing term label, definition, and preferred URL
+    #  for term in json_data['hits']['hits']:
+    #      #find preferred URL
+    #      for items in term['_source']['existing_ids']:
+    #          if items['preferred']=='1':
+    #              preferred_url=items['iri']
+    #      print(f"Label = {term['_source']['label']} \t Definition = {term['_source']['definition']} \t Preferred URL = {preferred_url} ")
 
-    #example of uber elastic search query returns dictionary of label, definition, and preferred_url
+    # example of uber elastic search query returns dictionary of label, definition, and preferred_url
     print("\n\n-------------------------------------------")
     print("Example uber elastic search:")
-    results = Utils.GetNIDMTermsFromSciCrunch(args.key,args.query_string)
-    for key,value in results.items():
-        print("Label: %s \t Definition: %s \t Preferred URL: %s " %(results[key]['label'],results[key]['definition'],results[key]['preferred_url']  ))
+    results = Utils.GetNIDMTermsFromSciCrunch(args.key, args.query_string)
+    for value in results.values():
+        print(
+            "Label: {label} \t Definition: {definition} \t Preferred URL: {preferred_url} ".format_map(
+                value
+            )
+        )
+
 
 if __name__ == "__main__":
-   main(sys.argv[1:])
+    main()
 
-# very simple test, just checking if main doesnt give any error
-def test_main():
-    main(sys.argv[1:])
 
+# very simple test, just checking if main does not give any error
+def test_main():
+    main()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tests/test_experiment.py` & `pynidm-4.0.0/tests/experiment/test_experiment.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,90 +1,109 @@
-import os,sys
-
-from nidm.experiment import Project,Session,MRAcquisition,MRObject, \
-    AssessmentAcquisition, AssessmentObject, DemographicsObject
+from pathlib import Path
+import pytest
 from nidm.core import Constants
+from nidm.experiment import (
+    AssessmentAcquisition,
+    AssessmentObject,
+    DemographicsObject,
+    MRAcquisition,
+    MRObject,
+    Project,
+    Session,
+)
 
 
 # dj TODO: adding more tests; I only put the Dave's pipeline to a function
-def main(argv):
-    #create new nidm-experiment document with project
-    kwargs={Constants.NIDM_PROJECT_NAME:"FBIRN_PhaseII",Constants.NIDM_PROJECT_IDENTIFIER:9610,Constants.NIDM_PROJECT_DESCRIPTION:"Test investigation"}
+def main():
+    # create new nidm-experiment document with project
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII",
+        Constants.NIDM_PROJECT_IDENTIFIER: 9610,
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation",
+    }
     project = Project(attributes=kwargs)
 
-    
-    #test add string attribute with existing namespace
-    #nidm_doc.addLiteralAttribute("nidm","isFun","ForMe")
-    project.add_attributes({Constants.NIDM["isFun"]:"ForMe"})
+    # test add string attribute with existing namespace
+    # nidm_doc.addLiteralAttribute("nidm","isFun","ForMe")
+    project.add_attributes({Constants.NIDM["isFun"]: "ForMe"})
 
-    #test adding string attribute with new namespace/term
-    project.addLiteralAttribute("fred","notFound","in namespaces","www.fred.org/")
+    # test adding string attribute with new namespace/term
+    project.addLiteralAttribute("fred", "notFound", "in namespaces", "www.fred.org/")
 
-    #test add float attribute
+    # test add float attribute
     project.addLiteralAttribute("nidm", "float", float(2.34))
 
-    #test adding attributes in bulk with mix of existing and new namespaces
-    #nidm_doc.addAttributesWithNamespaces(nidm_doc.getProject(),[{"prefix":"nidm", "uri":nidm_doc.namespaces["nidm"], "term":"score", "value":int(15)}, \
-        #                                              {"prefix":"dave", "uri":"http://www.davidkeator.com/", "term":"isAwesome", "value":"15"}, \
-        #                                              {"prefix":"nidm", "uri":nidm_doc.namespaces["nidm"], "term":"value", "value":float(2.34)}])
-    
-    #nidm_doc.addAttributes(nidm_doc.getProject(),{"nidm:test":int(15), "ncit:isTerminology":"15","ncit:joker":float(1)})
-
+    # test adding attributes in bulk with mix of existing and new namespaces
+    # nidm_doc.addAttributesWithNamespaces(nidm_doc.getProject(),[{"prefix":"nidm", "uri":nidm_doc.namespaces["nidm"], "term":"score", "value":int(15)}, \
+    #                                              {"prefix":"dave", "uri":"http://www.davidkeator.com/", "term":"isAwesome", "value":"15"}, \
+    #                                              {"prefix":"nidm", "uri":nidm_doc.namespaces["nidm"], "term":"value", "value":float(2.34)}])
+
+    # nidm_doc.addAttributes(nidm_doc.getProject(),{"nidm:test":int(15), "ncit:isTerminology":"15","ncit:joker":float(1)})
+
+    # test add PI to investigation
+    project_PI = project.add_person(
+        attributes={
+            Constants.NIDM_FAMILY_NAME: "Keator",
+            Constants.NIDM_GIVEN_NAME: "David",
+        }
+    )
 
-    #test add PI to investigation
-    project_PI = project.add_person(attributes={Constants.NIDM_FAMILY_NAME:"Keator", Constants.NIDM_GIVEN_NAME:"David"})
+    # add qualified association of project PI to project activity
+    project.add_qualified_association(person=project_PI, role=Constants.NIDM_PI)
 
-    #add qualified association of project PI to project activity
-    project.add_qualified_association(person=project_PI,role=Constants.NIDM_PI)
-
-    #test add session to graph and associate with project
+    # test add session to graph and associate with project
     session = Session(project)
-    session.add_attributes({Constants.NIDM:"test"})
-    #project.add_sessions(session)
+    session.add_attributes({Constants.NIDM: "test"})
+    # project.add_sessions(session)
 
-    #test add MR acquisition activity / entity to graph and associate with session
+    # test add MR acquisition activity / entity to graph and associate with session
     acq_act = MRAcquisition(session=session)
-    #test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
+    # test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
     acq_entity = MRObject(acquisition=acq_act)
 
-    #add person to graph
-    person = acq_act.add_person(attributes={Constants.NIDM_GIVEN_NAME:"George"})
-    #add qualified association of person with role NIDM_PARTICIPANT, and associated with acquistion activity
+    # add person to graph
+    person = acq_act.add_person(attributes={Constants.NIDM_GIVEN_NAME: "George"})
+    # add qualified association of person with role NIDM_PARTICIPANT, and associated with acquistion activity
     acq_act.add_qualified_association(person=person, role=Constants.NIDM_PARTICIPANT)
 
-
-    #test add Assessment acquisition activity / entity to graph and associate with session
+    # test add Assessment acquisition activity / entity to graph and associate with session
     acq_act = AssessmentAcquisition(session=session)
-    #test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
+    # test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
     acq_entity = AssessmentObject(acquisition=acq_act)
-    acq_entity.add_attributes({Constants.NIDM["Q1"]:"Q1 Answer",Constants.NIDM["Q2"]:"Q2 Answer" })
-    #associate person as participant
+    acq_entity.add_attributes(
+        {Constants.NIDM["Q1"]: "Q1 Answer", Constants.NIDM["Q2"]: "Q2 Answer"}
+    )
+    # associate person as participant
     acq_act.add_qualified_association(person=person, role=Constants.NIDM_PARTICIPANT)
 
-
-    #test add DemographicsAssessment acquisition activity / entity to graph and associate with session
+    # test add DemographicsAssessment acquisition activity / entity to graph and associate with session
     acq_act = AssessmentAcquisition(session=session)
-    #test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
+    # test add acquisition object entity to graph associated with participant role NIDM_PARTICIPANT
     acq_entity = DemographicsObject(acquisition=acq_act)
-    #add new person to graph
-    person2 = acq_act.add_person(attributes={Constants.NIDM_FAMILY_NAME:"Doe", \
-            Constants.NIDM_GIVEN_NAME:"John"})
-    #associate person2 with assessment acquisition
+    # add new person to graph
+    person2 = acq_act.add_person(
+        attributes={
+            Constants.NIDM_FAMILY_NAME: "Doe",
+            Constants.NIDM_GIVEN_NAME: "John",
+        }
+    )
+    # associate person2 with assessment acquisition
     acq_act.add_qualified_association(person=person2, role=Constants.NIDM_PARTICIPANT)
 
-    acq_entity.add_attributes({Constants.NIDM_AGE:60,Constants.NIDM_GENDER:"Male" })
-
+    acq_entity.add_attributes({Constants.NIDM_AGE: 60, Constants.NIDM_GENDER: "Male"})
 
-    #save a turtle file
-    with open("test.ttl",'w') as f:
-        f.write (project.serializeTurtle())
+    # save a turtle file
+    with open("test.ttl", "w", encoding="utf-8") as f:
+        f.write(project.serializeTurtle())
 
-    #save a DOT graph as PDF
+    # save a DOT graph as PDF
     # project.save_DotGraph("test.png",format="png")
 
+
 if __name__ == "__main__":
-   main(sys.argv[1:])
+    main()
 
-# very simple test, just checking if main doesnt give any error
-def test_main():
-    main(sys.argv[1:])
 
+# very simple test, just checking if main does not give any error
+def test_main(monkeypatch: pytest.MonkeyPatch, tmp_path: Path) -> None:
+    monkeypatch.chdir(tmp_path)
+    main()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tests/test_experiment_basic.py` & `pynidm-4.0.0/tests/experiment/test_experiment_basic.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,68 +1,58 @@
-import os,sys
-import pytest, pdb
-from os import remove
+from io import StringIO
 import json
-from nidm.experiment import Project, Session, Acquisition, AcquisitionObject
+from pathlib import Path
+import prov
+import rdflib
 from nidm.core import Constants
-from io import StringIO
-from rdflib import Graph
-from nidm.experiment.Utils import read_nidm
+from nidm.experiment import Project, Session
 
-import prov, rdflib
-
-def test_1(tmpdir):
-    tmpdir.chdir()
 
+def test_1(tmp_path: Path) -> None:
     project = Project()
-
-    #save a turtle file
-    with open("test.ttl",'w') as f:
+    # save a turtle file
+    with open(tmp_path / "test.ttl", "w", encoding="utf-8") as f:
         f.write(project.serializeTurtle())
 
 
-def test_2(tmpdir):
-    tmpdir.chdir()
-
-    kwargs={Constants.NIDM_PROJECT_NAME:"FBIRN_PhaseII",Constants.NIDM_PROJECT_IDENTIFIER:9610,Constants.NIDM_PROJECT_DESCRIPTION:"Test investigation"}
+def test_2(tmp_path: Path) -> None:
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII",
+        Constants.NIDM_PROJECT_IDENTIFIER: 9610,
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation",
+    }
     project = Project(attributes=kwargs)
 
-    with open("test.ttl",'w') as f:
+    with open(tmp_path / "test.ttl", "w", encoding="utf-8") as f:
         f.write(project.serializeTurtle())
 
 
-def test_sessions_1(tmpdir):
-    tmpdir.chdir()
-
+def test_sessions_1() -> None:
     project = Project()
-    assert project.sessions == []
+    assert not project.sessions
 
     session1 = Session(project)
     project.add_sessions(session1)
     assert session1.label == project.sessions[0].label
 
     session2 = Session(project)
     project.add_sessions(session2)
     assert len(project.sessions) == 2
     assert session2.label == project.sessions[1].label
 
 
-def test_sessions_2(tmpdir):
-    tmpdir.chdir()
-
+def test_sessions_2() -> None:
     project = Project()
-    assert project.sessions == []
+    assert not project.sessions
 
     session1 = Session(project)
     assert project.sessions[0].label == session1.label
 
 
-def test_sessions_3(tmpdir):
-    tmpdir.chdir()
-
+def test_sessions_3() -> None:
     project1 = Project()
     project2 = Project()
 
     session1 = Session(project1)
     session2 = Session(project2)
 
     project1.add_sessions(session1)
@@ -84,15 +74,15 @@
     # checking graph namespace
     const_l = list(Constants.namespaces)
     namesp = [i.prefix for i in proj.graph.namespaces]
     assert sorted(const_l) == sorted(namesp)
 
     # checking type
     proj_type = proj.get_type()
-    assert eval(proj_type.provn_representation()) == 'prov:Activity'
+    assert eval(proj_type.provn_representation()) == "prov:Activity"
 
     # checking length of graph records; it doesn work if all tests are run
     assert len(proj.graph.get_records()) == 1
 
 
 def test_project_emptygraph():
     # creating project without parameters
@@ -103,15 +93,15 @@
 
     # checking graph namespace
     namesp = [i.prefix for i in proj.graph.namespaces]
     assert namesp == ["nidm"]
 
     # checking type
     proj_type = proj.get_type()
-    assert eval(proj_type.provn_representation()) == 'prov:Activity'
+    assert eval(proj_type.provn_representation()) == "prov:Activity"
 
     assert len(proj.graph.get_records()) == 1
 
 
 def test_project_uuid():
     # creating project without parameters
     proj = Project(uuid="my_uuid")
@@ -123,111 +113,117 @@
     # checking graph namespace
     const_l = list(Constants.namespaces)
     namesp = [i.prefix for i in proj.graph.namespaces]
     assert sorted(const_l) == sorted(namesp)
 
     # checking type
     proj_type = proj.get_type()
-    assert eval(proj_type.provn_representation()) == 'prov:Activity'
+    assert eval(proj_type.provn_representation()) == "prov:Activity"
 
     # checking if uuid is correct
     assert proj.identifier.localpart == "my_uuid"
 
     # checking length of graph records; it doesn work if all tests are run
     assert len(proj.graph.get_records()) == 1
 
 
 def test_project_att():
     # creating project without parameters
-    proj = Project(attributes={prov.model.QualifiedName(Constants.NIDM, "title"): "MyPRoject"})
+    proj = Project(
+        attributes={prov.model.QualifiedName(Constants.NIDM, "title"): "MyPRoject"}
+    )
 
     # checking if we created ProvDocument
     assert type(proj.bundle) is Constants.NIDMDocument
     assert issubclass(type(proj.bundle), prov.model.ProvDocument)
 
     # checking graph namespace
     const_l = list(Constants.namespaces)
     namesp = [i.prefix for i in proj.graph.namespaces]
-    assert sorted(const_l+[rdflib.term.URIRef('http://purl.org/nidash/nidm#prefix')]) == sorted(namesp)
+    assert sorted(
+        const_l + [rdflib.term.URIRef("http://purl.org/nidash/nidm#prefix")]
+    ) == sorted(namesp)
 
     # checking type
     proj_type = proj.get_type()
-    assert eval(proj_type.provn_representation()) == 'prov:Activity'
+    assert eval(proj_type.provn_representation()) == "prov:Activity"
 
     # checking length of graph records; it doesn work if all tests are run
     assert len(proj.graph.get_records()) == 1
 
 
 def test_session_noparameters():
     # creating project without parameters and a session to the project
     proj = Project()
-    sess = Session(proj)
+    Session(proj)
 
     # checking if we created ProvDocument
     assert type(proj.bundle) is Constants.NIDMDocument
     assert issubclass(type(proj.bundle), prov.model.ProvDocument)
 
     # checking if one session is added
-    assert len(proj.sessions)
+    assert len(proj.sessions) != 0
 
     # checking graph namespace
     const_l = list(Constants.namespaces)
     namesp = [i.prefix for i in proj.graph.namespaces]
     assert sorted(const_l) == sorted(namesp)
 
     # checking type
     proj_type = proj.get_type()
-    assert eval(proj_type.provn_representation()) == 'prov:Activity'
+    assert eval(proj_type.provn_representation()) == "prov:Activity"
 
     # checking length of graph records; it doesn work if all tests are run
     assert len(proj.graph.get_records()) == 2
 
 
-def test_jsonld_exports():
+def test_jsonld_exports(tmp_path: Path) -> None:
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII",
+        Constants.NIDM_PROJECT_IDENTIFIER: 9610,
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation",
+    }
+    project = Project(uuid="_123456", attributes=kwargs)
 
-    kwargs={Constants.NIDM_PROJECT_NAME:"FBIRN_PhaseII",Constants.NIDM_PROJECT_IDENTIFIER:9610,Constants.NIDM_PROJECT_DESCRIPTION:"Test investigation"}
-    project = Project(uuid="_123456",attributes=kwargs)
-
-
-    #save a turtle file
-    with open("test.json",'w') as f:
+    # save a turtle file
+    with open(tmp_path / "test.json", "w", encoding="utf-8") as f:
         f.write(project.serializeJSONLD())
 
-    #load in JSON file
-    with open("test.json") as json_file:
+    # load in JSON file
+    with open(tmp_path / "test.json", encoding="utf-8") as json_file:
         data = json.load(json_file)
 
+    assert data["Identifier"]["@value"] == "9610"
+    # WIP  Read back in json-ld file and check that we have the project info
 
-    assert(data["Identifier"]['@value'] == "9610")
-    #WIP  Read back in json-ld file and check that we have the project info
-    #remove("test.json")
 
 def test_project_trig_serialization():
-
     outfile = StringIO()
 
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII",
+        Constants.NIDM_PROJECT_IDENTIFIER: 9610,
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation",
+    }
+    project = Project(uuid="_123456", attributes=kwargs)
 
-    kwargs={Constants.NIDM_PROJECT_NAME:"FBIRN_PhaseII",Constants.NIDM_PROJECT_IDENTIFIER:9610,Constants.NIDM_PROJECT_DESCRIPTION:"Test investigation"}
-    project = Project(uuid="_123456",attributes=kwargs)
-
-
-    #save as trig file with graph identifier Constants.NIDM_Project
+    # save as trig file with graph identifier Constants.NIDM_Project
     test = project.serializeTrig(identifier=Constants.NIIRI["_996"])
-    if not isinstance(test,str):
-        outfile.write(test.decode('ASCII'))
+    if not isinstance(test, str):
+        outfile.write(test.decode("ASCII"))
     else:
         outfile.write(test)
     outfile.seek(0)
 
     # WIP: RDFLib doesn't seem to have a Trig parser?!?
-    #load back into rdf graph and do assertions
+    # load back into rdf graph and do assertions
     # project2 = Graph()
     # project2.parse(source=outfile)
 
-
-    #test some assertion on read file
+    # test some assertion on read file
     # print(project2.serialize(format='turtle').decode('ASCII'))
     # print(project2.serialize(format='trig').decode('ASCII'))
 
-#TODO: checking
-#attributes{pm.QualifiedName(Namespace("uci", "https.../"), "mascot"): "bleble", ...}
+
+# TODO: checking
+# attributes{pm.QualifiedName(Namespace("uci", "https.../"), "mascot"): "bleble", ...}
 # (has to be "/" at the end (or #)
```

### Comparing `pynidm-3.9.7/nidm/experiment/tests/test_map_vars_to_terms.py` & `pynidm-4.0.0/tests/experiment/test_map_vars_to_terms.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,37 +1,45 @@
-
+from dataclasses import dataclass
+import json
 from pathlib import Path
-import pytest
 import pandas as pd
-import json
-import os
-import urllib
-import re
-from  nidm.experiment.Utils import map_variables_to_terms
-import tempfile
-from os.path import join
-from nidm.core import Constants
-from uuid import UUID
-
-
-
-
+import pytest
+from nidm.experiment.Utils import map_variables_to_terms
 
-@pytest.fixture(scope="module", autouse="True")
-def setup():
-    global DATA, REPROSCHEMA_JSON_MAP, BIDS_SIDECAR
 
-    temp = { 'participant_id': ['100', '101', '102', '103', '104', '105', '106', '107', '108', '109'],
-             'age': [18, 25, 30,19 ,35 ,20 ,27 ,29 ,38 ,27],
-             'sex': ['m', 'm', 'f', 'm', 'f', 'f', 'f', 'f', 'm','m'] }
+@dataclass
+class Setup:
+    data: pd.DataFrame
+    reproschema_json_map: dict
+    bids_sidecar: dict
+
+
+@pytest.fixture(scope="module")
+def setup() -> Setup:
+    temp = {
+        "participant_id": [
+            "100",
+            "101",
+            "102",
+            "103",
+            "104",
+            "105",
+            "106",
+            "107",
+            "108",
+            "109",
+        ],
+        "age": [18, 25, 30, 19, 35, 20, 27, 29, 38, 27],
+        "sex": ["m", "m", "f", "m", "f", "f", "f", "f", "m", "m"],
+    }
 
-    DATA = pd.DataFrame(temp)
+    data = pd.DataFrame(temp)
 
-    REPROSCHEMA_JSON_MAP = json.loads(
-        '''
+    reproschema_json_map = json.loads(
+        """
         {
             "DD(source='participants.tsv', variable='participant_id')": {
                 "label": "participant_id",
                 "description": "subject/participant identifier",
                 "source_variable": "participant_id",
                 "responseOptions": {
                     "valueType": "http://www.w3.org/2001/XMLSchema#string"
@@ -79,18 +87,19 @@
                 "isAbout": [
                     {
                         "@id": "http://uri.interlex.org/ilx_0738439",
                         "label": "SEX"
                     }
                 ]
             }
-        }''')
+        }"""
+    )
 
-    BIDS_SIDECAR = json.loads(
-        '''
+    bids_sidecar = json.loads(
+        """
         {
             "age": {
                 "label": "age",
                 "description": "age of participant",
                 "source_variable": "age",
                 "associatedWith": "NIDM",
                 "isAbout": [
@@ -120,143 +129,246 @@
                     {
                         "@id": "http://uri.interlex.org/ilx_0738439",
                         "label": "SEX"
                     }
                 ]
             }
         }
-        
-        ''')
+        """
+    )
+
+    return Setup(
+        data=data,
+        reproschema_json_map=reproschema_json_map,
+        bids_sidecar=bids_sidecar,
+    )
 
 
-def test_map_vars_to_terms_BIDS():
-    '''
+def test_map_vars_to_terms_BIDS(setup: Setup, tmp_path: Path) -> None:
+    """
     This function will test the Utils.py "map_vars_to_terms" function with a BIDS-formatted
     JSON sidecar file
-    '''
+    """
 
-
-    global DATA, BIDS_SIDECAR
-
-    column_to_terms, cde = map_variables_to_terms(df=DATA,json_source=BIDS_SIDECAR,
-                directory=tempfile.gettempdir(),assessment_name="test",bids=True)
+    column_to_terms, cde = map_variables_to_terms(
+        df=setup.data,
+        json_source=setup.bids_sidecar,
+        directory=str(tmp_path),
+        assessment_name="test",
+        bids=True,
+    )
 
     # check whether JSON mapping structure returned from map_variables_to_terms matches the
     # reproshema structure
-    assert "DD(source='test', variable='age')" in column_to_terms.keys()
-    assert "DD(source='test', variable='sex')" in column_to_terms.keys()
-    assert "isAbout" in column_to_terms["DD(source='test', variable='age')"].keys()
-    assert "http://uri.interlex.org/ilx_0100400" == column_to_terms["DD(source='test', variable='age')"] \
-            ['isAbout'][0]['@id']
-    assert "http://uri.interlex.org/ilx_0738439" == column_to_terms["DD(source='test', variable='sex')"] \
-                ['isAbout'][0]['@id']
-    assert "responseOptions" in column_to_terms["DD(source='test', variable='sex')"].keys()
-    assert "choices" in column_to_terms["DD(source='test', variable='sex')"]['responseOptions'].keys()
-    assert "Male" in column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices'].keys()
-    assert "m" == column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices']['Male']
-    assert "Male" in column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices'].keys()
-    assert "m" == column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices']['Male']
+    assert "DD(source='test', variable='age')" in column_to_terms
+    assert "DD(source='test', variable='sex')" in column_to_terms
+    assert "isAbout" in column_to_terms["DD(source='test', variable='age')"]
+    assert (
+        "http://uri.interlex.org/ilx_0100400"
+        == column_to_terms["DD(source='test', variable='age')"]["isAbout"][0]["@id"]
+    )
+    assert (
+        "http://uri.interlex.org/ilx_0738439"
+        == column_to_terms["DD(source='test', variable='sex')"]["isAbout"][0]["@id"]
+    )
+    assert (
+        "responseOptions" in column_to_terms["DD(source='test', variable='sex')"].keys()
+    )
+    assert (
+        "choices"
+        in column_to_terms["DD(source='test', variable='sex')"][
+            "responseOptions"
+        ].keys()
+    )
+    assert (
+        "Male"
+        in column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ].keys()
+    )
+    assert (
+        "m"
+        == column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ]["Male"]
+    )
+    assert (
+        "Male"
+        in column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ].keys()
+    )
+    assert (
+        "m"
+        == column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ]["Male"]
+    )
 
     # now check the JSON sidecar file created by map_variables_to_terms which should match BIDS format
-    with open(join(tempfile.gettempdir(),"nidm_annotations.json")) as fp:
+    with open(tmp_path / "nidm_annotations.json", encoding="utf-8") as fp:
         bids_sidecar = json.load(fp)
 
     assert "age" in bids_sidecar.keys()
     assert "sex" in bids_sidecar.keys()
     assert "isAbout" in bids_sidecar["age"].keys()
-    assert "http://uri.interlex.org/ilx_0100400" == bids_sidecar["age"] \
-        ['isAbout'][0]['@id']
-    assert "http://uri.interlex.org/ilx_0738439" == bids_sidecar["sex"] \
-        ['isAbout'][0]['@id']
+    assert (
+        "http://uri.interlex.org/ilx_0100400"
+        == bids_sidecar["age"]["isAbout"][0]["@id"]
+    )
+    assert (
+        "http://uri.interlex.org/ilx_0738439"
+        == bids_sidecar["sex"]["isAbout"][0]["@id"]
+    )
     assert "levels" in bids_sidecar["sex"].keys()
-    assert "Male" in bids_sidecar["sex"]['levels'].keys()
-    assert "m" == bids_sidecar["sex"]['levels']['Male']
-    assert "Male" in bids_sidecar["sex"]['levels'].keys()
-    assert "m" == bids_sidecar["sex"]['levels']['Male']
+    assert "Male" in bids_sidecar["sex"]["levels"].keys()
+    assert "m" == bids_sidecar["sex"]["levels"]["Male"]
+    assert "Male" in bids_sidecar["sex"]["levels"].keys()
+    assert "m" == bids_sidecar["sex"]["levels"]["Male"]
 
     # check the CDE dataelement graph for correct information
-    query = '''
+    query = """
         prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>
-        
+
         select distinct ?uuid ?DataElements ?property ?value
             where {
 
                 ?uuid a/rdfs:subClassOf* nidm:DataElement ;
                     ?property ?value .
 
-        }'''
-    qres=cde.query(query)
+        }"""
+    qres = cde.query(query)
 
-    results=[]
+    results = []
     for row in qres:
         results.append(list(row))
 
     assert len(results) == 20
 
 
-def test_map_vars_to_terms_reproschema():
-    '''
+def test_map_vars_to_terms_reproschema(setup: Setup, tmp_path: Path) -> None:
+    """
     This function will test the Utils.py "map_vars_to_terms" function with a reproschema-formatted
     JSON sidecar file
-    '''
+    """
 
-    global DATA, REPROSCHEMA_JSON_MAP
-
-    column_to_terms, cde = map_variables_to_terms(df=DATA, json_source=REPROSCHEMA_JSON_MAP,
-                                                  directory=tempfile.gettempdir(), assessment_name="test")
+    column_to_terms, cde = map_variables_to_terms(
+        df=setup.data,
+        json_source=setup.reproschema_json_map,
+        directory=str(tmp_path),
+        assessment_name="test",
+    )
 
     # check whether JSON mapping structure returned from map_variables_to_terms matches the
     # reproshema structure
-    assert "DD(source='test', variable='age')" in column_to_terms.keys()
-    assert "DD(source='test', variable='sex')" in column_to_terms.keys()
-    assert "isAbout" in column_to_terms["DD(source='test', variable='age')"].keys()
-    assert "http://uri.interlex.org/ilx_0100400" == column_to_terms["DD(source='test', variable='age')"] \
-        ['isAbout'][0]['@id']
-    assert "http://uri.interlex.org/ilx_0738439" == column_to_terms["DD(source='test', variable='sex')"] \
-        ['isAbout'][0]['@id']
-    assert "responseOptions" in column_to_terms["DD(source='test', variable='sex')"].keys()
-    assert "choices" in column_to_terms["DD(source='test', variable='sex')"]['responseOptions'].keys()
-    assert "Male" in column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices'].keys()
-    assert "m" == column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices']['Male']
-    assert "Male" in column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices'].keys()
-    assert "m" == column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices']['Male']
+    assert "DD(source='test', variable='age')" in column_to_terms
+    assert "DD(source='test', variable='sex')" in column_to_terms
+    assert "isAbout" in column_to_terms["DD(source='test', variable='age')"]
+    assert (
+        "http://uri.interlex.org/ilx_0100400"
+        == column_to_terms["DD(source='test', variable='age')"]["isAbout"][0]["@id"]
+    )
+    assert (
+        "http://uri.interlex.org/ilx_0738439"
+        == column_to_terms["DD(source='test', variable='sex')"]["isAbout"][0]["@id"]
+    )
+    assert (
+        "responseOptions" in column_to_terms["DD(source='test', variable='sex')"].keys()
+    )
+    assert (
+        "choices"
+        in column_to_terms["DD(source='test', variable='sex')"][
+            "responseOptions"
+        ].keys()
+    )
+    assert (
+        "Male"
+        in column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ].keys()
+    )
+    assert (
+        "m"
+        == column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ]["Male"]
+    )
+    assert (
+        "Male"
+        in column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ].keys()
+    )
+    assert (
+        "m"
+        == column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ]["Male"]
+    )
 
     # now check the JSON mapping file created by map_variables_to_terms which should match Reproschema format
-    with open(join(tempfile.gettempdir(), "nidm_annotations.json")) as fp:
-        reproschema_json = json.load(fp)
+    with open(tmp_path / "nidm_annotations_annotations.json", encoding="utf-8") as fp:
+        json.load(fp)
 
-    assert "DD(source='test', variable='age')" in column_to_terms.keys()
-    assert "DD(source='test', variable='sex')" in column_to_terms.keys()
-    assert "isAbout" in column_to_terms["DD(source='test', variable='age')"].keys()
-    assert "http://uri.interlex.org/ilx_0100400" == column_to_terms["DD(source='test', variable='age')"] \
-        ['isAbout'][0]['@id']
-    assert "http://uri.interlex.org/ilx_0738439" == column_to_terms["DD(source='test', variable='sex')"] \
-        ['isAbout'][0]['@id']
-    assert "responseOptions" in column_to_terms["DD(source='test', variable='sex')"].keys()
-    assert "choices" in column_to_terms["DD(source='test', variable='sex')"]['responseOptions'].keys()
-    assert "Male" in column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices'].keys()
-    assert "m" == column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices']['Male']
-    assert "Male" in column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices'].keys()
-    assert "m" == column_to_terms["DD(source='test', variable='sex')"]['responseOptions']['choices']['Male']
+    assert "DD(source='test', variable='age')" in column_to_terms
+    assert "DD(source='test', variable='sex')" in column_to_terms
+    assert "isAbout" in column_to_terms["DD(source='test', variable='age')"]
+    assert (
+        "http://uri.interlex.org/ilx_0100400"
+        == column_to_terms["DD(source='test', variable='age')"]["isAbout"][0]["@id"]
+    )
+    assert (
+        "http://uri.interlex.org/ilx_0738439"
+        == column_to_terms["DD(source='test', variable='sex')"]["isAbout"][0]["@id"]
+    )
+    assert (
+        "responseOptions" in column_to_terms["DD(source='test', variable='sex')"].keys()
+    )
+    assert (
+        "choices"
+        in column_to_terms["DD(source='test', variable='sex')"][
+            "responseOptions"
+        ].keys()
+    )
+    assert (
+        "Male"
+        in column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ].keys()
+    )
+    assert (
+        "m"
+        == column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ]["Male"]
+    )
+    assert (
+        "Male"
+        in column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ].keys()
+    )
+    assert (
+        "m"
+        == column_to_terms["DD(source='test', variable='sex')"]["responseOptions"][
+            "choices"
+        ]["Male"]
+    )
 
     # check the CDE dataelement graph for correct information
-    query = '''
+    query = """
         prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>
 
         select distinct ?uuid ?DataElements ?property ?value
             where {
 
                 ?uuid a/rdfs:subClassOf* nidm:DataElement ;
                     ?property ?value .
 
-        }'''
+        }"""
     qres = cde.query(query)
 
     results = []
     for row in qres:
         results.append(list(row))
 
     assert len(results) == 20
-
-
-    
-
```

### Comparing `pynidm-3.9.7/nidm/experiment/tests/test_query.py` & `pynidm-4.0.0/tests/experiment/test_query.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,163 +1,179 @@
-import nidm.experiment.Navigate
-from nidm.experiment import Project, Session, AssessmentAcquisition, AssessmentObject, Acquisition, AcquisitionObject, \
-    Query
-from nidm.core import Constants
-from rdflib import Namespace, URIRef
-import prov.model as pm
-from os import remove, path, environ
+from __future__ import annotations
+from dataclasses import dataclass
+from pathlib import Path
 import tempfile
+from typing import Optional
+import prov.model as pm
 import pytest
+from nidm.core import Constants
+from nidm.experiment import (
+    Acquisition,
+    AssessmentAcquisition,
+    AssessmentObject,
+    Project,
+    Query,
+    Session,
+)
 from nidm.experiment.CDE import download_cde_files
-from nidm.experiment.tools.rest_statistics import GetProjectsComputedMetadata
-
-
-from prov.model import ProvDocument, QualifiedName
-from prov.model import Namespace as provNamespace
-import json
-import urllib.request
-from pathlib import Path
-
-ABIDE_FILES = ('cmu_a.nidm.ttl',)
+import nidm.experiment.Navigate
 
-cmu_test_project_uuid = None
-cmu_test_subject_uuid = None
 
+@dataclass
+class ProjectData:
+    files: list[str]
+    cmu_test_project_uuid: str
 
-# when set to true, this will test example NIDM files downloaded from
-# the GitHub dbkeator/simple2_NIDM_examples repo
-#
-# DBK: this is a bit unsafe as the TTL files in the github repo above can change and the UUID will change since they are randomly
-# generated at this point.  It's probably more robust to explicitly create these files for the time being and explicitly set the
-# UUID in the test file:
-# For example:  kwargs={Constants.NIDM_PROJECT_NAME:"FBIRN_PhaseIII",Constants.NIDM_PROJECT_IDENTIFIER:1200,Constants.NIDM_PROJECT_DESCRIPTION:"Test investigation2"}
-#               project = Project(uuid="_654321",attributes=kwargs)
-USE_GITHUB_DATA = True
 
 @pytest.fixture(scope="module", autouse="True")
-def setup():
-    global cmu_test_project_uuid, cmu_test_subject_uuid
-
-    projects = Query.GetProjectsUUID(ABIDE_FILES)
+def abide(brain_vol_files) -> ProjectData:
+    files = [f for f in brain_vol_files if Path(f).name == "cmu_a.nidm.ttl"]
+    assert files
+    projects = Query.GetProjectsUUID(files)
+    cmu_test_project_uuid: Optional[str] = None
     for p in projects:
-        proj_info = nidm.experiment.Navigate.GetProjectAttributes(ABIDE_FILES, p)
-        if 'dctypes:title' in proj_info.keys() and proj_info['dctypes:title'] == 'ABIDE - CMU_a':
+        proj_info = nidm.experiment.Navigate.GetProjectAttributes(files, p)
+        if (
+            "dctypes:title" in proj_info
+            and proj_info["dctypes:title"] == "ABIDE - CMU_a"
+        ):
             cmu_test_project_uuid = p
             break
-    subjects = Query.GetParticipantIDs(ABIDE_FILES)
-    cmu_test_subject_uuid = subjects['uuid'][0]
+    assert cmu_test_project_uuid is not None
+    return ProjectData(files, cmu_test_project_uuid)
 
 
-def test_GetProjectMetadata():
+def test_GetProjectMetadata(tmp_path: Path) -> None:
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII",
+        Constants.NIDM_PROJECT_IDENTIFIER: 9610,
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation",
+    }
+    project = Project(uuid="_123456", attributes=kwargs)
 
-    kwargs={Constants.NIDM_PROJECT_NAME:"FBIRN_PhaseII",Constants.NIDM_PROJECT_IDENTIFIER:9610,Constants.NIDM_PROJECT_DESCRIPTION:"Test investigation"}
-    project = Project(uuid="_123456",attributes=kwargs)
+    # save a turtle file
+    with open(tmp_path / "test_gpm.ttl", "w", encoding="utf-8") as f:
+        f.write(project.serializeTurtle())
 
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseIII",
+        Constants.NIDM_PROJECT_IDENTIFIER: 1200,
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation2",
+    }
+    project = Project(uuid="_654321", attributes=kwargs)
 
-    #save a turtle file
-    with open("test_gpm.ttl",'w') as f:
+    # save a turtle file
+    with open(tmp_path / "test2_gpm.ttl", "w", encoding="utf-8") as f:
         f.write(project.serializeTurtle())
 
-    kwargs={Constants.NIDM_PROJECT_NAME:"FBIRN_PhaseIII",Constants.NIDM_PROJECT_IDENTIFIER:1200,Constants.NIDM_PROJECT_DESCRIPTION:"Test investigation2"}
-    project = Project(uuid="_654321",attributes=kwargs)
+    # WIP test = Query.GetProjectMetadata(["test.ttl", "test2.ttl"])
 
+    # assert URIRef(Constants.NIDM + "_654321") in test
+    # assert URIRef(Constants.NIDM + "_123456") in test
+    # assert URIRef(Constants.NIDM_PROJECT_IDENTIFIER + "1200") in test
+    # assert URIRef(Constants.NIDM_PROJECT_IDENTIFIER + "9610") in test
+    # assert URIRef((Constants.NIDM_PROJECT_NAME + "FBIRN_PhaseII")) in test
+    # assert URIRef((Constants.NIDM_PROJECT_NAME + "FBIRN_PhaseIII")) in test
+    # assert URIRef((Constants.NIDM_PROJECT_DESCRIPTION + "Test investigation")) in test
+    # assert URIRef((Constants.NIDM_PROJECT_DESCRIPTION + "Test investigation2")) in test
+
+
+def test_GetProjects(tmp_path: Path) -> None:
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII",
+        Constants.NIDM_PROJECT_IDENTIFIER: 9610,
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation",
+    }
+    project = Project(uuid="_123456", attributes=kwargs)
 
-    #save a turtle file
-    with open("test2_gpm.ttl",'w') as f:
+    # save a turtle file
+    with open(tmp_path / "test_gp.ttl", "w", encoding="utf-8") as f:
         f.write(project.serializeTurtle())
 
+    project_list = Query.GetProjectsUUID([str(tmp_path / "test_gp.ttl")])
 
-    #WIP test = Query.GetProjectMetadata(["test.ttl", "test2.ttl"])
-
-    #assert URIRef(Constants.NIDM + "_654321") in test
-    #assert URIRef(Constants.NIDM + "_123456") in test
-    #assert URIRef(Constants.NIDM_PROJECT_IDENTIFIER + "1200") in test
-    #assert URIRef(Constants.NIDM_PROJECT_IDENTIFIER + "9610") in test
-    #assert URIRef((Constants.NIDM_PROJECT_NAME + "FBIRN_PhaseII")) in test
-    #assert URIRef((Constants.NIDM_PROJECT_NAME + "FBIRN_PhaseIII")) in test
-    #assert URIRef((Constants.NIDM_PROJECT_DESCRIPTION + "Test investigation")) in test
-    #assert URIRef((Constants.NIDM_PROJECT_DESCRIPTION + "Test investigation2")) in test
-
-    remove("test_gpm.ttl")
-    remove("test2_gpm.ttl")
+    assert Constants.NIIRI + "_123456" in [str(x) for x in project_list]
 
 
-def test_GetProjects():
+def test_GetParticipantIDs(tmp_path: Path) -> None:
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII",
+        Constants.NIDM_PROJECT_IDENTIFIER: 9610,
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation",
+    }
+    project = Project(uuid="_123456", attributes=kwargs)
+    session = Session(uuid="_13579", project=project)
+    acq = Acquisition(uuid="_15793", session=session)
+    acq2 = Acquisition(uuid="_15795", session=session)
 
-    kwargs={Constants.NIDM_PROJECT_NAME:"FBIRN_PhaseII",Constants.NIDM_PROJECT_IDENTIFIER:9610,Constants.NIDM_PROJECT_DESCRIPTION:"Test investigation"}
-    project = Project(uuid="_123456",attributes=kwargs)
+    person = acq.add_person(attributes={Constants.NIDM_SUBJECTID: "9999"})
+    acq.add_qualified_association(person=person, role=Constants.NIDM_PARTICIPANT)
 
+    person2 = acq2.add_person(attributes={Constants.NIDM_SUBJECTID: "8888"})
+    acq2.add_qualified_association(person=person2, role=Constants.NIDM_PARTICIPANT)
 
-    #save a turtle file
-    with open("test_gp.ttl",'w') as f:
+    # save a turtle file
+    with open(tmp_path / "test_3.ttl", "w", encoding="utf-8") as f:
         f.write(project.serializeTurtle())
 
-    project_list = Query.GetProjectsUUID(["test_gp.ttl"])
-
-    remove("test_gp.ttl")
-    assert Constants.NIIRI + "_123456" in [ str(x) for x in project_list]
-
-def test_GetParticipantIDs():
-
-    kwargs={Constants.NIDM_PROJECT_NAME:"FBIRN_PhaseII",Constants.NIDM_PROJECT_IDENTIFIER:9610,Constants.NIDM_PROJECT_DESCRIPTION:"Test investigation"}
-    project = Project(uuid="_123456",attributes=kwargs)
-    session = Session(uuid="_13579",project=project)
-    acq = Acquisition(uuid="_15793",session=session)
-    acq2 = Acquisition(uuid="_15795",session=session)
-
-    person=acq.add_person(attributes=({Constants.NIDM_SUBJECTID:"9999"}))
-    acq.add_qualified_association(person=person,role=Constants.NIDM_PARTICIPANT)
+    participant_list = Query.GetParticipantIDs([str(tmp_path / "test_3.ttl")])
 
-    person2=acq2.add_person(attributes=({Constants.NIDM_SUBJECTID:"8888"}))
-    acq2.add_qualified_association(person=person2,role=Constants.NIDM_PARTICIPANT)
+    assert participant_list["ID"].str.contains("9999").any()
+    assert participant_list["ID"].str.contains("8888").any()
 
-    #save a turtle file
-    with open("test_3.ttl",'w') as f:
-        f.write(project.serializeTurtle())
-
-    participant_list = Query.GetParticipantIDs(["test_3.ttl"])
 
-    remove("test_3.ttl")
-    assert (participant_list['ID'].str.contains('9999').any())
-    assert (participant_list['ID'].str.contains('8888').any())
-
-def test_GetProjectInstruments():
-    kwargs = {Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII", Constants.NIDM_PROJECT_IDENTIFIER: 9610,
-              Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation"}
+def test_GetProjectInstruments(tmp_path: Path) -> None:
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII",
+        Constants.NIDM_PROJECT_IDENTIFIER: 9610,
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation",
+    }
     proj_uuid = "_123456gpi"
     project = Project(uuid=proj_uuid, attributes=kwargs)
 
     session = Session(project)
     acq = AssessmentAcquisition(session)
 
-    kwargs={pm.PROV_TYPE:pm.QualifiedName(pm.Namespace("nidm",Constants.NIDM),"NorthAmericanAdultReadingTest")}
-    acq_obj = AssessmentObject(acq,attributes=kwargs)
+    kwargs = {
+        pm.PROV_TYPE: pm.QualifiedName(
+            pm.Namespace("nidm", Constants.NIDM), "NorthAmericanAdultReadingTest"
+        )
+    }
+    AssessmentObject(acq, attributes=kwargs)
 
     acq2 = AssessmentAcquisition(session)
 
-    kwargs={pm.PROV_TYPE:pm.QualifiedName(pm.Namespace("nidm",Constants.NIDM),"PositiveAndNegativeSyndromeScale")}
-    acq_obj2 = AssessmentObject(acq2,attributes=kwargs)
+    kwargs = {
+        pm.PROV_TYPE: pm.QualifiedName(
+            pm.Namespace("nidm", Constants.NIDM), "PositiveAndNegativeSyndromeScale"
+        )
+    }
+    AssessmentObject(acq2, attributes=kwargs)
 
-    #save a turtle file
-    with open("test_gpi.ttl",'w') as f:
+    # save a turtle file
+    with open(tmp_path / "test_gpi.ttl", "w", encoding="utf-8") as f:
         f.write(project.serializeTurtle())
 
-    assessment_list = Query.GetProjectInstruments(["test_gpi.ttl"], proj_uuid)
-
-    remove("test_gpi.ttl")
+    assessment_list = Query.GetProjectInstruments(
+        [str(tmp_path / "test_gpi.ttl")], proj_uuid
+    )
+
+    assert Constants.NIDM + "NorthAmericanAdultReadingTest" in [
+        str(x) for x in assessment_list["assessment_type"].to_list()
+    ]
+    assert Constants.NIDM + "PositiveAndNegativeSyndromeScale" in [
+        str(x) for x in assessment_list["assessment_type"].to_list()
+    ]
 
-    assert Constants.NIDM + "NorthAmericanAdultReadingTest" in [str(x) for x in assessment_list['assessment_type'].to_list()]
-    assert Constants.NIDM + "PositiveAndNegativeSyndromeScale" in [str(x) for x in assessment_list['assessment_type'].to_list()]
 
-
-'''
+"""
 The test data file could/should have the following project meta data. Taken from
 https://raw.githubusercontent.com/incf-nidash/nidm/master/nidm/nidm-experiment/terms/nidm-experiment.owl
-  
-  - descrption
+
+  - description
   - fileName
   - license
   - source
   - title
   - hadNumericalValue ???
   - BathSolution ???
   - CellType
@@ -167,218 +183,192 @@
   - HollowElectrodeSolution
   - hadImageContrastType
   - hadImageUsageType
   - NumberOfChannels
   - AppliedFilter
   - SolutionFlowSpeed
   - RecordingLocation
-   
-Returns the 
-  
-'''
+
+Returns the
+
+"""
+
+
 def saveTestFile(file_name, data):
     project = Project(uuid="_123_" + file_name, attributes=data)
 
     return saveProject(file_name, project)
 
+
 def saveProject(file_name, project):
     # save a turtle file
-    with open(file_name, 'w') as f:
+    with open(file_name, "w", encoding="utf-8") as f:
         f.write(project.serializeTurtle())
-    return "nidm:_123_{}".format(file_name)
+    return f"nidm:_123_{file_name}"
 
 
 def makeProjectTestFile(filename):
-    DCTYPES = Namespace("http://purl.org/dc/dcmitype/")
-
-    kwargs = {Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII", # this is the "title"
-              Constants.NIDM_PROJECT_IDENTIFIER: 9610,
-              Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation",
-              Constants.NIDM_FILENAME: "testfile.ttl",
-              Constants.NIDM_PROJECT_LICENSE: "MIT Licence",
-              Constants.NIDM_PROJECT_SOURCE: "Educational Source",
-              Constants.NIDM_HAD_NUMERICAL_VALUE: "numval???",
-              Constants.NIDM_BATH_SOLUTION: "bath",
-              Constants.NIDM_CELL_TYPE: "ctype",
-              Constants.NIDM_CHANNEL_NUMBER: "5",
-              Constants.NIDM_ELECTRODE_IMPEDANCE: ".01",
-              Constants.NIDM_GROUP_LABEL: "group 123",
-              Constants.NIDM_HOLLOW_ELECTRODE_SOLUTION: "water",
-              Constants.NIDM_HAD_IMAGE_CONTRACT_TYPE: "off",
-              Constants.NIDM_HAD_IMAGE_USAGE_TYPE: "abcd",
-              Constants.NIDM_NUBMER_OF_CHANNELS: "11",
-              Constants.NIDM_APPLIED_FILTER: "on",
-              Constants.NIDM_SOLUTION_FLOW_SPEED: "2.8",
-              Constants.NIDM_RECORDING_LOCATION: "lab"
-              }
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "FBIRN_PhaseII",  # this is the "title"
+        Constants.NIDM_PROJECT_IDENTIFIER: 9610,
+        Constants.NIDM_PROJECT_DESCRIPTION: "Test investigation",
+        Constants.NIDM_FILENAME: "testfile.ttl",
+        Constants.NIDM_PROJECT_LICENSE: "MIT Licence",
+        Constants.NIDM_PROJECT_SOURCE: "Educational Source",
+        Constants.NIDM_HAD_NUMERICAL_VALUE: "numval???",
+        Constants.NIDM_BATH_SOLUTION: "bath",
+        Constants.NIDM_CELL_TYPE: "ctype",
+        Constants.NIDM_CHANNEL_NUMBER: "5",
+        Constants.NIDM_ELECTRODE_IMPEDANCE: ".01",
+        Constants.NIDM_GROUP_LABEL: "group 123",
+        Constants.NIDM_HOLLOW_ELECTRODE_SOLUTION: "water",
+        Constants.NIDM_HAD_IMAGE_CONTRACT_TYPE: "off",
+        Constants.NIDM_HAD_IMAGE_USAGE_TYPE: "abcd",
+        Constants.NIDM_NUBMER_OF_CHANNELS: "11",
+        Constants.NIDM_APPLIED_FILTER: "on",
+        Constants.NIDM_SOLUTION_FLOW_SPEED: "2.8",
+        Constants.NIDM_RECORDING_LOCATION: "lab",
+    }
     return saveTestFile(filename, kwargs)
 
-def makeProjectTestFile2(filename):
-    DCTYPES = Namespace("http://purl.org/dc/dcmitype/")
 
-    kwargs = {Constants.NIDM_PROJECT_NAME: "TEST B", # this is the "title"
-              Constants.NIDM_PROJECT_IDENTIFIER: 1234,
-              Constants.NIDM_PROJECT_DESCRIPTION: "More Scans",
-              Constants.NIDM_FILENAME: "testfile2.ttl",
-              Constants.NIDM_PROJECT_LICENSE: "Creative Commons",
-              Constants.NIDM_PROJECT_SOURCE: "Other",
-              Constants.NIDM_HAD_NUMERICAL_VALUE: "numval???",
-              Constants.NIDM_BATH_SOLUTION: "bath",
-              Constants.NIDM_CELL_TYPE: "ctype",
-              Constants.NIDM_CHANNEL_NUMBER: "5",
-              Constants.NIDM_ELECTRODE_IMPEDANCE: ".01",
-              Constants.NIDM_GROUP_LABEL: "group 123",
-              Constants.NIDM_HOLLOW_ELECTRODE_SOLUTION: "water",
-              Constants.NIDM_HAD_IMAGE_CONTRACT_TYPE: "off",
-              Constants.NIDM_HAD_IMAGE_USAGE_TYPE: "abcd",
-              Constants.NIDM_NUBMER_OF_CHANNELS: "11",
-              Constants.NIDM_APPLIED_FILTER: "on",
-              Constants.NIDM_SOLUTION_FLOW_SPEED: "2.8",
-              Constants.NIDM_RECORDING_LOCATION: "lab"
-              }
+def makeProjectTestFile2(filename):
+    kwargs = {
+        Constants.NIDM_PROJECT_NAME: "TEST B",  # this is the "title"
+        Constants.NIDM_PROJECT_IDENTIFIER: 1234,
+        Constants.NIDM_PROJECT_DESCRIPTION: "More Scans",
+        Constants.NIDM_FILENAME: "testfile2.ttl",
+        Constants.NIDM_PROJECT_LICENSE: "Creative Commons",
+        Constants.NIDM_PROJECT_SOURCE: "Other",
+        Constants.NIDM_HAD_NUMERICAL_VALUE: "numval???",
+        Constants.NIDM_BATH_SOLUTION: "bath",
+        Constants.NIDM_CELL_TYPE: "ctype",
+        Constants.NIDM_CHANNEL_NUMBER: "5",
+        Constants.NIDM_ELECTRODE_IMPEDANCE: ".01",
+        Constants.NIDM_GROUP_LABEL: "group 123",
+        Constants.NIDM_HOLLOW_ELECTRODE_SOLUTION: "water",
+        Constants.NIDM_HAD_IMAGE_CONTRACT_TYPE: "off",
+        Constants.NIDM_HAD_IMAGE_USAGE_TYPE: "abcd",
+        Constants.NIDM_NUBMER_OF_CHANNELS: "11",
+        Constants.NIDM_APPLIED_FILTER: "on",
+        Constants.NIDM_SOLUTION_FLOW_SPEED: "2.8",
+        Constants.NIDM_RECORDING_LOCATION: "lab",
+    }
     project = Project(uuid="_123_" + filename, attributes=kwargs)
     s1 = Session(project)
 
     a1 = AssessmentAcquisition(session=s1)
-      # = s1.add_acquisition("a1", attributes={"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#Age" : 22})
+    # = s1.add_acquisition("a1", attributes={"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#Age" : 22})
 
-    p1 = a1.add_person("p1", attributes={Constants.NIDM_GIVEN_NAME:"George", Constants.NIDM_AGE: 22})
+    p1 = a1.add_person(
+        "p1", attributes={Constants.NIDM_GIVEN_NAME: "George", Constants.NIDM_AGE: 22}
+    )
     a1.add_qualified_association(person=p1, role=Constants.NIDM_PARTICIPANT)
 
-
     return saveProject(filename, project)
 
 
-def test_GetProjectsMetadata():
-    p1 = makeProjectTestFile("testfile.ttl")
-    p2 = makeProjectTestFile2("testfile2.ttl")
-    files = ["testfile.ttl", "testfile2.ttl"]
-
-    if USE_GITHUB_DATA and not Path('./cmu_a.nidm.ttl').is_file():
-        urllib.request.urlretrieve(
-            "https://raw.githubusercontent.com/dbkeator/simple2_NIDM_examples/master/datasets.datalad.org/abide/RawDataBIDS/CMU_a/nidm.ttl",
-            "cmu_a.nidm.ttl"
-        )
-        files.append("cmu_a.nidm.ttl")
-    elif Path('./cmu_a.nidm.ttl').is_file():
-        files.append("cmu_a.nidm.ttl")
+def test_GetProjectsMetadata(abide: ProjectData, tmp_path: Path) -> None:
+    p1 = makeProjectTestFile(str(tmp_path / "testfile.ttl"))
+    p2 = makeProjectTestFile2(str(tmp_path / "testfile2.ttl"))
+    files = [
+        str(tmp_path / "testfile.ttl"),
+        str(tmp_path / "testfile2.ttl"),
+        *abide.files,
+    ]
 
     parsed = Query.GetProjectsMetadata(files)
 
     # assert parsed['projects'][p1][str(Constants.NIDM_PROJECT_DESCRIPTION)] == "Test investigation"
     # assert parsed['projects'][p2][str(Constants.NIDM_PROJECT_DESCRIPTION)] == "More Scans"
 
     # we shouldn't have the computed metadata in this result
     # assert parsed['projects'][p1].get (Query.matchPrefix(str(Constants.NIDM_NUMBER_OF_SUBJECTS)), -1) == -1
 
-    if USE_GITHUB_DATA:
-        # find the project ID from the CMU file
-        p3 = None
-        for project_id in parsed['projects']:
-            if project_id != p1 and project_id != p2:
-                if parsed['projects'][project_id][str(Constants.NIDM_PROJECT_NAME)] == "ABIDE - CMU_a":
-                    p3 = project_id
-                    break
-        assert p3 != None
-
-
-#
-# moved to test_rest.py
-#
-# def test_GetProjectsComputedMetadata():
-#
-#     p1 = makeProjectTestFile("testfile.ttl")
-#     p2 = makeProjectTestFile2("testfile2.ttl")
-#     files = ["testfile.ttl", "testfile2.ttl"]
-#
-#     if USE_GITHUB_DATA:
-#         if not Path('./cmu_a.nidm.ttl').is_file():
-#             urllib.request.urlretrieve (
-#                 "https://raw.githubusercontent.com/dbkeator/simple2_NIDM_examples/master/datasets.datalad.org/abide/RawDataBIDS/CMU_a/nidm.ttl",
-#                 "cmu_a.nidm.ttl"
-#             )
-#         files.append("cmu_a.nidm.ttl")
-#
-#     parsed = Query.GetProjectsComputedMetadata(files)
-#
-#     if USE_GITHUB_DATA:
-#         for project_id in parsed['projects']:
-#             if project_id != p1 and project_id != p2:
-#                 p3 = project_id
-#         assert parsed['projects'][p3][str(Constants.NIDM_PROJECT_NAME)] == "ABIDE CMU_a Site"
-#         assert parsed['projects'][p3][Query.matchPrefix(str(Constants.NIDM_NUMBER_OF_SUBJECTS))] == 14
-#         assert parsed['projects'][p3]["age_min"] == 21.0
-#         assert parsed['projects'][p3]["age_max"] == 33.0
-#         assert parsed['projects'][p3][str(Constants.NIDM_GENDER)] == ['1', '2']
+    # find the project ID from the CMU file
+    p3 = None
+    for project_id in parsed["projects"]:
+        if project_id not in (p1, p2):
+            if (
+                parsed["projects"][project_id][str(Constants.NIDM_PROJECT_NAME)]
+                == "ABIDE - CMU_a"
+            ):
+                p3 = project_id
+                break
+    assert p3 is not None
 
 
 def test_prefix_helpers():
-
-    assert Query.expandNIDMAbbreviation("ndar:src_subject_id") == "https://ndar.nih.gov/api/datadictionary/v2/dataelement/src_subject_id"
+    assert (
+        Query.expandNIDMAbbreviation("ndar:src_subject_id")
+        == "https://ndar.nih.gov/api/datadictionary/v2/dataelement/src_subject_id"
+    )
 
     assert Query.matchPrefix("http://purl.org/nidash/nidm#abc") == "nidm:abc"
     assert Query.matchPrefix("http://www.w3.org/ns/prov#123") == "prov:123"
     assert Query.matchPrefix("http://purl.org/nidash/fsl#xyz") == "fsl:xyz"
     assert Query.matchPrefix("http://purl.org/nidash/fsl#xyz", short=True) == "fsl"
 
 
-def test_getProjectAcquisitionObjects():
-    if not Path('./cmu_a.nidm.ttl').is_file():
-        urllib.request.urlretrieve (
-            "https://raw.githubusercontent.com/dbkeator/simple2_NIDM_examples/master/datasets.datalad.org/abide/RawDataBIDS/CMU_a/nidm.ttl",
-            "cmu_a.nidm.ttl"
-        )
-    files = ['cmu_a.nidm.ttl']
+def test_getProjectAcquisitionObjects(abide: ProjectData) -> None:
+    files = abide.files
 
     project_list = Query.GetProjectsUUID(files)
     project_uuid = str(project_list[0])
-    objects = Query.getProjectAcquisitionObjects(files,project_uuid)
+    objects = Query.getProjectAcquisitionObjects(files, project_uuid)
 
-    assert isinstance(objects,list)
+    assert isinstance(objects, list)
 
 
-def test_GetProjectAttributes():
-    global cmu_test_project_uuid
-    if not Path('./cmu_a.nidm.ttl').is_file():
-        urllib.request.urlretrieve (
-            "https://raw.githubusercontent.com/dbkeator/simple2_NIDM_examples/master/datasets.datalad.org/abide/RawDataBIDS/CMU_a/nidm.ttl",
-            "cmu_a.nidm.ttl"
-        )
-    files = ABIDE_FILES
+def test_GetProjectAttributes(abide: ProjectData) -> None:
+    files = abide.files
 
-    project_uuid = cmu_test_project_uuid
-    project_attributes = nidm.experiment.Navigate.GetProjectAttributes(files, project_uuid)
-    assert ('prov:Location' in project_attributes) or ('Location' in project_attributes)
-    assert ('dctypes:title' in project_attributes) or ('title' in project_attributes)
-    assert ('http://www.w3.org/1999/02/22-rdf-syntax-ns#type' in project_attributes) or ('type' in project_attributes)
-    assert ('AcquisitionModality') in project_attributes
-    assert ('ImageContrastType') in project_attributes
-    assert ('Task') in project_attributes
-    assert ('ImageUsageType') in project_attributes
+    project_uuid = abide.cmu_test_project_uuid
+    project_attributes = nidm.experiment.Navigate.GetProjectAttributes(
+        files, project_uuid
+    )
+    assert ("prov:Location" in project_attributes) or ("Location" in project_attributes)
+    assert ("dctypes:title" in project_attributes) or ("title" in project_attributes)
+    assert (
+        "http://www.w3.org/1999/02/22-rdf-syntax-ns#type" in project_attributes
+    ) or ("type" in project_attributes)
+    assert "AcquisitionModality" in project_attributes
+    assert "ImageContrastType" in project_attributes
+    assert "Task" in project_attributes
+    assert "ImageUsageType" in project_attributes
 
 
 def test_download_cde_files():
     cde_dir = download_cde_files()
     assert cde_dir == tempfile.gettempdir()
     fcount = 0
     for url in Constants.CDE_FILE_LOCATIONS:
-        fname = url.split('/')[-1]
-        assert path.isfile("{}/{}".format(cde_dir, fname) )
+        fname = url.split("/")[-1]
+        assert Path(cde_dir, fname).is_file()
         fcount += 1
     assert fcount > 0
 
-@pytest.mark.skip(reason="We don't have an easily accessible file for this test so skipping it until better test samples are available.")
-def test_custom_data_types():
-    SPECIAL_TEST_FILES = ['/opt/project/ttl/MTdemog_aseg.ttl']
 
-    valuetype1 = Query.getDataTypeInfo(Query.OpenGraph(SPECIAL_TEST_FILES[0]), 'no-real-value')
-    assert (valuetype1 == False)
+@pytest.mark.skip(
+    reason="We don't have an easily accessible file for this test so skipping it until better test samples are available."
+)
+def test_custom_data_types():
+    SPECIAL_TEST_FILES = ["/opt/project/ttl/MTdemog_aseg.ttl"]
 
-    valuetype2 = Query.getDataTypeInfo(Query.OpenGraph(SPECIAL_TEST_FILES[0]), Constants.NIIRI['age_e3hrcc'])
-    assert (str(valuetype2['label']) == 'age')
-    assert (str(valuetype2['description']) == "Age of participant at scan")
-    assert (str(valuetype2['isAbout']) == str(Constants.NIIRI['24d78sq']))
-
-    valuetype3 = Query.getDataTypeInfo(Query.OpenGraph(SPECIAL_TEST_FILES[0]), 'age_e3hrcc')
-    assert (str(valuetype3['label']) == 'age')
-    assert (str(valuetype3['description']) == "Age of participant at scan")
-    assert (str(valuetype3['isAbout']) == str(Constants.NIIRI['24d78sq']))
+    valuetype1 = Query.getDataTypeInfo(
+        Query.OpenGraph(SPECIAL_TEST_FILES[0]), "no-real-value"
+    )
+    assert valuetype1 is False
+
+    valuetype2 = Query.getDataTypeInfo(
+        Query.OpenGraph(SPECIAL_TEST_FILES[0]), Constants.NIIRI["age_e3hrcc"]
+    )
+    assert str(valuetype2["label"]) == "age"
+    assert str(valuetype2["description"]) == "Age of participant at scan"
+    assert str(valuetype2["isAbout"]) == str(Constants.NIIRI["24d78sq"])
+
+    valuetype3 = Query.getDataTypeInfo(
+        Query.OpenGraph(SPECIAL_TEST_FILES[0]), "age_e3hrcc"
+    )
+    assert str(valuetype3["label"]) == "age"
+    assert str(valuetype3["description"]) == "Age of participant at scan"
+    assert str(valuetype3["isAbout"]) == str(Constants.NIIRI["24d78sq"])
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/csv2nidm.py` & `pynidm-4.0.0/src/nidm/experiment/tools/csv2nidm.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,390 +1,450 @@
-#!/usr/bin/env python
-#**************************************************************************************
-#**************************************************************************************
-#  csv2nidm.py
-#  License:Apache License, Version 2.0 
-#**************************************************************************************
-#**************************************************************************************
-# Date: 01-19-18                 Coded by: David Keator (dbkeator@gmail.com)
-# Filename: csv2nidm.py
-#
-# Program description:  This program will load in a CSV file and iterate over the header
-# variable names performing an elastic search of https://scicrunch.org/ for NIDM-ReproNim
-# tagged terms that fuzzy match the variable names.  The user will then interactively pick
-# a term to associate with the variable name.  The resulting annotated CSV data will
-# then be written to a NIDM data file.
-#
-#**************************************************************************************
-# Development environment: Python - PyCharm IDE
-#
-#**************************************************************************************
-# System requirements:  Python 3.X
-# Libraries: pybids, numpy, matplotlib, pandas, scipy, math, dateutil, datetime,argparse,
-# os,sys,getopt,csv
-#**************************************************************************************
-#**************************************************************************************
-# Programmer comments:
-#
-#
-#**************************************************************************************
-#**************************************************************************************
-
-import os,sys
-from nidm.experiment import Project,Session,AssessmentAcquisition,AssessmentObject
-from nidm.core import Constants
-from nidm.experiment.Utils import read_nidm, map_variables_to_terms, add_attributes_with_cde, addGitAnnexSources, \
-    redcap_datadictionary_to_json
-from nidm.experiment.Query import GetParticipantIDs
+"""
+This program will load in a CSV file and iterate over the header variable names
+performing an elastic search of https://scicrunch.org/ for NIDM-ReproNim tagged
+terms that fuzzy match the variable names.  The user will then interactively
+pick a term to associate with the variable name.  The resulting annotated CSV
+data will then be written to a NIDM data file.
+"""
 
 from argparse import ArgumentParser
-from os.path import  dirname, join, splitext,basename
-import json
-import pandas as pd
-from rdflib import Graph,URIRef,RDF,Literal
 from io import StringIO
-from shutil import copy2
-from nidm.core.Constants import DD
 import logging
-import csv
-import tempfile
-
+import os
+from os.path import basename, dirname, join
+from shutil import copy2
+import sys
+import pandas as pd
+from rdflib import Graph
+from nidm.core import Constants
+from nidm.experiment import AssessmentAcquisition, AssessmentObject, Project, Session
+from nidm.experiment.Query import GetParticipantIDs
+from nidm.experiment.Utils import (
+    add_attributes_with_cde,
+    addGitAnnexSources,
+    map_variables_to_terms,
+    read_nidm,
+    redcap_datadictionary_to_json,
+)
 
-#def createDialogBox(search_results):
-#class NewListbox(tk.Listbox):
+# def createDialogBox(search_results):
+# class NewListbox(tk.Listbox):
 
 #    def autowidth(self, maxwidth=100):
 #        autowidth(self, maxwidth)
 
 
-#def autowidth(list, maxwidth=100):
+# def autowidth(list, maxwidth=100):
 #    f = font.Font(font=list.cget("font"))
 #    pixels = 0
 #    for item in list.get(0, "end"):
 #        pixels = max(pixels, f.measure(item))
 #    # bump listbox size until all entries fit
 #    pixels = pixels + 10
 #    width = int(list.cget("width"))
 #    for w in range(0, maxwidth+1, 5):
 #        if list.winfo_reqwidth() >= pixels:
 #            break
 #        list.config(width=width+w)
 
 
-
-
-
-def main(argv):
-    parser = ArgumentParser(description='This program will load in a CSV file and iterate over the header \
+def main():
+    parser = ArgumentParser(
+        description="This program will load in a CSV file and iterate over the header \
      variable names performing an elastic search of https://scicrunch.org/ for NIDM-ReproNim \
      tagged terms that fuzzy match the variable names.  The user will then interactively pick \
      a term to associate with the variable name.  The resulting annotated CSV data will \
      then be written to a NIDM data file.  Note, you must obtain an API key to Interlex by signing up \
      for an account at scicrunch.org then going to My Account and API Keys.  Then set the environment \
-     variable INTERLEX_API_KEY with your key.')
+     variable INTERLEX_API_KEY with your key."
+    )
 
-    parser.add_argument('-csv', dest='csv_file', required=True, help="Full path to CSV file to convert")
+    parser.add_argument(
+        "-csv", dest="csv_file", required=True, help="Full path to CSV file to convert"
+    )
     # parser.add_argument('-ilxkey', dest='key', required=True, help="Interlex/SciCrunch API key to use for query")
     dd_group = parser.add_mutually_exclusive_group()
-    dd_group.add_argument('-json_map', dest='json_map',required=False,help="Full path to user-suppled JSON file containing variable-term mappings.")
-    dd_group.add_argument('-redcap', dest='redcap',required=False, help="Full path to a user-supplied RedCap formatted data dictionary for csv file.")
-    parser.add_argument('-nidm', dest='nidm_file', required=False, help="Optional full path of NIDM file to add CSV->NIDM converted graph to")
-    parser.add_argument('-no_concepts', action='store_true', required=False, help='If this flag is set then no concept associations will be'
-                                'asked of the user.  This is useful if you already have a -json_map specified without concepts and want to'
-                                'simply run this program to get a NIDM file with user interaction to associate concepts.')
-    parser.add_argument('-log','--log', dest='logfile',required=False, default=None, help="full path to directory to save log file. Log file name is csv2nidm_[arg.csv_file].log")
-    parser.add_argument('-dataset_id', '--dataset_id', dest='dataset_identifier',required=False, default=None,
-                        help='If this is provided, which can be any dataset ID although its suggested to use a dataset'
-                             'DOI if available, unique data element IDs will use this information as part of the hash.')
-    parser.add_argument('-out', dest='output_file', required=True, help="Full path with filename to save NIDM file")
+    dd_group.add_argument(
+        "-json_map",
+        dest="json_map",
+        required=False,
+        help="Full path to user-suppled JSON file containing variable-term mappings.",
+    )
+    dd_group.add_argument(
+        "-redcap",
+        dest="redcap",
+        required=False,
+        help="Full path to a user-supplied RedCap formatted data dictionary for csv file.",
+    )
+    parser.add_argument(
+        "-nidm",
+        dest="nidm_file",
+        required=False,
+        help="Optional full path of NIDM file to add CSV->NIDM converted graph to",
+    )
+    parser.add_argument(
+        "-no_concepts",
+        action="store_true",
+        required=False,
+        help="If this flag is set then no concept associations will be"
+        "asked of the user.  This is useful if you already have a -json_map specified without concepts and want to"
+        "simply run this program to get a NIDM file with user interaction to associate concepts.",
+    )
+    parser.add_argument(
+        "-log",
+        "--log",
+        dest="logfile",
+        required=False,
+        default=None,
+        help="full path to directory to save log file. Log file name is csv2nidm_[arg.csv_file].log",
+    )
+    parser.add_argument(
+        "-dataset_id",
+        "--dataset_id",
+        dest="dataset_identifier",
+        required=False,
+        default=None,
+        help="If this is provided, which can be any dataset ID although its suggested to use a dataset"
+        "DOI if available, unique data element IDs will use this information as part of the hash.",
+    )
+    parser.add_argument(
+        "-out",
+        dest="output_file",
+        required=True,
+        help="Full path with filename to save NIDM file",
+    )
     args = parser.parse_args()
 
     # if we have a redcap datadictionary then convert it straight away to a json representation
     if args.redcap:
         json_map = redcap_datadictionary_to_json(args.redcap, basename(args.csv_file))
     else:
         json_map = args.json_map
     # open CSV file and load into
-    # DBK added to accomodate TSV files with tab separator 3/15/21
+    # DBK added to accommodate TSV files with tab separator 3/15/21
     if args.csv_file.endswith(".csv"):
         df = pd.read_csv(args.csv_file)
     elif args.csv_file.endswith(".tsv"):
-        df = pd.read_csv(args.csv_file,sep='\t', engine='python')
+        df = pd.read_csv(args.csv_file, sep="\t", engine="python")
 
     else:
-        print("ERROR: input file must have .csv (comma-separated) or .tsv (tab separated) extensions/"
-              "file types.  Please change your input file appropriately and re-run.")
+        print(
+            "ERROR: input file must have .csv (comma-separated) or .tsv (tab separated) extensions/"
+            "file types.  Please change your input file appropriately and re-run."
+        )
         print("no NIDM file created!")
-        exit(1)
-    #temp = csv.reader(args.csv_file)
-    #df = pd.DataFrame(temp)
+        sys.exit(1)
+    # temp = csv.reader(args.csv_file)
+    # df = pd.DataFrame(temp)
 
-    #maps variables in CSV file to terms
-    #if args.owl is not False:
+    # maps variables in CSV file to terms
+    # if args.owl is not False:
     #    column_to_terms = map_variables_to_terms(df=df, apikey=args.key, directory=dirname(args.output_file), output_file=args.output_file, json_file=args.json_map, owl_file=args.owl)
-    #else:
+    # else:
     # if user did not specify -no_concepts then associate concepts interactively with user
     if not args.no_concepts:
-        column_to_terms, cde = map_variables_to_terms(df=df,  assessment_name=basename(args.csv_file),
-                                                    directory=dirname(args.output_file), output_file=args.output_file,
-                                                      json_source=json_map,dataset_identifier=args.dataset_identifier)
+        column_to_terms, cde = map_variables_to_terms(
+            df=df,
+            assessment_name=basename(args.csv_file),
+            directory=dirname(args.output_file),
+            output_file=args.output_file,
+            json_source=json_map,
+            dataset_identifier=args.dataset_identifier,
+        )
     # run without concept mappings
     else:
-        column_to_terms, cde = map_variables_to_terms(df=df, assessment_name=basename(args.csv_file),
-                                                      directory=dirname(args.output_file), output_file=args.output_file,
-                                                      json_source=json_map, associate_concepts=False,
-                                                      dataset_identifier=args.dataset_identifier)
+        column_to_terms, cde = map_variables_to_terms(
+            df=df,
+            assessment_name=basename(args.csv_file),
+            directory=dirname(args.output_file),
+            output_file=args.output_file,
+            json_source=json_map,
+            associate_concepts=False,
+            dataset_identifier=args.dataset_identifier,
+        )
 
     if args.logfile is not None:
-        logging.basicConfig(filename=join(args.logfile,'csv2nidm_' + os.path.splitext(os.path.basename(args.csv_file))[0] + '.log'), level=logging.DEBUG)
+        logging.basicConfig(
+            filename=join(
+                args.logfile,
+                "csv2nidm_"
+                + os.path.splitext(os.path.basename(args.csv_file))[0]
+                + ".log",
+            ),
+            level=logging.DEBUG,
+        )
         # add some logging info
-        logging.info("csv2nidm %s" %args)
-
+        logging.info("csv2nidm %s", args)
 
-    #If user has added an existing NIDM file as a command line parameter then add to existing file for subjects who exist in the NIDM file
+    # If user has added an existing NIDM file as a command line parameter then add to existing file for subjects who exist in the NIDM file
     if args.nidm_file:
         print("Adding to NIDM file...")
         # get subjectID list for later
         qres = GetParticipantIDs([args.nidm_file])
 
-        #read in NIDM file
+        # read in NIDM file
         project = read_nidm(args.nidm_file)
-        #with open("/Users/dbkeator/Downloads/test.ttl","w") as f:
+        # with open("/Users/dbkeator/Downloads/test.ttl","w", encoding="utf-8") as f:
         #    f.write(project.serializeTurtle())
 
+        # get list of session objects
+        project.get_sessions()
 
-        #get list of session objects
-        session_objs=project.get_sessions()
-
-        #look at column_to_terms dictionary for NIDM URL for subject id  (Constants.NIDM_SUBJECTID)
-        id_field=None
+        # look at column_to_terms dictionary for NIDM URL for subject id  (Constants.NIDM_SUBJECTID)
+        id_field = None
         for key, value in column_to_terms.items():
-            if 'isAbout' in column_to_terms[key]:
-                for isabout_key,isabout_value in  column_to_terms[key]['isAbout'].items():
-                    if (isabout_key == 'url') or (isabout_key == '@id'):
-                        if (isabout_value == Constants.NIDM_SUBJECTID._uri):
+            if "isAbout" in value:
+                for isabout_key, isabout_value in value["isAbout"].items():
+                    if isabout_key in ("url", "@id"):
+                        if isabout_value == Constants.NIDM_SUBJECTID._uri:
                             key_tuple = eval(key)
-                            #id_field=key
+                            # id_field=key
                             id_field = key_tuple.variable
-                            #make sure id_field is a string for zero-padded subject ids
-                            #re-read data file with constraint that key field is read as string
-                            df = pd.read_csv(args.csv_file,dtype={id_field : str})
+                            # make sure id_field is a string for zero-padded subject ids
+                            # re-read data file with constraint that key field is read as string
+                            df = pd.read_csv(args.csv_file, dtype={id_field: str})
                             break
 
-        #if we couldn't find a subject ID field in column_to_terms, ask user
+        # if we couldn't find a subject ID field in column_to_terms, ask user
         if id_field is None:
-            option=1
+            option = 1
             for column in df.columns:
-                print("%d: %s" %(option,column))
-                option=option+1
-            selection=input("Please select the subject ID field from the list above: ")
+                print(f"{option}: {column}")
+                option = option + 1
+            selection = input(
+                "Please select the subject ID field from the list above: "
+            )
             # Make sure user selected one of the options.  If not present user with selection input again
             while (not selection.isdigit()) or (int(selection) > int(option)):
                 # Wait for user input
-                selection = input("Please select the subject ID field from the list above: \t" % option)
-            id_field=df.columns[int(selection)-1]
-            #make sure id_field is a string for zero-padded subject ids
-            #re-read data file with constraint that key field is read as string
+                selection = input(
+                    "Please select the subject ID field from the list above: \t"
+                )
+            id_field = df.columns[int(selection) - 1]
+            # make sure id_field is a string for zero-padded subject ids
+            # re-read data file with constraint that key field is read as string
             if args.csv_file.endswith(".csv"):
-                df = pd.read_csv(args.csv_file,dtype={id_field : str})
+                df = pd.read_csv(args.csv_file, dtype={id_field: str})
             else:
-                df = pd.read_csv(args.csv_file, dtype={id_field: str},sep='\t')
-
+                df = pd.read_csv(args.csv_file, dtype={id_field: str}, sep="\t")
 
+        # ## use RDFLib here for temporary graph making query easier
+        # rdf_graph = Graph()
+        # rdf_graph.parse(source=StringIO(project.serializeTurtle()),format='turtle')
 
-        ###use RDFLib here for temporary graph making query easier
-        #rdf_graph = Graph()
-        #rdf_graph.parse(source=StringIO(project.serializeTurtle()),format='turtle')
+        # print("Querying for existing participants in NIDM graph....")
 
-        #print("Querying for existing participants in NIDM graph....")
-
-        ###find subject ids and sessions in NIDM document
-        #query = """SELECT DISTINCT ?session ?nidm_subj_id ?agent
+        # ## find subject ids and sessions in NIDM document
+        # query = """SELECT DISTINCT ?session ?nidm_subj_id ?agent
         #            WHERE {
         #                ?activity prov:wasAssociatedWith ?agent ;
         #                    dct:isPartOf ?session  .
         #                ?agent rdf:type prov:Agent ;
         #                    ndar:src_subject_id ?nidm_subj_id .
         #            }"""
-        ###print(query)
-        #qres = rdf_graph.query(query)
-
-
-
+        # qres = rdf_graph.query(query)
 
-        for index,row in qres.iterrows():
-            logging.info("participant in NIDM file %s \t %s" %(row[0],row[1]))
-            #find row in CSV file with subject id matching agent from NIDM file
-
-            #csv_row = df.loc[df[id_field]==type(df[id_field][0])(row[1])]
-            #find row in CSV file with matching subject id to the agent in the NIDM file
-            #be carefull about data types...simply type-change dataframe subject id column and query to strings.
-            #here we're removing the leading 0's from IDs because pandas.read_csv strips those unless you know ahead of
-            #time which column is the subject id....
-            csv_row = df.loc[df[id_field].astype('str').str.contains(str(row[1]).lstrip("0"))]
-
-            #if there was data about this subject in the NIDM file already (i.e. an agent already exists with this subject id)
-            #then add this CSV assessment data to NIDM file, else skip it....
-            if (not (len(csv_row.index)==0)):
-
-                logging.info("found participant in CSV file" )
+        for _, row in qres.iterrows():
+            logging.info("participant in NIDM file %s \t %s", row[0], row[1])
+            # find row in CSV file with subject id matching agent from NIDM file
+
+            # csv_row = df.loc[df[id_field]==type(df[id_field][0])(row[1])]
+            # find row in CSV file with matching subject id to the agent in the NIDM file
+            # be careful about data types...simply type-change dataframe subject id column and query to strings.
+            # here we're removing the leading 0's from IDs because pandas.read_csv strips those unless you know ahead of
+            # time which column is the subject id....
+            csv_row = df.loc[
+                df[id_field].astype("str").str.contains(str(row[1]).lstrip("0"))
+            ]
+
+            # if there was data about this subject in the NIDM file already (i.e. an agent already exists with this subject id)
+            # then add this CSV assessment data to NIDM file, else skip it....
+            if len(csv_row.index) != 0:
+                logging.info("found participant in CSV file")
 
                 # create a new session for this assessment
-                new_session=Session(project=project)
+                new_session = Session(project=project)
 
-                #NIDM document sesssion uuid
-                #session_uuid = row[0]
+                # NIDM document session uuid
+                # session_uuid = row[0]
 
-                #temporary list of string-based URIs of session objects from API
-                #temp = [o.identifier._uri for o in session_objs]
-                #get session object from existing NIDM file that is associated with a specific subject id
-                #nidm_session = (i for i,x in enumerate([o.identifier._uri for o in session_objs]) if x == str(session_uuid))
-                #nidm_session = session_objs[temp.index(str(session_uuid))]
-                #for nidm_session in session_objs:
+                # temporary list of string-based URIs of session objects from API
+                # temp = [o.identifier._uri for o in session_objs]
+                # get session object from existing NIDM file that is associated with a specific subject id
+                # nidm_session = (i for i,x in enumerate([o.identifier._uri for o in session_objs]) if x == str(session_uuid))
+                # nidm_session = session_objs[temp.index(str(session_uuid))]
+                # for nidm_session in session_objs:
                 #    if nidm_session.identifier._uri == str(session_uuid):
-                #add an assessment acquisition for the phenotype data to session and associate with agent
-                #acq=AssessmentAcquisition(session=nidm_session)
-                acq=AssessmentAcquisition(session=new_session)
-                #add acquisition entity for assessment
+                # add an assessment acquisition for the phenotype data to session and associate with agent
+                # acq=AssessmentAcquisition(session=nidm_session)
+                acq = AssessmentAcquisition(session=new_session)
+                # add acquisition entity for assessment
                 acq_entity = AssessmentObject(acquisition=acq)
-                #add qualified association with existing agent
-                acq.add_qualified_association(person=row[0],role=Constants.NIDM_PARTICIPANT)
+                # add qualified association with existing agent
+                acq.add_qualified_association(
+                    person=row[0], role=Constants.NIDM_PARTICIPANT
+                )
 
                 # add git-annex info if exists
-                num_sources = addGitAnnexSources(obj=acq_entity,filepath=args.csv_file,bids_root=dirname(args.csv_file))
+                num_sources = addGitAnnexSources(
+                    obj=acq_entity,
+                    filepath=args.csv_file,
+                    bids_root=dirname(args.csv_file),
+                )
                 # if there aren't any git annex sources then just store the local directory information
                 if num_sources == 0:
                     # WIP: add absolute location of BIDS directory on disk for later finding of files
-                    acq_entity.add_attributes({Constants.PROV['Location']:"file:/" + args.csv_file})
+                    acq_entity.add_attributes(
+                        {Constants.PROV["Location"]: "file:/" + args.csv_file}
+                    )
 
                 # store file to acq_entity
-                acq_entity.add_attributes({Constants.NIDM_FILENAME:basename(args.csv_file)})
+                acq_entity.add_attributes(
+                    {Constants.NIDM_FILENAME: basename(args.csv_file)}
+                )
 
-                #store other data from row with columns_to_term mappings
+                # store other data from row with columns_to_term mappings
                 for row_variable in csv_row:
-                    #check if row_variable is subject id, if so skip it
-                    if row_variable==id_field:
+                    # check if row_variable is subject id, if so skip it
+                    if row_variable == id_field:
                         continue
                     else:
                         if not csv_row[row_variable].values[0]:
                             continue
 
-
-                        add_attributes_with_cde(acq_entity, cde, row_variable, csv_row[row_variable].values[0])
-
-
+                        add_attributes_with_cde(
+                            acq_entity,
+                            cde,
+                            row_variable,
+                            csv_row[row_variable].values[0],
+                        )
 
                 continue
 
-        print ("Adding CDEs to graph....")
+        print("Adding CDEs to graph....")
         # convert to rdflib Graph and add CDEs
         rdf_graph = Graph()
-        rdf_graph.parse(source=StringIO(project.serializeTurtle()),format='turtle')
+        rdf_graph.parse(source=StringIO(project.serializeTurtle()), format="turtle")
         rdf_graph = rdf_graph + cde
 
         print("Backing up original NIDM file...")
-        copy2(src=args.nidm_file,dst=args.nidm_file+".bak")
+        copy2(src=args.nidm_file, dst=args.nidm_file + ".bak")
         print("Writing NIDM file....")
-        rdf_graph.serialize(destination=args.nidm_file,format='turtle')
+        rdf_graph.serialize(destination=args.nidm_file, format="turtle")
 
     else:
         print("Creating NIDM file...")
-        #If user did not choose to add this data to an existing NIDM file then create a new one for the CSV data
-        #create empty project
-        project=Project()
+        # If user did not choose to add this data to an existing NIDM file then create a new one for the CSV data
+        # create empty project
+        project = Project()
 
-        #simply add name of file to project since we don't know anything about it
-        project.add_attributes({Constants.NIDM_FILENAME:args.csv_file})
+        # simply add name of file to project since we don't know anything about it
+        project.add_attributes({Constants.NIDM_FILENAME: args.csv_file})
 
-
-        #look at column_to_terms dictionary for NIDM URL for subject id  (Constants.NIDM_SUBJECTID)
-        id_field=None
+        # look at column_to_terms dictionary for NIDM URL for subject id  (Constants.NIDM_SUBJECTID)
+        id_field = None
         for key, value in column_to_terms.items():
             # using isAbout concept association to associate subject identifier variable from csv with a known term
             # for subject IDs
-            if 'isAbout' in column_to_terms[key]:
+            if "isAbout" in value:
                 # iterate over isAbout list entries and look for Constants.NIDM_SUBJECTID
-                for entries in column_to_terms[key]['isAbout']:
-                    if Constants.NIDM_SUBJECTID.uri == entries['@id']:
+                for entries in value["isAbout"]:
+                    if Constants.NIDM_SUBJECTID.uri == entries["@id"]:
                         key_tuple = eval(key)
-                        id_field=key_tuple.variable
-                        #make sure id_field is a string for zero-padded subject ids
-                        #re-read data file with constraint that key field is read as string
+                        id_field = key_tuple.variable
+                        # make sure id_field is a string for zero-padded subject ids
+                        # re-read data file with constraint that key field is read as string
                         if args.csv_file.endswith(".csv"):
-                            df = pd.read_csv(args.csv_file,dtype={id_field : str})
+                            df = pd.read_csv(args.csv_file, dtype={id_field: str})
                         else:
-                            df = pd.read_csv(args.csv_file, dtype={id_field: str},sep='\t')
+                            df = pd.read_csv(
+                                args.csv_file, dtype={id_field: str}, sep="\t"
+                            )
                         break
 
-        #if we couldn't find a subject ID field in column_to_terms, ask user
+        # if we couldn't find a subject ID field in column_to_terms, ask user
         if id_field is None:
-            option=1
+            option = 1
             for column in df.columns:
-                print("%d: %s" %(option,column))
-                option=option+1
-            selection=input("Please select the subject ID field from the list above: ")
+                print(f"{option}: {column}")
+                option = option + 1
+            selection = input(
+                "Please select the subject ID field from the list above: "
+            )
             # Make sure user selected one of the options.  If not present user with selection input again
             while (not selection.isdigit()) or (int(selection) > int(option)):
                 # Wait for user input
-                selection = input("Please select the subject ID field from the list above: \t" % option)
-            id_field=df.columns[int(selection)-1]
-            #make sure id_field is a string for zero-padded subject ids
-            #re-read data file with constraint that key field is read as string
+                selection = input(
+                    "Please select the subject ID field from the list above: \t"
+                )
+            id_field = df.columns[int(selection) - 1]
+            # make sure id_field is a string for zero-padded subject ids
+            # re-read data file with constraint that key field is read as string
             if args.csv_file.endswith(".csv"):
-                df = pd.read_csv(args.csv_file,dtype={id_field : str})
+                df = pd.read_csv(args.csv_file, dtype={id_field: str})
             else:
-                df = pd.read_csv(args.csv_file, dtype={id_field: str}, sep='\t')
-
+                df = pd.read_csv(args.csv_file, dtype={id_field: str}, sep="\t")
 
-        #iterate over rows and store in NIDM file
-        for csv_index, csv_row in df.iterrows():
-            #create a session object
-            session=Session(project)
+        # iterate over rows and store in NIDM file
+        for _, csv_row in df.iterrows():
+            # create a session object
+            session = Session(project)
+
+            # create and acquisition activity and entity
+            acq = AssessmentAcquisition(session)
+            acq_entity = AssessmentObject(acq)
 
-            #create and acquisition activity and entity
-            acq=AssessmentAcquisition(session)
-            acq_entity=AssessmentObject(acq)
-
-            #create prov:Agent for subject
-            #acq.add_person(attributes=({Constants.NIDM_SUBJECTID:row['participant_id']}))
+            # create prov:Agent for subject
+            # acq.add_person(attributes=({Constants.NIDM_SUBJECTID:row['participant_id']}))
 
             # add git-annex info if exists
-            num_sources = addGitAnnexSources(obj=acq_entity,filepath=args.csv_file,bids_root=os.path.dirname(args.csv_file))
+            num_sources = addGitAnnexSources(
+                obj=acq_entity,
+                filepath=args.csv_file,
+                bids_root=os.path.dirname(args.csv_file),
+            )
             # if there aren't any git annex sources then just store the local directory information
             if num_sources == 0:
                 # WIP: add absolute location of BIDS directory on disk for later finding of files
-                acq_entity.add_attributes({Constants.PROV['Location']:"file:/" + args.csv_file})
+                acq_entity.add_attributes(
+                    {Constants.PROV["Location"]: "file:/" + args.csv_file}
+                )
 
             # store file to acq_entity
-            acq_entity.add_attributes({Constants.NIDM_FILENAME : basename(args.csv_file)})
-
+            acq_entity.add_attributes(
+                {Constants.NIDM_FILENAME: basename(args.csv_file)}
+            )
 
-            #store other data from row with columns_to_term mappings
-            for row_variable,row_data in csv_row.iteritems():
+            # store other data from row with columns_to_term mappings
+            for row_variable, row_data in csv_row.iteritems():
                 if not row_data:
                     continue
 
-                #check if row_variable is subject id, if so skip it
-                if row_variable==id_field:
+                # check if row_variable is subject id, if so skip it
+                if row_variable == id_field:
                     ### WIP: Check if agent already exists with the same ID.  If so, use it else create a new agent
 
-                    #add qualified association with person
-                    acq.add_qualified_association(person= acq.add_person(attributes=({Constants.NIDM_SUBJECTID:str(row_data)})),role=Constants.NIDM_PARTICIPANT)
+                    # add qualified association with person
+                    acq.add_qualified_association(
+                        person=acq.add_person(
+                            attributes=({Constants.NIDM_SUBJECTID: str(row_data)})
+                        ),
+                        role=Constants.NIDM_PARTICIPANT,
+                    )
 
                     continue
                 else:
                     add_attributes_with_cde(acq_entity, cde, row_variable, row_data)
 
-                    #print(project.serializeTurtle())
+                    # print(project.serializeTurtle())
 
         # convert to rdflib Graph and add CDEs
         rdf_graph = Graph()
-        rdf_graph.parse(source=StringIO(project.serializeTurtle()),format='turtle')
+        rdf_graph.parse(source=StringIO(project.serializeTurtle()), format="turtle")
         rdf_graph = rdf_graph + cde
 
         print("Writing NIDM file....")
-        rdf_graph.serialize(destination=args.output_file,format='turtle')
-
+        rdf_graph.serialize(destination=args.output_file, format="turtle")
 
 
 if __name__ == "__main__":
-   main(sys.argv[1:])
+    main()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/nidm2bids.py` & `pynidm-4.0.0/src/nidm/experiment/tools/nidm2bids.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,764 +1,918 @@
-#!/usr/bin/env python
-#**************************************************************************************
-#**************************************************************************************
-#  NIDM2BIDSMRI.py
-#  License: Apache License, Version 2.0
-#**************************************************************************************
-#**************************************************************************************
-# Date: 10-2-17                 Coded by: David Keator (dbkeator@gmail.com)
-# Filename: NIDM2BIDSMRI.py
-#
-# Program description:  This program will convert a NIDM-Experiment RDF document
-# to a BIDS dataset.  The program will query the NIDM-Experiment document for subjects,
-# MRI scans, and associated assessments saving the MRI data to disk in an organization
-# according to the BIDS specification, the demographics metadata to a participants.tsv
-# file, the project-level metdata to a dataset_description.json file, and the
-# assessments to *.tsv/*.json file pairs in a phenotypes directory.
-#**************************************************************************************
-# Development environment: Python - PyCharm IDE
-#
-#**************************************************************************************
-# System requirements:  Python 3.X
-# Libraries: pybids, numpy, matplotlib, pandas, scipy, math, dateutil, datetime,argparse,
-# os,sys,getopt,csv
-#**************************************************************************************
-# Start date: 10-2-17
-# Update history:
-# DATE            MODIFICATION				Who
-#
-#
-#**************************************************************************************
-# Programmer comments:
-#
-#
-#**************************************************************************************
-#**************************************************************************************
-
-import sys, getopt, os
-from os.path import join, isfile, basename, isdir,splitext
-from os import mkdir
-from os import system
-
-from nidm.experiment import Project,Session,Acquisition,AcquisitionObject,DemographicsObject,AssessmentObject, MRObject
-from nidm.core import BIDS_Constants,Constants
-from prov.model import PROV_LABEL,PROV_TYPE
-from nidm.experiment.Utils import read_nidm, write_json_mapping_file
-from nidm.experiment.Query import GetProjectsUUID, GetProjectLocation, GetParticipantIDFromAcquisition
-from nidm.core.Constants import DD
+"""
+This program will convert a NIDM-Experiment RDF document to a BIDS dataset.
+The program will query the NIDM-Experiment document for subjects, MRI scans,
+and associated assessments saving the MRI data to disk in an organization
+according to the BIDS specification, the demographics metadata to a
+participants.tsv file, the project-level metadata to a dataset_description.json
+file, and the assessments to *.tsv/*.json file pairs in a phenotypes directory.
+"""
 
-import json
-from pprint import pprint
-import csv
-import glob
-from rdflib import Graph,URIRef,RDF
 from argparse import ArgumentParser
 from io import StringIO
-import pandas as pd
-import validators
-import urllib.parse
-from shutil import copyfile, move
-import urllib.request as ur
+import json
+import os
+from os import mkdir, system
+from os.path import basename, isdir, isfile, join, splitext
+from shutil import copyfile
+import sys
 import tempfile
+import urllib.parse
 import datalad.api as dl
+import pandas as pd
+from rdflib import Graph, URIRef
+import requests
+import validators
+from nidm.core import BIDS_Constants, Constants
+from nidm.core.Constants import DD
+from nidm.experiment.Query import (
+    GetParticipantIDFromAcquisition,
+    GetProjectLocation,
+    GetProjectsUUID,
+)
+from nidm.experiment.Utils import read_nidm, write_json_mapping_file
 
-def GetImageFromAWS(location, output_file,args):
-    '''
+
+def GetImageFromAWS(location, output_file, args):
+    """
     This function will attempt to get a BIDS image identified by location from AWS S3.  It only
     supports known URLs at this time (e.g. openneuro)
     :param location: path string to file. This can be a local path. Function will try and detect if this
     is a known project/archive and if so will format theh S3 string appropriately.  Otherwise it will return None
     :param output_file: This is the full path and filename to store the S3 downloaded file if successful
     :return: None if file not downloaded else will return True
-    '''
+    """
 
-    print("Trying AWS S3 for dataset: %s" % location)
+    print(f"Trying AWS S3 for dataset: {location}")
     # modify location to remove everything before the dataset name
     # problem is we don't know the dataset identifier inside the path string because
     # it doesn't have any constraints.  For openneuro datasets they start with "ds" so
     # we could pick that out but for others it's difficult (impossible)?
 
     # case for openneuro
-    if 'openneuro' in location:
+    if "openneuro" in location:
         # remove everything from location string before openneuro
-        openneuro_loc = location[location.find("openneuro/") + 10:]
+        openneuro_loc = location[location.find("openneuro/") + 10 :]
         # get a temporary directory for this file
-        temp_dir = tempfile.TemporaryDirectory()
+        temp_dir = tempfile.mkdtemp()
         # aws command
-        cmd = "aws s3 cp --no-sign-request " + "s3://openneuro.org/" + openneuro_loc + " " + temp_dir.name
+        cmd = (
+            "aws s3 cp --no-sign-request "
+            + "s3://openneuro.org/"
+            + openneuro_loc
+            + " "
+            + temp_dir
+        )
         # execute command
         print(cmd)
         system(cmd)
         # check if aws command downloaded something
-        if not isfile(join(temp_dir.name, basename(location))):
+        if not isfile(join(temp_dir, basename(location))):
             print("Couldn't get dataset from AWS either...")
             return None
         else:
             try:
                 # copy file from temp_dir to bids dataset
                 print("Copying temporary file to final location....")
-                copyfile(join(temp_dir.name, basename(location)),output_file)
+                copyfile(join(temp_dir, basename(location)), output_file)
                 return True
-            except:
+            except Exception:
                 print("Couldn't get dataset from AWS either...")
                 return None
     # if user supplied a URL base, add dataset, subject, and file information to it and try to download the image
     elif args.aws_baseurl:
         aws_baseurl = args.aws_baseurl
         # check if user supplied the last '/' in the aws_baseurl or not.  If not, add it.
-        if aws_baseurl[-1] != '/':
-            aws_baseurl = aws_baseurl = '/'
+        if aws_baseurl[-1] != "/":
+            aws_baseurl = aws_baseurl = "/"
         # remove everything from location string before openneuro
-        loc = location[location.find(args.dataset_string) + len(args.dataset_string):]
+        loc = location[location.find(args.dataset_string) + len(args.dataset_string) :]
         # get a temporary directory for this file
-        temp_dir = tempfile.TemporaryDirectory()
+        temp_dir = tempfile.mkdtemp()
         # aws command
-        cmd = "aws s3 cp --no-sign-request " + aws_baseurl + loc + " " + temp_dir.name
+        cmd = "aws s3 cp --no-sign-request " + aws_baseurl + loc + " " + temp_dir
         # execute command
         print(cmd)
         system(cmd)
         # check if aws command downloaded something
-        if not isfile(join(temp_dir.name, basename(location))):
+        if not isfile(join(temp_dir, basename(location))):
             print("Couldn't get dataset from AWS either...")
             return None
         else:
             try:
                 # copy file from temp_dir to bids dataset
                 print("Copying temporary file to final location....")
-                copyfile(join(temp_dir.name, basename(location)), output_file)
+                copyfile(join(temp_dir, basename(location)), output_file)
                 return True
-            except:
+            except Exception:
                 print("Couldn't get dataset from AWS either...")
                 return None
 
 
-
 def GetImageFromURL(url):
-    '''
+    """
     This function will try and retrieve the file referenced by url
     :param url: url to file to download
     :return: temporary filename or -1 if fails
-    '''
-
+    """
 
     # try to open the url and get the pointed to file
     try:
         # open url and get file
-        opener = ur.urlopen(url)
-        # write temporary file to disk and use for stats
-        temp = tempfile.NamedTemporaryFile(delete=False)
-        temp.write(opener.read())
-        temp.close()
-        return temp.name
-    except:
-        print("ERROR! Can't open url: %s" % url)
+        with requests.get(url, stream=True) as r:
+            r.raise_for_status()
+            # write temporary file to disk and use for stats
+            with tempfile.NamedTemporaryFile(delete=False) as temp:
+                for chunk in r.iter_content(65535):
+                    temp.write(chunk)
+                temp.flush()
+                return temp.name
+    except Exception:
+        print(f"ERROR! Can't open url: {url}")
         return -1
 
-def GetDataElementMetadata(nidm_graph,de_uuid):
-    '''
+
+def GetDataElementMetadata(nidm_graph, de_uuid):
+    """
     This function will query the nidm_graph for the DataElement de_uuid and return all the metadata as a BIDS-compliant
     participants sidecar file dictionary
-    '''
+    """
 
     # query nidm_graph for Constants.NIIRI[de_uuid] rdf:type PersonalDataElement
-    query = """
+    query = f"""
         PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
         PREFIX prov: <http://www.w3.org/ns/prov#>
         PREFIX niiri: <http://iri.nidash.org/>
         PREFIX nidm: <http://purl.org/nidash/nidm#>
-        
+
         select distinct ?p ?o
-        where {
-            
-            <%s> rdf:type nidm:PersonalDataElement ;
+        where {{
+
+            <{Constants.NIIRI[de_uuid]}> rdf:type nidm:PersonalDataElement ;
                 ?p ?o .
-        }  
-    """ % Constants.NIIRI[de_uuid]
+        }}
+    """
 
     # print(query)
     qres = nidm_graph.query(query)
 
     # set up a dictionary entry for this column
-    #current_tuple = str(DD(source="participants.tsv", variable=column))
+    # current_tuple = str(DD(source="participants.tsv", variable=column))
 
     # temporary dictionary of metadata
     temp_dict = {}
     # add info to BIDS-formatted json sidecar file
     for row in qres:
         temp_dict[str(row[0])] = str(row[1])
 
     # set up a dictionary entry for this column
-    current_tuple = str(DD(source="participants.tsv", variable=
-        temp_dict['http://purl.org/nidash/nidm#sourceVariable']))
+    current_tuple = str(
+        DD(
+            source="participants.tsv",
+            variable=temp_dict["http://purl.org/nidash/nidm#sourceVariable"],
+        )
+    )
 
     de = {}
     de[current_tuple] = {}
     # now look for label entry in temp_dict and set up a proper NIDM-style JSON data structure
     # see Utils.py function map_variables_to_terms for example (column_to_terms[current_tuple])
-    for key,value in temp_dict.items():
-        if key == 'http://purl.org/nidash/nidm#sourceVariable':
-            de[current_tuple]['source_variable'] = value
-        elif key == 'http://purl.org/dc/terms/description':
-            de[current_tuple]['description'] = value
-        elif key == 'http://purl.org/nidash/nidm#isAbout':
+    for key, value in temp_dict.items():
+        if key == "http://purl.org/nidash/nidm#sourceVariable":
+            de[current_tuple]["source_variable"] = value
+        elif key == "http://purl.org/dc/terms/description":
+            de[current_tuple]["description"] = value
+        elif key == "http://purl.org/nidash/nidm#isAbout":
             # here we need to do an additional query to see if there's a label associated with the isAbout value
-            de[current_tuple]['isAbout'] = []
+            de[current_tuple]["isAbout"] = []
 
             # check whether there are multiple 'isAbout' entries
-            if type(value) == 'list':
+            if type(value) == "list":
                 # if this is a list we have to loop through the entries and store the url and labels
                 for entry in value:
                     # query for label for this isAbout URL
-                    query = '''
+                    query = f"""
 
                                     prefix prov: <http://www.w3.org/ns/prov#>
                                     prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>
                                     prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
-                                    
+
                                     select distinct ?label
-                                    where {
-                                        <%s> rdf:type prov:Entity ;
-                                            rdfs:label ?label .    
-                                    }      
-                                ''' % entry
-                    #print(query)
+                                    where {{
+                                        <{entry}> rdf:type prov:Entity ;
+                                            rdfs:label ?label .
+                                    }}
+                                """
+                    # print(query)
                     qres = nidm_graph.query(query)
 
                     for row in qres:
-                        de[current_tuple]['isAbout'].append({'@id': value, 'label': row[0]})
+                        de[current_tuple]["isAbout"].append(
+                            {"@id": value, "label": row[0]}
+                        )
             else:
                 # only 1 isAbout entry
                 # query for label for this isAbout URL
-                query = '''
+                query = f"""
 
                         prefix prov: <http://www.w3.org/ns/prov#>
                         prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>
                         prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
 
                         select distinct ?label
-                        where {
-                            <%s> rdf:type prov:Entity ;
-                                rdfs:label ?label .    
-                        }      
-                    ''' % value
+                        where {{
+                            <{value}> rdf:type prov:Entity ;
+                                rdfs:label ?label .
+                        }}
+                    """
                 # print(query)
                 qres = nidm_graph.query(query)
                 for row in qres:
-                    de[current_tuple]['isAbout'].append({'@id': value, 'label': row[0]})
+                    de[current_tuple]["isAbout"].append({"@id": value, "label": row[0]})
 
-        elif key == 'http://www.w3.org/2000/01/rdf-schema#label':
-            de[current_tuple]['label'] = value
-        elif key =='http://purl.org/nidash/nidm#valueType':
-            if 'responseOptions' not in de[current_tuple].keys():
-                de[current_tuple]['responseOptions'] = {}
-                de[current_tuple]['responseOptions']['valueType'] = value
+        elif key == "http://www.w3.org/2000/01/rdf-schema#label":
+            de[current_tuple]["label"] = value
+        elif key == "http://purl.org/nidash/nidm#valueType":
+            if "responseOptions" not in de[current_tuple].keys():
+                de[current_tuple]["responseOptions"] = {}
+                de[current_tuple]["responseOptions"]["valueType"] = value
             else:
-                de[current_tuple]['responseOptions']['valueType'] = value
-        elif key == 'http://purl.org/nidash/nidm#levels':
-            if 'responseOptions' not in de[current_tuple].keys():
-                de[current_tuple]['responseOptions'] = {}
-                de[current_tuple]['responseOptions']['levels'] = value
+                de[current_tuple]["responseOptions"]["valueType"] = value
+        elif key == "http://purl.org/nidash/nidm#levels":
+            if "responseOptions" not in de[current_tuple].keys():
+                de[current_tuple]["responseOptions"] = {}
+                de[current_tuple]["responseOptions"]["levels"] = value
             else:
-                de[current_tuple]['responseOptions']['levels'] = value
-        elif key ==  'http://uri.interlex.org/ilx_0739289':
-            de[current_tuple]['associatedWith'] = value
-        elif key == Constants.NIDM['minValue']:
-            de[current_tuple]['responseOptions']['minValue'] = value
-        elif key == Constants.NIDM['maxValue']:
-            de[current_tuple]['responseOptions']['maxValue'] = value
-        elif key == Constants.NIDM['url']:
-            de[current_tuple]['url'] = value
+                de[current_tuple]["responseOptions"]["levels"] = value
+        elif key == "http://uri.interlex.org/ilx_0739289":
+            de[current_tuple]["associatedWith"] = value
+        elif key == Constants.NIDM["minValue"]:
+            de[current_tuple]["responseOptions"]["minValue"] = value
+        elif key == Constants.NIDM["maxValue"]:
+            de[current_tuple]["responseOptions"]["maxValue"] = value
+        elif key == Constants.NIDM["url"]:
+            de[current_tuple]["url"] = value
 
     return de
 
 
-def CreateBIDSParticipantFile(nidm_graph,output_file,participant_fields):
-    '''
+def CreateBIDSParticipantFile(nidm_graph, output_file, participant_fields):
+    """
     Creates participant file based on requested fields
 
     :param nidm_graph:
     :param output_directory:
     :param fields:
     :return:
-    '''
+    """
 
     print("Creating participants.json file...")
     fields = ["participant_id"]
-    #fields.extend(participant_fields)
-    participants=pd.DataFrame(columns=fields,index=[1])
+    # fields.extend(participant_fields)
+    participants = pd.DataFrame(columns=fields, index=[1])
     participants_json = {}
 
-    #for each Constants.NIDM_SUBJECTID in NIDM file
-    row_index=1
-    for subj_uri,subj_id in nidm_graph.subject_objects(predicate=URIRef(Constants.NIDM_SUBJECTID.uri)):
-
-        #adding subject ID to data list to append to participants data frame
-        participants.loc[row_index,'participant_id',] = subj_id
+    # for each Constants.NIDM_SUBJECTID in NIDM file
+    row_index = 1
+    for subj_uri, subj_id in nidm_graph.subject_objects(
+        predicate=URIRef(Constants.NIDM_SUBJECTID.uri)
+    ):
+        # adding subject ID to data list to append to participants data frame
+        participants.loc[
+            row_index,
+            "participant_id",
+        ] = subj_id
 
-        #for each of the fields in the participants list
+        # for each of the fields in the participants list
         for fields in participant_fields:
-            #if field identifier isn't a proper URI then do a fuzzy search on the graph, else an explicit search for the URL
-            if(validators.url(fields)):
-                #then this is a valid URI so simply query nidm_project document for it
-                for subj,obj in nidm_graph.subject_objects(predicate=URIRef(BIDS_Constants.participants[fields].uri)):
-                    #add row to the pandas data frame
-                    #data.append(obj)
-                    participants.loc[row_index,BIDS_Constants.participants[fields].uri] = obj
+            # if field identifier isn't a proper URI then do a fuzzy search on the graph, else an explicit search for the URL
+            if validators.url(fields):
+                # then this is a valid URI so simply query nidm_project document for it
+                for _, obj in nidm_graph.subject_objects(
+                    predicate=URIRef(BIDS_Constants.participants[fields].uri)
+                ):
+                    # add row to the pandas data frame
+                    # data.append(obj)
+                    participants.loc[
+                        row_index, BIDS_Constants.participants[fields].uri
+                    ] = obj
 
                     # find Data Element and add metadata to participants_json dictionary
 
             else:
-                #text matching task, remove basepart of URIs and try to fuzzy match the field in the part_fields parameter string
-                #to the "term" part of a qname URI...this part let's a user simply ask for "age" for example without knowing the
-                #complete URI....hopefully
+                # text matching task, remove basepart of URIs and try to fuzzy match the field in the part_fields parameter string
+                # to the "term" part of a qname URI...this part let's a user simply ask for "age" for example without knowing the
+                # complete URI....hopefully
                 #
-                #This needs to be a more complex query:
+                # This needs to be a more complex query:
                 #   Step(1): For subj_uri query for prov:Activity that were prov:wasAttributedTo subj_uri
                 #   Step(2): Query for prov:Entity that were prov:wasGeneratedBy uris from Step(1)
                 #   Step(3): For each metadata triple in objects whose subject is uris from Step(2), fuzzy match predicate after
                 #   removing base of uri to "fields" in participants list, then add these to data list for appending to pandas
-                match_ratio={}
                 #
-                #Steps(1):(3)
+                # Steps(1):(3)
 
-                query = """
+                query = f"""
                     PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
                     PREFIX prov: <http://www.w3.org/ns/prov#>
                     PREFIX onli: <http://neurolog.unice.fr/ontoneurolog/v3.0/instrument.owl#>
                     PREFIX sio: <http://semanticscience.org/ontology/sio.owl#>
                     PREFIX niiri: <http://iri.nidash.org/>
 
                 SELECT DISTINCT ?pred ?value
-                    WHERE {
+                    WHERE {{
                         ?asses_activity prov:qualifiedAssociation ?_blank .
-    					?_blank rdf:type prov:Association ;
-	                		prov:agent <%s> ;
-                   			prov:hadRole sio:Subject .
+                                        ?_blank rdf:type prov:Association ;
+                                        prov:agent <{subj_uri}> ;
+                                        prov:hadRole sio:Subject .
 
                         ?entities prov:wasGeneratedBy ?asses_activity ;
                             rdf:type onli:assessment-instrument ;
                             ?pred ?value .
-                        FILTER (regex(str(?pred) ,"%s","i" ))
-                    }""" % (subj_uri,fields)
-                #print(query)
+                        FILTER (regex(str(?pred) ,"{fields}","i" ))
+                    }}"""
+                # print(query)
                 qres = nidm_graph.query(query)
 
                 for row in qres:
-                    #use last field in URIs for short column name and add full URI to sidecar participants.json file
-                    url_parts = urllib.parse.urlsplit(row[0],scheme='#')
+                    # use last field in URIs for short column name and add full URI to sidecar participants.json file
+                    url_parts = urllib.parse.urlsplit(row[0], scheme="#")
 
-                    if url_parts.fragment == '':
-                        #do some parsing of the path URL because this particular one has no fragments
+                    if url_parts.fragment == "":
+                        # do some parsing of the path URL because this particular one has no fragments
                         url_parts = urllib.parse.urlparse(row[0])
-                        path_parts = url_parts[2].rpartition('/')
+                        path_parts = url_parts[2].rpartition("/")
                         short_name = path_parts[2]
                     else:
                         short_name = url_parts.fragment
 
                     # find Data Element and add metadata to participants_json dictionary
-                    if 'de' not in locals():
+                    if "de" not in locals():
                         de = GetDataElementMetadata(nidm_graph, short_name)
                     else:
                         de.update(GetDataElementMetadata(nidm_graph, short_name))
 
-                    participants.loc[row_index,str(short_name)] = str(row[1])
-                    #data.append(str(row[1]))
-
-        #add row to participants DataFrame
-        #participants=participants.append(pd.DataFrame(data))
-        participants
-        row_index = row_index+1
-
-
-    #save participants.tsv file
-    participants.to_csv(output_file + ".tsv",sep='\t',index=False)
-    #save participants.json file
-    with open(output_file + ".json",'w') as f:
-        json.dump(participants_json,f,sort_keys=True,indent=2)
+                    participants.loc[row_index, str(short_name)] = str(row[1])
+                    # data.append(str(row[1]))
 
+        # add row to participants DataFrame
+        # participants=participants.append(pd.DataFrame(data))
+        row_index += 1
+
+    # save participants.tsv file
+    participants.to_csv(output_file + ".tsv", sep="\t", index=False)
+    # save participants.json file
+    with open(output_file + ".json", "w", encoding="utf-8") as f:
+        json.dump(participants_json, f, sort_keys=True, indent=2)
 
     # save participant sidecar file
     write_json_mapping_file(de, join(splitext(output_file)[0] + ".json"), True)
 
     return participants, participants_json
 
 
-
-def NIDMProject2BIDSDatasetDescriptor(nidm_graph,output_directory):
-    '''
+def NIDMProject2BIDSDatasetDescriptor(nidm_graph, output_directory):
+    """
     :param nidm_graph: RDFLib graph object from NIDM-Exp file
     :param output_dir: directory for writing dataset_description of BIDS dataset
     :return: None
-    '''
+    """
 
     print("Creating dataset_description.json file...")
 
-    #Project -> Dataset_description.json############################################
-    #get json representation of project metadata
+    # Project -> Dataset_description.json############################################
+    # get json representation of project metadata
     project_metadata = nidm_graph.get_metadata_dict(Constants.NIDM_PROJECT)
-    #print(project_metadata)
+    # print(project_metadata)
 
-    #cycle through keys converting them to BIDS keys
-    #make copy of project_metadata
+    # cycle through keys converting them to BIDS keys
+    # make copy of project_metadata
     project_metadata_tmp = dict(project_metadata)
-    #iterate over the temporary dictionary and delete items from the original
-    for proj_key,value in project_metadata_tmp.items():
-        key_found=0
-        #print("proj_key = %s " % proj_key)
-        #print("project_metadata[proj_key] = %s" %project_metadata[proj_key])
+    # iterate over the temporary dictionary and delete items from the original
+    for proj_key in project_metadata_tmp:
+        key_found = 0
+        # print(f"proj_key = {proj_key} ")
+        # print(f"project_metadata[proj_key] = {project_metadata[proj_key]}")
 
-        for key,value in BIDS_Constants.dataset_description.items():
-            if BIDS_Constants.dataset_description[key]._uri == proj_key:
+        for key, value in BIDS_Constants.dataset_description.items():
+            if value._uri == proj_key:
                 # added since BIDS validator validates values of certain keys
-                if (key == "Authors") or (key == "Funding") or (key == "ReferencesAndLinks"):
+                if key in ("Authors", "Funding", "ReferencesAndLinks"):
                     project_metadata[key] = [project_metadata[proj_key]]
                 else:
                     project_metadata[key] = project_metadata[proj_key]
                 del project_metadata[proj_key]
-                key_found=1
+                key_found = 1
                 continue
-        #if this proj_key wasn't found in BIDS dataset_description Constants dictionary then delete it
+        # if this proj_key wasn't found in BIDS dataset_description Constants dictionary then delete it
         if not key_found:
             del project_metadata[proj_key]
 
-    with open(join(output_directory, "dataset_description.json"),'w') as f:
-        json.dump(project_metadata,f,sort_keys=True,indent=2)
+    with open(
+        join(output_directory, "dataset_description.json"), "w", encoding="utf-8"
+    ) as f:
+        json.dump(project_metadata, f, sort_keys=True, indent=2)
 
-    ##############################################################################
 
-def AddMetadataToImageSidecar(graph_entity,graph, output_directory, image_filename):
-    '''
+def AddMetadataToImageSidecar(graph_entity, graph, output_directory, image_filename):
+    """
     This function will query the metadata in graph_entity and compare the entries with mappings in
     core/BIDS_Constants.py json_keys where we'll be mapping the value (NIDM entry) to key (BIDS key). It
     will create the appropriate sidecar json file associated with image_filename in output_directory.
-    '''
+    """
 
     # query graph for metadata associated with graph_entity
-    query = '''
+    query = f"""
         Select DISTINCT ?p ?o
-        WHERE {
-            <%s> ?p ?o .
-        }
-    ''' %graph_entity
+        WHERE {{
+            <{graph_entity}> ?p ?o .
+        }}
+    """
     qres = graph.query(query)
 
     # dictionary to store metadata
     json_dict = {}
     for row in qres:
-        key = next((k for k in BIDS_Constants.json_keys if BIDS_Constants.json_keys[k] == row[0]), None)
-        if key != None:
+        key = next(
+            (k for k, v in BIDS_Constants.json_keys.items() if v == row[0]),
+            None,
+        )
+        if key is not None:
             json_dict[key] = row[1]
 
     # write json_dict out to appropriate sidecar filename
-    with open(join(output_directory,image_filename + ".json"),"w") as fp:
-        json.dump(json_dict,fp,indent=2)
+    with open(
+        join(output_directory, image_filename + ".json"), "w", encoding="utf-8"
+    ) as fp:
+        json.dump(json_dict, fp, indent=2)
 
 
-def ProcessFiles(graph,scan_type,output_directory,project_location,args):
-    '''
+def ProcessFiles(graph, scan_type, output_directory, project_location, args):
+    """
     This function will essentially cycle through the acquisition objects in the NIDM file loaded into graph
     and depending on the scan_type will try and copy the image to the output_directory
-    '''
+    """
 
     if scan_type == Constants.NIDM_MRI_DIFFUSION_TENSOR.uri:
-        bids_ext = 'dwi'
+        bids_ext = "dwi"
     elif scan_type == Constants.NIDM_MRI_ANATOMIC_SCAN.uri:
-        bids_ext = 'anat'
+        bids_ext = "anat"
     elif scan_type == Constants.NIDM_MRI_FUNCTION_SCAN.uri:
-        bids_ext = 'func'
+        bids_ext = "func"
 
     # query NIDM document for acquisition entity "subjects" with predicate nidm:hasImageUsageType and object scan_type
-    for acq in graph.subjects(predicate=URIRef(Constants.NIDM_IMAGE_USAGE_TYPE.uri),
-                                             object=URIRef(scan_type)):
+    for acq in graph.subjects(
+        predicate=URIRef(Constants.NIDM_IMAGE_USAGE_TYPE.uri), object=URIRef(scan_type)
+    ):
         # first see if file exists locally.  Get nidm:Project prov:Location and append the nfo:Filename of the image
         # from the acq acquisition entity.  If that file doesn't exist try the prov:Location in the func acq
         # entity and see if we can download it from the cloud
 
         # get acquisition uuid from entity uuid
-        temp = graph.objects(subject=acq, predicate=Constants.PROV['wasGeneratedBy'])
+        temp = graph.objects(subject=acq, predicate=Constants.PROV["wasGeneratedBy"])
         for item in temp:
             activity = item
         # get participant ID with sio:Subject role in anat_acq qualified association
-        part_id = GetParticipantIDFromAcquisition(nidm_file_list=[args.rdf_file], acquisition=activity)
+        part_id = GetParticipantIDFromAcquisition(
+            nidm_file_list=[args.rdf_file], acquisition=activity
+        )
 
         # make BIDS sub directory
-        if 'sub' in (part_id['ID'].values)[0]:
-            sub_dir = join(output_directory, (part_id['ID'].values)[0])
+        if "sub" in (part_id["ID"].values)[0]:
+            sub_dir = join(output_directory, (part_id["ID"].values)[0])
         else:
-            sub_dir = join(output_directory, "sub-" + (part_id['ID'].values)[0])
-        sub_filename_base = "sub-" + (part_id['ID'].values)[0]
+            sub_dir = join(output_directory, "sub-" + (part_id["ID"].values)[0])
+        sub_filename_base = "sub-" + (part_id["ID"].values)[0]
         if not os.path.exists(sub_dir):
             os.makedirs(sub_dir)
 
         # make BIDS scan type directory (bids_ext) directory
         if not os.path.exists(join(sub_dir, bids_ext)):
             os.makedirs(join(sub_dir, bids_ext))
 
-        for filename in graph.objects(subject=acq,predicate=URIRef(Constants.NIDM_FILENAME.uri)):
+        for filename in graph.objects(
+            subject=acq, predicate=URIRef(Constants.NIDM_FILENAME.uri)
+        ):
             # check if file exists
             for location in project_location:
                 # if MRI exists in this location then copy and rename
                 if isfile((location[0] + filename).lstrip("file:")):
                     # copy and rename file to be BIDS compliant
-                    copyfile((location[0] + filename).lstrip("file:"),
-                             join(sub_dir, bids_ext, sub_filename_base + splitext(filename)[1]))
+                    copyfile(
+                        (location[0] + filename).lstrip("file:"),
+                        join(
+                            sub_dir, bids_ext, sub_filename_base + splitext(filename)[1]
+                        ),
+                    )
                     continue
             # if the file wasn't accessible locally, try with the prov:Location in the acq
-            for location in graph.objects(subject=acq,predicate=URIRef(Constants.PROV['Location'])):
+            for location in graph.objects(
+                subject=acq, predicate=URIRef(Constants.PROV["Location"])
+            ):
                 # try to download the file and rename
                 ret = GetImageFromURL(location)
                 if ret == -1:
-                    print("ERROR! Can't download file: %s from url: %s, trying to copy locally...." % (
-                    filename, location))
+                    print(
+                        f"ERROR! Can't download file: {filename} from url: {location}, trying to copy locally...."
+                    )
                     if "file" in location:
                         location = str(location).lstrip("file:")
-                        print("Trying to copy file from %s" % (location))
+                        print(f"Trying to copy file from {location}")
                         try:
-                            copyfile(location, join(output_directory, sub_dir, bids_ext, basename(filename)))
-
-                        except:
-                            print("ERROR! Failed to find file %s on filesystem..." % location)
+                            copyfile(
+                                location,
+                                join(
+                                    output_directory,
+                                    sub_dir,
+                                    bids_ext,
+                                    basename(filename),
+                                ),
+                            )
+
+                        except Exception:
+                            print(
+                                f"ERROR! Failed to find file {location} on filesystem..."
+                            )
                             if not args.no_downloads:
                                 try:
                                     print(
-                                        "Running datalad get command on dataset: %s" % location)
-                                    dl.Dataset(os.path.dirname(location)).get(recursive=True, jobs=1)
+                                        f"Running datalad get command on dataset: {location}"
+                                    )
+                                    dl.Dataset(os.path.dirname(location)).get(
+                                        recursive=True, jobs=1
+                                    )
 
-                                except:
-                                    print("ERROR! Datalad returned error: %s for dataset %s." % (
-                                    sys.exc_info()[0], location))
-                                    GetImageFromAWS(location=location, output_file=
-                                        join(output_directory, sub_dir, bids_ext, basename(filename)),args=args)
+                                except Exception as e:
+                                    print(
+                                        f"ERROR! Datalad returned error: {type(e)} for dataset {location}."
+                                    )
+                                    GetImageFromAWS(
+                                        location=location,
+                                        output_file=join(
+                                            output_directory,
+                                            sub_dir,
+                                            bids_ext,
+                                            basename(filename),
+                                        ),
+                                        args=args,
+                                    )
 
                 else:
                     # copy temporary file to BIDS directory
-                    copyfile(ret, join(output_directory, sub_dir, bids_ext, basename(filename)))
+                    copyfile(
+                        ret,
+                        join(output_directory, sub_dir, bids_ext, basename(filename)),
+                    )
 
                 # if we were able to copy the image file then add the json sidecar file with additional metadata
                 # available in the NIDM file
-                if isfile(join(output_directory, sub_dir, bids_ext, basename(filename))):
+                if isfile(
+                    join(output_directory, sub_dir, bids_ext, basename(filename))
+                ):
                     # get rest of metadata for this acquisition and store in sidecar file
                     if "gz" in basename(filename):
                         image_filename = splitext(splitext(basename(filename))[0])[0]
                     else:
                         image_filename = splitext(basename(filename))[0]
-                    AddMetadataToImageSidecar(graph_entity=acq,graph=graph,output_directory=join(output_directory,
-                            sub_dir,bids_ext),image_filename=image_filename)
+                    AddMetadataToImageSidecar(
+                        graph_entity=acq,
+                        graph=graph,
+                        output_directory=join(output_directory, sub_dir, bids_ext),
+                        image_filename=image_filename,
+                    )
 
             # if this is a DWI scan then we should copy over the b-value and b-vector files
-            if bids_ext == 'dwi':
+            if bids_ext == "dwi":
                 # search for entity uuid with rdf:type nidm:b-value that was generated by activity
-                query = """
+                query = f"""
                     PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
                     PREFIX prov: <http://www.w3.org/ns/prov#>
                     PREFIX nidm: <http://purl.org/nidash/nidm#>
-    
+
                     SELECT DISTINCT ?entity
-                        WHERE {
+                        WHERE {{
                             ?entity rdf:type <http://purl.org/nidash/nidm#b-value> ;
-                                prov:wasGeneratedBy <%s> .
-                        }""" % activity
+                                prov:wasGeneratedBy <{activity}> .
+                        }}"""
                 # print(query)
                 qres = graph.query(query)
 
                 for row in qres:
                     bval_entity = str(row[0])
 
                 # if the file wasn't accessible locally, try with the prov:Location in the acq
-                for location in graph.objects(subject=URIRef(bval_entity), predicate=URIRef(Constants.PROV['Location'])):
+                for location in graph.objects(
+                    subject=URIRef(bval_entity),
+                    predicate=URIRef(Constants.PROV["Location"]),
+                ):
                     # try to download the file and rename
                     ret = GetImageFromURL(location)
                     if ret == -1:
-                        print("ERROR! Can't download file: %s from url: %s, trying to copy locally...." % (
-                            filename, location))
+                        print(
+                            f"ERROR! Can't download file: {filename} from url: {location}, trying to copy locally...."
+                        )
                         if "file" in location:
                             location = str(location).lstrip("file:")
-                            print("Trying to copy file from %s" % (location))
+                            print(f"Trying to copy file from {location}")
                             try:
-                                copyfile(location, join(output_directory, sub_dir, bids_ext, basename(location)))
-                            except:
-                                print("ERROR! Failed to find file %s on filesystem..." % location)
+                                copyfile(
+                                    location,
+                                    join(
+                                        output_directory,
+                                        sub_dir,
+                                        bids_ext,
+                                        basename(location),
+                                    ),
+                                )
+                            except Exception:
+                                print(
+                                    f"ERROR! Failed to find file {location} on filesystem..."
+                                )
                                 if not args.no_downloads:
                                     try:
                                         print(
-                                            "Running datalad get command on dataset: %s" % location)
-                                        dl.Dataset(os.path.dirname(location)).get(recursive=True, jobs=1)
+                                            f"Running datalad get command on dataset: {location}"
+                                        )
+                                        dl.Dataset(os.path.dirname(location)).get(
+                                            recursive=True, jobs=1
+                                        )
 
-                                    except:
-                                        print("ERROR! Datalad returned error: %s for dataset %s." % (
-                                            sys.exc_info()[0], location))
-                                        GetImageFromAWS(location=location, output_file=
-                                            join(output_directory, sub_dir, bids_ext, basename(location)),args=args)
+                                    except Exception as e:
+                                        print(
+                                            f"ERROR! Datalad returned error: {type(e)} for dataset {location}."
+                                        )
+                                        GetImageFromAWS(
+                                            location=location,
+                                            output_file=join(
+                                                output_directory,
+                                                sub_dir,
+                                                bids_ext,
+                                                basename(location),
+                                            ),
+                                            args=args,
+                                        )
                 # search for entity uuid with rdf:type nidm:b-value that was generated by activity
-                query = """
+                query = f"""
                     PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
                     PREFIX prov: <http://www.w3.org/ns/prov#>
                     PREFIX nidm: <http://purl.org/nidash/nidm#>
 
                     SELECT DISTINCT ?entity
-                        WHERE {
+                        WHERE {{
                             ?entity rdf:type <http://purl.org/nidash/nidm#b-vector> ;
-                                prov:wasGeneratedBy <%s> .
-                        }""" % activity
+                                prov:wasGeneratedBy <{activity}> .
+                        }}"""
                 # print(query)
                 qres = graph.query(query)
 
                 for row in qres:
                     bvec_entity = str(row[0])
 
                 # if the file wasn't accessible locally, try with the prov:Location in the acq
-                for location in graph.objects(subject=URIRef(bvec_entity),
-                                              predicate=URIRef(Constants.PROV['Location'])):
+                for location in graph.objects(
+                    subject=URIRef(bvec_entity),
+                    predicate=URIRef(Constants.PROV["Location"]),
+                ):
                     # try to download the file and rename
                     ret = GetImageFromURL(location)
                     if ret == -1:
                         print(
-                            "ERROR! Can't download file: %s from url: %s, trying to copy locally...." % (
-                                filename, location))
+                            f"ERROR! Can't download file: {filename} from url: {location}, trying to copy locally...."
+                        )
                         if "file" in location:
                             location = str(location).lstrip("file:")
-                            print("Trying to copy file from %s" % (location))
+                            print(f"Trying to copy file from {location}")
                             try:
-                                copyfile(location,
-                                         join(output_directory, sub_dir, bids_ext, basename(location)))
-                            except:
-                                print("ERROR! Failed to find file %s on filesystem..." % location)
+                                copyfile(
+                                    location,
+                                    join(
+                                        output_directory,
+                                        sub_dir,
+                                        bids_ext,
+                                        basename(location),
+                                    ),
+                                )
+                            except Exception:
+                                print(
+                                    f"ERROR! Failed to find file {location} on filesystem..."
+                                )
                                 if not args.no_downloads:
                                     try:
                                         print(
-                                            "Running datalad get command on dataset: %s" % location)
-                                        dl.Dataset(os.path.dirname(location)).get(recursive=True,
-                                                                                  jobs=1)
-
-                                    except:
-                                        print("ERROR! Datalad returned error: %s for dataset %s." % (
-                                            sys.exc_info()[0], location))
-                                        GetImageFromAWS(location=location, output_file=
-                                            join(output_directory, sub_dir, bids_ext, basename(location)),
-                                                        args=args)
-
+                                            f"Running datalad get command on dataset: {location}"
+                                        )
+                                        dl.Dataset(os.path.dirname(location)).get(
+                                            recursive=True, jobs=1
+                                        )
 
-def main(argv):
-    parser = ArgumentParser(description='This program will convert a NIDM-Experiment RDF document \
+                                    except Exception as e:
+                                        print(
+                                            f"ERROR! Datalad returned error: {type(e)} for dataset {location}."
+                                        )
+                                        GetImageFromAWS(
+                                            location=location,
+                                            output_file=join(
+                                                output_directory,
+                                                sub_dir,
+                                                bids_ext,
+                                                basename(location),
+                                            ),
+                                            args=args,
+                                        )
+
+
+def main():
+    parser = ArgumentParser(
+        description="This program will convert a NIDM-Experiment RDF document \
         to a BIDS dataset.  The program will query the NIDM-Experiment document for subjects, \
         MRI scans, and associated assessments saving the MRI data to disk in an organization \
         according to the BIDS specification, metadata to a participants.tsv \
-        file, the project-level metdata to a dataset_description.json file, and the \
-        assessments to *.tsv/*.json file pairs in a phenotypes directory.', epilog='Example of use: \
-        NIDM2BIDSMRI.py -nidm_file NIDM.ttl -part_fields age,gender -bids_dir BIDS')
-
-    parser.add_argument('-nidm_file', dest='rdf_file', required=True, help="NIDM RDF file")
-    parser.add_argument('-part_fields', nargs='+', dest='part_fields', required=False, \
-                        help='Variables to add to BIDS participant file. Variables will be fuzzy-matched to NIDM URIs')
-    parser.add_argument('-anat', dest='anat', action='store_true', required=False, help="Include flag to add anatomical scans to BIDS dataset")
-    parser.add_argument('-func', dest='func', action='store_true', required=False, help="Include flag to add functional scans + events files to BIDS dataset")
-    parser.add_argument('-dwi', dest='dwi', action='store_true', required=False, help="Include flag to add DWI scans + Bval/Bvec files to BIDS dataset")
-    parser.add_argument('-bids_dir', dest='bids_dir', required=True, help="Directory to store BIDS dataset")
+        file, the project-level metadata to a dataset_description.json file, and the \
+        assessments to *.tsv/*.json file pairs in a phenotypes directory.",
+        epilog="Example of use: \
+        NIDM2BIDSMRI.py -nidm_file NIDM.ttl -part_fields age,gender -bids_dir BIDS",
+    )
+
+    parser.add_argument(
+        "-nidm_file", dest="rdf_file", required=True, help="NIDM RDF file"
+    )
+    parser.add_argument(
+        "-part_fields",
+        nargs="+",
+        dest="part_fields",
+        required=False,
+        help="Variables to add to BIDS participant file. Variables will be fuzzy-matched to NIDM URIs",
+    )
+    parser.add_argument(
+        "-anat",
+        dest="anat",
+        action="store_true",
+        required=False,
+        help="Include flag to add anatomical scans to BIDS dataset",
+    )
+    parser.add_argument(
+        "-func",
+        dest="func",
+        action="store_true",
+        required=False,
+        help="Include flag to add functional scans + events files to BIDS dataset",
+    )
+    parser.add_argument(
+        "-dwi",
+        dest="dwi",
+        action="store_true",
+        required=False,
+        help="Include flag to add DWI scans + Bval/Bvec files to BIDS dataset",
+    )
+    parser.add_argument(
+        "-bids_dir",
+        dest="bids_dir",
+        required=True,
+        help="Directory to store BIDS dataset",
+    )
 
     group = parser.add_mutually_exclusive_group()
-    group.add_argument('-no_downloads',dest='no_downloads', action='store_true',required=False, help=
-                        "If this flag is set then script won't attempt to download images using datalad"
-                        "and AWS S3.  Default behavior is files are downloaded if they don't exist locally.")
-    group.add_argument('-aws_url', dest='aws_url', required=False, help="This tool facilites export of "
+    group.add_argument(
+        "-no_downloads",
+        dest="no_downloads",
+        action="store_true",
+        required=False,
+        help="If this flag is set then script won't attempt to download images using datalad"
+        "and AWS S3.  Default behavior is files are downloaded if they don't exist locally.",
+    )
+    group.add_argument(
+        "-aws_url",
+        dest="aws_url",
+        required=False,
+        help="This tool facilities export of "
         "user-selected information from a NIDM file to a BIDS dataset and may have to fetch images. The NIDM files contain links from"
         "the local filesystem used to convert BIDS to NIDM and possibly DataLad dataset links to the files if the"
         " original BIDS data was a DataLad dataset. Here we support 3 modes of trying to find images: (1) copy from"
         " the local directory space using the prov:Location information in the NIDM file; (2) fetch the images from"
         " a DataLad remote if the original BIDS dataset was a DataLad dataset when bids2nidm was run; (3) attempt "
         " to download the images via a AWS S3 link.  This parameter lets the user set the base AWS S3 URL to try and"
         " find the images.  Currently it supports using the URL provided here and adding the dataset id, subject id,"
         " and filename.  For example, in OpenNeuro (OpenNeuro is supported by default but will serve as an example) the base AWS S3"
-        " URL is \'s3://openneuro.org\'. The URL then becomes (for example) "
+        " URL is 's3://openneuro.org'. The URL then becomes (for example) "
         " s3://openneuro.org/ds000002/sub-06/func/sub-06_task-probabilisticclassification_run-02_bold.nii.gz where this tool"
-        " has added \'ds000002/sub-06/[FILENAME] to the base AWS S3 URL.")
-    parser.add_argument('-dataset_string', dest='dataset_string', required=False, help="If -aws_url parameter is supplied"
+        " has added 'ds000002/sub-06/[FILENAME] to the base AWS S3 URL.",
+    )
+    parser.add_argument(
+        "-dataset_string",
+        dest="dataset_string",
+        required=False,
+        help="If -aws_url parameter is supplied"
         " this parameter (-dataset_string) is required as it will be added to the aws_baseurl to retrieve images for each"
-        " subject and file.  For example, if -aws_baseurl is \'s3://davedata.org \' and -dataset_string is \'dataset1\' then"
+        " subject and file.  For example, if -aws_baseurl is 's3://davedata.org ' and -dataset_string is 'dataset1' then"
         " the AWS S3 url for sub-1 and file sub1-task-rest_run-1_bold.nii.gz would be: "
-        " \'s3://davedata.org/dataset1/sub-1/[anat | func | dwi/sub1-task-rest_run-1_bold.nii.gz\'")
+        " 's3://davedata.org/dataset1/sub-1/[anat | func | dwi/sub1-task-rest_run-1_bold.nii.gz'",
+    )
 
     args = parser.parse_args()
 
     # check some argument dependencies
     if args.aws_url and not args.dataset_string:
-        print("ERROR! You must include a -dataset_string if you supplied the -aws_baseurl.  If there is no dataset"
-              " string in your AWS S3 urls then just supply -aws_baseurl with nothing after it.")
+        print(
+            "ERROR! You must include a -dataset_string if you supplied the -aws_baseurl.  If there is no dataset"
+            " string in your AWS S3 urls then just supply -aws_baseurl with nothing after it."
+        )
         print(args.print_help())
-        exit(-1)
+        sys.exit(-1)
 
     # set up some local variables
     rdf_file = args.rdf_file
     output_directory = args.bids_dir
 
     # check if output directory exists, if not create it
     if not isdir(output_directory):
         mkdir(path=output_directory)
 
-
-    #try to read RDF file
+    # try to read RDF file
     print("Guessing RDF file format...")
-    format_found=False
-    for format in 'turtle','xml','n3','trix','rdfa':
+    format_found = False
+    for fmt in "turtle", "xml", "n3", "trix", "rdfa":
         try:
-            print("Reading RDF file as %s..." % format)
-            #load NIDM graph into NIDM-Exp API objects
+            print(f"Reading RDF file as {fmt}...")
+            # load NIDM graph into NIDM-Exp API objects
             nidm_project = read_nidm(rdf_file)
             # temporary save nidm_project
-            with open("/Users/dbkeator/Downloads/nidm.ttl", 'w') as f:
+            with open("/Users/dbkeator/Downloads/nidm.ttl", "w", encoding="utf-8") as f:
                 print(nidm_project.serializeTurtle(), file=f)
-            print("RDF file sucessfully read")
-            format_found=True
+            print("RDF file successfully read")
+            format_found = True
             break
         except Exception:
-            print("File: %s appears to be an invalid %s RDF file" % (rdf_file,format))
+            print(f"File: {rdf_file} appears to be an invalid {fmt} RDF file")
 
     if not format_found:
-        print("File doesn't appear to be a valid RDF format supported by Python RDFLib!  Please check input file")
+        print(
+            "File doesn't appear to be a valid RDF format supported by Python RDFLib!  Please check input file"
+        )
         print("exiting...")
-        exit(-1)
+        sys.exit(-1)
 
-  #  if not os.path.isdir(join(output_directory,os.path.splitext(args.rdf_file)[0])):
-  #      os.mkdir(join(output_directory,os.path.splitext(args.rdf_file)[0]))
+    #  if not os.path.isdir(join(output_directory,os.path.splitext(args.rdf_file)[0])):
+    #      os.mkdir(join(output_directory,os.path.splitext(args.rdf_file)[0]))
 
-    #convert Project NIDM object -> dataset_description.json file
-    NIDMProject2BIDSDatasetDescriptor(nidm_project,output_directory)
+    # convert Project NIDM object -> dataset_description.json file
+    NIDMProject2BIDSDatasetDescriptor(nidm_project, output_directory)
 
-    #create participants.tsv file.  In BIDS datasets there is no specification for how many or which type of assessment
-    #variables might be in this file.  The specification does mention a minimum participant_id which indexes each of the
-    #subjects in the BIDS dataset.
+    # create participants.tsv file.  In BIDS datasets there is no specification for how many or which type of assessment
+    # variables might be in this file.  The specification does mention a minimum participant_id which indexes each of the
+    # subjects in the BIDS dataset.
     #
-    #if parameter -parts_field is defined then the variables listed will be fuzzy matched to the URIs in the NIDM file
-    #and added to the participants.tsv file
+    # if parameter -parts_field is defined then the variables listed will be fuzzy matched to the URIs in the NIDM file
+    # and added to the participants.tsv file
 
-    #use RDFLib here for temporary graph making query easier
+    # use RDFLib here for temporary graph making query easier
     rdf_graph = Graph()
-    rdf_graph_parse = rdf_graph.parse(source=StringIO(nidm_project.serializeTurtle()), format='turtle')
+    rdf_graph_parse = rdf_graph.parse(
+        source=StringIO(nidm_project.serializeTurtle()), format="turtle"
+    )
 
     # temporary write out turtle file for testing
     # rdf_graph_parse.serialize(destination="/Users/dbkeator/Downloads/ds000117.ttl", format='turtle')
 
-
-    #create participants file
-    CreateBIDSParticipantFile(rdf_graph_parse, join(output_directory, "participants"), args.part_fields)
+    # create participants file
+    CreateBIDSParticipantFile(
+        rdf_graph_parse, join(output_directory, "participants"), args.part_fields
+    )
 
     # get nidm:Project prov:Location
     # first get nidm:Project UUIDs
     project_uuid = GetProjectsUUID([rdf_file], output_file=None)
     project_location = []
     for uuid in project_uuid:
-        project_location.append(GetProjectLocation(nidm_file_list=[rdf_file], project_uuid=uuid))
+        project_location.append(
+            GetProjectLocation(nidm_file_list=[rdf_file], project_uuid=uuid)
+        )
+
+    # creating BIDS hierarchy with requested scans
+    if args.anat is True:
+        ProcessFiles(
+            graph=rdf_graph_parse,
+            scan_type=Constants.NIDM_MRI_ANATOMIC_SCAN.uri,
+            output_directory=output_directory,
+            project_location=project_location,
+            args=args,
+        )
+
+    if args.func is True:
+        ProcessFiles(
+            graph=rdf_graph_parse,
+            scan_type=Constants.NIDM_MRI_FUNCTION_SCAN.uri,
+            output_directory=output_directory,
+            project_location=project_location,
+            args=args,
+        )
+    if args.dwi is True:
+        ProcessFiles(
+            graph=rdf_graph_parse,
+            scan_type=Constants.NIDM_MRI_DIFFUSION_TENSOR.uri,
+            output_directory=output_directory,
+            project_location=project_location,
+            args=args,
+        )
 
-    #creating BIDS hierarchy with requested scans
-    if args.anat==True:
-        ProcessFiles(graph=rdf_graph_parse, scan_type=Constants.NIDM_MRI_ANATOMIC_SCAN.uri,
-                     output_directory=output_directory, project_location=project_location, args=args)
-
-    if args.func == True:
-        ProcessFiles(graph=rdf_graph_parse, scan_type=Constants.NIDM_MRI_FUNCTION_SCAN.uri,
-                     output_directory=output_directory, project_location=project_location, args=args)
-    if args.dwi == True:
-        ProcessFiles(graph=rdf_graph_parse, scan_type = Constants.NIDM_MRI_DIFFUSION_TENSOR.uri ,
-                     output_directory=output_directory, project_location=project_location, args=args)
 
 if __name__ == "__main__":
-   main(sys.argv[1:])
-
+    main()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/nidm_affinity_propagation.py` & `pynidm-4.0.0/src/nidm/experiment/tools/nidm_agglomerative_clustering.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,61 +1,63 @@
+import csv
 import os
+import sys
 import tempfile
+import click
+import matplotlib.pyplot as plt
 import pandas as pd
-import csv
-from patsy.highlevel import dmatrices
+import scipy.cluster.hierarchy as sch
+from sklearn import preprocessing
+from sklearn.cluster import AgglomerativeClustering
+from sklearn.preprocessing import MinMaxScaler
 from nidm.experiment.Query import GetProjectsUUID
-import click
 from nidm.experiment.tools.click_base import cli
 from nidm.experiment.tools.rest import RestParser
-import numpy as np
-import matplotlib.pyplot as plt
-import seaborn as sns
-from sklearn.cluster import KMeans
-from sklearn.decomposition import PCA
-from sklearn.metrics import silhouette_score, adjusted_rand_score
-from sklearn.pipeline import Pipeline
-from sklearn.preprocessing import LabelEncoder, MinMaxScaler
-from sklearn.cluster import AffinityPropagation
-from sklearn import metrics
-from sklearn import preprocessing
+from .utils import Reporter
+
 
 @cli.command()
-@click.option("--nidm_file_list", "-nl", required=True,
-              help="A comma separated list of NIDM files with full path")
-@click.option("-variables", required=False,
-                 help="This parameter is for the variables the user would like to complete the k-means algorithm on.\nThe way this looks in the command is python3 nidm_kmeans.py -nl MTdemog_aseg_v2.ttl -v \"fs_003343,age*sex,sex,age,group,age*group,bmi\"")
-@click.option("--output_file", "-o", required=False,
-              help="Optional output file (TXT) to store results of the linear regression, contrast, and regularization")
-def full_ap(nidm_file_list, output_file, variables):
+@click.option(
+    "--nidm_file_list",
+    "-nl",
+    required=True,
+    help="A comma separated list of NIDM files with full path",
+)
+@click.option(
+    "-variables",
+    required=False,
+    help='This parameter is for the variables the user would like to complete the k-means algorithm on.\nThe way this looks in the command is python3 nidm_kmeans.py -nl MTdemog_aseg_v2.ttl -v "fs_003343,age*sex,sex,age,group,age*group,bmi"',
+)
+@click.option(
+    "--output_file",
+    "-o",
+    required=False,
+    help="Optional output file (TXT) to store results of the linear regression, contrast, and regularization",
+)
+def full_ac(nidm_file_list, output_file, variables):
     global v  # Needed to do this because the code only used the parameters in the first method, meaning I had to move it all to method 1.
-    v = variables.strip()  # used in data_aggregation, linreg(), spaces stripped from left and right
-    global o  # used in dataparsing()
-    o = output_file
-    global n  # used in data_aggregation()
-    n = nidm_file_list
-    data_aggregation()
-    dataparsing()
-    ap()
+    v = (
+        variables.strip()
+    )  # used in data_aggregation, linreg(), spaces stripped from left and right
+    with Reporter(output_file) as reporter:
+        global n  # used in data_aggregation()
+        n = nidm_file_list
+        data_aggregation(reporter)
+        dataparsing(reporter)
+        ac()
 
 
-def data_aggregation():  # all data from all the files is collected
-    """    This function provides query support for NIDM graphs.   """
-    # query result list
-    results = []
+def data_aggregation(reporter):  # all data from all the files is collected
+    """This function provides query support for NIDM graphs."""
     # if there is a CDE file list, seed the CDE cache
     if v:  # ex: fs_00343 ~ age + sex + group
-        print("***********************************************************************************************************")
-        command = "python nidm_kmeans.py -nl " + n + " -variables \"" + v + "\" "
+        print("*" * 107)
+        command = "python nidm_kmeans.py -nl " + n + ' -variables "' + v + '" '
 
-        print("Your command was: " + command)
-        if (o is not None):
-            f = open(o, "w")
-            f.write("Your command was " + command)
-            f.close()
+        reporter.print("Your command was:", command)
         verbosity = 0
         restParser = RestParser(verbosity_level=int(verbosity))
         restParser.setOutputFormat(RestParser.OBJECT_FORMAT)
         global df_list  # used in dataparsing()
         df_list = []
         # set up uri to do fields query for each nidm file
         global file_list
@@ -73,254 +75,287 @@
         count = 0
         not_found_count = 0
         for nidm_file in file_list:
             # get project UUID
             project = GetProjectsUUID([nidm_file])
             # split the model into its constituent variables
             global full_model_variable_list
-            full_model_variable_list=[]
+            full_model_variable_list = []
             global model_list
-            model_list = v.split(",")
-            for i in range(len(model_list)):  # here, we remove any leading or trailing spaces
-                model_list[i] = model_list[i].strip()
-            global vars  # used in dataparsing()
-            vars = ""
+            model_list = [vv.strip() for vv in v.split(",")]
+            global variables  # used in dataparsing()
+            variables = ""
             for i in range(len(model_list) - 1, -1, -1):
-                full_model_variable_list.append(model_list[i])  # will be used in the regularization, but we need the full list
-                if "*" in model_list[i]:  # removing the star term from the columns we're about to pull from data
+                full_model_variable_list.append(
+                    model_list[i]
+                )  # will be used in the regularization, but we need the full list
+                if (
+                    "*" in model_list[i]
+                ):  # removing the star term from the columns we're about to pull from data
                     model_list.pop(i)
                 else:
-                    vars = vars + model_list[i] + ","
-            vars = vars[0:len(vars) - 1]
-            uri = "/projects/" + project[0].toPython().split("/")[-1] + "?fields=" + vars
+                    variables = variables + model_list[i] + ","
+            variables = variables[0 : len(variables) - 1]
+            uri = (
+                "/projects/"
+                + project[0].toPython().split("/")[-1]
+                + "?fields="
+                + variables
+            )
             # get fields output from each file and concatenate
             df_list_holder[count].append(pd.DataFrame(restParser.run([nidm_file], uri)))
             df = pd.concat(df_list_holder[count])
-            with tempfile.NamedTemporaryFile(delete=False) as temp:  # turns the dataframe into a temporary csv
-                df.to_csv(temp.name + '.csv')
+            with tempfile.NamedTemporaryFile(
+                delete=False
+            ) as temp:  # turns the dataframe into a temporary csv
+                df.to_csv(temp.name + ".csv")
                 temp.close()
-            data = list(csv.reader(open(temp.name + '.csv')))  # makes the csv a 2D list to make it easier to call the contents of certain cells
-            numcols = (len(data) - 1) // (len(model_list))  # Finds the number of columns in the original dataframe
-            global condensed_data  # also used in linreg()
-            condensed_data_holder[count] = [[0] * (len(model_list))]  # makes an array 1 row by the number of necessary columns
-            for i in range(numcols):  # makes the 2D array big enough to store all of the necessary values in the edited dataset
-                condensed_data_holder[count].append([0] * (len(model_list)))
-            for i in range(len(model_list)):  # stores the independent variable names in the first row
-                condensed_data_holder[count][0][i] = model_list[i]
+            with open(temp.name + ".csv", encoding="utf-8") as fp:
+                data = list(
+                    csv.reader(fp)
+                )  # makes the csv a 2D list to make it easier to call the contents of certain cells
+            numcols = (len(data) - 1) // (
+                len(model_list)
+            )  # Finds the number of columns in the original dataframe
+            condensed_data_holder[count] = [
+                [0] * (len(model_list))
+            ]  # makes an array 1 row by the number of necessary columns
+            for _ in range(
+                numcols
+            ):  # makes the 2D array big enough to store all of the necessary values in the edited dataset
+                condensed_data_holder[count].append([0] * len(model_list))
+            for i, ml in enumerate(model_list):
+                # stores the independent variable names in the first row
+                condensed_data_holder[count][0][i] = ml
             numrows = 1  # begins at the first row to add data
-            fieldcolumn = 0  # the column the variable name is in in the original dataset
+            fieldcolumn = (
+                0  # the column the variable name is in in the original dataset
+            )
             valuecolumn = 0  # the column the value is in in the original dataset
             datacolumn = 0  # if it is identified by the dataElement name instead of the field's name
             not_found_list = []
             for i in range(len(data[0])):
-                if data[0][i] == 'sourceVariable':  # finds the column where the variable names are
+                if (
+                    data[0][i] == "sourceVariable"
+                ):  # finds the column where the variable names are
                     fieldcolumn = i
-                elif data[0][i] == 'source_variable':  # finds the column where the variable names are
+                elif (
+                    data[0][i] == "source_variable"
+                ):  # finds the column where the variable names are
                     fieldcolumn = i
-                elif data[0][i] == 'isAbout':
+                elif data[0][i] == "isAbout":
                     aboutcolumn = i
-                elif data[0][i] == 'label':
+                elif data[0][i] == "label":
                     namecolumn = i  # finds the column where the variable names are
-                elif data[0][i] == 'value':
+                elif data[0][i] == "value":
                     valuecolumn = i  # finds the column where the values are
-                elif data[0][i] == 'dataElement':  # finds the column where the data element is if necessary
+                elif (
+                    data[0][i] == "dataElement"
+                ):  # finds the column where the data element is if necessary
                     datacolumn = i
             for i in range(
-                    len(condensed_data_holder[count][
-                            0])):  # starts iterating through the dataset, looking for the name in that
-                for j in range(1, len(data)):  # column, so it can append the values under the proper variables
+                len(condensed_data_holder[count][0])
+            ):  # starts iterating through the dataset, looking for the name in that
+                for j in range(
+                    1, len(data)
+                ):  # column, so it can append the values under the proper variables
                     try:
                         split_url = condensed_data_holder[count][0][i].split("/")
-                        if data[j][fieldcolumn] == condensed_data_holder[count][0][
-                            i]:  # in the dataframe, the name is in column 3
+                        if (
+                            data[j][fieldcolumn] == condensed_data_holder[count][0][i]
+                        ):  # in the dataframe, the name is in column 3
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][aboutcolumn] == condensed_data_holder[count][0][
-                            i]:
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif data[j][aboutcolumn] == condensed_data_holder[count][0][i]:
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][aboutcolumn] == split_url[
-                            len(split_url) - 1]:  # this is in case the uri only works by querying the part after the last backslash
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            data[j][aboutcolumn] == split_url[len(split_url) - 1]
+                        ):  # this is in case the uri only works by querying the part after the last backslash
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-
-                        elif data[j][namecolumn] == condensed_data_holder[count][0][
-                            i]:  # in the dataframe, the name is in column 12
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+
+                        elif (
+                            data[j][namecolumn] == condensed_data_holder[count][0][i]
+                        ):  # in the dataframe, the name is in column 12
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif condensed_data_holder[count][0][i] == data[j][
-                            datacolumn]:  # in the dataframe, the name is in column 9
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            condensed_data_holder[count][0][i] == data[j][datacolumn]
+                        ):  # in the dataframe, the name is in column 9
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
                     except IndexError:
                         numrows = numrows + 1
                 numrows = 1  # resets to the first row for the next variable
             temp_list = condensed_data_holder[count]
-            for j in range(len(temp_list[0]) - 1, 0,-1):  # if the software appends a column with 0 as the heading, it removes this null column
+            for j in range(
+                len(temp_list[0]) - 1, 0, -1
+            ):  # if the software appends a column with 0 as the heading, it removes this null column
                 if temp_list[0][j] == "0" or temp_list[0][j] == "NaN":
                     for row in condensed_data_holder[count]:
                         row.pop(j)
             rowsize = len(condensed_data_holder[count][0])
             count1 = 0
             for i in range(0, rowsize):
                 for row in condensed_data_holder[count]:
                     if row[i] == 0 or row[i] == "NaN" or row[i] == "0":
                         count1 = count1 + 1
                 if count1 > len(condensed_data_holder[count]) - 2:
                     not_found_list.append(condensed_data_holder[count][0][i])
                 count1 = 0
-            for i in range(len(condensed_data_holder[count][0])):
-                if " " in condensed_data_holder[count][0][i]:
-                    condensed_data_holder[count][0][i] = condensed_data_holder[count][0][i].replace(" ", "_")
-            for i in range(len(vars)):
-                if " " in vars[i]:
-                    vars[i] = vars[i].replace(" ", "_")
-            count = count + 1
+            for i, cdh in enumerate(condensed_data_holder[count][0]):
+                if " " in cdh:
+                    condensed_data_holder[count][0][i] = cdh.replace(" ", "_")
+            variables = [v.replace(" ", "_") for v in variables]
+            count += 1
             if len(not_found_list) > 0:
-                print(
-                        "***********************************************************************************************************")
-                print()
-                print("Your variables were " + v)
+                print("*" * 107)
                 print()
-                print(
-                        "The following variables were not found in " + nidm_file + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables.")
-                if (o is not None):
-                    f = open(o, "a")
-                    f.write("Your variables were " + v)
-                    f.write(
-                            "The following variables were not found in " + nidm_file + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables.")
-                    f.close()
-                for i in range(0, len(not_found_list)):
-                    print(str(i + 1) + ". " + not_found_list[i])
-                    if (o is not None):
-                        f = open(o, "a")
-                        f.write(str(i + 1) + ". " + not_found_list[i])
-                        f.close()
-                for j in range(len(not_found_list) - 1, 0, -1):
-                    not_found_list.pop(j)
-                not_found_count = not_found_count + 1
+                reporter.print("Your variables were", v)
+                reporter.print()
+                reporter.print(
+                    "The following variables were not found in "
+                    + nidm_file
+                    + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables."
+                )
+                for i, nf in enumerate(not_found_list):
+                    reporter.print(f"{i+1}. {nf}")
+                not_found_list.clear()
+                not_found_count += 1
                 print()
         if not_found_count > 0:
-            exit(1)
-
+            sys.exit(1)
 
     else:
         print("ERROR: No query parameter provided.  See help:")
         print()
         os.system("pynidm query --help")
-        exit(1)
+        sys.exit(1)
 
-def dataparsing(): #The data is changed to a format that is usable by the linear regression method
+
+def dataparsing(
+    reporter,
+):  # The data is changed to a format that is usable by the linear regression method
     global condensed_data
     condensed_data = []
     for i in range(0, len(file_list)):
         condensed_data = condensed_data + condensed_data_holder[i]
-    x = pd.read_csv(opencsv(condensed_data))  # changes the dataframe to a csv to make it easier to work with
+    x = pd.read_csv(
+        opencsv(condensed_data)
+    )  # changes the dataframe to a csv to make it easier to work with
     x.head()  # prints what the csv looks like
     x.dtypes  # checks data format
     obj_df = x.select_dtypes  # puts all the variables in a dataset
     x.shape  # says number of rows and columns in form of tuple
     x.describe()  # says dataset statistics
     obj_df = x.select_dtypes(
-        include=['object']).copy()  # takes everything that is an object (not float or int) and puts it in a new dataset
+        include=["object"]
+    ).copy()  # takes everything that is an object (not float or int) and puts it in a new dataset
     obj_df.head()  # prints the new dataset
-    int_df = x.select_dtypes(include=['int64']).copy()  # takes everything that is an int and puts it in a new dataset
+    int_df = x.select_dtypes(
+        include=["int64"]
+    ).copy()  # takes everything that is an int and puts it in a new dataset
     float_df = x.select_dtypes(
-        include=['float64']).copy()  # takes everything that is a float and puts it in a new dataset
+        include=["float64"]
+    ).copy()  # takes everything that is a float and puts it in a new dataset
     df_int_float = pd.concat([float_df, int_df], axis=1)
     stringvars = []  # starts a list that will store all variables that are not numbers
     for i in range(1, len(condensed_data)):  # goes through each variable
         for j in range(len(condensed_data[0])):  # in the 2D array
             try:  # if the value of the field can be turned into a float (is numerical)
                 float(condensed_data[i][j])  # this means it's a number
             except ValueError:  # if it can't be (is a string)
-                if condensed_data[0][
-                    j] not in stringvars:  # adds the variable name to the list if it isn't there already
+                if (
+                    condensed_data[0][j] not in stringvars
+                ):  # adds the variable name to the list if it isn't there already
                     stringvars.append(condensed_data[0][j])
-    le = preprocessing.LabelEncoder()  # anything involving le shows the encoding of categorical variables
-    for i in range(len(stringvars)):
-        le.fit(obj_df[stringvars[i]].astype(str))
-    obj_df_trf = obj_df.astype(str).apply(le.fit_transform)  # transforms the categorical variables into numbers.
+    le = (
+        preprocessing.LabelEncoder()
+    )  # anything involving le shows the encoding of categorical variables
+    for sv in stringvars:
+        le.fit(obj_df[sv].astype(str))
+    obj_df_trf = obj_df.astype(str).apply(
+        le.fit_transform
+    )  # transforms the categorical variables into numbers.
     global df_final  # also used in linreg()
     if not obj_df_trf.empty:
-        df_final = pd.concat([df_int_float, obj_df_trf], axis=1)  # join_axes=[df_int_float.index])
+        df_final = pd.concat(
+            [df_int_float, obj_df_trf], axis=1
+        )  # join_axes=[df_int_float.index])
     else:
         df_final = df_int_float
-    df_final.head()  # shows the final dataset with all the encoding
-    print(df_final)  # prints the final dataset
-    print()
-    print("***********************************************************************************************************")
-    print()
-    if (o is not None):
-        f = open(o, "a")
-        f.write(df_final.to_string(header=True, index=True))
-        f.write(
-            "\n\n***********************************************************************************************************")
-        f.write("\n\nModel Results: ")
-        f.close()
-def ap():
+    reporter.print(df_final.to_string(header=True, index=True))
+    reporter.print("\n" + ("*" * 107))
+    reporter.print("\nModel Results: ")
+
+
+def ac():
     index = 0
     global levels  # also used in contrasting()
     levels = []
     for i in range(1, len(condensed_data)):
         if condensed_data[i][index] not in levels:
             levels.append(condensed_data[i][index])
-    for i in range(len(levels)):
-        levels[i] = i
+    levels = list(range(len(levels)))
 
     # Beginning of the linear regression
     global X
-    #global y
-    #Unsure on how to procede here with interacting variables, since I'm sure dmatrices won't work
+    # global y
+    # Unsure on how to proceed here with interacting variables, since I'm sure dmatrices won't work
 
     scaler = MinMaxScaler()
 
-    for i in range(len(model_list)):
-        scaler.fit(df_final[[model_list[i]]])
-        df_final[[model_list[i]]] = scaler.transform(df_final[[model_list[i]]])
-
-    X = df_final[model_list]
-
-    af = AffinityPropagation(preference=-50).fit(X)
-    cluster_center_indices=af.cluster_centers_indices_
-    labels = af.labels_
-    n_clusters_ = len(cluster_center_indices)
-
-    print('Estimated number of clusters: %d' % n_clusters_)
-    #print("Homogeneity: %0.3f" % metrics.homogeneity_score(labels_true, labels))
-    #print("Completeness: %0.3f" % metrics.completeness_score(labels_true, labels))
-    #print("V-measure: %0.3f" % metrics.v_measure_score(labels_true, labels))
-    #print("Adjusted Rand Index: %0.3f" % metrics.adjusted_rand_score(labels_true, labels))
-    #print("Adjusted Mutual Information: %0.3f" % metrics.adjusted_mutual_info_score(labels_true, labels))
-    print("Silhouette Coefficient: %0.3f" % metrics.silhouette_score(X, labels, metric='sqeuclidean'))
-
-    sns.scatterplot(data=X, x=model_list[0], y=model_list[1], hue=af, palette = "gnuplot")
-    plt.xlabel(model_list[1])
-    plt.ylabel(model_list[0])
-    title = "Clustering results of "
-    for i in range(len(model_list)):
-        title = title + model_list[i] + ","
-    title = title[0:len(title)-1]
-    plt.title(title)
+    for ml in model_list:
+        scaler.fit(df_final[[ml]])
+        df_final[[ml]] = scaler.transform(df_final[[ml]])
+
+    X = df_final[
+        model_list
+    ]  # going to need to find out how to do the correct number of clusters
+    sch.dendrogram(sch.linkage(X, method="ward"))
+    model = AgglomerativeClustering(n_clusters=5, affinity="euclidean", linkage="ward")
+    model.fit(X)
+    labels = model.labels_
+
+    plt.scatter(X[labels == 0, 0], X[labels == 0, 1], s=50, marker="o", color="red")
+    plt.scatter(X[labels == 1, 0], X[labels == 1, 1], s=50, marker="o", color="blue")
+    plt.scatter(X[labels == 2, 0], X[labels == 2, 1], s=50, marker="o", color="green")
+    plt.scatter(X[labels == 3, 0], X[labels == 3, 1], s=50, marker="o", color="purple")
+    plt.scatter(X[labels == 4, 0], X[labels == 4, 1], s=50, marker="o", color="orange")
     plt.show()
-    if (o is not None):
-        f = open(o, "a")
-        f.close()
+
+
 def opencsv(data):
     """saves a list of lists as a csv and opens"""
-    import tempfile
-    import os
-    import csv
-    handle, fn = tempfile.mkstemp(suffix='.csv')
-    with os.fdopen(handle,"w", encoding='utf8',errors='surrogateescape',newline='') as f:
+    handle, fn = tempfile.mkstemp(suffix=".csv")
+    with os.fdopen(
+        handle, "w", encoding="utf8", errors="surrogateescape", newline=""
+    ) as f:
         writer = csv.writer(f)
         writer.writerows(data)
     return fn
 
+
 # it can be used calling the script `python nidm_query.py -nl ... -q ..
 if __name__ == "__main__":
-    full_ap()
+    full_ac()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/nidm_agglomerative_clustering.py` & `pynidm-4.0.0/src/nidm/experiment/tools/nidm_affinity_propagation.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,63 +1,63 @@
+import csv
 import os
+import sys
 import tempfile
-import pandas as pd
-import csv
-from patsy.highlevel import dmatrices
-from nidm.experiment.Query import GetProjectsUUID
 import click
-from nidm.experiment.tools.click_base import cli
-from nidm.experiment.tools.rest import RestParser
-import numpy as np
 import matplotlib.pyplot as plt
+import pandas as pd
 import seaborn as sns
-from sklearn.cluster import AgglomerativeClustering
-import scipy.cluster.hierarchy as sch
-from sklearn.cluster import KMeans
-from sklearn.decomposition import PCA
-from sklearn.metrics import silhouette_score, adjusted_rand_score
-from sklearn.pipeline import Pipeline
-from sklearn.preprocessing import LabelEncoder, MinMaxScaler
+from sklearn import metrics, preprocessing
 from sklearn.cluster import AffinityPropagation
-from sklearn import metrics
-from sklearn import preprocessing
+from sklearn.preprocessing import MinMaxScaler
+from nidm.experiment.Query import GetProjectsUUID
+from nidm.experiment.tools.click_base import cli
+from nidm.experiment.tools.rest import RestParser
+from .utils import Reporter
+
 
 @cli.command()
-@click.option("--nidm_file_list", "-nl", required=True,
-              help="A comma separated list of NIDM files with full path")
-@click.option("-variables", required=False,
-                 help="This parameter is for the variables the user would like to complete the k-means algorithm on.\nThe way this looks in the command is python3 nidm_kmeans.py -nl MTdemog_aseg_v2.ttl -v \"fs_003343,age*sex,sex,age,group,age*group,bmi\"")
-@click.option("--output_file", "-o", required=False,
-              help="Optional output file (TXT) to store results of the linear regression, contrast, and regularization")
-def full_ac(nidm_file_list, output_file, variables):
+@click.option(
+    "--nidm_file_list",
+    "-nl",
+    required=True,
+    help="A comma separated list of NIDM files with full path",
+)
+@click.option(
+    "-variables",
+    required=False,
+    help='This parameter is for the variables the user would like to complete the k-means algorithm on.\nThe way this looks in the command is python3 nidm_kmeans.py -nl MTdemog_aseg_v2.ttl -v "fs_003343,age*sex,sex,age,group,age*group,bmi"',
+)
+@click.option(
+    "--output_file",
+    "-o",
+    required=False,
+    help="Optional output file (TXT) to store results of the linear regression, contrast, and regularization",
+)
+def full_ap(nidm_file_list, output_file, variables):
     global v  # Needed to do this because the code only used the parameters in the first method, meaning I had to move it all to method 1.
-    v = variables.strip()  # used in data_aggregation, linreg(), spaces stripped from left and right
-    global o  # used in dataparsing()
-    o = output_file
-    global n  # used in data_aggregation()
-    n = nidm_file_list
-    data_aggregation()
-    dataparsing()
-    ac()
+    v = (
+        variables.strip()
+    )  # used in data_aggregation, linreg(), spaces stripped from left and right
+    with Reporter(output_file) as reporter:
+        global n  # used in data_aggregation()
+        n = nidm_file_list
+        data_aggregation(reporter)
+        dataparsing(reporter)
+        ap()
 
 
-def data_aggregation():  # all data from all the files is collected
-    """    This function provides query support for NIDM graphs.   """
-    # query result list
-    results = []
+def data_aggregation(reporter):  # all data from all the files is collected
+    """This function provides query support for NIDM graphs."""
     # if there is a CDE file list, seed the CDE cache
     if v:  # ex: fs_00343 ~ age + sex + group
-        print("***********************************************************************************************************")
-        command = "python nidm_kmeans.py -nl " + n + " -variables \"" + v + "\" "
+        print("*" * 107)
+        command = "python nidm_kmeans.py -nl " + n + ' -variables "' + v + '" '
 
-        print("Your command was: " + command)
-        if (o is not None):
-            f = open(o, "w")
-            f.write("Your command was " + command)
-            f.close()
+        reporter.print("Your command was:", command)
         verbosity = 0
         restParser = RestParser(verbosity_level=int(verbosity))
         restParser.setOutputFormat(RestParser.OBJECT_FORMAT)
         global df_list  # used in dataparsing()
         df_list = []
         # set up uri to do fields query for each nidm file
         global file_list
@@ -75,244 +75,297 @@
         count = 0
         not_found_count = 0
         for nidm_file in file_list:
             # get project UUID
             project = GetProjectsUUID([nidm_file])
             # split the model into its constituent variables
             global full_model_variable_list
-            full_model_variable_list=[]
+            full_model_variable_list = []
             global model_list
-            model_list = v.split(",")
-            for i in range(len(model_list)):  # here, we remove any leading or trailing spaces
-                model_list[i] = model_list[i].strip()
-            global vars  # used in dataparsing()
-            vars = ""
+            model_list = [vv.strip() for vv in v.split(",")]
+            global variables  # used in dataparsing()
+            variables = ""
             for i in range(len(model_list) - 1, -1, -1):
-                full_model_variable_list.append(model_list[i])  # will be used in the regularization, but we need the full list
-                if "*" in model_list[i]:  # removing the star term from the columns we're about to pull from data
+                full_model_variable_list.append(
+                    model_list[i]
+                )  # will be used in the regularization, but we need the full list
+                if (
+                    "*" in model_list[i]
+                ):  # removing the star term from the columns we're about to pull from data
                     model_list.pop(i)
                 else:
-                    vars = vars + model_list[i] + ","
-            vars = vars[0:len(vars) - 1]
-            uri = "/projects/" + project[0].toPython().split("/")[-1] + "?fields=" + vars
+                    variables = variables + model_list[i] + ","
+            variables = variables[0 : len(variables) - 1]
+            uri = (
+                "/projects/"
+                + project[0].toPython().split("/")[-1]
+                + "?fields="
+                + variables
+            )
             # get fields output from each file and concatenate
             df_list_holder[count].append(pd.DataFrame(restParser.run([nidm_file], uri)))
             df = pd.concat(df_list_holder[count])
-            with tempfile.NamedTemporaryFile(delete=False) as temp:  # turns the dataframe into a temporary csv
-                df.to_csv(temp.name + '.csv')
+            with tempfile.NamedTemporaryFile(
+                delete=False
+            ) as temp:  # turns the dataframe into a temporary csv
+                df.to_csv(temp.name + ".csv")
                 temp.close()
-            data = list(csv.reader(open(temp.name + '.csv')))  # makes the csv a 2D list to make it easier to call the contents of certain cells
-            numcols = (len(data) - 1) // (len(model_list))  # Finds the number of columns in the original dataframe
-            global condensed_data  # also used in linreg()
-            condensed_data_holder[count] = [[0] * (len(model_list))]  # makes an array 1 row by the number of necessary columns
-            for i in range(numcols):  # makes the 2D array big enough to store all of the necessary values in the edited dataset
-                condensed_data_holder[count].append([0] * (len(model_list)))
-            for i in range(len(model_list)):  # stores the independent variable names in the first row
-                condensed_data_holder[count][0][i] = model_list[i]
+            with open(temp.name + ".csv", encoding="utf-8") as fp:
+                data = list(
+                    csv.reader(fp)
+                )  # makes the csv a 2D list to make it easier to call the contents of certain cells
+            numcols = (len(data) - 1) // (
+                len(model_list)
+            )  # Finds the number of columns in the original dataframe
+            condensed_data_holder[count] = [
+                [0] * (len(model_list))
+            ]  # makes an array 1 row by the number of necessary columns
+            for _ in range(
+                numcols
+            ):  # makes the 2D array big enough to store all of the necessary values in the edited dataset
+                condensed_data_holder[count].append([0] * len(model_list))
+            for i, ml in enumerate(model_list):
+                # stores the independent variable names in the first row
+                condensed_data_holder[count][0][i] = ml
             numrows = 1  # begins at the first row to add data
-            fieldcolumn = 0  # the column the variable name is in in the original dataset
+            fieldcolumn = (
+                0  # the column the variable name is in in the original dataset
+            )
             valuecolumn = 0  # the column the value is in in the original dataset
             datacolumn = 0  # if it is identified by the dataElement name instead of the field's name
             not_found_list = []
             for i in range(len(data[0])):
-                if data[0][i] == 'sourceVariable':  # finds the column where the variable names are
+                if (
+                    data[0][i] == "sourceVariable"
+                ):  # finds the column where the variable names are
                     fieldcolumn = i
-                elif data[0][i] == 'source_variable':  # finds the column where the variable names are
+                elif (
+                    data[0][i] == "source_variable"
+                ):  # finds the column where the variable names are
                     fieldcolumn = i
-                elif data[0][i] == 'isAbout':
+                elif data[0][i] == "isAbout":
                     aboutcolumn = i
-                elif data[0][i] == 'label':
+                elif data[0][i] == "label":
                     namecolumn = i  # finds the column where the variable names are
-                elif data[0][i] == 'value':
+                elif data[0][i] == "value":
                     valuecolumn = i  # finds the column where the values are
-                elif data[0][i] == 'dataElement':  # finds the column where the data element is if necessary
+                elif (
+                    data[0][i] == "dataElement"
+                ):  # finds the column where the data element is if necessary
                     datacolumn = i
             for i in range(
-                    len(condensed_data_holder[count][
-                            0])):  # starts iterating through the dataset, looking for the name in that
-                for j in range(1, len(data)):  # column, so it can append the values under the proper variables
+                len(condensed_data_holder[count][0])
+            ):  # starts iterating through the dataset, looking for the name in that
+                for j in range(
+                    1, len(data)
+                ):  # column, so it can append the values under the proper variables
                     try:
                         split_url = condensed_data_holder[count][0][i].split("/")
-                        if data[j][fieldcolumn] == condensed_data_holder[count][0][
-                            i]:  # in the dataframe, the name is in column 3
+                        if (
+                            data[j][fieldcolumn] == condensed_data_holder[count][0][i]
+                        ):  # in the dataframe, the name is in column 3
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][aboutcolumn] == condensed_data_holder[count][0][
-                            i]:
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif data[j][aboutcolumn] == condensed_data_holder[count][0][i]:
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][aboutcolumn] == split_url[
-                            len(split_url) - 1]:  # this is in case the uri only works by querying the part after the last backslash
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            data[j][aboutcolumn] == split_url[len(split_url) - 1]
+                        ):  # this is in case the uri only works by querying the part after the last backslash
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-
-                        elif data[j][namecolumn] == condensed_data_holder[count][0][
-                            i]:  # in the dataframe, the name is in column 12
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+
+                        elif (
+                            data[j][namecolumn] == condensed_data_holder[count][0][i]
+                        ):  # in the dataframe, the name is in column 12
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif condensed_data_holder[count][0][i] == data[j][
-                            datacolumn]:  # in the dataframe, the name is in column 9
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            condensed_data_holder[count][0][i] == data[j][datacolumn]
+                        ):  # in the dataframe, the name is in column 9
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
                     except IndexError:
                         numrows = numrows + 1
                 numrows = 1  # resets to the first row for the next variable
             temp_list = condensed_data_holder[count]
-            for j in range(len(temp_list[0]) - 1, 0,-1):  # if the software appends a column with 0 as the heading, it removes this null column
+            for j in range(
+                len(temp_list[0]) - 1, 0, -1
+            ):  # if the software appends a column with 0 as the heading, it removes this null column
                 if temp_list[0][j] == "0" or temp_list[0][j] == "NaN":
                     for row in condensed_data_holder[count]:
                         row.pop(j)
             rowsize = len(condensed_data_holder[count][0])
             count1 = 0
             for i in range(0, rowsize):
                 for row in condensed_data_holder[count]:
                     if row[i] == 0 or row[i] == "NaN" or row[i] == "0":
                         count1 = count1 + 1
                 if count1 > len(condensed_data_holder[count]) - 2:
                     not_found_list.append(condensed_data_holder[count][0][i])
                 count1 = 0
-            for i in range(len(condensed_data_holder[count][0])):
-                if " " in condensed_data_holder[count][0][i]:
-                    condensed_data_holder[count][0][i] = condensed_data_holder[count][0][i].replace(" ", "_")
-            for i in range(len(vars)):
-                if " " in vars[i]:
-                    vars[i] = vars[i].replace(" ", "_")
+            for i, cdh in enumerate(condensed_data_holder[count][0]):
+                condensed_data_holder[count][0][i] = cdh.replace(" ", "_")
+            for i, vrb in enumerate(variables):
+                variables[i] = vrb.replace(" ", "_")
             count = count + 1
             if len(not_found_list) > 0:
-                print(
-                        "***********************************************************************************************************")
-                print()
-                print("Your variables were " + v)
+                print("*" * 107)
                 print()
-                print(
-                        "The following variables were not found in " + nidm_file + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables.")
-                if (o is not None):
-                    f = open(o, "a")
-                    f.write("Your variables were " + v)
-                    f.write(
-                            "The following variables were not found in " + nidm_file + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables.")
-                    f.close()
-                for i in range(0, len(not_found_list)):
-                    print(str(i + 1) + ". " + not_found_list[i])
-                    if (o is not None):
-                        f = open(o, "a")
-                        f.write(str(i + 1) + ". " + not_found_list[i])
-                        f.close()
-                for j in range(len(not_found_list) - 1, 0, -1):
-                    not_found_list.pop(j)
-                not_found_count = not_found_count + 1
+                reporter.print("Your variables were", v)
+                reporter.print()
+                reporter.print(
+                    "The following variables were not found in "
+                    + nidm_file
+                    + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables."
+                )
+                for i, nf in enumerate(not_found_list):
+                    reporter.print(f"{i+1}. {nf}")
+                not_found_list.clear()
+                not_found_count += 1
                 print()
         if not_found_count > 0:
-            exit(1)
-
+            sys.exit(1)
 
     else:
         print("ERROR: No query parameter provided.  See help:")
         print()
         os.system("pynidm query --help")
-        exit(1)
+        sys.exit(1)
+
 
-def dataparsing(): #The data is changed to a format that is usable by the linear regression method
+def dataparsing(
+    reporter,
+):  # The data is changed to a format that is usable by the linear regression method
     global condensed_data
     condensed_data = []
     for i in range(0, len(file_list)):
         condensed_data = condensed_data + condensed_data_holder[i]
-    x = pd.read_csv(opencsv(condensed_data))  # changes the dataframe to a csv to make it easier to work with
+    x = pd.read_csv(
+        opencsv(condensed_data)
+    )  # changes the dataframe to a csv to make it easier to work with
     x.head()  # prints what the csv looks like
     x.dtypes  # checks data format
     obj_df = x.select_dtypes  # puts all the variables in a dataset
     x.shape  # says number of rows and columns in form of tuple
     x.describe()  # says dataset statistics
     obj_df = x.select_dtypes(
-        include=['object']).copy()  # takes everything that is an object (not float or int) and puts it in a new dataset
+        include=["object"]
+    ).copy()  # takes everything that is an object (not float or int) and puts it in a new dataset
     obj_df.head()  # prints the new dataset
-    int_df = x.select_dtypes(include=['int64']).copy()  # takes everything that is an int and puts it in a new dataset
+    int_df = x.select_dtypes(
+        include=["int64"]
+    ).copy()  # takes everything that is an int and puts it in a new dataset
     float_df = x.select_dtypes(
-        include=['float64']).copy()  # takes everything that is a float and puts it in a new dataset
+        include=["float64"]
+    ).copy()  # takes everything that is a float and puts it in a new dataset
     df_int_float = pd.concat([float_df, int_df], axis=1)
     stringvars = []  # starts a list that will store all variables that are not numbers
     for i in range(1, len(condensed_data)):  # goes through each variable
         for j in range(len(condensed_data[0])):  # in the 2D array
             try:  # if the value of the field can be turned into a float (is numerical)
                 float(condensed_data[i][j])  # this means it's a number
             except ValueError:  # if it can't be (is a string)
-                if condensed_data[0][
-                    j] not in stringvars:  # adds the variable name to the list if it isn't there already
+                if (
+                    condensed_data[0][j] not in stringvars
+                ):  # adds the variable name to the list if it isn't there already
                     stringvars.append(condensed_data[0][j])
-    le = preprocessing.LabelEncoder()  # anything involving le shows the encoding of categorical variables
-    for i in range(len(stringvars)):
-        le.fit(obj_df[stringvars[i]].astype(str))
-    obj_df_trf = obj_df.astype(str).apply(le.fit_transform)  # transforms the categorical variables into numbers.
+    le = (
+        preprocessing.LabelEncoder()
+    )  # anything involving le shows the encoding of categorical variables
+    for sv in stringvars:
+        le.fit(obj_df[sv].astype(str))
+    obj_df_trf = obj_df.astype(str).apply(
+        le.fit_transform
+    )  # transforms the categorical variables into numbers.
     global df_final  # also used in linreg()
     if not obj_df_trf.empty:
-        df_final = pd.concat([df_int_float, obj_df_trf], axis=1)  # join_axes=[df_int_float.index])
+        df_final = pd.concat(
+            [df_int_float, obj_df_trf], axis=1
+        )  # join_axes=[df_int_float.index])
     else:
         df_final = df_int_float
-    df_final.head()  # shows the final dataset with all the encoding
-    print(df_final)  # prints the final dataset
-    print()
-    print("***********************************************************************************************************")
-    print()
-    if (o is not None):
-        f = open(o, "a")
-        f.write(df_final.to_string(header=True, index=True))
-        f.write(
-            "\n\n***********************************************************************************************************")
-        f.write("\n\nModel Results: ")
-        f.close()
-def ac():
+    reporter.print(df_final.to_string(header=True, index=True))
+    reporter.print("\n\n" + ("*" * 107))
+    reporter.print("\n\nModel Results: ")
+
+
+def ap():
     index = 0
     global levels  # also used in contrasting()
     levels = []
     for i in range(1, len(condensed_data)):
         if condensed_data[i][index] not in levels:
             levels.append(condensed_data[i][index])
-    for i in range(len(levels)):
-        levels[i] = i
+    levels = list(range(len(levels)))
 
     # Beginning of the linear regression
     global X
-    #global y
-    #Unsure on how to procede here with interacting variables, since I'm sure dmatrices won't work
+    # global y
+    # Unsure on how to proceed here with interacting variables, since I'm sure dmatrices won't work
 
     scaler = MinMaxScaler()
 
-    for i in range(len(model_list)):
-        scaler.fit(df_final[[model_list[i]]])
-        df_final[[model_list[i]]] = scaler.transform(df_final[[model_list[i]]])
-
-    X = df_final[model_list] #going to need to find out how to do the correct number of clusters
-    dendrogram = sch.dendrogram(sch.linkage(X, method='ward'))
-    model = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')
-    model.fit(X)
-    labels = model.labels_
-
-    plt.scatter(X[labels == 0, 0], X[labels == 0, 1], s=50, marker='o', color='red')
-    plt.scatter(X[labels == 1, 0], X[labels == 1, 1], s=50, marker='o', color='blue')
-    plt.scatter(X[labels == 2, 0], X[labels == 2, 1], s=50, marker='o', color='green')
-    plt.scatter(X[labels == 3, 0], X[labels == 3, 1], s=50, marker='o', color='purple')
-    plt.scatter(X[labels == 4, 0], X[labels == 4, 1], s=50, marker='o', color='orange')
+    for ml in model_list:
+        scaler.fit(df_final[[ml]])
+        df_final[[ml]] = scaler.transform(df_final[[ml]])
+
+    X = df_final[model_list]
+
+    af = AffinityPropagation(preference=-50).fit(X)
+    cluster_center_indices = af.cluster_centers_indices_
+    labels = af.labels_
+    n_clusters_ = len(cluster_center_indices)
+
+    print(f"Estimated number of clusters: {n_clusters_}")
+    # print("Homogeneity: %0.3f" % metrics.homogeneity_score(labels_true, labels))
+    # print("Completeness: %0.3f" % metrics.completeness_score(labels_true, labels))
+    # print("V-measure: %0.3f" % metrics.v_measure_score(labels_true, labels))
+    # print("Adjusted Rand Index: %0.3f" % metrics.adjusted_rand_score(labels_true, labels))
+    # print("Adjusted Mutual Information: %0.3f" % metrics.adjusted_mutual_info_score(labels_true, labels))
+    print(
+        "Silhouette Coefficient: %0.3f"
+        % metrics.silhouette_score(X, labels, metric="sqeuclidean")
+    )
+
+    sns.scatterplot(data=X, x=model_list[0], y=model_list[1], hue=af, palette="gnuplot")
+    plt.xlabel(model_list[1])
+    plt.ylabel(model_list[0])
+    title = "Clustering results of " + ",".join(model_list)
+    plt.title(title)
     plt.show()
 
-    
-    if (o is not None):
-        f = open(o, "a")
-        f.close()
+
 def opencsv(data):
     """saves a list of lists as a csv and opens"""
-    import tempfile
-    import os
-    import csv
-    handle, fn = tempfile.mkstemp(suffix='.csv')
-    with os.fdopen(handle,"w", encoding='utf8',errors='surrogateescape',newline='') as f:
+    handle, fn = tempfile.mkstemp(suffix=".csv")
+    with os.fdopen(
+        handle, "w", encoding="utf8", errors="surrogateescape", newline=""
+    ) as f:
         writer = csv.writer(f)
         writer.writerows(data)
     return fn
 
+
 # it can be used calling the script `python nidm_query.py -nl ... -q ..
 if __name__ == "__main__":
-    full_ac()
+    full_ap()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/nidm_gmm.py` & `pynidm-4.0.0/src/nidm/experiment/tools/nidm_kmeans.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,67 +1,100 @@
+import csv
 import os
+import sys
 import tempfile
+import warnings
+import click
+import matplotlib.pyplot as plt
+import numpy as np
 import pandas as pd
-import csv
+from sklearn import preprocessing
+from sklearn.cluster import KMeans
+from sklearn.decomposition import PCA
+from sklearn.metrics import (
+    calinski_harabaz_score,
+    davies_bouldin_score,
+    silhouette_score,
+)
 from nidm.experiment.Query import GetProjectsUUID
-import click
 from nidm.experiment.tools.click_base import cli
 from nidm.experiment.tools.rest import RestParser
-import numpy as np
-import matplotlib.pyplot as plt
-from sklearn.metrics import silhouette_score
-from sklearn.mixture import GaussianMixture
-from sklearn.preprocessing import LabelEncoder, MinMaxScaler
-from sklearn import preprocessing
+from .utils import Reporter
+
 
 @cli.command()
-@click.option("--nidm_file_list", "-nl", required=True,
-              help="A comma separated list of NIDM files with full path")
-@click.option("--var","-variables", required=True,
-                 help="This parameter is for the variables the user would like to complete the k-means algorithm on.\nThe way this looks in the command is python3 nidm_kmeans.py -nl MTdemog_aseg_v2.ttl -v \"fs_003343,age*sex,sex,age,group,age*group,bmi\"")
-@click.option("--k_range", "-k", required=True,
-              help="The maxiumum number of clusters to try. The algorithm will go from 2 to this number to determine the optimal number of clusters.")
-@click.option("--optimal_cluster_method", "-m", required=True,
-              help="The criterion used to select the optimal partitioning (either Silhouette Score, AIC, or BIC).")
-@click.option("--output_file", "-o", required=False,
-              help="Optional output file (TXT) to store results of the linear regression, contrast, and regularization")
-def gmm(nidm_file_list, output_file, var, k_range, optimal_cluster_method):
+@click.option(
+    "--nidm_file_list",
+    "-nl",
+    required=True,
+    help="A comma separated list of NIDM files with full path",
+)
+@click.option(
+    "--var",
+    "-variables",
+    required=True,
+    help='This parameter is for the variables the user would like to complete the k-means algorithm on.\nThe way this looks in the command is python3 nidm_kmeans.py -nl MTdemog_aseg_v2.ttl -v "fs_003343,age*sex,sex,age,group,age*group,bmi"',
+)
+@click.option(
+    "--k_range",
+    "-k",
+    required=True,
+    help="The maximum number of clusters to try. The algorithm will go from 2 to this number to determine the optimal number of clusters.",
+)
+@click.option(
+    "--optimal_cluster_method",
+    "-m",
+    required=True,
+    help="The criterion used to select the optimal partitioning (either Gap Statistic, Elbow Method, Silhouette Coefficient, Calinski-Harabasz Index, or Davies_Bouldin Index).",
+)
+@click.option(
+    "--output_file",
+    "-o",
+    required=False,
+    help="Optional output file (TXT) to store results of the linear regression, contrast, and regularization",
+)
+def k_means(nidm_file_list, output_file, var, k_range, optimal_cluster_method):
+    """
+    This function provides a tool to complete k-means clustering on NIDM data.
     """
-            This function provides a tool to complete k-means clustering on NIDM data.
-            """
     global v  # Needed to do this because the code only used the parameters in the first method, meaning I had to move it all to method 1.
-    v = var.strip()  # used in data_aggregation, kmenas(), spaces stripped from left and right
-    global o  # used in dataparsing()
-    o = output_file
-    global n  # used in data_aggregation()
-    n = nidm_file_list
-    global k_num
-    k_num = int(k_range.strip())
-    global cm
-    cm = optimal_cluster_method
-    data_aggregation()
-    dataparsing()
-    cluster_number()
+    v = (
+        var.strip()
+    )  # used in data_aggregation, kmenas(), spaces stripped from left and right
+    with Reporter(output_file) as reporter:
+        global n  # used in data_aggregation()
+        n = nidm_file_list
+        global k_num
+        k_num = int(k_range)
+        global cm
+        cm = optimal_cluster_method
+        data_aggregation(reporter)
+        dataparsing(reporter)
+        cluster_number()
 
 
-def data_aggregation():  # all data from all the files is collected
-    """    This function provides query support for NIDM graphs.   """
-    # query result list
-    results = []
+def data_aggregation(reporter):  # all data from all the files is collected
+    """This function provides query support for NIDM graphs."""
     # if there is a CDE file list, seed the CDE cache
-    if v:  #ex: age,sex,DX_GROUP
-        print("***********************************************************************************************************")
-        command = "pynidm k-means -nl " + n + " -variables \"" + v + "\" " + "-k " + str(k_num) + " -m " + cm
-
-        print("Your command was: " + command)
-        if (o is not None):
-            f = open(o, "w")
-            f.write("Your command was " + command)
-            f.close()
-        verbosity=0
+    if v:  # ex: age,sex,DX_GROUP
+        print("*" * 107)
+        command = (
+            "pynidm k-means -nl "
+            + n
+            + ' -variables "'
+            + v
+            + '" '
+            + "-k "
+            + str(k_num)
+            + " -m "
+            + cm
+        )
+
+        reporter.print("Your command was:", command)
+        verbosity = 0
         restParser = RestParser(verbosity_level=int(verbosity))
         restParser.setOutputFormat(RestParser.OBJECT_FORMAT)
         global df_list  # used in dataparsing()
         df_list = []
         # set up uri to do fields query for each nidm file
         global file_list
         file_list = n.split(",")
@@ -81,384 +114,506 @@
         for nidm_file in file_list:
             # get project UUID
             project = GetProjectsUUID([nidm_file])
             # split the model into its constituent variables
             global var_list
             # below, we edit the model so it splits by +,~, or =. However, to help it out in catching everything
             # we replaced ~ and = with a + so that we can still use split. Regex wasn't working.
-            var_list = v.split(",")
-            for i in range(len(var_list)):  # here, we remove any leading or trailing spaces
-                var_list[i] = var_list[i].strip()
+            var_list = [vv.strip() for vv in v.split(",")]
             # set the dependent variable to the one dependent variable in the model
-            global vars  # used in dataparsing()
-            vars = ""
-            for i in range(len(var_list) - 1, -1, -1):
-                if not "*" in var_list[i]:  # removing the star term from the columns we're about to pull from data
-                    vars = vars + var_list[i] + ","
+            global variables  # used in dataparsing()
+            variables = ""
+            for vr in reversed(var_list):
+                if (
+                    "*" not in vr
+                ):  # removing the star term from the columns we're about to pull from data
+                    variables += vr + ","
                 else:
-                    print("Interacting variables are not present in clustering models. They will be removed.")
-            vars = vars[0:len(vars) - 1]
-            uri = "/projects/" + project[0].toPython().split("/")[-1] + "?fields=" + vars
+                    print(
+                        "Interacting variables are not present in clustering models. They will be removed."
+                    )
+            variables = variables[:-1]
+            uri = (
+                "/projects/"
+                + project[0].toPython().split("/")[-1]
+                + "?fields="
+                + variables
+            )
             # get fields output from each file and concatenate
             df_list_holder[count].append(pd.DataFrame(restParser.run([nidm_file], uri)))
             # global dep_var
             df = pd.concat(df_list_holder[count])
-            with tempfile.NamedTemporaryFile(delete=False) as temp:  # turns the dataframe into a temporary csv
-                df.to_csv(temp.name + '.csv')
+            with tempfile.NamedTemporaryFile(
+                delete=False
+            ) as temp:  # turns the dataframe into a temporary csv
+                df.to_csv(temp.name + ".csv")
                 temp.close()
-            data = list(csv.reader(open(
-                temp.name + '.csv')))  # makes the csv a 2D list to make it easier to call the contents of certain cells
+            with open(temp.name + ".csv", encoding="utf-8") as fp:
+                data = list(
+                    csv.reader(fp)
+                )  # makes the csv a 2D list to make it easier to call the contents of certain cells
 
-            var_list = vars.split(",")  # makes a list of the independent variables
+            var_list = variables.split(",")  # makes a list of the independent variables
             numcols = (len(data) - 1) // (
-                    len(var_list))  # Finds the number of columns in the original dataframe
-            global condensed_data  # also used in linreg()
+                len(var_list)
+            )  # Finds the number of columns in the original dataframe
             condensed_data_holder[count] = [
-                [0] * (len(var_list))]  # makes an array 1 row by the number of necessary columns
-            for i in range(
-                    numcols):  # makes the 2D array big enough to store all of the necessary values in the edited dataset
+                [0] * (len(var_list))
+            ]  # makes an array 1 row by the number of necessary columns
+            for _ in range(
+                numcols
+            ):  # makes the 2D array big enough to store all of the necessary values in the edited dataset
                 condensed_data_holder[count].append([0] * (len(var_list)))
-            for m in range(0, len(var_list)):
-                end_url = var_list[m].split("/")
-                if "/" in var_list[m]:
-                    var_list[m] = end_url[len(end_url) - 1]
-            for i in range(len(var_list)):  # stores the independent variable names in the first row
-                condensed_data_holder[count][0][i] = var_list[i]
+            var_list = [vr.split("/")[-1] for vr in var_list]
+            for i, vr in enumerate(var_list):
+                # stores the independent variable names in the first row
+                condensed_data_holder[count][0][i] = vr
             numrows = 1  # begins at the first row to add data
-            fieldcolumn = 0  # the column the variable name is in in the original dataset
+            fieldcolumn = (
+                0  # the column the variable name is in in the original dataset
+            )
             valuecolumn = 0  # the column the value is in in the original dataset
             datacolumn = 0  # if it is identified by the dataElement name instead of the field's name
             not_found_list = []
             for i in range(len(data[0])):
-                if data[0][i] == 'sourceVariable':  # finds the column where the variable names are
+                if (
+                    data[0][i] == "sourceVariable"
+                ):  # finds the column where the variable names are
                     fieldcolumn = i
-                elif data[0][i] == 'source_variable':  # finds the column where the variable names are
+                elif (
+                    data[0][i] == "source_variable"
+                ):  # finds the column where the variable names are
                     fieldcolumn = i
-                elif data[0][i] == 'isAbout':
+                elif data[0][i] == "isAbout":
                     aboutcolumn = i
-                elif data[0][i] == 'label':
+                elif data[0][i] == "label":
                     namecolumn = i  # finds the column where the variable names are
-                elif data[0][i] == 'value':
+                elif data[0][i] == "value":
                     valuecolumn = i  # finds the column where the values are
-                elif data[0][i] == 'dataElement':  # finds the column where the data element is if necessary
+                elif (
+                    data[0][i] == "dataElement"
+                ):  # finds the column where the data element is if necessary
                     datacolumn = i
             for i in range(
-                    len(condensed_data_holder[count][
-                            0])):  # starts iterating through the dataset, looking for the name in that
-                for j in range(1, len(data)):  # column, so it can append the values under the proper variables
+                len(condensed_data_holder[count][0])
+            ):  # starts iterating through the dataset, looking for the name in that
+                for j in range(
+                    1, len(data)
+                ):  # column, so it can append the values under the proper variables
                     try:
-                        if data[j][fieldcolumn] == condensed_data_holder[count][0][
-                            i]:  # in the dataframe, the name is in column 3
+                        if (
+                            data[j][fieldcolumn] == condensed_data_holder[count][0][i]
+                        ):  # in the dataframe, the name is in column 3
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][aboutcolumn] == condensed_data_holder[count][0][
-                            i]:
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif data[j][aboutcolumn] == condensed_data_holder[count][0][i]:
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif condensed_data_holder[count][0][
-                            i] in data[j][
-                            aboutcolumn]:  # this is in case the uri only works by querying the part after the last backslash
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            condensed_data_holder[count][0][i] in data[j][aboutcolumn]
+                        ):  # this is in case the uri only works by querying the part after the last backslash
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][namecolumn] == condensed_data_holder[count][0][
-                            i]:  # in the dataframe, the name is in column 12
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            data[j][namecolumn] == condensed_data_holder[count][0][i]
+                        ):  # in the dataframe, the name is in column 12
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif condensed_data_holder[count][0][i] == data[j][
-                            datacolumn]:  # in the dataframe, the name is in column 9
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            condensed_data_holder[count][0][i] == data[j][datacolumn]
+                        ):  # in the dataframe, the name is in column 9
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
                     except IndexError:
                         numrows = numrows + 1
                 numrows = 1  # resets to the first row for the next variable
             temp_list = condensed_data_holder[count]
-            for j in range(len(temp_list[0]) - 1, 0,
-                           -1):  # if the software appends a column with 0 as the heading, it removes this null column
+            for j in range(
+                len(temp_list[0]) - 1, 0, -1
+            ):  # if the software appends a column with 0 as the heading, it removes this null column
                 if temp_list[0][j] == "0" or temp_list[0][j] == "NaN":
                     for row in condensed_data_holder[count]:
                         row.pop(j)
             rowsize = len(condensed_data_holder[count][0])
             count1 = 0
             for i in range(0, rowsize):
                 for row in condensed_data_holder[count]:
                     if row[i] == 0 or row[i] == "NaN" or row[i] == "0":
                         count1 = count1 + 1
                 if count1 > len(condensed_data_holder[count]) - 2:
                     not_found_list.append(condensed_data_holder[count][0][i])
                 count1 = 0
-            for i in range(len(condensed_data_holder[count][0])):
-                if " " in condensed_data_holder[count][0][i]:
-                    condensed_data_holder[count][0][i] = condensed_data_holder[count][0][i].replace(" ", "_")
-            for i in range(len(var_list)):
-                if "/" in var_list[i]:
-                    splitted = var_list[i].split("/")
-                    var_list[i] = splitted[len(splitted) - 1]
-                if " " in var_list[i]:
-                    var_list[i] = var_list[i].replace(" ", "_")
-            count = count + 1
+            for i, cdh in enumerate(condensed_data_holder[count][0]):
+                if " " in cdh:
+                    condensed_data_holder[count][0][i] = cdh.replace(" ", "_")
+            var_list = [vr.split("/")[-1].replace(" ", "_") for vr in var_list]
+            count += 1
             if len(not_found_list) > 0:
-                print(
-                    "***********************************************************************************************************")
-                print()
-                print("Your variables were " + v)
+                print("*" * 107)
                 print()
-                print(
-                    "The following variables were not found in " + nidm_file + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables.")
-                if (o is not None):
-                    f = open(o, "a")
-                    f.write("Your variables were " + v)
-                    f.write(
-                        "The following variables were not found in " + nidm_file + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables.")
-                    f.close()
-                for i in range(0, len(not_found_list)):
-                    print(str(i + 1) + ". " + not_found_list[i])
-                    if (o is not None):
-                        f = open(o, "a")
-                        f.write(str(i + 1) + ". " + not_found_list[i])
-                        f.close()
-                for j in range(len(not_found_list) - 1, 0, -1):
-                    not_found_list.pop(j)
-                not_found_count = not_found_count + 1
+                reporter.print("Your variables were", v)
+                reporter.print()
+                reporter.print(
+                    "The following variables were not found in "
+                    + nidm_file
+                    + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables."
+                )
+                for i, nf in enumerate(not_found_list):
+                    reporter.print(f"{i+1}. {nf}")
+                not_found_list.clear()
+                not_found_count += 1
                 print()
         if not_found_count > 0:
-            exit(1)
-
+            sys.exit(1)
 
     else:
         print("ERROR: No query parameter provided.  See help:")
         print()
         os.system("pynidm k-means --help")
-        exit(1)
+        sys.exit(1)
+
 
-def dataparsing(): #The data is changed to a format that is usable by the linear regression method
+def dataparsing(
+    reporter,
+):  # The data is changed to a format that is usable by the linear regression method
     global condensed_data
     condensed_data = []
     for i in range(0, len(file_list)):
-        condensed_data = condensed_data + condensed_data_holder[i]
+        condensed_data += condensed_data_holder[i]
     global k_num
-    if len(condensed_data[0])<=k_num:
-        print("\nThe maximum number of clusters specified is greater than the amount of data present.")
-        print("The algorithm cannot run with this, so k_num will be reduced to 1 less than the length of the dataset.")
-        k_num = len(condensed_data) -1
-        print("The k_num value is now: " + str(k_num))
-    x = pd.read_csv(opencsv(condensed_data))  # changes the dataframe to a csv to make it easier to work with
+    if len(condensed_data[0]) <= k_num:
+        print(
+            "\nThe maximum number of clusters specified is greater than the amount of data present."
+        )
+        print(
+            "The algorithm cannot run with this, so k_num will be reduced to 1 less than the length of the dataset."
+        )
+        k_num = len(condensed_data) - 1
+        print("The k_num value is now:", k_num)
+    x = pd.read_csv(
+        opencsv(condensed_data)
+    )  # changes the dataframe to a csv to make it easier to work with
     x.head()  # prints what the csv looks like
     x.dtypes  # checks data format
     obj_df = x.select_dtypes  # puts all the variables in a dataset
     x.shape  # says number of rows and columns in form of tuple
     x.describe()  # says dataset statistics
     obj_df = x.select_dtypes(
-        include=['object']).copy()  # takes everything that is an object (not float or int) and puts it in a new dataset
+        include=["object"]
+    ).copy()  # takes everything that is an object (not float or int) and puts it in a new dataset
     obj_df.head()  # prints the new dataset
-    int_df = x.select_dtypes(include=['int64']).copy()  # takes everything that is an int and puts it in a new dataset
+    int_df = x.select_dtypes(
+        include=["int64"]
+    ).copy()  # takes everything that is an int and puts it in a new dataset
     float_df = x.select_dtypes(
-        include=['float64']).copy()  # takes everything that is a float and puts it in a new dataset
+        include=["float64"]
+    ).copy()  # takes everything that is a float and puts it in a new dataset
     df_int_float = pd.concat([float_df, int_df], axis=1)
     stringvars = []  # starts a list that will store all variables that are not numbers
     for i in range(1, len(condensed_data)):  # goes through each variable
         for j in range(len(condensed_data[0])):  # in the 2D array
             try:  # if the value of the field can be turned into a float (is numerical)
                 float(condensed_data[i][j])  # this means it's a number
             except ValueError:  # if it can't be (is a string)
-                if condensed_data[0][
-                    j] not in stringvars:  # adds the variable name to the list if it isn't there already
+                if (
+                    condensed_data[0][j] not in stringvars
+                ):  # adds the variable name to the list if it isn't there already
                     stringvars.append(condensed_data[0][j])
-    le = preprocessing.LabelEncoder()  # anything involving le shows the encoding of categorical variables
-    for i in range(len(stringvars)):
-        le.fit(obj_df[stringvars[i]].astype(str))
-    obj_df_trf = obj_df.astype(str).apply(le.fit_transform)  # transforms the categorical variables into numbers.
+    le = (
+        preprocessing.LabelEncoder()
+    )  # anything involving le shows the encoding of categorical variables
+    for sv in stringvars:
+        le.fit(obj_df[sv].astype(str))
+    obj_df_trf = obj_df.astype(str).apply(
+        le.fit_transform
+    )  # transforms the categorical variables into numbers.
     global df_final  # also used in linreg()
     if not obj_df_trf.empty:
-        df_final = pd.concat([df_int_float, obj_df_trf], axis=1)  # join_axes=[df_int_float.index])
+        df_final = pd.concat(
+            [df_int_float, obj_df_trf], axis=1
+        )  # join_axes=[df_int_float.index])
     else:
         df_final = df_int_float
-    df_final.head()  # shows the final dataset with all the encoding
-    print(df_final)  # prints the final dataset
-    print()
-    print("***********************************************************************************************************")
-    print()
-    if (o is not None):
-        f = open(o, "a")
-        f.write(df_final.to_string(header=True, index=True))
-        f.write(
-            "\n\n***********************************************************************************************************")
-        f.write("\n\nModel Results: ")
-        f.close()
+    reporter.print(df_final.to_string(header=True, index=True))
+    reporter.print("\n" + ("*" * 107))
+    reporter.print("\nModel Results: ")
+
+
 def cluster_number():
     index = 0
     global levels  # also used in contrasting()
     levels = []
     for i in range(1, len(condensed_data)):
         if condensed_data[i][index] not in levels:
             levels.append(condensed_data[i][index])
-    for i in range(len(levels)):
-        levels[i] = i
+    levels = list(range(len(levels)))
 
     # Beginning of the linear regression
     global X
-    #global y
-    #Unsure on how to procede here with interacting variables, since I'm sure dmatrices won't work
-
-    """scaler = MinMaxScaler()
+    # global y
+    # Unsure on how to proceed here with interacting variables, since I'm sure dmatrices won't work
 
-    for i in range(len(model_list)):
-        scaler.fit(df_final[[model_list[i]]])
-        df_final[[model_list[i]]] = scaler.transform(df_final[[model_list[i]]])"""
+    # scaler = MinMaxScaler()
+    #
+    # for i in range(len(model_list)):
+    #     scaler.fit(df_final[[model_list[i]]])
+    #     df_final[[model_list[i]]] = scaler.transform(df_final[[model_list[i]]])
     X = df_final[var_list]
-    if "si" in cm.lower():
-        print("Sillhoute Score")
+    if "ga" in cm.lower():
+        print("\n\nGap Statistic")
+        gaps = np.zeros((len(range(2, int(k_num)))))
+        global resulting_df
+        resulting_df = pd.DataFrame({"clusterCount": [], "gap": []})
+        global gap_index, k
+        for gap_index, k in enumerate(range(2, int(k_num))):
+            dispersion_results = np.zeros(3)  # make three random datasets
+            for i in range(3):
+                random_reference = np.random.random_sample(size=df_final.shape)
+                km = KMeans(k)
+                km.fit(random_reference)
+                dispersion_results[i] = km.inertia_
+            km = KMeans(k)
+            km.fit(df_final)
+
+            original_sse = km.inertia_
+            global gap
+            gap = np.log(np.mean(dispersion_results)) - np.log(original_sse)
 
-        ss = []
-
-        for i in range(2, k_num):
-            model = GaussianMixture(n_components=i, init_params='kmeans')
-            cluster_labels = model.fit_predict(X)
-            silhouette_avg = silhouette_score(X, cluster_labels)
-            ss.append(silhouette_avg)
+            gaps[gap_index] = gap
+        max_gap = gaps[0]
         optimal_i = 0
-        distance_to_one = abs(1-ss[0])
-        for i in range(0,len(ss)):
-            if abs(1-ss[i]) <= distance_to_one:
+        for i in range(1, len(gaps)):
+            if gaps[i] > max_gap:
                 optimal_i = i
-                distance_to_one = abs(1-ss[i])
-
-        n_clusters = optimal_i + 2
-        print("Optimal number of clusters: " + str(n_clusters)) #optimal number of clusters
-        gmm = GaussianMixture(n_components=n_clusters).fit(X)
-        labels = gmm.fit(X).predict(X)
+                max_gap = gaps[i]
+        optimal_cluster = optimal_i + 2
+        print(
+            "Optimal number of clusters: " + str(optimal_cluster)
+        )  # the optimal number of clusters for gap statistic
+        km = KMeans(
+            n_clusters=optimal_cluster,
+            init="k-means++",
+            max_iter=300,
+            n_init=10,
+            random_state=0,
+        )
+        labels = km.fit(X).predict(X)
         ax = None or plt.gca()
         X = df_final[var_list].to_numpy()
-        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)
-        ax.axis('equal')
+        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap="viridis", zorder=2)
+        ax.axis("equal")
         plt.show()
 
-    if "a" in cm.lower():
-        print("AIC\n")
-        aic = []
-        for i in range(2, k_num):
-            model = GaussianMixture(n_components=i, init_params='kmeans')
-            model.fit(X)
-            aic.append(model.bic(X))
-        min_aic = aic[0]
-        min_i = 0
-        for i in range(1, len(aic)):
-            if aic[i] <= min_aic:
-                min_aic = aic[i]
-                min_i = i
-        n_clusters = min_i +2
-        print("Optimal number of clusters: " + str(n_clusters)) #optimal number of clusters, minimizing aic
-        """min_aic = aic[0]
-        max_aic = aic[0]
+    if "el" in cm.lower():
+        print("\n\nElbow Method")
+        sse = []
+        for i in range(2, int(k_num)):
+            km = KMeans(
+                n_clusters=i, init="k-means++", max_iter=300, n_init=10, random_state=0
+            )
+            model = km.fit(X)
+            sse.append(km.inertia_)
+        min_sse = sse[0]
+        max_sse = sse[0]
         max_i = 0
         min_i = 0
-        for i in range(1, len(aic)):
-            if aic[i] >= max_aic:
-                max_aic = aic[i]
+        for i in range(1, len(sse)):
+            if sse[i] >= max_sse:
+                max_sse = sse[i]
                 max_i = i
-            elif aic[i] <= min_aic:
-                min_aic = aic[i]
+            elif sse[i] <= min_sse:
+                min_sse = sse[i]
                 min_i = i
-        p1 = np.array([min_i, aic[min_i]])
-        p2 = np.array([max_i, aic[max_i]])
-        # the way I am doing the method is as follows:
+        p1 = np.array([min_i, sse[min_i]])
+        p2 = np.array([max_i, sse[max_i]])
+        # the way I am doing the elbow method is as follows:
         # the different sse values form a curve like an L (like an exponential decay)
         # The elbow is the point furthest from a line connecting max and min
         # So I am calculating the distance, and the maximum distance from point to curve shows the optimal point
         # AKA the number of clusters
         dist = []
-        for n in range(0, len(aic)):
+        for n, s in enumerate(sse):
             norm = np.linalg.norm
-            p3 = np.array([n, aic[n]])
+            p3 = np.array([n, s])
             dist.append(np.abs(norm(np.cross(p2 - p1, p1 - p3))) / norm(p2 - p1))
         max_dist = dist[0]
-        n_clusters = 2
+        optimal_cluster = 2
         for x in range(1, len(dist)):
             if dist[x] >= max_dist:
                 max_dist = dist[x]
-                n_clusters = x + 2
+                optimal_cluster = x + 2
+        print(
+            "Optimal number of clusters: " + str(optimal_cluster)
+        )  # the optimal number of clusters for elbow method
+        km = KMeans(
+            n_clusters=optimal_cluster,
+            init="k-means++",
+            max_iter=300,
+            n_init=10,
+            random_state=0,
+        )
+        labels = km.fit(X).predict(X)
+        ax = None or plt.gca()
+        X = df_final[var_list].to_numpy()
+        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap="viridis", zorder=2)
+        ax.axis("equal")
+        plt.show()
+
+    if "si" in cm.lower():
+        print("Silhouette Score\n")
+        ss = []
+        for i in range(2, int(k_num)):
+            km = KMeans(
+                n_clusters=i, init="k-means++", max_iter=300, n_init=10, random_state=0
+            )
+            cluster_labels = km.fit_predict(X)
+            silhouette_avg = silhouette_score(X, cluster_labels)
+            ss.append(silhouette_avg)
+        optimal_i = 0
+        distance_to_one = abs(1 - ss[0])
+        for i, s in enumerate(ss):
+            if abs(1 - s) <= distance_to_one:
+                optimal_i = i
+                distance_to_one = abs(1 - s)
+        n_clusters = optimal_i + 2
+        print(
+            "Optimal number of clusters: " + str(n_clusters)
+        )  # the optimal number of clusters
+        km = KMeans(
+            n_clusters=n_clusters,
+            init="k-means++",
+            max_iter=300,
+            n_init=10,
+            random_state=0,
+        )
+        labels = km.fit(X).predict(X)
+        ax = None or plt.gca()
+        X = df_final[var_list].to_numpy()
+        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap="viridis", zorder=2)
+        ax.axis("equal")
+        plt.show()
 
-        plt.plot(aic)
-        plt.show()"""
+    if "ca" in cm.lower():
+        warnings.filterwarnings(
+            "ignore", category=FutureWarning
+        )  # it is a function for 0.24 but says it is deprecated in 0.23
+        print("Calinski-Harabasz Index\n")
+        pca = PCA(n_components=2)
+        impca = pca.fit_transform(X)
+        scores = []
+
+        centers = list(range(2, int(k_num)))
+        for center in centers:
+            km = KMeans(
+                n_clusters=center,
+                init="k-means++",
+                max_iter=300,
+                n_init=10,
+                random_state=0,
+            ).fit(impca)
+            score = calinski_harabaz_score(impca, km.labels_)
+            scores.append(score)
+        optimal_i = 0
+        max_score = scores[0]
 
-        gmm = GaussianMixture(n_components=n_clusters).fit(X)
-        labels = gmm.fit(X).predict(X)
+        for i in range(1, len(scores)):
+            if scores[i] >= max_score:
+                optimal_i = i
+                max_score = scores[i]
+        n_clusters = optimal_i + 2
+        print(
+            "Optimal number of clusters: " + str(n_clusters)
+        )  # the optimal number of clusters
+        km = KMeans(
+            n_clusters=n_clusters,
+            init="k-means++",
+            max_iter=300,
+            n_init=10,
+            random_state=0,
+        )
+        labels = km.fit(X).predict(X)
         ax = None or plt.gca()
         X = df_final[var_list].to_numpy()
-        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)
-        ax.axis('equal')
+        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap="viridis", zorder=2)
+        ax.axis("equal")
         plt.show()
 
-    if "b" in cm.lower():
-        print("\n\nBIC\n")
-        bic = []
-        for i in range(2, k_num):
-            model = GaussianMixture(n_components=i, init_params='kmeans')
-            model.fit(X)
-            bic.append(model.bic(X))
-        min_bic = bic[0]
-        min_i = 0
-        for i in range(1, len(bic)):
-            if bic[i] <= min_bic:
-                min_bic = bic[i]
-                min_i = i
-        n_clusters = min_i + 2
-        """min_bic = bic[0]
-        max_bic = bic[0]
-        max_i = 0
-        min_i = 0
-        for i in range(1,len(bic)):
-            if bic[i]>=max_bic:
-                max_bic = bic[i]
-                max_i = i
-            elif bic[i]<= min_bic:
-                min_bic = bic[i]
-                min_i = i
-        p1 = np.array([min_i, bic[min_i]])
-        p2 = np.array([max_i, bic[max_i]])
-        # the way I am doing the method is as follows:
-        # the different sse values form a curve like an L (like an exponential decay)
-        # The elbow is the point furthest from a line connecting max and min
-        # So I am calculating the distance, and the maximum distance from point to curve shows the optimal point
-        # AKA the number of clusters
-        dist = []
-        for n in range(0, len(bic)):
-            norm = np.linalg.norm
-            p3 = np.array([n, bic[n]])
-            dist.append(np.abs(norm(np.cross(p2 - p1, p1 - p3))) / norm(p2 - p1))
-        max_dist = dist[0]
-        n_clusters = 2
-        for x in range(1, len(dist)):
-            if dist[x] >= max_dist:
-                max_dist = dist[x]
-                n_clusters = x + 2
-        plt.plot(bic)
-        plt.show()"""
-        print("Optimal number of clusters: " + str(n_clusters)) #optimal number of clusters
-        gmm = GaussianMixture(n_components=n_clusters).fit(X)
-        labels = gmm.fit(X).predict(X)
+    if "da" in cm.lower():
+        print("Davies-Bouldin Index\n")
+        scores = []
+
+        centers = list(range(2, int(k_num)))
+        for center in centers:
+            km = KMeans(
+                n_clusters=center,
+                init="k-means++",
+                max_iter=300,
+                n_init=10,
+                random_state=0,
+            )
+            model = km.fit_predict(X)
+            score = davies_bouldin_score(X, model)
+            scores.append(score)
+        optimal_i = 0
+        min_score = scores[0]
+
+        for i in range(1, len(scores)):
+            if scores[i] <= min_score:
+                optimal_i = i
+                min_score = scores[i]
+        n_clusters = optimal_i + 2
+        print(
+            "Optimal number of clusters: " + str(n_clusters)
+        )  # the optimal number of clusters
+        km = KMeans(
+            n_clusters=n_clusters,
+            init="k-means++",
+            max_iter=300,
+            n_init=10,
+            random_state=0,
+        )
+        labels = km.fit(X).predict(X)
         ax = None or plt.gca()
         X = df_final[var_list].to_numpy()
-        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)
-        ax.axis('equal')
+        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap="viridis", zorder=2)
+        ax.axis("equal")
         plt.show()
 
-    if (o is not None):
-        f = open(o, "a")
-        f.close()
+    if "de" in cm.lower():
+        print("Dendrogram")
+        # ask for help: how does one do a dendrogram, also without graphing?
+
+
 def opencsv(data):
     """saves a list of lists as a csv and opens"""
-    import tempfile
-    import os
-    import csv
-    handle, fn = tempfile.mkstemp(suffix='.csv')
-    with os.fdopen(handle,"w", encoding='utf8',errors='surrogateescape',newline='') as f:
+    handle, fn = tempfile.mkstemp(suffix=".csv")
+    with os.fdopen(
+        handle, "w", encoding="utf8", errors="surrogateescape", newline=""
+    ) as f:
         writer = csv.writer(f)
         writer.writerows(data)
     return fn
+
+
 # it can be used calling the script `python nidm_query.py -nl ... -q ..
 if __name__ == "__main__":
-    gmm()
+    k_means()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/nidm_kmeans.py` & `pynidm-4.0.0/src/nidm/experiment/tools/nidm_gmm.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,70 +1,93 @@
+import csv
 import os
+import sys
 import tempfile
+import click
+import matplotlib.pyplot as plt
 import pandas as pd
-import csv
+from sklearn import preprocessing
+from sklearn.metrics import silhouette_score
+from sklearn.mixture import GaussianMixture
 from nidm.experiment.Query import GetProjectsUUID
-import click
 from nidm.experiment.tools.click_base import cli
 from nidm.experiment.tools.rest import RestParser
-import numpy as np
-import matplotlib.pyplot as plt
-from sklearn.cluster import KMeans
-from sklearn.decomposition import PCA
-from sklearn.metrics import silhouette_score
-from sklearn.preprocessing import LabelEncoder, MinMaxScaler
-from sklearn import preprocessing
-from sklearn.metrics import davies_bouldin_score
-from sklearn.metrics import calinski_harabaz_score
+from .utils import Reporter
 
 
 @cli.command()
-@click.option("--nidm_file_list", "-nl", required=True,
-              help="A comma separated list of NIDM files with full path")
-@click.option("--var","-variables", required=True,
-                 help="This parameter is for the variables the user would like to complete the k-means algorithm on.\nThe way this looks in the command is python3 nidm_kmeans.py -nl MTdemog_aseg_v2.ttl -v \"fs_003343,age*sex,sex,age,group,age*group,bmi\"")
-@click.option("--k_range", "-k", required=True,
-              help="The maxiumum number of clusters to try. The algorithm will go from 2 to this number to determine the optimal number of clusters.")
-@click.option("--optimal_cluster_method", "-m", required=True,
-              help="The criterion used to select the optimal partitioning (either Gap Statistic, Elbow Method, Silhouette Coefficient, Calinski-Harabasz Index, or Davies_Bouldin Index).")
-@click.option("--output_file", "-o", required=False,
-              help="Optional output file (TXT) to store results of the linear regression, contrast, and regularization")
-def k_means(nidm_file_list, output_file, var, k_range, optimal_cluster_method):
+@click.option(
+    "--nidm_file_list",
+    "-nl",
+    required=True,
+    help="A comma separated list of NIDM files with full path",
+)
+@click.option(
+    "--var",
+    "-variables",
+    required=True,
+    help='This parameter is for the variables the user would like to complete the k-means algorithm on.\nThe way this looks in the command is python3 nidm_kmeans.py -nl MTdemog_aseg_v2.ttl -v "fs_003343,age*sex,sex,age,group,age*group,bmi"',
+)
+@click.option(
+    "--k_range",
+    "-k",
+    required=True,
+    help="The maximum number of clusters to try. The algorithm will go from 2 to this number to determine the optimal number of clusters.",
+)
+@click.option(
+    "--optimal_cluster_method",
+    "-m",
+    required=True,
+    help="The criterion used to select the optimal partitioning (either Silhouette Score, AIC, or BIC).",
+)
+@click.option(
+    "--output_file",
+    "-o",
+    required=False,
+    help="Optional output file (TXT) to store results of the linear regression, contrast, and regularization",
+)
+def gmm(nidm_file_list, output_file, var, k_range, optimal_cluster_method):
+    """
+    This function provides a tool to complete k-means clustering on NIDM data.
     """
-            This function provides a tool to complete k-means clustering on NIDM data.
-            """
     global v  # Needed to do this because the code only used the parameters in the first method, meaning I had to move it all to method 1.
-    v = var.strip()  # used in data_aggregation, kmenas(), spaces stripped from left and right
-    global o  # used in dataparsing()
-    o = output_file
-    global n  # used in data_aggregation()
-    n = nidm_file_list
-    global k_num
-    k_num = int(k_range)
-    global cm
-    cm = optimal_cluster_method
-    data_aggregation()
-    dataparsing()
-    cluster_number()
-
-def data_aggregation():  # all data from all the files is collected
-    """    This function provides query support for NIDM graphs.   """
-    # query result list
-    results = []
+    v = (
+        var.strip()
+    )  # used in data_aggregation, kmenas(), spaces stripped from left and right
+    with Reporter(output_file) as reporter:
+        global n  # used in data_aggregation()
+        n = nidm_file_list
+        global k_num
+        k_num = int(k_range.strip())
+        global cm
+        cm = optimal_cluster_method
+        data_aggregation(reporter)
+        dataparsing(reporter)
+        cluster_number()
+
+
+def data_aggregation(reporter):  # all data from all the files is collected
+    """This function provides query support for NIDM graphs."""
     # if there is a CDE file list, seed the CDE cache
-    if v:  #ex: age,sex,DX_GROUP
-        print("***********************************************************************************************************")
-        command = "pynidm k-means -nl " + n + " -variables \"" + v + "\" " + "-k " + str(k_num) + " -m " + cm
-
-        print("Your command was: " + command)
-        if (o is not None):
-            f = open(o, "w")
-            f.write("Your command was " + command)
-            f.close()
-        verbosity=0
+    if v:  # ex: age,sex,DX_GROUP
+        print("*" * 107)
+        command = (
+            "pynidm k-means -nl "
+            + n
+            + ' -variables "'
+            + v
+            + '" '
+            + "-k "
+            + str(k_num)
+            + " -m "
+            + cm
+        )
+
+        reporter.print("Your command was:", command)
+        verbosity = 0
         restParser = RestParser(verbosity_level=int(verbosity))
         restParser.setOutputFormat(RestParser.OBJECT_FORMAT)
         global df_list  # used in dataparsing()
         df_list = []
         # set up uri to do fields query for each nidm file
         global file_list
         file_list = n.split(",")
@@ -84,415 +107,425 @@
         for nidm_file in file_list:
             # get project UUID
             project = GetProjectsUUID([nidm_file])
             # split the model into its constituent variables
             global var_list
             # below, we edit the model so it splits by +,~, or =. However, to help it out in catching everything
             # we replaced ~ and = with a + so that we can still use split. Regex wasn't working.
-            var_list = v.split(",")
-            for i in range(len(var_list)):  # here, we remove any leading or trailing spaces
-                var_list[i] = var_list[i].strip()
+            var_list = [vv.strip() for vv in v.split(",")]
             # set the dependent variable to the one dependent variable in the model
-            global vars  # used in dataparsing()
-            vars = ""
+            global variables  # used in dataparsing()
+            variables = ""
             for i in range(len(var_list) - 1, -1, -1):
-                if not "*" in var_list[i]:  # removing the star term from the columns we're about to pull from data
-                    vars = vars + var_list[i] + ","
+                if (
+                    "*" not in var_list[i]
+                ):  # removing the star term from the columns we're about to pull from data
+                    variables = variables + var_list[i] + ","
                 else:
-                    print("Interacting variables are not present in clustering models. They will be removed.")
-            vars = vars[0:len(vars) - 1]
-            uri = "/projects/" + project[0].toPython().split("/")[-1] + "?fields=" + vars
+                    print(
+                        "Interacting variables are not present in clustering models. They will be removed."
+                    )
+            variables = variables[0 : len(variables) - 1]
+            uri = (
+                "/projects/"
+                + project[0].toPython().split("/")[-1]
+                + "?fields="
+                + variables
+            )
             # get fields output from each file and concatenate
             df_list_holder[count].append(pd.DataFrame(restParser.run([nidm_file], uri)))
             # global dep_var
             df = pd.concat(df_list_holder[count])
-            with tempfile.NamedTemporaryFile(delete=False) as temp:  # turns the dataframe into a temporary csv
-                df.to_csv(temp.name + '.csv')
+            with tempfile.NamedTemporaryFile(
+                delete=False
+            ) as temp:  # turns the dataframe into a temporary csv
+                df.to_csv(temp.name + ".csv")
                 temp.close()
-            data = list(csv.reader(open(
-                temp.name + '.csv')))  # makes the csv a 2D list to make it easier to call the contents of certain cells
 
-            var_list = vars.split(",")  # makes a list of the independent variables
+            with open(temp.name + ".csv", encoding="utf-8") as fp:
+                data = list(
+                    csv.reader(fp)
+                )  # makes the csv a 2D list to make it easier to call the contents of certain cells
+
+            var_list = variables.split(",")  # makes a list of the independent variables
             numcols = (len(data) - 1) // (
-                    len(var_list))  # Finds the number of columns in the original dataframe
-            global condensed_data  # also used in linreg()
+                len(var_list)
+            )  # Finds the number of columns in the original dataframe
             condensed_data_holder[count] = [
-                [0] * (len(var_list))]  # makes an array 1 row by the number of necessary columns
-            for i in range(
-                    numcols):  # makes the 2D array big enough to store all of the necessary values in the edited dataset
+                [0] * (len(var_list))
+            ]  # makes an array 1 row by the number of necessary columns
+            for _ in range(
+                numcols
+            ):  # makes the 2D array big enough to store all of the necessary values in the edited dataset
                 condensed_data_holder[count].append([0] * (len(var_list)))
-            for m in range(0, len(var_list)):
-                end_url = var_list[m].split("/")
-                if "/" in var_list[m]:
-                    var_list[m] = end_url[len(end_url) - 1]
-            for i in range(len(var_list)):  # stores the independent variable names in the first row
-                condensed_data_holder[count][0][i] = var_list[i]
+            var_list = [v.split("/")[-1] for v in var_list]
+            for i, vr in enumerate(var_list):
+                # stores the independent variable names in the first row
+                condensed_data_holder[count][0][i] = vr
             numrows = 1  # begins at the first row to add data
-            fieldcolumn = 0  # the column the variable name is in in the original dataset
+            fieldcolumn = (
+                0  # the column the variable name is in in the original dataset
+            )
             valuecolumn = 0  # the column the value is in in the original dataset
             datacolumn = 0  # if it is identified by the dataElement name instead of the field's name
             not_found_list = []
             for i in range(len(data[0])):
-                if data[0][i] == 'sourceVariable':  # finds the column where the variable names are
+                if (
+                    data[0][i] == "sourceVariable"
+                ):  # finds the column where the variable names are
                     fieldcolumn = i
-                elif data[0][i] == 'source_variable':  # finds the column where the variable names are
+                elif (
+                    data[0][i] == "source_variable"
+                ):  # finds the column where the variable names are
                     fieldcolumn = i
-                elif data[0][i] == 'isAbout':
+                elif data[0][i] == "isAbout":
                     aboutcolumn = i
-                elif data[0][i] == 'label':
+                elif data[0][i] == "label":
                     namecolumn = i  # finds the column where the variable names are
-                elif data[0][i] == 'value':
+                elif data[0][i] == "value":
                     valuecolumn = i  # finds the column where the values are
-                elif data[0][i] == 'dataElement':  # finds the column where the data element is if necessary
+                elif (
+                    data[0][i] == "dataElement"
+                ):  # finds the column where the data element is if necessary
                     datacolumn = i
             for i in range(
-                    len(condensed_data_holder[count][
-                            0])):  # starts iterating through the dataset, looking for the name in that
-                for j in range(1, len(data)):  # column, so it can append the values under the proper variables
+                len(condensed_data_holder[count][0])
+            ):  # starts iterating through the dataset, looking for the name in that
+                for j in range(
+                    1, len(data)
+                ):  # column, so it can append the values under the proper variables
                     try:
-                        if data[j][fieldcolumn] == condensed_data_holder[count][0][
-                            i]:  # in the dataframe, the name is in column 3
+                        if (
+                            data[j][fieldcolumn] == condensed_data_holder[count][0][i]
+                        ):  # in the dataframe, the name is in column 3
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][aboutcolumn] == condensed_data_holder[count][0][
-                            i]:
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif data[j][aboutcolumn] == condensed_data_holder[count][0][i]:
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif condensed_data_holder[count][0][
-                            i] in data[j][
-                            aboutcolumn]:  # this is in case the uri only works by querying the part after the last backslash
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            condensed_data_holder[count][0][i] in data[j][aboutcolumn]
+                        ):  # this is in case the uri only works by querying the part after the last backslash
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][namecolumn] == condensed_data_holder[count][0][
-                            i]:  # in the dataframe, the name is in column 12
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            data[j][namecolumn] == condensed_data_holder[count][0][i]
+                        ):  # in the dataframe, the name is in column 12
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif condensed_data_holder[count][0][i] == data[j][
-                            datacolumn]:  # in the dataframe, the name is in column 9
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            condensed_data_holder[count][0][i] == data[j][datacolumn]
+                        ):  # in the dataframe, the name is in column 9
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
                     except IndexError:
                         numrows = numrows + 1
                 numrows = 1  # resets to the first row for the next variable
             temp_list = condensed_data_holder[count]
-            for j in range(len(temp_list[0]) - 1, 0,
-                           -1):  # if the software appends a column with 0 as the heading, it removes this null column
+            for j in range(
+                len(temp_list[0]) - 1, 0, -1
+            ):  # if the software appends a column with 0 as the heading, it removes this null column
                 if temp_list[0][j] == "0" or temp_list[0][j] == "NaN":
                     for row in condensed_data_holder[count]:
                         row.pop(j)
             rowsize = len(condensed_data_holder[count][0])
             count1 = 0
             for i in range(0, rowsize):
                 for row in condensed_data_holder[count]:
                     if row[i] == 0 or row[i] == "NaN" or row[i] == "0":
                         count1 = count1 + 1
                 if count1 > len(condensed_data_holder[count]) - 2:
                     not_found_list.append(condensed_data_holder[count][0][i])
                 count1 = 0
-            for i in range(len(condensed_data_holder[count][0])):
-                if " " in condensed_data_holder[count][0][i]:
-                    condensed_data_holder[count][0][i] = condensed_data_holder[count][0][i].replace(" ", "_")
-            for i in range(len(var_list)):
-                if "/" in var_list[i]:
-                    splitted = var_list[i].split("/")
-                    var_list[i] = splitted[len(splitted) - 1]
-                if " " in var_list[i]:
-                    var_list[i] = var_list[i].replace(" ", "_")
-            count = count + 1
+            for i, cdh in enumerate(condensed_data_holder[count][0]):
+                if " " in cdh:
+                    condensed_data_holder[count][0][i] = cdh.replace(" ", "_")
+            var_list = [vr.split("/")[-1].replace(" ", "_") for vr in var_list]
+            count += 1
             if len(not_found_list) > 0:
-                print(
-                    "***********************************************************************************************************")
-                print()
-                print("Your variables were " + v)
+                print("*" * 107)
                 print()
-                print(
-                    "The following variables were not found in " + nidm_file + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables.")
-                if (o is not None):
-                    f = open(o, "a")
-                    f.write("Your variables were " + v)
-                    f.write(
-                        "The following variables were not found in " + nidm_file + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables.")
-                    f.close()
-                for i in range(0, len(not_found_list)):
-                    print(str(i + 1) + ". " + not_found_list[i])
-                    if (o is not None):
-                        f = open(o, "a")
-                        f.write(str(i + 1) + ". " + not_found_list[i])
-                        f.close()
-                for j in range(len(not_found_list) - 1, 0, -1):
-                    not_found_list.pop(j)
-                not_found_count = not_found_count + 1
+                reporter.print("Your variables were " + v)
+                reporter.print()
+                reporter.print(
+                    "The following variables were not found in "
+                    + nidm_file
+                    + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables."
+                )
+                for i, nf in enumerate(not_found_list):
+                    reporter.print(f"{i+1}. {nf}")
+                not_found_list.clear()
+                not_found_count += 1
                 print()
         if not_found_count > 0:
-            exit(1)
-
+            sys.exit(1)
 
     else:
         print("ERROR: No query parameter provided.  See help:")
         print()
         os.system("pynidm k-means --help")
-        exit(1)
+        sys.exit(1)
+
 
-def dataparsing(): #The data is changed to a format that is usable by the linear regression method
+def dataparsing(
+    reporter,
+):  # The data is changed to a format that is usable by the linear regression method
     global condensed_data
     condensed_data = []
     for i in range(0, len(file_list)):
         condensed_data = condensed_data + condensed_data_holder[i]
     global k_num
     if len(condensed_data[0]) <= k_num:
-        print("\nThe maximum number of clusters specified is greater than the amount of data present.")
-        print("The algorithm cannot run with this, so k_num will be reduced to 1 less than the length of the dataset.")
+        print(
+            "\nThe maximum number of clusters specified is greater than the amount of data present."
+        )
+        print(
+            "The algorithm cannot run with this, so k_num will be reduced to 1 less than the length of the dataset."
+        )
         k_num = len(condensed_data) - 1
         print("The k_num value is now: " + str(k_num))
-    x = pd.read_csv(opencsv(condensed_data))  # changes the dataframe to a csv to make it easier to work with
+    x = pd.read_csv(
+        opencsv(condensed_data)
+    )  # changes the dataframe to a csv to make it easier to work with
     x.head()  # prints what the csv looks like
     x.dtypes  # checks data format
     obj_df = x.select_dtypes  # puts all the variables in a dataset
     x.shape  # says number of rows and columns in form of tuple
     x.describe()  # says dataset statistics
     obj_df = x.select_dtypes(
-        include=['object']).copy()  # takes everything that is an object (not float or int) and puts it in a new dataset
+        include=["object"]
+    ).copy()  # takes everything that is an object (not float or int) and puts it in a new dataset
     obj_df.head()  # prints the new dataset
-    int_df = x.select_dtypes(include=['int64']).copy()  # takes everything that is an int and puts it in a new dataset
+    int_df = x.select_dtypes(
+        include=["int64"]
+    ).copy()  # takes everything that is an int and puts it in a new dataset
     float_df = x.select_dtypes(
-        include=['float64']).copy()  # takes everything that is a float and puts it in a new dataset
+        include=["float64"]
+    ).copy()  # takes everything that is a float and puts it in a new dataset
     df_int_float = pd.concat([float_df, int_df], axis=1)
     stringvars = []  # starts a list that will store all variables that are not numbers
     for i in range(1, len(condensed_data)):  # goes through each variable
         for j in range(len(condensed_data[0])):  # in the 2D array
             try:  # if the value of the field can be turned into a float (is numerical)
                 float(condensed_data[i][j])  # this means it's a number
             except ValueError:  # if it can't be (is a string)
-                if condensed_data[0][
-                    j] not in stringvars:  # adds the variable name to the list if it isn't there already
+                if (
+                    condensed_data[0][j] not in stringvars
+                ):  # adds the variable name to the list if it isn't there already
                     stringvars.append(condensed_data[0][j])
-    le = preprocessing.LabelEncoder()  # anything involving le shows the encoding of categorical variables
-    for i in range(len(stringvars)):
-        le.fit(obj_df[stringvars[i]].astype(str))
-    obj_df_trf = obj_df.astype(str).apply(le.fit_transform)  # transforms the categorical variables into numbers.
+    le = (
+        preprocessing.LabelEncoder()
+    )  # anything involving le shows the encoding of categorical variables
+    for sv in stringvars:
+        le.fit(obj_df[sv].astype(str))
+    obj_df_trf = obj_df.astype(str).apply(
+        le.fit_transform
+    )  # transforms the categorical variables into numbers.
     global df_final  # also used in linreg()
     if not obj_df_trf.empty:
-        df_final = pd.concat([df_int_float, obj_df_trf], axis=1)  # join_axes=[df_int_float.index])
+        df_final = pd.concat(
+            [df_int_float, obj_df_trf], axis=1
+        )  # join_axes=[df_int_float.index])
     else:
         df_final = df_int_float
-    df_final.head()  # shows the final dataset with all the encoding
-    print(df_final)  # prints the final dataset
-    print()
-    print("***********************************************************************************************************")
-    print()
-    if (o is not None):
-        f = open(o, "a")
-        f.write(df_final.to_string(header=True, index=True))
-        f.write(
-            "\n\n***********************************************************************************************************")
-        f.write("\n\nModel Results: ")
-        f.close()
+    reporter.print(df_final.to_string(header=True, index=True))
+    reporter.print("\n\n" + ("*" * 107))
+    reporter.print("\n\nModel Results: ")
+
+
 def cluster_number():
     index = 0
     global levels  # also used in contrasting()
     levels = []
     for i in range(1, len(condensed_data)):
         if condensed_data[i][index] not in levels:
             levels.append(condensed_data[i][index])
-    for i in range(len(levels)):
-        levels[i] = i
+    levels = list(range(len(levels)))
 
     # Beginning of the linear regression
     global X
-    #global y
-    #Unsure on how to procede here with interacting variables, since I'm sure dmatrices won't work
-
-    """scaler = MinMaxScaler()
+    # global y
+    # Unsure on how to proceed here with interacting variables, since I'm sure dmatrices won't work
 
-    for i in range(len(model_list)):
-        scaler.fit(df_final[[model_list[i]]])
-        df_final[[model_list[i]]] = scaler.transform(df_final[[model_list[i]]])"""
+    # scaler = MinMaxScaler()
+    #
+    # for i in range(len(model_list)):
+    #     scaler.fit(df_final[[model_list[i]]])
+    #     df_final[[model_list[i]]] = scaler.transform(df_final[[model_list[i]]])
     X = df_final[var_list]
-    if "ga" in cm.lower():
-        print("\n\nGap Statistic")
-        gaps = np.zeros((len(range(2,int(k_num)))))
-        global resulting_df
-        resulting_df = pd.DataFrame({'clusterCount':[],'gap':[]})
-        global gap_index, k
-        for gap_index, k in enumerate(range(2,int(k_num))):
-            dispersion_results = np.zeros(3) #make three random datasets
-            for i in range(3):
-                random_reference = np.random.random_sample(size=df_final.shape)
-                km = KMeans(k)
-                km.fit(random_reference)
-                dispersion_results[i] = km.inertia_
-            km = KMeans(k)
-            km.fit(df_final)
-
-            original_sse = km.inertia_
-            global gap
-            gap = np.log(np.mean(dispersion_results)) - np.log(original_sse)
-
-            gaps[gap_index] = gap
-        max_gap = gaps[0]
-        optimal_i = 0
-        for i in range(1,len(gaps)):
-            if gaps[i] > max_gap:
-                optimal_i = i
-                max_gap = gaps[i]
-        optimal_cluster = optimal_i + 2
-        print("Optimal number of clusters: " + str(optimal_cluster)) #the optimal number of clusters for gap statistic
-        km = KMeans(n_clusters=optimal_cluster, init='k-means++', max_iter=300, n_init=10, random_state=0)
-        labels = km.fit(X).predict(X)
-        ax = None or plt.gca()
-        X = df_final[var_list].to_numpy()
-        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)
-        ax.axis('equal')
-        plt.show()
-
-    if "el" in cm.lower():
-        print("\n\nElbow Method")
-        sse = []
-        for i in range(2,int(k_num)):
-            km = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
-            model = km.fit(X)
-            sse.append(km.inertia_)
-        min_sse = sse[0]
-        max_sse = sse[0]
-        max_i = 0
-        min_i = 0
-        for i in range(1, len(sse)):
-            if sse[i] >= max_sse:
-                max_sse = sse[i]
-                max_i = i
-            elif sse[i] <= min_sse:
-                min_sse = sse[i]
-                min_i = i
-        p1 = np.array([min_i, sse[min_i]])
-        p2 = np.array([max_i, sse[max_i]])
-        #the way I am doing the elbow method is as follows:
-        #the different sse values form a curve like an L (like an exponential decay)
-        #The elbow is the point furthest from a line connecting max and min
-        #So I am calculating the distance, and the maximum distance from point to curve shows the optimal point
-        #AKA the number of clusters
-        dist = []
-        for n in range(0,len(sse)):
-            norm = np.linalg.norm
-            p3 = np.array([n,sse[n]])
-            dist.append(np.abs(norm(np.cross(p2-p1, p1-p3)))/norm(p2-p1))
-        max_dist = dist[0]
-        optimal_cluster = 2
-        for x in range(1,len(dist)):
-            if dist[x]>=max_dist:
-                max_dist = dist[x]
-                optimal_cluster = x+2
-        print("Optimal number of clusters: " + str(optimal_cluster)) #the optimal number of clusters for elbow method
-        km = KMeans(n_clusters=optimal_cluster, init='k-means++', max_iter=300, n_init=10, random_state=0)
-        labels = km.fit(X).predict(X)
-        ax = None or plt.gca()
-        X = df_final[var_list].to_numpy()
-        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)
-        ax.axis('equal')
-        plt.show()
-
     if "si" in cm.lower():
-        print("Silhouette Score\n")
+        print("Sillhoute Score")
+
         ss = []
-        for i in range(2,int(k_num)):
-            km = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
-            cluster_labels = km.fit_predict(X)
+
+        for i in range(2, k_num):
+            model = GaussianMixture(n_components=i, init_params="kmeans")
+            cluster_labels = model.fit_predict(X)
             silhouette_avg = silhouette_score(X, cluster_labels)
             ss.append(silhouette_avg)
         optimal_i = 0
         distance_to_one = abs(1 - ss[0])
-        for i in range(0, len(ss)):
-            if abs(1 - ss[i]) <= distance_to_one:
+        for i, s in enumerate(ss):
+            if abs(1 - s) <= distance_to_one:
                 optimal_i = i
-                distance_to_one = abs(1 - ss[i])
+                distance_to_one = abs(1 - s)
+
         n_clusters = optimal_i + 2
-        print("Optimal number of clusters: " + str(n_clusters)) #the optimal number of clusters
-        km = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0)
-        labels = km.fit(X).predict(X)
+        print(
+            "Optimal number of clusters: " + str(n_clusters)
+        )  # optimal number of clusters
+        gmm = GaussianMixture(n_components=n_clusters).fit(X)
+        labels = gmm.fit(X).predict(X)
         ax = None or plt.gca()
         X = df_final[var_list].to_numpy()
-        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)
-        ax.axis('equal')
+        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap="viridis", zorder=2)
+        ax.axis("equal")
         plt.show()
 
-    if "ca" in cm.lower():
-        import warnings
-        warnings.filterwarnings("ignore", category=FutureWarning) #it is a function for 0.24 but says it is depracated in 0.23
-        print("Calinski-Harabasz Index\n")
-        pca = PCA(n_components=2)
-        impca = pca.fit_transform(X)
-        scores = []
-
-        centers = list(range(2, int(k_num)))
-        for center in centers:
-            km = KMeans(n_clusters=center, init='k-means++', max_iter=300, n_init=10, random_state=0).fit(impca)
-            score = calinski_harabaz_score(impca,km.labels_)
-            scores.append(score)
-        optimal_i = 0
-        max_score = scores[0]
+    if "a" in cm.lower():
+        print("AIC\n")
+        aic = []
+        for i in range(2, k_num):
+            model = GaussianMixture(n_components=i, init_params="kmeans")
+            model.fit(X)
+            aic.append(model.bic(X))
+        min_aic = aic[0]
+        min_i = 0
+        for i in range(1, len(aic)):
+            if aic[i] <= min_aic:
+                min_aic = aic[i]
+                min_i = i
+        n_clusters = min_i + 2
+        print(
+            "Optimal number of clusters: " + str(n_clusters)
+        )  # optimal number of clusters, minimizing aic
+
+        # min_aic = aic[0]
+        # max_aic = aic[0]
+        # max_i = 0
+        # min_i = 0
+        # for i in range(1, len(aic)):
+        #     if aic[i] >= max_aic:
+        #         max_aic = aic[i]
+        #         max_i = i
+        #     elif aic[i] <= min_aic:
+        #         min_aic = aic[i]
+        #         min_i = i
+        # p1 = np.array([min_i, aic[min_i]])
+        # p2 = np.array([max_i, aic[max_i]])
+        # # the way I am doing the method is as follows:
+        # # the different sse values form a curve like an L (like an exponential decay)
+        # # The elbow is the point furthest from a line connecting max and min
+        # # So I am calculating the distance, and the maximum distance from point to curve shows the optimal point
+        # # AKA the number of clusters
+        # dist = []
+        # for n in range(0, len(aic)):
+        #     norm = np.linalg.norm
+        #     p3 = np.array([n, aic[n]])
+        #     dist.append(np.abs(norm(np.cross(p2 - p1, p1 - p3))) / norm(p2 - p1))
+        # max_dist = dist[0]
+        # n_clusters = 2
+        # for x in range(1, len(dist)):
+        #     if dist[x] >= max_dist:
+        #         max_dist = dist[x]
+        #         n_clusters = x + 2
+        #
+        # plt.plot(aic)
+        # plt.show()
 
-        for i in range(1, len(scores)):
-            if scores[i] >= max_score:
-                optimal_i = i
-                max_score = scores[i]
-        n_clusters = optimal_i + 2
-        print("Optimal number of clusters: " + str(n_clusters)) #the optimal number of clusters
-        km = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0)
-        labels = km.fit(X).predict(X)
+        gmm = GaussianMixture(n_components=n_clusters).fit(X)
+        labels = gmm.fit(X).predict(X)
         ax = None or plt.gca()
         X = df_final[var_list].to_numpy()
-        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)
-        ax.axis('equal')
+        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap="viridis", zorder=2)
+        ax.axis("equal")
         plt.show()
 
-    if "da" in cm.lower():
-        print("Davies-Bouldin Index\n")
-        scores = []
-
-        centers = list(range(2,int(k_num)))
-        for center in centers:
-            km = KMeans(n_clusters=center, init='k-means++', max_iter=300, n_init=10, random_state=0)
-            model = km.fit_predict(X)
-            score = davies_bouldin_score(X, model)
-            scores.append(score)
-        optimal_i = 0
-        min_score = scores[0]
-
-        for i in range(1,len(scores)):
-            if scores[i]<=min_score:
-                optimal_i = i
-                min_score = scores[i]
-        n_clusters = optimal_i + 2
-        print("Optimal number of clusters: " + str(n_clusters)) #the optimal number of clusters
-        km = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0)
-        labels = km.fit(X).predict(X)
-        ax = None or plt.gca()
+    if "b" in cm.lower():
+        print("\n\nBIC\n")
+        bic = []
+        for i in range(2, k_num):
+            model = GaussianMixture(n_components=i, init_params="kmeans")
+            model.fit(X)
+            bic.append(model.bic(X))
+        min_bic = bic[0]
+        min_i = 0
+        for i in range(1, len(bic)):
+            if bic[i] <= min_bic:
+                min_bic = bic[i]
+                min_i = i
+        n_clusters = min_i + 2
+        # min_bic = bic[0]
+        # max_bic = bic[0]
+        # max_i = 0
+        # min_i = 0
+        # for i in range(1,len(bic)):
+        #     if bic[i]>=max_bic:
+        #         max_bic = bic[i]
+        #         max_i = i
+        #     elif bic[i]<= min_bic:
+        #         min_bic = bic[i]
+        #         min_i = i
+        # p1 = np.array([min_i, bic[min_i]])
+        # p2 = np.array([max_i, bic[max_i]])
+        # # the way I am doing the method is as follows:
+        # # the different sse values form a curve like an L (like an exponential decay)
+        # # The elbow is the point furthest from a line connecting max and min
+        # # So I am calculating the distance, and the maximum distance from point to curve shows the optimal point
+        # # AKA the number of clusters
+        # dist = []
+        # for n in range(0, len(bic)):
+        #     norm = np.linalg.norm
+        #     p3 = np.array([n, bic[n]])
+        #     dist.append(np.abs(norm(np.cross(p2 - p1, p1 - p3))) / norm(p2 - p1))
+        # max_dist = dist[0]
+        # n_clusters = 2
+        # for x in range(1, len(dist)):
+        #     if dist[x] >= max_dist:
+        #         max_dist = dist[x]
+        #         n_clusters = x + 2
+        # plt.plot(bic)
+        # plt.show()
+        print("Optimal number of clusters:", n_clusters)
+        gmm = GaussianMixture(n_components=n_clusters).fit(X)
+        labels = gmm.fit(X).predict(X)
+        ax = plt.gca()
         X = df_final[var_list].to_numpy()
-        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)
-        ax.axis('equal')
+        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap="viridis", zorder=2)
+        ax.axis("equal")
         plt.show()
 
-    if "de" in cm.lower():
-        print("Dendrogram")
-        #ask for help: how does one do a dendrogram, also without graphing?
-
-    if (o is not None):
-        f = open(o, "a")
-        f.close()
+
 def opencsv(data):
     """saves a list of lists as a csv and opens"""
-    import tempfile
-    import os
-    import csv
-    handle, fn = tempfile.mkstemp(suffix='.csv')
-    with os.fdopen(handle,"w", encoding='utf8',errors='surrogateescape',newline='') as f:
+    handle, fn = tempfile.mkstemp(suffix=".csv")
+    with os.fdopen(
+        handle, "w", encoding="utf8", errors="surrogateescape", newline=""
+    ) as f:
         writer = csv.writer(f)
         writer.writerows(data)
     return fn
 
+
 # it can be used calling the script `python nidm_query.py -nl ... -q ..
 if __name__ == "__main__":
-    k_means()
+    gmm()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/nidm_linreg.py` & `pynidm-4.0.0/src/nidm/experiment/tools/nidm_linreg.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,154 +1,106 @@
-# coding=utf-8
-# !/usr/bin/env python
+"""This program provides a tool to complete a linear regression on nidm files"""
 
-# *******************************************************************************************************
-# *******************************************************************************************************
-#  nidm_linreg.py
-#  License: Apache License, Version 2.0
-# *******************************************************************************************************
-# *******************************************************************************************************
-# Date: 10-09-21                 Coded by: Ashmita Kumar (ashmita.kumar@gmail.com)
-# Filename: nidm_linreg.py
-#
-# Program description:  This program provides a tool to complete a linear regression on nidm files
-#
-#
-# *******************************************************************************************************
-# Development environment: Python - PyCharm IDE
-#
-# *******************************************************************************************************
-# System requirements:  Python 3.X
-# Libraries: os, sys, tempfile, pandas, click, nidm, csv, sklearn, numpy, statsmodel.api, patsy.contrasts
-# *******************************************************************************************************
-# Start date: 6-15-20
-# Update history:
-# DATE            MODIFICATION				Who
-#
-#
-# *******************************************************************************************************
-# Programmer comments:
-#
-#
-# *******************************************************************************************************
-# *******************************************************************************************************
+import csv
 import os
+from statistics import mean
 import sys
-from os import system
 import tempfile
+import warnings
+import click
+import numpy as np
 import pandas as pd
-import csv
+from patsy.contrasts import ContrastMatrix, Diff, Helmert, Sum, Treatment
 from patsy.highlevel import dmatrices
+from sklearn import preprocessing
+from sklearn.linear_model import Lasso, LinearRegression, Ridge
+from sklearn.model_selection import cross_val_score
+import statsmodels.api as sm
+from statsmodels.formula.api import ols
 from nidm.experiment.Query import GetProjectsUUID
-import click
 from nidm.experiment.tools.click_base import cli
 from nidm.experiment.tools.rest import RestParser
-import numpy as np
-try:
-    from sklearn.linear_model import LinearRegression
-    from sklearn import preprocessing
-    from sklearn.linear_model import Ridge
-    from sklearn.linear_model import Lasso
-    from sklearn.model_selection import cross_val_score
-except:
-    system('python -m pip install --upgrade pip sklearn')
-    from sklearn.linear_model import LinearRegression
-    from sklearn import preprocessing
-    from sklearn.linear_model import Ridge
-    from sklearn.linear_model import Lasso
-    from sklearn.model_selection import cross_val_score
-
-try:
-    import statsmodels.api as sm
-    from statsmodels.formula.api import ols
-except:
-    system('python -m pip install --upgrade pip statsmodels')
-    import statsmodels.api as sm
-    from statsmodels.formula.api import ols
-
-try:
-    from statistics import mean
-except:
-    system('python -m pip install --upgrade pip statistics')
-    from statistics import mean
-
-try:
-    from patsy.contrasts import Treatment
-    from patsy.contrasts import ContrastMatrix
-    from patsy.contrasts import Sum
-    from patsy.contrasts import Diff
-    from patsy.contrasts import Helmert
-except:
-    system('python -m pip install --upgrade pip patsy')
-    from patsy.contrasts import Treatment
-    from patsy.contrasts import ContrastMatrix
-    from patsy.contrasts import Sum
-    from patsy.contrasts import Diff
-    from patsy.contrasts import Helmert
+from .utils import Reporter
 
 MAX_ALPHA = 700
-#Defining the parameters of the commands.
-@cli.command()
-@click.option("--nidm_file_list", "-nl", required=True,
-              help="A comma separated list of NIDM files with full path")
-@click.option("--ctr", "-contrast", required=False,
-              help="This parameter will show differences in relationship by group (e.g. -contrast age*sex,group). It can be one variable, interacting variables, or multiple")
-@click.option("--ml", "-model", required=True,
-                 help="This parameter will return the results of the linear regression from all nidm files supplied\nThe way this looks in the command is python3 nidm_linreg.py -nl MTdemog_aseg_v2.ttl -model \"fs_003343 = age*sex + sex + age + group + age*group + bmi\" -contrast group -r L1")
-@click.option("--output_file", "-o", required=False,
-              help="Optional output file (TXT) to store results of the linear regression, contrast, and regularization")
-@click.option("--regularization", "-r", required=False,
-              help="This parameter will return the results of the linear regression with L1 or L2 regularization depending on the type specified, and the weight with the maximum likelihood solution")
 
+
+# Defining the parameters of the commands.
+@cli.command()
+@click.option(
+    "--nidm_file_list",
+    "-nl",
+    required=True,
+    help="A comma separated list of NIDM files with full path",
+)
+@click.option(
+    "--ctr",
+    "-contrast",
+    required=False,
+    help="This parameter will show differences in relationship by group (e.g. -contrast age*sex,group). It can be one variable, interacting variables, or multiple",
+)
+@click.option(
+    "--ml",
+    "-model",
+    required=True,
+    help='This parameter will return the results of the linear regression from all nidm files supplied\nThe way this looks in the command is python3 nidm_linreg.py -nl MTdemog_aseg_v2.ttl -model "fs_003343 = age*sex + sex + age + group + age*group + bmi" -contrast group -r L1',
+)
+@click.option(
+    "--output_file",
+    "-o",
+    required=False,
+    help="Optional output file (TXT) to store results of the linear regression, contrast, and regularization",
+)
+@click.option(
+    "--regularization",
+    "-r",
+    required=False,
+    help="This parameter will return the results of the linear regression with L1 or L2 regularization depending on the type specified, and the weight with the maximum likelihood solution",
+)
 def linear_regression(nidm_file_list, output_file, ml, ctr, regularization):
     """
-        This function provides a tool to complete a linear regression on NIDM data with optional contrast and regularization.
-        """
+    This function provides a tool to complete a linear regression on NIDM data with optional contrast and regularization.
+    """
 
+    # NOTE: Every time I make a global variable, it is because I need it in at least one other method.
+    global c  # used in linreg(), contrasting()
+    c = ctr  # Storing all important parameters in global variables so they can be accessed in other methods
+    global m  # Needed to do this because the code only used the parameters in the first method, meaning I had to move it all to method 1.
+    m = (
+        ml.strip()
+    )  # used in data_aggregation, linreg(), spaces stripped from left and right
+    with Reporter(output_file) as reporter:
+        global n  # used in data_aggregation()
+        n = nidm_file_list
+        global r
+        r = regularization
+        data_aggregation(reporter)  # collects data
+        dataparsing(reporter)  # converts it to proper format
+        linreg(reporter)  # performs linear regression
+        contrasting(reporter)  # performs contrast
+        regularizing(reporter)  # performs regularization
 
-    #NOTE: Every time I make a global variable, it is because I need it in at least one other method.
-    global c #used in linreg(), contrasting()
-    c = ctr #Storing all important parameters in global variables so they can be accessed in other methods
-    global m #Needed to do this because the code only used the parameters in the first method, meaning I had to move it all to method 1.
-    m = ml.strip() #used in data_aggregation, linreg(), spaces stripped from left and right
-    global o #used in dataparsing()
-    o = output_file
-    global n #used in data_aggregation()
-    n = nidm_file_list
-    global r
-    r = regularization
-    data_aggregation() #collects data
-    dataparsing() #converts it to proper format
-    l = linreg() #performs linear regression
-    contrasting() #performs contrast
-    regularizing() #performs regularization
 
-def data_aggregation(): #all data from all the files is collected
+def data_aggregation(reporter):  # all data from all the files is collected
+    """
+    This function provides query support for NIDM graphs.
     """
-            This function provides query support for NIDM graphs.
-            """
-    # query result list
-    results = []
     # if there is a CDE file list, seed the CDE cache
     if m:  # ex: fs_00343 ~ age + sex + group
-        print("***********************************************************************************************************")
-        command = "pynidm linear-regression -nl " + n + " -model \"" + m + "\" "
+        print("*" * 107)
+        command = "pynidm linear-regression -nl " + n + ' -model "' + m + '" '
         if c:
-            command = command + "-contrast \"" + c + "\" "
+            command += '-contrast "' + c + '" '
         if r:
-            command = command + "-r " + r + " "
-        print("Your command was: " + command)
-        if (o is not None):
-            f = open(o, "w")
-            f.write("Your command was " + command)
-            f.close()
+            command += "-r " + r + " "
+        reporter.print("Your command was:", command)
         verbosity = 0
         restParser = RestParser(verbosity_level=int(verbosity))
         restParser.setOutputFormat(RestParser.OBJECT_FORMAT)
-        global df_list #used in dataparsing()
+        global df_list  # used in dataparsing()
         df_list = []
         # set up uri to do fields query for each nidm file
         global file_list
         file_list = n.split(",")
         df_list_holder = {}
         for i in range(len(file_list)):
             df_list_holder[i] = []
@@ -163,584 +115,624 @@
         count = 0
         not_found_count = 0
         for nidm_file in file_list:
             # get project UUID
             project = GetProjectsUUID([nidm_file])
             # split the model into its constituent variables
             global full_model_variable_list
-            #below, we edit the model so it splits by +,~, or =. However, to help it out in catching everything
-            #we replaced ~ and = with a + so that we can still use split. Regex wasn't working.
+            # below, we edit the model so it splits by +,~, or =. However, to help it out in catching everything
+            # we replaced ~ and = with a + so that we can still use split. Regex wasn't working.
             plus_replace = m
             if "~" in m:
-                plus_replace = m.replace('~','+')
+                plus_replace = m.replace("~", "+")
             elif "=" in m:
-                plus_replace = m.replace('=', '+')
+                plus_replace = m.replace("=", "+")
             elif "," in m:
-                plus_replace = m.replace(",", '+')
-            model_list = plus_replace.split("+")
-            for i in range(len(model_list)): #here, we remove any leading or trailing spaces
-                model_list[i] = model_list[i].strip()
+                plus_replace = m.replace(",", "+")
+            model_list = [v.strip() for v in plus_replace.split("+")]
             full_model_variable_list = []
             # set the dependent variable to the one dependent variable in the model
-            global dep_var #used in dataparsing(), linreg(), and contrasting()
+            global dep_var  # used in dataparsing(), linreg(), and contrasting()
             dep_var = model_list[0]
             # join the independent variables into a comma-separated list to make it easier to call from the uri
-            global ind_vars #used in dataparsing()
+            global ind_vars  # used in dataparsing()
             ind_vars = ""
-            for i in range(len(model_list)-1, 0, -1):
-                full_model_variable_list.append(model_list[i]) #will be used in the regularization, but we need the full list
-                if "*" in model_list[i]: #removing the star term from the columns we're about to pull from data
+            for i in range(len(model_list) - 1, 0, -1):
+                full_model_variable_list.append(
+                    model_list[i]
+                )  # will be used in the regularization, but we need the full list
+                if (
+                    "*" in model_list[i]
+                ):  # removing the star term from the columns we're about to pull from data
                     model_list.pop(i)
                 elif model_list[i] == dep_var:
                     model_list.pop(i)
-                    print("\n\nAn independent variable cannot be the same as the dependent variable. This prevents the model from running accurately.")
-                    print("Please try a different model removing \"" + dep_var + "\" from either the right or the left side of the equation.\n\n")
-                    if (o is not None):
-                        f = open(o, "a")
-                        f.write("\n\nAn independent variable cannot be the same as the dependent variable. This prevents the model from running accurately.")
-                        f.write("Please try a different model removing \"" + dep_var + "\" from either the right or the left side of the equation.")
-                        f.close()
-                    exit(1)
+                    reporter.print(
+                        "\n\nAn independent variable cannot be the same as the dependent variable. This prevents the model from running accurately."
+                    )
+                    reporter.print(
+                        'Please try a different model removing "'
+                        + dep_var
+                        + '" from either the right or the left side of the equation.\n\n'
+                    )
+                    sys.exit(1)
                 else:
                     ind_vars = ind_vars + model_list[i] + ","
-            ind_vars = ind_vars[0:len(ind_vars) - 1]
-            uri = "/projects/" + project[0].toPython().split("/")[-1] + "?fields=" + ind_vars + "," + dep_var
+            ind_vars = ind_vars[0 : len(ind_vars) - 1]
+            uri = (
+                "/projects/"
+                + project[0].toPython().split("/")[-1]
+                + "?fields="
+                + ind_vars
+                + ","
+                + dep_var
+            )
             # get fields output from each file and concatenate
             df_list_holder[count].append(pd.DataFrame(restParser.run([nidm_file], uri)))
-            #global dep_var
+            # global dep_var
             df = pd.concat(df_list_holder[count])
-            with tempfile.NamedTemporaryFile(delete=False) as temp:  # turns the dataframe into a temporary csv
-                df.to_csv(temp.name + '.csv')
+            with tempfile.NamedTemporaryFile(
+                delete=False
+            ) as temp:  # turns the dataframe into a temporary csv
+                df.to_csv(temp.name + ".csv")
                 temp.close()
-            data = list(csv.reader(open(
-                temp.name + '.csv')))  # makes the csv a 2D list to make it easier to call the contents of certain cells
+            with open(temp.name + ".csv", encoding="utf-8") as fp:
+                data = list(
+                    csv.reader(fp)
+                )  # makes the csv a 2D list to make it easier to call the contents of certain cells
 
             global independentvariables  # used in linreg
-            independentvariables = ind_vars.split(",")  # makes a list of the independent variables
+            independentvariables = ind_vars.split(
+                ","
+            )  # makes a list of the independent variables
             numcols = (len(data) - 1) // (
-                        len(independentvariables) + 1)  # Finds the number of columns in the original dataframe
-            global condensed_data  # also used in linreg()
+                len(independentvariables) + 1
+            )  # Finds the number of columns in the original dataframe
             condensed_data_holder[count] = [
-                [0] * (len(independentvariables) + 1)]  # makes an array 1 row by the number of necessary columns
-            for i in range(
-                    numcols):  # makes the 2D array big enough to store all of the necessary values in the edited dataset
-                condensed_data_holder[count].append([0] * (len(independentvariables) + 1))
-            for i in range(len(independentvariables)):  # stores the independent variable names in the first row
-                condensed_data_holder[count][0][i] = independentvariables[i]
-            condensed_data_holder[count][0][-1] = str(dep_var)  # stores the dependent variable name in the first row
+                [0] * (len(independentvariables) + 1)
+            ]  # makes an array 1 row by the number of necessary columns
+            for _ in range(
+                numcols
+            ):  # makes the 2D array big enough to store all of the necessary values in the edited dataset
+                condensed_data_holder[count].append(
+                    [0] * (len(independentvariables) + 1)
+                )
+            for i, v in enumerate(independentvariables):
+                # stores the independent variable names in the first row
+                condensed_data_holder[count][0][i] = v
+            condensed_data_holder[count][0][-1] = str(
+                dep_var
+            )  # stores the dependent variable name in the first row
             numrows = 1  # begins at the first row to add data
-            fieldcolumn = 0  # the column the variable name is in in the original dataset
+            fieldcolumn = (
+                0  # the column the variable name is in in the original dataset
+            )
             valuecolumn = 0  # the column the value is in in the original dataset
             datacolumn = 0  # if it is identified by the dataElement name instead of the field's name
             not_found_list = []
             for i in range(len(data[0])):
-                if data[0][i] == 'sourceVariable':  # finds the column where the variable names are
+                if (
+                    data[0][i] == "sourceVariable"
+                ):  # finds the column where the variable names are
                     fieldcolumn = i
-                elif data[0][i] == 'source_variable':  # finds the column where the variable names are
+                elif (
+                    data[0][i] == "source_variable"
+                ):  # finds the column where the variable names are
                     fieldcolumn = i
-                elif data[0][i] == 'isAbout':
+                elif data[0][i] == "isAbout":
                     aboutcolumn = i
-                elif data[0][i] == 'label':
+                elif data[0][i] == "label":
                     namecolumn = i  # finds the column where the variable names are
-                elif data[0][i] == 'value':
+                elif data[0][i] == "value":
                     valuecolumn = i  # finds the column where the values are
-                elif data[0][i] == 'dataElement':  # finds the column where the data element is if necessary
+                elif (
+                    data[0][i] == "dataElement"
+                ):  # finds the column where the data element is if necessary
                     datacolumn = i
             for i in range(
-                    len(condensed_data_holder[count][0])):  # starts iterating through the dataset, looking for the name in that
-                for j in range(1, len(data)):  # column, so it can append the values under the proper variables
+                len(condensed_data_holder[count][0])
+            ):  # starts iterating through the dataset, looking for the name in that
+                for j in range(
+                    1, len(data)
+                ):  # column, so it can append the values under the proper variables
                     try:
                         split_url = condensed_data_holder[count][0][i].split("/")
-                        for k in range(0, len(full_model_variable_list)):
-                            if "/" in full_model_variable_list[k]:
-                                full_model_variable_list[k] = split_url[len(split_url) - 1]
-                        if data[j][fieldcolumn] == condensed_data_holder[count][0][i]:  # in the dataframe, the name is in column 3
+                        for k, fmv in enumerate(full_model_variable_list):
+                            if "/" in fmv:
+                                full_model_variable_list[k] = split_url[-1]
+                        if (
+                            data[j][fieldcolumn] == condensed_data_holder[count][0][i]
+                        ):  # in the dataframe, the name is in column 3
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][aboutcolumn] == condensed_data_holder[count][0][
-                            i]:
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif data[j][aboutcolumn] == condensed_data_holder[count][0][i]:
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][aboutcolumn] == split_url[len(split_url)-1]: #this is in case the uri only works by querying the part after the last backslash
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            data[j][aboutcolumn] == split_url[len(split_url) - 1]
+                        ):  # this is in case the uri only works by querying the part after the last backslash
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif condensed_data_holder[count][0][
-                            i] in data[j][aboutcolumn]: #this is in case the uri only works by querying the part after the last backslash
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            condensed_data_holder[count][0][i] in data[j][aboutcolumn]
+                        ):  # this is in case the uri only works by querying the part after the last backslash
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif data[j][namecolumn] == condensed_data_holder[count][0][i]:  # in the dataframe, the name is in column 12
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            data[j][namecolumn] == condensed_data_holder[count][0][i]
+                        ):  # in the dataframe, the name is in column 12
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
-                        elif condensed_data_holder[count][0][i] == data[j][datacolumn]:  # in the dataframe, the name is in column 9
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
+                        elif (
+                            condensed_data_holder[count][0][i] == data[j][datacolumn]
+                        ):  # in the dataframe, the name is in column 9
                             condensed_data_holder[count][numrows][i] = data[j][
-                                valuecolumn]  # in the dataframe, the value is in column 2
-                            numrows = numrows + 1  # moves on to the next row to add the proper values
+                                valuecolumn
+                            ]  # in the dataframe, the value is in column 2
+                            numrows = (
+                                numrows + 1
+                            )  # moves on to the next row to add the proper values
                     except IndexError:
                         numrows = numrows + 1
                 numrows = 1  # resets to the first row for the next variable
             temp_list = condensed_data_holder[count]
-            for j in range(len(temp_list[0])-1, 0,-1):  # if the software appends a column with 0 as the heading, it removes this null column
+            for j in range(
+                len(temp_list[0]) - 1, 0, -1
+            ):  # if the software appends a column with 0 as the heading, it removes this null column
                 if temp_list[0][j] == "0" or temp_list[0][j] == "NaN":
                     for row in condensed_data_holder[count]:
                         row.pop(j)
             rowsize = len(condensed_data_holder[count][0])
             count1 = 0
             for i in range(0, rowsize):
                 for row in condensed_data_holder[count]:
                     if row[i] == 0 or row[i] == "NaN" or row[i] == "0":
                         count1 = count1 + 1
                 if count1 > len(condensed_data_holder[count]) - 2:
                     not_found_list.append(condensed_data_holder[count][0][i])
                 count1 = 0
-            for i in range(len(condensed_data_holder[count][0])):
-                if " " in condensed_data_holder[count][0][i]:
-                    condensed_data_holder[count][0][i] = condensed_data_holder[count][0][i].replace(" ", "_")
-            for i in range(len(independentvariables)):
-                if "/" in independentvariables[i]:
-                    splitted = independentvariables[i].split("/")
-                    independentvariables[i] = splitted[len(splitted)-1]
-                if " " in independentvariables[i]:
-                    independentvariables[i] = independentvariables[i].replace(" ", "_")
-            if " " in dep_var:
-                dep_var = dep_var.replace(" ", "_")
-            count = count + 1
+            for i, cdh in enumerate(condensed_data_holder[count][0]):
+                condensed_data_holder[count][0][i] = cdh.replace(" ", "_")
+            independentvariables = [
+                v.split("/")[-1].replace(" ", "_") for v in independentvariables
+            ]
+            dep_var = dep_var.replace(" ", "_")
+            count += 1
             if len(not_found_list) > 0:
-                print(
-                    "***********************************************************************************************************")
+                print("*" * 107)
                 print()
-                print("Your model was " + m)
-                print()
-                print(
-                    "The following variables were not found in " + nidm_file + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables.")
-                if (o is not None):
-                    f = open(o, "a")
-                    f.write("Your model was " + m)
-                    f.write(
-                        "The following variables were not found in " + nidm_file + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables.")
-                    f.close()
-                for i in range(0, len(not_found_list)):
-                    print(str(i + 1) + ". " + not_found_list[i])
-                    if (o is not None):
-                        f = open(o, "a")
-                        f.write(str(i + 1) + ". " + not_found_list[i])
-                        f.close()
-                for j in range(len(not_found_list)-1, 0,-1):
-                    not_found_list.pop(j)
-                not_found_count = not_found_count + 1
+                reporter.print("Your model was", m)
+                reporter.print()
+                reporter.print(
+                    "The following variables were not found in "
+                    + nidm_file
+                    + ". The model cannot run because this will skew the data. Try checking your spelling or use nidm_query.py to see other possible variables."
+                )
+                for i, nf in enumerate(not_found_list):
+                    reporter.print(f"{i+1}. {nf}")
+                not_found_list.clear()
+                not_found_count += 1
                 print()
         if not_found_count > 0:
-            exit(1)
-
+            sys.exit(1)
 
     else:
         print("ERROR: No query parameter provided.  See help:")
         print()
         os.system("pynidm linreg --help")
-        exit(1)
+        sys.exit(1)
 
-def dataparsing(): #The data is changed to a format that is usable by the linear regression method
+
+def dataparsing(
+    reporter,
+):  # The data is changed to a format that is usable by the linear regression method
     global condensed_data
     condensed_data = []
     for i in range(0, len(file_list)):
         condensed_data = condensed_data + condensed_data_holder[i]
     for i in range(len(condensed_data[0])):
-        if "/" in condensed_data[0][i]: #change any URLs to just the last part so contrasting works.
-            splitted = condensed_data[0][i].split("/")
-            condensed_data[0][i] = splitted[len(splitted) - 1]
-
-    """In this section, if there are less than 20 points, the model will be innacurate and there are too few variables for regularization.
-    That means that we warn the user that such errors can occur and ask them if they want to proceed.
-    The answer is stored in answer. If the user responds with N, it exits the code after writing the error to the output file (if there is one).
-    If the user says Y instead, the code runs, but stops before doing the regularization."""
+        if (
+            "/" in condensed_data[0][i]
+        ):  # change any URLs to just the last part so contrasting works.
+            split = condensed_data[0][i].split("/")
+            condensed_data[0][i] = split[len(split) - 1]
+
+    # In this section, if there are less than 20 points, the model will be
+    # inaccurate and there are too few variables for regularization.  That
+    # means that we warn the user that such errors can occur and ask them if
+    # they want to proceed.  The answer is stored in answer. If the user
+    # responds with N, it exits the code after writing the error to the output
+    # file (if there is one).  If the user says Y instead, the code runs, but
+    # stops before doing the regularization.
     global answer
     answer = "?"
-    if(len(condensed_data)-1)<20:
-        print("\nYour data set has less than 20 points, which means the model calculated may not be accurate due to a lack of data. ")
+    if (len(condensed_data) - 1) < 20:
+        print(
+            "\nYour data set has less than 20 points, which means the model calculated may not be accurate due to a lack of data. "
+        )
         print("This means you cannot regularize the data either.")
-        import warnings
         warnings.filterwarnings("ignore")
         answer = input("Continue anyways? Y or N: ")
-        if (o is not None):
-            f = open(o, "a")
-            f.write("Your model was " + m)
-            f.write(
-                "\n\nThere was a lack of data (<20 points) in your model, which may result in inaccuracies. In addition, a regularization cannot and will not be performed.\n")
-            f.close()
+        reporter.print_file("Your model was", m)
+        reporter.print_file(
+            "\n\nThere was a lack of data (<20 points) in your model, which may result in inaccuracies. In addition, a regularization cannot and will not be performed.\n"
+        )
     if "n" in answer.lower():
         print("\nModel halted.")
-        if (o is not None):
-            f = open(o, "a")
-            f.write("Your model was " + m)
-            f.write("Due to a lack of data (<20 points), you stopped the model because the results may have been innacurate.")
-            f.close()
-        exit(1)
-    x = pd.read_csv(opencsv(condensed_data))  # changes the dataframe to a csv to make it easier to work with
+        reporter.print_file("Your model was", m)
+        reporter.print_file(
+            "Due to a lack of data (<20 points), you stopped the model because the results may have been inaccurate."
+        )
+        sys.exit(1)
+    x = pd.read_csv(
+        opencsv(condensed_data)
+    )  # changes the dataframe to a csv to make it easier to work with
     x.head()  # prints what the csv looks like
     x.dtypes  # checks data format
     obj_df = x.select_dtypes  # puts all the variables in a dataset
     x.shape  # says number of rows and columns in form of tuple
     x.describe()  # says dataset statistics
-    obj_df = x.select_dtypes(include=['object']).copy()  # takes everything that is an object (not float or int) and puts it in a new dataset
+    obj_df = x.select_dtypes(
+        include=["object"]
+    ).copy()  # takes everything that is an object (not float or int) and puts it in a new dataset
     obj_df.head()  # prints the new dataset
-    int_df = x.select_dtypes(include=['int64']).copy()  # takes everything that is an int and puts it in a new dataset
-    float_df = x.select_dtypes(include=['float64']).copy()  # takes everything that is a float and puts it in a new dataset
+    int_df = x.select_dtypes(
+        include=["int64"]
+    ).copy()  # takes everything that is an int and puts it in a new dataset
+    float_df = x.select_dtypes(
+        include=["float64"]
+    ).copy()  # takes everything that is a float and puts it in a new dataset
     df_int_float = pd.concat([float_df, int_df], axis=1)
     variables = []  # starts a list that will store all variables that are not numbers
     for i in range(1, len(condensed_data)):  # goes through each variable
         for j in range(len(condensed_data[0])):  # in the 2D array
             try:  # if the value of the field can be turned into a float (is numerical)
                 float(condensed_data[i][j])  # this means it's a number
             except ValueError:  # if it can't be (is a string)
-                if condensed_data[0][j] not in variables:  # adds the variable name to the list if it isn't there already
+                if (
+                    condensed_data[0][j] not in variables
+                ):  # adds the variable name to the list if it isn't there already
                     variables.append(condensed_data[0][j])
-    le = preprocessing.LabelEncoder()  # anything involving le shows the encoding of categorical variables
-    for i in range(len(variables)):
-        le.fit(obj_df[variables[i]].astype(str))
-    obj_df_trf = obj_df.astype(str).apply(le.fit_transform)  # transforms the categorical variables into numbers.
-    global df_final #also used in linreg()
+    le = (
+        preprocessing.LabelEncoder()
+    )  # anything involving le shows the encoding of categorical variables
+    for v in variables:
+        le.fit(obj_df[v].astype(str))
+    obj_df_trf = obj_df.astype(str).apply(
+        le.fit_transform
+    )  # transforms the categorical variables into numbers.
+    global df_final  # also used in linreg()
     if not obj_df_trf.empty:
-        df_final = pd.concat([df_int_float, obj_df_trf], axis=1)  # join_axes=[df_int_float.index])
+        df_final = pd.concat(
+            [df_int_float, obj_df_trf], axis=1
+        )  # join_axes=[df_int_float.index])
     else:
         df_final = df_int_float
-    df_final.head()  # shows the final dataset with all the encoding
-    print(df_final)  # prints the final dataset
-    print()
-    print("***********************************************************************************************************")
-    print()
-    if (o is not None):
-        f = open(o,"a")
-        f.write(df_final.to_string(header=True, index=True))
-        f.write("\n\n***********************************************************************************************************")
-        f.write("\n\nModel Results: ")
-        f.close()
+    reporter.print(df_final.to_string(header=True, index=True))
+    reporter.print("\n\n" + ("*" * 107))
+    reporter.print("\n\nModel Results: ")
+
 
-def linreg(): #actual linear regression
+def linreg(reporter):  # actual linear regression
     print("Model Results: ")
-    #printing the corrected model_string
+    # printing the corrected model_string
     model_string = []
     model_string.append(dep_var)
     model_string.append(" ~ ")
-    for i in range(0, len(full_model_variable_list)):
-        model_string.append(full_model_variable_list[i])
+    for fmv in full_model_variable_list:
+        model_string.append(fmv)
         model_string.append(" + ")
     model_string.pop(-1)
     global full_model
-    full_model = ''.join(model_string)
-    print(full_model) #prints model
+    full_model = "".join(model_string)
+    print(full_model)  # prints model
     print()
-    print("***********************************************************************************************************")
+    print("*" * 107)
     print()
     index = 0
-    global levels #also used in contrasting()
+    global levels  # also used in contrasting()
     levels = []
     for i in range(len(condensed_data[0])):
         if c == condensed_data[0][i]:
             index = i
-    for i in range(1,len(condensed_data)):
+    for i in range(1, len(condensed_data)):
         if condensed_data[i][index] not in levels:
             levels.append(condensed_data[i][index])
-    for i in range(len(levels)):
-        levels[i] = i
+    levels = list(range(len(levels)))
 
-    #Beginning of the linear regression
+    # Beginning of the linear regression
     global X
     global y
     if "*" in m:
-        #correcting the format of the model string
+        # correcting the format of the model string
         model_string = []
         model_string.append(dep_var)
         model_string.append(" ~ ")
-        for i in range(0,len(full_model_variable_list)):
-            model_string.append(full_model_variable_list[i])
+        for fmv in full_model_variable_list:
+            model_string.append(fmv)
             model_string.append(" + ")
         model_string.pop(-1)
-        for i in range(0,len(model_string)):
-            if "*" in model_string[i]:
-                replacement = model_string[i].split("*")
+        for i, mdl in enumerate(model_string):
+            if "*" in mdl:
+                replacement = mdl.split("*")
                 model_string[i] = replacement[0] + ":" + replacement[1]
-               #makes sure the model is in the right format.
-        string = ''.join(model_string)
+            # makes sure the model is in the right format.
+        string = "".join(model_string)
         y, X = dmatrices(string, df_final)
     else:
-        X = df_final[independentvariables]  # gets the modified values of the independent variables
-        y = df_final[dep_var] # gets the modified values of the dependent variable
+        X = df_final[
+            independentvariables
+        ]  # gets the modified values of the independent variables
+        y = df_final[dep_var]  # gets the modified values of the dependent variable
     if not c:
-        #The linear regression
+        # The linear regression
         regressor = LinearRegression()
         regressor.fit(X, y)
-        regression = regressor.fit(X, y)
-        #Data about the linear regression, starting without contrast
+        # Data about the linear regression, starting without contrast
         X2 = sm.add_constant(X)
         statistics = sm.OLS(y, X2)
         finalstats = statistics.fit()
-        print(finalstats.summary())
-        if (o is not None):
-            # concatenate data frames
-            """f = open(o,"a")
-            f.write(full_model)
-            f.write("\n*************************************************************************************\n")
-            f.write(finalstats.summary())
-            f.close()"""
-            sys.stdout = open(o, "a")
-            print(full_model)
-            print("\n*************************************************************************************\n")
-            print(finalstats.summary())
-            sys.stdout.close()
+        # concatenate data frames
+        reporter.print_file(full_model)
+        reporter.print_file("\n" + ("*" * 85) + "\n")
+        reporter.print(finalstats.summary())
         return finalstats
-def contrasting():
+
+
+def contrasting(reporter):
     global c
+    global full_model_variable_list
     if c:
-        #to account for multiple contrast variables
+        # to account for multiple contrast variables
         contrastvars = []
         if "," in c:
             contrastvars = c.split(",")
-        for i in range(len(contrastvars)):
-            contrastvars[i] = contrastvars[i].strip()
-            if " " in contrastvars[i]:
-                contrastvars[i]=contrastvars[i].replace(" ","_")
-            if "/" in contrastvars[i]: #to account for URLs
-                splitted = contrastvars[i].split("/")
-                contrastvars[i] = splitted[len(splitted) - 1]
-        else:
-            splitted = c.split("/") #to account for URLs
-            c = splitted[len(splitted) - 1]
-
-        ind_vars_no_contrast_var = ''
+        contrastvars = [
+            v.strip().replace(" ", "_").split("/")[-1] for v in contrastvars
+        ]
+        c = c.split("/")[-1]  # to account for URLs
+        ind_vars_no_contrast_var = ""
         index = 1
-        for i in range(len(full_model_variable_list)):
-            if "/" in full_model_variable_list[i]:
-                splitted = full_model_variable_list[i].split("/")
-                full_model_variable_list[i] = splitted[len(splitted) - 1]
-            if " " in full_model_variable_list[i]:
-                full_model_variable_list[i]=full_model_variable_list[i].replace(" ","_")
+        full_model_variable_list = [
+            v.split("/")[-1].replace(" ", "_") for v in full_model_variable_list
+        ]
         for var in full_model_variable_list:
-            if var != c and not(var in contrastvars):
+            if var != c and var not in contrastvars:
                 if index == 1:
                     ind_vars_no_contrast_var = var
                     index += 1
                 else:
-                    ind_vars_no_contrast_var = ind_vars_no_contrast_var + " + " + var
-        if len(contrastvars)>0:
-            contraststring = ' + '.join(contrastvars)
+                    ind_vars_no_contrast_var += " + " + var
+        if len(contrastvars) > 0:
+            contraststring = " + ".join(contrastvars)
         else:
             if " " in c:
                 c = c.replace(" ", "_")
-            contraststring=c
+            contraststring = c
         # With contrast (treatment coding)
-        print("\n\nTreatment (Dummy) Coding: Dummy coding compares each level of the categorical variable to a base reference level. The base reference level is the value of the intercept.")
-        ctrst = Treatment(reference=0).code_without_intercept(levels)
-        mod = ols(dep_var + " ~ " + ind_vars_no_contrast_var + " + C(" + contraststring + ", Treatment)", data=df_final)
+        reporter.print_file("\n" + full_model)
+        reporter.print_file("\n\n" + ("*" * 107))
+        reporter.print(
+            "\n\nTreatment (Dummy) Coding: Dummy coding compares each level of the categorical variable to a base reference level. The base reference level is the value of the intercept."
+        )
+        Treatment(reference=0).code_without_intercept(levels)
+        mod = ols(
+            dep_var
+            + " ~ "
+            + ind_vars_no_contrast_var
+            + " + C("
+            + contraststring
+            + ", Treatment)",
+            data=df_final,
+        )
         res = mod.fit()
-        print("With contrast (treatment coding)")
-        print(res.summary())
-        if (o is not None):
-            # concatenate data frames
-            f = open(o, "a")
-            f.write("\n" + full_model)
-            f.write(
-                "\n\n***********************************************************************************************************")
-
-            f.write("\n\n\n\nTreatment (Dummy) Coding: Dummy coding compares each level of the categorical variable to a base reference level. The base reference level is the value of the intercept.")
-            f.write("With contrast (treatment coding)")
-            f.write(res.summary().as_text())
-            f.close()
+        reporter.print("With contrast (treatment coding)")
+        reporter.print(res.summary())
+
         # Defining the Simple class
         def _name_levels(prefix, levels):
-            return ["[%s%s]" % (prefix, level) for level in levels]
+            return [f"[{prefix}{level}]" for level in levels]
 
-        class Simple(object):
+        class Simple:
             def _simple_contrast(self, levels):
                 nlevels = len(levels)
-                contr = -1. / nlevels * np.ones((nlevels, nlevels - 1))
-                contr[1:][np.diag_indices(nlevels - 1)] = (nlevels - 1.) / nlevels
+                contr = -1.0 / nlevels * np.ones((nlevels, nlevels - 1))
+                contr[1:][np.diag_indices(nlevels - 1)] = (nlevels - 1.0) / nlevels
                 return contr
 
             def code_with_intercept(self, levels):
-                c = np.column_stack((np.ones(len(levels)), self._simple_contrast(levels)))
+                c = np.column_stack(
+                    (np.ones(len(levels)), self._simple_contrast(levels))
+                )
                 return ContrastMatrix(c, _name_levels("Simp.", levels))
 
             def code_without_intercept(self, levels):
                 c = self._simple_contrast(levels)
                 return ContrastMatrix(c, _name_levels("Simp.", levels[:-1]))
 
-        ctrst = Simple().code_without_intercept(levels)
-        mod = ols(dep_var + " ~ " + ind_vars_no_contrast_var + " + C(" + contraststring + ", Simple)", data=df_final)
+        Simple().code_without_intercept(levels)
+        mod = ols(
+            dep_var
+            + " ~ "
+            + ind_vars_no_contrast_var
+            + " + C("
+            + contraststring
+            + ", Simple)",
+            data=df_final,
+        )
         res = mod.fit()
-        print("\n\nSimple Coding: Like Treatment Coding, Simple Coding compares each level to a fixed reference level. However, with simple coding, the intercept is the grand mean of all the levels of the factors.")
-        print(res.summary())
-        if (o is not None):
-            # concatenate data frames
-            f = open(o, "a")
-            f.write("\n\n\nSimple Coding: Like Treatment Coding, Simple Coding compares each level to a fixed reference level. However, with simple coding, the intercept is the grand mean of all the levels of the factors.")
-            f.write(res.summary().as_text())
-            f.close()
-
-        #With contrast (sum/deviation coding)
-        ctrst = Sum().code_without_intercept(levels)
-        mod = ols(dep_var + " ~ " + ind_vars_no_contrast_var + " + C(" + contraststring + ", Sum)", data=df_final)
+        reporter.print(
+            "\n\nSimple Coding: Like Treatment Coding, Simple Coding compares each level to a fixed reference level. However, with simple coding, the intercept is the grand mean of all the levels of the factors."
+        )
+        reporter.print(res.summary())
+
+        # With contrast (sum/deviation coding)
+        Sum().code_without_intercept(levels)
+        mod = ols(
+            dep_var
+            + " ~ "
+            + ind_vars_no_contrast_var
+            + " + C("
+            + contraststring
+            + ", Sum)",
+            data=df_final,
+        )
         res = mod.fit()
-        print("\n\nSum (Deviation) Coding: Sum coding compares the mean of the dependent variable for a given level to the overall mean of the dependent variable over all the levels.")
-        print(res.summary())
-        if (o is not None):
-            # concatenate data frames
-            f = open(o, "a")
-            f.write("\n\n\nSum (Deviation) Coding: Sum coding compares the mean of the dependent variable for a given level to the overall mean of the dependent variable over all the levels.")
-            f.write(res.summary().as_text())
-            f.close()
-
-        #With contrast (backward difference coding)
-        ctrst = Diff().code_without_intercept(levels)
-        mod = ols(dep_var + " ~ " + ind_vars_no_contrast_var + " + C(" + contraststring + ", Diff)", data=df_final)
+        reporter.print(
+            "\n\nSum (Deviation) Coding: Sum coding compares the mean of the dependent variable for a given level to the overall mean of the dependent variable over all the levels."
+        )
+        reporter.print(res.summary())
+
+        # With contrast (backward difference coding)
+        Diff().code_without_intercept(levels)
+        mod = ols(
+            dep_var
+            + " ~ "
+            + ind_vars_no_contrast_var
+            + " + C("
+            + contraststring
+            + ", Diff)",
+            data=df_final,
+        )
         res = mod.fit()
-        print("\n\nBackward Difference Coding: In backward difference coding, the mean of the dependent variable for a level is compared with the mean of the dependent variable for the prior level.")
-        print(res.summary())
-        if (o is not None):
-            # concatenate data frames
-            f = open(o, "a")
-            f.write("\n\n\nBackward Difference Coding: In backward difference coding, the mean of the dependent variable for a level is compared with the mean of the dependent variable for the prior level.")
-            f.write(res.summary().as_text())
-            f.close()
-
-        #With contrast (Helmert coding)
-        ctrst = Helmert().code_without_intercept(levels)
-        mod = ols(dep_var + " ~ " + ind_vars_no_contrast_var + " + C(" + contraststring + ", Helmert)", data=df_final)
+        reporter.print(
+            "\n\nBackward Difference Coding: In backward difference coding, the mean of the dependent variable for a level is compared with the mean of the dependent variable for the prior level."
+        )
+        reporter.print(res.summary())
+
+        # With contrast (Helmert coding)
+        Helmert().code_without_intercept(levels)
+        mod = ols(
+            dep_var
+            + " ~ "
+            + ind_vars_no_contrast_var
+            + " + C("
+            + contraststring
+            + ", Helmert)",
+            data=df_final,
+        )
         res = mod.fit()
-        print("\n\nHelmert Coding: Our version of Helmert coding is sometimes referred to as Reverse Helmert Coding. The mean of the dependent variable for a level is compared to the mean of the dependent variable over all previous levels. Hence, the name reverse being sometimes applied to differentiate from forward Helmert coding.")
-        print(res.summary())
-        if (o is not None):
-            # concatenate data frames
-            f = open(o, "a")
-            f.write("\n\n\nHelmert Coding: Our version of Helmert coding is sometimes referred to as Reverse Helmert Coding. The mean of the dependent variable for a level is compared to the mean of the dependent variable over all previous levels. Hence, the name reverse being sometimes applied to differentiate from forward Helmert coding.")
-            f.write(res.summary().as_text())
-            f.close()
+        reporter.print(
+            "\n\nHelmert Coding: Our version of Helmert coding is sometimes referred to as Reverse Helmert Coding. The mean of the dependent variable for a level is compared to the mean of the dependent variable over all previous levels. Hence, the name reverse being sometimes applied to differentiate from forward Helmert coding."
+        )
+        reporter.print(res.summary())
+
 
-def regularizing():
-    if (r== ("L1" or "Lasso" or "l1" or "lasso") and not("y" in answer.lower())): #does it say L1, and has the user chosen to go ahead with running the code?
+def regularizing(reporter):
+    # does it say L1, and has the user chosen to go ahead with running the code?
+    if r in ("L1", "Lasso", "l1", "lasso") and "y" not in answer.lower():
         # Loop to compute the cross-validation scores
         max_cross_val_alpha = 1
-        max_cross_val_score = -1000000000.000 #making it a super negative number initially
+        max_cross_val_score = (
+            -1000000000.000
+        )  # making it a super negative number initially
         for x in range(1, MAX_ALPHA):
             lassoModel = Lasso(alpha=x, tol=0.0925)
             lassoModel.fit(X, y)
             scores = cross_val_score(lassoModel, X, y, cv=10)
             avg_cross_val_score = mean(scores) * 100
-            #figure out which setting of the regularization parameter results in the max likelihood score
+            # figure out which setting of the regularization parameter results in the max likelihood score
             if avg_cross_val_score > max_cross_val_score:
                 max_cross_val_alpha = x
                 max_cross_val_score = avg_cross_val_score
 
         # Building and fitting the Lasso Regression Model
         lassoModelChosen = Lasso(alpha=max_cross_val_alpha, tol=0.0925)
         lassoModelChosen.fit(X, y)
-        print("\nLasso regression model:")
-        print("Alpha with maximum likelihood (range: 1 to %d) = %f" %(MAX_ALPHA, max_cross_val_alpha))
-        print("Current Model Score = %f" %(lassoModelChosen.score(X, y)))
+        reporter.print("\nLasso regression model:")
+        reporter.print(
+            f"Alpha with maximum likelihood (range: 1 to {MAX_ALPHA}) = {max_cross_val_alpha}"
+        )
+        reporter.print(f"Current Model Score = {lassoModelChosen.score(X, y)}")
         index = 0
-        print("\nCoefficients:")
-        if (o is not None):
-            # concatenate data frames
-            f = open(o, "a")
-            f.write("\n\nLasso regression model:")
-            f.write("\nAlpha with maximum likelihood (range: 1 to %d) = %f" %(MAX_ALPHA, max_cross_val_alpha))
-            f.write("\nCurrent Model Score = %f" %(lassoModelChosen.score(X, y)))
-            f.write("\n\nCoefficients:")
-            f.close()
+        reporter.print("\nCoefficients:")
         for var in full_model_variable_list:
-            print("%s \t %f" %(var,lassoModelChosen.coef_[index]))
-            if (o is not None):
-                with open(o, "a") as f:
-                    f.write("\n%s \t %f" %(var, lassoModelChosen.coef_[index]))
-                f.close()
-            index = index + 1
-        print("Intercept: %f" %(lassoModelChosen.intercept_))
-        if (o is not None):
-            with open(o, "a") as f:
-                f.write("\nIntercept: %f" %(lassoModelChosen.intercept_))
-                f.close()
-        print()
+            reporter.print(f"{var} \t {lassoModelChosen.coef_[index]}")
+            index += 1
+        reporter.print(f"Intercept: {lassoModelChosen.intercept_}")
+        reporter.print()
 
-    if (r== ("L2" or "Ridge" or "l2" or "Ridge") and not("y" in answer.lower())): #does it say L2, and has the user chosen to go ahead with running the code?
+    # does it say L2, and has the user chosen to go ahead with running the code?
+    if r in ("L2", "Ridge", "l2", "ridge") and "y" not in answer.lower():
         # Loop to compute the different values of cross-validation scores
         max_cross_val_alpha = 1
-        max_cross_val_score = -1000000000.000  # making it a super negative number initially
+        max_cross_val_score = (
+            -1000000000.000
+        )  # making it a super negative number initially
         for x in range(1, MAX_ALPHA):
             ridgeModel = Ridge(alpha=x, tol=0.0925)
             ridgeModel.fit(X, y)
             scores = cross_val_score(ridgeModel, X, y, cv=10)
             avg_cross_val_score = mean(scores) * 100
             # figure out which setting of the regularization parameter results in the max likelihood score
             if avg_cross_val_score > max_cross_val_score:
                 max_cross_val_alpha = x
                 max_cross_val_score = avg_cross_val_score
 
         # Building and fitting the Lasso Regression Model
         ridgeModelChosen = Ridge(alpha=max_cross_val_alpha, tol=0.0925)
         ridgeModelChosen.fit(X, y)
-        print("\nRidge regression model:")
-        print("Alpha with maximum likelihood (range: 1 to %d) = %f" % (MAX_ALPHA, max_cross_val_alpha))
-        print("Current Model Score = %f" % (ridgeModelChosen.score(X, y)))
+        reporter.print("\nRidge regression model:")
+        reporter.print(
+            f"Alpha with maximum likelihood (range: 1 to {MAX_ALPHA}) = {max_cross_val_alpha}"
+        )
+        reporter.print(f"Current Model Score = {ridgeModelChosen.score(X, y)}")
         index = 0
-        """This numpy_conversion part was necessary because for the ridge model, all the coefficients get stored in a
-        numpy array, and the conversion is necessary to get the coefficients. However, it is only needed if the model
-        has interacting variables."""
+        # This numpy_conversion part was necessary because for the ridge model,
+        # all the coefficients get stored in a numpy array, and the conversion
+        # is necessary to get the coefficients. However, it is only needed if
+        # the model has interacting variables.
         numpy_conversion = False
         for var in full_model_variable_list:
             if ("*" in var) or (":" in var):
                 numpy_conversion = True
-        if (o is not None):
-            # concatenate data frames
-            f = open(o, "a")
-            f.write("\n\nRidge regression model:")
-            f.write("\nAlpha with maximum likelihood (range: 1 to %d) = %f" %(MAX_ALPHA, max_cross_val_alpha))
-            f.write("\nCurrent Model Score = %f" %(ridgeModelChosen.score(X, y)))
-            f.write("\n\nCoefficients:")
-            f.close()
-        print("\nCoefficients:")
+        reporter.print("\nCoefficients:")
         if numpy_conversion:
             coeff_list = ridgeModelChosen.coef_[index].tolist()
             coeff_list.pop(0)
             for var in full_model_variable_list:
-                print("%s \t %f" %(var, coeff_list[index]))
-                if (o is not None):
-                    with open(o,"a") as f:
-                        f.write("\n%s \t %f" % (var, coeff_list[index]))
-                index = index + 1
-            print("Intercept: %f" % (ridgeModelChosen.intercept_))
-            if (o is not None):
-                with open(o, "a") as f:
-                    f.write("\nIntercept: %f" % (ridgeModelChosen.intercept_))
-                f.close()
-            print()
+                reporter.print(f"{var} \t {coeff_list[index]}")
+                index += 1
+            reporter.print(f"Intercept: {ridgeModelChosen.intercept_}")
+            reporter.print()
         else:
             for var in full_model_variable_list:
-                print("%s \t %f" % (var, ridgeModelChosen.coef_[index]))
-                if (o is not None):
-                    with open(o,"a") as f:
-                        f.write("\n%s \t %f" % (var, ridgeModelChosen.coef_[index]))
-                index = index + 1
-            print("Intercept: %f" % (ridgeModelChosen.intercept_))
-            if (o is not None):
-                with open(o, "a") as f:
-                    f.write("\nIntercept: %f" % (ridgeModelChosen.intercept_))
-                f.close()
-            print()
+                reporter.print(f"{var} \t {ridgeModelChosen.coef_[index]}")
+                index += 1
+            reporter.print(f"Intercept: {ridgeModelChosen.intercept_}")
+            reporter.print()
+
+
 def opencsv(data):
     """saves a list of lists as a csv and opens"""
-    import tempfile
-    import os
-    import csv
-    handle, fn = tempfile.mkstemp(suffix='.csv')
-    with os.fdopen(handle,"w", encoding='utf8',errors='surrogateescape',newline='') as f:
+    handle, fn = tempfile.mkstemp(suffix=".csv")
+    with os.fdopen(
+        handle, "w", encoding="utf8", errors="surrogateescape", newline=""
+    ) as f:
         writer = csv.writer(f)
         writer.writerows(data)
     return fn
 
+
 # it can be used calling the script `python nidm_query.py -nl ... -q ..
 if __name__ == "__main__":
-
     linear_regression()
-
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/nidm_query.py` & `pynidm-4.0.0/src/nidm/experiment/tools/nidm_query.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,232 +1,285 @@
-#!/usr/bin/env python
+"""This program provides query functionality for NIDM-Experiment files"""
 
-#**************************************************************************************
-#**************************************************************************************
-#  nidm_query.py
-#  License: Apache License, Version 2.0
-#**************************************************************************************
-#**************************************************************************************
-# Date: 8-1-18                 Coded by: David Keator (dbkeator@gmail.com)
-# Filename: nidm_query.py
-#
-# Program description:  This program provides query functionalty for NIDM-Experiment files
-#
-#
-#**************************************************************************************
-# Development environment: Python - PyCharm IDE
-#
-#**************************************************************************************
-# System requirements:  Python 3.X
-# Libraries: os, sys, rdflib, pandas, argparse, logging
-#**************************************************************************************
-# Start date: 8-1-18
-# Update history:
-# DATE            MODIFICATION				Who
-#
-#
-#**************************************************************************************
-# Programmer comments:
-#
-#
-#**************************************************************************************
-#**************************************************************************************
-
-import os, sys
-from rdflib import Graph, util
+from json import dumps
+import os
+import sys
+import click
+from click_option_group import RequiredMutuallyExclusiveOptionGroup, optgroup
 import pandas as pd
-from argparse import ArgumentParser
-import logging
-import csv
-from nidm.experiment.Query import sparql_query_nidm, GetParticipantIDs,GetProjectInstruments,GetProjectsUUID,GetInstrumentVariables,GetDataElements,GetBrainVolumes,GetBrainVolumeDataElements
 from nidm.experiment.CDE import getCDEs
-import click
-from click_option_group import optgroup, RequiredMutuallyExclusiveOptionGroup
+from nidm.experiment.Query import (
+    GetBrainVolumeDataElements,
+    GetBrainVolumes,
+    GetDataElements,
+    GetInstrumentVariables,
+    GetParticipantIDs,
+    GetProjectInstruments,
+    GetProjectsUUID,
+    sparql_query_nidm,
+)
 from nidm.experiment.tools.click_base import cli
 from nidm.experiment.tools.rest import RestParser
-from json import dumps, loads
 
 
 @cli.command()
-@click.option("--nidm_file_list", "-nl", required=True,
-              help="A comma separated list of NIDM files with full path")
-@click.option("--cde_file_list", "-nc", required=False,
-              help="A comma separated list of NIDM CDE files with full path. Can also be set in the CDE_DIR environment variable")
-@optgroup.group('Query Type',help='Pick among the following query type selections',cls=RequiredMutuallyExclusiveOptionGroup)
-@optgroup.option("--query_file", "-q", type=click.File('r'),
-              help="Text file containing a SPARQL query to execute")
-@optgroup.option("--get_participants", "-p", is_flag=True,
-              help="Parameter, if set, query will return participant IDs and prov:agent entity IDs")
-@optgroup.option("--get_instruments", "-i", is_flag=True,
-              help="Parameter, if set, query will return list of onli:assessment-instrument:")
-@optgroup.option("--get_instrument_vars", "-iv", is_flag=True,
-              help="Parameter, if set, query will return list of onli:assessment-instrument: variables")
-@optgroup.option("--get_dataelements", "-de", is_flag=True,
-              help="Parameter, if set, will return all DataElements in NIDM file")
-@optgroup.option("--get_dataelements_brainvols", "-debv", is_flag=True,
-              help="Parameter, if set, will return all brain volume DataElements in NIDM file along with details")
-@optgroup.option("--get_brainvols", "-bv", is_flag=True,
-              help="Parameter, if set, will return all brain volume data elements and values along with participant IDs in NIDM file")
-@optgroup.option("--get_fields", "-gf",
-              help="This parameter will return data for only the field names in the comma separated list (e.g. -gf age,fs_00003) from all nidm files supplied")
-@optgroup.option("--uri", "-u",
-              help="A REST API URI query")
-@click.option("--output_file", "-o", required=False,
-              help="Optional output file (CSV) to store results of query")
-@click.option("-j/-no_j", required=False, default=False,
-              help="Return result of a uri query as JSON")
-@click.option("--blaze", "-bg", required=False,
-              help="Base URL for Blazegraph. Ex: http://172.19.0.2:9999/blazegraph/sparql")
-@click.option('-v', '--verbosity', required=False, help="Verbosity level 0-5, 0 is default", default="0")
-
-def query(nidm_file_list, cde_file_list, query_file, output_file, get_participants, get_instruments, get_instrument_vars, get_dataelements, get_brainvols,get_dataelements_brainvols, get_fields, uri, blaze, j, verbosity):
+@click.option(
+    "--nidm_file_list",
+    "-nl",
+    required=True,
+    help="A comma separated list of NIDM files with full path",
+)
+@click.option(
+    "--cde_file_list",
+    "-nc",
+    required=False,
+    help="A comma separated list of NIDM CDE files with full path. Can also be set in the CDE_DIR environment variable",
+)
+@optgroup.group(
+    "Query Type",
+    help="Pick among the following query type selections",
+    cls=RequiredMutuallyExclusiveOptionGroup,
+)
+@optgroup.option(
+    "--query_file",
+    "-q",
+    type=click.File("r"),
+    help="Text file containing a SPARQL query to execute",
+)
+@optgroup.option(
+    "--get_participants",
+    "-p",
+    is_flag=True,
+    help="Parameter, if set, query will return participant IDs and prov:agent entity IDs",
+)
+@optgroup.option(
+    "--get_instruments",
+    "-i",
+    is_flag=True,
+    help="Parameter, if set, query will return list of onli:assessment-instrument:",
+)
+@optgroup.option(
+    "--get_instrument_vars",
+    "-iv",
+    is_flag=True,
+    help="Parameter, if set, query will return list of onli:assessment-instrument: variables",
+)
+@optgroup.option(
+    "--get_dataelements",
+    "-de",
+    is_flag=True,
+    help="Parameter, if set, will return all DataElements in NIDM file",
+)
+@optgroup.option(
+    "--get_dataelements_brainvols",
+    "-debv",
+    is_flag=True,
+    help="Parameter, if set, will return all brain volume DataElements in NIDM file along with details",
+)
+@optgroup.option(
+    "--get_brainvols",
+    "-bv",
+    is_flag=True,
+    help="Parameter, if set, will return all brain volume data elements and values along with participant IDs in NIDM file",
+)
+@optgroup.option(
+    "--get_fields",
+    "-gf",
+    help="This parameter will return data for only the field names in the comma separated list (e.g. -gf age,fs_00003) from all nidm files supplied",
+)
+@optgroup.option("--uri", "-u", help="A REST API URI query")
+@click.option(
+    "--output_file",
+    "-o",
+    required=False,
+    help="Optional output file (CSV) to store results of query",
+)
+@click.option(
+    "-j/-no_j",
+    required=False,
+    default=False,
+    help="Return result of a uri query as JSON",
+)
+@click.option(
+    "--blaze",
+    "-bg",
+    required=False,
+    help="Base URL for Blazegraph. Ex: http://172.19.0.2:9999/blazegraph/sparql",
+)
+@click.option(
+    "-v",
+    "--verbosity",
+    required=False,
+    help="Verbosity level 0-5, 0 is default",
+    default="0",
+)
+def query(
+    nidm_file_list,
+    cde_file_list,
+    query_file,
+    output_file,
+    get_participants,
+    get_instruments,
+    get_instrument_vars,
+    get_dataelements,
+    get_brainvols,
+    get_dataelements_brainvols,
+    get_fields,
+    uri,
+    blaze,
+    j,
+    verbosity,
+):
     """
     This function provides query support for NIDM graphs.
     """
-    #query result list
-    results = []
-
     # if there is a CDE file list, seed the CDE cache
     if cde_file_list:
         getCDEs(cde_file_list.split(","))
 
     if blaze:
         os.environ["BLAZEGRAPH_URL"] = blaze
-        print("setting BLAZEGRAPH_URL to {}".format(blaze))
+        print(f"setting BLAZEGRAPH_URL to {blaze}")
 
     if get_participants:
-        df = GetParticipantIDs(nidm_file_list.split(','),output_file=output_file)
-        if ((output_file) is None):
-
+        df = GetParticipantIDs(nidm_file_list.split(","), output_file=output_file)
+        if (output_file) is None:
             print(df.to_string())
 
-
         return df
     elif get_instruments:
-        #first get all project UUIDs then iterate and get instruments adding to output dataframe
-        project_list = GetProjectsUUID(nidm_file_list.split(','))
-        count=1
+        # first get all project UUIDs then iterate and get instruments adding to output dataframe
+        project_list = GetProjectsUUID(nidm_file_list.split(","))
+        count = 1
         for project in project_list:
             if count == 1:
-                df = GetProjectInstruments(nidm_file_list.split(','),project_id=project)
-                count+=1
+                df = GetProjectInstruments(
+                    nidm_file_list.split(","), project_id=project
+                )
+                count += 1
             else:
-                df = df.append(GetProjectInstruments(nidm_file_list.split(','),project_id=project))
-
-        #write dataframe
-        #if output file parameter specified
-        if (output_file is not None):
-
+                df = df.append(
+                    GetProjectInstruments(nidm_file_list.split(","), project_id=project)
+                )
+
+        # write dataframe
+        # if output file parameter specified
+        if output_file is not None:
             df.to_csv(output_file)
-            #with open(output_file,'w') as myfile:
+            # with open(output_file,'w', encoding="utf-8") as myfile:
             #    wr=csv.writer(myfile,quoting=csv.QUOTE_ALL)
             #    wr.writerow(df)
 
-            #pd.DataFrame.from_records(df,columns=["Instruments"]).to_csv(output_file)
+            # pd.DataFrame.from_records(df,columns=["Instruments"]).to_csv(output_file)
         else:
             print(df.to_string())
     elif get_instrument_vars:
-        #first get all project UUIDs then iterate and get instruments adding to output dataframe
-        project_list = GetProjectsUUID(nidm_file_list.split(','))
-        count=1
+        # first get all project UUIDs then iterate and get instruments adding to output dataframe
+        project_list = GetProjectsUUID(nidm_file_list.split(","))
+        count = 1
         for project in project_list:
             if count == 1:
-                df = GetInstrumentVariables(nidm_file_list.split(','),project_id=project)
-                count+=1
+                df = GetInstrumentVariables(
+                    nidm_file_list.split(","), project_id=project
+                )
+                count += 1
             else:
-                df = df.append(GetInstrumentVariables(nidm_file_list.split(','),project_id=project))
-
-        #write dataframe
-        #if output file parameter specified
-        if (output_file is not None):
-
+                df = df.append(
+                    GetInstrumentVariables(
+                        nidm_file_list.split(","), project_id=project
+                    )
+                )
+
+        # write dataframe
+        # if output file parameter specified
+        if output_file is not None:
             df.to_csv(output_file)
         else:
             print(df.to_string())
     elif get_dataelements:
         datael = GetDataElements(nidm_file_list=nidm_file_list)
-         #if output file parameter specified
-        if (output_file is not None):
-
+        # if output file parameter specified
+        if output_file is not None:
             datael.to_csv(output_file)
         else:
             print(datael.to_string())
     elif get_fields:
         # fields only query.  We'll do it with the rest api
         restParser = RestParser(verbosity_level=int(verbosity))
-        if (output_file is not None):
+        if output_file is not None:
             restParser.setOutputFormat(RestParser.OBJECT_FORMAT)
             df_list = []
         else:
             restParser.setOutputFormat(RestParser.CLI_FORMAT)
         # set up uri to do fields query for each nidm file
         for nidm_file in nidm_file_list.split(","):
             # get project UUID
             project = GetProjectsUUID([nidm_file])
-            uri = "/projects/" +  project[0].toPython().split("/")[-1] + "?fields=" + get_fields
+            uri = (
+                "/projects/"
+                + project[0].toPython().split("/")[-1]
+                + "?fields="
+                + get_fields
+            )
             # get fields output from each file and concatenate
-            if (output_file is None):
+            if output_file is None:
                 # just print results
                 print(restParser.run([nidm_file], uri))
             else:
                 df_list.append(pd.DataFrame(restParser.run([nidm_file], uri)))
 
-        if (output_file is not None):
+        if output_file is not None:
             # concatenate data frames
             df = pd.concat(df_list)
             # output to csv file
             df.to_csv(output_file)
 
     elif uri:
-        restParser = RestParser(verbosity_level = int(verbosity))
+        restParser = RestParser(verbosity_level=int(verbosity))
         if j:
             restParser.setOutputFormat(RestParser.JSON_FORMAT)
-        elif (output_file is not None):
+        elif output_file is not None:
             restParser.setOutputFormat(RestParser.OBJECT_FORMAT)
         else:
             restParser.setOutputFormat(RestParser.CLI_FORMAT)
-        df = restParser.run(nidm_file_list.split(','), uri)
-        if (output_file is not None):
+        df = restParser.run(nidm_file_list.split(","), uri)
+        if output_file is not None:
             if j:
-                with open(output_file,"w+") as f:
+                with open(output_file, "w+", encoding="utf-8") as f:
                     f.write(dumps(df))
             else:
                 # convert object df to dataframe and output
                 pd.DataFrame(df).to_csv(output_file)
         else:
-            print (df)
+            print(df)
 
     elif get_dataelements_brainvols:
         brainvol = GetBrainVolumeDataElements(nidm_file_list=nidm_file_list)
-         #if output file parameter specified
-        if (output_file is not None):
-
+        # if output file parameter specified
+        if output_file is not None:
             brainvol.to_csv(output_file)
         else:
             print(brainvol.to_string())
     elif get_brainvols:
         brainvol = GetBrainVolumes(nidm_file_list=nidm_file_list)
-         #if output file parameter specified
-        if (output_file is not None):
-
+        # if output file parameter specified
+        if output_file is not None:
             brainvol.to_csv(output_file)
         else:
             print(brainvol.to_string())
     elif query_file:
+        df = sparql_query_nidm(nidm_file_list.split(","), query_file, output_file)
 
-        df = sparql_query_nidm(nidm_file_list.split(','),query_file,output_file)
-
-        if ((output_file) is None):
-
+        if (output_file) is None:
             print(df.to_string())
 
         return df
     else:
         print("ERROR: No query parameter provided.  See help:")
         print()
         os.system("pynidm query --help")
-        exit(1)
+        sys.exit(1)
 
 
 # it can be used calling the script `python nidm_query.py -nl ... -q ..
 if __name__ == "__main__":
     query()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/repronim_simple2_brainvolumes.py` & `pynidm-4.0.0/src/nidm/experiment/tools/repronim_simple2_brainvolumes.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,465 +1,754 @@
-#!/usr/bin/env python
-#**************************************************************************************
-#**************************************************************************************
-#  repronim_simple2_brainvolumes.py
-#  License: Apache License, Version 2.0
-#**************************************************************************************
-#**************************************************************************************
-# Date: 03-22-19                 Coded by: David Keator (dbkeator@gmail.com)
-# Filename: repronim_simple2_brainvolumes.py
-#
-# Program description:  This program will load in a CSV file made during simple-2
-# brain volumes experiment which has the following organization:
-#
-#source	FSL	FSL	FSL
-# participant_id	left nucleus accumbens volume	left amygdala volume	left caudate nucleus volume
-#sub-0050002	796.4723293	1255.574283	4449.579039
-#sub-0050003	268.9688215	878.7860634	3838.602449
-#sub-0050004	539.0969914	1195.288168	3561.518188
-#
-# If will use the first row to determine the software used for the segmentations and the
-# second row for the variable names.  Then it does a simple NIDM conversion using
-# example model in: https://docs.google.com/document/d/1PyBoM7J0TuzTC1TIIFPDqd05nomcCM5Pvst8yCoqLng/edit
-
-#**************************************************************************************
-# Development environment: Python - PyCharm IDE
-#
-#**************************************************************************************
-# System requirements:  Python 3.X
-# Libraries: pybids, numpy, matplotlib, pandas, scipy, math, dateutil, datetime,argparse,
-# os,sys,getopt,csv
-#**************************************************************************************
-# Start date: 03-22-18
-# Update history:
-# DATE            MODIFICATION				Who
-#
-#
-#**************************************************************************************
-# Programmer comments:
-#
-#
-#**************************************************************************************
-#**************************************************************************************
+"""
+Program description:  This program will load in a CSV file made during simple-2
+brain volumes experiment which has the following organization::
+
+    source  FSL     FSL     FSL
+    participant_id  left nucleus accumbens volume   left amygdala volume    left caudate nucleus volume
+    sub-0050002     796.4723293     1255.574283     4449.579039
+    sub-0050003     268.9688215     878.7860634     3838.602449
+    sub-0050004     539.0969914     1195.288168     3561.518188
+
+If will use the first row to determine the software used for the segmentations
+and the second row for the variable names.  Then it does a simple NIDM
+conversion using example model in:
+https://docs.google.com/document/d/1PyBoM7J0TuzTC1TIIFPDqd05nomcCM5Pvst8yCoqLng/edit
+"""
 
-import os,sys
-from nidm.experiment import Project,Session,AssessmentAcquisition,AssessmentObject
-from nidm.core import Constants
-from nidm.experiment.Utils import read_nidm, map_variables_to_terms, getSubjIDColumn
-from nidm.experiment.Core import getUUID
-from nidm.experiment.Core import Core
-from prov.model import QualifiedName,PROV_ROLE, ProvDocument, PROV_ATTR_USED_ENTITY
-from prov.model import Namespace as provNamespace
-import prov as pm
 from argparse import ArgumentParser
-from os.path import  dirname, join, splitext,basename
-import json
-import pandas as pd
-from rdflib import Graph,URIRef,RDF
-import numpy as np
 from io import StringIO
-from urllib.parse import urlparse
+from os.path import dirname, join
+import numpy as np
+import pandas as pd
+from prov.model import Namespace as provNamespace
+from prov.model import PROV_ATTR_USED_ENTITY, PROV_ROLE
+from prov.model import QualifiedName
+from rdflib import Graph
+from nidm.core import Constants
+from nidm.experiment.Core import Core, getUUID
+from nidm.experiment.Utils import getSubjIDColumn, map_variables_to_terms, read_nidm
+
 
 def column_index(df, query_cols):
     cols = df.columns.values
     sidx = np.argsort(cols)
-    return sidx[np.searchsorted(cols,query_cols,sorter=sidx)]
+    return sidx[np.searchsorted(cols, query_cols, sorter=sidx)]
+
 
-def add_brainvolume_data(nidmdoc, df, id_field, source_row, column_to_terms, png_file=None, output_file=None, root_act=None, nidm_graph=None):
-    '''
+def add_brainvolume_data(
+    nidmdoc,
+    df,
+    id_field,
+    source_row,
+    column_to_terms,
+    png_file=None,
+    output_file=None,
+    root_act=None,
+    nidm_graph=None,
+):
+    """
 
     :param nidmdoc:
     :param df:
     :param id_field:
     :param source_row:
     :param empty:
     :param png_file:
     :param root_act:
     :return:
-    '''
-    #dictionary to store activities for each software agent
-    software_agent={}
-    software_activity={}
-    participant_agent={}
-    entity={}
+    """
+    # dictionary to store activities for each software agent
+    software_agent = {}
+    software_activity = {}
+    participant_agent = {}
+    entity = {}
 
-    #this function can be used for both creating a brainvolumes NIDM file from scratch or adding brain volumes to
-    #existing NIDM file.  The following logic basically determines which route to take...
+    # this function can be used for both creating a brainvolumes NIDM file from scratch or adding brain volumes to
+    # existing NIDM file.  The following logic basically determines which route to take...
 
-    #if an existing NIDM graph is passed as a parameter then add to existing file
+    # if an existing NIDM graph is passed as a parameter then add to existing file
     if nidm_graph is None:
-        first_row=True
-        #iterate over rows and store in NIDM file
-        for csv_index, csv_row in df.iterrows():
-
-            #store other data from row with columns_to_term mappings
-            for row_variable,row_data in csv_row.iteritems():
-
-                #check if row_variable is subject id, if so check whether we have an agent for this participant
-                if row_variable==id_field:
-                    #store participant id for later use in processing the data for this row
+        first_row = True
+        # iterate over rows and store in NIDM file
+        for _, csv_row in df.iterrows():
+            # store other data from row with columns_to_term mappings
+            for row_variable, row_data in csv_row.iteritems():
+                # check if row_variable is subject id, if so check whether we have an agent for this participant
+                if row_variable == id_field:
+                    # store participant id for later use in processing the data for this row
                     participant_id = row_data
-                    #if there is no agent for the participant then add one
-                    if row_data not in participant_agent.keys():
-                        #add an agent for this person
-                        participant_agent[row_data] = nidmdoc.graph.agent(QualifiedName(provNamespace("nidm",Constants.NIDM),getUUID()),other_attributes=({Constants.NIDM_SUBJECTID:row_data}))
+                    # if there is no agent for the participant then add one
+                    if row_data not in participant_agent:
+                        # add an agent for this person
+                        participant_agent[row_data] = nidmdoc.graph.agent(
+                            QualifiedName(
+                                provNamespace("nidm", Constants.NIDM), getUUID()
+                            ),
+                            other_attributes=({Constants.NIDM_SUBJECTID: row_data}),
+                        )
                     continue
                 else:
-
-                    #get source software matching this column deal with duplicate variables in source_row and pandas changing duplicate names
-                    software_key = source_row.columns[[column_index(df,row_variable)]]._values[0].split(".")[0]
-
-                    #see if we already have a software_activity for this agent
-                    if software_key not in software_activity.keys():
-
-                        #create an activity for the computation...simply a placeholder for more extensive provenance
-                        software_activity[software_key] = nidmdoc.graph.activity(QualifiedName(provNamespace("nidm",Constants.NIDM),getUUID()),other_attributes={Constants.NIDM_PROJECT_DESCRIPTION:"brain volume computation"})
+                    # get source software matching this column deal with duplicate variables in source_row and pandas changing duplicate names
+                    software_key = (
+                        source_row.columns[[column_index(df, row_variable)]]
+                        ._values[0]
+                        .split(".")[0]
+                    )
+
+                    # see if we already have a software_activity for this agent
+                    if software_key not in software_activity:
+                        # create an activity for the computation...simply a placeholder for more extensive provenance
+                        software_activity[software_key] = nidmdoc.graph.activity(
+                            QualifiedName(
+                                provNamespace("nidm", Constants.NIDM), getUUID()
+                            ),
+                            other_attributes={
+                                Constants.NIDM_PROJECT_DESCRIPTION: "brain volume computation"
+                            },
+                        )
 
                         if root_act is not None:
-                            #associate activity with activity of brain volumes creation (root-level activity)
-                            software_activity[software_key].add_attributes({QualifiedName(provNamespace("dct",Constants.DCT),'isPartOf'):root_act})
-
-                        #associate this activity with the participant
-                        nidmdoc.graph.association(activity=software_activity[software_key],agent=participant_agent[participant_id],other_attributes={PROV_ROLE:Constants.NIDM_PARTICIPANT})
-                        nidmdoc.graph.wasAssociatedWith(activity=software_activity[software_key],agent=participant_agent[participant_id])
-
-                        #check if there's an associated software agent and if not, create one
-                        if software_key not in software_agent.keys():
-                            #create an agent
-                            software_agent[software_key] = nidmdoc.graph.agent(QualifiedName(provNamespace("nidm",Constants.NIDM),getUUID()),other_attributes={'prov:type':QualifiedName(provNamespace(Core.safe_string(None,string=str("Neuroimaging Analysis Software")),Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE),""),
-                                                                    QualifiedName(provNamespace(Core.safe_string(None,string=str("Neuroimaging Analysis Software")),Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE),""):software_key } )
-                            #create qualified association with brain volume computation activity
-                            nidmdoc.graph.association(activity=software_activity[software_key],agent=software_agent[software_key],other_attributes={PROV_ROLE:QualifiedName(provNamespace(Core.safe_string(None,string=str("Neuroimaging Analysis Software")),Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE),"")})
-                            nidmdoc.graph.wasAssociatedWith(activity=software_activity[software_key],agent=software_agent[software_key])
-
-                    #check if we have an entity for storing this particular variable for this subject and software else create one
-                    if software_activity[software_key].identifier.localpart + participant_agent[participant_id].identifier.localpart not in entity.keys():
-                        #create an entity to store brain volume data for this participant
-                        entity[software_activity[software_key].identifier.localpart + participant_agent[participant_id].identifier.localpart] = nidmdoc.graph.entity( QualifiedName(provNamespace("nidm",Constants.NIDM),getUUID()))
-                        #add wasGeneratedBy association to activity
-                        nidmdoc.graph.wasGeneratedBy(entity=entity[software_activity[software_key].identifier.localpart + participant_agent[participant_id].identifier.localpart], activity=software_activity[software_key])
-
-                    #get column_to_term mapping uri and add as namespace in NIDM document
-                    entity[software_activity[software_key].identifier.localpart + participant_agent[participant_id].identifier.localpart].add_attributes({QualifiedName(provNamespace(Core.safe_string(None,string=str(row_variable)), column_to_terms[row_variable.split(".")[0]]["url"]),""):row_data})
-                    #print(project.serializeTurtle())
-
-
-            #just for debugging.  resulting graph is too big right now for DOT graph creation so here I'm simply creating
-            #a DOT graph for the processing of 1 row of the brain volumes CSV file so we can at least visually see the
-            #model
+                            # associate activity with activity of brain volumes creation (root-level activity)
+                            software_activity[software_key].add_attributes(
+                                {
+                                    QualifiedName(
+                                        provNamespace("dct", Constants.DCT), "isPartOf"
+                                    ): root_act
+                                }
+                            )
+
+                        # associate this activity with the participant
+                        nidmdoc.graph.association(
+                            activity=software_activity[software_key],
+                            agent=participant_agent[participant_id],
+                            other_attributes={PROV_ROLE: Constants.NIDM_PARTICIPANT},
+                        )
+                        nidmdoc.graph.wasAssociatedWith(
+                            activity=software_activity[software_key],
+                            agent=participant_agent[participant_id],
+                        )
+
+                        # check if there's an associated software agent and if not, create one
+                        if software_key not in software_agent:
+                            # create an agent
+                            software_agent[software_key] = nidmdoc.graph.agent(
+                                QualifiedName(
+                                    provNamespace("nidm", Constants.NIDM), getUUID()
+                                ),
+                                other_attributes={
+                                    "prov:type": QualifiedName(
+                                        provNamespace(
+                                            Core.safe_string(
+                                                None,
+                                                string=str(
+                                                    "Neuroimaging Analysis Software"
+                                                ),
+                                            ),
+                                            Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE,
+                                        ),
+                                        "",
+                                    ),
+                                    QualifiedName(
+                                        provNamespace(
+                                            Core.safe_string(
+                                                None,
+                                                string=str(
+                                                    "Neuroimaging Analysis Software"
+                                                ),
+                                            ),
+                                            Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE,
+                                        ),
+                                        "",
+                                    ): software_key,
+                                },
+                            )
+                            # create qualified association with brain volume computation activity
+                            nidmdoc.graph.association(
+                                activity=software_activity[software_key],
+                                agent=software_agent[software_key],
+                                other_attributes={
+                                    PROV_ROLE: QualifiedName(
+                                        provNamespace(
+                                            Core.safe_string(
+                                                None,
+                                                string=str(
+                                                    "Neuroimaging Analysis Software"
+                                                ),
+                                            ),
+                                            Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE,
+                                        ),
+                                        "",
+                                    )
+                                },
+                            )
+                            nidmdoc.graph.wasAssociatedWith(
+                                activity=software_activity[software_key],
+                                agent=software_agent[software_key],
+                            )
+
+                    # check if we have an entity for storing this particular variable for this subject and software else create one
+                    if (
+                        software_activity[software_key].identifier.localpart
+                        + participant_agent[participant_id].identifier.localpart
+                        not in entity
+                    ):
+                        # create an entity to store brain volume data for this participant
+                        entity[
+                            software_activity[software_key].identifier.localpart
+                            + participant_agent[participant_id].identifier.localpart
+                        ] = nidmdoc.graph.entity(
+                            QualifiedName(
+                                provNamespace("nidm", Constants.NIDM), getUUID()
+                            )
+                        )
+                        # add wasGeneratedBy association to activity
+                        nidmdoc.graph.wasGeneratedBy(
+                            entity=entity[
+                                software_activity[software_key].identifier.localpart
+                                + participant_agent[participant_id].identifier.localpart
+                            ],
+                            activity=software_activity[software_key],
+                        )
+
+                    # get column_to_term mapping uri and add as namespace in NIDM document
+                    entity[
+                        software_activity[software_key].identifier.localpart
+                        + participant_agent[participant_id].identifier.localpart
+                    ].add_attributes(
+                        {
+                            QualifiedName(
+                                provNamespace(
+                                    Core.safe_string(None, string=str(row_variable)),
+                                    column_to_terms[row_variable.split(".")[0]]["url"],
+                                ),
+                                "",
+                            ): row_data
+                        }
+                    )
+                    # print(project.serializeTurtle())
+
+            # just for debugging.  resulting graph is too big right now for DOT graph creation so here I'm simply creating
+            # a DOT graph for the processing of 1 row of the brain volumes CSV file so we can at least visually see the
+            # model
             if png_file is not None:
                 if first_row:
-                    #serialize NIDM file
-                    #with open(args.output_file,'w') as f:
+                    # serialize NIDM file
+                    # with open(args.output_file,'w', encoding="utf-8") as f:
                     #   print("Writing NIDM file...")
                     #   f.write(nidmdoc.serializeTurtle())
                     if png_file:
                         nidmdoc.save_DotGraph(str(output_file + ".pdf"), format="pdf")
-                    first_row=False
+                    first_row = False
     else:
-        first_row=True
-        #logic to add to existing graph
-        #use RDFLib here for temporary graph making query easier
+        first_row = True
+        # logic to add to existing graph
+        # use RDFLib here for temporary graph making query easier
         rdf_graph = Graph()
-        rdf_graph_parse = rdf_graph.parse(source=StringIO(nidmdoc.serializeTurtle()),format='turtle')
-
+        rdf_graph_parse = rdf_graph.parse(
+            source=StringIO(nidmdoc.serializeTurtle()), format="turtle"
+        )
 
-        #find subject ids and sessions in NIDM document
+        # find subject ids and sessions in NIDM document
         query = """SELECT DISTINCT ?session ?nidm_subj_id ?agent ?entity
                     WHERE {
                         ?activity prov:wasAssociatedWith ?agent ;
                             dct:isPartOf ?session  .
                         ?entity prov:wasGeneratedBy ?activity ;
                             nidm:hadImageUsageType nidm:Anatomical .
                         ?agent rdf:type prov:Agent ;
                             ndar:src_subject_id ?nidm_subj_id .
 
                     }"""
-        #print(query)
+        # print(query)
         qres = rdf_graph_parse.query(query)
 
-
-
         for row in qres:
-            print('%s \t %s' %(row[2],row[1]))
-            #find row in CSV file with subject id matching agent from NIDM file
-
-            #csv_row = df.loc[df[id_field]==type(df[id_field][0])(row[1])]
-            #find row in CSV file with matching subject id to the agent in the NIDM file
-            #be careful about data types...simply type-change dataframe subject id column and query to strings.
-            #here we're removing the leading 0's from IDs because pandas.read_csv strips those unless you know ahead of
-            #time which column is the subject id....
-            csv_row = df.loc[df[id_field].astype('str').str.contains(str(row[1]).lstrip("0"))]
-
-            #if there was data about this subject in the NIDM file already (i.e. an agent already exists with this subject id)
-            #then add this brain volumes data to NIDM file, else skip it....
-            if (not (len(csv_row.index)==0)):
-                print("found other data for participant %s" %row[1])
-
-                #Here we're sure we have an agent in the NIDM graph that corresponds to the participant in the
-                #brain volumes data.  We don't know which AcquisitionObject (entity) describes the T1-weighted scans
-                #used for the project.  Since we don't have the SHA512 sums in the brain volumes data (YET) we can't
-                #really verify that it's a particular T1-weighted scan that was used for the brain volumes but we're
-                #simply, for the moment, going to assume it's the activity/session returned by the above query
-                #where we've specifically asked for the entity which has a nidm:hasImageUsageType nidm:Anatomical
-
+            print(f"{row[2]} \t {row[1]}")
+            # find row in CSV file with subject id matching agent from NIDM file
 
+            # csv_row = df.loc[df[id_field]==type(df[id_field][0])(row[1])]
+            # find row in CSV file with matching subject id to the agent in the NIDM file
+            # be careful about data types...simply type-change dataframe subject id column and query to strings.
+            # here we're removing the leading 0's from IDs because pandas.read_csv strips those unless you know ahead of
+            # time which column is the subject id....
+            csv_row = df.loc[
+                df[id_field].astype("str").str.contains(str(row[1]).lstrip("0"))
+            ]
+
+            # if there was data about this subject in the NIDM file already (i.e. an agent already exists with this subject id)
+            # then add this brain volumes data to NIDM file, else skip it....
+            if len(csv_row.index) != 0:
+                print(f"found other data for participant {row[1]}")
+
+                # Here we're sure we have an agent in the NIDM graph that corresponds to the participant in the
+                # brain volumes data.  We don't know which AcquisitionObject (entity) describes the T1-weighted scans
+                # used for the project.  Since we don't have the SHA512 sums in the brain volumes data (YET) we can't
+                # really verify that it's a particular T1-weighted scan that was used for the brain volumes but we're
+                # simply, for the moment, going to assume it's the activity/session returned by the above query
+                # where we've specifically asked for the entity which has a nidm:hasImageUsageType nidm:Anatomical
 
-                #NIDM document entity uuid which has a nidm:hasImageUsageType nidm:Anatomical
-                #this is the entity that is associated with the brain volume report for this participant
+                # NIDM document entity uuid which has a nidm:hasImageUsageType nidm:Anatomical
+                # this is the entity that is associated with the brain volume report for this participant
                 anat_entity_uuid = row[3]
 
-                #Now we need to set up the entities/activities, etc. to add the brain volume data for this row of the
-                #CSV file and link it to the above entity and the agent for this participant which is row[0]
-                #store other data from row with columns_to_term mappings
-                for row_variable,row_data in csv_row.iteritems():
-
-                    #check if row_variable is subject id, if so check whether we have an agent for this participant
-                    if row_variable==id_field:
-                        #store participant id for later use in processing the data for this row
+                # Now we need to set up the entities/activities, etc. to add the brain volume data for this row of the
+                # CSV file and link it to the above entity and the agent for this participant which is row[0]
+                # store other data from row with columns_to_term mappings
+                for row_variable, row_data in csv_row.iteritems():
+                    # check if row_variable is subject id, if so check whether we have an agent for this participant
+                    if row_variable == id_field:
+                        # store participant id for later use in processing the data for this row
                         participant_id = row_data.values[0]
-                        print("participant id: %s" %participant_id)
+                        print(f"participant id: {participant_id}")
                         continue
                     else:
+                        # get source software matching this column deal with duplicate variables in source_row and pandas changing duplicate names
+                        software_key = (
+                            source_row.columns[[column_index(df, row_variable)]]
+                            ._values[0]
+                            .split(".")[0]
+                        )
+
+                        # see if we already have a software_activity for this agent
+                        if software_key + row[2] not in software_activity:
+                            # create an activity for the computation...simply a placeholder for more extensive provenance
+                            software_activity[
+                                software_key + row[2]
+                            ] = nidmdoc.graph.activity(
+                                QualifiedName(
+                                    provNamespace("niiri", Constants.NIIRI), getUUID()
+                                ),
+                                other_attributes={
+                                    Constants.NIDM_PROJECT_DESCRIPTION: "brain volume computation",
+                                    PROV_ATTR_USED_ENTITY: anat_entity_uuid,
+                                },
+                            )
 
-                        #get source software matching this column deal with duplicate variables in source_row and pandas changing duplicate names
-                        software_key = source_row.columns[[column_index(df,row_variable)]]._values[0].split(".")[0]
-
-                        #see if we already have a software_activity for this agent
-                        if software_key+row[2] not in software_activity.keys():
-
-                            #create an activity for the computation...simply a placeholder for more extensive provenance
-                            software_activity[software_key+row[2]] = nidmdoc.graph.activity(QualifiedName(provNamespace("niiri",Constants.NIIRI),getUUID()),other_attributes={Constants.NIDM_PROJECT_DESCRIPTION:"brain volume computation",
-                                                                                            PROV_ATTR_USED_ENTITY:anat_entity_uuid})
-
-                            #associate the activity with the entity containing the original T1-weighted scan which is stored in anat_entity_uuid
+                            # associate the activity with the entity containing the original T1-weighted scan which is stored in anat_entity_uuid
                             if root_act is not None:
-                                #associate activity with activity of brain volumes creation (root-level activity)
-                                software_activity[software_key+row[2]].add_attributes({QualifiedName(provNamespace("dct",Constants.DCT),'isPartOf'):root_act})
-
-
-
-                            #associate this activity with the participant..the participant's agent is row[2] in the query response
-                            nidmdoc.graph.association(activity=software_activity[software_key+row[2]],agent=row[2],other_attributes={PROV_ROLE:Constants.NIDM_PARTICIPANT})
-                            nidmdoc.graph.wasAssociatedWith(activity=software_activity[software_key+row[2]],agent=row[2])
-
-
-                            #check if there's an associated software agent and if not, create one
-                            if software_key not in software_agent.keys():
-                                #if we have a URL defined for this software in Constants.py then use it else simply use the string name of the software product
+                                # associate activity with activity of brain volumes creation (root-level activity)
+                                software_activity[software_key + row[2]].add_attributes(
+                                    {
+                                        QualifiedName(
+                                            provNamespace("dct", Constants.DCT),
+                                            "isPartOf",
+                                        ): root_act
+                                    }
+                                )
+
+                            # associate this activity with the participant..the participant's agent is row[2] in the query response
+                            nidmdoc.graph.association(
+                                activity=software_activity[software_key + row[2]],
+                                agent=row[2],
+                                other_attributes={
+                                    PROV_ROLE: Constants.NIDM_PARTICIPANT
+                                },
+                            )
+                            nidmdoc.graph.wasAssociatedWith(
+                                activity=software_activity[software_key + row[2]],
+                                agent=row[2],
+                            )
+
+                            # check if there's an associated software agent and if not, create one
+                            if software_key not in software_agent:
+                                # if we have a URL defined for this software in Constants.py then use it else simply use the string name of the software product
                                 if software_key.lower() in Constants.namespaces:
-                                    #create an agent
-                                    software_agent[software_key] = nidmdoc.graph.agent(QualifiedName(provNamespace("niiri",Constants.NIIRI),getUUID()),other_attributes={'prov:type':QualifiedName(provNamespace(Core.safe_string(None,string=str("Neuroimaging Analysis Software")),Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE),""),
-                                                                            QualifiedName(provNamespace(Core.safe_string(None,string=str("Neuroimaging Analysis Software")),Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE),""):QualifiedName(provNamespace(software_key,Constants.namespaces[software_key.lower()]),"") } )
+                                    # create an agent
+                                    software_agent[software_key] = nidmdoc.graph.agent(
+                                        QualifiedName(
+                                            provNamespace("niiri", Constants.NIIRI),
+                                            getUUID(),
+                                        ),
+                                        other_attributes={
+                                            "prov:type": QualifiedName(
+                                                provNamespace(
+                                                    Core.safe_string(
+                                                        None,
+                                                        string=str(
+                                                            "Neuroimaging Analysis Software"
+                                                        ),
+                                                    ),
+                                                    Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE,
+                                                ),
+                                                "",
+                                            ),
+                                            QualifiedName(
+                                                provNamespace(
+                                                    Core.safe_string(
+                                                        None,
+                                                        string=str(
+                                                            "Neuroimaging Analysis Software"
+                                                        ),
+                                                    ),
+                                                    Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE,
+                                                ),
+                                                "",
+                                            ): QualifiedName(
+                                                provNamespace(
+                                                    software_key,
+                                                    Constants.namespaces[
+                                                        software_key.lower()
+                                                    ],
+                                                ),
+                                                "",
+                                            ),
+                                        },
+                                    )
                                 else:
-                                    #create an agent
-                                    software_agent[software_key] = nidmdoc.graph.agent(QualifiedName(provNamespace("niiri",Constants.NIIRI),getUUID()),other_attributes={'prov:type':QualifiedName(provNamespace(Core.safe_string(None,string=str("Neuroimaging Analysis Software")),Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE),""),
-                                                                            QualifiedName(provNamespace(Core.safe_string(None,string=str("Neuroimaging Analysis Software")),Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE),""):software_key } )
-                            #create qualified association with brain volume computation activity
-                            nidmdoc.graph.association(activity=software_activity[software_key+row[2]],agent=software_agent[software_key],other_attributes={PROV_ROLE:QualifiedName(provNamespace(Core.safe_string(None,string=str("Neuroimaging Analysis Software")),Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE),"")})
-                            nidmdoc.graph.wasAssociatedWith(activity=software_activity[software_key+row[2]],agent=software_agent[software_key])
-
-                        #check if we have an entity for storing this particular variable for this subject and software else create one
-                        if software_activity[software_key+row[2]].identifier.localpart + row[2] not in entity.keys():
-                            #create an entity to store brain volume data for this participant
-                            entity[software_activity[software_key+row[2]].identifier.localpart + row[2]] = nidmdoc.graph.entity( QualifiedName(provNamespace("niiri",Constants.NIIRI),getUUID()))
-                            #add wasGeneratedBy association to activity
-                            nidmdoc.graph.wasGeneratedBy(entity=entity[software_activity[software_key+row[2]].identifier.localpart + row[2]], activity=software_activity[software_key+row[2]])
-
-                        #get column_to_term mapping uri and add as namespace in NIDM document
-                        entity[software_activity[software_key+row[2]].identifier.localpart + row[2]].add_attributes({QualifiedName(provNamespace(Core.safe_string(None,string=str(row_variable)), column_to_terms[row_variable.split(".")[0]]["url"]),""):row_data.values[0]})
-                        #print(project.serializeTurtle())
-
-            #just for debugging.  resulting graph is too big right now for DOT graph creation so here I'm simply creating
-            #a DOT graph for the processing of 1 row of the brain volumes CSV file so we can at least visually see the
-            #model
-            #if png_file is not None:
+                                    # create an agent
+                                    software_agent[software_key] = nidmdoc.graph.agent(
+                                        QualifiedName(
+                                            provNamespace("niiri", Constants.NIIRI),
+                                            getUUID(),
+                                        ),
+                                        other_attributes={
+                                            "prov:type": QualifiedName(
+                                                provNamespace(
+                                                    Core.safe_string(
+                                                        None,
+                                                        string=str(
+                                                            "Neuroimaging Analysis Software"
+                                                        ),
+                                                    ),
+                                                    Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE,
+                                                ),
+                                                "",
+                                            ),
+                                            QualifiedName(
+                                                provNamespace(
+                                                    Core.safe_string(
+                                                        None,
+                                                        string=str(
+                                                            "Neuroimaging Analysis Software"
+                                                        ),
+                                                    ),
+                                                    Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE,
+                                                ),
+                                                "",
+                                            ): software_key,
+                                        },
+                                    )
+                            # create qualified association with brain volume computation activity
+                            nidmdoc.graph.association(
+                                activity=software_activity[software_key + row[2]],
+                                agent=software_agent[software_key],
+                                other_attributes={
+                                    PROV_ROLE: QualifiedName(
+                                        provNamespace(
+                                            Core.safe_string(
+                                                None,
+                                                string=str(
+                                                    "Neuroimaging Analysis Software"
+                                                ),
+                                            ),
+                                            Constants.NIDM_NEUROIMAGING_ANALYSIS_SOFTWARE,
+                                        ),
+                                        "",
+                                    )
+                                },
+                            )
+                            nidmdoc.graph.wasAssociatedWith(
+                                activity=software_activity[software_key + row[2]],
+                                agent=software_agent[software_key],
+                            )
+
+                        # check if we have an entity for storing this particular variable for this subject and software else create one
+                        if (
+                            software_activity[
+                                software_key + row[2]
+                            ].identifier.localpart
+                            + row[2]
+                            not in entity
+                        ):
+                            # create an entity to store brain volume data for this participant
+                            entity[
+                                software_activity[
+                                    software_key + row[2]
+                                ].identifier.localpart
+                                + row[2]
+                            ] = nidmdoc.graph.entity(
+                                QualifiedName(
+                                    provNamespace("niiri", Constants.NIIRI), getUUID()
+                                )
+                            )
+                            # add wasGeneratedBy association to activity
+                            nidmdoc.graph.wasGeneratedBy(
+                                entity=entity[
+                                    software_activity[
+                                        software_key + row[2]
+                                    ].identifier.localpart
+                                    + row[2]
+                                ],
+                                activity=software_activity[software_key + row[2]],
+                            )
+
+                        # get column_to_term mapping uri and add as namespace in NIDM document
+                        entity[
+                            software_activity[
+                                software_key + row[2]
+                            ].identifier.localpart
+                            + row[2]
+                        ].add_attributes(
+                            {
+                                QualifiedName(
+                                    provNamespace(
+                                        Core.safe_string(
+                                            None, string=str(row_variable)
+                                        ),
+                                        column_to_terms[row_variable.split(".")[0]][
+                                            "url"
+                                        ],
+                                    ),
+                                    "",
+                                ): row_data.values[0]
+                            }
+                        )
+                        # print(project.serializeTurtle())
+
+            # just for debugging.  resulting graph is too big right now for DOT graph creation so here I'm simply creating
+            # a DOT graph for the processing of 1 row of the brain volumes CSV file so we can at least visually see the
+            # model
+            # if png_file is not None:
             #    if first_row:
-                    #serialize NIDM file
-                    #with open(args.output_file,'w') as f:
-                    #   print("Writing NIDM file...")
-                    #   f.write(nidmdoc.serializeTurtle())
+            # serialize NIDM file
+            # with open(args.output_file,'w', encoding="utf-8") as f:
+            #   print("Writing NIDM file...")
+            #   f.write(nidmdoc.serializeTurtle())
             #        nidmdoc.save_DotGraph(str(output_file + ".pdf"), format="pdf")
             #        first_row=False
 
 
-
-
-def main(argv):
-    parser = ArgumentParser(description="""This program will load in a CSV file made during simple-2
+def main():
+    parser = ArgumentParser(
+        description="""This program will load in a CSV file made during simple-2
                 brain volumes experiment which has the following organization:
                 source	FSL	FSL	FSL
                 participant_id	left nucleus accumbens volume	left amygdala volume
                 sub-0050002	    796.4723293	    1255.574283	    4449.579039
                 sub-0050003	    268.9688215	    878.7860634	    3838.602449
                 sub-0050004	    539.0969914	    1195.288168	    3561.518188
                 If will use the first row to determine the software used for the segmentations and the
                 second row for the variable names.  Then it does a simple NIDM conversion using
-                example model in: https://docs.google.com/document/d/1PyBoM7J0TuzTC1TIIFPDqd05nomcCM5Pvst8yCoqLng/edit""")
+                example model in: https://docs.google.com/document/d/1PyBoM7J0TuzTC1TIIFPDqd05nomcCM5Pvst8yCoqLng/edit"""
+    )
 
-    parser.add_argument('-csv', dest='csv_file', required=True, help="Path to CSV file to convert")
-    parser.add_argument('-ilxkey', dest='key', required=True, help="Interlex/SciCrunch API key to use for query")
-    parser.add_argument('-json_map', dest='json_map',required=False,help="User-suppled JSON file containing variable-term mappings.")
-    parser.add_argument('-nidm', dest='nidm_file', required=False, help="Optional NIDM file to add CSV->NIDM converted graph to")
-    parser.add_argument('-owl', action='store_true', required=False, help='Optionally searches NIDM OWL files...internet connection required')
-    parser.add_argument('-png', action='store_true', required=False, help='Optional flag, when set a PNG image file of RDF graph will be produced')
-    parser.add_argument('-out', dest='output_file', required=True, help="Filename to save NIDM file")
+    parser.add_argument(
+        "-csv", dest="csv_file", required=True, help="Path to CSV file to convert"
+    )
+    parser.add_argument(
+        "-ilxkey",
+        dest="key",
+        required=True,
+        help="Interlex/SciCrunch API key to use for query",
+    )
+    parser.add_argument(
+        "-json_map",
+        dest="json_map",
+        required=False,
+        help="User-suppled JSON file containing variable-term mappings.",
+    )
+    parser.add_argument(
+        "-nidm",
+        dest="nidm_file",
+        required=False,
+        help="Optional NIDM file to add CSV->NIDM converted graph to",
+    )
+    parser.add_argument(
+        "-owl",
+        action="store_true",
+        required=False,
+        help="Optionally searches NIDM OWL files...internet connection required",
+    )
+    parser.add_argument(
+        "-png",
+        action="store_true",
+        required=False,
+        help="Optional flag, when set a PNG image file of RDF graph will be produced",
+    )
+    parser.add_argument(
+        "-out", dest="output_file", required=True, help="Filename to save NIDM file"
+    )
     args = parser.parse_args()
 
-    #open CSV file and read first line which is the source of the segmentations
+    # open CSV file and read first line which is the source of the segmentations
     source_row = pd.read_csv(args.csv_file, nrows=0)
-    #open CSV file and load into
-    df = pd.read_csv(args.csv_file, skiprows=0,header=1)
-    #account for duplicate column names
+    # open CSV file and load into
+    df = pd.read_csv(args.csv_file, skiprows=0, header=1)
+    # account for duplicate column names
     # df.columns = df.iloc[0]
     df = df.reindex(df.index.drop(0)).reset_index(drop=True)
 
-
-    #get unique variable names from CSV data file
-    #note, duplicate variable names will be appended with a ".X" where X is the number of duplicates
-    unique_vars=[]
+    # get unique variable names from CSV data file
+    # note, duplicate variable names will be appended with a ".X" where X is the number of duplicates
+    unique_vars = []
     for variable in list(df):
-        temp=variable.split(".")[0]
+        temp = variable.split(".")[0]
         if temp not in unique_vars:
             unique_vars.append(temp)
 
-    #do same as above for unique software agents
-    unique_software=[]
+    # do same as above for unique software agents
+    unique_software = []
     for variable in list(source_row):
-        temp=variable.split(".")[0]
+        temp = variable.split(".")[0]
         if temp not in unique_software:
             unique_software.append(temp)
 
-
-    #maps variables in CSV file to terms
+    # maps variables in CSV file to terms
     if args.owl:
-        column_to_terms = map_variables_to_terms(df=pd.DataFrame(columns=unique_vars), apikey=args.key, directory=dirname(args.output_file), output_file=join(dirname(args.output_file),"json_map.json"), json_file=args.json_map,owl_file=args.owl)
+        column_to_terms = map_variables_to_terms(
+            df=pd.DataFrame(columns=unique_vars),
+            apikey=args.key,
+            directory=dirname(args.output_file),
+            output_file=join(dirname(args.output_file), "json_map.json"),
+            json_file=args.json_map,
+            owl_file=args.owl,
+        )
     else:
-        column_to_terms = map_variables_to_terms(df=pd.DataFrame(columns=unique_vars), apikey=args.key, directory=dirname(args.output_file), output_file=join(dirname(args.output_file),"json_map.json"), json_file=args.json_map)
-
-    #get subjectID field from CSV
-    id_field = getSubjIDColumn(column_to_terms,df)
-
-
-    # WIP!!!#########################################################################################
-    #go line by line through CSV file creating NIDM structures
-    #If user has added an existing NIDM file as a command line parameter then add to existing file for subjects who exist in the NIDM file
+        column_to_terms = map_variables_to_terms(
+            df=pd.DataFrame(columns=unique_vars),
+            apikey=args.key,
+            directory=dirname(args.output_file),
+            output_file=join(dirname(args.output_file), "json_map.json"),
+            json_file=args.json_map,
+        )
+
+    # get subjectID field from CSV
+    id_field = getSubjIDColumn(column_to_terms, df)
+
+    # WIP!!!###################################################################
+    # go line by line through CSV file creating NIDM structures
+    # If user has added an existing NIDM file as a command line parameter then add to existing file for subjects who exist in the NIDM file
     if args.nidm_file is not None:
         print("Adding to NIDM file...")
-        #read in NIDM file
+        # read in NIDM file
         project = read_nidm(args.nidm_file)
 
+        root_act = project.graph.activity(
+            QualifiedName(provNamespace("niiri", Constants.NIIRI), getUUID()),
+            other_attributes={
+                Constants.NIDM_PROJECT_DESCRIPTION: "Brain volumes provenance document"
+            },
+        )
+
+        # this function sucks...more thought needed for version that works with adding to existing NIDM file versus creating a new NIDM file....
+        add_brainvolume_data(
+            nidmdoc=project,
+            df=df,
+            id_field=id_field,
+            root_act=root_act,
+            column_to_terms=column_to_terms,
+            png_file=args.png,
+            output_file=args.output_file,
+            source_row=source_row,
+            nidm_graph=True,
+        )
 
-        root_act = project.graph.activity(QualifiedName(provNamespace("niiri",Constants.NIIRI),getUUID()),other_attributes={Constants.NIDM_PROJECT_DESCRIPTION:"Brain volumes provenance document"})
-
-        #this function sucks...more thought needed for version that works with adding to existing NIDM file versus creating a new NIDM file....
-        add_brainvolume_data(nidmdoc=project,df=df,id_field=id_field,root_act=root_act,column_to_terms=column_to_terms,png_file=args.png,output_file=args.output_file,source_row=source_row,nidm_graph=True)
-
-        #serialize NIDM file
-        with open(args.output_file,'w') as f:
+        # serialize NIDM file
+        with open(args.output_file, "w", encoding="utf-8") as f:
             print("Writing NIDM file...")
             f.write(project.serializeTurtle())
-            #if args.png:
+            # if args.png:
             #    nidmdoc.save_DotGraph(str(args.output_file + ".png"), format="png")
 
-
-
-#        #find subject ids and sessions in NIDM document
-#        query = """SELECT DISTINCT ?session ?nidm_subj_id ?agent ?entity
-#                    WHERE {
-#                        ?activity prov:wasAssociatedWith ?agent ;
-#                            dct:isPartOf ?session  .
-#                        ?entity prov:wasGeneratedBy ?activity ;
-#                            nidm:hasImageUsageType nidm:Anatomical .
-#                        ?agent rdf:type prov:Agent ;
-#                            ndar:src_subject_id ?nidm_subj_id .
-#
-#                    }"""
-#        #print(query)
-#        qres = rdf_graph_parse.query(query)
-
-
-
-#        for row in qres:
-#            print('%s \t %s' %(row[0],row[1]))
-#            #find row in CSV file with subject id matching agent from NIDM file
-
-#            #csv_row = df.loc[df[id_field]==type(df[id_field][0])(row[1])]
-#            #find row in CSV file with matching subject id to the agent in the NIDM file
-#            #be carefull about data types...simply type-change dataframe subject id column and query to strings.
-#            #here we're removing the leading 0's from IDs because pandas.read_csv strips those unless you know ahead of
-#            #time which column is the subject id....
-#            csv_row = df.loc[df[id_field].astype('str').str.contains(str(row[1]).lstrip("0"))]
-
-#            #if there was data about this subject in the NIDM file already (i.e. an agent already exists with this subject id)
-#            #then add this brain volumes data to NIDM file, else skip it....
-#            if (not (len(csv_row.index)==0)):
-
-                #Here we're sure we have an agent in the NIDM graph that corresponds to the participant in the
-                #brain volumes data.  We don't know which AcquisitionObject (entity) describes the T1-weighted scans
-                #used for the project.  Since we don't have the SHA512 sums in the brain volumes data (YET) we can't
-                #really verify that it's a particular T1-weighted scan that was used for the brain volumes but we're
-                #simply, for the moment, going to assume it's the activity/session returned by the above query
-                #where we've specifically asked for the entity which has a nidm:hasImageUsageType nidm:Anatomical
-
-
-
-                #NIDM document entity uuid which has a nidm:hasImageUsageType nidm:Anatomical
-                #this is the entity that is associated with the brain volume report for this participant
-#                entity_uuid = row[3]
-
-                #Now we need to set up the entities/activities, etc. to add the brain volume data for this row of the
-                #CSV file and link it to the above entity and the agent for this participant which is row[0]
-
-
-
-
-
-                #add acquisition entity for assessment
-#                acq_entity = AssessmentObject(acquisition=acq)
-                #add qualified association with existing agent
-#                acq.add_qualified_association(person=row[2],role=Constants.NIDM_PARTICIPANT)
-
-#                #store other data from row with columns_to_term mappings
-#                for row_variable in csv_row:
-                    #check if row_variable is subject id, if so skip it
-#                    if row_variable==id_field:
-#                        continue
-#                    else:
-                        #get column_to_term mapping uri and add as namespace in NIDM document
-                        #provNamespace(Core.safe_string(None,string=str(row_variable)), column_to_terms[row_variable]["url"])
-#                        acq_entity.add_attributes({QualifiedName(provNamespace(Core.safe_string(None,string=str(row_variable)), column_to_terms[row_variable]["url"]), ""):csv_row[row_variable].values[0]})
-#                continue
-
-#        #serialize NIDM file
-#        with open(args.nidm_file,'w') as f:
-#            print("Writing NIDM file...")
-#            f.write(project.serializeTurtle())
-#            project.save_DotGraph(str(args.nidm_file + ".png"), format="png")
-    ##############################################################################################################################
-
+    #        #find subject ids and sessions in NIDM document
+    #        query = """SELECT DISTINCT ?session ?nidm_subj_id ?agent ?entity
+    #                    WHERE {
+    #                        ?activity prov:wasAssociatedWith ?agent ;
+    #                            dct:isPartOf ?session  .
+    #                        ?entity prov:wasGeneratedBy ?activity ;
+    #                            nidm:hasImageUsageType nidm:Anatomical .
+    #                        ?agent rdf:type prov:Agent ;
+    #                            ndar:src_subject_id ?nidm_subj_id .
+    #
+    #                    }"""
+    #        #print(query)
+    #        qres = rdf_graph_parse.query(query)
+
+    #        for row in qres:
+    #            print(f'{row[0]} \t {row[1]}')
+    #            #find row in CSV file with subject id matching agent from NIDM file
+
+    #            #csv_row = df.loc[df[id_field]==type(df[id_field][0])(row[1])]
+    #            #find row in CSV file with matching subject id to the agent in the NIDM file
+    #            #be careful about data types...simply type-change dataframe subject id column and query to strings.
+    #            #here we're removing the leading 0's from IDs because pandas.read_csv strips those unless you know ahead of
+    #            #time which column is the subject id....
+    #            csv_row = df.loc[df[id_field].astype('str').str.contains(str(row[1]).lstrip("0"))]
+
+    #            #if there was data about this subject in the NIDM file already (i.e. an agent already exists with this subject id)
+    #            #then add this brain volumes data to NIDM file, else skip it....
+    #            if (not (len(csv_row.index)==0)):
+
+    # Here we're sure we have an agent in the NIDM graph that corresponds to the participant in the
+    # brain volumes data.  We don't know which AcquisitionObject (entity) describes the T1-weighted scans
+    # used for the project.  Since we don't have the SHA512 sums in the brain volumes data (YET) we can't
+    # really verify that it's a particular T1-weighted scan that was used for the brain volumes but we're
+    # simply, for the moment, going to assume it's the activity/session returned by the above query
+    # where we've specifically asked for the entity which has a nidm:hasImageUsageType nidm:Anatomical
+
+    # NIDM document entity uuid which has a nidm:hasImageUsageType nidm:Anatomical
+    # this is the entity that is associated with the brain volume report for this participant
+    #                entity_uuid = row[3]
+
+    # Now we need to set up the entities/activities, etc. to add the brain volume data for this row of the
+    # CSV file and link it to the above entity and the agent for this participant which is row[0]
+
+    # add acquisition entity for assessment
+    #                acq_entity = AssessmentObject(acquisition=acq)
+    # add qualified association with existing agent
+    #                acq.add_qualified_association(person=row[2],role=Constants.NIDM_PARTICIPANT)
+
+    #                #store other data from row with columns_to_term mappings
+    #                for row_variable in csv_row:
+    # check if row_variable is subject id, if so skip it
+    #                    if row_variable==id_field:
+    #                        continue
+    #                    else:
+    # get column_to_term mapping uri and add as namespace in NIDM document
+    # provNamespace(Core.safe_string(None,string=str(row_variable)), column_to_terms[row_variable]["url"])
+    #                        acq_entity.add_attributes({QualifiedName(provNamespace(Core.safe_string(None,string=str(row_variable)), column_to_terms[row_variable]["url"]), ""):csv_row[row_variable].values[0]})
+    #                continue
+
+    #        #serialize NIDM file
+    #        with open(args.nidm_file,'w', encoding="utf-8") as f:
+    #            print("Writing NIDM file...")
+    #            f.write(project.serializeTurtle())
+    #            project.save_DotGraph(str(args.nidm_file + ".png"), format="png")
+    ###########################################################################
 
     else:
         print("Creating NIDM file...")
-        #If user did not choose to add this data to an existing NIDM file then create a new one for the CSV data
+        # If user did not choose to add this data to an existing NIDM file then create a new one for the CSV data
 
-        #create an empty NIDM graph
+        # create an empty NIDM graph
         nidmdoc = Core()
-        root_act = nidmdoc.graph.activity(QualifiedName(provNamespace("niiri",Constants.NIIRI),getUUID()),other_attributes={Constants.NIDM_PROJECT_DESCRIPTION:"Brain volumes provenance document"})
-
-        #this function sucks...more thought needed for version that works with adding to existing NIDM file versus creating a new NIDM file....
-        add_brainvolume_data(nidmdoc=nidmdoc,df=df,id_field=id_field,root_act=root_act,column_to_terms=column_to_terms,png_file=args.png,output_file=args.output_file,source_row=source_row)
+        root_act = nidmdoc.graph.activity(
+            QualifiedName(provNamespace("niiri", Constants.NIIRI), getUUID()),
+            other_attributes={
+                Constants.NIDM_PROJECT_DESCRIPTION: "Brain volumes provenance document"
+            },
+        )
+
+        # this function sucks...more thought needed for version that works with adding to existing NIDM file versus creating a new NIDM file....
+        add_brainvolume_data(
+            nidmdoc=nidmdoc,
+            df=df,
+            id_field=id_field,
+            root_act=root_act,
+            column_to_terms=column_to_terms,
+            png_file=args.png,
+            output_file=args.output_file,
+            source_row=source_row,
+        )
 
-
-
-        #serialize NIDM file
-        with open(args.output_file,'w') as f:
+        # serialize NIDM file
+        with open(args.output_file, "w", encoding="utf-8") as f:
             print("Writing NIDM file...")
             f.write(nidmdoc.serializeTurtle())
             if args.png:
-            #    nidmdoc.save_DotGraph(str(args.output_file + ".png"), format="png")
+                #    nidmdoc.save_DotGraph(str(args.output_file + ".png"), format="png")
 
                 nidmdoc.save_DotGraph(str(args.output_file + ".pdf"), format="pdf")
 
 
 if __name__ == "__main__":
-   main(sys.argv[1:])
+    main()
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/rest.py` & `pynidm-4.0.0/src/nidm/experiment/tools/rest.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,111 +1,101 @@
-import nidm.experiment.Navigate
-from nidm.experiment import Query
-import nidm.experiment.tools.rest_statistics
-from nidm.core import Constants
+from copy import deepcopy
+import functools
 import json
-import re
-from urllib import parse
 import logging
-import pprint
-import os
+import operator
+import re
 from tempfile import gettempdir
+from urllib import parse
+from urllib.parse import parse_qs, urlparse
+from numpy import mean, median, std
 from tabulate import tabulate
-from copy import copy, deepcopy
-from urllib.parse import urlparse, parse_qs
-from  nidm.experiment import Navigate
+from nidm.core import Constants
+from nidm.experiment import Navigate, Query
 from nidm.experiment.Utils import validate_uuid
 
-from numpy import std, mean, median
-import functools
-import operator
-
-from joblib import Memory
-memory = Memory(gettempdir(), verbose=0)
-USE_JOBLIB_CACHE = False
-
-import simplejson
 
 def convertListtoDict(lst):
-    '''
+    """
     This function converts a list to a dictionary
     :param lst: list to convert
     :return: dictionary
-    '''
-    res_dct = {lst[i]: lst[i+1] for i in range(0,len(lst),2)}
+    """
+    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)}
     return res_dct
-class RestParser:
 
 
+class RestParser:
     OBJECT_FORMAT = 0
     JSON_FORMAT = 1
     CLI_FORMAT = 2
 
-    def __init__(self, verbosity_level = 0, output_format = 0):
+    def __init__(self, verbosity_level=0, output_format=0):
         self.verbosity_level = verbosity_level
         self.output_format = output_format
-        self.restLog ("Setting output format {}".format(self.output_format), 4)
+        self.restLog(f"Setting output format {self.output_format}", 4)
 
     def setOutputFormat(self, output_format):
         self.output_format = output_format
-        self.restLog ("Setting output format {}".format(self.output_format), 4)
+        self.restLog(f"Setting output format {self.output_format}", 4)
 
     #####################
     # Standard formatters
     #####################
 
     def arrayFormat(self, result, headers):
-
         def allUUIDs(arr):
             uuid_only = True
             for s in arr:
-                if type(s) != str or not re.match("^[0-9a-f]+-[0-9a-f]+-[0-9a-f]+-[0-9a-f]+-[0-9a-f]+$", s):
+                if type(s) != str or not re.match(
+                    "^[0-9a-f]+-[0-9a-f]+-[0-9a-f]+-[0-9a-f]+-[0-9a-f]+$", s
+                ):
                     uuid_only = False
             return uuid_only
 
-
         if self.output_format == RestParser.JSON_FORMAT:
             return json.dumps(result, indent=2)
         elif self.output_format == RestParser.CLI_FORMAT:
             # most likely this is an array of strings but tabulate wants an array of arrays
             table = []
             for s in result:
-                table.append( [s] )
+                table.append([s])
             if allUUIDs(result) and headers[0] == "":
                 headers[0] = "UUID"
             return tabulate(table, headers=headers)
         return result
 
-    def dictFormat(self, result, headers=[""]):
+    def dictFormat(self, result, headers=None):
+        if headers is None:
+            headers = [""]
         if self.output_format == self.CLI_FORMAT:
             table = []
             appendicies = []
             for key in result:
-
                 # format a list
                 if type(result[key]) == list:
                     appendix = []
                     for line in result[key]:
-                        appendix.append( [ json.dumps(line) ] )
+                        appendix.append([json.dumps(line)])
                     appendicies.append(tabulate(appendix, [key]))
 
                     # also put really short lists in as comma separated values
-                    if len ( json.dumps(result[key]) ) < 40:
-                        table.append( [ json.dumps(key), ",".join(result[key]) ] )
+                    if len(json.dumps(result[key])) < 40:
+                        table.append([json.dumps(key), ",".join(result[key])])
 
                 # format a string
                 elif type(result[key]) == str:
-                    table.append([ json.dumps(key), result[key]])
+                    table.append([json.dumps(key), result[key]])
 
                 # format a dictionary
                 elif type(result[key]) == dict:
                     # put any dict into it's own table at the end (sort of like an appendix)
                     appendix = []
                     for inner_key in result[key]:
-                        appendix.append( [key, inner_key, result[key][inner_key] ] )
+                        appendix.append([key, inner_key, result[key][inner_key]])
                     appendicies.append(tabulate(appendix))
 
                 # format anything else
                 else:
                     col1 = json.dumps(key)
                     if type(result[key]) == set:
                         col2 = json.dumps(list(result[key]))
@@ -113,124 +103,177 @@
                         col2 = json.dumps(result[key])
                     table.append([col1, col2])
 
             return tabulate(table, headers) + "\n\n" + "\n\n".join(appendicies)
         else:
             return self.format(result)
 
-    def objectTableFormat(self,result, headers = None):
-
-        def flatten(obj, maxDepth=10, table = [], rowInProgress = [], depth = 0):
+    def objectTableFormat(self, result, headers=None):
+        def flatten(obj, maxDepth=10, table=None, rowInProgress=None, depth=0):
+            if table is None:
+                table = []
+            if rowInProgress is None:
+                rowInProgress = []
             for key in obj:
                 newrow = deepcopy(rowInProgress)
-                if depth< maxDepth and type(obj[key]) == dict:
+                if depth < maxDepth and type(obj[key]) == dict:
                     newrow.append(key)
-                    flatten(obj[key], maxDepth, table, newrow, depth+1)
+                    flatten(obj[key], maxDepth, table, newrow, depth + 1)
                 elif type(obj[key]) == str:
                     newrow.append(key)
                     newrow.append(obj[key])
                     table.append(newrow)
                 else:
                     newrow.append(json.dumps(obj[key]))
                     table.append(newrow)
 
             return table
 
-        if headers == None:
+        if headers is None:
             headers = [""]
 
-        return (tabulate(flatten(result), headers=headers))
-
+        return tabulate(flatten(result), headers=headers)
 
     def activityDataTableFormat(self, data):
-        headers = ['uuid', 'measure', 'label', 'value', 'unit']
-        rows=[]
+        headers = ["uuid", "measure", "label", "value", "unit"]
+        rows = []
         for inst_or_deriv in data:
             for d in inst_or_deriv.data:
-                rows.append( [inst_or_deriv.uuid, d.measureOf, d.label, d.value, d.hasUnit] )
-
-        return (tabulate(rows, headers=headers))
+                rows.append(
+                    [inst_or_deriv.uuid, d.measureOf, d.label, d.value, d.hasUnit]
+                )
 
+        return tabulate(rows, headers=headers)
 
     #####################
     # Custom formatters
     #####################
 
     def projectSummaryFormat(self, result):
-
         if self.output_format == self.CLI_FORMAT:
             ### added by DBK to sort things
             if "subjects" in result:
-                result["subjects"]["uuid"],result["subjects"]["subject id"] = self.sort_list(result["subjects"]["uuid"], result["subjects"]["subject id"])
+                (
+                    result["subjects"]["uuid"],
+                    result["subjects"]["subject id"],
+                ) = self.sort_list(
+                    result["subjects"]["uuid"], result["subjects"]["subject id"]
+                )
             else:
                 result["subjects"] = []
             if "data_elements" in result:
-                result["data_elements"]["uuid"],result["data_elements"]["label"] = self.sort_list(result["data_elements"]["uuid"], result["data_elements"]["label"])
+                (
+                    result["data_elements"]["uuid"],
+                    result["data_elements"]["label"],
+                ) = self.sort_list(
+                    result["data_elements"]["uuid"], result["data_elements"]["label"]
+                )
             else:
                 result["data_elements"] = []
 
             toptable = []
             for key in result:
-                if not key in ['subjects', 'data_elements', 'field_values']:
-                    toptable.append([ key, simplejson.dumps(result[key]) ])
+                if key not in ["subjects", "data_elements", "field_values"]:
+                    toptable.append([key, json.dumps(result[key])])
 
-            if 'field_values' in result and len(result['field_values']) > 0 :
-                fh_header = ['subject', 'label', 'value', 'unit', 'isAbout'] #result['field_values'][0].keys()
-                fh_rows = [ [x.subject, x.label, x.value, x.hasUnit, x.isAbout] for x in result['field_values']]
+            if "field_values" in result and len(result["field_values"]) > 0:
+                fh_header = [
+                    "subject",
+                    "label",
+                    "value",
+                    "unit",
+                    "isAbout",
+                ]  # result['field_values'][0].keys()
+                fh_rows = [
+                    [x.subject, x.label, x.value, x.hasUnit, x.isAbout]
+                    for x in result["field_values"]
+                ]
                 field_table = tabulate(fh_rows, fh_header)
-                #added by DBK, if they asked for fields then just give them the fields
-                return "{}".format(field_table)
+                # added by DBK, if they asked for fields then just give them the fields
+                return str(field_table)
             else:
-                field_table = ''
+                field_table = ""
 
             return "{}\n\n{}\n{}\n\n{}\n{}\n\n{}".format(
                 tabulate(toptable),
                 ### modified by DBK to account for new dictionary format of results
                 # tabulate({"subjects": result["subjects"]}, headers="keys"),
                 # sort list 2 by list 1 and replace unsorted version
-                tabulate([],headers=["Subject Information"]),
+                tabulate([], headers=["Subject Information"]),
                 tabulate(result["subjects"], headers="keys"),
-                #tabulate({"data_elements": result["data_elements"]}, headers="keys"),
-                tabulate([],headers = ["Data Elements"]),
-                tabulate({'uuid': result["data_elements"]['uuid'], 'label': result["data_elements"]['label']}, headers="keys"),
-                field_table
+                # tabulate({"data_elements": result["data_elements"]}, headers="keys"),
+                tabulate([], headers=["Data Elements"]),
+                tabulate(
+                    {
+                        "uuid": result["data_elements"]["uuid"],
+                        "label": result["data_elements"]["label"],
+                    },
+                    headers="keys",
+                ),
+                field_table,
             )
         else:
             # added by DBK to check if we had fields requested then we should just return those
-            if 'field_values' in result:
+            if "field_values" in result:
                 # convert result['field_values'] to a list for json export
-                return self.format(result['field_values'])
+                return self.format(result["field_values"])
             else:
                 return self.format(result)
 
     def formatDerivatives(self, derivative):
-        self.restLog("formatting derivatives in format {}".format(self.output_format), 5)
+        self.restLog(f"formatting derivatives in format {self.output_format}", 5)
         if self.output_format == self.CLI_FORMAT:
             table = []
             for uri in derivative:
                 for measurement in derivative[uri]["values"]:
-                    if measurement not in ["http://www.w3.org/ns/prov#wasGeneratedBy", "http://www.w3.org/1999/02/22-rdf-syntax-ns#type"]:  # skip some NIDM structure artifacts
-                        table.append([uri,
-                                      measurement,
-                                      derivative[uri]["values"][measurement]["label"],
-                                      "{} {}".format(derivative[uri]["values"][measurement]["value"], derivative[uri]["values"][measurement]["units"]),
-                                      derivative[uri]["values"][measurement]["datumType"],
-                                      derivative[uri]["values"][measurement]["isAbout"]])
-            return tabulate(table, headers=["Derivative_UUID", "Measurement", "Label", "Value", "Datumtype", "isAbout"])
+                    if measurement not in [
+                        "http://www.w3.org/ns/prov#wasGeneratedBy",
+                        "http://www.w3.org/1999/02/22-rdf-syntax-ns#type",
+                    ]:  # skip some NIDM structure artifacts
+                        table.append(
+                            [
+                                uri,
+                                measurement,
+                                derivative[uri]["values"][measurement]["label"],
+                                "{} {}".format(
+                                    derivative[uri]["values"][measurement]["value"],
+                                    derivative[uri]["values"][measurement]["units"],
+                                ),
+                                derivative[uri]["values"][measurement]["datumType"],
+                                derivative[uri]["values"][measurement]["isAbout"],
+                            ]
+                        )
+            return tabulate(
+                table,
+                headers=[
+                    "Derivative_UUID",
+                    "Measurement",
+                    "Label",
+                    "Value",
+                    "Datumtype",
+                    "isAbout",
+                ],
+            )
         else:
             return self.format(derivative)
 
     def dataElementsFormat(self, de_data):
         if self.output_format == self.CLI_FORMAT:
-
             table = []
-            headers = ['label', 'source_variable', 'hasUnit', 'description', 'dataElement', 'isAbout']
+            headers = [
+                "label",
+                "source_variable",
+                "hasUnit",
+                "description",
+                "dataElement",
+                "isAbout",
+            ]
 
             # for each data element, create a row with each value from the header
-            for de in de_data['data_elements']['data_type_info']:
+            for de in de_data["data_elements"]["data_type_info"]:
                 row = []
                 for h in headers:
                     row.append(de[h])
                 table.append(row)
 
             # print (de_data['data_elements']['data_type_info'][0])
 
@@ -239,106 +282,107 @@
 
             text = tabulate(sorted_table, headers)
             return text
         else:
             return self.format(de_data)
 
     def dataElementDetailsFormat(self, de_data):
-            return self.format(de_data)
-
+        return self.format(de_data)
 
     def subjectFormat(self, subject_data):
         if self.output_format == self.CLI_FORMAT:
-
             subjects = []
-            for subject in subject_data['subject']:
+            for subject in subject_data["subject"]:
                 subjects.append(subject)
             text = tabulate(subjects, headers=["Subject UUID", "Source Subject ID"])
 
-            if 'fields' in subject_data:
+            if "fields" in subject_data:
                 field_data = []
                 text += "\n\n"
-                for sub in subject_data['fields']:
-                    for act in subject_data['fields'][sub]:
-                        de = subject_data['fields'][sub][act]
+                for sub in subject_data["fields"]:
+                    for act in subject_data["fields"][sub]:
+                        de = subject_data["fields"][sub][act]
                         field_data.append([sub, act, de.label, de.value])
-                text += tabulate(field_data, headers=["Subject", "Activity", "Field", "Value"])
+                text += tabulate(
+                    field_data, headers=["Subject", "Activity", "Field", "Value"]
+                )
 
             return text
         else:
             return self.format(subject_data)
 
-    def subjectSummaryFormat(self,result):
+    def subjectSummaryFormat(self, result):
         if self.output_format == self.CLI_FORMAT:
-            special_keys = ['instruments', 'derivatives', "activity"]
+            special_keys = ["instruments", "derivatives", "activity"]
             toptable = []
             for key in result:
-                if not key in special_keys:
-                    toptable.append([ key, result[key] ])
+                if key not in special_keys:
+                    toptable.append([key, result[key]])
 
             for key in special_keys:
                 if type(result[key]) == dict:
-                    toptable.append( [ key, ",".join(result[key].keys()) ] )
+                    toptable.append([key, ",".join(result[key].keys())])
                 elif type(result[key]) == list:
-                    toptable.append( [ key, ",".join(result[key]) ])
+                    toptable.append([key, ",".join(result[key])])
                 else:
-                    toptable.append([key, json.dumps(result[key]) ])
-
-            instruments = self.objectTableFormat(result['instruments'], ["Instrument_UUID", "Category", "Value"])
-            derivatives=  self.formatDerivatives(result['derivatives'])
+                    toptable.append([key, json.dumps(result[key])])
 
-            return "{}\n\n{}\n\n{}".format(
-                tabulate(toptable),
-                derivatives,
-                instruments
+            instruments = self.objectTableFormat(
+                result["instruments"], ["Instrument_UUID", "Category", "Value"]
             )
+            derivatives = self.formatDerivatives(result["derivatives"])
+
+            return f"{tabulate(toptable)}\n\n{derivatives}\n\n{instruments}"
         else:
             return self.format(result)
 
-
-    def subjectSummaryFormat_v2(self,result):
+    def subjectSummaryFormat_v2(self, result):
         if self.output_format == self.CLI_FORMAT:
-            special_keys = ['instruments', 'derivatives', "activity"]
+            special_keys = ["instruments", "derivatives", "activity"]
             toptable = []
             for key in result:
-                if not key in special_keys:
-                    toptable.append([ key, result[key] ])
+                if key not in special_keys:
+                    toptable.append([key, result[key]])
 
             for key in special_keys:
                 if key in result:
                     if type(result[key]) == dict:
-                        toptable.append( [ key, ",".join(result[key].keys()) ] )
-                    if type(result[key]) == list and len(result[key]) > 0 and  type(result[key][0]) == Navigate.ActivityData:
-                        toptable.append( [ key, ",".join( [x.uuid for x in result[key] ]   ) ])
+                        toptable.append([key, ",".join(result[key].keys())])
+                    if (
+                        type(result[key]) == list
+                        and len(result[key]) > 0
+                        and type(result[key][0]) == Navigate.ActivityData
+                    ):
+                        toptable.append([key, ",".join([x.uuid for x in result[key]])])
                     elif type(result[key]) == list:
                         toptable.append([key, ",".join])
                     else:
-                        toptable.append([key, json.dumps(result[key]) ])
+                        toptable.append([key, json.dumps(result[key])])
 
-            instruments = self.activityDataTableFormat(result['instruments'])
-            derivatives=  self.activityDataTableFormat(result['derivatives'])
+            instruments = self.activityDataTableFormat(result["instruments"])
+            derivatives = self.activityDataTableFormat(result["derivatives"])
 
-            return "{}\n\n{}\n\n{}".format(tabulate(toptable), derivatives, instruments )
+            return f"{tabulate(toptable)}\n\n{derivatives}\n\n{instruments}"
         else:
             return self.format(result)
 
     ### Added by DBK to sorty data elements lists
     #####################
     # Sort Functions
     #####################
-    def sort_list (self,list1,list2):
-        '''
+    def sort_list(self, list1, list2):
+        """
         This function will sort list 1 using list 2 values, returning sorted list 1, sorted list 2
-        '''
+        """
 
         if len(list1) == 0 or len(list2) == 0:
             return list1, list2
 
-        list1 = list(zip(*sorted(zip(list2,list1))))[1]
-        return list1,sorted(list2)
+        list1 = list(zip(*sorted(zip(list2, list1))))[1]
+        return list1, sorted(list2)
 
     #####################
     # Route Functions
     #####################
 
     def dataelements(self):
         result = Navigate.GetDataelements(self.nidm_files)
@@ -348,66 +392,75 @@
         path = (urlparse(self.command)).path
         match = re.match(r"^/?dataelements/([^/\?]+)", path)
         dataelement = parse.unquote(str(match.group(1)))
 
         result = Navigate.GetDataelementDetails(self.nidm_files, dataelement)
         return self.dataElementDetailsFormat(result)
 
-
     def projects(self):
         result = []
         field_values = []
         self.restLog("Returning all projects", 2)
         projects = Query.GetProjectsUUID(self.nidm_files)
         for uuid in projects:
             result.append(str(uuid).replace(Constants.NIIRI, ""))
 
-
         # if we got fields, drill into each subject and pull out the field data
-        # subject details -> derivitives / instrument -> values -> element
-        if 'fields' in self.query and len(self.query['fields']) > 0:
+        # subject details -> derivatives / instrument -> values -> element
+        if "fields" in self.query and len(self.query["fields"]) > 0:
             subjects_set = set()
             dataelements_set = set()
-            self.restLog("Using fields {}".format(self.query['fields']), 2)
+            self.restLog(f"Using fields {self.query['fields']}", 2)
             # result['field_values'] = []
 
             for proj in projects:
                 # get all the synonyms for all the fields
-                field_synonyms = functools.reduce(operator.iconcat,
-                                                  [Query.GetDatatypeSynonyms(self.nidm_files, proj, x) for x in
-                                                   self.query['fields']], [])
-
-                files = self.nidm_files
-                all_subjects = Query.GetParticipantUUIDsForProject(self.nidm_files, proj, self.query['filter']) # nidm_file_list= files, project_id=proj['uuid'], filter=self.query['filter']):
-                for sub in all_subjects['uuid']:
-
+                field_synonyms = functools.reduce(
+                    operator.iconcat,
+                    [
+                        Query.GetDatatypeSynonyms(self.nidm_files, proj, x)
+                        for x in self.query["fields"]
+                    ],
+                    [],
+                )
+
+                # files = self.nidm_files
+                all_subjects = Query.GetParticipantUUIDsForProject(
+                    self.nidm_files, proj, self.query["filter"]
+                )  # nidm_file_list= files, project_id=proj['uuid'], filter=self.query['filter']):
+                for sub in all_subjects["uuid"]:
                     for activity in Navigate.getActivities(self.nidm_files, sub):
                         activity = Navigate.getActivityData(self.nidm_files, activity)
                         for data_element in activity.data:
                             if data_element.dataElement in field_synonyms:
                                 field_values.append(data_element._replace(subject=sub))
                                 subjects_set.add(sub)
-                                dataelements_set.add( (data_element.datumType, data_element.label) )
+                                dataelements_set.add(
+                                    (data_element.datumType, data_element.label)
+                                )
 
             if len(field_values) == 0:
-                raise ValueError("Supplied field not found. (" + ", ".join(self.query['fields']) + ")")
+                raise ValueError(
+                    "Supplied field not found. ("
+                    + ", ".join(self.query["fields"])
+                    + ")"
+                )
             else:
                 summary_result = {}
-                summary_result['subjects']= {"uuid":[], "subject id":[]}
+                summary_result["subjects"] = {"uuid": [], "subject id": []}
                 for sub in subjects_set:
                     summary_result["subjects"]["uuid"].append(sub)
                     summary_result["subjects"]["subject id"].append("")
-                summary_result['data_elements'] = {"uuid": [], "lable":[]}
+                summary_result["data_elements"] = {"uuid": [], "label": []}
                 for de in dataelements_set:
-                    summary_result['data_elements']["uuid"] = de[0]
-                    summary_result['data_elements']["label"] = de[1]
-                summary_result['field_values'] = field_values
+                    summary_result["data_elements"]["uuid"] = de[0]
+                    summary_result["data_elements"]["label"] = de[1]
+                summary_result["field_values"] = field_values
                 return self.projectSummaryFormat(summary_result)
 
-
         return self.format(result, ["UUID"])
 
     def ExpandProjectMetaData(self, meta_data):
         """
         Takes in the meta_data from GetProjectsMetadata() and adds
         the following statistics about each project to the existing
         meta_data structure:
@@ -416,377 +469,488 @@
          handedness of subjects (list)
          genders of subjects (list)
          number of subjects (int)
 
         :param meta_data:
         :return:
         """
-        for project_id in meta_data['projects']:
-
-            project_uuid = str(project_id)[6:] if (str(project_id).startswith("niiri:")) else project_id
-            project = meta_data['projects'][project_id]
+        for project_id in meta_data["projects"]:
+            project_uuid = (
+                str(project_id)[6:]
+                if (str(project_id).startswith("niiri:"))
+                else project_id
+            )
+            project = meta_data["projects"][project_id]
 
             ages = set()
             hands = set()
             genders = set()
 
-
             for session in Navigate.getSessions(self.nidm_files, project_uuid):
                 for acq in Navigate.getAcquisitions(self.nidm_files, session):
                     act_data = Navigate.getActivityData(self.nidm_files, acq)
                     for de in act_data.data:
-                        if de.isAbout == "http://uri.interlex.org/ilx_0100400" or de.isAbout == "http://uri.interlex.org/base/ilx_0100400":
-                            if de.value == 'n/a' or de.value =='nan':
+                        if de.isAbout in (
+                            "http://uri.interlex.org/ilx_0100400",
+                            "http://uri.interlex.org/base/ilx_0100400",
+                        ):
+                            if de.value in ("n/a", "nan"):
                                 ages.add(float("nan"))
                             else:
                                 ages.add(float(de.value))
-                        elif de.isAbout == "http://uri.interlex.org/ilx_0101292" or de.isAbout == "http://uri.interlex.org/base/ilx_0101292"\
-                                or de.isAbout == "http://uri.interlex.org/ilx_0738439" or de.isAbout == \
-                                "https://ndar.nih.gov/api/datadictionary/v2/dataelement/gender":
+                        elif de.isAbout in (
+                            "http://uri.interlex.org/ilx_0101292",
+                            "http://uri.interlex.org/base/ilx_0101292",
+                            "http://uri.interlex.org/ilx_0738439",
+                            "https://ndar.nih.gov/api/datadictionary/v2/dataelement/gender",
+                        ):
                             genders.add(de.value)
-                        elif de.isAbout == "http://purl.obolibrary.org/obo/PATO_0002201":
+                        elif (
+                            de.isAbout == "http://purl.obolibrary.org/obo/PATO_0002201"
+                        ):
                             hands.add(de.value)
 
             print(Query.GetParticipantUUIDsForProject(self.nidm_files, project_uuid))
 
-            project['age_max'] = max(ages) if len(ages) > 0 else 0
-            project['age_min'] = min(ages) if len(ages) > 0 else 0
-            project[Query.matchPrefix(str(Constants.NIDM_NUMBER_OF_SUBJECTS))] = len((Query.GetParticipantUUIDsForProject(self.nidm_files, project_uuid))['uuid'])
+            project["age_max"] = max(ages) if len(ages) > 0 else 0
+            project["age_min"] = min(ages) if len(ages) > 0 else 0
+            project[Query.matchPrefix(str(Constants.NIDM_NUMBER_OF_SUBJECTS))] = len(
+                (Query.GetParticipantUUIDsForProject(self.nidm_files, project_uuid))[
+                    "uuid"
+                ]
+            )
             project[str(Constants.NIDM_GENDER)] = list(genders)
             project[str(Constants.NIDM_HANDEDNESS)] = list(hands)
 
     def projectStats(self):
-        result = dict()
+        result = {}
         subjects = None
         path = (urlparse(self.command)).path
 
         match = re.match(r"^/?statistics/projects/([^/]+)\??$", path)
-        id = parse.unquote(str(match.group(1)))
-        self.restLog("Returning project {} stats metadata".format(id), 2)
+        id_ = parse.unquote(str(match.group(1)))
+        self.restLog(f"Returning project {id_} stats metadata", 2)
 
         meta_data = Query.GetProjectsMetadata(self.nidm_files)
         self.ExpandProjectMetaData(meta_data)
         projects = Query.compressForJSONResponse(meta_data)
 
-        for pid in projects['projects'].keys():
-            self.restLog("comparng " + str(pid) + " with " + str(id), 5)
-            self.restLog("comparng " + str(pid) + " with " + Constants.NIIRI + id, 5)
-            self.restLog("comparng " + str(pid) + " with niiri:" + id, 5)
-            if pid == id or pid == Constants.NIIRI + id or pid == "niiri:" + id:
-                # stip off prefixes to make it more human readable
-                for key in projects['projects'][pid]:
+        for pid in projects["projects"].keys():
+            self.restLog("comparng " + str(pid) + " with " + str(id_), 5)
+            self.restLog("comparng " + str(pid) + " with " + Constants.NIIRI + id_, 5)
+            self.restLog("comparng " + str(pid) + " with niiri:" + id_, 5)
+            if pid in (id_, Constants.NIIRI + id_, "niiri:" + id_):
+                # strip off prefixes to make it more human readable
+                for key in projects["projects"][pid]:
                     short_key = key
-                    possible_prefix = re.sub(':.*', '', short_key)
+                    possible_prefix = re.sub(":.*", "", short_key)
                     if possible_prefix in Constants.namespaces:
-                        short_key = re.sub('^.*:', '', short_key)
-                    result[short_key] = projects['projects'][pid][key]
+                        short_key = re.sub("^.*:", "", short_key)
+                    result[short_key] = projects["projects"][pid][key]
 
-        # now get any fields they reqested
-        for field in self.query['fields']:
-            if subjects == None:
-                subjects = Query.GetParticipantUUIDsForProject(tuple(self.nidm_files), project_id=id, filter=self.query['filter'])
-                result['subjects'] = subjects['uuid']
-            bits = field.split('.')
+        # now get any fields they requested
+        for field in self.query["fields"]:
+            if subjects is None:
+                subjects = Query.GetParticipantUUIDsForProject(
+                    tuple(self.nidm_files), project_id=id_, filter=self.query["filter"]
+                )
+                result["subjects"] = subjects["uuid"]
+            bits = field.split(".")
             if len(bits) > 1:
-                stat_type = self.getStatType(bits[0]) # should be either instruments or derivatives for now.
-                self.addFieldStats(result, id, subjects['uuid'], bits[1], stat_type) # bits[1] will be the ID
+                stat_type = self.getStatType(
+                    bits[0]
+                )  # should be either instruments or derivatives for now.
+                self.addFieldStats(
+                    result, id_, subjects["uuid"], bits[1], stat_type
+                )  # bits[1] will be the ID
 
         return self.dictFormat(result)
 
     STAT_TYPE_OTHER = 0
     STAT_TYPE_INSTRUMENTS = 1
     STAT_TYPE_DERIVATIVES = 2
+
     def getStatType(self, name):
-        lookup = {"instruments": self.STAT_TYPE_INSTRUMENTS, "derivatives" : self.STAT_TYPE_DERIVATIVES}
-        if name in lookup: return lookup[name]
+        lookup = {
+            "instruments": self.STAT_TYPE_INSTRUMENTS,
+            "derivatives": self.STAT_TYPE_DERIVATIVES,
+        }
+        if name in lookup:
+            return lookup[name]
         return self.STAT_TYPE_OTHER
 
-
     @staticmethod
     def getTailOfURI(uri):
-        if '#' in uri:
-            return uri[uri.rfind('#') + 1:]
+        if "#" in uri:
+            return uri[uri.rfind("#") + 1 :]
         else:
-            return uri[uri.rfind('/') + 1:]
-
+            return uri[uri.rfind("/") + 1 :]
 
-    def addFieldStats(self, result, project, subjects, field, type):
-        '''
+    def addFieldStats(self, result, project, subjects, field, type):  # noqa: A002
+        """
         Geneerates basic stats on a group of subjects and adds it to the result
         :param result:
         :param subjects:
         :param field:
         :return:
-        '''
+        """
         values = []
         for s in subjects:
             if type == self.STAT_TYPE_INSTRUMENTS:
-                data = Query.GetParticipantInstrumentData(tuple(self.nidm_files), project, s)
-                for i in data:
-                    if field in data[i]:
-                        values.append( float(data[i][field]) )
+                data = Query.GetParticipantInstrumentData(
+                    tuple(self.nidm_files), project, s
+                )
+                for v in data.values():
+                    if field in v:
+                        values.append(float(v[field]))
             # derivatives are of the form [UUID]['values'][URI]{datumType, label, values, units}
             if type == self.STAT_TYPE_DERIVATIVES:
-                data = Query.GetDerivativesDataForSubject(tuple(self.nidm_files), project, s)
-                for deriv in data:
-                    for URI in data[deriv]['values']:
-                        measures = data[deriv]['values'][URI]
-                        if field == measures['label'] or field == self.getTailOfURI(URI):
-                            values.append( float(measures['value']) )
+                data = Query.GetDerivativesDataForSubject(
+                    tuple(self.nidm_files), project, s
+                )
+                for deriv_value in data.values():
+                    for URI in deriv_value["values"]:
+                        measures = deriv_value["values"][URI]
+                        if field == measures["label"] or field == self.getTailOfURI(
+                            URI
+                        ):
+                            values.append(float(measures["value"]))
 
         if len(values) > 0:
             med = median(values)
             avg = mean(values)
             st = std(values)
             mn = min(values)
             mx = max(values)
         else:
             med = avg = st = mn = mx = None
-        result[field] = {"max": mx, "min": mn, "median": med, "mean": avg, "standard_deviation": st}
+        result[field] = {
+            "max": mx,
+            "min": mn,
+            "median": med,
+            "mean": avg,
+            "standard_deviation": st,
+        }
 
     def projectSummary(self):
-
         match = re.match(r"^/?projects/([^/]+)$", self.command)
-        id = parse.unquote(str(match.group(1)))
-        self.restLog("Returing project {} summary".format(id), 2)
-
-        result = nidm.experiment.Navigate.GetProjectAttributes(self.nidm_files, project_id=id)
-        result['subjects'] = Query.GetParticipantUUIDsForProject(self.nidm_files, project_id=id, filter=self.query['filter'])
-        result['data_elements'] = Query.GetProjectDataElements(self.nidm_files, project_id=id)
+        pid = parse.unquote(str(match.group(1)))
+        self.restLog(f"Returning project {pid} summary", 2)
 
+        result = Navigate.GetProjectAttributes(self.nidm_files, project_id=pid)
+        result["subjects"] = Query.GetParticipantUUIDsForProject(
+            self.nidm_files, project_id=pid, filter=self.query["filter"]
+        )
+        result["data_elements"] = Query.GetProjectDataElements(
+            self.nidm_files, project_id=pid
+        )
 
         # if we got fields, drill into each subject and pull out the field data
-        # subject details -> derivitives / instrument -> values -> element
-        if 'fields' in self.query and len(self.query['fields']) > 0:
-            self.restLog("Using fields {}".format(self.query['fields']), 2)
-            result['field_values'] = []
+        # subject details -> derivatives / instrument -> values -> element
+        if "fields" in self.query and len(self.query["fields"]) > 0:
+            self.restLog(f"Using fields {self.query['fields']}", 2)
+            result["field_values"] = []
             # get all the synonyms for all the fields
-            field_synonyms = functools.reduce( operator.iconcat, [ Query.GetDatatypeSynonyms(self.nidm_files, id, x) for x in self.query['fields'] ], [])
-            for sub in result['subjects']['uuid']:
-
+            field_synonyms = functools.reduce(
+                operator.iconcat,
+                [
+                    Query.GetDatatypeSynonyms(self.nidm_files, pid, x)
+                    for x in self.query["fields"]
+                ],
+                [],
+            )
+            for sub in result["subjects"]["uuid"]:
                 for activity in Navigate.getActivities(self.nidm_files, sub):
                     activity = Navigate.getActivityData(self.nidm_files, activity)
                     for data_element in activity.data:
                         if data_element.dataElement in field_synonyms:
-                            result['field_values'].append(data_element._replace(subject=sub))
-
-            if len(result['field_values']) == 0:
-                raise ValueError("Supplied field not found. (" + ", ".join(self.query['fields']) + ")")
+                            result["field_values"].append(
+                                data_element._replace(subject=sub)
+                            )
+
+            if len(result["field_values"]) == 0:
+                raise ValueError(
+                    "Supplied field not found. ("
+                    + ", ".join(self.query["fields"])
+                    + ")"
+                )
 
         return self.projectSummaryFormat(result)
 
-
     def subjectsList(self):
         match = re.match(r"^/?projects/([^/]+)/subjects/?$", self.command)
         project = match.group((1))
-        self.restLog("Returning all agents matching filter '{}' for project {}".format(self.query['filter'], project), 2)
+        self.restLog(
+            f"Returning all agents matching filter '{self.query['filter']}' for project {project}",
+            2,
+        )
         # result = Query.GetParticipantUUIDsForProject(self.nidm_files, project, self.query['filter'], None)
         all_subjects = Navigate.getSubjects(self.nidm_files, project)
         result = {}
-        result['uuid'] = []
-        result['subject id'] = []
+        result["uuid"] = []
+        result["subject id"] = []
         for sub_uuid in all_subjects:
-            if Query.CheckSubjectMatchesFilter(self.nidm_files,project, sub_uuid, self.query['filter']):
-                uuid_string = (str(sub_uuid)).split('/')[-1]  # srip off the http://whatever/whatever/
-                result['uuid'].append(uuid_string)
+            if Query.CheckSubjectMatchesFilter(
+                self.nidm_files, project, sub_uuid, self.query["filter"]
+            ):
+                uuid_string = (str(sub_uuid)).split("/")[
+                    -1
+                ]  # srip off the http://whatever/whatever/
+                result["uuid"].append(uuid_string)
                 sid = Navigate.getSubjectIDfromUUID(self.nidm_files, sub_uuid)
-                result['subject id'].append(str(sid))
+                result["subject id"].append(str(sid))
         return self.format(result)
 
     def projectSubjectSummary(self):
         match = re.match(r"^/?projects/([^/]+)/subjects/([^/]+)/?$", self.command)
         subject = Navigate.normalizeSingleSubjectToUUID(self.nidm_files, match.group(2))
-        self.restLog("Returning info about subject {}".format(match.group(2)), 2)
-        return self.subjectSummaryFormat(Query.GetParticipantDetails(self.nidm_files, match.group(1), subject))
+        self.restLog(f"Returning info about subject {match[2]}", 2)
+        return self.subjectSummaryFormat(
+            Query.GetParticipantDetails(self.nidm_files, match.group(1), subject)
+        )
 
     def getFieldInfoForSubject(self, project, subject):
-        '''
+        """
         Returns a dictionary of activities where the subject has matching field data
         The result[activity] is the full data_element so to get the value you would use result[activity].value
         Note that a subject could match the same field in multiple activities.
 
         :param project:
         :param subject:
         :return:
-        '''
+        """
         result = {}
         # if we got fields, drill into each subject and pull out the field data
-        # subject details -> derivitives / instrument -> values -> element
-        if 'fields' in self.query and len(self.query['fields']) > 0:
-            # get all the synonyms for all the fields - we can seach for them all at once
-            field_synonyms = functools.reduce( operator.iconcat, [ Query.GetDatatypeSynonyms(self.nidm_files, project, x) for x in self.query['fields'] ], [])
+        # subject details -> derivatives / instrument -> values -> element
+        if "fields" in self.query and len(self.query["fields"]) > 0:
+            # get all the synonyms for all the fields - we can search for them all at once
+            field_synonyms = functools.reduce(
+                operator.iconcat,
+                [
+                    Query.GetDatatypeSynonyms(self.nidm_files, project, x)
+                    for x in self.query["fields"]
+                ],
+                [],
+            )
 
             # print (field_synonyms)
 
             for activity in Navigate.getActivities(self.nidm_files, subject):
                 activity_data = Navigate.getActivityData(self.nidm_files, activity)
                 # print ([ x.label for x in activity.data])
                 for data_element in activity_data.data:
-                    if not set([data_element.dataElement, data_element.label, data_element.isAbout]).isdisjoint(set(field_synonyms)):
+                    if not set(
+                        [
+                            data_element.dataElement,
+                            data_element.label,
+                            data_element.isAbout,
+                        ]
+                    ).isdisjoint(set(field_synonyms)):
                         result[Query.URITail(activity)] = data_element
         return result
 
-
     def subjects(self):
-        self.restLog("Returning info about subjects",2)
+        self.restLog("Returning info about subjects", 2)
         projects = Navigate.getProjects(self.nidm_files)
-        result = {'subject': []}
-        if 'fields' in self.query and len(self.query['fields']) > 0:
-            result['fields'] = {}
+        result = {"subject": []}
+        if "fields" in self.query and len(self.query["fields"]) > 0:
+            result["fields"] = {}
 
         for proj in projects:
             subs = Navigate.getSubjects(self.nidm_files, proj)
             for s in subs:
-                result['subject'].append( [Query.URITail(s), Navigate.getSubjectIDfromUUID(self.nidm_files, s) ])
+                result["subject"].append(
+                    [
+                        Query.URITail(s),
+                        Navigate.getSubjectIDfromUUID(self.nidm_files, s),
+                    ]
+                )
 
                 # print ("getting info for " + str(s))
                 x = self.getFieldInfoForSubject(proj, s)
-                if x != {}:
-                    result['fields'][Query.URITail(s)] = x
+                if x:
+                    result["fields"][Query.URITail(s)] = x
         return self.subjectFormat(result)
 
     def subjectSummary(self):
         match = re.match(r"^/?subjects/([^/]+)/?$", self.command)
-        self.restLog("Returning info about subject {}".format(match.group(1)), 2)
-        id = match.group(1)
+        self.restLog(f"Returning info about subject {match[1]}", 2)
+        sid = match.group(1)
 
         # if we were passed in a sub_id rather than a UUID, lookup the associated UUID. (we might get multiple!)
-        if validate_uuid(id):
-            sub_ids = id
+        if validate_uuid(sid):
+            sub_ids = sid
         else:
-            sub_ids = Navigate.getSubjectUUIDsfromID(self.nidm_files, id)
+            sub_ids = Navigate.getSubjectUUIDsfromID(self.nidm_files, sid)
             if len(sub_ids) == 1:
                 sub_ids = sub_ids[0]
 
-        activities = Navigate.getActivities(self.nidm_files, id)
+        activities = Navigate.getActivities(self.nidm_files, sid)
         activityData = []
         for a in activities:
             data = Navigate.getActivityData(self.nidm_files, a)
             activityData.append(data)
 
-        return self.subjectSummaryFormat_v2( {'uuid': sub_ids,
-                'instruments' : list(filter(lambda x: x.category == 'instrument', activityData)),
-                'derivatives' : list(filter(lambda x: x.category == 'derivative', activityData))
-                })
-
+        return self.subjectSummaryFormat_v2(
+            {
+                "uuid": sub_ids,
+                "instruments": list(
+                    filter(lambda x: x.category == "instrument", activityData)
+                ),
+                "derivatives": list(
+                    filter(lambda x: x.category == "derivative", activityData)
+                ),
+            }
+        )
 
     def instrumentsList(self):
         result = []
-        match = re.match(r"^/?projects/([^/]+)/subjects/([^/]+)/instruments/?$", self.command)
-        self.restLog("Returning instruments in subject {}".format(match.group(2)), 2)
+        match = re.match(
+            r"^/?projects/([^/]+)/subjects/([^/]+)/instruments/?$", self.command
+        )
+        self.restLog(f"Returning instruments in subject {match[2]}", 2)
         subject = Navigate.normalizeSingleSubjectToUUID(self.nidm_files, match.group(2))
-        instruments = Query.GetParticipantInstrumentData(self.nidm_files, match.group(1), subject)
+        instruments = Query.GetParticipantInstrumentData(
+            self.nidm_files, match.group(1), subject
+        )
         for i in instruments:
             result.append(i)
         return self.format(result)
 
     def instrumentSummary(self):
-        match = re.match(r"^/?projects/([^/]+)/subjects/([^/]+)/instruments/([^/]+)$", self.command)
-        self.restLog("Returning instrument {} in subject {}".format(match.group(3), match.group(2)), 2)
+        match = re.match(
+            r"^/?projects/([^/]+)/subjects/([^/]+)/instruments/([^/]+)$", self.command
+        )
+        self.restLog(
+            f"Returning instrument {match[3]} in subject {match[2]}",
+            2,
+        )
         subject = Navigate.normalizeSingleSubjectToUUID(self.nidm_files, match.group(2))
-        instruments = Query.GetParticipantInstrumentData(self.nidm_files, match.group(1), subject)
+        instruments = Query.GetParticipantInstrumentData(
+            self.nidm_files, match.group(1), subject
+        )
         return self.format(instruments[match.group(3)], headers=["Category", "Value"])
 
     def derivativesList(self):
         result = []
         match = re.match(r"^/?projects/([^/]+)/subjects/([^/]+)", self.command)
-        self.restLog("Returning derivatives in subject {}".format(match.group(2)), 2)
+        self.restLog(f"Returning derivatives in subject {match[2]}", 2)
         subject = Navigate.normalizeSingleSubjectToUUID(self.nidm_files, match.group(2))
-        derivatives = Query.GetDerivativesDataForSubject(self.nidm_files, match.group(1), subject)
+        derivatives = Query.GetDerivativesDataForSubject(
+            self.nidm_files, match.group(1), subject
+        )
         for s in derivatives:
             result.append(s)
         return self.format(result)
 
     def derivativeSummary(self):
-        match = re.match(r"^/?projects/([^/]+)/subjects/([^/]+)/derivatives/([^/]+)", self.command)
+        match = re.match(
+            r"^/?projects/([^/]+)/subjects/([^/]+)/derivatives/([^/]+)", self.command
+        )
         subject = Navigate.normalizeSingleSubjectToUUID(self.nidm_files, match.group(2))
         uri = match.group(3)
-        self.restLog("Returning stat {} in subject {}".format(uri, match.group(2)), 2)
-        derivatives = Query.GetDerivativesDataForSubject(self.nidm_files, match.group(1), subject)
+        self.restLog(f"Returning stat {uri} in subject {match[2]}", 2)
+        derivatives = Query.GetDerivativesDataForSubject(
+            self.nidm_files, match.group(1), subject
+        )
 
-        single_derivative = { uri: derivatives[uri] }
+        single_derivative = {uri: derivatives[uri]}
 
         self.restLog("Formatting single derivative", 5)
 
-
         return self.formatDerivatives(single_derivative)
 
     def run(self, nidm_files, command):
         try:
             self.restLog("parsing command " + command, 1)
             self.restLog("Files to read:" + str(nidm_files), 1)
-            self.restLog("Using {} as the graph cache directory".format(gettempdir()), 1)
+            self.restLog(f"Using {gettempdir()} as the graph cache directory", 1)
 
             self.nidm_files = tuple(nidm_files)
-            #replace # marks with %23 - they are sometimes used in the is_about terms
+            # replace # marks with %23 - they are sometimes used in the is_about terms
             escaped = command.replace("#", "%23")
             u = urlparse(escaped)
             self.command = u.path
             self.query = parse_qs(u.query)
 
-            if 'filter' in self.query:
-                self.query['filter'] = self.query['filter'][0]
+            if "filter" in self.query:
+                self.query["filter"] = self.query["filter"][0]
             else:
-                self.query['filter'] = None
+                self.query["filter"] = None
 
             # normalize query dict for our particular situation
-            if 'fields' in self.query:
-                self.query['fields'] = str.split(self.query['fields'][0], ',')
+            if "fields" in self.query:
+                self.query["fields"] = str.split(self.query["fields"][0], ",")
             else:
-                self.query['fields'] = []
+                self.query["fields"] = []
 
             return self.route()
         except ValueError as ve:
-            logging.error("Exception: {}".format(ve))
-            return (self.format({"error": "One of the supplied field terms was not found."}))
-
-
+            logging.error("Exception: %s", ve)
+            return self.format(
+                {"error": "One of the supplied field terms was not found."}
+            )
 
     def route(self):
+        if re.match(r"^/?dataelements/?$", self.command):
+            return self.dataelements()
 
-        if re.match(r"^/?dataelements/?$", self.command): return self.dataelements()
-
-        if re.match(r"^/?dataelements/[^/]+/?$", self.command): return self.dataelementsSummary()
+        if re.match(r"^/?dataelements/[^/]+/?$", self.command):
+            return self.dataelementsSummary()
 
-        if re.match(r"^/?projects/?$", self.command): return self.projects()
+        if re.match(r"^/?projects/?$", self.command):
+            return self.projects()
 
-        if re.match(r"^/?statistics/projects/[^/]+$", self.command): return self.projectStats()
+        if re.match(r"^/?statistics/projects/[^/]+$", self.command):
+            return self.projectStats()
 
-        if re.match(r"^/?projects/[^/]+$", self.command): return self.projectSummary()
+        if re.match(r"^/?projects/[^/]+$", self.command):
+            return self.projectSummary()
 
-        if re.match(r"^/?subjects/?$", self.command): return self.subjects()
+        if re.match(r"^/?subjects/?$", self.command):
+            return self.subjects()
 
-        if re.match(r"^/?subjects/[^/]+$", self.command): return self.subjectSummary()
+        if re.match(r"^/?subjects/[^/]+$", self.command):
+            return self.subjectSummary()
 
-        if re.match(r"^/?projects/[^/]+/subjects/?$", self.command): return self.subjectsList()
+        if re.match(r"^/?projects/[^/]+/subjects/?$", self.command):
+            return self.subjectsList()
 
-        if re.match(r"^/?projects/[^/]+/subjects/[^/]+/?$", self.command): return self.projectSubjectSummary()
+        if re.match(r"^/?projects/[^/]+/subjects/[^/]+/?$", self.command):
+            return self.projectSubjectSummary()
 
-        if re.match(r"^/?projects/[^/]+/subjects/[^/]+/instruments/?$", self.command): return self.instrumentsList()
+        if re.match(r"^/?projects/[^/]+/subjects/[^/]+/instruments/?$", self.command):
+            return self.instrumentsList()
 
-        if re.match(r"^/?projects/[^/]+/subjects/[^/]+/instruments/[^/]+/?$", self.command): return self.instrumentSummary()
+        if re.match(
+            r"^/?projects/[^/]+/subjects/[^/]+/instruments/[^/]+/?$", self.command
+        ):
+            return self.instrumentSummary()
 
-        if re.match(r"^/?projects/[^/]+/subjects/[^/]+/derivatives/?$", self.command): return self.derivativesList()
+        if re.match(r"^/?projects/[^/]+/subjects/[^/]+/derivatives/?$", self.command):
+            return self.derivativesList()
 
-        if re.match(r"^/?projects/[^/]+/subjects/[^/]+/derivatives/[^/]+/?$", self.command): return self.derivativeSummary()
+        if re.match(
+            r"^/?projects/[^/]+/subjects/[^/]+/derivatives/[^/]+/?$", self.command
+        ):
+            return self.derivativeSummary()
 
         self.restLog("NO MATCH!", 2)
 
         return {"error": "No match for supplied URI"}
 
-
     def restLog(self, message, verbosity_of_message):
         if verbosity_of_message <= self.verbosity_level:
-            print (message)
-
+            print(message)
 
-
-    def format(self, result, headers = [""]):
+    def format(self, result, headers=None):
+        if headers is None:
+            headers = [""]
         if self.output_format == RestParser.JSON_FORMAT:
-            json_str = simplejson.dumps(result, indent=2)
+            json_str = json.dumps(result, indent=2)
             return json_str
 
         elif self.output_format == RestParser.CLI_FORMAT:
             if type(result) == dict:
                 return self.dictFormat(result, headers)
             if type(result) == list:
                 return self.arrayFormat(result, headers)
```

### Comparing `pynidm-3.9.7/nidm/experiment/tools/rest_statistics.py` & `pynidm-4.0.0/src/nidm/experiment/tools/rest_statistics.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,55 +1,64 @@
-import nidm.experiment.Navigate
+import sys
 from nidm.core import Constants
-from tempfile import gettempdir
 from nidm.experiment import Navigate
 import nidm.experiment.tools.rest
 
-import sys
-
-from joblib import Memory
-memory = Memory(gettempdir(), verbose=0)
-USE_JOBLIB_CACHE = False
-
 
 def GetProjectsComputedMetadata(nidm_file_list):
-    '''
+    """
      :param nidm_file_list: List of one or more NIDM files to query across for list of Projects
-    :return: Dictionay or projects, each project having a dictionary of project stats
+    :return: Dictionary or projects, each project having a dictionary of project stats
              including age_max, age_min, gender list, and handedness list.
-    '''
+    """
 
     meta_data = {"projects": {}}
     projects = Navigate.getProjects(tuple(nidm_file_list))
     for p in projects:
         proj_id = nidm.experiment.tools.rest.RestParser.getTailOfURI(str(p))
-        meta_data["projects"][proj_id] = {"age_max": 0, "age_min": sys.maxsize, "gender": [], "handedness": [] }
-        meta_data["projects"][proj_id].update(Navigate.GetProjectAttributes(tuple(nidm_file_list), p))
+        meta_data["projects"][proj_id] = {
+            "age_max": 0,
+            "age_min": sys.maxsize,
+            "gender": [],
+            "handedness": [],
+        }
+        meta_data["projects"][proj_id].update(
+            Navigate.GetProjectAttributes(tuple(nidm_file_list), p)
+        )
         gender_set = set()
         hand_set = set()
         subjects = Navigate.getSubjects(tuple(nidm_file_list), p)
         for s in subjects:
             activities = Navigate.getActivities(tuple(nidm_file_list), s)
             meta_data["projects"][proj_id]["number_of_subjects"] = len(subjects)
 
             for a in activities:
                 data = Navigate.getActivityData(tuple(nidm_file_list), a)
-                if type(data) == nidm.experiment.Navigate.ActivityData:
+                if type(data) == Navigate.ActivityData:
                     for x in data.data:
                         if x.isAbout == Constants.NIDM_IS_ABOUT_AGE:
-                            if float(x.value) > meta_data["projects"][proj_id]["age_max"]:
-                                meta_data["projects"][proj_id]["age_max"] = float(x.value)
-                            if float(x.value) < meta_data["projects"][proj_id]["age_min"]:
-                                meta_data["projects"][proj_id]["age_min"] = float(x.value)
+                            if (
+                                float(x.value)
+                                > meta_data["projects"][proj_id]["age_max"]
+                            ):
+                                meta_data["projects"][proj_id]["age_max"] = float(
+                                    x.value
+                                )
+                            if (
+                                float(x.value)
+                                < meta_data["projects"][proj_id]["age_min"]
+                            ):
+                                meta_data["projects"][proj_id]["age_min"] = float(
+                                    x.value
+                                )
                         if x.isAbout == Constants.NIDM_IS_ABOUT_GENDER:
                             gender_set.add(str(x.value))
                         if x.isAbout == Constants.NIDM_IS_ABOUT_HANDEDNESS:
                             hand_set.add(str(x.value))
         meta_data["projects"][proj_id]["gender"] = list(gender_set)
         meta_data["projects"][proj_id]["handedness"] = list(hand_set)
 
-
     return meta_data
     # meta_data = GetProjectsMetadata(nidm_file_list)
     # ExtractProjectSummary(meta_data, nidm_file_list)
 
     # return compressForJSONResponse(meta_data)
```

### Comparing `pynidm-3.9.7/nidm/workflows/ProcessExecution.py` & `pynidm-4.0.0/src/nidm/workflows/ProcessExecution.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,37 +1,33 @@
 import prov.model as pm
-
 from ..core import Constants
-
-from ..experiment.Core import Core
-from ..experiment.Core import getUUID
+from ..experiment.Core import Core, getUUID
 
 
 class ProcessExecution(pm.ProvActivity, Core):
     """Class for NIDM-Workflow ProcessExecution Objects.
 
     Default constructor uses empty graph with namespaces added from
     NIDM/Scripts/Constants.py. Additional alternate constructors for
     user-supplied graphs and default namespaces (i.e. from Constants.py)
     and user-supplied graph and namespaces
 
     """
+
     def __init__(self, parentDoc=None, attributes=None):
         """
-        Default contructor, creates document and adds Process activity to graph
+        Default constructor, creates document and adds Process activity to graph
         with optional attributes
-        
+
         :param parentDoc: optional ProvDocument
         :param attributes: optional dictionary of attributes to add
         """
 
-        #set graph document
-        if (parentDoc):
+        # set graph document
+        if parentDoc:
             self.graph = parentDoc
         else:
             self.graph = Constants.NIDMDocument(namespaces=Constants.namespaces)
 
-         #execute default parent class constructor
-        super(ProcessExecution, self).__init__(self.graph,
-                                               pm.PROV[getUUID()],
-                                               attributes)
+        # execute default parent class constructor
+        super().__init__(self.graph, pm.PROV[getUUID()], attributes)
         self.graph._add_record(self)
```

### Comparing `pynidm-3.9.7/nidm/workflows/ProcessSpecification.py` & `pynidm-4.0.0/src/nidm/workflows/ProcessSpecification.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,40 +1,35 @@
 import prov.model as pm
-
 from ..core import Constants
-
-from ..experiment.Core import Core
-from ..experiment.Core import getUUID
+from ..experiment.Core import Core, getUUID
 
 
 class ProcessSpecification(pm.ProvEntity, Core):
     """Class for NIDM-Workflow Process Objects.
 
     Default constructor uses empty graph with namespaces added from
     NIDM/Scripts/Constants.py. Additional alternate constructors for
     user-supplied graphs and default namespaces (i.e. from Constants.py)
     and user-supplied graph and namespaces
 
     """
 
     def __init__(self, parentdoc=None, attributes=None):
         """
-        Default contructor, creates document and adds Process activity to graph
+        Default constructor, creates document and adds Process activity to graph
         with optional attributes
-        
+
         :param parentDoc: optional ProvDocument
         :param attributes: optional dictionary of attributes to add
-    
+
         """
 
-        #set graph document
-        if (parentdoc):
+        # set graph document
+        if parentdoc:
             self.graph = parentdoc
         else:
             self.graph = Constants.NIDMDocument(namespaces=Constants.namespaces)
 
-         #execute default parent class constructor
-        super(ProcessSpecification,self).__init__(self.graph,
-                                                  pm.PROV[getUUID()],
-                                                  attributes)
+        # execute default parent class constructor
+        super().__init__(self.graph, pm.PROV[getUUID()], attributes)
         self.add_attributes({pm.PROV_TYPE: pm.PROV_ATTR_PLAN})
         self.graph._add_record(self)
```

### Comparing `pynidm-3.9.7/nidm/workflows/tests/test_workflows.py` & `pynidm-4.0.0/tests/workflows/test_workflows.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,29 +1,27 @@
-# from .. import ProcessSpecification, ProcessExecution
+# from nidm.workflows import ProcessSpecification, ProcessExecution
 #
 #
-# def test_processspec(tmpdir):
+# def test_processspec(monkeypatch, tmp_path):
 #     #create new nidm-experiment document with project
 #     proc = ProcessSpecification()
 #
-#     tmpdir.chdir()
+#     monkeypatch.chdir(tmp_path)
 #     #save a turtle file
-#     with open("test.ttl",'w') as f:
+#     with open("test.ttl",'w', encoding="utf-8") as f:
 #         f.write(proc.serializeTurtle())
 #
 #     #save a DOT graph as PDF
 #     proc.save_DotGraph("test.png", format="png")
 #
 #
-# def test_processexec(tmpdir):
+# def test_processexec(monkeypatch, tmp_path):
 #     #create new nidm-experiment document with project
 #     proc = ProcessExecution()
 #
-#     tmpdir.chdir()
+#     monkeypatch.chdir(tmp_path)
 #     #save a turtle file
-#     with open("test.ttl", 'w') as f:
+#     with open("test.ttl", 'w', encoding="utf-8") as f:
 #         f.write(proc.serializeTurtle())
 #
 #     #save a DOT graph as PDF
 #     proc.save_DotGraph("test.png", format="png")
-#
-#
```

